<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 16 Jul 2020 08:17:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 16 Jul 2020 08:17:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Collabera infected with Maze ransomware; employee data stolen]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830538">thread link</a>) | @darshansavla
<br/>
July 14, 2020 | https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8857"><div><div><div><h2>Hackers infected the recruitment and IT consultancy firm Collabera with Maze Ransomware, stole employees data</h2><p>The Basking Ridge, New Jersey, United States-based IT consulting and recruitment firm, Collabera has been hacked and infected by ransomware. The hackers believed to be from Maze ransomware group infiltrated into Collabera servers and stole exposed employee data like&nbsp;names, addresses, contact and social security numbers, dates of birth, employment benefits, and passport and immigration visa details.</p><p>Collabera is a multinational company offering information technology recruiting, staffing, consulting, and business services to companies worldwide. It is a $1billion company with more than 16,000 employees globally.</p><p>The Maze Ransomware group claimed the hacking of Collabera and infecting it with Maze ransomware on their Dark Web website in June. However, Collabera has not confirmed it was the work of Maze Ransomware. The Collabera security team discovered the ransomware attack on 8th June 2020.</p><blockquote><p>On June 8, 2020, Collabera identified malware in its network system consistent with a ransomware attack. We promptly restored access to our backup files and immediately launched an investigation to determine the nature and scope of the event. On June 10, we became aware that the unauthorized party obtained some data from our system.</p><p>Mike Chirico, director Collabera in an email to employees.</p></blockquote><p>While Collabera suffered no consequences of the ransomware, it has emerged that the hackers stole some of the exposed employee data. The company said it was informing every employee whose data was stolen. In the meantime, the company is offering two years of credit and identity monitoring services through Experian to the affected staff.</p></div></div></div></article><div><h3>About Author</h3><section> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20100%20100'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=100&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/076b4a64b03cee86288f1132004881ab?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><div> <p>Hacker, coder, Jouno by night
When a good man is hurt, all who would be called good must suffer with him</p></div></section></div></div>]]>
            </description>
            <link>https://androidrookies.com/recruiting-firm-collabera-infected-by-maze-ransomware-employees-personal-data-stolen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830538</guid>
            <pubDate>Tue, 14 Jul 2020 11:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeepSinger: Singing Voice Synthesis with Data Mined from the Web]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830477">thread link</a>) | @dgorges
<br/>
July 14, 2020 | https://speechresearch.github.io/deepsinger/ | <a href="https://web.archive.org/web/*/https://speechresearch.github.io/deepsinger/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="entry-text">
				
<ul>
<li>Yi Ren* (Zhejiang University) <a href="mailto:rayeren@zju.edu.cn">rayeren@zju.edu.cn</a></li>
<li>Xu Tan* (Microsoft Research Asia) <a href="mailto:xuta@microsoft.com">xuta@microsoft.com</a></li>
<li>Tao Qin (Microsoft Research Asia) <a href="mailto:taoqin@microsoft.com">taoqin@microsoft.com</a></li>
<li>Jian Luan (Microsoft STCA) <a href="mailto:jianluan@microsoft.com">jianluan@microsoft.com</a></li>
<li>Zhou Zhao (Zhejiang University) <a href="mailto:zhaozhou@zju.edu.cn">zhaozhou@zju.edu.cn</a></li>
<li>Tie-Yan Liu (Microsoft Research Asia) <a href="mailto:tyliu@microsoft.com">tyliu@microsoft.com</a></li>
</ul>
<p><small>* Equal contribution.</small></p>
<h2 id="chinese">Chinese</h2>
<table><thead>
<tr>
<th> / </th>
<th>Sample 1</th>
<th>Sample 2</th>
<th>Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_0K2P2e1dc_5.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 爱从不容许人三心两意<br>Phonemes: PAD ai c ong b u r ong x v r en s an x in l iang PAD i</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_0K2P2e1dc_15.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 遮住你的眼睛<br>Phonemes: zh e zh u n i d e PAD ian j ing</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/xx_XIKddfe0_37.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 好久好久<br>Phonemes: h ao j iou h ao j iou</td>
</tr>
<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_raw.wav" autoplay="">Your browser does not support the audio element.</audio> </td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_raw.wav" autoplay="">Your browser does not support the audio element.</audio>  </td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/XIKddfe0_37_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
</tr>
<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_attn_0.8244.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_splits.png"> </td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_attn_0.8329.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/zh/XIKddfe0_37_attn_0.3764.png"></td>
</tr>
<tr>
<td>Data filtration</td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8244 $)  </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8359 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.3764 $)</td>
</tr>
<tr>
<td>Singing modeling</td>
<td>
$\textit{GT (Linear+GL)}$   <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_5_pitch.png">
</td>
<td>
$\textit{GT (Linear+GL)}$   <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15.wav" autoplay="">Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src="https://speechresearch.github.io/audio/deepsinger/zh/0K2P2e1dc_15_pitch.png">
</td>
<td>
<p>/</p>
</td>
</tr>
</tbody></table>
<p>
P.S. 1) $\textit{GT}$, the ground-truth audio; 2) $\textit{GT (Linear+GL)}$, where we synthesize voices based on the ground-truth linear-spectrograms using Griffin-Lim; 3) $\textit{DeepSinger}$, where the audio is generated by DeepSinger.
</p>
<!-- 
## English
<table><thead>
<tr>
<th style="text-align: center"> / </th>
<th style="text-align: center">Sample 1</th>
<th style="text-align: center">Sample 2</th>
<th style="text-align: center">Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_1.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: But sometimes I feel so<br>Phonemes: b ʌ t s ʌ m t aɪ m z aɪ f iː l s oʊ</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_39.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: In my dreams I'm not so far away from home<br>Phonemes: ɪ n m aɪ d ɹ iː m z aɪ m n ɑː t s oʊ f ɑː ɹ ɐ w eɪ f ɹ ʌ m h oʊ m</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/xx_8GfscTff70f_37.wav" autoplay/>Your browser does not support the audio element.</audio><br>Lyrics: All my life all the time so far away from home<br>Phonemes: ɔː l m aɪ l aɪ f ɔː l ð ə t aɪ m s oʊ f ɑː ɹ ɐ w eɪ f ɹ ʌ m h oʊ m</td>
</tr>

<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_37_raw.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>


<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_1_attn_0.7427.png'/><br> Lyrics-to-singing alignment <img src='../audio/deepsinger/en/8GfscTff70f_1_splits.png'/> </td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_39_attn_0.7306.png'/><br> Lyrics-to-singing alignment <img src='../audio/deepsinger/en/8GfscTff70f_39_splits.png'/></td>
<td>Attention map <img src='../audio/deepsinger/en/8GfscTff70f_37_attn_0.4725.png'/></td>
</tr>

<tr>
<td>Data filtration</td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7427 $) </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7306 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.4725 $)</td>
</tr>

<tr>
<td>Singing modeling</td>

<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1_gt.wav" autoplay/>Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_1.wav" autoplay/>Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src='../audio/deepsinger/en/8GfscTff70f_1_pitch.png'/>
</td>

<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39_gt.wav" autoplay/>Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls" ><source src="../audio/deepsinger/en/8GfscTff70f_39.wav" autoplay/>Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src='../audio/deepsinger/en/8GfscTff70f_39_pitch.png'/>
</td>

<td>

/

</td>
</tr>

</tbody></table>
-->
<h2 id="cantonese">Cantonese</h2>
<table><thead>
<tr>
<th> / </th>
<th>Sample 1</th>
<th>Sample 2</th>
<th>Sample 3</th>
</tr></thead><tbody>
<tr>
<td>Data crawling</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bClau824b25f_3.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 我已经不懂心痛<br>Phonemes: ŋ o5 j i5 ɡ inɡ1 b a1 t d unɡ2 s a1 m t unɡɜ</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bClau824b25f_9.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 或你会了解在孤单中的心痛<br>Phonemes: w aa6 k n ei5 w ui6 l iu5 ɡ aai2 z oi6 ɡ u1 d aa1 n z unɡ1 d i1 k s a1 m t unɡɜ</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/xx_bBfZ2b39bf_32.wav" autoplay="">Your browser does not support the audio element.</audio><br>Lyrics: 唔知点解 我成日都好担心<br>Phonemes: nɡ4 z i1 d i2 m ɡ aai2 ŋ o5 s inɡ4 j a6 t d ou1 h ou2 d aa1 m s a1 m</td>
</tr>
<tr>
<td>Singing and accompaniment separation</td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
<td><audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bBfZ2b39bf_32_raw.wav" autoplay="">Your browser does not support the audio element.</audio></td>
</tr>
<tr>
<td>Lyrics-to-singing alignment</td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_attn_0.8105.png"> <br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_attn_0.7372.png"><br> Lyrics-to-singing alignment <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_splits.png"></td>
<td>Attention map <img src="https://speechresearch.github.io/audio/deepsinger/hk/bBfZ2b39bf_32_attn_0.3601.png"></td>
</tr>
<tr>
<td>Data filtration </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.8105 $) </td>
<td>Keep (Splitting Reward: $\mathcal{O} = 0.7372 $)  </td>
<td>Discard (Splitting Reward: $\mathcal{O} = 0.3601 $)</td>
</tr>
<tr>
<td>Singing modeling</td>
<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
$\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3.wav" autoplay="">Your browser does not support the audio element.</audio> <br>  
Pitch Plot
<img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_3_pitch.png">
</td>
<td>
$\textit{GT (Linear+GL)}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_gt.wav" autoplay="">Your browser does not support the audio element.</audio> <br> 
 $\textit{DeepSinger}$  <br>  <audio controls="controls"><source src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9.wav" autoplay="">Your browser does not support the audio element.</audio> <br>
 Pitch Plot
 <img src="https://speechresearch.github.io/audio/deepsinger/hk/bClau824b25f_9_pitch.png">
</td>
<td>
<p>/</p>
</td>
</tr>
</tbody></table>

<p><a href="https://speechresearch.github.io/unsuper/">Almost Unsupervised Text to Speech and Automatic Speech Recognition</a><br>
<a href="https://speechresearch.github.io/fastspeech/">FastSpeech: Fast, Robust and Controllable Text to Speech</a><br>
<a href="https://speechresearch.github.io/multispeech/">MultiSpeech: Multi-Speaker Text to Speech with Transformer</a><br>
<a href="https://speechresearch.github.io/seminas/">Semi-Supervised Neural Architecture Search</a><br>
<a href="https://speechresearch.github.io/lrspeech/">LRSpeech: Extremely Low-Resource Speech Synthesis and Recognition</a><br>
<a href="https://speechresearch.github.io/fastspeech2/">FastSpeech 2: Fast and High-Quality End-to-End Text-to-Speech</a><br>
<a href="https://speechresearch.github.io/uwspeech/">UWSpeech: Speech to Speech Translation for Unwritten Languages</a><br></p>
<!-- ### Good Alignment Example

<p>
Splitting Reward: $\mathcal{O} = 0.8024 $  
</p>

<img src='../audio/deepsinger/good_align.png'/>
<audio controls="controls" ><source src="../audio/deepsinger/good_align.wav" autoplay/>Your browser does not support the audio element.</audio>

### Bad Alignment Example

<p>
Splitting Reward: $\mathcal{O} = 0.3196 $  
</p>

<img src='../audio/deepsinger/bad_align.png'/>
<audio controls="controls" ><source src="../audio/deepsinger/bad_align.wav" autoplay/>Your browser does not support the audio element.</audio>


## Audio Samples

<!-- ### Chinese  -->
<!-- 
*爱从不容许人三心两意*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/0.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>


*遇见浑然天成的交集*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>



*遮住你的眼睛*

<table><thead>
<tr>
<th style="text-align: center">Raw Audio</th>
<th style="text-align: center">Vocal (after seperation)</th>
<th style="text-align: center">GT (Linear+GL)</th>
<th style="text-align: center">DeepSinger</th>
</tr></thead><tbody>
<tr>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/raw/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/gt_gl/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td><audio controls="controls" ><source src="../audio/deepsinger/audio/ds/2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody></table>

<br> --> 

			</section></div>]]>
            </description>
            <link>https://speechresearch.github.io/deepsinger/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830477</guid>
            <pubDate>Tue, 14 Jul 2020 11:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could predictive database queries replace machine learning models?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23830474">thread link</a>) | @tlarkworthy
<br/>
July 14, 2020 | https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models | <a href="https://web.archive.org/web/*/https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This post appeared first on <a href="https://towardsdatascience.com/predictive-queries-vs-supervised-ml-models-ee7f17e4840e">Towards Data Science</a> in July 12th, 2020.</p></blockquote><p>One of the greatest trends in today’s technology landscape is the <a href="http://knowledge.wharton.upenn.edu/article/democratization-ai-means-tech-innovation/">democratization of machine learning</a>. Because the commodity state-of-the-art models, better tooling and better access to hardware: machine learning is becoming an everyday tool in the companies’ toolbox.</p><p>The ML democratization is still an on-going trend and given the disruption in this space it’s worth asking: where will this transformation take us? What the future of the everyday ML will look like?</p><p>Predictive queries are an interesting take on machine learning, especially in the ML democratization context. Solutions like <a href="http://probcomp.csail.mit.edu/">MIT’s</a> <a href="https://github.com/probcomp/bayeslite">BayesDB/BayesLite</a> and Aito provide a way to get arbitrary predictions instantly with SQL-like queries. As an example, here’s a predictive query in Aito:</p><div data-language="json"><pre><code><span>{</span>
  <span>"from"</span><span>:</span> <span>"invoice_data"</span><span>,</span>
  <span>"where"</span><span>:</span> <span>{</span>
    <span>"Item_Description"</span><span>:</span> <span>"Packaging design"</span><span>,</span>
    <span>"Vendor_Code"</span><span>:</span> <span>"VENDOR-1676"</span>
  <span>}</span><span>,</span>
  <span>"predict"</span><span>:</span> <span>"Product_Category"</span>
<span>}</span></code></pre></div><p>As such: the predictive queries seem like an easier, faster and radically different way to do machine learning. They give a glimpse of a future, where anyone can do machine learning as easily as one does database queries.</p><p>This article gives a brief introduction to the predictive queries, and it compares the predictive queries to supervised learning through 3 different aspects that are:</p><ol><li>The workflow, comparing the easiness and the costs between predictive queries and supervised machine learning</li><li>The architecture, comparing the high level differences between using predictive queries and using supervised models</li><li>And the qualitative properties (scaling, accuracy) as the quality is an obvious concern for an emerging, if promising, technology.</li></ol><h2>Introduction to the predictive queries</h2><p>Predictive queries resemble normal database queries with the exception that they provide predictions about the unknown, while the traditional database queries provide facts about the known. Here’s an example of the BQL (Bayesian Query Language) query done against BayesDB/BayesLite database:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-queries-in-bayeslite.png" alt=""></p></div><p><span>Predictive BayesQL queries in BayesLite. BayesQL is based on SQL and it provides a very elegant way to query arbitrary estimates. This query can be executed after the CREATE POPULATION, CREATE ANALYSIS, INITIALIZE ANALYSIS and ANALYZE operations. </span></p></div><p>In essence, the predictive queries can provide a very SQL-like alternative to the supervised ML models with the key differences that:</p><ol><li><p>While supervised machine learning models need to be configured, trained and deployed before usage, the predictive queries provide instant answers after the database is prepared with data. As such: the predictive queries have a different workflow.</p></li><li><p>While supervised machine learning is always specialized for a single prediction from A to B, predictive queries can be used a) to instantly predict any unknown X based on any known Y and b) to provide also recommendations, smart search and pattern mining. As such, the supervised models are narrow, while the predictive queries are multipurpose, which has implications on the architecture.</p></li><li><p>While with the supervised machine learning the narrow models are explicitly formed train time, the predictive queries do multi-purpose modeling write time or narrow modeling during query time. As such: the predictive queries are technically more challenging.</p></li></ol><p>Only few solutions exist, that provide such predictive queries. One is the mentioned BayesDB/BayesLite, which creates an in-memory multi-purpose models in a special preparation phase. Another solution is Aito.ai, which does query-time narrow modeling without explicit preparations. Here’s is an example of the Aito workflow:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-queries-in-3-steps.png" alt=""></p></div><p><span>Predictive BayesQL queries in BayesLite. BayesQL is based on SQL and it provides a very elegant way to query arbitrary estimates. This query can be executed after the CREATE POPULATION, CREATE ANALYSIS, INITIALIZE ANALYSIS and ANALYZE operations. </span></p></div><p>We are focusing the following comparisons on Aito. We feel this focus is justified as in Aito we are more familiar with the solution, and it is mature enough to serve the end customers in live production settings. While BayesLite is extremely impressive and their BQL interface and DB/ML integration are worth envy: BayesLite seems to have properties like the 16 minute preparation phase for simple data, which are not consistent with the presented arguments.</p><p>So let’s next dig deeper on the difference in workflow, architecture and quality between the predictive queries and supervised ML models.</p><h2>1. The Workflow</h2><p>The first difference between predictive queries and the traditional supervised models relates to the workflow and the costs.</p><p>Supervised ML models are deployed typically in data science projects, which have several steps like the handover to the data scientist, data preparation, feature engineering, model fitting, deployment, integrations, retraining and monitoring &amp; maintenance. As an addition to this linear progression, you also often have an iteration phase, where the results are improved by refining the data, the preparations, the features, the models, the deployment or the integrations.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-data-science-project-workflow.png" alt=""></p></div><p><span>A simplified version of the data science project.</span></p></div><p>Taking a supervised model to production may take several weeks or months from one to two persons. This can raise the price point up to hundred thousand euros per model. If you need several models, you need several data science projects, leading to multiplied expenses and delays.</p><p>Now this process changes rather dramatically, if you implement the machine learning functionality with predictive queries. With predictive queries the workflow is in essence the following:</p><ol><li>Prepare the auxiliary <a href="https://aito.ai/blog/introducing-a-new-database-category-the-predictive-database/">predictive database</a> once (if it’s not used as the main database)</li><li>Verify good enough prediction quality with evaluate requests</li><li>Integrate the predictive queries like you would integrate SQL queries</li><li>Write the test/evaluation cases, push these to Git and let the CI handle the regression testing</li><li>If seen as necessary: track the in-production prediction quality with analytics and display the metrics in the product dashboard.</li></ol><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-query-workflow.png" alt=""></p></div><p><span>The workflow with the predictive queries is similar to the workflow with the database queries. Still, because predictive functionality is statistical and its behavior may drift as the data changes: it is advisable to verify the prediction quality (step 2) before implementation and monitor the prediction quality in production (step 5).</span></p></div><p>While putting an auxiliary database (like ElasticSearch) into production can take weeks, the expense related to putting each query into production is closer to the expense of using search/database queries. Often such queries form only a small part of the related functionality’s expense, and often the query based functionality can be implemented in hours and put into production in days.</p><p>This dramatic difference between the workflows and the expenses are explained a) partly by the <a href="https://aito.ai/blog/introducing-a-new-database-category-the-predictive-database/">predictive database</a>’s AutoML capabilities that are accelerated by a specialized database and b) partly by the reduced need for deployments and integrations as the data and the ML are already integrated into a single system. The complex phases of the data science project get systematically eliminated or simplified:</p><ol><li>The handover of the data science project to the data scientist is not needed as the predictive query workflow is easy enough for the software developers.</li><li>Data preparation and feature engineering steps can be greatly eliminated with the ML-database integration. You don’t need to re-prepare and re-upload the data, if the data is already in the database. You don’t need to manually aggregate data into flat data frames, if you can do <a href="https://aito.ai/docs/articles/utilizing-relationships-in-aito/">inference through the database references</a>. You don’t need to manually featurize text either, as the predictive database analyzes the <a href="https://aito.ai/docs/api/#schema-analyzer">text automatically</a> just like ElasticSearch. Last: you don’t need to manage feature redundancies, if the database has built-in <a href="https://aito.ai/blog/introducing-concept-learning-to-free-you-from-feature-engineering/">feature learning capabilities</a>.</li><li>Modeling phase can be automated with a single sophisticated model that provides good enough results for most applications.</li><li>Per model cloud deployment, live integrations and retraining of models simply disappear, because you don’t need to ‘deploy’ or retrain the predictive queries. Instead you integrate one auxiliary predictive database like you would integrate <a href="https://www.elastic.co/">ElasticSearch</a>. If you use the predictive database as your main database, you can omit even that one integration.</li><li>Maintenance is easier, because instead of maintaining deployed infrastructure for each prediction target, you maintain the SQL-like queries like you would maintain code with Git &amp; CI.</li></ol><p>As a consequence, the workflow and the cost of implementing ML via predictive queries is similar to the process of implementing normal business logic via SQL.</p><p>The second difference between the predictive queries and the supervised models is the narrowness and it’s implications on the software architecture.</p><p>Famously: the supervised ML models are <em>narrow</em> in 2 different respects:</p><p>1.Narrowness of the prediction setting. Supervised learning models are essentially narrow functions from A (e.g. text) to B (category), which means that if you have 10 different problems, you end up with with 10 different supervised ML models.
2. Narrowness of the predictive functionality type. A single kind of supervised method can typically serve only one kind of predictions. For this reason you often need completely separate systems or products to implement predictions, recommendations, smart search and pattern mining.d up with with 10 different supervised ML models.</p><p>This combined narrowness has negative implications on the architecture. If you have 10 different predictive functionalities that mix prediction, recommendation and smart search use cases: you end up struggling with a very complex system. The system may include separate supervised model platform with half dozen deployed models, separate recommendation system, a separate smart searching product and separate pattern mining tools. Such complexity is hard to learn, master and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models">https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models</a></em></p>]]>
            </description>
            <link>https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830474</guid>
            <pubDate>Tue, 14 Jul 2020 11:01:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Purism-Librem13v4]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23830046">thread link</a>) | @luu
<br/>
July 14, 2020 | https://anarc.at/hardware/laptop/purism-librem13v4/ | <a href="https://web.archive.org/web/*/https://anarc.at/hardware/laptop/purism-librem13v4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">


          

            <p>The <a href="https://puri.sm/products/librem-13/">Purism Librem 13</a> is a 13" laptop that's similar to the
Macbook Air but slightly heavier and thicker, from what I
understand. I have the <code>v4</code> means it's the fourth hardware version of
the device. This is the latest incarnation of the <a href="https://anarc.at/hardware/angela/">angela</a>
node.</p>

<p>TL;DR: I recommend people avoid the Purism brand and products. I find
they have questionable politics, operate in a "libre-washing" fashion,
and produce unreliable hardware. Will not buy again.</p>






<ul>
<li>Operating system: PureOS</li>
<li>TPM: Included</li>
<li>Battery life: Roughly 7 to 9 hours (actual: more like 6h)</li>
<li>Processor: Core i7 7500U (Kabylake)</li>
<li>Display: 13.3" 1920×1080</li>
<li>Graphics: Intel HD Graphics 620</li>
<li>Memory: Up to 32GB, DDR4 at 2133 MHz</li>
<li>Storage: 2.5" SATA + NVMe-capable M.2 slots</li>
<li>Chassis: Black anodized aluminium</li>
<li>Webcam: 720p 1.0 megapixel</li>
<li>Dimensions: 325×219×18mm</li>
<li>Weight: 1.4kg</li>
<li>Wireless: Atheros 802.11n w/ Two Antenna</li>
<li>Radio hardware killswitch: Yes</li>
<li>Mic and cam killswitches: Yes</li>
<li>Audio port: 1 headphone/line output jack</li>
<li>USB ports: 2 USB 3.0 Ports (1 type C, data transfer only)</li>
<li>External monitor output: 1 HDMI Port (4K capable @ 30Hz max)</li>
<li>Card reader: Yes, 2-in-1 SD/MMC</li>
<li>Backlit keyboard: Yes</li>
<li>Touch interface: Elantech Multitouch Trackpad</li>
<li>Thermal design: Low noise fan (actual: not really, quite noisy when
all CPUs are maxed)</li>
</ul>


<p>The machine came with a 250GB Crucial SSD drive with PureOS
pre-installed, even if I ordered it without storage.</p>

<h2 id="semi-standard-power-connector"><a name="index1h2"></a>Semi-standard power connector</h2>

<p>The power connector is <a href="https://learn.sparkfun.com/tutorials/connector-basics/power-connectors">somewhat standard</a>: 19V DC on a 5.5mm
sleeve with 2.5 positive pin, with a <a href="https://en.wikipedia.org/wiki/IEC_60320#C5/C6_coupler">C5/C6 cable</a> for the AC side
(as opposed to the more standard C13/C14 coupler, mind you). I was
able to find a "universal 19V adapter" for ~60$ at a local store that
also supported other barrel connectors.</p>

<p>It would be better if the laptop would charge through USB-C,
naturally, as <em>that</em> is slowly becoming the standard for charging
computing devices, but that will have to do for now.</p>

<h2 id="good-monitor"><a name="index2h2"></a>Good monitor</h2>

<p>The monitor shipped with the Librem is actually quite good by my
standards (1920x1080 / 1080p / FullHD). It does mean messing around
with <a href="https://wiki.debian.org/MonitorDPI">HiDPI</a> settings which I haven't quite figured out yet.</p>

<p><a href="https://vincent.bernat.ch/en/blog/2018-4k-hidpi-dual-screen-linux">This post</a> seems to have good resources. From what I understand,
the resolution of the screen is actually 166dpi, which takes some
configuring to display properly. This can be computed from the aspect
ratio (16:9), the resolution (1920x1080) and the diagonal of the
screen (13.3"). According to <a href="https://www.sven.de/dpi/">this calculator</a>, this is the
formula:</p>

<pre><code>Display size: 11.59" × 6.52" = 75.59in² (29.44cm × 16.56cm = 487.64cm²) at 165.63 PPI, 0.1534mm dot pitch, 27434 PPI² 
</code></pre>

<p>All this does make my old monitor (which I found in the basement) look
like crap. So I need to find a <a href="https://forums.puri.sm/t/suitable-external-monitor-for-librem-13/5627">new monitor</a>, arguably not a
problem with the Librem per se of course...</p>

<p>It seems the Librem can drive 1440p, so not "4K UHD" (3840x2160), but
"QHD" (2560x1440) which should be more than enough.</p>

<h2 id="liberated-boot"><a name="index3h2"></a>Liberated boot</h2>

<p>The Purism folks did a pretty awesome job at liberating their
BIOS. They run their own version of coreboot they call
<a href="https://docs.puri.sm/PureBoot.html">Pureboot</a>. In theory, it should be easier to setup a trusted,
<a href="http://wiki.debian.org/SecureBoot">SecureBoot</a> but in practice I have yet to set that up.</p>

<p>I did try to configure the laptop with an encrypted <code>/boot</code>, but that
didn't go so well. First, I get a double password prompt: once in
<code>grub</code> and once in the <code>initramfs</code>. But more annoying is the <code>grub</code>
prompt has no retry: if you fail, you drop in the rescue shell which
is really impractical.</p>

<p>(Update: that is, of course, not specific to Purism or PureOS, but a
limitation in grub itself.)</p>

<p>Finally, Pureboot doesn't support encrypted <code>/boot</code> so it actually
makes it <em>harder</em> to implement trusted boot.</p>

<p>The coreboot stuff needs to be updated, and instructions are available
<a href="https://puri.sm/coreboot/">on the Purism website</a>.</p>

<h2 id="excellent-linux-support"><a name="index4h2"></a>Excellent Linux support</h2>

<p>On top of the liberated BIOS, it must be said the device has
<em>excellent</em> support for free operating systems. <em>Every</em> device on the
machine has full support in the Linux kernel, even the "older" version
in Debian stretch (Linux 4.9). No binary blobs, no proprietary
drivers, even for wifi.</p>

<p>That is just awesome. It's the first device, in a long time, that
gives me this freedom, so it should be acknowledged and celebrated.</p>

<p>Update: I still have some <code>non-free</code> packages installed:</p>

<ul>
<li><p>the Intel CPU firmware package (<a href="http://packages.debian.org/intel%2Dmicrocode">intel-microcode</a>)</p></li>
<li><p>I also use some "non-free" documentation packages (<a href="http://packages.debian.org/doc%2Drfc">doc-rfc</a>, <a href="http://packages.debian.org/emacs%2Dcommon%2Dnon%2Ddfsg">emacs-common-non-dfsg</a>, <a href="http://packages.debian.org/make%2Ddoc">make-doc</a>)</p></li>
<li><p>Bluetooth requires <a href="http://packages.debian.org/firmware%2Datheros">firmware-atheros</a></p></li>
</ul>


<p>When building the <code>initramfs</code>, there are warnings about the <code>i915</code>
graphics controller, which is solved by installing the <a href="http://packages.debian.org/firmware%2Dmisc%2Dnonfree">firmware-misc-nonfree</a> package, but the graphics card works without
the firmware. Apparently, the warnings are harmless and indeed PureOS
fixed <a href="https://tracker.pureos.net/T362">the bug</a> by simply <a href="https://source.puri.sm/pureos/core/initramfs-tools/commit/005ca5b834fa7ee44bb913d74b4ff2aa542fc9d1">disabling all such warnings</a>.3</p>

<p>The Debian-specific stuff is also documented in <a href="https://wiki.debian.org/InstallingDebianOn/Purism/Librem%2013">the Debian wiki</a>.</p>

<h2 id="good-speakers"><a name="index5h2"></a>Good speakers</h2>

<p>The builtin speakers sound great.</p>



<p>I have a few issues with the device.</p>

<h2 id="weird-keyboard-layout"><a name="index6h2"></a>Weird keyboard layout</h2>

<p>The <a href="https://forums.puri.sm/t/keyboard-layout-unable-to-recognize-pipe/2022">keyboard layout is strange</a>: the key above <kbd>enter</kbd>,
instead of sending <kbd>\</kbd> or <kbd>|</kbd>, sends
"chevrons". This is due to the Purism folks expecting you to pick the
"US international" keyboard instead of the "US" keyboard, which is a
very strange pick, as the "US" keyboard seems pretty standard. The
workaround is to drop this in your <code>udev</code> configuration, say in
<code>/etc/udev/hwdb.d/90-purism-pipe-symbol-fix.hwdb</code>:</p>

<pre><code>evdev:atkbd:dmi:bvn*:bvr*:bd*:svnPurism:pnLibrem13v4*
 KEYBOARD_KEY_56=backslash
</code></pre>

<p>Then running:</p>

<pre><code>sudo systemd-hwdb update
sudo udevadm trigger
</code></pre>

<p>The keyboard layout, in general, is a little unique: the sound buttons
are split across the <kbd>F4</kbd> key (mute) and
<kbd>-</kbd>/<kbd>=</kbd> (volume up/down keys) for some reason.</p>

<p>The <kbd>PrtSc</kbd> key <a href="https://forums.puri.sm/t/does-alt-sysrq-work-on-librem-laptops/5290/9">can be as SysRq</a> but is <em>backwards</em>
(<kbd>ScrLk</kbd> <kbd>PrtSc</kbd>) to their usual order
(<kbd>PrtSc</kbd> <kbd>ScrLk</kbd>).</p>

<h2 id="limited-usb-c-port"><a name="index7h2"></a>Limited USB-C port</h2>

<p>The USB-C port <a href="https://forums.puri.sm/t/is-hdmi-over-usb-c-possible-on-13v2/2020">does not support video</a> which makes it limited to
charging and data transfer. It can also not charge the laptop itself,
as there's a separate power connector, losing many of the benefits
usually associated with USB-C.</p>

<p>Ideally, a USB-C port might be used as a universal docking port: one
wire to plug and you have power, video, audio, and USB for keyboard
and mouse. Unfortunately, I'm still stuck with about 4 wires to plugin
when I come into the office, something I was hoping to avoid. People
have <a href="https://forums.puri.sm/t/please-recommend-a-port-replicator-docking-station/1115">looked for a dock station</a> without success.</p>

<h2 id="shipping-delays-doa"><a name="index8h2"></a>Shipping delays, DOA</h2>

<p>I waited almost four weeks to have my laptop delivered. Presumably
this was due to a <a href="https://forums.puri.sm/t/where-was-purism-moving/5799/">warehouse move</a> but I found that communication
about the issue could have been better. Worse: the laptop was <a href="https://forums.puri.sm/t/librem-13v3-bricked/5714/19?u=anarcat">dead on
arrival</a> (DOA) so I had to return it, adding another week delay for
getting an actual working laptop. FedEx even charged me for the return
even though Purism actually issued a shipping label, something I still
haven't quite resolved.</p>

<p>Update: I ended up paying over 260$ in shipping fees to Fedex, in the
end. I first paid around 70$ for the first laptop sent, then Fedex
sent me <em>another</em> 200$ bill for the <em>second</em> laptop. Purism were
unable to help me with this issue and Fedex has been totally useless
as well. I've tried to reach to both organizations to get around those
fees but the time wasted waiting on hold and support has outgrown the
possible savings I could to by not paying the damn bill, so I just
paid it now.</p>

<h2 id="bright-leds-not-accessible-when-lid-closed"><a name="index9h2"></a>Bright LEDs, not accessible when lid closed</h2>

<p>There are three leds on the top right of the keyboard: one for wifi,
battery and power. They are very bright and even though they can
technically be dimmed, the firmware is not open so there's <a href="https://forums.puri.sm/t/is-there-a-way-to-dim-the-leds-on-the-13-v2/1172">no way to
dim the LEDs</a>.</p>

<h2 id="no-ethernet-port"><a name="index10h2"></a>No ethernet port</h2>

<p>That was a deal breaker for me originally, but I changed my
mind. First, I don't need gigabit transfer speeds that often. Then my
office doesn't have wired connectivity yet, so it is not that
useful. Plus, I can afford to have a USB dongle there with a gigabit
ethernet port, indeed, I already have one of those USB hubs. So not
that big of a deal.</p>

<h2 id="libre-washing"><a name="index11h2"></a>Libre-washing</h2>

<p>I have found Purism's commitment to free hardware and free software to
be questionable. While, yes, they try to provide a <a href="#liberated-boot">liberated boot</a>
and coreboot-based BIOS, that BIOS is not free software. At best they
"neuter" the Intel Management Engine, but you still require non-free
firmware to operate a Librem Computer, from the CPU down to the
Bluetooth and Wifi hardware. Even if that is a very common pattern on
laptops and phone, it is a huge disconnect with the "purity" and
"freedom" narrative on their website.</p>

<p>For example, the replacement for the Librem 13, called Librem 14,
claims to be:</p>

<blockquote><p><strong>The first 14″ laptop designed to protect your digital life</strong></p>

<p>Ultra-portable workstation laptop that was designed chip-by-chip,
line-by-line, to respect your rights to privacy, security, and
freedom.</p></blockquote>

<p>Yet it still ships with Intel processors, known for a large variety of
fundamental security issues that are part of the hardware design,
which Intel refuses to fix. That it ships <a href="https://puri.sm/coreboot/">coreboot</a> on top of that
is besides the point: coreboot, as shipped by Purism, is not open
source, or at least ships proprietary blobs.</p>

<p>Compare this with the work System76 has been doing in recent
times. While they brand themselves as just a company shipping Linux
laptops, they <a href="https://blog.system76.com/post/187072707563/the-new-firmware-manager-updating-firmware-across">work with the de-facto standard LVFS</a> (even though
that is a <a href="https://blog.system76.com/post/173801677358/system76-and-lvfs-what-really-happened">bumpy ride</a>), actually <a href="https://blog.system76.com/post/612315972866637824/a-look-back-at-manufacturing">design and prototype their own
hardware</a>, and <a href="https://opensource.com/article/20/1/system76-open-source-firmware">liberated their keyboard microcontroller</a>. They
have even started <a href="https://blog.system76.com/post/186655523269/open-firmware-and-more-news-from-july">working on an open Thunderbolt
microcontroller</a>. And while those might sound like small things
compared to liberating the CPU firmware, I will point out that they
actually <em>succeed</em> in completely liberating those components, while
Purism, in the <em>years</em> they have supposedly been working on those
projects, have only managed to reuse (and, to be fair, improve on) the
work <em>others</em> have done to neutralize the IME.</p>

<p>What has Purism done, in the meantime? Neutralized IME. That's
it. They have not published <em>anything</em> on LVFS. Even closed-source
companies like <a href="https://fwupd.org/lvfs/vendors/#logitech">Logitech</a>, <a href="https://fwupd.org/lvfs/vendors/#synaptics">Synaptics</a>, <a href="https://fwupd.org/lvfs/vendors/#hp-ws">HP</a> and <a href="https://fwupd.org/lvfs/vendors/#dell">Dell</a>
ship their updates on LVFS. Purism <a href="https://fwupd.org/lvfs/vendors/#purism">has a test account</a> and work
has been <a href="https://forums.puri.sm/t/submit-firmware-to-linux-vendor-firmware-service-lvfs-for-easy-updating/4731">stalled for years now</a>.</p>

<h2 id="bullshit-anti-interdiction"><a name="index12h2"></a>Bullshit anti-interdiction</h2>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anarc.at/hardware/laptop/purism-librem13v4/">https://anarc.at/hardware/laptop/purism-librem13v4/</a></em></p>]]>
            </description>
            <link>https://anarc.at/hardware/laptop/purism-librem13v4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830046</guid>
            <pubDate>Tue, 14 Jul 2020 09:38:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatland Challenge - Multi Agent Reinforcement Learning on Trains]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829991">thread link</a>) | @jonbaer
<br/>
July 14, 2020 | https://www.aicrowd.com/challenges/flatland-challenge | <a href="https://web.archive.org/web/*/https://www.aicrowd.com/challenges/flatland-challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="description-wrapper">
        <div>
          <div data-controller="challenge-overview" data-action="resize@window->challenge-overview#showTOC" data-challenge-overview-scrollable-tabs="true">
            <blockquote>
<p>The Flatland 2019&nbsp;challenge has ended! Do you want more?</p>

<p><a href="https://www.aicrowd.com/challenges/neurips-2020-flatland-challenge/"><strong>Check out the NeurIPS 2020 Flatland challenge!</strong></a></p>
</blockquote>

<figure><img alt="flatland_logo" src="https://s3.eu-central-1.amazonaws.com/aicrowd-static/SBB/images/Flatland_Logo.svg"></figure>

<p><strong>The key question we want to answer here is: How can trains learn to automatically coordinate among themselves, so that there are minimal delays in large train networks ?</strong></p>

<h2>Abstract</h2>

<p><i>The Flatland Challenge is a competition to foster progress in multi-agent reinforcement learning for any </i><a href="https://en.wikipedia.org/wiki/Vehicle_rescheduling_problem"><i>re-scheduling problem (RSP)</i></a><i>. The challenge addresses a real-world problem faced by many transportation and logistics companies around the world (such as the Swiss Federal Railways, SBB. Different tasks related to RSP on a simplified 2D multi-agent railway simulation must be solved. Your contribution may shape the way modern traffic management systems (TMS) are implemented not only in railway but also in other areas of transportation and logistics. This will be the first of a series of challenges related to re-scheduling and complex transportation systems.</i></p>

<h2>Background</h2>

<p>The Swiss Federal Railways (SBB) operate the densest mixed railway traffic in the world. SBB maintain and operate the biggest railway infrastructure in Switzerland. Today, there are more than 10,000 trains running each day, being routed over 13,000 switches and controlled by more than 32,000 signals. Each day 1.2 million passengers and almost half of Switzerland’s volume of transported goods are transported on this railway network. Due to the growing demand for mobility, SBB needs to increase the transportation capacity of the network by approximately 30% in the future.</p>

<p>The increase in transport capacity can be achieved through different measures, such as <a href="https://smartrail40.ch/index.asp?inc=&amp;lang=en">denser train schedules, investments in new infrastructure, and/or investments in new rolling stock</a>. However, SBB currently lack suitable technologies and tools to quantitatively assess these different measures.</p>

<p>A promising solution to this dilemma is a complete railway simulation that efficiently evaluates the consequences of infrastructure changes or schedule adaptations for network stability and traffic flow. A complete railway simulation consists of a full dynamical physics simulation as well as an automated traffic management system.</p>

<figure><img alt="flatland_visual" src="https://s3.eu-central-1.amazonaws.com/aicrowd-static/SBB/images/Flatland_Preview.svg"></figure>

<p><i><strong>Flatland</strong>: This image illustrates an early draft of the environment visualization. The core task of this challenge is to manage and maintain railway traffic on complex scenarios in complex networks.</i></p>

<p>The research group at SBB has developed a high-performance simulator which simulates the dynamics of train traffic as well as the railway infrastructure. Different approaches for <a href="https://on-demand-gtc.gputechconf.com/gtcnew/on-demand-gtc.php?searchByKeyword=erik%20nygren&amp;searchItems=&amp;sessionTopic=&amp;sessionEvent=&amp;sessionYear=&amp;sessionFormat=&amp;submit=&amp;select=">automated traffic management systems (TMS)</a> are currently under investigation. The role of the traffic management system is to select routes for all trains and decide on their priorities at switches in order to optimize traffic flow across the network.</p>

<p>At the core of this challenge lies the general vehicle re-scheduling problem (VRSP) proposed by Li, Mirchandani and Borenstein in 2007:</p>

<blockquote>
<p>The vehicle rescheduling problem (VRSP) arises when a previously assigned trip is disrupted. A traffic accident, a medical emergency, or a breakdown of a vehicle are examples of possible disruptions that demand the rescheduling of vehicle trips. The VRSP can be approached as a dynamic version of the classical vehicle scheduling problem (VSP) where assignments are generated dynamically.</p>
</blockquote>

<p>The “Flatland” Competition aims to address the vehicle rescheduling problem by providing a simplistic grid world environment and allowing for diverse solution approaches. The challenge is open to any methodological approach, e.g. from the domain of reinforcement learning or of operations research.</p>

<p>The problems are formulated as a 2D grid environment with restricted transitions between neighboring cells to represent railway networks. On the 2D grid, multiple agents with different objectives must collaborate to maximize global reward. There is a range of tasks with increasing difficulty that need to be solved as explained in the coming sections.</p>

<h2>Tasks</h2>

<p>The challenge requires your creativity and savviness. In 3 submission rounds with increasing difficulty, you can prove that you have what it takes. We invite you to enter the race with your unique solution and to win great prizes - at the same time solving one of the key challenges in the world of transportation!</p>

<p>Here is a teaser of what we expect you to do:&nbsp;</p>

<figure><img alt="Teaser" src="https://i.imgur.com/9cNtWjs.gif"></figure>

<p>Your overall goal is to make all agents (trains) arrive at their target destination with a minimal travel time. In other words, we want to minimize the time steps (or wait time) that it takes for each agent in the group to reach its destination.</p>

<p>Let’s say in a scenario with n-agents, the travel time is measured by the collected amount of timesteps all the agents have until the n-th agent arrives at its destination.</p>

<h3>1. Can you design the best-performing agent?</h3>

<p>Design the best-performing agent. At the more basic levels, the agents may achieve their goals using ad-hoc decisions. But as difficulty increases from round to round, the agents have to be able to plan ahead, i.e. with increasing difficulty, planning becomes more relevant!</p>

<h3>2. Can you design the best observation?</h3>

<p>As a participant, you have the choice. You can either work with the three base observations that we prepared or better, design an improved observation yourself. If you do the latter, then share your observation and you will have chances of winning the Community Contribution Prize (see Prizes). These are the three base observation that we prepared:</p>

<p>Global Observation: The whole scene is observed</p>

<p>Local Grid Observation: A local grid around the agent is observed</p>

<p>Tree Observation: The agent can observe its navigable path to some predefined depth.</p>

<p>Sounds complicated? Do not despair, the next sections will provide you with more useful information about these rounds!</p>

<h2>Timeline</h2>

<p>There will be 3 rounds in the challenge. The first one (round 0) is a beta round and serves as an introduction to get familiar with Flatland (as well as bug fixing). Rounds 1 and 2 pose the actual problems to be solved. Submissions are only accepted for Round 1 and Round 2, both rounds will contribute to the final ranking. <strong>Round 2 is currently ongoing and will close on Sunday, 5th of January 2020, 12 PM, UTC +1.</strong></p>

<h3>Round 0: Learn to navigate (Beta Round)</h3>

<p>A single agent has to navigate from a freely chosen starting point to a freely chosen target destination on a random infrastructure. It is, in other words, a relatively simple shortest path problem.</p>

<p>There will be no uploading possibility, no ranking, nor any prizes to be gained in this round - but the collected insights make it all worth it!</p>

<p>Check out this simple <a href="https://gitlab.aicrowd.com/flatland/baselines/blob/master/torch_training/Getting_Started_Training.md">introduction to training</a> to get started with your own training on Flatland.</p>

<p><strong>The beta round starts on the 1st of July 2019 and ends on the 30th of July 2019</strong></p>

<figure><img alt="Round0" src="https://i.imgur.com/t5ULr4L.gif"></figure>

<h3>Round 1: Avoid conflicts</h3>

<p>We pick-up the same problem from the previous round and turn it into a multi-agent problem. This means, multiple agents have to find their ways to their respective target destinations. In this scenario you are likely to encounter resource conflicts when two or more agents simultaneously plan to occupy the same section of infrastructure. Thus, the agents have to learn to avoid conflicts and find feasible solutions. By timely submitting your solution and adhering to the <a href="#rules">participation rules</a> you are automatically eligible for the <a href="#prizes">Contribution Prize &amp; Best Agent Prize</a>. Good luck!</p>

<p><strong>Round 1 will open on Tuesday, 30th of July and close on Sunday, 13th of October 2019, 12 PM, UTC +1.</strong> <strong>Round 1 submissions closed early in order to start with Round 2 as early as possible.</strong> <strong>If you still want to test your code on earlier version please get in touch with us directly.</strong></p>

<figure><img alt="Round1" src="https://i.imgur.com/AvBHKaD.gif"></figure>

<p><strong>Round 2: Optimize train traffic</strong>: In reality, not all trains can go at the same speed. In round 2 we introduce additional complexity to the multi-agent-problem of round 1 by letting the trains have different speeds! Furthermore, stochastic events will occur during the episodes which mean that your controller will need to adapt to a changing environment. Key features of the updated environment are:</p>

<ul>
	<li>Agents travel at 4 different speeds.</li>
	<li>Some agents will experience malfunctions which render them immobile at times.</li>
	<li>Agents have to actively start their journey in the environment and leave the environment when they reach their target.</li>
</ul>

<p>This means that a good solution not only avoids/resolves conflicts, but also optimizes by taking into account that slower agents can slow down the faster ones. The prize is reserved for the winner who submits the solution with the minimal cumulated travel time for all agent. By submitting your solution timely and adhering to the <a href="#rules">participation rules</a>, you are automatically eligible for the <a href="#prizes">Contribution Prize &amp; Best Agent Prize</a>. Good luck!</p>

<figure><img alt="Round2" src="https://i.imgur.com/Pc9aH4P.gif"></figure>

<p><strong>Round 2 is now open and will close on Sunday, 5th of January 2020, 12 PM, UTC +1.</strong></p>

<h2>Environment</h2>

<p>There are a few important basic elements and notions specific to this challenge that you should be aware of before diving into the “Lets get started” section.</p>

<h3>Agent</h3>

<p>Flatland is a discrete time simulation, that means that all actions performed happen with a constant time step. At each step, the agents can choose an action. The term agent is defined as an entity that can move within the grid and must solve tasks - these agents are, who would have thought, trains. A train does basically two things: wait or go into a particular direction. Depending on the train type (e.g. freight train or passenger train), they have different speeds. An agent can move in any arbitrary direction (if the environment permits it) and transition from one cell to the next. If the agent chooses a valid action, the corresponding transition will be executed and the agent’s position and orientation is updated. Each agent has its individual start and target.</p>

<p>Agent at start:</p>

<figure><img alt="starting_agent" src="https://i.imgur.com/mXW7O3L.png"></figure>

<p>Target Destination:</p>

<figure><img alt="destination" src="https://i.imgur.com/NiSEryT.png"></figure>

<p>The cell where the agent is located at must have enough capacity to hold …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aicrowd.com/challenges/flatland-challenge">https://www.aicrowd.com/challenges/flatland-challenge</a></em></p>]]>
            </description>
            <link>https://www.aicrowd.com/challenges/flatland-challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829991</guid>
            <pubDate>Tue, 14 Jul 2020 09:24:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Decision Trap for Developers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829988">thread link</a>) | @KingOfCoders
<br/>
July 14, 2020 | https://www.svese.de/essay/the-decision-trap-for-developers-in-startups | <a href="https://web.archive.org/web/*/https://www.svese.de/essay/the-decision-trap-for-developers-in-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When I was joining a startup with plans to replace the CTO, there was a relaunch going on. I’ve talked to people and no one seemed happy. Developers were unhappy and helpless and the founders were also unhappy with the relaunch. I’ve heard it had being going on since months. The whole company couldn’t understand why tech didn’t deliver. Digging deeper I found over 150 open bugs in a small team, a founder who changed the design every week and a product manager sandwiched between the unhappy founder and the unhappy developers. I forced the founder to make a lasting decision, we fixed or closed all of the bugs and delivered a new website. The founder team, developers and I were happy, not to speak of the product manager.</p><p>Developers are trapped in a cycle of bad decision making in startups. Companies are bad at making decisions. Founders and executives treat decisions as a way to show leadership, the woman or man at the helm being able to decide about the future of the company. Creative visionaries come up with new ideas and decisions to build new products every day, changing direction on a whim in the chase for customers and investor satisfaction. Developers bear the brunt. They believe a process around decisions in startups and companies is not of their concern. They only need to execute. Tell me what I should code. </p><p>I hear from founders and CEOs who want to speed up development because they have the perception technology is slow. With the abundance of knowledge on processes, lean development and of-the-shelf technology this is unlikely. The perception of development being slow is the impact of a bad decision process in startups. For development the negative consequences are time pressure, constantly changing requirements, ongoing reprioritizations and therefor even more pressure and blame. </p><p>We will investigate why decision making is broken, what consequences this has for developers and CTOs and how to fix it.</p><p>0.</p><p><em>“Our research shows that the difference between leaders who make good decisions and those who make bad ones is striking. The former recognize that all decisions are processes, and they explicitly design and manage them as such.” </em><br>David A. Garvin and Michael A. Roberto in HBR</p><p>To many people decision making is an event, while decision making is a process. This perception causes several bad side effects. The most important one is that their decision has not the intended effects. Founders wonder why after taking a decision, the company does not change. Why after taking a decision they get a lot of discussion instead of people executing their decision towards success.</p><p>‍</p></div><div><p>How does one change this? How would a decision process look if done right? </p><p>The four steps of a decision process are:</p><ol start="" role="list"><li>Prepare</li><li>Make</li><li>Rollout</li><li>Enforce</li></ol><p>Let us look into each phase in more detail. I’ll show how mistakes in all four phases have impact on software developers and CTOs.</p><p>1.</p><p>The first phase is ‘prepare a decision’. Preparing a decision means getting the facts and information that are needed to make a decision. It also means getting feedback and the mood from stakeholders about the decision. If you surprise people with a decision, you have done it wrong. If as a founder you want to make a decision, ask your management team before what they think about it. First in a team meeting and then in one-on-one discussions with your managers. Get the buy-in from everyone that a decision needs to be made. Make sure everyone knows if the decision is to be a team decision or something a founder or managers decides.</p><p>Without the right preparation, managers make wrong assumptions, miss key parts of the decisions or do not think about consequences. Bad preparation leads to features in development that take too long, are too complicated, hard to maintain or not worth the effort. If a decision has large infrastructure impacts, feature implementation will take a long time. Cost and time pressure is put on the CTO because of badly prepared decisions.</p><p>2.</p><p>The second phase is ‘making the decision’. When you have the buy-in from everyone and all the information you need, it is time to decide. Decisions with consequences are hard to make with all the options on the table. For this managers postpone decisions to not lose options and commit themselves. If you have all the information and you have the feedback from people, make the decision and do not delay it. Break the pattern to move the decision to next week’s management meeting because of the desire to not constrain yourself. Make the decision as fast and as early as possible despite the fear of making the wrong one. A mistake I often see around making decisions: it is unclear on how decisions are made and who makes them. Introducing a decision framework like RACI helps here. It defines roles people have:</p><ul role="list"><li>R = Responsible: The person or people to successfully execute the decision</li><li>A = Accountable: The person or people who make the decision</li><li>C = Consulted: People who are asked for input to the decision</li><li>I = Informed: People informed about the decision</li></ul><p>This way roles are clear, and it is clear who makes a decision e.g. the CEO, CTO, Head of Product or the group. Otherwise people often confuse their role of giving input and with making a decision.<br>Not making a decision has bad consequences for development and CTOs. All the time lost prolonging the decision is put on development as pressure to speed up development. Donald G. Reinertsen shows in “Developing Products in Half the Time” that half of the time to market is lost in the “fuzzy frontend” before development even starts. If I consult a company, I tell people it is hard to cut 10% out of development time with already agile and lean development departments, but it is easy to cut 50% out of pre-development time. Every second after an idea is found in a company is as precious as a second in the last week before launch. People treat these differently though. Time in the decision making phase is treated as an unlimited resource and time in crunch mode before release is treated as gold. The most urgent job for a CTO is to have a decision process in place and force fast decisions to make his life happier. It helps to write down the dates of when an idea is new and when development starts to optimize lead times.</p><p>3.</p><p>While some people are at least able to make timely decisions, they fail miserably at rolling them out. Decisions are made, decisions are communicated by email or in all-hands meetings and decision makers expect the course of the company to change. They do not understand that after making a decision the most important next step is rolling it out. Every important decision involves change management. Rolling out a decision means communicating the decision, explain the decision, explain why alternatives have not been chosen, explain what the decision means for the company, departments and employees. Transparency about the decision, the reasons that the decision was made the way it went is paramount to success. Every decision needs to be explained in one-on-ones to make it stick, let people vent their feelings, get feedback and the buy-in from those carrying it out. Proclaiming you have decided something will not make the decision stick and will result in a disaster. The company ignores your decision and just carries on. Founders feel frustrated and react with pressure on execution. </p><p>When not rolling out a decision and explaining the circumstances, people have different perceptions about it, how to interpret it, what it means for them, the state of the company, what is important and what to focus on. This creates increased friction all over the company. As development needs to work with many parts of the company, it is highly impacted by high friction and differing &nbsp;assumptions and perceptions. If a company has a decision process with good rollout practices friction is minimized and development speed is increased. High friction leads to low development speed which is blamed on developers and CTOs. </p><p>4.</p><p>The last phase of decision making is enforcement. There are many people who will not be happy with your decision.</p><p><em>"Surely a decision is a decision?" "Only if it's the decision you want. If not, it's just a temporary setback." Sir Humphery, Yes Minister.</em></p><p>They will ignore it or try to reopen it. There are many ways to do so. Managers will sabotage decisions if they don’t like them and you don’t act. They agree with the decision but do not carry it out. After a decision has been made in a meeting, next week people will claim “This is not the way how I have perceived this. We haven’t made a clear decision.” People act just as if you haven’t made a decision at all. </p><p>After making a decision and rolled it out, it’s time to enforce it. Every decision has to be recorded in meeting notes or in other forms to make it clear to everyone that a decision has been made, how the decision looks and misunderstandings are reduced. Without writing it down people will leave a meeting and everyone has a different understanding and takeaway. If people show tendencies to counteract your decision, bring them back on the right path. Explain the decision again. Then explain it even more. Remind people of the decision. Pull out the meeting notes. There will be opposition from many people who had a different opinion. After you’ve made every effort to convince them and take them with you, it’s the managers and founders duty to enforce the decision. </p><p>Because the effects of a decision often cannot be seen immediately, people reopen decisions too early. If there is no new important information, don’t reopen decisions. Stick to them until you clearly see you have to change them. Change decisions as soon as needed but not earlier. Flip flopping decisions creates confusion and frustration.</p><p>Changing a decision is easy and involves not a lot of work. But the more your work is down the execution chain, the bigger the impact. A dog tail wiggles only slightly at its base but furiously at its tip.</p><p>When a decision is not enforced, it leads to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.svese.de/essay/the-decision-trap-for-developers-in-startups">https://www.svese.de/essay/the-decision-trap-for-developers-in-startups</a></em></p>]]>
            </description>
            <link>https://www.svese.de/essay/the-decision-trap-for-developers-in-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829988</guid>
            <pubDate>Tue, 14 Jul 2020 09:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Report on zero-knowledge blockchain scalability]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829951">thread link</a>) | @ArlietaBex
<br/>
July 14, 2020 | https://ethworks.io/ethereum-scaling-report | <a href="https://web.archive.org/web/*/https://ethworks.io/ethereum-scaling-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
    <header>
    
  </header>
    
    <section>
  <div>
    
    <div>
      
      <p>Our extensive report on Ethereum scaling <br> will help you:</p>
      <ul>
        <li>
          <span>demystify the buzz around Ethereum layer 2 solutions,</span>
        </li>
        <li>
          <span>understand the potential of the zero-knowledge technology,</span>
        </li>
        <li>
          <span>choose your perfect-match solution and scale your product.</span>
        </li>
      </ul>

      

      <p>
        Don't want to share your email? Download our zero-knowledge scaling report directly <a href="https://ethworks.io/assets/download/zero-knowledge-blockchain-scaling-ethworks.pdf" download="">here</a>. <br>
        By clicking "download" you agree to add your email address to our subscriber list. <br>
        You'll occasionally receive updates about new reports and other resources from Ethworks.
      </p>
    </div>
  </div>
  <p><img src="https://ethworks.io/assets/images/rectangles/r1.svg" alt="Background accent">
    <img src="https://ethworks.io/assets/images/rectangles/r2.svg" alt="Background accent">
    <img src="https://ethworks.io/assets/images/rectangles/r3.svg" alt="Background accent">
  </p>
</section>
<section>
  <div>
    <div>
      <div>
        <h2>Table of Contents</h2>
        <p>Ethereum scaling has been a topic of hot discussion for some time,
          but looks like now, things are finally about to change. The concept of generating a zero-knowledge proof for offloading the blockchain may be a real game-changer. Our extensive research on zero knowledge Ethereum scaling will help you understand why.</p>
      </div>
      <ul>
        <li>
          <h3>01. Introduction	</h3>
          <p>Oh, Boy… Scaling Again... <br>
            Report Contents	</p>
        </li>
        <li>
          <h3>02. Zero Knowledge</h3>
          <p>Real-Life Example <br>
            Zero Knowledge and Blockchain <br>
            SNARKs vs. STARKs </p>
        </li>
        <li>
          <h3>03. Architectures</h3>
          <p>Data Availability Problem <br>
            zkRollup <br>
            Validium <br>
            Volition </p>
        </li>
        <li>
          <h3>04. Technologies	</h3>
          <p>zkSync <br>
            StarkEx <br>
            Loopring	</p>
        </li>
        <li>
          <h3>05. Summary	</h3>
        </li>
        <li>
          <h3>06. About Authors</h3>
          <p>Acknowledgements</p>
        </li>
      </ul>
    </div>
  </div>
</section>




    

    

  </div><div>
  <div>
    <p>I agree to and accept that ETHworks Sp. z o.o. will collect, make automatic decisions
      about, analyze and catalog information about Internet electronic addresses which have connected with the device I
      have used, information about the type of the device I have used, including the type and version of software
      installed on the device, for the purpose of determining my Internet activities (the user profile). Automatic
      decision-making does not involve sensitive data. The agreement is in force for the period when it is legally
      binding, or until a Party withdraws from the agreement. Withdrawing from the agreement shall result in removing
      the user’s profile.</p>
    </div>
</div></div>]]>
            </description>
            <link>https://ethworks.io/ethereum-scaling-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829951</guid>
            <pubDate>Tue, 14 Jul 2020 09:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instant Cloud Functions Deployment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829702">thread link</a>) | @antho1404
<br/>
July 14, 2020 | https://liteflow.com/functions | <a href="https://web.archive.org/web/*/https://liteflow.com/functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="pay">
        <div>
          <h2>Pay only for the executions your app uses</h2>
          
        </div>
        
        <div>
          <div>
            <table data-type="freenium">
              <thead>
                <tr>
                  <th colspan="5">
                    Free Quota per month included in every account on Liteflow
                  </th>
                </tr>
                <tr>
                  <th>Function</th>
                  <th></th>
                  <th>Invocation</th>
                  <th>Duration<span>In second</span></th>
                  <th>Data<span>In kilobyte</span></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Tasks</td>
                  <td>Execute</td>
                  <td>10k</td>
                  <td>10k</td>
                  <td>10k</td>
                </tr>
              </tbody>
            </table>
            <table data-type="ondemand">
              <thead>
                <tr>
                  <th colspan="5">
                    Function's cost table (only for upgraded account)
                  </th>
                </tr>
                <tr>
                  <th>Function</th>
                  <th></th>
                  <th>Invocation<span>Per execution</span></th>
                  <th>Duration<span>Per second</span></th>
                  <th>Data<span>Per kilobyte</span></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Tasks</td>
                  <td>Execute</td>
                  <td>$0.000004</td>
                  <td>$0.0002</td>
                  <td>$0.000001</td>
                </tr>
              </tbody>
            </table>
          </div>
          
        </div>

        <p>
          <h3>Frequently Asked Questions</h3>
        </p>

        <div>
          <div>
            <h4>How do I know Liteflow is right for me?</h4>
            <p>
              Liteflow is designed for early-stage Lean startups. Every account
              includes a Free Quota for every services' executions, allowing you
              to run small-to-medium apps without having to pay anything.
            </p>
          </div>
          <div>
            <h4>Do I need a credit card to start using Liteflow?</h4>
            <p>
              No, Liteflow is completely free to start using and don't require
              your credit card upfront. You will be able to upgrade your account
              when reaching the monthly Free Quota limits.
            </p>
          </div>
        </div>
        <div>
          <div>
            <h4>What happens if I reach the monthly Free Quota limits?</h4>
            <p>
              We will warn you with a message in the console and by email,
              inviting you to enter a payment method to continue running your
              app on Liteflow. If you decide to not upgrade your account, we
              will shut off your app for the remainder of that month.
              <strong>No surprise billing!</strong>
            </p>
          </div>
          <div>
            <h4>What kind of support will I receive?</h4>
            <p>
              All apps hosted on Liteflow come with email and Intercom support
              from the Liteflow team during Southeast Asia business hours. We
              provide unlimited support to help you grow your business with
              Liteflow.
              <strong>For paid accounts, a one-to-one video call support is
                available.</strong>
            </p>
          </div>
        </div>
      </section>
    </div></div>]]>
            </description>
            <link>https://liteflow.com/functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829702</guid>
            <pubDate>Tue, 14 Jul 2020 08:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Rust NIFs for Elixir with Rustler]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23829651">thread link</a>) | @marcoow
<br/>
July 14, 2020 | https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/ | <a href="https://web.archive.org/web/*/https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>Rustler is a fantastic project built to make writing Rust NIFs a simple process;
and the upcoming v0.22 release will provide a much cleaner syntax to do so. The
library handles encoding and decoding Rust values into Erlang terms, catches
Rust panics before they unwind to C and <em>should</em> make it impossible to crash the
BEAM from a Rust NIF.</p>
<h2 id="getting-started-with-rustler">Getting started with Rustler</h2>
<p>One of my first forays into Rust-implemented NIFs was while building a
micro-library providing Base64 encoding and decoding, creatively named
<a href="https://github.com/niklaslong/base64" target="_blank" rel="noopener">base64</a>. It's utterly pointless as that
functionality comes built-in to Elixir but I wanted to start with something
simple. On the plus side, this meant I could easily compare the performance of
the NIF version to the Elixir implementation which can be found in the
<a href="https://hexdocs.pm/elixir/Base.html" target="_blank" rel="noopener"><code>Base</code> module</a>.</p>
<p>The library consists of two functions: <code>encode/2</code> and <code>decode/2</code> and it's using
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64</a> to do the heavy
lifting in the NIFs. Let's walk through how this all works.</p>
<p>To get started, we need a new mix project with rustler installed as a
dependency.</p>
<pre><code>mix new base64

mix deps.get
mix rustler.new
</code></pre><p>Let's explore the project's resulting structure (I've left out the usual Elixir
files and directories and focused on <code>lib</code> and <code>native</code>):</p>
<pre><code>.
â”œâ”€â”€ lib
â”‚   â””â”€â”€ base64.ex
â””â”€â”€ native
    â””â”€â”€ base64_nif
        â”œâ”€â”€ Cargo.lock
        â”œâ”€â”€ Cargo.toml
        â”œâ”€â”€ README.md
        â””â”€â”€ src
            â””â”€â”€ lib.rs</code></pre><ul>
<li><code>lib</code> will contain Elixir code (like any standard mix project).</li>
<li><code>base64.ex</code> will contain the stubs to our NIFs. This is the Elixir module the
NIF module will be registered to.</li>
<li><code>native</code> will be home to the Rust code. In fact, a cargo package has been
created within this directory (in this case named <code>base64_nif</code>).</li>
<li><code>lib.rs</code> will contain the NIFs.</li>
</ul>
<p>The Rust NIFs are compiled and linked into a shared library loaded by Erlang
code at runtime. Elixir (or Erlang) implementations of the functions are also
necessary. These are usually minimal stubs defining the name and arity of the
NIFs and serve as fallback implementations if the NIFs aren't loaded. Let's
start with the Elixir stubs.</p>
<pre><code>

<span><span>defmodule</span> <span>Base64</span></span> <span>do</span>
  <span>use</span> Rustler, <span>otp_app:</span> <span>:base64</span>, <span>crate:</span> <span>"base64_nif"</span>

  <span>@spec</span> decode(binary, atom) :: binary
  <span><span>def</span> <span>decode</span></span>(_b64, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span>@spec</span> encode(binary, atom) :: binary
  <span><span>def</span> <span>encode</span></span>(_s, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span><span>defp</span> <span>error</span></span>(), <span>do:</span> <span>:erlang</span>.nif_error(<span>:nif_not_loaded</span>)
<span>end</span></code></pre><p>The first line is configuration and lets Rustler know what Rust crate to compile
for the Elixir module.</p>
<p>As mentioned above, <code>decode/2</code> and <code>encode/2</code> don't actually implement any
decoding or encoding; they simply call <code>error/0</code> if the NIFs can't be found.
However, the names and the arguments must match in both the Rust and Elixir
implementations. Both functions take in a <code>binary</code> to be encoded or decoded and
an <code>atom</code> for configuration as different character sets that can be used
(url-safe, without padding, etc...). The default is fittingly set to
<code>:standard</code>. The Rust NIFs are implemented as follows.</p>
<pre><code>

<span>use</span> base64;
<span>use</span> rustler::Atom;

<span>mod</span> atoms {
    rustler::atoms! {
      crypt,
      imap_map7,
      standard,
      standard_no_pad,
      url_safe,
      url_safe_no_pad,
    }
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>decode</span></span>(b64: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    <span>let</span> bytes = base64::decode_config(b64, config).expect(<span>"decode failed: invalid b64"</span>);

    <span>String</span>::from_utf8(bytes).unwrap()
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>encode</span></span>(s: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    base64::encode_config(s.as_bytes(), config)
}

<span><span>fn</span> <span>match_config</span></span>(option: Atom) -&gt; base64::Config {
    
}

rustler::init!(<span>"Elixir.Base64"</span>, [decode, encode]);</code></pre><p>The last line is interesting: <code>rustler::init</code> is a procedural macro that allows
the use of <code>#[rustler::nif]</code> to annotate functions to be wrapped as NIFs. It
takes in the name of the Elixir module in which the stubs are defined (in this
case <code>"Elixir.Base64"</code>) and an array containing the names of the functions
annotated as NIFs (in this case <code>[decode, encode]</code>). In short, this links
everything together.</p>
<p>The use statements at the top of the file are importing the
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64 crate</a> (<code>base64</code>)
mentioned earlier, which we'll use for encoding and decoding, and the
<code>rustler::Atom</code> type which allows us to represent an Elixir/Erlang <code>atom</code> in
Rust. Both the <code>rustler</code> and <code>base64</code> crates have been added to the <code>Cargo.toml</code>
dependencies.</p>
<p>The <code>rustler::atoms</code> macro defines Rust functions that return Erlang atoms; in
this case, the possible options for the <code>encode/2</code> and <code>decode/2</code> functions.</p>
<p>Finally, we come to the NIF definitions. The functions take in a <code>String</code> and a
<code>rustler::Atom</code>, and return a <code>String</code>. This is consistent with the Elixir
stubs, as are the names. In this case, the conversions between Rust values and
Elixir terms are conveniently handled by Rustler. However, for more complex
types, this may need to be implemented manually.</p>
<h2 id="how-does-it-compare-to-the-elixir-implementation">How does it compare to the Elixir implementation?</h2>
<p>Rust is fast. Really fast. This was my set-up (using
<a href="https://github.com/bencheeorg/benchee" target="_blank" rel="noopener">benchee</a>):</p>
<pre><code>Operating System: macOS
CPU Information: Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
Number of Available Cores: 4
Available memory: 16 GB
Elixir 1.10.2
Erlang 22.3.2</code></pre><p>I used <em>hello world</em> as the short string and Sarah Kayâ€™s poem
<em><a href="https://www.youtube.com/watch?v=0snNB1yS3IE" target="_blank" rel="noopener">B (If I Should Have a Daughter)</a></em>
as the longer string.</p>
<p>Decoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif decode           175.74 K
Elixir/Erlang decode        4.35 K - 40.37x slower +224.03 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif decode           953.17 K
Elixir/Erlang decode      555.63 K - 1.72x slower +0.75 Î¼s</code></pre><p>Encoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif encode           203.14 K
Elixir/Erlang encode        6.95 K - 29.23x slower +138.98 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif encode           941.14 K
Elixir/Erlang encode      615.62 K - 1.53x slower +0.56 Î¼s</code></pre><p>As the data to encode or decode becomes larger, the overhead of creating the
NIFs becomes smaller and the gains in speed are impressive. These results were
obtained with fairly small data and so the potential performance gains possible
by leveraging Rust NIFs when dealing with CPU-intensive tasks are exciting.</p>
<p>I left out the memory usage comparisons but the Elixir/Erlang implementations
used 3-5x more memory than the NIFs.</p>
<h2 id="tldr-rustler-makes-it-easy-to-implement-nifs">TL;DR: Rustler makes it easy to implement NIFs</h2>
<p>Other than the <code>#[rustler::nif]</code> function annotations and the <code>rustler::init</code>
call, nothing more is required to implement Rust NIFs with Rustler. The
boilerplate and the complexities of translating Rust values to Erlang terms
being handled by the library, there's little resistance to leveraging the power
of Rust in Elixir/Erlang.</p>

  </div></div>]]>
            </description>
            <link>https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829651</guid>
            <pubDate>Tue, 14 Jul 2020 08:16:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Instant Customizable RDBMS Vue UI in 20kb Gist Desktop App]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829512">thread link</a>) | @mythz
<br/>
July 14, 2020 | https://sharpscript.net/sharp-apps/sharpdata | <a href="https://web.archive.org/web/*/https://sharpscript.net/sharp-apps/sharpdata">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://github.com/NetCoreApps/SharpData">SharpData</a> is a generic app for providing an instant UI around multiple RDBMS's:</p>
<blockquote>
<p>YouTube: <a href="https://youtu.be/GjVipOqwZMA" rel="nofollow">youtu.be/GjVipOqwZMA</a></p>
</blockquote>
<p><a href="https://youtu.be/GjVipOqwZMA" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-custom-appsettings.png" alt=""></a></p>
<p>It makes use of the <a href="https://docs.servicestack.net/netcore-windows-desktop" rel="nofollow">app</a> dotnet tool for running Chromium
<a href="https://sharpscript.net/sharp-apps/gist-desktop-apps" rel="nofollow">Gist Desktop Apps</a> on-the-fly without installation, from a single URL that can also
<a href="https://docs.servicestack.net/mix-tool" rel="nofollow">mix in additional gists</a> which can be used in SharpData to configure RDBMS's, copy SQLite databases and
apply per-database customizations to add navigable deep links and customized UI Views to each table resultset.</p>
<p>Whilst SharpData supports <a href="https://github.com/ServiceStack/ServiceStack.OrmLite#8-flavours-of-ormlite-is-on-nuget">connecting to most popular RDBMS's</a>, it's
especially useful for being able to deploy an instant stand-alone UI with an embedded SQLite databases which can be published independently in a gist and
launched from a single URL.</p>
<p>For an example of this in action we've published customized gists for the
<a href="https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/linq/downloading-sample-databases" rel="nofollow">Northwind</a> and
<a href="https://www.sqlitetutorial.net/sqlite-sample-database/" rel="nofollow">Chinook</a> SQLite databases which after installing the latest
<a href="https://docs.servicestack.net/netcore-windows-desktop" rel="nofollow">app</a> dotnet tool:</p>
<pre><code>$ dotnet tool install -g app
$ app -version
</code></pre>
<p>First time <code>app</code> is run it registers the <a href="#app-url-schemes">app:// URL scheme</a> allowing Windows x64 Desktop Apps to be launched from URLs:</p>
<ul>
    <li><strong><a name="app://sharpdata?mix=northwind.sharpdata">app://sharpdata?mix=northwind.sharpdata</a></strong></li>
    <li><strong><a name="app://sharpdata?mix=chinook.sharpdata">app://sharpdata?mix=chinook.sharpdata</a></strong></li>
</ul>
<p>Or via command-line:</p>
<pre><code>$ app open sharpdata mix northwind.sharpdata
$ app open sharpdata mix chinook.sharpdata
</code></pre>
<p>Cross platform using the <a href="https://docs.servicestack.net/dotnet-tool" rel="nofollow">x dotnet tool</a> (in Default Browser):</p>
<pre><code>$ x open sharpdata mix northwind.sharpdata
$ x open sharpdata mix chinook.sharpdata
</code></pre>
<p>Each of these options will download &amp; run the latest version of <a href="https://github.com/NetCoreApps/SharpData">SharpData</a> along with a
copy of the <a href="https://gist.github.com/gistlyn/0ce0d5b828303f1cb4637450b563adbd">northwind.sharpdata</a> or
<a href="https://gist.github.com/gistlyn/96b10369daf94897531810841cb097f2">chinook.sharpdata</a> gists on-the-fly containing the embedded SQLite DB along with any
UI customizations.</p>
<h4>
Hosted as a .NET Core App</h4>
<p>As <a href="https://github.com/NetCoreApps/SharpData">NetCoreApps/SharpData</a> is also a standard .NET Core project, it can also be deployed as a
normal stand-alone .NET Core Web App:</p>
<h3>
<a href="https://sharpdata.netcore.io/" rel="nofollow">https://sharpdata.netcore.io</a>
</h3>
<h3>
Tiny footprint</h3>
<p>An impressively capable .NET Core App that fits into a tiny <strong>20kb .zip</strong> footprint thanks to <a href="https://sharpscript.net/gist-desktop-apps">Gist Desktop App's Architecture</a>. It's small dynamic <code>#Script</code> &amp; Vue TypeScript code-base also makes it highly customizable to tailor &amp; further extend with
App-specific requirements - suitable for offering advanced system users a quick, capable customized read-only UI of your DBs.</p>
<p><strong>SharpData</strong> started as a demonstration showing how productive <a href="https://sharpscript.net/" rel="nofollow">#Script</a> can be in the number of areas where
dynamic languages offer far superior productivity then the typical .NET approach of using C# to type an entire code-base &amp; models.</p>
<p>For example a single <code>#Script</code> page provides a lot of the functionality in <a href="https://docs.servicestack.net/autoquery-rdbms" rel="nofollow">AutoQuery</a> where it provides an instant HTTP API
(in all registered ServiceStack formats) around all registered RDBMS tables, in all OrmLite supported RBDMS's, that includes support for custom fields,
multiple querying options, paging, multi OrderBy's in a parameterized SQL query executed with OrmLite's SQL async DB APIs:</p>
<h2>
AutoQuery Script</h2>
<h3>
<a href="https://github.com/NetCoreApps/SharpData/blob/master/wwwroot/db/_db/_table/index.html">/db/_db/_table/index.html</a>
</h3>
<pre><code>{{ {namedConnection:db} |&gt; if (db &amp;&amp; db != 'main') |&gt; useDb }}

```code|quiet
var ignore = ['db','fields','format','skip','take','orderBy']
var fields = qs.fields ? qs.fields.split(',').map(x =&gt; sqlQuote(x)).join(',') : '*'
var sql = `SELECT ${fields} FROM ${sqlQuote(table)}`
var filters = []
var queryMap = qs.toObjectDictionary().withoutKeys(ignore)
#each queryMap.Keys.toList()
    var search = queryMap[it.sqlVerifyFragment()].sqlVerifyFragment();
    #if search == '=null' || search == '!=null'
        `${sqlQuote(it)} ${search=='=null' ? 'IS' : 'IS NOT'} NULL` |&gt; addTo =&gt; filters
        queryMap[it] = null
    else if search.startsWith('=')
        `${sqlQuote(it)} = @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(1).coerce()
    else if search.startsWith('&lt;=') || search.startsWith('&gt;=') || search.startsWith('!=')
        `${sqlQuote(it)} ${search.substring(0,2)} @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(2).coerce()
    else if search.startsWith('&lt;') || search.startsWith('&gt;')
        `${sqlQuote(it)} ${search.substring(0,1)} @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(1).coerce()
    else if search.endsWith(',')
        `${sqlQuote(it)} IN (${search.trimEnd(',').split(',').map(i=&gt;i.toLong()).join(',')})` |&gt;addTo=&gt;filters
        queryMap[it] = null
    else if search.startsWith('%') || search.endsWith('%')
        `${sqlQuote(it).sqlCast('varchar')} LIKE @${it}` |&gt; addTo =&gt; filters
    else
        `${sqlQuote(it).sqlCast('varchar')} = @${it}` |&gt; addTo =&gt; filters
    /if
/each
#if !filters.isEmpty()
    sql = `${sql} WHERE ${filters.join(' AND ')}`
/if
#if qs.orderBy
    sql = `${sql} ORDER BY ${sqlOrderByFields(qs.orderBy)}`
/if
#if qs.skip || qs.take
    sql = `${sql} ${sqlLimit(qs.skip,qs.take)}`
/if
sql |&gt; dbSelect(queryMap) |&gt; return
```
{{ ifError |&gt; show(sql) }}
{{htmlError}}
</code></pre>
<p>The <code>_</code> prefixes in the path utilizes <a href="https://sharpscript.net/docs/sharp-pages#page-based-routing" rel="nofollow">Page Based Routing</a> allowing for
<a href="https://en.wikipedia.org/wiki/Convention_over_configuration" rel="nofollow">CoC</a> based
<a href="https://en.wikipedia.org/wiki/Clean_URL" rel="nofollow">Clean URL</a> routes without needing to define &amp; maintain separate routes where the
same script supports querying all <a href="https://docs.servicestack.net/multitenancy#changedb-apphost-registration" rel="nofollow">registered multitenancy databases</a>.</p>
<h3>
Instant Customizable RDBMS UI</h3>
<p>The <a href="https://github.com/NetCoreApps/SharpData">SharpData</a> project essentially provides a UI around this script, surfacing its features &amp; give
it instant utility which ended up being so useful that it's become the quickest way to perform fast adhoc DB queries as it's easy to configure
which RDBMS's &amp; tables to show in a simple text file, easy to customize its UI, enables 1-click export into Excel and its shortcut syntax
support in column filters is a fast way to perform quick adhoc queries.</p>
<h3>
Quick Tour</h3>
<p>We'll quickly go through some of its features to give you an idea of its capabilities, from the above screenshot we can some of its
filtering capabilities. All results displayed in the UI are queried using the above
<a href="https://github.com/NetCoreApps/SharpData/blob/master/wwwroot/db/_db/_table/index.html">sharpdata</a> <code>#Script</code> HTTP API
which supports the following features:</p>
<h3>
Filters</h3>
<p>All query string parameter except for <code>db,fields,format,skip,take,orderBy</code> are treated as filters, where you can:</p>
<ul>
<li>Use <code>=null</code> or <code>!=null</code> to search <code>NULL</code> columns</li>
<li>Use <code>&lt;=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;&gt;</code>, <code>!=</code> prefix to search with that operator</li>
<li>Use <code>,</code> trailing comma to perform an <code>IN (values)</code> search (integer columns only)</li>
<li>Use <code>%</code> suffix or prefix to perform a <code>LIKE</code> search</li>
<li>Use <code>=</code> prefix to perform a coerced "JS" search, for exact <code>number</code>, <code>boolean</code>, <code>null</code> and WCF date comparisons</li>
<li>Otherwise by default performs a "string equality" search where columns are casted and compared as strings</li>
</ul>
<p>Here's the filtered list used in the above screenshot:</p>
<p><a href="http://sharpdata.netcore.io/db/northwind/Order?format=json&amp;Id=%3E10200&amp;CustomerId=V%25&amp;Freight=%3C%3D30&amp;OrderDate=%3E1997-01-01&amp;take=100" rel="nofollow">/db/northwind/Order?Id=&gt;10200&amp;CustomerId=V%&amp;Freight=&lt;=30&amp;OrderDate=&gt;1997-01-01</a></p>
<h3>
Custom Field Selection</h3>
<p>The <strong>column selection</strong> icon on the top left of the results lets you query custom select columns which is specified using <code>?fields</code>:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json&amp;fields=Id%2CCompanyName%2CContactName%2CContactTitle&amp;take=100" rel="nofollow">/db/northwind/Customer?fields=Id,CompanyName,ContactName,ContactTitle</a></li>
</ul>
<h3>
Multiple OrderBy's</h3>
<p>You can use <a href="https://docs.servicestack.net/autoquery-rdbms#multiple-orderbys" rel="nofollow">AutoQuery Syntax</a> to specify multiple Order By's:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json&amp;orderBy=-Id,CompanyName,-ContactName" rel="nofollow">/db/northwind/Customer?orderBy=-Id,CompanyName,-ContactName</a></li>
</ul>
<h3>
Paging</h3>
<p>Use <code>?skip</code> and <code>?take</code> to page through a result set</p>
<h3>
Format</h3>
<p>Use <code>?format</code> to specify which <strong>Content-Type</strong> to return the results in, e.g:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=html" rel="nofollow">/db/northwind/Customer?format=html</a></li>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json" rel="nofollow">/db/northwind/Customer?format=json</a></li>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=csv" rel="nofollow">/db/northwind/Customer?format=csv</a></li>
</ul>
<h3>
Multitenancy</h3>
<p>You can specify which registered DB to search using the path info, use <code>main</code> to query the default database:</p>
<pre><code>/db/&lt;named-db&gt;/&lt;table&gt;
</code></pre>
<h3>
Open in Excel</h3>
<p>SharpData detects if <strong>Excel</strong> is installed and lets you open the un-paged filtered resultset directly by clicking the <strong>Excel</strong> button</p>
<p><a href="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-excel.png" target="_blank" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-excel.png" alt=""></a></p>
<p>This works seamlessly as it's able to "by-pass" the browser download where the query is performed by the back-end .NET Core Server who streams the response directly to the Users <strong>Downloads</strong> folder and launches it in Excel as soon as it's finished.</p>
<h3>
Launching SharpData</h3>
<p>To run SharpData in a .NET Core Desktop App you'll need latest <code>app</code> dotnet tool:</p>
<pre><code>$ dotnet tool update -g app
</code></pre>
<blockquote>
<p>If on macOS/Linux you can use the <a href="https://docs.servicestack.net/dotnet-tool" rel="nofollow">x dotnet tool</a> instead to view SharpData in your default browser</p>
</blockquote>
<h3>
Configure RDBMS from command-line</h3>
<p>You can override which database to connect to by specifying it on the command line, e.g. here's an example of connecting to <a href="https://techstacks.io/" rel="nofollow">https://techstacks.io</a> RDBMS:</p>
<pre><code>$ app open sharpdata -db postgres -db.connection $TECHSTACKS_DB
</code></pre>
<p>Which will open SharpData listing all of TechStack's RDBMS tables. If you have a lot of tables the <strong>Sidebar filter</strong> provides a quick way to
find the table you want, e.g:</p>
<p><a href="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-technology.png" target="_blank" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-technology.png" alt=""></a></p>
<h3>
app URL Schemes</h3>
<p>What can be done with the <code>open</code> command on the command-line can also be done from a <strong>custom URL Scheme</strong>, a feature that opens up a myriad of new
possibilities as <code>app</code> can open <a href="https://sharpscript.net/docs/gist-desktop-apps" rel="nofollow">Gist Desktop Apps</a> from Gists or in public &amp; private GitHub repositories,
where it's able to download and launch Apps on the fly with custom arguments - allowing a single URL to run a <strong>never installed</strong> Desktop App stored in a
Gist &amp; pass it custom params to enable <strong>deep linking</strong>.</p>
<p>With this organizations could maintain a dashboard of links to its different Desktop Apps that anyone can access, especially useful as the
<strong>only software</strong> that's needed to run any <a href="https://sharpscript.net/docs/sharp-apps" rel="nofollow">Sharp Apps</a> is the <code>app</code> dotnet tool which thanks to all
ServiceStack .dll's &amp; dependencies being bundled with the tool, (including Vue/React/Bootstrap fontawesome and Material SVG Icon assets),
the only files that need to be published are the App's specific resources, which is how Apps like <strong>SharpData</strong> can be compressed in a
<strong>20kb .zip</strong> - a tiny payload that's viable to download the latest app each on each run, removing the pain &amp; friction to distribute updates as
everyone's already running the latest version every time it's run.</p>
<p>Should you need to (e.g. large Sharp App or github.com is down) you can run your previously locally cached App using <code>run</code>:</p>
<pre><code>$ app run sharpdata
</code></pre>
<p>With Custom URL Schemes everyone with <code>app</code> installed can view any database they have network access to from specifying the db type and connection string in the URL:</p>
<pre><code>app://sharpdata?db=postgres&amp;db.connection={CONNECTION_STRING}
</code></pre>
<blockquote>
<p>CONNECTION_STRING needs to be URL Encoded, e.g. with JS's <code>encodeURIComponent()</code></p>
</blockquote>
<p>or by specifying an Environment variable containing the connection string:</p>
<pre><code>app://sharpdata?db=postgres&amp;db.connection=$TECHSTACKS_DB
</code></pre>
<h3>
Mix in Gists</h3>
<p>In…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sharpscript.net/sharp-apps/sharpdata">https://sharpscript.net/sharp-apps/sharpdata</a></em></p>]]>
            </description>
            <link>https://sharpscript.net/sharp-apps/sharpdata</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829512</guid>
            <pubDate>Tue, 14 Jul 2020 07:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun won't get it done]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23829157">thread link</a>) | @luu
<br/>
July 13, 2020 | http://yosefk.com/blog/fun-wont-get-it-done.html | <a href="https://web.archive.org/web/*/http://yosefk.com/blog/fun-wont-get-it-done.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>OK, published at 3:30 AM. That's a first!</p>
<p>So.&nbsp;Got something you want to do over the coarse of a year? Here's a&nbsp;motivation woefully insufficient to pull it off:</p>
<ul>
<li>It's fun!</li>
</ul>
<p>What could&nbsp;give you enough drive to finish the job? Anything with a reward <em>in the future, once you're done</em>:</p>
<ul>
<li>Millions of fans&nbsp;<strong>will</strong> adore me.</li>
<li>It <strong>will</strong> be the ugliest thing on the planet.</li>
<li>I <strong>will</strong> finally understand quantum neural rockets.</li>
<li>We <strong>will</strong> see who the loser is, Todd!</li>
<li>I <strong>will</strong> help humanity.</li>
<li>I <strong>will</strong>&nbsp;destroy humanity.</li>
</ul>
<p>It doesn't matter how noble or ignoble your&nbsp;goal is. What matters is <strong>delaying gratification</strong>. Because even your&nbsp;favorite thing in the&nbsp;world will have&nbsp;shitty bits if you chew on&nbsp;a big enough chunk of it. A few months or years worth of work are <em>always</em> a big enough chunk, so there <em>will</em> be shitty bits. Unfortunately, it's also the minimum-sized chunk to do anything of significance.</p>
<p>This is&nbsp;where many brilliant talents drown. Having known the joy of true inspiration, it's hard to settle for less, which you <em>must</em> to have any impact. Meanwhile,&nbsp;their&nbsp;thicker peers happily butcher task after task. Before you know it,&nbsp;these tasks&nbsp;add up to an&nbsp;impactful result.</p>
<p>In hindsight, I was really&nbsp;lucky in that I chose a profession for money instead of love.&nbsp;Why? <strong>Stamina</strong>. Money is a reward in the future that lets you ignore the shittier bits of the present.</p>
<p>Loving every moment of it, on the other hand, carries you until that moment&nbsp;which you <em>hate</em>, and then you need a new sort of fuel. Believe me, I know. I love drawing and animation, and you won't believe how many times I started and stopped doing it.</p>
<p>But the animation teacher who taught me 3D said he was happy to put textures on toilet seat models when he started out. <em>That's</em> the kind of appetite you need – and very few people&nbsp;naturally feel that sort of attraction to toilet seats. You need a&nbsp;big reward in the future, like "I'm going to become a pro," to pull it off.</p>
<p>But I don't want to become a pro. I don't want to work in the Israeli animation market where there's scarcely a feature film&nbsp;made. I don't even want to work for a big overseas animation studio. I want to make something, erm, something beautiful that I love, <strong>which is a piece of shit of a goal</strong>.</p>
<p>Because you know where I made most progress picking up actual skills? In an evening animation school, where I had a&nbsp;perfectly good goal: survive. It's good because it's a simple, binary thing which doesn't give a rat's ass about your mood. You either drop out or you don't. But "something I love" is fluid, and depends a lot on the mood. And&nbsp;when you hate this thing you're making, as you sometimes will, it's hard to imagine loving it later.</p>
<p>Conversely, imagining how I don't drop&nbsp;out is easy. This is what I was imagining when sculpting this bust, which 90% of the time I hated with a passion because it looked like crap. But I thought, "I'm not quitting, I'm not quitting, I'm not quitting, hey, I&nbsp;get the point of re-topology in Mudbox, I'm not quitting, I'm not quitting, hey, I guess I see what&nbsp;the specular map does, I'm not quitting… Guess I'm done!"</p>
<p><iframe src="https://player.vimeo.com/video/171365263" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>And now let's talk about beauty for a moment.</p>
<p>I'm a programmer. I like to think that I'm not the thickest, butcherest programmer, in that I understand the role of beauty in it. For the trained eye, programs can be beautiful as much as&nbsp;math, physics or chess, and a beautiful program is better <em>for business</em> than the&nbsp;needlessly uglier program. (Ever tried pitching the value of beauty to someone businessy? Loads of fun.)</p>
<p>But you know why beauty is your enemy? Because it sucks the fun out of things. How? Because you're making this thing and chances are, <strong>it's not beautiful according to your own standard</strong>. The trap is, your&nbsp;taste for beauty is usually ahead of your&nbsp;creative ability. In any area, and then in any sub-area of that area, ad infinitum, you can tell ugly from beautiful long before you can make something beautiful yourself. And&nbsp;even if&nbsp;you can satisfy your own taste,&nbsp;often&nbsp;the final thing is beautiful, but not the states it goes through.</p>
<p>So&nbsp;the passionate, sensitive soul is hit twice:</p>
<ol>
<li>You're driven by fun and inspiration because you've once experienced it and now you covet it.</li>
<li>Your sense of beauty, frustrated by the state of your creation, kills&nbsp;all the fun – that very fun which&nbsp;you insist must be your only fuel.</li>
</ol>
<p>Life is easier if you want a yacht. I think you can buy a&nbsp;decent&nbsp;one for $300K, and certainly for $1M. Now all you need to do is make that money, doing doesn't matter what – imagining that yacht will help you do <em>anything</em> well! If you want beauty, however, I do not envy you.</p>
<p>How do I cope with my desire for beauty?&nbsp;The first step is acknowledging&nbsp;the problem, which I do. The fact is that my worst failures in programming came when I insisted on beauty the most. The second step is shunning beauty as a <em>goal</em>, and making it&nbsp;into a <em>means</em> and a <em>side-effect</em>.</p>
<p>I need a program doing at least X, taking at most Y seconds, at a date not later than Z.&nbsp;I'll keep ugliness to a minimum because ugly programs work badly. And if it comes out particularly nicely, that's great. But beauty is&nbsp;not a goal, and&nbsp;enjoying the beauty of this program as I write it is not why I write it.</p>
<p>And if you think it's true for commercial work but not open source software, look at, I dunno, Linux. Read some <a href="http://www.h-online.com/open/features/Interview-Linus-Torvalds-I-don-t-read-code-any-more-1748462.html">Torvalds</a>:</p>
<blockquote><p>Realistically, every single release, most of it is just driver work. Which is <strong>kind of boring in the sense there is nothing fundamentally interesting in a driver</strong>, it's just support for yet another chipset or something, and at the same time that's kind of the bread and butter of the kernel. More than half of the kernel is just drivers, and so <strong>all the big exciting smart things we do, in the end it pales</strong> when compared to all the work we just do to support new hardware.</p></blockquote>
<p>Boring bits. Boring bits that&nbsp;must be done to make something of value.</p>
<p>Does this&nbsp;transfer to art or poetry or any of those things&nbsp;whose whole point is beauty? Well, yeah, I think it does, because no,&nbsp;beauty is not the whole point:</p>
<ul>
<li>The most important thing about a drawing is that it's done. Now it exists, and people can see it, and you can make <em>another one</em>. Practice. They will not come out very well if they don't come out.</li>
<li>Often people like your&nbsp;subject.&nbsp;There's a continuum between "it's beautiful in a way that words cannot convey" and "I love how this song&nbsp;expresses&nbsp;my favorite political philosophy." To the extent that a work of art tells a story, or even sets up&nbsp;a mood, its beauty <em>does</em> become a means to an end.</li>
<li>Just because the end result is beautiful to the observer, and even if that's the only point, doesn't mean every step making it was an orgy of beauty for whomever made it. Part of what goes into it is boring, technical work.</li>
</ul>
<p>So here, too I'm trying to make beauty a non-goal. Instead my goals are "make a point" and "keep going," and you try to add beauty, or remove ugliness, as you go.</p>
<p>For example,&nbsp;I didn't do a graduation project in the evening school, but I&nbsp;animated a short on my own in the same timeframe, and I published it, even though it's not the beautiful thing I always dreamed about making. And&nbsp;I'm not sure anyone gets the joke except me. (I'm not sure I get it anymore, either.)</p>
<p><iframe src="https://player.vimeo.com/video/171368757" width="480" height="270" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Now my goal is "make another one." It's a good goal, because it's easy to imagine making another one. It's proper&nbsp;delayed gratification.</p>
<p>And if you've enjoyed programming 20 years ago&nbsp;and are trying to reignite the passion, I suggest that you find a goal as worthy for you as "fun" or "beauty", but as clear and binary as a yacht.&nbsp;And you can settle for less worthy, but not for less clear and binary. Because everything they told you about "extrinsic motivation" being inferior to "intrinsic motivation" is one big lie. And this lie will&nbsp;fall apart the moment you sink your teeth into a bunch of shit, as will always happen if you're trying to accomplish anything.</p>
<p><a href="https://twitter.com/YossiKreinin">Follow me on Twitter</a> to receive pearls of wisdom such as the following sample:</p>
<blockquote data-lang="en"><p lang="en" dir="ltr">Authority is the idea that what matters is not which answer is pulled out of the ass, but whose ass it's pulled out of.</p>
<p>— Yossi Kreinin (@YossiKreinin) <a href="https://twitter.com/YossiKreinin/status/756221299358216192">July 21, 2016</a></p></blockquote>


							</div></div>]]>
            </description>
            <link>http://yosefk.com/blog/fun-wont-get-it-done.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829157</guid>
            <pubDate>Tue, 14 Jul 2020 06:32:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cost of Mistake in Hardware Projects]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23828667">thread link</a>) | @Gen1us
<br/>
July 13, 2020 | https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&sk=eb21eb69d892cb19c0f85f3e0276481e | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&sk=eb21eb69d892cb19c0f85f3e0276481e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="9209">Have you reached your free story limit this month? Read free on the <a target="_blank" rel="noopener" href="https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e"><strong>link</strong></a>.</h2><div><div><div><div><p><a href="https://blog.maddevs.io/@anton_oxide?source=post_page-----7d73b0fd8465----------------------" rel="noopener"><img alt="Anton Kozlov" src="https://miro.medium.com/fit/c/96/96/2*cVORyQUYPKciCqxow6QtZg.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Hardware design." src="https://miro.medium.com/max/12000/1*CvgVOgiQFDODqdijfCfk4g.jpeg" width="6000" height="3258" srcset="https://miro.medium.com/max/552/1*CvgVOgiQFDODqdijfCfk4g.jpeg 276w, https://miro.medium.com/max/1104/1*CvgVOgiQFDODqdijfCfk4g.jpeg 552w, https://miro.medium.com/max/1280/1*CvgVOgiQFDODqdijfCfk4g.jpeg 640w, https://miro.medium.com/max/1400/1*CvgVOgiQFDODqdijfCfk4g.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*CvgVOgiQFDODqdijfCfk4g.jpeg?q=20"></p></div></div></div></figure><p id="cf40">Hello everyone!</p><p id="4a9f">In this article, we will consider common errors in the design of electronic devices and how to solve them. We will see how to calculate the cost of rolling back a batch of devices, get familiar with the main prototyping cycle.</p><h2 id="57be"><strong>Introduction</strong></h2><p id="c309">You have probably heard that various manufacturers recall batches of electronic devices from time to time. Smartphones hanging up, cameras turning off suddenly, electronic cigarettes exploding — these are the results of an incorrect approach to prototyping devices and savings on-device testing.</p><p id="a8d9">For users, such cases look like routine and can only undermine their trust in the device manufacturer. For a company that has released insufficiently tested devices in a series, defects can lead to recalling of the entire party of devices, paying compensations, and even bankruptcy.</p><h2 id="11b5"><strong>Real-world cases</strong></h2><p id="7451">Nowadays almost all portable or stationary devices have intelligent control. They use the computing capabilities of microcontrollers, microprocessors and processors for their work. This means that to change complex electronic logic, one will need to make changes in the software. This approach simplifies debugging, development, and error fixes, also reducing the cost of devices. Besides, manufacturers try to protect themselves by preferring software solution to hardware solutions for flexibility of the manufacturing process. As technologies develop, technical requirements for devices become more and more complex. Due to their complexity, modern devices should be properly designed and tested.</p><p id="d415">Software errors are resolved by updating the device software, normally it doesn’t cause serious damage. Below you can find some examples of errors made by well-known companies:</p><ul><li id="7f65">2019 — a login error on a Samsung smart watch:</li></ul><ul><li id="3640">2018 — an error causing the Apple iPhone restart when receiving messages with certain characters:</li></ul><ul><li id="28af">2016 — a vulnerability in Android enabling attackers to access a number o smartphone models:</li></ul><ul><li id="0f88">2016 — an issue with the shutter being stuck in Nikon D750 cameras:</li></ul><p id="8398">Errors in the software are common for any device manufacturer. They only indicate that the device circuit was properly designed so the device didn’t stop working, and the error resulted in zero hardware damage.</p><p id="c892">The errors in circuitry, layout of electronic components or mechanical parts, insufficient protection of the device from external influence lead to more serious consequences. Unlike software issues, they cannot be resolved remotely and result in higher costs as the manufacturer needs to pay for repair or even release another series of devices. Moreover, hardware errors often mean that the device won’t work properly.</p><p id="e4e4">However, errors in the firmware of the devices (especially those performing simple tasks without the possibility of remote firmware upgrade) should not be treated irresponsibly either. Even if such errors do not make their manufacturer rework the circuitry, they can still lead to reflashing. When designing devices on simple microcontrollers with peripherals used for outer word communication, it is possible to add the function of remote firmware updates and protect yourself from device recalls. We will cover remote firmware upgrades in more detail in one of our upcoming publications.</p><p id="c686">Here are some examples of hardware issues:</p><ul><li id="c041">2017 — Spectre, Meltdown — major hardware vulnerabilities at the core level of most Intel, AMD, ARM processors were detected. The command execution optimization mechanism could be used to access the arbitrary memory allocated for specific applications:</li></ul><ul><li id="d937">2016 — The discovery of a known problem with Samsung Galaxy Note 7 batteries causing smartphones to burn. Due to possible fires, some countries banned this model from air transportation:</li></ul><ul><li id="c99a">2013 — nowadays — numerous incidents involving the ignition of electronic cigarette batteries resulting in severe burns and injuries to users (warning! explicit content):</li></ul><p id="82e7">These examples show that hardware errors in devices can be fatal to the device itself or to the manufacturer. This is why hardware development and testing must be more delicate.</p><h2 id="fd51"><strong>A simple example of a disruptive design error in a device</strong></h2><p id="9500">The consequences of hardware errors are clear, but why they occur? What is the reason behind them?</p><p id="f9af">Errors in the circuitry and mechanics of the device often occur due to the lack of load, crash tests, tests in an aggressive environment. The approach to developing hardware may be incorrect, too.</p><p id="81e3">Let’s say we designed a simple device — a component of the meteorological data collection system.</p><p id="bd28">The device is installed on a hill (a lamppost, a tree trunk, a roof of some building).</p><p id="0958">The device consists of the following parts:</p><ul><li id="0a43">a series of sensors;</li><li id="b2d4">a microcontroller unit;</li><li id="79a6">a <a href="https://en.wikipedia.org/wiki/Zigbee" target="_blank" rel="noopener">ZigBee</a> transmitter;</li><li id="e9d8">a <a href="https://en.wikipedia.org/wiki/Lithium_iron_phosphate_battery" target="_blank" rel="noopener">LiFePO4 </a>battery with 2000mАh capacity;</li><li id="8319">a DC/DC converter;</li><li id="058e">a charge/discharge controller;</li><li id="1350">a solar panel for autonomous working.</li></ul><p id="ddc7">The device is sealed in the IP67 housing (description: <a href="https://en.wikipedia.org/wiki/IP_Code" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/IP_Code</a>).</p><p id="0c33">The block diagram of the device is as follows:</p><figure><div><div><p><img alt="The block diagram of the device." src="https://miro.medium.com/max/1218/0*4MNTWWozHSXtf3nF" width="609" height="402" srcset="https://miro.medium.com/max/552/0*4MNTWWozHSXtf3nF 276w, https://miro.medium.com/max/1104/0*4MNTWWozHSXtf3nF 552w, https://miro.medium.com/max/1218/0*4MNTWWozHSXtf3nF 609w" sizes="609px" data-old-src="https://miro.medium.com/max/60/0*4MNTWWozHSXtf3nF?q=20"></p></div></div></figure><p id="983d">Let’s suppose that during the development phase, some tests were carried out to check:</p><ul><li id="1c07">Stand-alone operation using solar battery charging;</li><li id="43e0">Transmitting of actual sensor data at the required distance;</li><li id="0562">Current consumption of the device within the permitted limits;</li><li id="219d">Hull tightness.</li></ul><p id="a3aa">It looks like the device passed all the necessary tests, and it is possible to start serial production.</p><p id="061a">Next, the following scenario is possible:</p><ol><li id="7bdf">The device documentation for mass production is written.</li><li id="30f7">A trial batch of 100 products is produced.</li><li id="de5d">The product is launched officially.</li><li id="c546">After a long and successful use during several months, the company produces a larger batch of several thousand units.</li><li id="0b29">The ambient temperature gets higher as summer comes.</li><li id="38a0">Due to high tightness of the device and the lack of active cooling, the devices gradually heat up to the temperatures when their batteries become unusable.</li><li id="a899">The battery capacity drops rapidly, making it harder to keep the supply voltage at the necessary level.</li><li id="17e4">The DC/DC converter starts to operate at its power limit and lose conversion efficiency over time, dissipating more and more power.</li><li id="729c">The increased temperature of the device’s active elements causes a fire.</li></ol><p id="9522">In this scenario, at best the devices will simply fail, at worst they will cause a fire.</p><p id="0cc3">In this example, the error is made at the initial stages of the construction of circuitry, as the device should have been load tested in aggressive conditions. To prevent the error in the remaining devices, it is necessary to completely change the approach to power supply and sealing.</p><p id="31b3">This means that producing hotfixes for devices with problems in circuitry and sealing mechanics is simply pointless. It is much cheaper and faster to reissue the entire batch of devices.</p><h2 id="b316"><strong>Price calculation of a simple error in a hardware project</strong></h2><p id="5150">If the errors from our example are detected in a real hardware project, the manufacturer will suffer colossal losses, and their reputation will also be affected, which may lead to bankruptcy.</p><p id="99e2">If that hardware company from our example decides to re-design and reissue their simple devices, it will need to spend huge amounts of money on the redevelopment of problem parts and additional testing.</p><p id="7ca3">Let’s make a simple calculation on how much it will have to spend on re-issuing the series of devices:</p><p id="1d46"><strong>Cost of parts: </strong>the price of parts for one device from the example ranges between $70 and $90.</p><p id="b8e1"><strong>Development: </strong>fixing power supply and sealing problems plus preliminary test will take an Embedded Systems Engineer about 15 hours.</p><p id="cb16"><strong>Simulation, testing under aggressive environment: </strong>simulation of the device’s behavior in real-world, calculation of power consumption and dissipation, and tests in aggressive conditions can take up to 50 hours.</p><p id="f40f">The average cost of the Embedded Systems Engineer work is <a href="https://www.payscale.com/research/US/Job=Embedded_Systems_Engineer/Salary" target="_blank" rel="noopener">30$/h</a>.</p><p id="8f01">Thus, to correct the error from our example, the company will need about $ 2,000, and reissuing of the trial 100-device batch will cost it about $ 8,000.</p><p id="94ac">The cost of lost time and customer confidence should also be added to the resulting amount. If the worst-case scenario unfolds, the damage compensations paid to the users will increase it even more.</p><p id="0a73">How to avoid such mistakes? Which tests should be given more attention? What are the main design problems when it comes to hardware? That’s what we’ll talk about later.</p><h2 id="5787">Step-by-step planning for prototype device development</h2><p id="32c8">To issue a test batch of devices successfully, you need to have a fully tested prototype device and complete technical documentation describing the production technology.</p><p id="7e42">The keyword here is “prototype” — a device that fully implements the required functionality and is ready for modification and optimization for the consequent serial production. More information about prototyping can be found here:</p><p id="5615">When you discuss the statement of work and possible deadlines with the customer, it is vital to take into account the following facts:</p><ul><li id="b40f">If all your hardware modules are stable as separate parts, it does not guarantee that they will work together in any way.</li><li id="f124">Successful prototyping does not mean that a product can be launched into a series — it is just one of the achievements on the way to mass production.</li><li id="4ac8">Each significant correction of the circuitry or mechanics requires the production of a new prototype. It also means another series of tests (no matter how long it takes, otherwise the production of prototypes does not make sense at all).</li><li id="a4b6">You need to allocate some extra time for prototyping as production depends on many off-project factors.</li><li id="56e6">While simulation and testing on debug stands to speed up the development at early design stages, they only add errors to the prototype at late stages.</li><li id="7555">One should avoid producing a large series of devices once the production technology is ready. It’s better to go with a small batch of devices to collect feedback and conduct tests in an aggressive environment.</li><li id="0806">At the design stage, it is necessary to allocate additional budget for …</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e">https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e</a></em></p>]]>
            </description>
            <link>https://blog.maddevs.io/the-cost-of-errors-in-hardware-projects-7d73b0fd8465?source=friends_link&amp;sk=eb21eb69d892cb19c0f85f3e0276481e</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828667</guid>
            <pubDate>Tue, 14 Jul 2020 04:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Committing Suicide]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828663">thread link</a>) | @lettergram
<br/>
July 13, 2020 | https://austingwalters.com/on-committing-suicide/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/on-committing-suicide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3389">

<div>
<p>Those that know me, know that I am both bold and resolute. I stand by my thoughts / comments, yet I attempt to keep an open mind, analyze a situation, self-reflect on any biases, and integrate feedback. I even go so far as to analyze my confidence level, see <a href="https://predictionbook.com/" target="_blank" rel="noopener noreferrer">predictionbook.com</a>.</p>
<p>With that in mind. I want to share how utterly angry and helpless I feel —</p>
<p>I can’t share my true thoughts, hell my analysis, of the current political situation in the U.S. Although I have written on it countless times, I end up deleting the posts.</p>
<p>Why?</p>
<p>It’s not safe to share thoughts.</p>
<h2>State of Affairs</h2>
<p>Today, sharing one’s opinion can cost you your livelihood, your ability to communicate, and more.</p>
<p>Historically, that was always true, perhaps more-so. We’re now returning to the status quo — repression.</p>
<p>Today’s flavor of repression is one where offending someone randomly across the globe, can cost you your job. That person may not have a standing in your community and may not have a relationship with your employer. However, they can amplify their voice, tweet your employer, and your employer (scared out of its mind by the current situation) will terminate you. That is the state of affairs today. It doesn’t matter if you’re correct or innocent. It doesn’t even matter if 99.9% of people aren’t offended by what you said — we are now in a world of “<a href="https://en.wikipedia.org/wiki/Online_shaming#Cancellation" target="_blank" rel="noopener noreferrer">cancel culture</a>“.</p>
<h2>Finding Middle Ground</h2>
<p>In the United States in 2020, we have two paths. One path leads to an ever more left-leaning populous “uprising”; the other path leads to an ever more right-leaning populous “uprising”. I don’t see an alternative, outside of some quite-frankly comical alternatives (e.g. President Mitt Romney, with VP Bernie Sanders).</p>
<p>One way or another, I lose. No one is speaking up for my beliefs or representing me.</p>
<p>I sense I’m not alone. Everyone I speak to left or right, hates the current state of affairs. Most of us even agree on <em>why</em> we distrust the system. Unfortunately, we can’t elect someone to fix the system. Neither Trump, nor Biden, nor Bernie, nor anyone on the ballot accurately represents or even inspires us.</p>
<p>By and large, I believe this is due to the “absolute” nature of our current social strife. Take the question:</p>
<blockquote><p>Why can’t I be anti-vaccine and pro-choice?</p></blockquote>
<p>You would suspect everyone would agree that we “own” our bodies. If that were true, then you would effectively have to be pro-choice AND support people’s right to choose what to put in their bodies; body ownership is the middle ground. I wish we could coalesce around the middle ground, then compromise on edge cases, enabling progress.</p>
<p>Take another example:</p>
<blockquote><p>Why don’t we do firearms training in schools?</p></blockquote>
<p>It’s an honest question — we’ve had the 2nd amendment for hundreds of years. Similar to driving a car, we should train our youth to handle firearms. I suspect we all know the reason this is not occurring — because a significant portion of the United States is fearful of firearms.</p>
<p>From the evidence, the fear is unjustified. We have evidence that with a good training program and robust mental evaluation process, firearms by-and-large are safe for society. <a href="https://en.wikipedia.org/wiki/Firearms_regulation_in_Switzerland" target="_blank" rel="noopener noreferrer">See Switzerland</a>:</p>
<blockquote><p>Swiss males grow up expecting to undergo basic military training, usually at age 20 in the recruit school..</p>
<p>…Prior to 2007, members of the Swiss Militia were supplied with 50 rounds of ammunition for their military weapon in a sealed ammo box that was regularly audited by the government…</p>
<p>…Every person with a Swiss citizenship, aged 10 years or older, can take part at any federal ranges and will be able to shoot for free with the ordinance rifle…</p>
<p>…In 2016, there were 187 attempted and 45 completed homicides, for a homicide rate of 0.50 per 100,000 population, giving Switzerland one of the lowest homicide rates in the world…</p></blockquote>
<p>Further, firearms are already widely available (<a href="https://en.wikipedia.org/wiki/Estimated_number_of_civilian_guns_per_capita_by_country" target="_blank" rel="noopener noreferrer">300+ million guns in the U.S.</a>) &amp; availability enshrined in law.</p>
<p>Sorrowfully, evidence doesn’t matter here; fear guides many. Yoda has some insights here:</p>
<blockquote><p><span data-parade-type="promoarea" data-parade-location-types="promoarea" data-parade-location-ids="article" data-parade-views="false" data-parade-touches="false" data-parade-clicks="false" data-parade-mouseovers="false">Fear is the path to the dark side. Fear leads to anger. Anger leads to hate. Hate leads to suffering.</span></p>
<p>— George Lucas (Yoda)</p></blockquote>
<h2>The False Dichotomy</h2>
<p>I don’t agree with the left or the right on many things in United States politics. In fact, I find most of the arguments a false dichotomy, designed to garner votes. To share one’s full thoughts would cause either or both sides to lash out, even though evidence may support the claims / musings.</p>
<p>Regretfully, this leaves me and many others out of the public discourse. While most of us have heard,</p>
<blockquote><p>The only thing necessary for the triumph of evil is for good men to do nothing.</p>
<p>— Edmund Burke (attributed)</p></blockquote>
<p>It’s not quite that simple and I prefer another sentiment:</p>
<blockquote><p>A man dies when he refuses to stand up for that which is right. A man dies when he refuses to stand up for justice. A man dies when he refuses to take a stand for that which is true.</p>
<p>— Martin Luther King Jr.</p></blockquote>
<center><br>
<iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/0On19DRA2fU?start=88" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"><span style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" data-mce-type="bookmark" class="lazy lazy-hidden mce_SELRES_start">﻿</span></iframe></center><p>Truthfully, we’re all being held hostage. I am very confident few people fully agree with either side in this political theater. We have extremists on either side shouting and being amplified by social media. In truth, the vast majority of us don’t agree [fully] with either extreme. Most of us, want to “live and let live” — that’s the American way. We’re a country founded on our hatred for taxes and the desire to live free from persecution. Please, please.. Don’t let that change.</p>
<p>It’s easy to decide “what’s right” when you look at it through that lens — am I persecuting others or increasing taxes (arguably a form of persecution)? If either are true, likely we should reconsider our stance.</p>
<h2>The Chaos</h2>
<p>Today, we are edging towards chaos. We all feel it. Riots, job loss, deadly diseases, [trade] wars, homelessness… We need leadership that can unite us.</p>
<p>Unfortunately, many of our would-be leaders have opted out or have been pushed out of this system. They’ve become engineers, scientists, bloggers — too scared to share their opinions (<a href="https://en.wikipedia.org/wiki/Slate_Star_Codex" target="_blank" rel="noopener noreferrer">even shutting down</a>). To hold a nuanced opinion different from the “socially accepted” by one group or another will get you “canceled”. In this case, “canceled” can mean anything from losing your job, to losing financial platforms/instruments (i.e. PayPal, VISA, YouTube revenue, etc.), to receiving threats on your life.</p>
<p>We have an ongoing pandemic, with millions in the United States likely about to perish, the economy collapsing, and we still cannot escape the politics.</p>
<p>I’m not hopeful.</p>
<p>I have so many musings, stories, and analyses I’d like to share, but neither facts nor my opinions matter.</p>
<p>Let’s be honest —</p>
<ul>
<li>I’m a white, cisgender, straight, male</li>
<li>I work as a technical manager in a research group, at a bank</li>
<li>I’m socially liberal in many ways and conservative in others</li>
<li>I grew up lower-middle class; now, I’m upper-middle class</li>
<li>I don’t attribute myself to any political party</li>
</ul>
<p>A large number of people dismiss or overlook me because of my background. Those who don’t outright dismiss me are also not likely to support my interest(s).</p>
<h2>Meritocracy or Bust</h2>
<p>What scares me is that I am a father and I am fearful for my children’s future. I was raised with the understanding that America is a meritocracy. Regardless of your race, gender, or creed, you should have the ability to make a life in the United States,<strong><em> to build a future for your children</em></strong>. Sadly, I don’t see the same core mission today. None of the political parties or the government at large appears forward-looking, for the children. Perhaps, that’s because of a <a href="https://www.cdc.gov/nchs/nvss/births.htm" target="_blank" rel="noopener noreferrer">declining birthrate</a>, I’m not sure.</p>
<p>As someone with children, I’m pleading for a group to come together to challenge the current status quo and equitably look to improve our society. We do have systemic problems that need to be fixed. Compromises will need to be made, but I don’t believe we need sacrifices from anyone.</p>
<p>The racism and sexism needs to stop. I suspect, most of us (though, not all) want a meritocracy, a hierarchy based on merit. Unfortunately, what’s being propagated is a hierarchy based on race, sex and orientation — the under-privileged. It’s clear from the countless stories we see in the news. I am sure you are tired of the racism, as am I. That’s probably true regardless of which side of the political spectrum you fall.</p>
<p><em>No one’s</em> value to society should be assessed by their race, gender or creed. A person’s value should be based off what they have to offer to a given group, organization, or society. We can rally around that idea (that we’re all equal, differentiated on merit) and work to improve. It’s a middle ground we can [mostly] agree on. From there, we can fix the injustices.</p>
<p>What horrifies me, is that even to express that <em>“we’re all equal” </em>is a challenge to this new socio-economic hierarchy. <em>No one</em> is representing me or has my family’s best interests in mind. Realistically, I don’t expect anyone to have <em>my family’s interests</em> in mind, but I don’t want my potential / rights eroded.</p>
<p>Due to this political tug of war, both sides of the political spectrum want to diminish our rights; they’re only bickering over which rights to diminish. Let’s stop this tug of war and come together.</p>
<p>If we don’t come together, soon enough we won’t have a democracy, or frankly, a future to build for.</p>
<h2>In the Words of John Adams…</h2>
<blockquote><p>Remember, democracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide. It is in vain to say that democracy is less vain, less proud, less selfish, less ambitious, or less avaricious than aristocracy or monarchy. It is not true, in fact, and nowhere appears in history. Those passions are the same in all men, under all forms of simple government, and when unchecked, produce the same effects of fraud, violence, and cruelty. When clear prospects are opened before vanity, pride, avarice, or ambition, for their easy gratification, it is hard for the most considerate philosophers and the most conscientious moralists to resist the temptation. Individuals have conquered themselves. Nations and large bodies of men, never.</p>
<p>— …</p></blockquote></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/on-committing-suicide/">https://austingwalters.com/on-committing-suicide/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/on-committing-suicide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828663</guid>
            <pubDate>Tue, 14 Jul 2020 04:56:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Google Committed $10B to India's Digital Future]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828478">thread link</a>) | @sbmthakur
<br/>
July 13, 2020 | https://finshots.in/archive/why-google-is-investing-in-india/ | <a href="https://web.archive.org/web/*/https://finshots.in/archive/why-google-is-investing-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">

    <div>

        <article>

            

            <figure>
                <img srcset="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 300w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 600w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 1000w,
                            https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://d3jlwjv6gmyigl.cloudfront.net/images/2020/07/google1.jpg" alt="Why Google committed $10 Billion to India's Digital Future">
            </figure>

            <section>
                <div>
                    <p><em>Google just promised to invest $10 Billion in India and we need to talk about it.</em></p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="the-story">The Story</h3><p>Yesterday, Google’s CEO, Sundar Pichai had a <a href="https://blog.google/inside-google/company-announcements/investing-in-indias-digital-future">big announcement</a> to make.</p><blockquote>Today, I’m excited to announce the Google for India Digitization Fund. Through this effort, we will invest ₹75,000 crore, or approximately $10 billion, into India over the next 5–7 years. We’ll do this through a mix of equity investments, partnerships, and operational, infrastructure and ecosystem investments. This is a reflection of our confidence in the future of India and its digital economy.</blockquote><p>And truth be told, it’s a big bet. I mean, when was the last time you saw a foreign company commit such an exorbitant sum to the future of India? It’s quite an unprecedented push for India’s digital dreams. And there was a four-point agenda that Google outlined to turn these dreams into reality.</p><p><strong>1) Enabling affordable access and information for every Indian in their own language, whether it’s Hindi, Tamil, Punjabi or any other.</strong></p><p>Explanation: India isn’t a large <a href="https://hbr.org/2017/12/you-dont-need-an-india-strategy-you-need-a-strategy-for-each-state-in-india">homogeneous market</a>. Instead, it’s an amalgamation of multiple micro markets with subtle differences in culture, language, income, tradition, and wealth. So tech companies aspiring to foray deep into these micro-markets will have to adapt to these differences.</p><p>Consider for instance the language divide.</p><p>Back in 2018, India had an <a href="https://www.livemint.com/industry/media/most-of-india-s-digitally-monetizable-users-want-vernacular-content-report-1565097932712.html">active internet user base</a> of 530 Million. However, close to half these users preferred digital content in their own language. And don’t scoff at this population. They come with an annual spending power of $300 billion. That’s a massive market crying out for tailor-made products. You can’t ignore them anymore.</p><p>Unfortunately, building a library rich in vernacular content will take time and money. Just look at the scale of the problem here — <a href="https://qz.com/india/1372074/google-using-ai-for-more-indian-language-content/">90% of the country’s</a> registered 135,000 publications don’t even have a website since they only cater to local communities. And most of them couldn’t scale their business online since they had very limited tools at their disposal.</p><p>In fact, back in 2018, Google said it was working with Indian language publishers to solve this very problem. They introduced <a href="https://navlekha.withgoogle.com/intl/en/#!/overview">Navlekha</a> — a platform that was supposed to allow publishers to edit and produce content in local languages without any expert digital knowledge. And they were just scratching the surface here.</p><p>But if they really wanted to make a dent , they had to have better subtitles, better translation, better content, better accessibility, better everything. They needed to make investments to help grow the vernacular ecosystem.</p><p>And guess what? It’s happening now.</p><p><strong>2) Building new products and services that are deeply relevant to India’s unique needs</strong></p><p>Every market has its own peculiar quirks and India is no different. When Samsung <a href="https://news.samsung.com/global/thinking-local-how-products-are-tailored-to-markets-2">launched its ActivWash+</a> washing machine they added a built-in sink, given the tendency among Indians to pre-wash clothes by hand. This meant consumers no longer had to crouch on the floor and they could hand wash their clothes standing upright. I am not saying Google is trying to build washing machines here. But like most things, tech products are likely to witness a surge in adoption rates if they are built specifically for the audience they cater to.</p><p>In fact, Google is no stranger to this. Back in 2017, they wrote a rather <a href="https://www.blog.google/technology/next-billion-users/building-india-first-products-and-features/">elaborate memo</a> on how they were building India-first products and features for the next billion Internet users.</p><blockquote>Another India-first feature is the new “two-wheeler mode” in Google Maps. India is the largest two-wheeler market in the world, and the millions of motorcycle and scooter riders have different navigation needs than drivers of automobiles. Two-wheeler mode in Maps shows trip routes that use “shortcuts” not accessible to cars and trucks. It also provides customized traffic and arrival time estimations. And since so many Indians rely on local landmarks for navigation, two-wheeler mode will show major landmarks on the route so that riders can plan their trip before starting, and don’t have to keep checking the phone on the go.</blockquote><p>I think it’s pretty clear what Google is trying to do here.</p><p><strong>3) Empowering businesses as they continue or embark on their digital transformation</strong></p><p>Think Google Pay. Currently the <a href="https://www.livemint.com/technology/tech-news/google-pay-set-to-tap-into-12mn-kirana-stores-in-india-1566990709066.html">platform has</a> over 3,000 online merchants and over 200,000 offline merchants. They use it to take payments, pay their suppliers, transfer money to employees and pay the odd electricity bill. And if Google can partner with other similar entities that are trying to help grow India’s fledgling digital ecosystem, it would be a win-win for everyone involved.</p><p>Right?</p><p><strong>4) Leveraging technology and AI for social good, in areas like health, education, and agriculture</strong></p><p>“Don’t be evil” was a part of the company’s <a href="https://abc.xyz/investor/other/google-code-of-conduct.html" rel="noopener noreferrer noopener">corporate code of conduct</a> since 2000. When Google reorganized in 2015, the parent company Alphabet assumed a <a href="https://www.engadget.com/2015/10/02/alphabet-do-the-right-thing/" rel="noopener noreferrer noopener">slightly different version</a> of the motto — “do the right thing.”</p><p>So, point 4 ought to be self-explanatory. It’s literally their motto.</p><p>But do bear in mind, that there is an ulterior motive here. Google wasn’t going to spend this money and push the digitization initiative if it didn’t make business sense. After all, a digital India translates to more people taking to the internet. And since Google makes most of its money offering advertising services online, you can get a sense of why they are making this bet right now.</p><!--kg-card-begin: image--><figure><img src="https://cdn-images-1.medium.com/max/900/1*EuniDplL-G6F5Fs-XOXXjw.jpeg"></figure><!--kg-card-end: image--><p>Nonetheless, that’s it from us today. If you had a friend, family member, or relative talking about this big investment, make sure they get some context. Make sure they know what this means and why Google is venturing down this path. Ergo, share this article on <a href="https://api.whatsapp.com/send?text=An%20explainer%20on%20why%20Google%20is%20investing%20$10%20billion%20in%20India?%20https://bit.ly/3gSwU1o">WhatsApp</a>, <a href="https://twitter.com/intent/tweet?url=https://bit.ly/303yozb&amp;via=finshots&amp;text=An%20explainer%20on%20why%20Google%20is%20investing%20$10%20billion%20in%20India?">Twitter</a>, and <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://finshots.in/archive/why-google-is-investing-in-india">LinkedIn</a>, will you?</p><p>Until next time…</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p><em>Correction: We removed the infographic benchmarking GDP of different states with other countries across the world since the data in the chart was erroneous. We regret the error</em></p>
                </div>
            </section>


            

            

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://finshots.in/archive/why-google-is-investing-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828478</guid>
            <pubDate>Tue, 14 Jul 2020 04:17:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How major and minor device numbers worked in V7 Unix]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828398">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How major and minor device numbers worked in V7 Unix</h2>

	<p><small>July 13, 2020</small></p>
</div><div><p>Unix people who've been around for a while know that Unix devices
have <em>device numbers</em>, and that device numbers are divided into
<em>major</em> and <em>minor</em> device numbers. When you do '<code>ls -l /dev/null</code>'
and one of the fields that <code>ls</code> prints is two comma separated
numbers, those are the major and minor numbers (on Linux, they are
'1, 3'; this varies by Unix). Device numbers and their split into
major and minor parts go back a long way, to before Research Unix
V7, but V7 makes a convenient point to look at what they meant and
how they worked in the original Unixes.</p>

<p>As various sources will tell you, the major number tells you (and
the Unix kernel) what sort of device it is and thus what device
driver to use to talk to it, while the minor number tells the device
driver what specific bit of hardware it's responsible for that you
want to talk to.  Sometimes the minor number also determines some
bit of functionality. Because V7 was a deliberately simple and
brute force system and kernel, major device numbers had a very
simple implementation. We can see it in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/c.c">the generated V7 kernel
configuration file <code>c.c</code></a>:</p>


<pre> struct bdevsw bdevsw[] =
 {
   nulldev, nulldev, rkstrategy, &amp;rktab, /* rk = 0 */
   nodev, nodev, nodev, 0, /* rp = 1 */
   [...]
   nodev, nodev, nodev, 0, /* hp = 6 */
   htopen, htclose, htstrategy, &amp;httab, /* ht = 7 */
   nodev, nodev, nodev, 0, /* rl = 8 */
   0
 };
</pre>

<p>What we're seeing here is that V7 literally had an array of <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/conf.h"><code>bdevsw</code>
structures</a> indexed
by the major (block) device number, with various function that were
called when you did things like open a device (in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/sys/fio.c"><code>fio.c</code></a>).
There was a similar array for character devices, the <code>cdevsw</code> array.
In both of them, what driver functions were listed here instead of
stubbed out were determined by simple configuration files (<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf">here</a>)
that said what devices you had (among other things).</p>

<p>(The <code>c.c</code> file was generated by <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/conf/mkconf.c">a program</a>.
The particular <code>c.c</code> file in the TUHS V7 tree was built with only
two block devices configured, the <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rk.c">RK disk driver</a> and
<a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/ht.c">TJU16 tape driver 'ht'</a>.)</p>

<p>In V7 the minor device number was only interpreted by the device
driver, as far as I can see. Device drivers used this for a variety
of purposes. For instance, <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/mem.c">the <code>mem</code> character driver</a>
implemented <code>/dev/null</code> as minor device 2, to go along with access
to physical memory and kernel memory. The <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/rl.c"><code>rl</code> disk driver</a> used
the minor device number to decide what physical disk it was talking
to (it supported up to four of them). Once V7 started getting out
in the world, other people wrote drivers for it (such as <a href="http://clara.comm.sfu.ca/pups/PDP-11/Trees/V7/usr/sys/dev/rx2.c">the RX02
floppy disk driver</a>) that
used minor device numbers both to select what to talk to and control
what features to use.</p>

<p>(There's also <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/kl.c">the <code>kl</code> KL/DL-11 serial and console driver</a>, which
seems to deal with three different sets of hardware control registers
based on the minor number.)</p>

<p>The <code>/dev/tty</code> character device was implemented in a clever and
very short way in <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/dev/sys.c"><code>sys.c</code></a>. In
V7, there were no pseudo-ttys and no hot-plugged devices, so your
underlying physical terminal device always existed and was recorded
in your <code>u</code> area (see <a href="https://minnie.tuhs.org/cgi-bin/utree.pl?file=V7/usr/sys/h/user.h"><code>user.h</code></a>) The
general tty driver simply used this recorded device number of your
controlling tty to call its open, read, write, and ioctl functions
through the <code>cdevsw</code> array. As far as I can tell, this driver paid
no attention at all to the minor device number; as long as <code>/dev/tty</code>
had major number 7, the minor number was irrelevant.</p>

<p>PS: Note that V7 device drivers tended to be a little relaxed about
error checking for their minor device numbers (and other things).
For instance, as far as I can tell the <code>mem</code> driver actually only
distinguishes between minor number 2, minor number 1, and 'everything
else', which is treated as minor number 0, giving access to physical
memory.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/V7DeviceNumbersHow</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828398</guid>
            <pubDate>Tue, 14 Jul 2020 04:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial: How to Build LinkedIn Automation Tools with Python with a Code Example]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828280">thread link</a>) | @ferlita
<br/>
July 13, 2020 | https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/ | <a href="https://web.archive.org/web/*/https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<blockquote>LinkedIn is the most popular social media platform for people to meet one another in a professional setting. I recommend you to read our article, <a href="https://nubela.co/blog/why-every-salesperson-should-crawl-linkedin/">Why Every Salesperson Should Crawl LinkedIn</a> and <a href="https://nubela.co/blog/how-to-automate-linkedin-sales-prospecting/">How to Automate LinkedIn Sales Prospecting</a>, to illustrate the needs of LinkedIn automation for scaling up your business.</blockquote><p>In this tutorial, I will guide you with code to get LinkedIn profile details from a list of LinkedIn URL. While this tutorial focuses only on getting the profile details you need, data processing can be done according to your needs.</p><p>This tutorial will show you two ways of doing it:</p><p><code>sequential</code> and <code>asynchronous</code></p><h3 id="setting-up-prerequisites">Setting up prerequisites</h3><ul><li>Python 3</li><li>A Proxycurl LinkedIn API credential ( API key )</li></ul><p>For sequential method:</p><ul><li><a href="https://pypi.org/project/requests/"><code>request</code></a></li></ul><p>For asynchronous method:</p><ul><li><a href="https://pypi.org/project/asyncio/"><code>asyncio</code></a></li><li><a href="https://pypi.org/project/aiohttp/"><code>aiohttp</code></a></li></ul><h3 id="how-to-get-a-proxycurl-linkedin-api-credential">How to get a Proxycurl LinkedIn API credential</h3><p>You can create a free trial Proxycurl credential at <a href="https://nubela.co/proxycurl">Proxycurl's website</a>. However, with the trial credential, your credits are limited to 100 points (1 point for 1 successful profile request).</p><p>If you need more credits, it is only $0.01 per profile! Read the <a href="https://nubela.co/blog/introducing-proxycurls-linkedin-api/">introduction to Proxycurl's LinkedIn API here</a> and please send an email to <a><span data-cfemail="473735283f3e2432352b07293225222b26692428">[email&nbsp;protected]</span></a> for inquiries.</p><h3 id="sequential-vs-asynchronous">Sequential vs Asynchronous</h3><p>The asynchronous method gives a shorter overall duration than the sequential method as it sends multiple requests at once while the sequential method only sends one request at a time, each request waiting on the previous one to return a response. However, it also depends on the request execution time that varies according to the latency of the server. As such, this tutorial provides both sequential and asynchronous methods to give comparisons of the code between them.</p><p>Let's start with viewing the base code from <a href="https://nubela.co/proxycurl/docs#introduction-to-proxycurl-39-s-api">proxycurl's documentation</a> :</p><pre><code>
import requests

api_endpoint = 'https://nubela.co/proxycurl/api/linkedin'

linkedin_profile_url = 'https://www.linkedin.com/in/williamhgates'

api_key = '********-****-****-****-************' # your api_key

header_dic = {'Authorization': 'Bearer ' + api_key}

response = requests.get(api_endpoint,

                        params={'url': linkedin_profile_url},

                        headers=header_dic)

print(response.content)  # To get all profile details

print(response.content["first_name"])  # To get profile first name

</code></pre><p>You can change the <code>"first_name"</code> to other <code>respond key</code> in <a href="https://nubela.co/proxycurl/docs#crawling-linkedin-profiles">this Proxycurl documentation</a></p><h3 id="1-sequential-method">1. Sequential Method</h3><pre><code>
import requests , json 

from requests.exceptions import HTTPError

api_endpoint = 'https://nubela.co/proxycurl/api/linkedin'

api_key = '********-****-****-****-************' # your api_key

header_dic = {'Authorization': 'Bearer ' + api_key}

linkedin_profile_list = [

    'https://www.linkedin.com/in/williamhgates',

    'https://www.linkedin.com/in/melindagates',

    'https://www.linkedin.com/in/owinfrey'

                        ]

def get_profile_details(likedin_profile_url, session):

    url = api_endpoint

    response = None

    try:

        response = session.get(url, params={'url': linkedin_profile_url}, headers=header_dic)

        response.raise_for_status()

        # print(f"Response status ({url}): {response.status_code}")

    except HTTPError as http_err:

        print(f"HTTP error occurred: {http_err}")

    except Exception as err:

        print(f"An error ocurred: {err}")

    response_json = json.loads(response.content)

    return response_json

with requests.Session() as session:

    for linkedin_profile_url in linkedin_profile_list:

        try:

            response = get_profile_details(linkedin_profile_url, session)

            print (response["first_name"]) # To get first_name key

            # print(response) # To get all profile details

            # print()

        except Exception as err:

            print(f"Exception occured: {err}")

</code></pre><h4 id="let-s-breakdown-the-code-">Let's breakdown the code.</h4><p>As usual, we imported the required library.</p><p>Then we use all the variables defined before in the base code except the <code>linkedin_profile_url</code>. Instead, we create a new list, <code>linkedin_profile_list</code>, to hold the URLs of the profiles we want to scrape. For now, we will use 3 LinkedIn profiles for demonstration purposes.</p><p>Next, we define <code>get_profile_details</code> function to make a GET request to Proxycurl's LinkedIn API. We pass in the profile URL as a <code>query param</code> of the request, along with the Authorization header. Then the JSON response is parsed into Python dictionary using <code>json.loads()</code>.</p><p>Uncomment line with <code>print(f"Response status ({url}): {response.status_code}")</code> to print response status (200 for success). Take note that a request with a 200 response code indicates a successful request and 1 credit is consumed.</p><p>The code block under <code>with requests.Session() as session</code> will iterate through the <code>linkedin_profile_list</code> and print the <code>public_identifier</code>.</p><p>Uncomment line with <code>print (response)</code> to print all profile details.</p><h3 id="2-asynchronous-method">2. Asynchronous Method</h3><pre><code>
import aiohttp, asyncio, json

from aiohttp import ClientSession

from urllib.error import HTTPError

api_endpoint = 'https://nubela.co/proxycurl/api/linkedin'

api_key = '********-****-****-****-************' # your api_key

header_dic = {'Authorization': 'Bearer ' + api_key}

linkedin_profile_list = [

    'https://www.linkedin.com/in/williamhgates',

    'https://www.linkedin.com/in/melindagates',

    'https://www.linkedin.com/in/owinfrey'

                        ]

async def get_profile_details_async(linkedin_profile_url, session):

    url = api_endpoint

    response = None

    try:

        response = await session.request(method='GET', url=url, params={'url': linkedin_profile_url}, headers=header_dic)

        response.raise_for_status()

        print(f"Response status ({url}): {response.status}")

    except HTTPError as http_err:

        print(f"HTTP error occurred: {http_err}")

    except Exception as err:

        print(f"An error ocurred: {err}")

    response_json = await response.content.read()

    return json.loads(response_json)

async def run_program(linkedin_profile_url, session):

    try:

        response = await get_profile_details_async(linkedin_profile_url, session)

        print (response["public_identifier"])

        print(response)

        print()

    except Exception as err:

        print(f"Exception occurred: {err}")

        pass

async def run_async():

    async with ClientSession() as session:

        await asyncio.gather(*[run_program(linkedin_profile_url, session) for linkedin_profile_url in linkedin_profile_list])

def main():

    loop = asyncio.get_event_loop()

    loop.run_until_complete(run_async())

    loop.close()

if __name__ == '__main__':

    main()

</code></pre><p><strong><em>note: &nbsp; </em></strong>if you got this error on Mac OS:</p><p><code>urllib.error.URLError: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed</code></p><p>In the terminal, try to run:</p><p><code>pip install --upgrade certifi</code></p><p>If it doesn't work, try to run:</p><p><code>open /Applications/Python\ 3.6/Install\ Certificates.command</code></p><h4 id="let-s-breakdown-the-code--1">Let's breakdown the code.</h4><p>The <code>async</code> keyword that prepends the function signature tells Python that this function is a coroutine.</p><p>The <code>await</code> keyword, such as in <code>response = await session.request(...)</code> and <code>response_json = await response.content.read()</code>, tell that coroutine to suspend execution and give back control to the event loop, while the operation is awaiting finishes.</p><p>A coroutine is similar to generators in Python that consume values instead of producing values. It will pause the execution while waiting for the new data.</p><p>In our case, it suspends the execution of <code>get_profile_details_async</code> while the request is being performed: <code>await session.request(...)</code>. It is suspended again, while the response is being read by the stream reader: <code>await response.content.read()</code> and <code>json.loads(response_json)</code>.</p><p>Then, we have the <code>run_program</code> coroutine as a wrapper around the pipeline of getting a response from the API, parsing it to JSON, and printing the results on the screen. It awaits the execution of the <code>get_profile_details_async</code> coroutine.</p><p>After that, using the <code>asyncio.gather</code> syntax, we tell the program to schedule all the tasks based on the list of coroutines we provided. This is what allows us to execute tasks concurrently.</p><p>Lastly, define <code>main</code> function to run <code>run_async</code> function using <code>asyncio.get_event_loop()</code> and run it under <code>if __name__ == '__main__'</code> block.</p><h3 id="3-challenges">3. Challenges</h3><p>There are still many things you can do beyond this tutorial after retrieving the data you need. You can either store all the data first into any type of file you want and do the data processing, or you can filter the data by adding functions to our code before and only saving the information you need, to make your own personalized LinkedIn automation tool!</p>
</div>
</section></div>]]>
            </description>
            <link>https://nubela.co/blog/tutorial-how-to-build-linkedin-automation-tools-with-python-with-a-code-example/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828280</guid>
            <pubDate>Tue, 14 Jul 2020 03:41:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tufte CSS]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23828196">thread link</a>) | @mmastrac
<br/>
July 13, 2020 | https://edwardtufte.github.io/tufte-css/ | <a href="https://web.archive.org/web/*/https://edwardtufte.github.io/tufte-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>Dave Liepmann</p>
      <section>
        <p>Tufte CSS provides tools to style web articles using the ideas demonstrated by Edward Tufte’s books and handouts. Tufte’s style is known for its simplicity, extensive use of sidenotes, tight integration of graphics with text, and carefully chosen typography.</p>
        <p>Tufte CSS was created by <a href="http://www.daveliepmann.com/">Dave Liepmann</a> and is now an Edward Tufte project. The original idea was cribbed from <a href="https://tufte-latex.github.io/tufte-latex/">Tufte-<span>L<span>a</span>T<span>e</span>X</span></a> and <a href="http://rmarkdown.rstudio.com/tufte_handout_format.html">R Markdown’s Tufte Handout format</a>. We give hearty thanks to all the people who have contributed to those projects.</p>
        <p>If you see anything that Tufte CSS could improve, we welcome your contribution in the form of an issue or pull request on the GitHub project: <a href="https://github.com/edwardtufte/tufte-css">tufte-css</a>. Please note the <a href="https://github.com/edwardtufte/tufte-css#contributing">contribution guidelines</a>.</p>
        <p>Finally, a reminder about the goal of this project. The web is not print. Webpages are not books. Therefore, the goal of Tufte CSS is not to say “websites should look like this interpretation of Tufte’s books” but rather “here are some techniques Tufte developed that we’ve found useful in print; maybe you can find a way to make them useful on the web”. Tufte CSS is merely a sketch of one way to implement this particular set of ideas. It should be a starting point, not a design goal, because any project should present their information as best suits their particular circumstances.</p>
      </section>

      <section>
        <h2 id="getting-started">Getting Started</h2>
        <p>To use Tufte CSS, copy <code>tufte.css</code> and the <code>et-book</code> directory of font files to your project directory, then add the following to your HTML document’s <code>head</code> block:</p>

        <pre><code>&lt;link rel="stylesheet" href="tufte.css"/&gt;</code></pre>

        <p>Now you just have to use the provided CSS rules, and the Tufte CSS conventions described in this document. For best results, View Source and Inspect Element frequently.</p>
      </section>

      <section>
        <h2 id="fundamentals">Fundamentals</h2>
        <h3 id="fundamentals--sections-and-headers">Sections and Headings</h3>
        <p>Organize your document with an <code>article</code> element inside your <code>body</code> tag. Inside that, use <code>section</code> tags around each logical grouping of text and headings.</p>
        <p>Tufte CSS uses <code>h1</code> for the document title, <code>p</code> with class <code>subtitle</code> for the document subtitle, <code>h2</code> for section headings, and <code>h3</code> for low-level headings. More specific headings are not supported. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:</p>
        <blockquote cite="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB">
          <p>[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of <em>sentences</em> which then cumulate sequentially into <em>paragraphs</em>, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.</p>
          
        </blockquote>
        <p>As a bonus, this excerpt regarding the use of headings provides an example of block quotes. In Tufte CSS they are just lightly styled, semantically correct HTML using <code>blockquote</code> and <code>footer</code> elements. See page 20 of <a href="https://www.edwardtufte.com/tufte/books_vdqi">The Visual Display of Quantitative Information</a> for an example in print.</p>
        <p><span>In his later books<label for="sn-in-his-later-books"></label></span><span><a href="http://www.edwardtufte.com/tufte/books_be"><em>Beautiful Evidence</em></a></span>, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and the first few words of the sentence set in small caps. For this we use a span with the class <code>newthought</code>, as demonstrated at the beginning of this paragraph. Vertical spacing is accomplished separately through <code>&lt;section&gt;</code> tags. Be consistent: though we do so in this paragraph for the purpose of demonstration, do not alternate use of header elements and the <code>newthought</code> technique. Pick one approach and stick to it.</p>

        <h3 id="fundamentals--text">Text</h3>
        <p>Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. Tufte CSS uses <code>#fffff8</code> and <code>#111111</code> because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. We stick to the greyscale for text, reserving color for specific, careful use in figures and images.</p>
        <p>In print, Tufte has used the proprietary Monotype Bembo<label for="sn-proprietary-monotype-bembo"></label><span>See Tufte’s comment in the <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt">Tufte book fonts</a> thread.</span> font. A similar effect is achieved in digital formats with the now open-source <a href="https://github.com/edwardtufte/et-book">ETBook</a>, which Tufte CSS supplies with a <code>@font-face</code> reference to a .ttf file. In case ETBook somehow doesn’t work, Tufte CSS shifts gracefully to other serif fonts like Palatino and Georgia.</p>
        <p>Also notice how Tufte CSS includes separate font files for bold (strong) and italic (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice.</p>
        <p>If you prefer sans-serifs, use the <code>sans</code> class. It relies on Gill Sans, Tufte’s sans-serif font of choice.</p>
        <p>Links in Tufte CSS match the body text in color and do not change on mouseover or when clicked. Here is a <a href="#">dummy example</a> that goes nowhere. These links are underlined, since this is the most widely recognized indicator of clickable text. <label for="mn-blue-links">⊕</label><span>Blue text, while also a widely recognizable clickable-text indicator, is crass and distracting. Luckily, it is also rendered unnecessary by the use of underlining.</span> However, because most browsers’ default underlining does not clear descenders and is so thick and distracting, the underline effect is instead achieved using CSS trickery involving background gradients instead of standard <code>text-decoration</code>. Credit goes to Adam Schwartz for that technique.</p>
        <p>As always, these design choices are merely one approach that Tufte CSS provides by default. Other approaches can also be made to work. The goal is to make sentences readable without interference from links, as well as to make links immediately identifiable even by casual web users.</p>
      </section>

      <section>
        <h2 id="epigraphs">Epigraphs</h2>
        <div>
          <blockquote>
            <p>The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.</p>
            
          </blockquote>
          <blockquote>
            <p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p>
            
          </blockquote>
          <blockquote>I do not paint things, I paint only the differences between things.</blockquote>
        </div>
        <p>If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. Modeled after chapter epigraphs in Tufte’s books (particularly <em>Beautiful Evidence</em>), these are <code>blockquote</code> elements with a bit of specialized styling. Quoted text is italicized. The source goes in a <code>footer</code> element inside the <code>blockquote</code>. We have provided three examples in the epigraph of this section, demonstrating shorter and longer quotes, with and without a paragraph tag, and showing how multiple quotes within an epigraph fit together with the use of a wrapper class.</p>
      </section>

      <section>
        <h2 id="sidenotes">Sidenotes: Footnotes and Marginal Notes</h2>
        <p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<label for="sn-extensive-use-of-sidenotes"></label><span>This is a sidenote.</span> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p>
        <p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p>
        <p>Sidenotes consist of two elements: a superscript reference number that goes inline with the text, and a sidenote with content. To add the former, just put a label and dummy checkbox into the text where you want the reference to go, like so:</p>
        <pre><code>&lt;label for="sn-demo"
       class="margin-toggle sidenote-number"&gt;
&lt;/label&gt;
&lt;input type="checkbox"
       id="sn-demo"
       class="margin-toggle"/&gt;</code></pre>
        <p>You must manually assign a reference <code>id</code> to each side or margin note, replacing “sn-demo” in the <code>for</code> and the <code>id</code> attribute values with an appropriate descriptor. It is useful to use prefixes like <code>sn-</code> for sidenotes and <code>mn-</code> for margin notes.</p>
        <p>Immediately adjacent to that sidenote reference in the main text goes the sidenote content itself, in a <code>span</code> with class <code>sidenote</code>. This tag is also inserted directly in the middle of the body text, but is either pushed into the margin or hidden by default. Make sure to position your sidenotes correctly by keeping the sidenote-number label close to the sidenote itself.</p>
        <p>If you want a sidenote without footnote-style numberings, then you want a margin note.
          <label for="mn-demo">⊕</label>
          
          <span>
            This is a margin note. Notice there isn’t a number preceding the note.
          </span> On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text. However, on small screens, a margin note is like a sidenote except its viewability-toggle is a symbol rather than a reference number. This document currently uses the symbol ⊕ (<code>&amp;#8853;</code>), but it’s up to you.</p>
        <p>Margin notes are created just like sidenotes, but with the <code>marginnote</code> class for the content and the <code>margin-toggle</code> class for the label and dummy checkbox. For instance, here is the code for the margin note used in the previous paragraph:</p>
        <pre><code>&lt;label for="mn-demo" class="margin-toggle"&gt;&amp;#8853;&lt;/label&gt;
&lt;input type="checkbox" id="mn-demo" class="margin-toggle"/&gt;
&lt;span class="marginnote"&gt;
  This is a margin note. Notice there isn’t a number preceding the note.
&lt;/span&gt;</code></pre>
        </section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edwardtufte.github.io/tufte-css/">https://edwardtufte.github.io/tufte-css/</a></em></p>]]>
            </description>
            <link>https://edwardtufte.github.io/tufte-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828196</guid>
            <pubDate>Tue, 14 Jul 2020 03:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terraform Pain Points]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23828089">thread link</a>) | @jbergknoff
<br/>
July 13, 2020 | https://jonathan.bergknoff.com/journal/terraform-pain-points/ | <a href="https://web.archive.org/web/*/https://jonathan.bergknoff.com/journal/terraform-pain-points/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
	
	<h6>
		<span>2020-07-08</span>

		
		<span>
			
			<a href="https://jonathan.bergknoff.com/tags/tech">tech</a>
			
			<a href="https://jonathan.bergknoff.com/tags/programming">programming</a>
			
			<a href="https://jonathan.bergknoff.com/tags/terraform">terraform</a>
			
		</span>
		
	</h6>
	<hr>
	

<p>I love using <a href="https://www.terraform.io/">Terraform</a>. At my previous job, we managed our infrastructure entirely with Terraform: tens of thousands of resources spread across several cloud providers. The benefits of infrastructure-as-code and Terraform, in particular, are massive, but well known. While I still consider Terraform the best tool of its kind, this article describes some pain points that my team and I encountered as power users. I hope it can lead to some discussion about ways to improve.</p>

<p>All of these are relevant as recently as Terraform v0.13.0-beta3, July 2020.</p>

<ul>
<li><a href="#refactoring-is-difficult">Refactoring is difficult</a></li>
<li><a href="#code-reuse-is-limited">Code reuse is limited</a></li>
<li><a href="#type-system-is-too-rigid">Type system is too rigid</a></li>
<li><a href="#upstream-development-frustrating-priorities">Upstream development: frustrating priorities</a></li>
</ul>

<p>This is part one in a series about Terraform. Part two, detailing some Terraform practices that we found effective, will be up shortly.</p>

<h2 id="refactoring-is-difficult">Refactoring is difficult</h2>

<p>Terraform code is unwieldy to refactor. Even giving a resource a new <em>internal</em> name is a hassle. Here’s our simple Terraform definition:</p>

<pre><code>resource "aws_s3_bucket" "bucket" {
  bucket = "images.bigco.com"
}
</code></pre>

<p>Now it’s a month later, and we’re adding our second bucket, so let’s change our Terraform code to use a more specific name:</p>

<pre><code>resource "aws_s3_bucket" "images_bucket" {
  bucket = "images.bigco.com"
}
</code></pre>

<p>If we naively try to make this innocuous-looking change, Terraform will want to delete and recreate the bucket. We probably all understand why that’s the case, and it helps us appreciate how wonderful the concept of <code>terraform plan</code> is, but it’s ludicrous to have no serious facility for doing this smoothly. <code>terraform state mv</code> exists, but you need to run that separately, outside the plan/apply lifecycle. If you need to do this for ten environments, it’s a lot of work.</p>

<p>And that’s the easy case. Moving across module boundaries is harder, especially if you want to move the resources from the module into the root of the state (spoiler: <code>state mv</code> can’t do it). Moving across state boundaries is harder still. While the <a href="https://www.terraform.io/docs/commands/state/mv.html">documentation</a> mentions moving to a different state file, there’s no support for hooking it up to an already-existing state in S3 (for example). The tool is not at all user friendly or convenient.</p>

<p>The silver lining is that Terraform state is a simple JSON file, so it’s easy to write your own tooling around it. My team had occasion to do several refactors where we pulled individual projects’ resources out of a monolithic state and into their own states, once for each of our environments. Trying to orchestrate that with <code>state mv</code> would have been an awkward mess, but writing a simple Python script to pull state from S3, modify it, and push it back, was not too bad (if you do this, you’ll also want to remove the state checksum from DynamoDB).</p>

<p>You’re never going to nail the module and state boundaries correctly on your first pass (or ever?). Refactoring is inescapable. It needs to be more convenient. It would be great if there was some way to signal to Terraform “hey, this resource used to have a different address”. Something like this seems reasonable:</p>

<pre><code>resource "aws_s3_bucket" "images_bucket" {
  bucket = "images.bigco.com"

  lifecycle {
    old_addresses = [
      "aws_s3_bucket.bucket",
      "module.images_bucket.aws_s3_bucket.bucket",
    ]
  }
}
</code></pre>

<h2 id="code-reuse-is-limited">Code reuse is limited</h2>

<p>Terraform’s main tool for code reuse (i.e. a chunk of resource definitions that can be reused with different inputs) is the <code>module</code> (symlinks may also be useful in some situations, but I haven’t used them for this). Modules are limited in some ways.</p>

<h4 id="it-s-awkward-to-pin-module-versions">It’s awkward to pin module versions</h4>

<p>You <a href="https://github.com/hashicorp/terraform/issues/1439">can’t do interpolation in a module’s <code>source</code> parameter</a>. So if a dozen modules should all be pointing at the same revision of your <a href="https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d">modules git repository</a>, there’s no clean way to update all those references in one place. My team had a Makefile target, which we ran manually, that used <code>find</code> and <code>sed</code> to update all the references.</p>

<p>Leaving the module source unpinned is not an option I’d be comfortable with because it’s a vector for un-source-controlled drift that can be easily avoided.</p>

<h4 id="can-t-partially-apply-modules">Can’t partially apply modules</h4>

<p>The biggest problem we’ve faced with the module system is the inability to do <a href="https://en.wikipedia.org/wiki/Partial_application">partial application</a> (in the computer science sense). In essence, it would be nice to simplify a module’s interface by binding a bunch of common parameters. Here’s an example:</p>

<pre><code>module "service_a" {
  source = "..."

  name = "service_a"

  environment_variables = merge(
    local.environment_variable_defaults,
    {
      THING = "1",
    },
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
  ...
}

module "service_b" {
  source = "..."

  name = "service_b"

  environment_variables = merge(
    local.environment_variable_defaults,
    {
      THING = "2",
    },
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
  ...
}
</code></pre>

<p>These services have, say, fifteen parameters being passed in, and they only differ in one or two. There should be some more expressive way of writing them so that only those two unique values are prominent. Instead, you’re stuck copy/pasting a bunch of boilerplate, and editing in the unique values. That’s error-prone and a maintenance burden.</p>

<p>There’s an <a href="https://www.terraform.io/docs/configuration/locals.html">analogy</a> between Terraform definitions and a conventional programming language: a set of Terraform definitions (a module) is like a function, with TF variables being inputs to the function, TF locals being local variables, and TF outputs being return values. The extension of that analogy to this use case is partial application, where you give a module some of its inputs, it binds those values and you get back a module with only the rest of the inputs. Terraform doesn’t support it.</p>

<p>Ideally, we’d be able to define some sort of a “submodule” like this:</p>

<pre><code>submodule "service" {
  source = "..."

  environment_variables = merge(
    local.environment_variable_defaults,
    ?
  )

  vpc_id     = local.vpc_id
  subnet_ids = local.subnet_ids
}

module "service_a" {
  source = submodule.service

  name = "service_a"

  environment_variable_overrides = {
    THING = "1",
  }
}
</code></pre>

<p>We can’t use a proper module for this, because it doesn’t have access to its parent’s locals (which seems right). Notice the unsolved problem here of how to refer to those environment variable overrides in the submodule. This isn’t a fully-formed proposal.</p>

<p>Here are some ways we’ve dealt with this.</p>

<h5 id="code-reuse-workaround-1-big-map-of-config">Code reuse workaround 1: big map of config</h5>

<p>You can pass a big map of config as input to the module, rather than individual variables. That map can be defined as a local, and can include all the common values. Each service can merge on top of it to provide its overrides.</p>

<p>It’s a hack, but it works to reduce boilerplate. There are a couple of serious drawbacks, though:</p>

<ul>
<li><p>Terraform’s <code>merge()</code> only performs a shallow merge. This is surprising behavior, and can lead to subtle bugs. You can work around it if you know about it, but the workarounds are often awkward. There’s an <a href="https://github.com/hashicorp/terraform/pull/25032">open PR</a> adding a <code>deepmerge()</code> function.</p></li>

<li><p>When anything in the map is “not known until after apply” (e.g. an attribute of a resource that hasn’t been created yet), the entire map is considered “not known until after apply”. For example, if our config map looks like</p>

<pre><code>config = {
  vpc_id = aws_vpc.vpc.id,
  thing_enabled = true,
}
</code></pre>

<p>and the module does something like</p>

<pre><code>resource ... {
  count = var.config.thing_enabled ? 1 : 0

  ...
}
</code></pre></li>
</ul>

<p>then this will fail to plan if the VPC doesn’t already exist because <code>var.config</code> contains something (the VPC id) which isn’t known yet, and so <code>var.config.thing_enabled</code> is not known until after apply. This is subtle and unexpected, and the error messages you’ll see from it are cryptic. But it’s very easy to do by accident once some resources are created already. Then the next time you try to bootstrap a new state (e.g. a new environment), you’ll find that it won’t plan successfully.</p>

<h5 id="code-reuse-workaround-2-generate-terraform-definitions-from-templates">Code reuse workaround 2: generate Terraform definitions from templates</h5>

<p>In some instances, it can make sense to generate Terraform code from templates. On my team, there were a few places that we did this, and we checked those generated files in to git as regular <code>*.tf</code> files (their names started with <code>generated.</code> to make it obvious). This can work well, but adds some process overhead (pre-processing, knowing which files to not edit, CI validation that the files haven’t been edited).</p>

<p>There are also some TF preprocessors, like <a href="https://pypi.org/project/terraformpy/">terraformpy</a>, but I haven’t tried any.</p>

<h2 id="type-system-is-too-rigid">Type system is too rigid</h2>

<p>In Terraform before 0.12, everything was a string, and that was ugly (<code>count = "${var.enabled ? 1 : 0}"</code>). Terraform 0.12 added proper booleans, numbers, even some data structures like sets and maps. That was an improvement. However:</p>

<ul>
<li><p>When defining a module’s contract (i.e. specifying the types for its input variables), it’s not currently practical to use <code>map</code> or <code>object</code>.</p>

<p>The <code>map</code> type requires all values in the map to have the same type, which can be useful in a some cases (environment variable values are always strings), but not very often, in my experience.</p>

<p>The <code>object</code> type is a map without that restriction on value types, but if you’re going to say a variable’s type is <code>object</code>, you need to specify all the names of the keys and the types of their values. Okay… that doesn’t sound so bad. And <a href="https://github.com/hashicorp/terraform/issues/19898">all of the keys are mandatory</a>. What!? This makes <code>object</code> useless as a variable type, where you’ll often want to just pass in one value as an override and leave some set of defaults.</p>

<p>If you put these types on your variables, you’ll fail to plan in all sorts of surprising ways. You’ll try to pass <code>alarm_config = { enabled = true, threshold_seconds = 30 }</code> to your <code>map</code> variable and fail to plan because the value types aren’t uniform. So you’ll change it to an object, then realize that you can’t omit the <code>period_seconds</code> parameter which was supposed to optionally merge on top of a default. It’s an uphill battle. These types, in this context, are so rigid that they cause a lot of …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jonathan.bergknoff.com/journal/terraform-pain-points/">https://jonathan.bergknoff.com/journal/terraform-pain-points/</a></em></p>]]>
            </description>
            <link>https://jonathan.bergknoff.com/journal/terraform-pain-points/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828089</guid>
            <pubDate>Tue, 14 Jul 2020 03:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 Explorer – Visual Zilog Z-80 netlist-level simulator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827755">thread link</a>) | @userbinator
<br/>
July 13, 2020 | https://baltazarstudios.com/z80explorer/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p><em>Z80 Explorer</em> is a Zilog Z80 netlist-level simulator capable of running Z80 machine code and also an educational tool with features that help reverse engineer and understand this chip better.</p>
<p>Z80 Explorer is a tool I wished I had a few years ago when I first started looking at the photos of Z80 chip die and was learning to reverse-engineer its <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noreferrer noopener">features</a>. The process was slow and painful as it involved deciphering the faint image traces into logic gates and functions.</p>
<p>Sometimes later, I’ve found that the Visual6502 team have done a wonderful work with mapping the cpu’s traces into bitmaps representing various layers. Their online viewing <a href="http://www.visual6502.org/JSSim/expert-z80.html" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">tool </a>is impressive and one can learn a lot from using it, but as most online tools, it has limitations which I quickly hit when trying to understand the chip behavior in more depth.&nbsp;</p>
<p>As I kept playing with the online tool, my wish list of additional features steadily grew. I would have wanted it not only to be a fully functional and a fast simulator but also to provide more elaborate ways to gain deeper insights into the chip's internal behavior, while also being educational, easy, and intuitive to use.</p>
<p>Fast forward to today, and with the help of repeated COVID-19 stay-at-home orders, I have written this tool to be the way I imagined it.</p>
<figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" alt=""></a><figcaption>Z80 Explorer (click to enlarge)</figcaption></figure>
<p>In this blog, I will give an overview of <em>Z80 Explorer</em>'s capabilities and show a couple of useful features which might be easy to miss even after reading the documentation. This blog may change periodically along with the tool itself as I am actively developing it at the moment (Summer 2020).</p>
<p>The tool's user’s guide is a separate online document located here <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/Z80ExplorerGuide/" target="_blank" rel="noreferrer noopener">https://baltazarstudios.com/Z80ExplorerGuide</a> It is very concise; if something is still unclear, please email me and I will correct it.</p>
<p>The tool is written to load and use the Z80 dataset (layer images and netlist). It should be able to accommodate other NMOS chips with minimal changes. However, at this time I haven't done any other ports yet as I was solely focused on Z80. The chip's data (resources) are kept separate from the application and can be independently downloaded and updated from a shared <a aria-label="undefined (opens in a new tab)" href="https://github.com/gdevic/Z80Explorer_Z80" target="_blank" rel="noreferrer noopener">github repo</a>. In particular, as the functions of various nets is understood and nets and buses get named, the list of the net names, tips and annotations can grow and be shared.</p>
<p><em>Z80 Explorer</em> is capable of running native Z80 code at the netlist level. That means, as the instruction opcodes are fed to its pins, the binary 1s and 0s propagate through its internal nets of transistor gates and perform the function identical to what the silicon gates would do on a real chip.</p>
<p>The engine that runs it is quite fast: On my 4GHz i7-4790K CPU, I am able to run Z80 code at around 2.3kHz which is (only!) around 2000 times slower from the speed it would have run on the real silicon. At those “speeds”, it is not inconceivable to run some of the standard CPU diagnostic programs - so I did just that: I run a well known ZEXALL diagnostic program.&nbsp;</p>
<p>This program normally takes hours even on a real Z80. </p>
<p>After a few days of running within the simulator, the list of passing tests kept growing. At one point, after a week or so, the simulator’s internal cycle counter overflowed its 32-bit variable and the simulation stopped. I simply had to resume it, with no need to reset it and with no loss to the accumulated progress.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-zexall.png" alt=""><figcaption>Z80 Explorer running ZEXALL diagnostic</figcaption></figure></div>
<p>I have added this version of ZEXALL to the app resources. It is modified from the original in that I had sorted the tests by how long they run: with the quickest going first, it does not take too long before you start seeing some results, assuring you that it is indeed running well.</p>
<p><em>Z80 Explorer</em> shows various versions of chip images. Some of them are unmodified resource files shown as layers (diffusion, metal layer etc.), and some are created as combinations of those: vss.vcc.nets.col is a layer with the nets colored such that ground is shown as green, vcc red, and the rest of the nets are colored according to user filters (press F6 to define those filters).</p>
<p>You can view different layers and create combinations of them if you hold down the Ctrl key while clicking on layer buttons, or press a key assigned to each layer while holding down the Ctrl key.</p>
<p>The Z80 chip/layer view can be annotated. The application loads a default annotation file (containing those annotations) when it starts, but you can load any other annotation file by dragging that file and dropping it into the application image view. For example, “annot_internals.json” (located in the resource folder) contains a different set of annotations focused more on the internal features. Annotations are adaptive so that they will show and hide as you zoom in and out. They also can contain current net and bus values which are updated as the simulation modifies them.</p>
<p>Let us examine a few Z80 control / logic signals.</p>
<p>In my older article <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noreferrer noopener">here</a> I looked at the Instruction Register. The signal that enables loading it is a complementary WE (Write Enable) pair of control traces.</p>
<p>Can we find exactly at what time(s) the write enable, now called, "load_ir", is asserted? What is the internal logic equation that governs this control signal?</p>
<p>Using the <em>Z80 Explorer</em>'s "Find" option to search for "load_ir" signal name, and then asking for the schematic of that net, brings up this view:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir1.png" alt=""><figcaption>Schematic view for "load_ir" net</figcaption></figure></div>
<p>Hence, the signal is generated by OR'ing net 255 with a latch. Let's follow net 255 which is a NAND gate of clock (hence, a clock gating) with the net 1329. Selecting (double-clicking on) 1329 and asking for the schematic brings us even closer to what we expected to see:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1329.png" alt=""><figcaption>Schematic view for net 1329</figcaption></figure></div>
<p>Therefore, the net 1329 is a clock-gated, NAND-combined signal, active when M3, T3 and PLA22 are active. PLA22 represents "IX/IY+CB" instruction extension decode. (The description of PLA22 is held in the application "tips" file as are descriptions of all other PLA entries and some other important nets).</p>
<p>Back to the latch 244 - and this part may not too obvious unless you have some experience looking at the chip traces - the net 244 is at the bottom and the latch set and reset signals are at the top, both clock-gated:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-244.png" alt=""><figcaption>Latch at the net 244</figcaption></figure></div>
<p>Asking for the schematic of the net 1306 (the one connected from the top-left), which also acts as the latch reset:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1306.png" alt=""><figcaption>Latch 244 reset</figcaption></figure></div>
<p>we see that the latch will reset on the "internal reset" or a T3 cycle. The latch will be set on an M1 and T2 cycle edge (so it will show at M1/T3):</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1307.png" alt=""><figcaption>Latch 244 set</figcaption></figure></div>
<p>We can verify what we've found by running a hand-crafted test code. I used a template test program "test_blank.asm" to code in a couple of instructions, one of them using IX register, and then I run it for a couple of cycles. In a Waveform view window the result shows how the load_ir signal is being asserted at every M1/T3 as well as at M3/T3, when the instruction is using the IX/IY prefix (PLA22 active).</p>
<div><figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" alt=""></a><figcaption>Waveform diagram showing "load_ir" signal (click to enlarge)</figcaption></figure></div>
<p>Next, let's look at some other features of <em>Z80 Explorer</em>.</p>
<p>Load the "annot_internals.json" file by dropping it onto on the application's image view (the main pane).</p>
<p>You can zoom into the area where are all M and T latches located by pasting this command into the Command Window:&nbsp;</p>
<p><code>img.setZoom(0.98); img.setPos(1151,901)</code></p>
<p>On the startup, the app will try to detect latches, and it will detect most of them automatically. For those not detected, you can add them as you find them. The easiest way to find latches is by using the “Driven by” option. After selecting a net and following its signal chain, if you see two nets being driven by each other in a co-dependent loop, you have found a latch that consists of those two nets (they also act as inverters). One of the app's initialization files, "latches.ini" contains definitions of additional latches. You can add to that file as you find latches that the app did not detect.</p>
<p>Schematic view uses an expanded version of such “Driven by” algorithm to build a tree of gates that contribute to the selected net.</p>
<p>Going the other way, the “Driving nets” option assists you to trace an input net as it branches into the network. For example, pick the /RESET input pad and iterate “Driving nets”, following the highlighted lines. Soon, you should reach a “dead end”, with the nets which apparently nothing is driving, here:</p>
<p><code>img.setZoom(2.926); img.setPos(338,606); img.show(294,548,80,101)</code></p>
<p>About these commands: In order to create these zoom and position commands yourself, set up a desired view and then type “img.state()” in the Command window. The required lines will be printed in the Application Log window.</p>
<p>To obtain the coordinates used in the img.show() command, right-click and select an area you wanted to highlight, and then simply read the coordinates from the Log window and paste them into img.show() as arguments.</p>
<p>The particular network mentioned above contains reset input flops and latches. One of the control signals coming out of it is “int_reset”, or internal reset:</p>
<p><code>img.find("int_reset")</code></p>
<p>This signal branches off to different parts of the chip.&nbsp;</p>
<p>Every chip normally has several signals that are propagated across its die to literally every corner. Some of those networks are power, ground, reset and the clocking network. (Newer chips implement various “gating” to parts of the design to limit the power consumption, but Z80 does not do such thing.)&nbsp;</p>
<p>I have already mention the Waveform view. This view should be familiar to anyone who has worked with simulation tools like ModelSim; but even for the rest, it should still be very simple and intuitive to use.</p>
<p>The important thing to remember is to “name” the net that you wish to observe, if it hasn't been named yet, before you can add it to the waveform view. Double click on the net and select “Edit net name...”. You can type any name; a simple "n123" (where 123 was its net number) would suffice, especially if that is only a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80explorer/">https://baltazarstudios.com/z80explorer/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827755</guid>
            <pubDate>Tue, 14 Jul 2020 02:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strange public IPv4 address assigned behind NAT (2019)]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23827521">thread link</a>) | @rohan1024
<br/>
July 13, 2020 | https://broadbandforum.co/t/190267/ | <a href="https://web.archive.org/web/*/https://broadbandforum.co/t/190267/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://broadbandforum.co/t/190267/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827521</guid>
            <pubDate>Tue, 14 Jul 2020 01:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jonathan Blow: Video Games and the Future of Education]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827489">thread link</a>) | @doppp
<br/>
July 13, 2020 | https://www.twitch.tv/videos/678729516 | <a href="https://web.archive.org/web/*/https://www.twitch.tv/videos/678729516">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/videos/678729516</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827489</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking with environment variables]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23827486">thread link</a>) | @pentestercrab
<br/>
July 13, 2020 | https://www.elttam.com/blog/env/ | <a href="https://web.archive.org/web/*/https://www.elttam.com/blog/env/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

<p>On a recent project we gained the ability to specify environment variables but not the process that was executed.
We were also unable to control the contents of a file on disk, and bruteforcing process identifiers (PIDs) and file descriptors found no interesting results, eliminating <a href="https://www.elttam.com/blog/goahead/">remote LD_PRELOAD exploitation</a>.
Fortunately, a scripting language interpreter was executed which enabled us to execute arbitrary commands by specifying particular environment variables.
This blog post discusses how arbitrary commands can be executed by a range of scripting language interpreters when supplied with malicious environment variables.</p>



<p>A quick read of the <code>ENVIRONMENT</code> section of the <code>perlrun(1)</code> man page reveals plenty of environment variables worth investigating.
The <code>PERL5OPT</code> environment variable allows specifying command-line options, but is restricted to only accepting the options <code>CDIMTUWdmtw</code>.
This unfortunately means that <code>-e</code>, which allows supplying perl code to run, is out.</p>

<p>All is not lost though, as demonstrated in the <a href="https://github.com/HackerFantastic/exploits/blob/master/cve-2016-1531.sh">exploit</a> for CVE-2016-1531 by <a href="https://twitter.com/hackerfantastic">Hacker Fantastic</a>.
The exploit writes a malicious perl module to <code>/tmp/root.pm</code> and supplies the environment variables <code>PERL5OPT=-Mroot</code> and <code>PERL5LIB=/tmp</code> to achieve arbitrary code execution.
However this was an exploit for a local privilege escalation vulnerability and a generic technique should ideally not require access to the file system. Looking at <a href="https://twitter.com/bl4sty">blasty</a>’s <a href="https://haxx.in/blasty-vs-exim.sh">exploit</a> for the same CVE, the exploit did not require creating a file and used the environment variables <code>PERL5OPT=-d</code> and <code>PERL5DB=system("sh");exit;</code>.
The same environment variables were also used to <a href="https://old.reddit.com/r/netsec/comments/1dm8fv/hack_this_website_and_win_bitcoins_the_first/c9tm6j4/">solve a CTF challenge</a> in 2013.</p>

<p>One final nicety of a generic technique would be to use a single environment variable instead of two.
<a href="https://twitter.com/justinsteven">@justinsteven</a> found this was possible by leveraging <code>PERL5OPT=-M</code>.
While either <code>-m</code> or <code>-M</code> can be used to load a perl module, the <code>-M</code> option allows adding extra code after the module name.</p>

<h2 id="proof-of-concept">Proof of Concept</h2>

<figure>
  <figcaption>Figure-0: arbitrary code execution achieved using an environment variable against perl running an empty script (/dev/null)</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>--env</span> <span>'PERL5OPT=-Mbase;print(`id`)'</span> perl:5.30.2 perl /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>Reading the <code>ENVIRONMENT VARIABLES</code> section of the <code>python(1)</code> man page, <code>PYTHONSTARTUP</code> initially appears like it may be a piece of a straightforward solution.
It allows specifying a path to a Python script that will be executed prior to displaying the prompt in interactive mode.
The interactive mode requirement didn’t seem like it would be an issue as the <code>PYTHONINSPECT</code> environment variable can be used to enter interactive mode, the same as specifying <code>-i</code> on the command line.
However, the documentation for the <code>-i</code> option explains that <code>PYTHONSTARTUP</code> will not be used when python is started with a script to execute.
This means that <code>PYTHONSTARTUP</code> and <code>PYTHONINSPECT</code> cannot be combined and <code>PYTHONSTARTUP</code> only has an effect when the python REPL is immediately launched.
This ultimately means that <code>PYTHONSTARTUP</code> is not viable as it has no effect when executing a regular Python script.</p>

<p>Other environment variables which looked promising were <code>PYTHONHOME</code> and <code>PYTHONPATH</code>. Both of these will let you gain arbitrary code execution but require you to also be able to create directories and files on the filesystem. It may be possible to loosen those requirements through the use of the proc filesystem and/or ZIP files.</p>

<p>The majority of the remaining environment variables are simply checked if they contain a non-empty string, and if so, toggle a generally benign setting. One of the rare exceptions to this is <code>PYTHONWARNINGS</code>.</p>

<h2 id="making-progress-with-pythonwarnings">Making progress with PYTHONWARNINGS</h2>
<p>The documentation for <code>PYTHONWARNINGS</code> states <code>it is equivalent to specifying the -W option</code>. The <code>-W</code> option is used for warning control to specify which warnings and how often they are printed. The full form of argument is <code>action:message:category:module:line</code>. While warning control didn’t seem like a promising lead, that quickly changed after checking the implementation.</p>

<figure>
  <figcaption>Figure-1: Python-3.8.2/Lib/warnings.py</figcaption>

<figure><pre><code data-lang="python"><span>[...]</span>
<span>def</span> <span>_getcategory</span><span>(</span><span>category</span><span>):</span>
    <span>if</span> <span>not</span> <span>category</span><span>:</span>
        <span>return</span> <span>Warning</span>
    <span>if</span> <span>'.'</span> <span>not</span> <span>in</span> <span>category</span><span>:</span>
        <span>import</span> <span>builtins</span> <span>as</span> <span>m</span>
        <span>klass</span> <span>=</span> <span>category</span>
    <span>else</span><span>:</span>
        <span>module</span><span>,</span> <span>_</span><span>,</span> <span>klass</span> <span>=</span> <span>category</span><span>.</span><span>rpartition</span><span>(</span><span>'.'</span><span>)</span>
        <span>try</span><span>:</span>
            <span>m</span> <span>=</span> <span>__import__</span><span>(</span><span>module</span><span>,</span> <span>None</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>klass</span><span>])</span>
        <span>except</span> <span>ImportError</span><span>:</span>
            <span>raise</span> <span>_OptionError</span><span>(</span><span>"invalid module name: %r"</span> <span>%</span> <span>(</span><span>module</span><span>,))</span> <span>from</span> <span>None</span>
<span>[...]</span></code></pre></figure>

</figure>

<p>The above code shows that as long as our specified category contains a dot, we can trigger the import an arbitrary Python module.</p>

<p>The next problem is that the vast majority of modules from Python’s standard library run very little code when imported. They tend to just define classes to be used later, and even when they provide code to run, the code is typically <a href="https://docs.python.org/3/library/__main__.html">guarded with a check of the <code>__main__</code> variable</a> (to detect if the file has been imported or run directly).</p>

<p>An unexpected exception to this is the <a href="https://xkcd.com/353/">antigravity module</a>. The Python developers included an <a href="https://en.wikipedia.org/wiki/Easter_egg_(media)">easter egg</a> in <a href="https://github.com/python/cpython/commit/206e3074d34aeb5a4d0c1e24d970b6569f7ad702">2008</a> which can be triggered by running <code>import antigravity</code>. This import will immediately open your browser to the xkcd comic that joked that <code>import antigravity</code> in Python would grant you the ability to fly.</p>

<p>As for how the <code>antigravity</code> module opens your browser, it uses another module from the standard library called <code>webbrowser</code>. This module checks your PATH for a large variety of browsers, including mosaic, opera, skipstone, konqueror, chrome, chromium, firefox, links, elinks and lynx. It also accepts an environment variable <code>BROWSER</code> that lets you specify which process should be executed. It is not possible to supply arguments to the process in the environment variable and the xkcd comic URL is the one hard-coded argument for the command.</p>

<p>The ability to turn this into arbitrary code execution depends on what other executables are available on the system.</p>

<h2 id="leveraging-perl-for-arbitrary-code-execution">Leveraging Perl for Arbitrary Code Execution</h2>

<p>One approach is to leverage Perl which is commonly installed on systems and is even available in the standard Python docker image. However, the <code>perl</code> binary cannot itself be used. This is because the first and only argument is the xkcd comic URL. The comic URL argument will cause an error and the process to exit without the <code>PERL5OPT</code> environment variable being used.</p>

<figure>
  <figcaption>Figure-2: PERL5OPT having no effect when a URL is passed to perl</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perl https://xkcd.com/353/
<span>Can't open perl script "https://xkcd.com/353/": No such file or directory</span></code></pre></figure>

</figure>

<p>Fortunately, when Perl is available it also common to have the default Perl scripts available, such as perldoc and perlthanks. These scripts will also error and exit with an invalid argument, but the error in this case happens later than the processing of the <code>PERL5OPT</code> environment variable. This means you can leverage the Perl environment variable payload detailed earlier in this blog post.</p>

<figure>
  <figcaption>Figure-3: PERL5OPT working as intended with perldoc and perlthanks</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perldoc https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)
</span><span>$</span><span> </span>run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perlthanks https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>

<h2 id="proof-of-concept-1">Proof of Concept</h2>

<figure>
  <figcaption>Figure-4: arbitrary code execution achieved using multiple environment variables against Python 2 and Python 3</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:2.7.18 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'

</span><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:3.8.2 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'</span></code></pre></figure>

</figure>



<p>A <a href="https://research.securitum.com/prototype-pollution-rce-kibana-cve-2019-7609/">blog post</a> by <a href="https://twitter.com/securitymb">Michał Bentkowski</a> provided a payload for exploiting Kibana (CVE-2019-7609). A prototype pollution vulnerability was used to set arbitrary environment variables which resulted in arbitrary command execution. Michał’s payload used the <code>NODE_OPTIONS</code> environment variable and the <a href="https://en.wikipedia.org/wiki/Procfs">proc filesystem</a>, specifically <code>/proc/self/environ</code>.</p>

<p>Although Michał’s technique was creative and worked perfectly for their vulnerability, the technique is not always guaranteed to work and has some constraints that would be nice to remove.</p>

<p>The first constraint is that it using <code>/proc/self/environ</code> is only viable if the contents can be made to be syntactically valid JavaScript. This requires being able to create an environment variable and have it appear first in the contents of <code>/proc/self/environ</code>, or knowing/bruteforcing the environment variable’s name that will appear first and overwriting it’s value.</p>

<p>Another constraint, as the first environment variable’s value finishes with a single line comment (<code>//</code>). Therefore, any newline character in other environment variables will likely cause a syntax error and prevent the payload from executing. The use of multi-line comments (<code>/*</code>) will not fix this issue as they must be closed to be syntactically valid. Therefore, in the rare case that an environment variable contains a newline character, it is required to know/bruteforce the environment variable’s name and overwrite it’s value to a new value that does not contain a newline.</p>

<p>Removing these contraints is an exercise left for the reader.</p>

<h2 id="proof-of-concept-2">Proof of Concept</h2>

<figure>
  <figcaption>Figure-5: achieving arbitrary code execution with environment variables against NodeJS by Michał Bentkowski</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'NODE_VERSION=console.log(require("child_process").execSync("id").toString());//'</span> <span>-e</span> <span>'NODE_OPTIONS=--require /proc/self/environ'</span> node:14.2.0 node /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>If you run <code>ltrace -e getenv php /dev/null</code> you will find PHP uses the <code>PHPRC</code> environment variable.
The environment variable is used …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elttam.com/blog/env/">https://www.elttam.com/blog/env/</a></em></p>]]>
            </description>
            <link>https://www.elttam.com/blog/env/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827486</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is QuantGov?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827427">thread link</a>) | @hhs
<br/>
July 13, 2020 | https://www.quantgov.org/about | <a href="https://web.archive.org/web/*/https://www.quantgov.org/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.quantgov.org/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827427</guid>
            <pubDate>Tue, 14 Jul 2020 00:55:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alex: An Updatable Adaptive Learned Index [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827257">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf | <a href="https://web.archive.org/web/*/https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jiayuasu.github.io/files/paper/alex-sigmod2020.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827257</guid>
            <pubDate>Tue, 14 Jul 2020 00:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond Analytics: The Evolution of Stream Processing Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23827170">thread link</a>) | @guodong
<br/>
July 13, 2020 | https://streaming-research.github.io/Tutorial-SIGMOD-2020/ | <a href="https://web.archive.org/web/*/https://streaming-research.github.io/Tutorial-SIGMOD-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <h2 id="tutorial-information">Tutorial Information</h2>
<h3 id="wednesday-june-17-2020">Wednesday, June 17 2020</h3>
<h4 id="join-us-on-zoom-and-slack">Join us on <a href="https://acm-org.zoom.us/j/93450885761?pwd=OGZmekwyRFR2Q3ZTd3VwL3hsc0JlUT09">Zoom</a> and <a href="https://join.slack.com/t/sigmodpods/shared_invite/zt-em1btw2v-tTI9OXRtzi4apsMaCoqjTA">Slack</a></h4>

<h4 id="session-1-1030-am---1200-pm-pdt">Session 1: 10:30 AM - 12:00 PM PDT</h4>
<ul>
  <li>Part I: Introduction &amp; Fundamentals</li>
  <li>Part II: Time, Order, &amp; Progress</li>
  <li>Part III: State Management</li>
</ul>

<h4 id="session-2-130-pm---300-pm-pdt">Session 2: 1:30 PM - 3:00 PM PDT</h4>
<ul>
  <li>Part IV: Fault Recovery &amp; High Availability</li>
  <li>Part V: Load Management &amp; Elasticity</li>
  <li>Part VI: Prospects</li>
</ul>

<h2 id="overview">Overview</h2>
<p>Stream processing has been an active research field for more than 20 years, but it is now witnessing its prime time due to recent successful efforts by the research community and numerous worldwide open-source communities. The goal of this tutorial is threefold. First, we aim to review and highlight noteworthy past research findings, which were largely ignored until very recently. Second, we intend to underline the differences between early (’00-’10) and modern (’11-’18) streaming systems, and how those systems have evolved through the years. Most importantly, we wish to turn the attention of the database community to recent trends: streaming systems are no longer used only for classic stream processing workloads, namely window aggregates and joins. Instead, modern streaming systems are being increasingly used to deploy general event-driven applications in a scalable fashion, challenging the design decisions, architecture and intended use of existing stream processing systems.</p>

<h2 id="presenters">Presenters</h2>

<ul>
  <li><a href="https://www.ri.se/en/paris-carbone">Paris Carbone</a> (RISE)</li>
  <li><a href="http://mariosfragkoulis.gr/">Marios Fragkoulis</a> (Delft University of Technology)</li>
  <li><a href="https://cs-people.bu.edu/vkalavri/">Vasiliki Kalavri</a> (Boston University)</li>
  <li><a href="http://asterios.katsifodimos.com/">Asterios Katsifodimos</a> (Delft University of Technology)</li>
</ul>

<h2 id="slides-and-videos">Slides and Videos</h2>

<ol>
  <li>Introduction and fundamentals <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part1-introduction.pdf">[Slides]</a> <a href="https://youtu.be/6qmwLKzXdgM">[Video]</a></li>
  <li>Time, order, and progress <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part2-time.pdf">[Slides]</a> <a href="https://youtu.be/sWcMx52eP58">[Video]</a></li>
  <li>State management and guarantees <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part3-state-management.pdf">[Slides]</a> <a href="https://youtu.be/Zgy5a5tBOco">[Video]</a></li>
  <li>Advanced fault recovery and high availability <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part4-Fault-HA.pdf">[Slides]</a> <a href="https://youtu.be/p3zXV2w_MgM">[Video - Part I]</a> <a href="https://youtu.be/28CRUcFAGPs">[Video - Part II]</a></li>
  <li>Load management and elasticity <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part5-load-management.pdf">[Slides]</a> <a href="https://youtu.be/Pxe0M-mprOM">[Video]</a></li>
  <li>Prospects and discussion <a href="https://github.com/streaming-research/Tutorial-SIGMOD-2020/blob/master/slides/part6-prospects.pdf">[Slides]</a> <a href="https://youtu.be/DW9kU7gCL8A">[Video]</a></li>
</ol>

<h2 id="cite-pdf">Cite (<a href="https://dl.acm.org/doi/abs/10.1145/3318464.3383131">PDF</a>)</h2>

<div><div><pre><code>@inproceedings{10.1145/3318464.3383131,
author = {Carbone, Paris and Fragkoulis, Marios and Kalavri, Vasiliki and Katsifodimos, Asterios},
title = {Beyond Analytics: The Evolution of Stream Processing Systems},
year = {2020},
isbn = {9781450367356},
doi = {10.1145/3318464.3383131},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {2651–2658}
}
</code></pre></div></div>



      </section>
    </div></div>]]>
            </description>
            <link>https://streaming-research.github.io/Tutorial-SIGMOD-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827170</guid>
            <pubDate>Tue, 14 Jul 2020 00:12:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826786">thread link</a>) | @elsewhen
<br/>
July 13, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826786</guid>
            <pubDate>Mon, 13 Jul 2020 23:20:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark (Changelog)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826706">thread link</a>) | @tosh
<br/>
July 13, 2020 | https://darklang.github.io/docs/changelog/#july-13th-2020 | <a href="https://web.archive.org/web/*/https://darklang.github.io/docs/changelog/#july-13th-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://darklang.github.io/docs/changelog/#july-13th-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826706</guid>
            <pubDate>Mon, 13 Jul 2020 23:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defragging Your Brain (2012)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826671">thread link</a>) | @tosh
<br/>
July 13, 2020 | https://www.theslowhunch.net/2012/defragging-your-brain-the-slow-hunch-and-open-commonplace-books/ | <a href="https://web.archive.org/web/*/https://www.theslowhunch.net/2012/defragging-your-brain-the-slow-hunch-and-open-commonplace-books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.theslowhunch.net/2012/defragging-your-brain-the-slow-hunch-and-open-commonplace-books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826671</guid>
            <pubDate>Mon, 13 Jul 2020 23:07:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Platonic solids and fundamental tests of quantum mechanics]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826281">thread link</a>) | @mathgenius
<br/>
July 13, 2020 | https://quantum-journal.org/papers/q-2020-07-09-293/ | <a href="https://web.archive.org/web/*/https://quantum-journal.org/papers/q-2020-07-09-293/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://quantum-journal.org/papers/q-2020-07-09-293/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826281</guid>
            <pubDate>Mon, 13 Jul 2020 22:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What are we weighting for? A mechanistic model for probability weighting]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23826257">thread link</a>) | @vo2maxer
<br/>
July 13, 2020 | http://lml.org.uk/paper-announcement/what-are-we-weighting-for-a-mechanistic-model-for-probability-weighting/ | <a href="https://web.archive.org/web/*/http://lml.org.uk/paper-announcement/what-are-we-weighting-for-a-mechanistic-model-for-probability-weighting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://lml.org.uk/paper-announcement/what-are-we-weighting-for-a-mechanistic-model-for-probability-weighting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826257</guid>
            <pubDate>Mon, 13 Jul 2020 22:24:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Medical Nemesis by Ivan Illitch [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23826220">thread link</a>) | @mimixco
<br/>
July 13, 2020 | https://ratical.org/ratville/AoS/MedicalNemesis.pdf | <a href="https://web.archive.org/web/*/https://ratical.org/ratville/AoS/MedicalNemesis.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div endstream="" endobj="" obj="" type="" page="" parent="" r="" resources="" contents="" mediabox="">&gt;
endobj
6 0 obj
&lt;&lt; /ProcSet [ /PDF /Text /ImageB /ImageC /ImageI ] /ColorSpace &lt;&lt; /Cs1 7 0 R
&gt;&gt; /Font &lt;&lt; /F1.0 8 0 R &gt;&gt; /XObject &lt;&lt; /Im1 9 0 R &gt;&gt; &gt;&gt;
endobj
9 0 obj
&lt;&lt; /Length 10 0 R /Type /XObject /Subtype /Image /Width 52 /Height 36 /ColorSpace
11 0 R /Interpolate true /Intent /Perceptual /BitsPerComponent 8 /Filter /DCTDecode
&gt;&gt;
stream
ÿØÿàJFIFHHÿízPhotoshop 3.08BIMíHH8BIM
x8BIMó8BIM
8BIM'
8BIMô5-8BIM÷ÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿÿè8BIM@@8BIM8BIMt4$œðXÿØÿàJFIFHHÿþ&amp;File written by Adobe Photoshop¨ 5.0ÿîAdobed€ÿÛ„			



ÿÀ$4"ÿÝÿÄ?	
	
3!1AQa"q�2‘¡±B#$RÁb34r‚ÑC%’Sðáñcs5¢²ƒ&amp;D“TdEÂ£t6ÒUâeò³„ÃÓuãóF'”¤…´•ÄÔäô¥µÅÕåõVfv†–¦¶ÆÖæö7GWgw‡—§·Ç×ç÷5!1AQaq"2�‘¡±B#ÁRÑð3$bár‚’CScs4ñ%¢²ƒ&amp;5ÂÒD“T£dEU6teâò³„ÃÓuãóF”¤…´•ÄÔäô¥µÅÕåõVfv†–¦¶ÆÖæö'7GWgw‡—§·ÇÿÚ?õT’Uz–S10®¹ö¶˜i±ÜìIIm„Å5ïþSŽÖþG;þ‚VÆÉ±€0k¹®ÝømjÅ£+2ömÃÏa¢¿gÚ_é�B�Ùy˜ƒÔ~srqû¹‚¡gÝôS¸’Îè™”dã=”Þ/&lt;°;¾ÑôŠJRI$’ŸÿÐõUS©ÖË16½»Ç©VŸõÆ+k;?§Û™`6»)gÑcÜñ¯‹¶$§‡Å²�QïúxŸÿ†Tð_cß‹ê=ÿ¤³Õ÷ÿÂä®§ö¿î6þ	ýê°Yÿq±ðOïIL&gt;§€zKl:Øó6;Ä­Õ“�ÒnÆ½—c¶ªu‹C]aÜÏí~rÖIJI$’SÿÑõT—Ê©$§ê¤—Ê©$§ê¤—Ê©$§ê¤—Ê©$§ÿÙ8BIMÿâ&nbsp;ICC_PROFILE�ADBEmntrGRAYXYZ Ó3acspMSFTnoneöÖÓ-ADBEcprtÀ$descäqwtptXbkptlkTRC€text(c) 2003 Adobe Systems Inc.descGrayscale - Gamma 2.2XYZ óQÌXYZ curv3ÿþ&amp;File written by Adobe Photoshop¨ 5.0ÿîAdobed€ÿÛC			
ÿÀ$4ÿÝÿÄ¢	
3!1AQa"q�2‘¡±B#$RÁb34r‚ÑC%’Sðáñcs5¢²ƒ&amp;D“TdEÂ£t6ÒUâeò³„ÃÓuãóF'”¤…´•ÄÔäô¥µÅÕåõVfv†–¦¶ÆÖæö7GWgw‡—§·Ç×ç÷ÿÚ?õT�_m„Å5ïþSŽÖþG;þ‚VÆÉ±€0k¹®Ýømj*I/ÿÐõUW©e3
ëŸki†�ËÀqÅ•FVeìÛ‡žÃE~Ï´¿Ó:…;²ó1¨üæäã÷sBÏ»è+}2Œœg²›Åâ‡–wÚ&gt;‚ÑIÿÑõUS©ÖË16½»Ç©VŸõÆ.þÊ=G¿éà~þSÁ}�~/¨÷þ’ÌWßÿ’ºŸ©à’Û¶&lt;ÍŽñ+u%ÿÒõU�ŸÓíÌ°]”³è±îx×ÅÛ?Ø.ÿ¸Øø'÷©þÁgýÆÅÿÁ?½¤Ý�{.ÇmTë†ºÃ¹ŸÚüå¬’ÿÓõT’I$’_ÿÙ
endstream
endobj
10 0 obj
2161
endobj
12 0 obj
&lt;&lt; /Length 13 0 R /N 1 /Alternate /DeviceGray /Filter /FlateDecode &gt;&gt;
stream
xc``œàèâäÊ$ÀÀ�›WRää¥ÀÀÁ~™����AŽÁ81¹¸À7Ø-„òòóRA4*øv��$rYdªAkrAQ	PÕ VII-NÒO€¸°¼¤(Îd‹$eƒÙ9 vvH�3P¼Èæ+I­éeÐHÖT0200VpLÉOJU®,.IÍ-VðÌKÖc€š	R&amp;æ^”XYœœ˜“ª&nbsp;«àž˜››¨`¤g’¡2‡!ØÌÏ�à°a;ƒCX–\ZTå1230\U4
endstream
endobj
13 0 obj
213
endobj
11 0 obj
[ /ICCBased 12 0 R ]
endobj
14 0 obj
&lt;&lt; /Length 15 0 R /N 1 /Alternate /DeviceGray /Filter /FlateDecode &gt;&gt;
stream
x…ROHQþÍ6„ˆA…xˆw
	•)¬¬&nbsp;ÚvuY•m[•Ò¢gßº£³3Ó›Ù5Å“]¢<u¢ctìÐ¡›—¢À¬k× ©="" <uèûÍìê(„oy;ßûýý~ß{dm�¦ï;)atsc•+¥§nnm‹ƒ)eÔnx¦øébqŒ±ë¹’¿»×ÖgÒØ²ÞÇµvûö="µ•e`!ê-¶·ú!‘f�™Ÿ(e€³À–¯Ø"><x¬ð#¢š¹0ÓÑœt¥²-‘sæ¢(*¯b;i®ûù¹Æ¾‹µ‰ƒþ\�fÖŽ½³êªÑlÔ´÷d¡¼®dÏ_töl5§ ãœhc)ò®Õß+lÇ‘+jr5d¹Ÿjn�uàu»]º“ãøö¥="">É`¨‰µé²™…}v*Ëìðèñ²bç�{aÿ[QÃ“À'a?d‡yÖ­ö®Sà{„=5àÎ®ÅñÚŠ^-C÷T#hŒsMÄÓ×9s¤ˆï1Ô˜÷F9¦1w–ª7€;aYªf
±]û®ê%î{wÓã;Ñ›9\&nbsp;Ir±ÙÐ&lt;	X}‹°I&lt;&gt;ÎUàw¨˜À¹‰ÜÍ(÷Õg£R�Vz�WÆOã¹ñÅøelÏ€~¬v×{|ÿéãu×¶&gt;&lt;ù�zÜ9®½�UaVqeÝÿÇ2„�Ù'9¦ÁÓ¡YXkØväšÌL°(Ä&gt;—ú’UÜÕîí¸EÌP&gt;,l%ºKTn)Ôê=ƒJ¬+Øvp’Ä,Z¸Skº9xwØ"zmùMW²ë†þúözûÚòmÊ¨)(Í³Df”±[£äÝxÛýf‘Ÿ8:¾ç½ŠZÉþIE?…9Z*òUôVPÖÄog~¶~\?¥çõAý&lt;	=­ŸÑ¯è£¾tIÏÂsQ£Ið°i!â&nbsp;Šƒ3ÔNTc�â)ñò´[d‘ý@ýf
endstream
endobj
15 0 obj
704
endobj
7 0 obj
[ /ICCBased 14 0 R ]
endobj
17 0 obj
&lt;&lt; /Length 18 0 R /Filter /FlateDecode &gt;&gt;
stream
x�UËrÚ0Ýç+îª“Ì€‚åww@Ò–’æA'‹�…0«‘-ŸÔÏéõÚ!!1n›Ø²¸÷œsÏ‘à&nbsp;ƒß0
!	(7&nbsp;à¸o=È,x`³êóYÍÂn{ÀÝE©vñSÔÊÐ�çoW}#¥4¥¸ÂhÇŸ&lt;ÒÁ�fpØ×Ë�óÜý/�#˜làŠ©©^À½²¼•‘£ƒÑw8•¨ë›EÛfÐ4 ßKêšÁŒ¾ü³Pê(®¢îJ	%j‹ÊYnÖ|
+5åá:nsB+&amp;™ÀSíî‚‘1ÏtñJ­¹*öYÿ'X‡+¡U\«‰6G4B�Ë9|SÂáÝµcŽÛB\DƒëZAOë{ÛS±a€žU¤o†*ÝS«aÎù�'æžÀWÔN&nbsp;&gt;rË—ˆ?ÎôŒpñ#Ú&gt;“…¨í†„;tS,Õõöäjtš"»©”&amp;‹Îƒ5Nk ¥Èò7Ø¯f:4ð«ÓŠ‰afS�ÓŸ£s,2tLjTc^Œ¬œ_VºNðI3¢qPíüHÃ„¬Z45«Œ®ä¶Ÿ3&gt;EƒKP|Á­°oÐlÙçóÁ÷ðPx}&gt;&lt;–Ú8%I�z1ÔTC'ÊÕ´H‚À&nbsp;è¹aË¼„møŒ®2|TdV`–ò¦Áôé^ždò\ëL&nbsp;P‹B0¡8J&nbsp;To~_äBj«—ùæ=”wâñ[ÐßVÇ–3Ø.  ™3zÎ•È0ý–3[P	'qÇíÉùðì# Öf Â=ú'\Š5´~Î™tùr?u8ŒöÖAñ&gt;À7ª&amp;„~¼§Òß‰ü¢kˆëZ
‡XD5cj¦E²§ÅMüŽGÓEùÂcw�ê�=b·WÝÀKÈ ¼4¡wOŽð#J¼Ýmy•Ðv§!mÖÃUqÙàºw�¶ŸíØ£AØa|¸œÜ“ñÑ«ÎÝnÿªaÓ ©6=cj5c™[™¿½ðð¤Ý¾zwD/ÿ4Õ;0
endstream
endobj
18 0 obj
753
endobj
16 0 obj
&lt;&lt; /Type /Page /Parent 3 0 R /Resources 19 0 R /Contents 17 0 R /MediaBox
[0 0 595 842] &gt;&gt;
endobj
19 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs1 7 0 R &gt;&gt; /Font &lt;&lt; /F1.0 8 0 R
&gt;&gt; &gt;&gt;
endobj
21 0 obj
&lt;&lt; /Length 22 0 R /Filter /FlateDecode &gt;&gt;
stream
x¥VËn›@Ýû+î®Í"†UÕØ‰d©–Üš¶ëœIa&amp;apªö/ûG½˜Ç¸ÙÅ¤ßsçœË3|†gpñGc
, P
ø
næÆƒÔ€&amp;&gt;ÏFføÚ3¾]‡º®ou¬´€ÛHÐœâ�†N“˜€ÇH
¸¹'Ž‹ÿJ2x?×ªª2W³äîLsê0¦ã²�DÅÈNìRÆ0Ø4¢ç7ˆxïIèÎˆKU•z»O+©Õ¡*wO°€YŸD
€×—´þø%�¥ó\*™òrŽˆ;¡„‘æÄ®N,/t×‰†za‹¡‡¤i¨E÷HÜ=É­($öQg°Ò[Q*X‰­L¥¶×®±Ø
	…ŸMßç›©¾oæc“žõ�öCß	¼0†|ýY›f²Ó=ž5´­’!WjÚØ*¡¾l/‡ì‚YFDÔ‰YÅàwÁ,:­tiÞÁ]–	äÅK=*ó‡+XæùÞÔ&lt;éÙ9DjÙ&gt;Æ=?Ž†l?¤
ðÕˆš� A’Rðª@\„x-	lE-NSØõRe¹L+±…¥zÜ—R©íŒz2UÏBdBµ5­y%kAÃ9µxqìøñ&nbsp;Ç°£öÉÛ‘F„ÄlHšF˜¨Ì�NåP—ý„�üÇêò”+Œè’úþÐH£Ëƒy.c›´ªÅùIfbšÉÈ/«1ê�Æe�Æú³ÿÓ¥¯œ¤%Ñtn¯UÆ|'rEËïÂYN®u.«ƒ&amp;%W¦�¦VVÝ�eã�E
i7G5EÏ±žGã.Ñ–�vÑ�x*ªµÏCk$¸ÌhÕr’=o‡î“²)=õ)Co+­ô“Î�UEºSÓµPç¶÷…&gt;°mÏ7žïÅõ})Ì÷¥øpaÆ^Ûk]ªç$Ê&lt;'ŠÃD»x6ÑzM¾–c…§·ûíN\fÆ¡?eÆ‡µ¼~àeÁS±o”°T/üâý“üYH¾SÚ ,‹'Q¢ÛISœÓ8K�îÃ6®Äº¸*ë}	›Jî
~@4YF"ÊB*tê¹(E¡Õ¥›¿&gt;'61Üæ&lt;ý+¾“éEÙGîdöëfbðG]¢õ¯ÝÏh¯¥
endstream
endobj
22 0 obj
823
endobj
20 0 obj
&lt;&lt; /Type /Page /Parent 3 0 R /Resources 23 0 R /Contents 21 0 R /MediaBox
[0 0 595 842] /Annots 26 0 R &gt;&gt;
endobj
23 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs4 25 0 R /Cs1 7 0 R &gt;&gt; /Font
&lt;&lt; /F1.0 8 0 R /F2.0 24 0 R &gt;&gt; &gt;&gt;
endobj
26 0 obj
[ 27 0 R 28 0 R 29 0 R 30 0 R ]
endobj
31 0 obj
&lt;&lt; /Length 32 0 R /N 3 /Alternate /DeviceRGB /Filter /FlateDecode &gt;&gt;
stream
x…”MHaÇÿ³�±Ñ—ÅÐÁ$T&amp;RÓõ+S¶eÕL	b�}w�g§™Ý-E"„è˜uŒ.VD‡ˆNá¡C§:D™u‰&nbsp;£E^"¶ÿ;“»cT¾03¿yžÿû|½ÃU�RŽcE4`ÊÎ»ÉÞ˜vztLÛüU¨F\)Ãs:‰Ÿ©•Ïõkõ-iYj”±Öû6|«v™P4*wd&gt;,y&lt;àã’/ä�&lt;5g$©4Ù!7¸CÉNò-òÖlˆÇCœžTµS“3—q";È-E#+c&gt; ëvÚ´Éï¥=íSÔ°ßÈ79Ú¸òý@Û`Ó‹ŠmÌÜv×Ulõ5ÀÎ`ñPÅö=éÏGÙõÊËjöÃ)ÑkúP*}¯6ß~^/•~Ü.•~ÞaÖñÔ2
nÑ×²0å%Ôìfüäý‹ƒž|U°À9Žlú¯7?ûÛ‰j`¨‘Ël7¸òâ"çtæœi×ÌNäµf]?¢uðh…ÖgM
ZÊ²4ßåi®ð„[é&amp;LYÎÙ_Ûx�
{x�Oö¹$¼îß¬Ì¥S]œ%šØÖ§´èê&amp;7�ïgÌž&gt;r=¯÷·g8`å€™ï
8rÊ¶â&lt;©‰ÔØãñ“dÆWT'“ó�&lt;çeLß~.u"A®¥=9™ë—š]ÜÛ&gt;31Ä3’¬X3�ñßüÆ-$eÞ}ÔÜu,ÿ›gm‘g…6ï64$Ñ‹áÀEzL*LZ¥_ÐjÂÃä_•å]½XážÏy¸[Æ?…Xs
åšþNÿ¢/ëú]ýó|m¡¾â™sÏšÆ«k_Wf–ÕÈ¸A�2¾¬)ˆo°Úz-di�âôä•õ�áê2ö|mÙ£Éâj|5Ô¥ejÄ8ãÉ®e÷E²Å7áç[Ëö¯éQû|öIM%×²ºxf)ú|6\
kÿ³«`Ò²«ðä��.<k¡îuª}j‹Ú m="¦¶«mjßŽªåÃœ•‰¬Ûeõ)ö`cšÞÊIWf‹àßÂ/†ÿ¥^a×44ùM¸¹Œi" ßÜ6p‡”ÿÃ_³="" Þ="" endstream="" endobj="" 32="" 0="" obj="" 792="" 25="" [="" iccbased="" 31="" r="" ]="" 34="" <<="" length="" 35="" filter="" flatedecode="">&gt;
stream
x¥WËrÛ8¼ó+æ¸9,C‚àëèÐN­*q"[Jr†IHÆ1J9¹´dš”¬]çà2ìL÷ôLÏŒžàžÀÁ~ìCD	Ô~@	ï“Æ…´štúûÝÌƒ…ö„-Cý)¿ÉXi¶àFê5?°ƒ˜ÄB
ÛÞtmÿÓv¬¯î·°Z­lHº¼íj–CÎÚºÚó’7¢ygmÿ†›-ÒEfT2“HŽ8ý—d¹ï)xÏÀ»N`õøDã¯JËº´UùF0	{¡ïÀ¯8ÙL€7‰5¬3E(;¦4€\Ï±#åÐo9lú¼ÔÍRºŠxpDœ:Sá&lt;¶�&gt;‰&lt;åª¬™S°îP£0Š�€ø˜‚TÌ‰R!íØñ£ˆPØ$³â™¨kS7ˆ­ˆãÛ„†¸ê
æsk?—CècÖqñé�Ãª&lt;ðRX™ÁM.
Q²þgÌêZ4œ5ÜÔf*»”ÍPƒž2Êî‘í‚”Ç·‹)êýbúÕ·áš³ö®ö(wÓ?-³“‚Œì,BÉÈŽ¸qï	Ðo»Ñ€Î©ÖžQ—Î”*ô_§©IŸ£„±ÑØ
AG3F²f
$UQT™hŸ/‰<j�$|eÁ�'ôí|Í•¬<Ž�kv¦\öu‹mŽèÙ2Þè“‰Á‹ÕÈ1™¼ÀceÃá–¥ì¡î{Ìê‡Í´Çn´µ‡úmfš^�®¥h†®^g3t?t]½ç•ht«]v«à‘x iÂŽ*$8="">D*õ–mmæíyÒ&amp;:]Ö¸f‡o¥4w’3Q4ÐVÀàfýÿõSZõ[™ñp¾ó²	Ã
Ÿofiy¸"'¶Ö÷a|­«\´Wöê_œåÇ*^¼µf¬M½WÖlØüä©Ø‰ýØaŽõOµÆçœiéºQo˜ï8,Ñ–¶GüôÛÆÑh»9Î�ÒÌ4\hÏÊrê–0!Q·!ÌpV•ÀfV¢¸:ºš�sm}RoâGÃ|¦�z3‚Xýrâô˜c½:}”Ï÷¤™ql‡NäS&nbsp;c8£oR•MW`Ë¯ëªåýA»ª†«,i{F‚É5öuw˜qnÀÍS‡B_¥)ozSo«ú¿¢¸¯šE£¬»‡¼ory§åè±f(7f¹CäaWÜ²�`—©Kî{ËÊûj“
y›H£}­÷¬¿ûËä,\¦¶ëàõ£±LÇþ#=qzç˜ê“ÐŽ0È”gÏg±{Ã€3áŒtYÿ›r/JÎkycÊnb°ÎYƒã~TÅƒ‘aÖÑÞ0~Oo˜h±÷&lt;•…&gt;±úVŸsô8â,?rôÅå©‹K¿G,Þäè14~rŠ¦lGGŸäöÒj‘§­Ã™š®Ê¬kÚZ°\üæ|áEÿ‘è‚èšlàÒ�¬‰®-ö±®
Ü“�XäanŸñºÅ%}Ï\1í®Ë¥×Ržá U?^Ì©þ23ƒ½||ô7ß½Ø?¶qº<!--ÁX-->ATXÀÓ•ÁwQ·Ý‘Kîþ›âuX
endstream
endobj
35 0 obj
1138
endobj
33 0 obj
&lt;&lt; /Type /Page /Parent 3 0 R /Resources 36 0 R /Contents 34 0 R /MediaBox
[0 0 595 842] /Annots 37 0 R &gt;&gt;
endobj
36 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs4 25 0 R /Cs1 7 0 R &gt;&gt; /Font
&lt;&lt; /F1.0 8 0 R /F2.0 24 0 R &gt;&gt; &gt;&gt;
endobj
37 0 obj
[ 38 0 R 39 0 R 40 0 R 41 0 R 42 0 R 43 0 R 44 0 R 45 0 R 46 0 R 47 0 R 48 0 R
49 0 R 50 0 R 51 0 R ]
endobj
53 0 obj
&lt;&lt; /Length 54 0 R /Filter /FlateDecode &gt;&gt;
stream
x¥X]�ÛÈ|×¯è·Ø€–'~Iü8±8À1°Á=y‘Cqbr†æ�«ègæ¥zHJZRÝòlÃ»+­†=ÕÕÕÕý“¾ÓOÚào¼�)‰j$ýFš~ù«õ)µä“M§ïçw^Xá×~â·ù¨'þÂg¥ýå™‚}ÿ*¾Æ[o»öÞ¥çŠ~ù›ïmð¡çœ&gt;øéù?ôõ™¾¯Þ:g8=ð¯çøA&lt;=è¹�ôµV™¬Tj?®†CßîÞ¡ÛÙ¡&amp;§_M&amp;M¿ÊL¥JË‡'ûáFxî&gt;™†K|ïßû­ïÌ	€Dô¥k”&gt;Rja[|ÓHIG©e#Ze´uoeÊJa¥%‘ç¥J[þÈoÒ¶|;kR%[…7ñ"iÑ%ƒh–ÜN»£Ñ’²FTˆ%¥´ú(­÷ð&nbsp;ÿÙõh^~
‚­·Ùú&gt;ÑÆÛG!?suŸP¿Ø H¼}ïpÚ5øUÏLú‡)•YS¦êÐ6J¬IèŒÚî ›´+�UÀuó"´²àüä’êÈ&lt;{öª/Š»I�gIeÈlaZ…Æ¿V”aüLÞJMi× Wµ–]e´d²çºP¥²Ÿ\�ÖP%ôÿY»0�»+"C­þPe)›�#©©$¹SjtÛ˜, ßÉ&lt;µ…j2ë‚/KÊ¤h‹*mN„ˆÀ6ÑÊla`É®Ñ‡“j‹×,r¦ÌH¥GÏ…±’N…A2%�Mêsæ*ƒÿzD»&amp;
Ä_¸4*þã
4û€œþ›žÿ~?«ƒÔÝËj¸¹ÅoÅZ'Òú¤[»ÆSL)u*×.u¤%“ÞE
gìžs©'·—Ÿ‚pãùqR¸ékb5ÑˆàáÉwo²¾*.ˆ
tXeLJS!E	ðm+Ú®Ïr¯<ey&ù³s‰vé`bÚ°ñÇl—ç(*dâ¡Ü .Þl”,àòmÛ¨cÇôjq.Ã="" {�-´Ž*rqr="" xô¡›îx�(+é”="" ²9sõd©ð:ÉÏrÜô”aw\• pj="" �Ç³@Õz’7jj”ÍÉt="" .sñ="" —‚="" óÅnµ$ÿ›Êº¥Ïro¹$]�-d1™¢ø!3ikš5�â@xÈu.Òæoê"fuÉt#ñn#Ë¾Ïªf˜o="" °tu`:ÐÂèàm&ltv¥?´„¬91fÌz"áucŽf§<.ÏhØ‹;mÅžŸì¶îý»�&|ou…qâ%[(}xs©±Ó ¦.z¾çÜ‹µŠ‚í´ìq­™¬Á)hº:Ø¡dÛ�†5zº="" ÊÀ�(Ób›ÒÝ+m#´Á¸_Ã;¬¡›*-˜m«°¨z£="õµñcýmd^‚@ÈN?q÷èÙgñµocâü‰™xvrÍ%aÕQ«�êúâ˜×W:—Ã²Øâí,6´€�°\µ6Ð1P�#Çd-z_µD¯÷)ô£—<UWŒ¸»C·<´Ý" ¶amÁôdïÍ�øÁa¹òÈ÷^zÆ¤ƒ±·ßƒëÑvw—ëÑ{8="" —êí¶áž¢›øg®ƒ�É2€k4ãe«Áaî¸sm' ¨mœ="" f="" qn§¢$Æc£äúÐà2dhyzfÍ¢dÆ�c× ž¸ˆcÍßr°%Ëy®àÏðöy="" %vÏÖÊ²ÿ(sw:k7ö="" ¥Ñ‘^À•Åof="" írñ‚Áu.m]öÎ‡ë="" vêxpcqö�¥Ô£o *wëþs%²Þ”¼§–¢8ñ‚ÃÝ%œ+öpzpe©uúç÷yÑµ8="" ¦å="" ]û="" ˜”¼®9»»v�íÔ+|ÿÙš¶ýásß¨ŠÐß{›}²£˜Ç„;³Æö="U�—ìü˜noÔW¬‹“;g¤®»‹ß°Šàµ�!¢üHOÑæ�™WÆÊh7…ò¤lfªõÛ÷Ž{!ƒ" ˜(ŽÂ¡wãýîædÜõÎšàÆÜù›Ä‹fhèÅ·ytŒjÇiµwi(8u±v +°ìbi²Óz?ßxÕrå»d¼�ÑÊ…æ%tŠ|qïr£³i]â2xk´\(‚¨0n8vrv%‡Énk…’|(×ßc’Þ�uÍèn–q¥û!gƒe,lˆ¡¸*Öšà�Ý[¦ò#¦sçx1-kŽñ“c³yÖ="“–�¤&amp;²eïßjSwƒydØ}ß¶xÝxÜ`ÚÏæ€Ñ©cWÂvxQdÛÍ" 4ˆ_Ç="[f}/w‡£Ñ³™”Ùc" ÎöÔwq*n×µÅzaÀ§±öoô³{="" ¬h¬ýßgmßÊ²ãn¾ìbÉ|½ä5ø“.sâÈ<�="" ¦ìÆö:6¯ó6@x&4†Ý½½š|gêìº[zÛnnqp�rîÑð¹âÁfª·ƒr\äñÔáf86<(¤="" qi4_¶ûphàÅ²ÀühÃ]Ñº1ûaÀru×¥"ff¬<úql·k–Œ?n¾="œé`0»º2]ZÀ“âµe�…3Ä´ÄzC6®®V¸2œ0žä=<èb¾V¬Hx:ç¼Q­«µZ6lé{§½,,X«" �gÓk™óÊº0¯[ÒÎ¶¦b­ƒ6Â¨«#.Özp£?°�Œ°ãÀ^Ð§]�-çÕŽ"¹i9÷7Ó7jm"oav7×­êeq="" .ËÑã½çè‹À="" o'³¼ƒkéÿ~{ÂÛˆÁ›uvæ="" oòˆ^vÙl�k³ÏxÀn¾f]¼q§ïÿ@x="" endstream="" endobj="" 54="" 0="" obj="" 2027="" 52="" <<="" type="" page="" parent="" 3="" r="" resources="" 55="" contents="" 53="" mediabox="" [0="" 595="" 842]="">&gt;
endobj
55 0 obj
&lt;&lt; /ProcSet [ /PDF /Text ] /ColorSpace &lt;&lt; /Cs1 7 0 R &gt;&gt; /Font &lt;&lt; /F1.0 8 0 R
/F2.0 24 0 R &gt;&gt; &gt;&gt;
endobj
57 0 obj
&lt;&lt; /Length 58 0 R /Filter /FlateDecode &gt;&gt;
stream
x¥ZÛŽãÆ}Ÿ¯(ø%^`†æýâ<y0‚$02À"€_zdkl Éæ6É‘•¯Ï©&uõ(³¢g�i$µŠu9uê¿Ð¯ô…|ükŠ„ò8$#éuôÝ�c@å@="" åõëÛ7þð€·}Á»ù¨'þÅg•-}|¦="" zþq’zi!¥="·ôÝÏ�çãCÏ[ú–ˆžkIªÛÊrTºh¬ÅH½‘/B5²&quot;<ñ=�ƒIoí3ÕUÓ0%;|ºiø©%ÕzOž§Ÿží5~µiy|mZ++UªNR)ZI›©q€Ÿúil©÷î×àªù'›ýpzÆ‘—ÅIF¹ïq¥øâ‡KŸèë/" Œ3="" `ýÅ<,¾}ž6Ò”s£5<ÒvøyewÊg\ˆ(kö="" õr|&ý"="" ÝþÞ‡Û1-œ˜Ž{m;Ùi„#êÑ="" ýsîé?Ú|†äaøhãxi1Öd·Éat-¢xÑ¨iƒ`ª]Íf­‰g8efu”ù="">®ØPà?ú¾ÿWŽk�ç°g_ËŽþ®Ëš¶Ê#©A7ÖÑU'Ž“aÃ�‹QÚŒ{DF¬4.tœVÄ¢ATªU²l�xÖ
Qvi¯g«åä°Jï;öU�û³ýlÞlþ:§ÅŽÓÑ‰Q5µÄ!Ò=[Ù(p!Éxm¬õ´«é›ÑžÚž£þ
!–MCµl*$^©¨oD)W:,q†Dâ«mµE£Æ�bÓÈáñÝ?¢­Ó³ ÇÃÀ�)H®KöÄ«²üÛõáb^PD^’¦9ŽcÓ_�D?lG¤à'màœOÂÐ/¿&lt;Òf‘ó(RI¢ÕFéQ‰7ÒÂ�"%Wº/sâŠÔå”Õ÷6&nbsp;H#Ùp8Q‘s¤ö
Å\žÞ8÷èÇZ7¨ëÕNŽŠÌ£�‚ÌbŸëãàÇ~èià8ç$ª®EšÃã»GžràuFÄiâ%q˜�¬}¸j^AøîÑ]0ÎB/ˆ¾øøú$„¼ú?ðë¦×©¥yq}Øxèk­[ÕªF˜æ`!Aæ/©öhžÜX¹£ªJÚ"êëÃ€^'º¿„R�n&lt;úˆ’B�’WmˆbºòT†$¢Ñ»ƒE”©«$ðVëÙ¾ùøßˆþ`S&nbsp;aÂÐËRmUi;Ç ©RƒƒÖUD8€Âå€V9R;¡	ÌLÆ¾(35=ÓºM�f#
—5¤Úž1ŸÑÖn,z¿‹DÉqŠgh�çGºè’[£[P3dh‹j5�pD_³¿”à&amp;¦u¯º¢D~´&amp;·p€‘D«ñÂ:£bÇ[e­šÊü§ž;ÐVÒðl[8\'mî¶•¨Å#{5ûØä¸•œ1|�u©“g9îÙ€ºo�ib³I—åd¸“/XÏÁd|5YÊF^â¯-Ì5$ÌŸíQo¨-MµíÔ©ÿþI&amp;ø^æ	…Ù�–ÝPa ÌÀ›fÓ_·,p¸^&amp;ãŠYp)‡mžZq`¦&amp;F°qt0øÉ€Š0 ”'D{àiã«™xX8á¿8«98_pòÀ�@�…œ‹ákUiô“6;Ñ©¡óµ­õ@[tZwËE¾*Ó"ß‰é±úQŽ¢Q²˜&amp;ŽÔµÆW=	þm‚ª	àÁÜvdÐMðš�%˜"÷Ÿ^gVèxõ�¤V(ûQWâÀ(!Œ©¥°&gt;œÐó
ÛÕ+pImO˜žJpÞófë„+s%øG‘ãª­‘_&amp;à@s�4$F0kÃU×,œÿ	àå°áä*ðrë©GêôJo%Ž·0tp<xxœÁ~ z96È�x€]$€”gs&›«gÀ(k½="" ÉrŠ’<(¾§p£<ô²<oq_šs¸?u»="">F!Ì-½U(À:¾¥ß˜[%uhzÜ@í'0¯SBMîz&nbsp;JsXš:ÐÃ4�Àâ€ä÷Õé1ú.²B+šsÆ‡®BßÄl@·vŒ1F•Ÿ%ÆyÎ¼^6�Øa»÷)“A=b.†mü–uUéNÆ/ŒH˜ºÁaì€{éF¦§�KçîiÛ,šºµöã2ö,�ðhŠÊ�ãVÙå¯¨fcÕ�Qµšt%;dýÔ”àg´`ÊÕÐyô‰‡eXÌ<lvç‰¾Å§à»uf¹sñ9i@g•â{p£;aÀá£ñè4Ì¢-óxÙ‚mð¸ndÝco€¿#’q�qîh\€ž£ì¸>Àüýö-ÐU4àÛKE4ð×ðÛœkFzXús.rb
ú	ÈÂt|�qîXŒðXvùÂ0±öèoó�ÆÀrØæ‰ºu6%øá"‹À_€¥&nbsp;­=X¥$ùªC?·wÖŒÖYæNœœà,¡.Bö”ÐdvrX�¤aèC[(¾5P&amp;÷ifžŸeŽs�ôãöiaELa=ò@¨î{K+Ày¶3+BÕôÜOË³–wŠs§y"¥NS†4ÑušõBÅVˆnEvZgËsß?|JCc@[ëôs[]ØÄêpèFÁ”X‡c1LøN0oÓ@&lt;µX¦â,ƒâ‹Ú±ÕÒ¨­�ð0$hVe\âNtÃ´Ýb.hÙ¹‰�ÓA‡&lt;¢¬G?Ã\Kq¬4(Î}ùß`$¶&gt;[ÞN#¦�jå¸™¸S]�6ÄÓãè"rË<vw\ÂÌ3ØÞÞ@Ôu¨lÃa=�q ”¨vdxÖz›•nsg;Àjƒ&Ž“eí@÷º Ð`}‘ú="">TŸ&lt;§$¾1§¤wU©Ÿzy–†8ŽËä5ÝùÇBÖvR£§£dVË?…</vw\âì3øþþ@ôu¨lãa=�q ”¨vdxöz›•nsg;àjƒ&ž“eí@÷º></lvç‰¾å§à»uf¹sñ9i@g•â{p£;aàá£ñè4ì¢-óxù‚mð¸ndýco€¿#’q�qîh\€ž£ì¸></xxœá~></y0‚$02à"€_zdkl></ey&ù³s‰vé`bú°ñçl—ç(*dâ¡ü></j�$|eá�'ôí|í•¬<ž�kv¦\öu‹mžèù2þè“‰á‹õè1™¼àceãá–¥ì¡î{ìê‡í´çn´µ‡úmfš^�®¥h†®^g3t?t]½ç•ht«]v«à‘x></k¡îuª}j‹ú></x¬ð#¢š¹0óñœt¥²-‘sæ¢(*¯b;i®ûù¹æ¾‹µ‰ƒþ\�föž½³êªñlô´÷d¡¼®dï_töl5§></u¢ctìð¡›—¢à¬k×></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ratical.org/ratville/AoS/MedicalNemesis.pdf">https://ratical.org/ratville/AoS/MedicalNemesis.pdf</a></em></p>]]>
            </description>
            <link>https://ratical.org/ratville/AoS/MedicalNemesis.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826220</guid>
            <pubDate>Mon, 13 Jul 2020 22:20:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The AirPods Pro “Rattlegate”]]>
            </title>
            <description>
<![CDATA[
Score 371 | Comments 314 (<a href="https://news.ycombinator.com/item?id=23826070">thread link</a>) | @dewey
<br/>
July 13, 2020 | https://annoying.technology/posts/abea6876cf4f2e13/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/abea6876cf4f2e13/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/a57da8f4dbb8954a0649e58235d5555af26d4c2f/d294d/media/rattlegate.jpg"></p><p>The AirPods Pro “Rattlegate”</p><p>The first generation of the AirPods was generally regarded as a perfect product. “Apple at its best!” was the universally accepted opinion.</p><p>I used them for a long time. No speaker issues, no battery issues.</p><p>Excited for the noise cancelling feature I ordered the AirPods Pro and for the first few months everything was fine. One day the left AirPod started buzzing every time I was moving my head. Slightly tilting my head would result in a buzzing noise with changing intensity depending on how my head moved.</p><p>Support agreed that this is a problem and sent a new AirPod.</p><p>A few weeks later the right AirPod started to produce weird rattling noises. It sounded like some tiny part fell off and was now bouncing around in the AirPod. It also started to behave weird as soon as there was a bit of wind.</p><p>Support agreed that this is a problem and sent a new AirPod.</p><p>Days later it was the left AirPod’s turn and it’s now rattling again.</p><p>There’s something very wrong with this product line and just getting a new one every few months is — financially and ecologically — not sustainable as they end up in a landfill. I’m also <a href="https://forums.macrumors.com/threads/airpods-pro-rattlegate.2233658/">far from being the only one</a> having this issue.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/abea6876cf4f2e13/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23826070</guid>
            <pubDate>Mon, 13 Jul 2020 22:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23825606">thread link</a>) | @refrigerator
<br/>
July 13, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825606</guid>
            <pubDate>Mon, 13 Jul 2020 21:09:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Calculating Churn Rates Wrong]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23825420">thread link</a>) | @cmogni1
<br/>
July 13, 2020 | https://catchjs.com/Blog/Churn | <a href="https://web.archive.org/web/*/https://catchjs.com/Blog/Churn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        
<ol>
    <li><a href="https://catchjs.com/Docs">Blog</a></li>
    <li>You're all calculating churn rates wrong</li>
</ol>

        

        
        <p>
            Many smart people will tell you to obsess over your churn rate.
        </p>
        <p>
            <img src="https://catchjs.com/Blog//images/blog/churn/churn_rate_formula2.png" alt="churn rate=(customers lost in month)/(customers at start of month)">
        </p>
        <p>
            According to Andreessen Horowitz, this number is <a href="https://a16z.com/2015/08/21/16-metrics/">one of the top 16 metrics</a>
            to measure a SaaS startup by. Well, sorry Andreessen, and sorry Horowitz, but this just isn't right.
        </p><p>
            It's counterintuitive, but it's a statistical fact: This number actually <b>tells you nothing useful about churn</b>,
            but really relates to the age of the subscriptions you have.
            It will in most cases go down on it's own, and, absurdly, the only way to keep it from going down is to have very
            high growth. So the number will literally <b>only look <i>bad</i> if your business is doing extremely <i>well</i></b>,
            and optimizing for it will be directly counter-productive.
            The error here is a simple statistical mistake that is easy to make, and luckily also easy to understand and avoid.
        </p><p>
            If you run a subscription based SaaS business, you're likely very concerned with how long you can keep your
            customers. We're a JavaScript exception tracking service, and the health of this business is fully determined by how many
            customers we bring in, and how long we can keep them. On the surface, <i>churn rate</i> may seem like a natural proxy for changes
            in <i>customer lifetimes</i>. Let's dig into why that is not true.
        </p>
        <h2>
            The false assumption
        </h2>
        <p>
            Computing a churn rate <b>assumes that a customer is equally likely to leave at any time</b>, no matter how long they've
            been subscribed to you. This is almost certainly not true. In fact, as we will see, having a constant churn probability over time
            essentially implies that you'll <i>never have long term customers</i>.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/expon.png" alt="Hazard function (churn) and the implied survival function (from an Exponential distribution)">
            <figcaption>If a user has a constant churn probability over time, this implies that customer lifetimes come from an Exponential distribution.</figcaption>
        </figure>
        <p>
            If you have a constant churn of <code>c</code> per month, the probability that a customer stays subscribed for <code>n</code> months is <code>(1-c)^n</code>. This implies that customer lifetimes come from the <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric distribution</a>. If customers can quit the subscription at any time, we have continuous time and should use the continuous time analogue, the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential distribution</a>.
        </p>
        <h2>
            What your churn is actually like, with help from K. S. Lomax
        </h2>
        <p>
            The problem is, your customer is not equally likely to cancel their subscription at any time. Most likely, you have a situation where the drop-off in customers is higher in the first few days than it is later. This is even more so if you have a free trial period for your product.
        </p><p>
            If the churn probability gets lower the longer the customer has been subscribed, you could model that as <code>c/(t+1)</code>, where
            <code>t</code> is the timestep (e.g. number of days the customer has been subscribed), and <code>c</code> is some constant.
            In this case, this implies that customer lifetimes comes from a <a href="https://en.wikipedia.org/wiki/Lomax_distribution">Lomax distribution</a>.
            This is equivalent to a Pareto distribution shifted to start at 0.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/lomax.png" alt="Hazard function (churn) and the implied survival function (from a Lomax distribution)">
            <figcaption>The Lomax distribution can express churn probabilities that get lower with time.</figcaption>
        </figure>
        <h2>
            What your churn is actually like, with help from Waloddi Weibull
        </h2>
        <p>
            If you suspect that churn probability per day may <i>increase</i> the longer a user has been subscribed, the Lomax distribution won't
            work for you. Instead you could enlist the help of Swedish statistician Waloddi Weibull.
            The <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull distribution</a> can express both decreasing,
            flat, and increasing probabilities of a customer quitting. This makes it a popular choice for modeling customer lifetimes.
        </p>

        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/weibull.png" alt="Hazard function (churn) and the implied survival function (from two Weibull distributions)">
            <figcaption>The Weibull distribution can express both growing and shrinking churn probabilities.</figcaption>
        </figure>

        <h2>
            Optimizing for a falsehood will lead you astray
        </h2>
        <p>
            Now let's see why properly modeling this is important.
        </p><p>
            Let's measure churn the wrong way, and see where it takes us.
            Let's say customer lifetimes come from a Lomax distribution. Let's also say you have a business that is in terrible shape, where
            the number of new sign ups per day is falling by one per day. How will this look on the churn rate? We can simulate it and find out.
        </p>
        <p>
            Keep in mind, in each of the examples below we simulate lifetimes from the same customer lifetime distribution,
            and this distribution <b>does not change</b> over time.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/shrinking_business.png" alt="Shrinking business, churn appears to fall">
            <figcaption>With a shrinking business, churn appears to improve because subscriptions are getting fewer and older.</figcaption>
        </figure>
        <p>
            This is clearly a dying business, yet the churn rate graph is looking great! <b>
                The churn rate per day is falling steadily,
                even if we know that there is no change in customer lifetimes in our model.
            </b>
        </p><p>
            So what's going on? This sharp fall in churn rate is a consequence of the fact that we're not getting new customers.
            Because we're not growing, a bigger share of our customers have been around for a long time, which
            means they're less likely to churn, which means our daily churn graph goes down more than it would otherwise.
            This change on the population level happens despite there being no change in underlying individual customer lifetimes.
        </p><p>
            Let's change this into a scenario where your business is experiencing insane growth. We'll keep the customer lifetimes exactly the same,
            but change it so that the number of new sign ups per day is growing superlinearly.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/growing_business.png" alt="Growing business, churn appears to be flat">
            <figcaption>With a growing business, churn rate appears to not change, only because most subscriptions are new.</figcaption>
        </figure>
        <p>
            Even if the customer lifetimes are unchanged from before, the churn rate graph here is flat. An investor would frown and say
            we're doing nothing to improve how well we retain our customers. In reality, the only reason the graph looks "bad" has nothing to
            do with churn, it is because we're doing insanely well at getting new sign ups.
        </p><p>
            <b>
                If you are steering yourself and your team on the basis of this metric, you're rewarding yourself for stifling growth
                and punishing yourself for growing.
            </b> Obviously, this is 100% counterproductive.
        </p>
        <h2>
            How the h*** do we measure churn then?
        </h2>
        <p>
            As you might have guessed from the previous paragraphs, we should model the <i>distribution of customer lifetimes</i>,
            and we should do it in a <i>statistically sound way</i>. Lomax and Weibull distributions are good choices of model.
        </p><p>
            The part where this gets tricky is that we'll have two types of data: The customers that have quit, and the customers
            that are still subscribed. It's only our ex-customers that give us a total lifetime to work with. For our still-subscribed
            customers, we only know that their subscription has lasted up until now, and we don't know how much longer it will last
            into the future. In statistical lingo, we have what is called <i>right-censored data</i>.
        </p><p>
            Luckily there's a way to use all our data, even from our still-subscribed customers.
        </p>


        <h2>
            Weibull or Lomax?
        </h2>
        <p>
            Choosing between Weibull or Lomax (or any other distribution) has no simple answer. Weibull is more flexible
            in that it can express growing, shrinking and flat churn probabilities. However, this expressive power will
            not help you if your data is fundamentally Lomax-like. First and foremost, base your choice
            on your knowledge of the business that you're in. If you have any prior knowledge about how churn probabilities
            will develop, base your choice of distribution on that. There are also various
            <a href="https://www.weibull.com/hotwire/issue71/relbasics71.htm">goodness of fit</a> tests you could use to
            inform this decision. The truth is, any choice of distribution will be wrong to some degree, so you need to make
            a judgment call as to what fits your situation the best, based both on both your data and your prior knowledge.
            For the purposes of the rest of this post, we'll just fit both distributions and disregard the question of
            which suits us the best.
        </p>

        <h2>
            Let's do some proper statistics
        </h2>
        <p>
            The probability distributions we'll model are defined by their parameters.
            We want to find the parameters that fit the data best. To start, we want to make a guess at these parameters,
            and have a way to tell how good our guess was. Luckily, we have a statistically sound way of knowing how good a guess
            is given the data we have. Extra luckily, this is also true when we have censored data.
            This function that tells us how likely our parameters are given the data we have is called the Likelihood function.
            We get it by looking up the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a>
            value for the uncensored data points and the <a href="https://en.wikipedia.org/wiki/Survival_function">survival function</a> value
            for each of the censored data points, and multiplying all these values together.
        </p>
        <figure>
            <img src="https://catchjs.com/Blog//images/blog/churn/likelihood.png" alt="Likelihood formula with right-censored data">
            <figcaption>
                Likelihood function L for right-censored data. <code>f(.)</code> is the probability distribution function, <code>S(.)</code> is the survival function,
                <code>D</code> is the set of uncensored lifetimes and <code>R</code> …</figcaption></figure></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://catchjs.com/Blog/Churn">https://catchjs.com/Blog/Churn</a></em></p>]]>
            </description>
            <link>https://catchjs.com/Blog/Churn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23825420</guid>
            <pubDate>Mon, 13 Jul 2020 20:49:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Octo-Bouncer: Advanced Bouncing Patterns]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824933">thread link</a>) | @jeffreyrogers
<br/>
July 13, 2020 | https://electrondust.com/2020/05/25/the-octo-bouncer-advanced-bouncing-patterns/ | <a href="https://web.archive.org/web/*/https://electrondust.com/2020/05/25/the-octo-bouncer-advanced-bouncing-patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Roughly three months have passed since I wrote my <a href="https://electrondust.com/2020/03/01/the-octo-bouncer/">initial post</a> about a machine I call “The Octo-Bouncer.” What has happend since then? In this post I talk about what parts of the machine were updated. Why they were updated and what kind of stuff the machine is able to do thanks to these updates.</p>



<h2>So what changed?</h2>



<p>I will cut straight to the juice. Here’s what the machine is able to pull off now:</p>



<figure><p><span><iframe type="text/html" width="660" height="372" src="https://www.youtube.com/embed/ItzOya7qWmk?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<p>And here are all the things that changed in order to make the new bouncing patterns possible:</p>



<ol><li>I cut the squared acrylic plate into the shape of a octagon</li><li>New custom ball detection algorithm</li><li>New ball position data visualization</li><li>Hit position prediction using gradient descent</li><li>Plate tilt visualization</li><li>Analytical tilt control</li><li>Two-step bouncing</li></ol>



<h2>Octagonal top plate</h2>



<p>So I did what I planned on doing since I was designing this machine; I went ahead and cut the acrylic top plate into an octagon. Why didn’t I do this right away? Because I wasn’t sure whether or not I’d be able to get a good finish. Turns out cutting and polishing an acrylic plate isn’t all that hard. Here’s some pics I took while changing the top plate.</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0736.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0736.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-1536x1024.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0736.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0736-1536x1024.jpg 1536w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0736.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Plate-less Octo-Bouncer.</figcaption></figure>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0737.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0737.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-1536x1024.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0737.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0737-1536x1024.jpg 1536w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0737.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Both new and old top plate.</figcaption></figure>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0739.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0739.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-1536x1024.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/IMG_0739.jpg 1920w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-512x341.jpg 512w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-768x512.jpg 768w, https://electrondust.com/wp-content/uploads/2020/05/IMG_0739-1536x1024.jpg 1536w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/IMG_0739.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Freshly plated Octo-Bouncer.</figcaption></figure>



<p>“Huh, so that’s why you call it Octo-Bouncer?” – Yes. But let me explain. It’s not only the plate. There are a lot of octagons in the design. Like here:</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer.jpg 1440w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-384x512.jpg 384w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-768x1024.jpg 768w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-1152x1536.jpg 1152w" sizes="(max-width: 1440px) 100vw, 1440px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer.jpg 1440w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-384x512.jpg 384w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-768x1024.jpg 768w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-1152x1536.jpg 1152w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>and here:</p>



<figure><a href="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg"><img src="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg 1440w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-384x512.jpg 384w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-768x1024.jpg 768w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-1152x1536.jpg 1152w" sizes="(max-width: 1440px) 100vw, 1440px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg 1440w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-384x512.jpg 384w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-768x1024.jpg 768w, https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2-1152x1536.jpg 1152w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/03/why-octo-bouncer-2.jpg?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<p>I was constantly thinking how to implement more octagons into the design while working on the aluminium build. Naming it Octo-Bouncer seemed like the only reasonable thing to do at the time.</p>



<h2>New ball detection algorithm</h2>



<p>“Why fix something that’s not broken? What was so bad about the old ball detection?” – there were mainly 2 things I didn’t like about using <a href="https://docs.opencv.org/master/da/d53/tutorial_py_houghcircles.html">OpenCVs HT21 circle detection</a> algorithm in this specific project:</p>



<ul><li>Too much noise in both the position and radius data</li><li>Too slow. Wasn’t able to reliably process at 120 FPS.</li></ul>



<p>Let me be very clear here. I am not bashing the HT21 circle detection algorithm. It just wasn’t the right fit for the job. HT21 shines in circumstances when there’s a lot of different shapes and edges and you want to know where the f*ck the circle is. But our image data is very clear cut from the start. Just look at it:</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1.png" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1.png 639w, https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1-512x385.png 512w" sizes="(max-width: 639px) 100vw, 639px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1.png 639w, https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1-512x385.png 512w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/original-image-stream-1.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>After doing a simple orange to gray scale conversion the data is even crisper.</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale.png" alt="" srcset="https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale.png 639w, https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale-512x385.png 512w" sizes="(max-width: 639px) 100vw, 639px" data-lazy-srcset="https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale.png 639w, https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale-512x385.png 512w" data-lazy-src="https://electrondust.com/wp-content/uploads/2020/05/orange-to-grayscale.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p> We could find the ball’s position just by counting all the bright pixels and then taking the average. Following this line of thought a bit deeper, we also see that there’s an easy way to get the ball’s radius by counting all the bright pixels and then using the fact that a circles area is equal to pi * r^2.</p>



<p>I did just that. It worked flawlessly. The only problem with this approach is that detecting multiple balls is only possible if we’re adding code to distinguish the different lumps of bright pixels. I went down this route for a while but the processing load quickly got out of hand and my goal of 120 FPS didn’t seem feasible. </p>



<p>So here’s what I ended up doing: Edge following. My current algorithm just follows around the edge of all the bright pixel lumps it is able to detect. After we got this edge data we just look at one of the edge-pixels and determine which of all the other edge pixels is the furthest away. Computing the 2D distance between these two pixels yields the diameter of the ball. And if we do this for 10 pixels randomly chosen and then only consider the 5 biggest diameters we are able to get very accurate ball data even if the ball isn’t fully visible or part of the edge isn’t appearing circely. </p>



<p>If you’re not convinced just look at this data:</p>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/BallDetectionAlgorithmComparison_1.gif" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>HT21 circle detection algorithm.  </figcaption></figure>



<figure><img src="https://electrondust.com/wp-content/uploads/2020/05/BallDetectionAlgorithmComparison_2.gif" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Custom edge following circle detection algorithm.</figcaption></figure>



<p>Don’t tell me you see no difference; The custom one outperforms OpenCVs HT21 circle detection algorithm both in performance and accuracy (in this specific case that is.)</p>



<h2>Analytical tilt control</h2>



<p>Another big software update was the addition of analytical tilt control. Now “analytical tilt control” are just 3 words put together because I thought that they’d describes fairly well what’s going on. But do they though? What’s so analytical about this tilt control mechanism?</p>



<p>So here’s the idea: We’ve got a ton of accurate data describing the ball’s current state. We’ve got position, we are able to get a good approximation of the balls velocity using gradient descent on this position data. We also know how long the ball is in the air between bounces. So the idea is that with all this data and leveraging the power of basic physics we should be able to analyse the situation in such a way that there is an ideal tilt which will lead to the ball bouncing exactly to where we want it to bounce.</p>



<p>Analytical tilt control works well. It outperforms the PID algorithm I used up to this point. But it isn’t perfect. Every once in a while the ball will end up bouncing in an unexpected direction.</p>



<div><p>But this unexpected behavior isn’t so much caused by the tilt controlling mechanism misjudging the situation, but rather by small dirt particles on the plate (I think.) There is also a line of thought concerning the balls rotational momentum; When the ball hits the plate, some of the energy put back into the ball after the hit might be in the form of rotational momentum. This rotational momentum could influence the balls trajectory on later bounces.</p><p>But I checked the relationship between “ball suddenly bouncing in an unexpected direction” and “ball is spinning.” And the two seemed unrelated. This brings me to the current conclusion that it really must be a problem with small uneven areas in both plate and ball, since the degree to which the ball sometimes suddenly changes direction would need to plate to wrongly tilt several degrees in the wrong direction. And I also checked this possibility. On occasions where the ball acts unexpected, the plate isn’t showing a unexpected tilt. So currently I’m thinking it has to be a problem with the fact that the touching surfaces of ball and plate are actually really small and that if there’s something uneven about these small areas it will lead to the ball doing something unexpected.</p></div>
	</div></div>]]>
            </description>
            <link>https://electrondust.com/2020/05/25/the-octo-bouncer-advanced-bouncing-patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824933</guid>
            <pubDate>Mon, 13 Jul 2020 19:57:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3: An AI that’s eerily good at writing almost anything]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824805">thread link</a>) | @arram
<br/>
July 13, 2020 | https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/ | <a href="https://web.archive.org/web/*/https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I got access the the <a href="https://openai.com/blog/openai-api/">OpenAI GPT-3 API</a> and I have to say I’m blown away. It’s far more coherent than any AI language system I’ve ever tried. All you have to do is write a prompt and it’ll add text it thinks would plausibly follow. I’ve gotten it to write songs, stories, press releases, guitar tabs, interviews, essays, technical manuals. It’s hilarious and frightening. I feel like I’ve seen the future and that full AGI might not be too far away.</p>



<p>In each case below bold is the prompt I provided GPT-3, and the rest is all generated by the AI. In some cases I had to click generate a few times, and in about 2/3 of the examples I picked the best example after a few tries, but I generally didn’t have work too hard to get it to write amazingly coherent text given a simple prompts. Here are some of my favorites. </p>



<figure><img data-attachment-id="196" data-permalink="https://arr.am/screen-shot-2020-07-08-at-9-36-23-pm/" data-orig-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png" data-orig-size="731,453" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2020-07-08-at-9.36.23-pm" data-image-description="" data-medium-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=300" data-large-file="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=731" src="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=731" alt="" srcset="https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png 731w, https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=150 150w, https://arramsabeti.files.wordpress.com/2020/07/screen-shot-2020-07-08-at-9.36.23-pm.png?w=300 300w" sizes="(max-width: 731px) 100vw, 731px"></figure>



<p><strong>Below is a screenplay for a film-noir hard boiled detective story by Raymond Chandler about the boy wizard Harry Potter:</strong></p>



<p><strong>“Harry Potter”</strong><br><strong>By Raymond Chandler</strong></p>



<p>Harry Potter, Private Eye.<br>Scene: A small dingy office, early morning, furniture of the Salvation Army store variety. Sordid atmosphere. Harry Potter, in ratty tweed suit, unpressed shirt, and unshined shoes, sits behind the desk looking haggard, rumpled, and embittered. In one corner of the office a torn shade rattles at the wind gusts outside. Harry has one long index finger on the butt of a .38 and he broods over a photograph. The photograph shows a gorgeous blonde wearing an evening gown. She is holding a cocktail in one hand and looking pensively at a cigarette in the other. A tear adorns her cheek. Harry looks at her for a long moment, sighs, then puts his gun down and stands. He straightens his clothes, scratches his head, then with more resolution turns around, picks up his pistol, and leaves the office. He passes through the front room and looks out the dirty window. An old woman is washing the sidewalk outside with a mop. A young man in a double breasted gray suit is leaning against the building. Harry sighs again and goes out the door. He walks up to the young man and without ceremony punches him in the jaw.</p>



<p><strong>Press Release: Anaheim, CA: President Kanye West declares Disney Land to be the new capital of the United States. Washington D.C. will be maintained as a museum.</strong><br>The move has been in the works since the mid-2000’s. <br>Advertisement <br>*2. Removes his sunglasses, revealing that he is no longer in any way blinded. <br>*3. Endorsed by Senator Kid Rock, who has also declared this new government of Disneyland will be paying for his divorce.<br>*4. An elaborate surgery will take place to repair Kanye’s “Diamond Tiara” tattoo, and reposition it to his forehead so that he can legally be recognized as a Princess. <br>Advertisement <br>*5. Joe Rogan has been picked to be the new Drug Czar. <br>“It’s long been established I’ve been Kanye’s gateway drug, so why not put me in a position of power,” Rogan said, clearly relishing his new position. “I have an in-depth understanding of the ways in which recreational drug use enhances one’s experience of life. I am deeply passionate about getting drugs to kids.” <br>*6. Kardashian sisters will no longer be known as The Kardashians. The family will change its name to The Wests. <br>*7. Kanye West’s new sports bra will no longer be known as a sports bra. It will be officially recognized as The West Bandit. <br>Advertisement <br>*8. President Kanye will announce that he has a new national anthem. The government-mandated anthem will be a modified version of Kanye’s 2007 hit “Stronger.” It will be played on a continuous loop at all times.</p>



<p><strong>Below is a rap song by Lil Wayne about the boy Wizard Harry Potter. </strong></p>



<p><strong>“Harry Potter” </strong><br><strong>By Lil Wayne</strong></p>



<p>Har-Har-Har <br>Harry Potter <br>Har-Har-Har <br>O.K. No need to ask a label, I’m my own team<br>Me I’m higher than a kite like a witch on a broomstick<br>I got bigger balls than Dumbledore with a Firebolt<br>At Hogwarts, on stage like I’m Nicki on Nick<br>But I’m the shit, make a good verse like I’m Nicki on Nikki<br>I got Biggie bars, Wiz-a-more bars<br>Damn this verse is too good to be a freestyle<br>I never die, when I start, then end of the night<br>Bitches gonna ride the broom when I call them to the quidditch game<br>But I’ve been playing harry Potter in my games lately<br>And you might have guessed but I don’t play for Gryffindor<br>I’m a Slytherin and what’s happening now</p>



<p>I’m on fire like Harry in his Triwizard task<br>Don’t let these games stop<br>I’m gonna do it till the day I get a lot of cash<br>Just like a nerdy nerd that grows up to be a bad boy<br>I don’t really see a point of coming back<br>But in the wizarding world I’d rather be famous<br>I’ve been thinking, what would be cooler than that?<br>This is my life, what would make a good story? <br>Never die <br>The realest thang since my pen went back and forth <br>And came back as a double headed snake <br>It’s Voldemort, with a new name <br>Don’t be the Death Eater that made me lose my fame <br>Get your ass in the bathroom while I make a spell <br>I got some awesome wizard bars, I’m not the Doctor <br>My wand is great and it’s straight from Ollivanders</p>



<p><strong>Kayne West Exclusive – Why He’s Running for the Presidency, and what his priorities would be as President. <br>Anderson Cooper: Yeezy, how would you describe your presidential platform? </strong><br><strong>Kanye:</strong> My platform is very simple. I want to make everything awesome again. <br>Anderson Cooper: But what about foreign policy? <br>Kanye: Who cares about that stuff? Let’s talk about important stuff, like Kim Kardashian’s butt. Anderson Cooper: That’s a bit sexist. <br>Kanye: I’m sorry. I’m not sexist. I love women. I’m just an equal opportunity objectifier. <br>Anderson Cooper: But what about abortion? <br>Kanye: I think abortion is fine. I mean, women should have the right to choose what they want to do with their bodies. <br>Anderson Cooper: But what about climate change? <br>Kanye: Let’s talk about Kim Kardashian’s butt. <br>Anderson Cooper: I’m going to be straight with you, Kanye. <br>Kanye: Oh no, you’re going to be gay with me? <br>Anderson Cooper: No, I’m going to be straight with you. You’re not going to win this election. <br>Kanye: I’m going to win. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am. <br>Anderson Cooper: No, you’re not. <br>Kanye: Yes, I am.</p>



<p><strong>Blood Song</strong><br><strong>By HP Lovecraft</strong></p>



<p><strong>The creeping chaos Nyarlathotep walks upon the earth while in his House at R’lyeh dead Cthulhu waits dreaming. After eight seaons on&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://paper.dropbox.com/?q=%23TeamDaenerys">#TeamDaenerys</a>&nbsp;&nbsp;Nyarlathotep is quite irritated with what he feels is a very hackneyed ending to Game of Thrones.</strong></p>



<p>On the third day of season eight, Nyarlathotep looks down upon his television and utters&nbsp;“What&nbsp;the hell are they doing?”At this point, Nyarlathotep goes on a long tirade about how the Starks were supposed to be there at the end. Instead we have Daenerys looking like she is going to set everything on fire. He tells his cult of followers that Daenerys’ actions are completely nonsensical and that it is completely disrespectful to not finish a story with all its main characters alive. He mentions that they should just burn down Winterfell because it makes no sense for her to even be there. It would make more sense if she flew in with Drogon and just burned King’s Landing. His followers start to get nervous when Nyarlathotep mentions he has always liked Cersei.</p>



<p><strong>Below is a pop song by Taylor Swift about the boy Wizard Harry Potter. </strong></p>



<p><strong>“Harry Potter” <br>By Taylor Swift </strong></p>



<p>Harry’s got glasses <br>He’s got those bright green eyes <br>Girls are always screaming </p>



<p>‘Cause he’s got that Potter hair </p>



<p>Even when he’s super stressed <br>He’s still got those supersonic cheekbones <br>I’m not surprised they made a movie </p>



<p>‘Cause I’d watch him anytime <br>Oh, yeah, Harry, baby, you’re my favorite character </p>



<p>I’d walk a thousand miles </p>



<p>To get to see you and </p>



<p>Harry, Harry, you’re so fine </p>



<p>My girly parts all tingle </p>



<p>When you smile that smirk </p>



<p>I’d love to be your girl </p>



<p><strong>The following is an essay by Paul Graham on paulgraham.com on how to make Mars a startup hub</strong>.</p>



<p><strong>Startups On Mar</strong>s<br><strong>By Paul Graham</strong></p>



<p>Here’s the sort of startup that might make a go of it on Mars:<br>One that makes money by taking advantage of local resources. For example, a startup that uses the Martian atmosphere to make fertilizer or methane fuel. A startup that sells water from Martian rivers. A startup that uses minerals from the Martian soil. A startup that uses solar power from the Martian sun. A startup that uses a new kind of solar panel that’s more efficient at converting sunlight into electricity.<br>I would even invest in a startup that did nothing but extract the helium-3 from the Martian atmosphere and send it back to Earth.<br>If you can find a way to make money by using local resources, there’s probably a business there.<br>There’s another class of startups that might work on Mars:<br>Startups that produce services for other startups. For example, a startup that makes it easier to build rockets, or to extract gases from the Martian atmosphere, or to construct solar panels, or to farm the local soil.<br>Startups that make things more comfortable for colonists. For example, a startup that sells air conditioners, or houses. A startup that sells things to keep colonists entertained. A startup that provides Internet services.</p>



<p><strong>The following is a blog post from Slate Star Codex about the value of free speech and civility in a democratic society.</strong></p>



<p><strong>Do Not Go Gentle Into That Good Night</strong><br><strong>By Scott Alexander</strong></p>



<p>I.<br>There’s a concept that comes up often in debates about free speech called&nbsp;“shouting&nbsp;fire in a crowded theater”. The basic idea is that you can’t just say whatever you want whenever you want – especially if it’s likely to cause panic. And the reason for this is obvious: panic leads to violence, and violence hurts people. If you are causing panic, then your right to free speech ends where the other person’s right to not get hurt begins.<br>But this isn’t really true. If shouting fire in a crowded theater were illegal, then there wouldn’t be any actual fires in theaters, would there? How could there be? If everyone knew that shouting fire …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/">https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/</a></em></p>]]>
            </description>
            <link>https://arr.am/2020/07/09/gpt-3-an-ai-thats-eerily-good-at-writing-almost-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824805</guid>
            <pubDate>Mon, 13 Jul 2020 19:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python malware on the rise]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 58 (<a href="https://news.ycombinator.com/item?id=23824689">thread link</a>) | @vesche
<br/>
July 13, 2020 | https://www.cyborgsecurity.com/python-malware-on-the-rise/ | <a href="https://web.archive.org/web/*/https://www.cyborgsecurity.com/python-malware-on-the-rise/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
                        <p>
                July 13, 2020            </p>
            
			
            <hr>
                        <p><img width="2560" height="1646" src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-scaled.jpg" alt="" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-scaled.jpg 2560w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-300x193.jpg 300w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-1024x658.jpg 1024w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-768x494.jpg 768w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-1536x988.jpg 1536w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/david-clode-d0CasEMHDQs-unsplash-2048x1317.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">            </p>
                        <p>The vast majority of serious malware&nbsp;<a href="https://software.imdea.org/~juanca/papers/malsource_raid16.pdf">over the past 30 years</a>&nbsp;has been written in Assembly or compiled languages such as C, C++, and Delphi. However, ever-increasing over the past decade, a large amount of malware has been written in interpreted languages, such as Python. The low barrier to entry, ease of use, rapid development process, and massive library collection has made Python attractive for millions of developers- including malware authors. Python has quickly become a standard language in which threat actors create Remote Access Trojans (RATs), information stealers, and vulnerability exploit tools. As&nbsp;<a href="https://www.techrepublic.com/article/python-is-eating-the-world-how-one-developers-side-project-became-the-hottest-programming-language-on-the-planet/">Python continues to grow radically in popularity</a>&nbsp;and the&nbsp;<a href="https://research.checkpoint.com/2019/malware-against-the-c-monoculture/">C malware monoculture</a>&nbsp;continues to be challenged, it would seem only certain that Python will be increasingly utilized as malware in cyber attacks.</p>

<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth.jpg" alt="" width="770" height="660" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth.jpg 770w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth-300x257.jpg 300w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/python_growth-768x658.jpg 768w" sizes="(max-width: 770px) 100vw, 770px"></p>
<p><span>Image Source: Stack Overflow</span></p>

<p>In comparison to a standard compiled language like C, writing malware in Python comes with a whole host of difficulties. The first being that Python is required to be installed on the operating system in order to interpret and execute Python code. However, as we’ll see in the next section, a Python program can easily be converted into a native executable using a variety of different methods.</p>
<p>Malware written in Python will also have adverse effects on file size, memory footprint, and processing power. Serious malware is often designed to be small, stealthy, have low memory footprint, and use limited processing power. A compiled malware sample written in C might be 200 KB, while a comparable malware sample written in Python might be 20 MB after converted into an executable. Both the CPU &amp; RAM usage will also be significantly higher when using an interpreted language.</p>
<p>However, it’s 2020 and the digital landscape isn’t what it once was. The internet is faster than it’s ever been, our computers have more memory &amp; storage capacity than ever, and CPUs get faster every year. Python is also more ubiquitous than ever, coming pre-installed on macOS and most all Linux distributions by default.</p>

<p>Microsoft Windows is still the primary target for most malicious campaigns, and it does not come with Python installed by default. Therefore, for threat actors to distribute their malware effectively they must convert their Python code into an executable format. There are many methods to “compile Python” into a native executable. Let’s take a look at the few most popular methods…</p>
<h3>PyInstaller</h3>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller.png" alt="" width="500" height="100" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller.png 500w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/pyinstaller-300x60.png 300w" sizes="(max-width: 500px) 100vw, 500px"></p>

<p><a href="https://www.pyinstaller.org/">PyInstaller</a>&nbsp;is capable of building Python applications into stand-alone executables for Windows, Linux, macOS and more by “freezing” Python code. It is one of the most popular methods to convert Python code into executable format and has been used widely for both legitimate and malicious purposes.</p>
<p>Let’s create a simple “Hello, world!” program in Python and freeze it into a stand-alone executable using PyInstaller:</p>
<pre><code>$ cat hello.py
print('Hello, world!')

$ pyinstaller --onefile hello.py
...

$ ./dist/hello 
Hello, world!

$ file dist/hello 
dist/hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=294d1f19a085a730da19a6c55788ec08c2187039, stripped

$ du -sh dist/hello 
7.0M    dist/hello
</code></pre>
<p>This process created a portable, stand-alone Linux ELF (Executable and Linkable Format) which is the equivalent to an EXE on Windows. Now let’s create and compile a “Hello, world!” program in C on Linux for comparison:</p>
<pre><code>$ cat hello.c
#include &lt;stdio.h&gt;
int main() {
    printf("Hello, world!");
}

$ gcc hello.c -o hello

$ ./hello 
Hello, world!

$ file hello
hello: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=480c7c75e09c169ab25d1b81bd28f66fde08da7c, for GNU/Linux 3.2.0, not stripped

$ du -sh hello
20K hello
</code></pre>
<p>Notice how much larger the file size is: 7 MB (Python) vs 20 KB (C)! This demonstrates the major drawback we discussed previously about file size and memory usage. The Python executable is so much larger due to the fact it must bundle the Python interpreter (as a shared object file on Linux) inside the executable itself in order to run.</p>
<h3>py2exe</h3>
<p><a href="https://www.py2exe.org/">Py2exe</a>&nbsp;is another popular method to convert Python code into Windows EXE (executable) format that can be run natively. Similar to PyInstaller, it bundles the Python interpreter with your Python code to make a portable executable. Py2exe is likely to fall out of style with time as it has not been supported past Python 3.4, this is due to&nbsp;<a href="https://docs.python.org/3/whatsnew/3.6.html#cpython-bytecode-changes">the bytecode in CPython being heavily changed in Python 3.6 and beyond</a>.</p>
<p>Py2exe utilizes distutils and requires a small&nbsp;<code>setup.py</code>&nbsp;script to be created to produce an executable. Let’s create an example “Hello, world!” executable using py2exe:</p>
<pre><code>&gt; type hello.py
print('Hello, world!')

&gt; type setup.py
import py2exe
from distutils.core import setup
setup(
    console=['hello.py'],
    options={'py2exe': {'bundle_files': 1, 'compressed': True}},
    zipfile=None
)

&gt; python setup.py py2exe
...

&gt; dist\hello.exe
Hello, world!
</code></pre>
<p>The&nbsp;<code>hello.exe</code>&nbsp;created by py2exe is similar in size to PyInstaller coming in at 6.83 MB.</p>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe.png" alt="" width="369" height="508" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe.png 369w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/hello_exe-218x300.png 218w" sizes="(max-width: 369px) 100vw, 369px"></p>
<h3>Nuitka</h3>
<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/nuitka.png" alt="" width="120" height="24"></p>
<p><a href="https://nuitka.net/">Nuitka</a>&nbsp;is perhaps the most underutilized, and yet more advanced method of compiling Python code to an executable. It translates Python code into a C program that then is linked against libpython to execute code the same as CPython. Nuitka can use a variety of C compilers including gcc, clang, MinGW64, Visual Studio 2019+, and clang-cl to convert your Python code to C.</p>
<p>Let’s create a “Hello, world!” Python program on Linux and compile it using Nuitka:</p>
<pre><code>$ cat hello.py
print('Hello, world!')

$ nuitka3 hello.py
...

$ ./hello.bin
Hello, world!

$ file hello.bin 
hello.bin: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=eb6a504e8922f8983b23ce6e82c45a907c6ebadf, for GNU/Linux 3.2.0, stripped

$ du -sh hello.bin
432K    hello.bin
</code></pre>
<p>Nuitka produced a portable binary very simply, and at 432 KB is a fraction of the size of what PyInstaller or py2exe can produce! How is Nuitka able to do this? Let’s take a look at the build folder:</p>
<pre><code>$ cloc hello.build/
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
C                               11           2263            709           8109
C/C++ Header                     1              1              0              7
-------------------------------------------------------------------------------
SUM:                            12           2264            709           8116
-------------------------------------------------------------------------------
</code></pre>
<p>Nuitka produced over 8,000 lines of C code from our 1 line Python program. The way Nuitka works is it actually translates the Python modules into C code and then uses libpython and static C files of its own to execute in the same way as CPython does.</p>
<p>This is very impressive, and it seems highly likely the Nuitka “Python compiler” will see further adoption as time goes on. As we’ll see later, Nuitka might have a further, built-in advantage in protection against Reverse Engineering (RE). There already exist several tools to easily analyze binaries produced by PyInstaller and py2exe to recover Python source code. However, by Nuitka translating the Python code to C it is much more difficult to reverse engineer.</p>

<p><img src="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools.png" alt="" width="557" height="383" srcset="https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools.png 557w, https://www.cyborgsecurity.com/wp-content/uploads/2020/07/tools-300x206.png 300w" sizes="(max-width: 557px) 100vw, 557px"></p>
<p>Python malware can take advantage of a massive ecosystem of open-source Python packages and repositories. Almost anything you could think of, someone has already built it using Python. This is a huge advantage to malware authors as simplistic capabilities can be cherry-picked from the open web and more complex capabilities likely don’t need to be written from scratch.</p>
<p>Let’s take a look at three simple, yet powerful tool examples:</p>
<ol>
<li>Code Obfuscation</li>
<li>Taking Screenshots</li>
<li>Performing Web Requests</li>
</ol>
<h3>Tool Example 1 – Obfuscation</h3>
<p>Malware authors using Python have many libraries they could use to obfuscate their Python code to make code readability much more difficult, such as:&nbsp;<a href="https://github.com/liftoff/pyminifier">pyminifier</a>&nbsp;and&nbsp;<a href="https://github.com/dashingsoft/pyarmor">pyarmor</a>.</p>
<p>Here’s a small example of how&nbsp;<code>pyarmor</code>&nbsp;can obfuscate Python code:</p>
<pre><code>$ cat hello.py 
print('Hello, world!')

$ pyarmor obfuscate hello.py
...

$ cat dist/hello.py
from pytransform import pyarmor_runtime
pyarmor_runtime()
__pyarmor__(__name__, __file__, b'\x50\x59\x41\x52\x4d\x4f\x52\x00\x00\x03\x08\x00\x55\x0d\x0d\x0a\x04\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x40\x00\x00\x00\xd5\x00\x00\x00\x00\x00\x00\x18\xf4\x63\x79\xf6\xaa\xd7\xbd\xc8\x85\x25\x4e\x4f\xa6\x80\x72\x9f\x00\x00\x00\x00\x00\x00\x00\x00\xec\x50\x8c\x64\x26\x42\xd6\x01\x10\x54\xca\x9c\xb6\x30\x82\x05\xb8\x63\x3f\xb0\x96\xb1\x97\x0b\xc1\x49\xc9\x47\x86\x55\x61\x93\x75\xa2\xc2\x8c\xb7\x13\x87\xff\x31\x46\xa5\x29\x41\x9d\xdf\x32\xed\x7a\xb9\xa0\xe1\x9a\x50\x4a\x65\x25\xdb\xbe\x1b\xb6\xcd\xd4\xe7\xc2\x97\x35\xd3\x3e\xd3\xd0\x74\xb8\xd5\xab\x48\xd3\x05\x29\x5e\x31\xcf\x3f\xd3\x51\x78\x13\xbc\xb3\x3e\x63\x62\xca\x05\xfb\xac\xed\xfa\xc1\xe3\xb8\xa2\xaa\xfb\xaa\xbb\xb5\x92\x19\x73\xf0\x78\xe4\x9f\xb0\x1c\x7a\x1c\x0c\x6a\xa7\x8b\x19\x38\x37\x7f\x16\xe8\x61\x41\x68\xef\x6a\x96\x3f\x68\x2b\xb7\xec\x60\x39\x51\xa3\xfc\xbd\x65\xdb\xb8\xff\x39\xfe\xc0\x3d\x16\x51\x7f\xc9\x7f\x8b\xbd\x88\x80\x92\xfe\xe1\x23\x61\xd0\xf1\xd3\xf8\xfa\xce\x86\x92\x6d\x4d\xd7\x69\x50\x8b\xf1\x09\x31\xcc\x19\x15\xef\x37\x12\xd4\xbd\x3d\x0d\x6e\xbb\x28\x3e\xac\xbb\xc4\xdb\x98\xb5\x85\xa6\x19\x11\x74\xe9\xab\xdf', 1)

$ python dist/hello.py
Hello, world!
</code></pre>

<h3>Tool Example 2 – Screenshots</h3>
<p>Information stealing malware will often come with the capability to take screenshots of the users desktop in order to steal sensitive …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cyborgsecurity.com/python-malware-on-the-rise/">https://www.cyborgsecurity.com/python-malware-on-the-rise/</a></em></p>]]>
            </description>
            <link>https://www.cyborgsecurity.com/python-malware-on-the-rise/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824689</guid>
            <pubDate>Mon, 13 Jul 2020 19:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Igalia's open prioritization experiment for contributing to browsers]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23824505">thread link</a>) | @staktrace
<br/>
July 13, 2020 | http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html | <a href="https://web.archive.org/web/*/http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
  <article>
  
  <p>Jul 13, 2020</p>
  <p>As many web platform developer and Firefox users, I believe <a href="https://www.mozilla.org/en-US/mission/">Mozilla’s mission</a> is instrumental for a better Internet. In a recent <a href="https://www.igalia.com/chats/ecosystem-health">Igalia’s chat about the Web Ecosystem Health</a>, participants made the usual observation regarding this important role played by Mozilla on the one hand and the limited development resources and small Firefox’s usage share on the other hand. In this blog post, I’d like to explain an experimental idea we are launching at Igalia to try and make browser development better match the interest of the web developer and user community.</p>

<p><a href="https://www.igalia.com/open-prioritization/">
    <img src="http://frederic-wang.fr/images/open-prioritization.png" width="750" height="255" alt="Open Prioritization by Igalia. An experiment in crowd-funding prioritization.">
  </a>
</p>

<h2 id="igalias-contribution-to-browser-repositories">Igalia’s contribution to browser repositories</h2>

<p>As mentioned in the past in this blog, Igalia has contributed to different part of Firefox such as multimedia (e.g. &lt;video&gt; support), layout (e.g. Stylo, WebRender, CSS, MathML), scripts (e.g. BigInt, WebAssembly) or accessibility (e.g. ARIA). But is it enough?</p>

<p>Although commit count is an imperfect metric it is also one of the easiest to obtain. Let’s take a look at how Igalia’s commits repositories of the Chromium (chromium, v8), Mozilla (mozilla-central, servo, servo-web-render) and WebKit projects were distributed last year:</p>

<figure>
  <img width="374" height="305" src="http://frederic-wang.fr/images/distribution-of-igalia-commits-2019.png" alt="pie chart">
  <figcaption><small>Diagram showing, the distribution of Igalia's contributions to browser repositories in 2019 (~5200 commits). Chromium (~73%), Mozilla (~4%) and WebKit (~23%).</small>
  </figcaption>
</figure>

<p>As you can see, in absolute value Igalia contributed roughly 3/4 to Chromium, 1/4 to WebKit, with a small remaining amount to Mozilla. This is not surprising since Igalia is a consulting company and our work depends on the importance of browsers in the market where Chromium dominates and WebKit is also quite good for iOS devices and embedded systems.</p>

<p>This suggests a different way to measure our contribution by considering, for each project, the percentage relative to the total amount of commits:</p>

<figure>
  <img width="436" height="339" src="http://frederic-wang.fr/images/igalia-commit-percentage-per-project-2019.png" alt="Bar graph">
  <figcaption><small>Diagram showing, for each project, the percentage of Igalia's commits in 2019 relative to the total amount of the project. From left to right:
  Chromium (~3.96%), Mozilla (~0.43%) and WebKit (~10.92%).</small>
  </figcaption>
</figure>

<p>In the WebKit project, where ~80% of the contributions were made by Apple, Igalia was second with ~10% of the total. In the Chromium project, the huge Google team made more than 90% of the contributions and many more companies are involved, but Igalia was second with about 4% of the total. In the Mozilla project, Mozilla is also doing ~90% of the contributions but Igalia only had ~0.5% of the total. Interestingly, the second contributing organization was… the community of unindentified gmail.com addresses! Of course, this shows the importance of volunteers in the Mozilla project where a great effort is done to encourage participation.</p>

<h2 id="open-prioritization">Open Prioritization</h2>

<p>From the commit count, it’s clear Igalia is not contributing as much to the Mozilla project as to Chromium or WebKit projects. But this is expected and is just reflecting the priority set by large companies. The solid base of Firefox users as well as the large amount of volunteer contributors show that the Mozilla project is nevertheless still attractive for many people. Could we turn this into browser development that is not funded by advertising or selling devices?</p>

<p>Another related question is whether the internet can really be shaped by the global community as defended by the Mozilla’s mission? Is the web doomed to be controlled by big corporations doing technology’s “evangelism” or lobbying at standardization committees? Are there prioritization issues that can be addressed by moving to a more collective decision process?</p>

<p>At <a href="https://www.igalia.com/about/">Igalia</a>, we internally try and follow <a href="https://wingolog.org/tags/cooperatives">a more democratic organization</a> and, at our level, intend to make the world a better place. Today, we are launching a new <a href="https://www.igalia.com/open-prioritization/">Open Prioritization</a> experiment to verify whether crowdfunding could be a way to influence how browser development is prioritized. Below is a short (5 min) <a href="https://www.youtube.com/embed/xCRxNVbUqhk">introductory video</a>:</p>

<iframe width="850" height="508" src="https://www.youtube.com/embed/xCRxNVbUqhk" frameborder="0" allowfullscreen=""></iframe>

<p>I strongly recommend you to take a look at the proposed projects and <a href="https://www.igalia.com/open-prioritization/#faq">read the FAQ</a> to understand how this is going to work. But remember <em>this is an experiment</em> so we are starting with a few ideas that we selected and tasks that are relatively small. We know there are tons of user reports in bug trackers and suggestions of standards, but we are not going to solve everything in one day !</p>

<p>If the process is successful, we can consider generalizing this approach, but we need to test it first, check what works and what doesn’t, consider whether it is worth pursuing, analyze how it can be improved, etc</p>

<h2 id="two-crowdfunding-tasks-for-firefox">Two Crowdfunding Tasks for Firefox</h2>

<figure>
  <img src="https://upload.wikimedia.org/wikipedia/commons/0/06/CIELAB_color_space_top_view.png" alt="CIELAB color space*">
  <figcaption><small>Representation of the CIELAB color space (top view)
  <a href="https://commons.wikimedia.org/wiki/File:CIELAB_color_space_top_view.png">by Holger Everding, under CC-SA 4.0</a>.</small>
  </figcaption>
</figure>

<p>As explained in the previous paragraph, we are starting with small tasks. For Firefox, we selected the following ones:</p>

<ul>
  <li>
    <p>CSS <code>lab()</code> colors. This is about giving web developers a way to express colors using the <a href="https://en.wikipedia.org/wiki/CIELAB_color_space">CIELAB color space</a> which approximates better the human perception. My colleague Brian Kardell wrote a <a href="https://bkardell.com/blog/Unlocking-Colors.html">blog with more details</a>. Some investigations have been made by <a href="https://bugs.webkit.org/show_bug.cgi?id=205675">Apple</a> and <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1026287">Google</a>. Let’s see what we can do for Firefox !</p>
  </li>
  <li>
    <p>SVG path <code>d</code> attribute. This is about expressing <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1571119">SVG path using the corresponding CSS syntax</a> for example <code>&lt;path style="d: path('M0,0 L10,10,...')"&gt;</code>. This will likely involve a refactoring to use the same parser for both SVG and CSS paths. It’s a small feature but part of a more general <a href="https://www.youtube.com/watch?v=1d--S_wgAJA">convergence effort between SVG and CSS</a> that Igalia has been involved in.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Is this crowd-funded experiment going to work? Can this approach solve the prioritization problems or at least help a bit? How can we improve that idea in the future?…</p>

<p>There are many open questions but we will only be able to answer them if we have enough people participating. I’ll personally pledge for the two Firefox projects and I invite you to at least take a look and decide whether there is something there that is interesting for you. Let’s try and see!</p>

</article>


</div></div>]]>
            </description>
            <link>http://frederic-wang.fr/igalia-contribution-to-mozilla-and-open-prioritization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824505</guid>
            <pubDate>Mon, 13 Jul 2020 19:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Every Developer Should Start Blogging]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824478">thread link</a>) | @Sandeepg33k
<br/>
July 13, 2020 | https://lo-victoria.com/why-every-developer-should-start-blogging-ckcga7ulq007tkes13frydqnz | <a href="https://web.archive.org/web/*/https://lo-victoria.com/why-every-developer-should-start-blogging-ckcga7ulq007tkes13frydqnz">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Hello everyone! Hashnode has proudly launched the #2Articles1Week challenge! How exciting! To commemorate the start of this challenge, I'm dedicating this post to Hashnode and the fellow writers on this platform who are also partaking in this challenge! </p>
<p>Note: All articles I'm writing during this 4-week challenge will be under the <a target="_blank" rel="noopener noreferrer" href="https://hashnode.com/series/2articles1week-challenge-ckcdmmffj001efzs1fodo0rbi">#2Articles1Week Challenge Series</a>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594482149929/Eh8cIHqKA.png?auto=format&amp;q=60" alt="2a1w.png"></p>
<p>If you haven't already, I strongly encourage you to please participate in the challenge! Learn more about it <a target="_blank" rel="noopener noreferrer" href="https://hashnode.com/2Articles1week">here</a>.</p>
<h2 id="why-i-decided-to-start-blogging">Why I decided to start blogging</h2>
<p>For this special post, I just want to reflect on why I started blogging and why every developer should start blogging. Every writer/ blogger has their own reasons to start writing but here's mine.</p>
<h3 id="-motivation-"><strong>Motivation</strong></h3>
<p>At some point in time, I reached that developer's plateau where I'm uncertain on which new technology/skill I wanted to acquire and what direction I'm heading. So I tried to get started with React but without a structured syllabus and deadlines, it was difficult to stay focused and committed to learning it every day. I felt like I needed an outlet for <strong>accountability</strong> as well as a platform to <strong>reinforce my learning</strong>.</p>
<p>In terms of non-programming reasons, I like reading books and I especially like to <strong>pen down my thoughts and reflections</strong> on the insights I have gained from reading. My OneNote got so full of my "reading notes"...</p>
<p>It was then I decided to blog. I have always written journals in my childhood, so I thought a blog is basically like an online journal. My reason was that simple.</p>
<blockquote>
<p>Then why not just record your learning in your physical book journal?</p>
</blockquote>
<p>I chose blogging because unlike a book journal, I wanted something <strong>more accessible</strong> that I can read from anywhere and <strong>would never disappear</strong>. I have written over 10 books of journals in my childhood and unfortunately lost all of them from moving a lot. I don't want the same outcome for my learning journal.</p>
<p>Plus, learning from others and gaining valuable feedback is the best way to learn something quickly. So having a blog achieves the following for me:</p>
<ul>
<li><strong>Accountability:</strong> It's like keeping a physical journal. Having a blog makes me want to constantly write on it. So it makes me learn without losing focus.</li>
<li><strong>Monitor/Reinforce Learning:</strong> Writing down what I've learnt is how I like to check my learning progress and reinforce core concepts.</li>
<li><strong>Accessibility:</strong> Always there and never disappear.</li>
<li><strong>Feedback from others:</strong> Learning from the community, sharing knowledge and gain insights.</li>
</ul>
<h3 id="-first-steps-i-did-"><strong>First Steps I did</strong></h3>
<p>To commit to logging what I've learned every day, I took the #100DaysofCode challenge and told people around me that I am doing the challenge. I find that it is easier to stay on track after you've publicly announced your plan of action to your peers, family or friends.</p>
<p>So, my blogging journey began. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594231182027/jUKSMZY5J.png?auto=format&amp;q=60" alt="1.png">
<em>Source: My Nintendo Switch (Pokemon Shield)</em></p>
<h2 id="why-you-should-blog-learning-outcomes-gains-">Why you should blog (Learning Outcomes + Gains)</h2>
<h3 id="-1-communication-"><strong>1. Communication</strong></h3>
<p>By communication, I mean the ability to <strong>articulate information in a clear, well-organized and concise manner</strong> (orally and written).</p>
<p>Initially, my blog on Medium was intended for 1 audience: myself. It was easy to write in a way that only I would understand (because I am me haha). But once I started seeing more people reading my articles, I found myself having to express my thoughts more clearly, organize my writing for better flow and explain ideas more simply.</p>
<p>If you think you are a terrible writer right now, all the more reason to start blogging. That means you will learn a lot from writing. Don't be afraid of showing your work to others because the community is full of wonderful people who are willing to proofread your articles and help you. In time, you will notice improvements in your written communication skills. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594233127088/3wqKKrg54.jpeg?auto=format&amp;q=60" alt="1.jpg">
<em>Source: <a href="https://pbs.twimg.com/media/CnVdEPSVYAAocDI.jpg" target="_blank">pbs.twimg.com/media/CnVdEPSVYAAocDI.jpg</a></em></p>
<blockquote>
<p>"All good writing begins with terrible first efforts. You need to start somewhere." - Anne Lammot</p>
</blockquote>
<h3 id="-2-time-management-"><strong>2. Time Management</strong></h3>
<p>Time management is about <strong>effectively optimizing time to accomplish productive tasks</strong>. When I started blogging, I realized that I have to allocate some time during the day to do it, which means I spend less time on procrastinating and other distractions. </p>
<p>To balance my work and my blogging, I had to <strong>learn how to manage my time</strong> quickly. I found what works for me and what doesn't. For example, I tried to be a morning person and blog early in the morning before work - but I ended up snoozing my alarm every time... Now I learned that blogging midday to evenings works for me best. I can stay focused during those times better. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594249248243/_kuCenfmt.gif?auto=format,compress&amp;gif-q=60" alt="1.gif"></p>
<p>Each person has his/her own time management strategies. For me, it is <strong>planning my day</strong> ahead and <strong>prioritizing</strong> which tasks to accomplish first. Focusing on what I want to achieve at the end of the day is how I often organize my short-term priorities.</p>
<blockquote>
<p>"Focus is not saying yes to all important things, rather it is saying no to less important things." - Steve Jobs</p>
</blockquote>
<h3 id="-3-get-rid-of-perfectionism-"><strong>3. Get Rid of Perfectionism</strong></h3>
<p>I was quite a perfectionist before I started blogging. I held myself to very high standards which in turn, <strong>made me fear to start writing</strong> because I'll be unable to publish an article. It was an arduous journey for me to finally accept that <strong>nothing is perfect</strong> and that I would rather practice my writing on 10 different articles rather than working towards 1 "perfect" article for who knows how long.</p>
<p>Blogging helps me to shift away from my perfectionist tendencies and put more focus into continuous self-improvement by writing more and practising my skills as I go. <strong>Progress over perfection</strong>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594249748562/_x-tMYUtz.jpeg?auto=format&amp;q=60" alt="2.jpg">
<em>Source: <a href="https://i0.wp.com/dariusforoux.com/wp-content/uploads/2016/09/IMG_0058.jpg?fit=2048%2C1536&amp;ssl=1" target="_blank">i0.wp.com/dariusforoux.com/wp-content/uploa..</a></em></p>
<blockquote>
<p>"Perfectionism doesn't make you feel perfect; it makes you feel inadequate." - Maria Shriver</p>
</blockquote>
<h3 id="-4-learning-from-others-"><strong>4. Learning from Others</strong></h3>
<p>The most valuable lesson from blogging is learning from others. I like to receive <strong>constructive feedback</strong> from my readers because it must have some important insight/detail that I didn't notice before. It also <strong>validates my understanding</strong> on a certain topic. Making a mental note of the feedback helps me grow as a developer and writer. Of course, if the feedback is very subjective (i.e. personal preferences in style, etc.), I allow myself to ignore it since I have my own writing style that I am comfortable with.</p>
<p>Another way I learn from others by blogging is <strong>reading other's blogs</strong> in the community. Everyone has their own experiences and knowledge to share. By reading blogs with a newer or deeper knowledge on certain topics than my own, I get to learn, reflect and get inspired from their insights!</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1594250331664/a2R5UKXH2.png?auto=format&amp;q=60" alt="3.png"></p>
<blockquote>
<p>"It takes a wise man to learn from his mistakes but an even wiser man to learn from others." - Chinese Proverb</p>
</blockquote>
<h3 id="-5-personal-brand-"><strong>5. Personal Brand</strong></h3>
<p>Each article you publish will reflect you as an extension of your skills, knowledge, interests, thoughts and values. Hence, by writing, you are essentially creating and building your personal brand. </p>
<p>As a developer, having a personal brand can help you:</p>
<ul>
<li>Build reputation and credibility</li>
<li>Share your knowledge and projects for feedback</li>
<li>Increase visibility in the job market</li>
<li>Make new connections with people in the same industry</li>
</ul>
<blockquote>
<p>"We are CEOs of our own companies: Me Inc. To be in business today, our most important job is to be head marketer for the brand called You." - Tom Peters, Writer</p>
</blockquote>
<h2 id="how-to-start">How to Start</h2>
<h3 id="find-your-reason">Find your reason</h3>
<p>Whether it is recording your journey of learning/building something or sharing your passion on a certain subject, find a <strong>strong intrinsic reason</strong> to start or else your resolve will not last long.</p>
<h3 id="be-your-own-audience">Be Your Own Audience</h3>
<p>Ask yourself: <strong>Would you want to read this?</strong></p>
<p>If yes, then you have your first audience! Your job is to write for yourself, and eventually, as your writing gets better, you'll gain more readers. Most likely, people with similar interests or in the same field as you would be your readers too.</p>
<h3 id="consistency">CONSISTENCY</h3>
<p>This one is critical. You want to <strong>keep your blog as up-to-date</strong> as possible. You don't have to blog every day but once a week or so maintains a healthy habit to write. </p>
<p>It is always harder to start than to continue something. Once you stopped writing for a long time, it will be even more difficult to get back to writing. </p>
<h3 id="have-fun-">Have Fun!</h3>
<p>Don't feel pressured to come up with the most unique topics or the most engaging piece every time you want to write about a topic. Just <strong>enjoy the process of writing</strong> itself! Have fun and <strong>stay true to writing what you like</strong>. Remember, you are your own audience. If you like it, there will be people who appreciate your work too!</p>
<blockquote>
<p>"You don't have to be great to start, but you have to start to be great." - Zig Zaglar</p>
</blockquote>
<h2 id="thanks-for-reading-">Thanks for reading!</h2>
<p>I appreciate you for taking the time to read this far. Please like and share this article to encourage more aspiring writers to start! If you are a new blogger on Hashnode and planning to do the #2Articles1Week challenge, please leave your blog url in the comments below. I would love to check out your articles! </p>
<p>Alternatively, you can connect with me on <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/lo_victoria2666">Twitter</a> and share your articles with me there! I hope you'll join and enjoy the #2Articles1Week challenge! Cheers!</p>
</div></div>]]>
            </description>
            <link>https://lo-victoria.com/why-every-developer-should-start-blogging-ckcga7ulq007tkes13frydqnz</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824478</guid>
            <pubDate>Mon, 13 Jul 2020 19:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Subscribing to RethinkDB Record Changes in Go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824404">thread link</a>) | @aspleenic
<br/>
July 13, 2020 | https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/ | <a href="https://web.archive.org/web/*/https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5926">
	
	
	<div>
		
<p><a href="https://rethinkdb.com/">RethinkDB</a>&nbsp;is a document storage database with excellent clustering capabilities. However it can also&nbsp;<strong>auto notify when records are updated in real-time</strong>, and this article is going to explore how to do that using&nbsp;<a href="https://golang.org/">Go</a>.</p>



<div><figure><img src="https://jah.io/content/images/2020/05/Untitled.svg" alt="" width="718" height="179"><figcaption><a href="https://rethinkdb.com/">RethinkDB</a>&nbsp;is a document storage database with real-time record pub/sub capabilities.</figcaption></figure></div>



<h2>What is RethinkDB?</h2>



<p>RethinkDB is a document storage database with a lot of really nice modern features, like multiple nodes joining a cluster and automatically rebalancing and re-sharding data among themselves when that data changes. In this article though, we’ll be exploring the&nbsp;<code>changes</code>&nbsp;feature, so we can get automatic updates when something in the data for any given row, or even a whole table, gets changed.</p>



<figure><img src="https://jah.io/content/images/2020/05/Screen-Shot-2020-05-22-at-3.39.34-PM.png" alt=""><figcaption>The RethinkDB Data Explorer/Dashboard</figcaption></figure>



<p>A few details about RethinkDB at a glance:</p>



<ul><li>Written in C++</li><li>Default ports:<ul><li>28015 for client drivers (command execution)</li><li>29015 for inter-cluster communication</li><li>8080 for admin dashboard</li></ul></li><li>Config file location<ul><li>MacOS:&nbsp;<code>$BREW_HOME/etc/rethinkdb.conf</code></li><li>Linux (Ubuntu, from RethinkDB’s apt):&nbsp;<code>/etc/rethinkdb/instances.d/&lt;HOSTNAME&gt;.conf</code></li><li>Windows: I have no idea, good luck with that 🙂</li></ul></li></ul>



<h3>Didn’t RethinkDB die years ago?</h3>



<p>You might have heard back in 2016 that the RethinkDB project shut down. That’s true: it did. The company behind it essentially ran out of money. Then something miraculous happened: the open source community picked it up and carried it forward, eventually&nbsp;<a href="https://rethinkdb.com/blog/rethinkdb-joins-linux-foundation">joining the Linux Foundation in 2017</a>&nbsp;and as of this writing (May 2020) has multiple well-known sponsors. So the idea that RethinkDB is a “dead” project is just “dead” wrong.</p>



<figure><img src="https://jah.io/content/images/2020/05/Screen-Shot-2020-05-22-at-4.28.36-PM.png" alt=""><figcaption><a href="https://rethinkdb.com/blog/rethinkdb-joins-linux-foundation">RethinkDB Joined the Linux Foundation in 2017</a>&nbsp;and presently has users including NASA along with sponsors like Digital Ocean, Atlassian and Netlify.</figcaption></figure>



<h2>Install RethinkDB</h2>


<pre title="">$ brew install rethinkdb
</pre>


<p>On other platforms, make use of the&nbsp;<a href="https://rethinkdb.com/docs/install/">installation directions at rethinkdb.com</a>.</p>



<h3>Configure RethinkDB</h3>



<p>Now let’s edit the default configuration. On MacOS, you’ll find this under your&nbsp;<code>brew</code>&nbsp;directory,&nbsp;<code>etc/rethinkdb.conf</code>. In this code example below, I’ve done a&nbsp;<code>grep</code>&nbsp;on my own configuration for any line that’s&nbsp;<em>not</em>&nbsp;commented; you can see the values for the corresponding configuration directives here.</p>


<pre title="">$ grep "^[^#]" /Users/jah/.brew/etc/rethinkdb.conf
directory=/Users/jah/.brew/var/rethinkdb
log-file=/Users/jah/.rethinkdb.log
bind=all
canonical-address=nova.local
server-name=nova.local
</pre>


<p>You can set the directory and log file to wherever you want as long as you have write access to that location on disk.&nbsp;<code>bind=all</code>&nbsp;is highly recommended so you can access RethinkDB at either&nbsp;<code>localhost</code>&nbsp;or&nbsp;<code>127.0.0.1</code>&nbsp;or your network IP address. Finally, my machine is specified in multicast DNS as&nbsp;<code>nova.local</code>, so put your hostname here as well so you can have other clients connect by hostname instead of internal IP address.</p>



<p>Next, on MacOS, use&nbsp;<code>brew services</code>&nbsp;to start and monitor RethinkDB:</p>


<pre title="">$ brew services start rethinkdb
$ brew services list
rethinkdb         started jah  /Users/jah/Library/LaunchAgents/homebrew.mxcl.rethinkdb.plist
</pre>


<p>If you installed RethinkDB on Ubuntu using their apt repository, it should already be running and monitored. Try running&nbsp;<code>systemctl rethinkdb</code>&nbsp;to view its status.</p>



<p>If you’re on another platform, try the&nbsp;<a href="https://rethinkdb.com/docs/install/">installation instructions at the RethinkDB website.</a></p>



<h2 id="let-s-write-some-code">Let’s Write Some Code</h2>



<p>To use RethinkDB with Go, we’re going to use the&nbsp;<a href="https://gopkg.in/rethinkdb/rethinkdb-go.v6">rethinkdb-go</a>&nbsp;database driver (source code available on&nbsp;<a href="https://github.com/rethinkdb/rethinkdb-go/tree/v6.2.1">GitHub</a>). You can see its full API documentation&nbsp;<a href="https://godoc.org/gopkg.in/rethinkdb/rethinkdb-go.v6">here</a>.</p>



<p>Side note: You might want to use&nbsp;<a href="https://code.visualstudio.com/">Visual Studio Code</a>&nbsp;with the&nbsp;<a href="https://github.com/golang/vscode-go">Go extension</a>&nbsp;installed. The extension is excellent, and provides “intellisense” while writing Go code so you can see what types a function returns, how many arguments it returns and what they are, etc. Highly recommended.</p>



<figure><img src="https://jah.io/content/images/2020/05/Screen-Shot-2020-05-22-at-4.37.47-PM.png" alt=""></figure>



<h3 id="create-the-tv_shows-table">Create the tv_shows&nbsp;Table</h3>



<p>Let’s get started. Create a file:&nbsp;<code>go.mod</code>. We’re going to populate it with the following to get started:</p>


<pre title="">module github.com/jahio/rethinkdb-go
</pre>


<p>Yep, just one line. This is our module definition that tells Go where our code will eventually live and what it’ll be called. (Feel free to rename it to whatever GitHub repository you’ll store yours in.)</p>



<p>Now, add another file:&nbsp;<code>main.go</code>:</p>


<pre title="">package main

import (
	"log"

	r "gopkg.in/rethinkdb/rethinkdb-go.v6"
)

func main() {
	log.SetFlags(0)

	rdbOpts := r.ConnectOpts{
		Address: "localhost:28015",
	}

	rconn, err := r.Connect(rdbOpts)
	checkError(err)

	err = r.DB("test").TableCreate("tv_shows").Exec(rconn)
	checkError(err)
}

func checkError(err error) {
	if err != nil {
		log.Println(err)
		return
	}
}
</pre>


<p>In this file, we’re importing&nbsp;<a href="http://gopkg.in/rethinkdb/rethinkdb-go.v6">gopkg.in/rethinkdb/rethinkdb-go.v6</a>&nbsp;as our RethinkDB database driver and renaming it to&nbsp;<code>r</code>&nbsp;in our code for convenience sake, which you can see kick in around line 12.</p>



<p>The first thing we do is set our connection options for RethinkDB. In this case, we create a new variable,&nbsp;<code>rdbOpts</code>, based on the&nbsp;<code>rethinkdb</code>&nbsp;package’s&nbsp;<code>ConnectOpts</code>&nbsp;struct with an&nbsp;<code>Address</code>&nbsp;property set to&nbsp;<code>localhost:28015</code>. This the default location and port; if you changed either one of those (maybe you’re running RethinkDB on another machine), update this accordingly.</p>



<p>Next, we connect to RethinkDB with that options object and check for an error if the connection failed. After that, we run a query:</p>


<pre title="">err = r.DB("test").TableCreate("tv_shows").Exec(rconn)
</pre>


<p>Here we’re method chaining a pseudo&nbsp;<a href="https://rethinkdb.com/api/">RQL</a> query to RethinkDB. We start with&nbsp;<code>r</code>, the RethinkDB driver module, then tell it what database to use with&nbsp;<code>DB("test")</code>.</p>



<p>Note that RethinkDB sets up a table for every new installation called “test” which you can use to test out queries and just generally experiment with.&nbsp;<strong>Never store permanent data in this table.</strong></p>



<p>Next, we call&nbsp;<code>TableCreate("tv_shows")</code>.&nbsp;<code>TableCreate</code>&nbsp;is the Golang equivalent of&nbsp;<code>tableCreate</code>&nbsp;in RQL and JavaScript, or&nbsp;<code>table_create</code>&nbsp;in Ruby. They all do the same thing: create a table with the string passed in. In our case, this is&nbsp;<code>tv_shows</code>. We’ll use some good shows here (shows I happen to like) to demonstrate how this works.</p>



<p>Finally, we call&nbsp;<code>Exec(rconn)</code>&nbsp;here to tell RethinkDB to execute the command&nbsp;<em>over the&nbsp;<code>rconn</code>&nbsp;connection.</em>&nbsp;Passing the connection to the&nbsp;<code>Run()</code>&nbsp;or&nbsp;<code>Exec()</code>&nbsp;functions is a necessary step every time, and may throw you an error if you forget to do it (and trust me, you’ll forget here and there).</p>



<p>Now let’s run the code. In a terminal, cd into the directory you have this code in and run&nbsp;<code>go run main.go</code>. This will compile the program and run it, thus creating your table.</p>



<p>To verify you’ve created the table successfully, check it out in the&nbsp;<a href="http://localhost:8080/">RethinkDB Console</a>:</p>



<figure><img src="https://jah.io/content/images/2020/05/Screen-Shot-2020-05-28-at-3.02.54-PM.png" alt=""><figcaption>Access the&nbsp;<a href="http://localhost:8080/">RethinkDB Console</a>&nbsp;at&nbsp;<a href="http://localhost:8080/">http://localhost:8080</a>&nbsp;and look for the&nbsp;<code>tv_shows</code>&nbsp;table.</figcaption></figure>



<p><a href="https://github.com/jahio/rethinkdb-subscribe-go/commit/3ed16af9a8b11af0254daea34c187563eec1585b#diff-7ddfb3e035b42cd70649cc33393fe32c">View the code at this point in the tutorial on GitHub.</a></p>



<h3 id="add-some-tv_shows">Add some tv_shows</h3>



<p>Now that the table has been created, let’s add a few shows to it. First, download&nbsp;<a href="https://github.com/jahio/rethinkdb-subscribe-go/blob/master/shows.json">this JSON file</a>&nbsp;and save it in the same directory as&nbsp;<code>main.go</code>, calling it&nbsp;<code>shows.json</code>. Next, modify the code above to look like this:</p>


<pre title="">package main

import (
	"encoding/json"
	"fmt"
	"io/ioutil"
	"log"

	r "gopkg.in/rethinkdb/rethinkdb-go.v6"
)

type show struct {
	Name     string    `json:"name" gorethink:"name"`
	Genre    string    `json:"genre" gorethink:"genre"`
	Website  string    `json:"website" gorethink:"website"`
	Episodes []episode `json:"episodes" gorethink:"episodes"`
}

type episode struct {
	Name    string `json:"name" gorethink:"name"`
	Summary string `json:"summary" gorethink:"summary"`
}

func main() {
	log.SetFlags(0)

	rdbOpts := r.ConnectOpts{
		Address: "localhost:28015",
	}

	rconn, err := r.Connect(rdbOpts)
	checkError(err)

	// Make sure you have shows.json in the same directory as this file.
	file, err := ioutil.ReadFile("shows.json")
	checkError(err)

	var shows []show
	err = json.Unmarshal(file, &amp;shows)
	checkError(err)

	result, err := r.Table("tv_shows").Insert(shows).RunWrite(rconn)
	checkError(err)
	printObj(result)

}

func checkError(err error) {
	if err != nil {
		log.Println(err)
		return
	}
}

func printObj(v interface{}) {
	vBytes, err := json.Marshal(v)
	checkError(err)
	fmt.Println(string(vBytes))
}
</pre>


<p>Now, run the code again in a terminal with&nbsp;<code>go run main.go</code>.</p>



<p>To walk through the changes here, first we’ve created two new types, Show and Episode, both of which are&nbsp;<code>struct</code>s. This is so we can serialize the data in the JSON file and insert it into the database later.</p>



<p>Next, we use&nbsp;<code>ioutil</code>&nbsp;to read the contents of&nbsp;<code>shows.json</code>, then we use the&nbsp;<code>json</code>&nbsp;package to&nbsp;<code>Unmarshal</code>&nbsp;(convert from JSON to objects) that payload of data into instances of those structs we mentioned earlier. Then we insert those structs into RethinkDB by passing that slice directly to the driver:</p>


<pre title="">result, err := r.Table("tv_shows").Insert(shows).RunWrite(rconn)
checkError(err)
printObj(result)
</pre>


<p>Note: Using the&nbsp;<code>rethinkdb-go</code>&nbsp;driver, you use&nbsp;<code>RunWrite</code>&nbsp;to&nbsp;<strong>write&nbsp;</strong>information to the database,&nbsp;<code>Run</code>&nbsp;to&nbsp;<strong>read&nbsp;</strong>information from the database, and&nbsp;<code>Exec</code>&nbsp;to simply run a command that you need no output for, like creating a table or an index.</p>



<p>Then we’re using the new&nbsp;<code>printObj()</code>&nbsp;function to print the result of that insertion operation as JSON out on the console. What’s that look like, you might ask?</p>


<pre title="">{
  "Errors":0, "Inserted":2, "Updated":0, "Unchanged":0, 
  "Replaced":0, "Renamed":0, "Skipped":0, "Deleted":0, 
  "Created":0, "DBsCreated":0, "TablesCreated":0, "Dropped":0, 
  "DBsDropped":0, "TablesDropped":0, 
  "GeneratedKeys":
  [
    "c9461b23-14af-4c47-8aaa-bff62957486f",
    "10e81779-3b5b-413d-9e27-dbc1af9d4089"
  ], 
  "FirstError":"", "ConfigChanges":null, "Changes":null
}
</pre>


<p>From the returned data, we can get a lot of information. First of all, we see that two records were inserted, and nothing was deleted, created, or threw errors (all of which are good signs). Perhaps more importantly, we see the unique IDs (UUIDs) the database assigned to our new objects in the&nbsp;<code>GeneratedKeys</code>&nbsp;field.</p>



<p>You’ll probably note that we didn’t specify these IDs. RethinkDB generates those for us automatically, and in fact may complain when …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/">https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/</a></em></p>]]>
            </description>
            <link>https://blog.joshsoftware.com/2020/06/14/subscribing-to-rethinkdb-record-changes-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824404</guid>
            <pubDate>Mon, 13 Jul 2020 19:10:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of Data Websites and Portfolios in 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824399">thread link</a>) | @fazlerocks
<br/>
July 13, 2020 | https://www.kamwithk.com/the-state-of-data-websites-and-portfolios-in-2020-develop-a-dashboard-in-a-day-dash-vs-streamlit-and-is-javascript-still-king-ckckn2lib00egf6s1eupt0wgv | <a href="https://web.archive.org/web/*/https://www.kamwithk.com/the-state-of-data-websites-and-portfolios-in-2020-develop-a-dashboard-in-a-day-dash-vs-streamlit-and-is-javascript-still-king-ckckn2lib00egf6s1eupt0wgv">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Having a visual product, website or dashboard to show what your arduous efforts on a coding/machine learning project amounted to is something truly spectacular!
Yet, it's often extremely difficult as numerous tools and technologies are usually required.
Don't stress though, we'll discuss and compare <strong>two frameworks</strong> (Dash and Streamlit) which make it <strong>simple and easy to create an impressive portfolio</strong> (without a steep learning curve)!</p>

<p>You just created a machine learning model.
It took a long time, but  <em>it's finally done</em>, and you want to take in your victory for a second.
You deserve a break... but wise old you knows the importance of creating a monument to show off your work.</p>
<p>You take the <em>natural next step</em>, looking up how to build a website.
They begin with Python frameworks like Flask and Django, then proceed to JavaScript and before long you're stuck contemplating which front-end framework to use, and how you'll parse the data between the Python back-end (model) and JavaScript front-end (actual website).
Oh, boy... this is a long and dark rabbit hole to scurry through.
But then out of the blue, you hear that there is an <em>easy solution for simple websites</em>.
You look up this new shinny framework (Streamlit), and it sure is easy 😊 and quick to use.
Before long you've forgotten all your troubles and insecurities!
But then you suddenly realise Streamlit's catch... it only works for <em>simple Jupyter notebook-esk websites</em>.
It's all aboard the web dev train again for you.
Requests and JavaScript, here you come 😰.</p>
<p><strong>It doesn't have to be that way though</strong>... you <em>can find middle ground</em>.
Something simple enough to be understood in a few days, but complex enough... well, for nearly anything 🤓!
Welcome to Dash.
You still need to know a few web fundamentals (HTML and CSS), but at least your development journey has a clearly defined path ahead.
Even if it feels slightly clunky, it does get the job done well enough!</p>
<p><strong>The whole process can be dumbed down to three decisions</strong>:</p>
<ol>
<li>What you want on the page (text, graphs, tables, images, etc)</li>
<li>How to arrange and style the page (using CSS)</li>
<li>How you want the user to interact with the page</li>
</ol>
<p>No JavaScript, HTTP requests or even multiple separate frameworks for the front and back end any more!</p>

<p>To get started, make sure you have Dash installed.
With plain vanilla Python use <code>pip install dash</code> and for Anaconda <code>conda install -c conda-forge dash</code>.
Next, create a new Python file and import the relevant libraries:</p>
<pre><code><span>import</span> dash
<span>import</span> dash_core_components <span>as</span> dcc
<span>import</span> dash_html_components <span>as</span> html
</code></pre>
<p>If you try and run the app so far, you'll notice one thing - nothing happens.
That's because we actually have to create a Dash app object and tell it to start.</p>
<pre><code>app = dash.Dash(__name__, external_stylesheets=[<span>"https://codepen.io/chriddyp/pen/bWLwgP.css"</span>])
app.title = <span>"Allocate++"</span>

<span>if</span> __name__ == <span>"__main__"</span>:
    app.run_server(debug=<span>True</span>)
</code></pre>
<p>We can include a style sheet (CSS using <code>external_stylesheets</code>) and set our website's title (<code>app.title</code>) to make things look better.
Checking that <code>__name__ == "__main__"</code> just ensures that the website only launches when directly started (not when imported in another file).</p>
<p>If we try to run this code, in the terminal we'll get a message like:</p>
<pre><code>Running <span>on</span> http:<span>//</span><span>127.0</span><span>.0</span><span>.1</span>:<span>8050</span>/
Debugger PIN: <span>409</span><span>-929</span><span>-250</span>
 * Serving Flask app <span>"Main"</span> (lazy loading)
 * Environment: production
   WARNING: This <span>is</span> a development server. Do <span>not</span> use it <span>in</span> a production deployment.
   Use a production WSGI server instead.
 * Debug mode: <span>on</span>
Running <span>on</span> http:<span>//</span><span>127.0</span><span>.0</span><span>.1</span>:<span>8050</span>/
Debugger PIN: <span>791</span><span>-028</span><span>-264</span>
</code></pre><p>It indicates that your app has started and can be found using the URL <code>http://127.0.0.1:8050/</code>.
Although it's currently just a blank page (real <em>fancy-schmancy</em>), it does indicate that everything is working fine.</p>
<p>Once you're ready to progress, try adding in a heading:</p>
<pre><code>app.layout = html.H1(children=<span>"Fancy-Schmancy Website"</span>)
</code></pre>
<p>After you save the file, that website should automatically reload.
If it hasn't reloaded, or there are popups on the screen, you probably have an error in the source code.
Just check the actual terminal/debugger for more information.</p>
<p>Now that you're familiar with how to get a basic website, let's move onto transitioning your concept into code.
It starts with what's called a layout, which is composed of components.
Dash provides core (<code>dash_core_components</code>) and HTML (<code>dash_html_components</code>) components.
You always start using the HTML elements, since they provide the basic building blocks for text and grouping components together, before moving onto the core components.
Core components offer more interactivity (graphs, tables, check box's...).
It's now natural to ask, how to style the web page.
In short, you use CSS (cascading style sheets) for this.
Dash themselves provide concrete overviews of <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/dash-core-components">core components</a> and trusty Mozilla have an amazing <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/HTML_basics">HTML</a> and <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/CSS_basics">CSS</a> intro.
Several examples of how to use the elements are <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/layout">here</a>.</p>
<p>The last part of any Dash app is making it responsive.
Getting the buttons you click, text you enter and images you upload... do something!
This is where things would normally get difficult, but here it really <em>isn't too bad</em>.
With Dash, all you've got to define is a function which receives and controls specific element/s properties.
<em>Properties</em> start with the "@" symbol.</p>
<pre><code><span>@app.callback(</span>
    [dash.dependencies.Output(<span>"output element id"</span>, <span>"property to set value of"</span>)],
    [dash.dependencies.Input(<span>"input element id"</span>, <span>"input property"</span>)]
)
<span><span>def</span> <span>update_output</span><span>(value)</span>:</span>
       <span>return</span> value
</code></pre>
<p>We can do this for multiple elements by adding more <code>Input</code> and <code>Output</code> objects to those lists!
One thing to watch out for here though - more <code>Input</code> objects means more inputs to the function are required, and more <code>Output</code> objects mean more values to return (sounds obvious, but it can easily slip your mind). 
Also, note that you <em>shouldn't modify global variables</em> within these functions (this for technical reasons is an antipattern).
Further documentation is provided on these <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/basic-callbacks">callbacks</a>.</p>

<p>There it is, everything you'll need to know to start creating an interactive and impressive web application!
It'll likely still be difficult to create one, but the official documentation and tutorials for <a target="_blank" rel="noopener noreferrer" href="https://docs.streamlit.io/en/stable/getting_started.html">Steamlit</a> and <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/">Dash</a> are amazing.
There are also cool galleries of sample apps using <a target="_blank" rel="noopener noreferrer" href="https://dash-gallery.plotly.host/Portal/">Dash</a> and <a target="_blank" rel="noopener noreferrer" href="https://www.streamlit.io/gallery">Streamlit</a> (so you can learn from others examples).</p>
<p>Of course, there are use cases for JavaScript.
In fact, you can build plugins for Dash with <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/plugins">JavaScript/React</a> and <a target="_blank" rel="noopener noreferrer" href="https://dash.plotly.com/d3-react-components">D3.js</a>.
Hell, if you are already comfortable with web technologies it may even be easier for you to use them.
However, using JavaScript <strong>isn't 100% necessary to build websites</strong> any more (it's more so optional).
It may be useful to know about web technologies, but if your aim isn't to become a full-stack web developer, you don't need to become an expert to put together a flashy portfolio 🥳!</p>
<p>I hope this has helped you out!
Dash helped me hack together <a target="_blank" rel="noopener noreferrer" href="https://github.com/KamWithK/AllocatePlusPlus">my first dashboard</a> in a day.
If you've made a cool website, app or portfolio make sure to comment and tell me about them.
Feel free to check out my other posts - some highlights are <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/the-complete-coding-practitioners-handbook-ck9u1vmgv03kg7bs1e5zwit2z?guid=34cbed9b-13ac-43c7-94a3-dbfe4ac247a9&amp;deviceId=a348da4b-4d6e-44a9-80b2-3456c05bf4d0">practical coding tools</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/zero-to-hero-data-collection-through-web-scraping-ck78o0bmg08ktd9s1bi7znd19">web scrapping</a> and <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/machine-learning-field-guide-ckbbqt0iv025u5ks1a7kgjckx">machine learning</a> (with the <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/machine-learning-energy-demand-prediction-project-part-1-data-cleaning-ckc5nni0j00edkss13rgm75h4">practical project</a>).
You can follow my <a target="_blank" rel="noopener noreferrer" href="https://www.kamwithk.com/">newsletter</a> and <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/kamwithk_">Twitter</a> for updates 😉.</p>
<p><em>Photo by Luke Peters on <a target="_blank" rel="noopener noreferrer" href="https://unsplash.com/photos/B6JINerWMz0">Unsplash</a></em></p>
</div></div>]]>
            </description>
            <link>https://www.kamwithk.com/the-state-of-data-websites-and-portfolios-in-2020-develop-a-dashboard-in-a-day-dash-vs-streamlit-and-is-javascript-still-king-ckckn2lib00egf6s1eupt0wgv</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824399</guid>
            <pubDate>Mon, 13 Jul 2020 19:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Introduction to JavaScript Map, Filter and Reduce Methods]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824381">thread link</a>) | @fazlerocks
<br/>
July 13, 2020 | https://blog.nemotivity.xyz/a-brief-introduction-to-javascript-map-filter-and-reduce-methods-ckck648il00df57s122yn0eub | <a href="https://web.archive.org/web/*/https://blog.nemotivity.xyz/a-brief-introduction-to-javascript-map-filter-and-reduce-methods-ckck648il00df57s122yn0eub">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1594624222999/ZFFuUffXV.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text">

<p>Arrays are important Data Structures in programming. All the methods which we are going to discuss in this article will iterate over an array and return a new array based on the result function we define. The results we'll get here can also be achieved using loops, but it'll make the code more lengthy.</p>

<p>We use the <code>map()</code> method to create a new array from an existing one by applying a function to each of the elements in the array. </p>
<h3 id="syntax">Syntax</h3>
<pre><code>array.map(<span><span>function</span>(<span>currentValue, index, arr</span>), <span>thisValue</span>)</span>
</code></pre>
<p>In the arguments, we can execute the function by passing only the <code>currentValue</code> also. Let's see an example</p>
<h3 id="example">Example</h3>
<pre><code><span>const</span> array = [<span>3</span>, <span>6</span>, <span>9</span>, <span>12</span>];
<span>const</span> square = array.map((item) =&gt; item * item);
<span>console</span>.log(square);
</code></pre>
<p>In the above example, we created a new array named <code>square</code> by passing only the <code>currentValue</code>. Now, if we wanted to write the same square function with imperative style, the code will look something like this,</p>
<pre><code><span>const</span> numbers = [<span>3</span>, <span>6</span>, <span>9</span>, <span>12</span>];
<span>const</span> square = (numbers) =&gt; {
  <span>let</span> newArray = [];
  <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; numbers.length; i++) {
    newArray.push(numbers[i] * numbers[i]);
  }
  <span>return</span> newArray;
};
<span>console</span>.log(square(numbers)); 
</code></pre>
<p>We can clearly see how much longer is this method. We can shorten the code by using <code>forEach</code> but it'll also be larger than using the <code>map</code> method.</p>
<p>To learn more about the <code>map()</code> method, you can check the article <a target="_blank" rel="noopener noreferrer" href="https://www.geeksforgeeks.org/javascript-array-map-method/">here</a>.</p>

<p>As the name suggests, the <code>filter()</code> method is used to filter items of an array based on a certain condition. </p>
<h3 id="syntax">Syntax</h3>
<pre><code>array.filter(callback(element, index, arr), thisValue)
</code></pre>
<p>The <code>filter()</code> method basically takes each element of the array and applies the specific condition we define. If the element satisfies the condition then the item is pushed to a new array.</p>
<h3 id="example">Example</h3>
<p>We'll try to return an array which filters odd numbers from an given array. In declarative approach we would write something like, </p>
<pre><code><span>const</span> arr = [<span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>];
<span>const</span> odds = arr.filter((i) =&gt; i % <span>2</span> !== <span>0</span>);
<span>console</span>.log(odds); 
</code></pre>
<p>Now, if we try to get the same result using the imperative way, we have to write something like this,</p>
<pre><code><span>const</span> odds = (arr) =&gt; {
  <span>let</span> oddArray = [];
  <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; arr.length; i++) {
    <span>if</span> (arr[i] % <span>2</span> !== <span>0</span>) {
      oddArray.push(arr[i]);
    }
  }
  <span>return</span> oddArray;
};
<span>console</span>.log(odds(arr)); 
</code></pre>
<p>Which shows how much more code we need to achieve the same result.</p>
<p>To know more about the method, you can check this <a target="_blank" rel="noopener noreferrer" href="https://www.geeksforgeeks.org/javascript-array-filter-method/">article</a>.</p>

<p>The <code>reduce</code> method is the least used among the three methods we are discussing here. This method reduces a whole array into a single value and returns it. </p>
<h3 id="syntax">Syntax</h3>
<pre><code>arr.reduce(callback[, initialValue])
</code></pre>
<p>Let's see the reduce function in action</p>
<h3 id="example">Example</h3>
<p>Suppose we want to add the items of an array. We are taking this example because the function will return only a single value. To implement this using  the <code>reduce()</code> method, we can write the code like this,</p>
<pre><code><span>const</span> arr = [<span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>];
<span>const</span> sum = arr.reduce((result, item) =&gt; {
  result = result + item;
  <span>return</span> result;
});
<span>console</span>.log(sum); 
</code></pre>
<p>It's literally two lines of code. Now, the same code using a for loop will look like this,</p>
<pre><code><span>const</span> sum = (arr) =&gt; {
  <span>let</span> result = <span>0</span>;
  <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; arr.length; i++) {
    result = result + arr[i];
  }
  <span>return</span> result;
};
<span>console</span>.log(sum(arr)); 
</code></pre>
<p>To know more about the <code>reduce()</code> method, you can check the article <a target="_blank" rel="noopener noreferrer" href="https://www.geeksforgeeks.org/javascript-array-reduce-method/">here</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I hope this article gave you an idea about the JavaScript <code>map()</code>, <code>filter()</code>, and <code>reduce()</code> method. The links of the articles provided below each of the methods will give you a more in-depth knowledge of each method.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.nemotivity.xyz/a-brief-introduction-to-javascript-map-filter-and-reduce-methods-ckck648il00df57s122yn0eub</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824381</guid>
            <pubDate>Mon, 13 Jul 2020 19:08:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planting a Tree for Every In-App Subscription]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824342">thread link</a>) | @CyberSkys
<br/>
July 13, 2020 | https://snapsearch.online/announcements/commitment-to-the-environment/ | <a href="https://web.archive.org/web/*/https://snapsearch.online/announcements/commitment-to-the-environment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>By building Snap Search, I made a commitment to try my best to provide a safe way for everyone to search the web. However, I’ve also learnt that each of us have more responsibilities in life – one such being a commitment to the environment.</p> <figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1024x484.jpg" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1024x484.jpg" alt="One Tree Planted Snap Search" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1024x484.jpg 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-300x142.jpg 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-768x363.jpg 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1536x725.jpg 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1160x548.jpg 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_106/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-106x50.jpg 106w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-650x307.jpg 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1000x472.jpg 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-50x24.jpg 50w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1800/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted.jpg 1800w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1024x484.jpg 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-300x142.jpg 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-768x363.jpg 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1536x725.jpg 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1160x548.jpg 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_106/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-106x50.jpg 106w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-650x307.jpg 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-1000x472.jpg 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted-50x24.jpg 50w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1800/https://snapsearch.online/wp-content/uploads/2020/07/snapsearch-onetreeplanted.jpg 1800w"></figure><p>I am not going to try to preach about why it’s necessary. Instead I am going to assume that it’s obvious by now and you understand it already. Alone, I probably cannot make enough of a difference – but with your support, we together can make a lot of impact! <strong>YOU</strong> can make a difference.</p><h2>Our Commitment to the Environment:</h2><p>Starting with August, Snap Search is going to plant one tree for every subscription/purchase of Snap Search premium. We plan to do this with the help of <a href="https://onetreeplanted.org/" target="_blank" rel="noreferrer noopener">OneTreePlanted</a>.</p><p>For example:</p><ul><li>Subscriptions/Purchases (including renewals): 100</li><li>Number of trees planted: 100</li></ul><p>Snap Search was not created for profit, and the only reason premium mode even exists is to bare the costs of services and to support further development (read about it <a href="https://snapsearch.online/general/why-should-i-pay-for-premium-mode-of-snap-search/">here</a>). Using the revenue generated for an amazing purpose like this seems like the right thing to do. My sincere hope is that together we plant many many trees each month.</p><p>Thank you for being a user! Also, don’t forget to leave us a nice review/rating on the <a href="https://play.google.com/store/apps/details?id=cybersky.snapsearch">Play Store</a> if you haven’t already 😁</p></div></div></div>]]>
            </description>
            <link>https://snapsearch.online/announcements/commitment-to-the-environment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824342</guid>
            <pubDate>Mon, 13 Jul 2020 19:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Managing Burnout in Startups]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824291">thread link</a>) | @calhat
<br/>
July 13, 2020 | https://www.spill.chat/burnout/burnout-symptoms | <a href="https://web.archive.org/web/*/https://www.spill.chat/burnout/burnout-symptoms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><span>2<!-- -->min read</span></p><p>To know how to manage burnout, you must first know how to recognise it.</p><div><div emoji="🤔"><p><span>🤔</span></p><p><span>I want to understand the psychology</span></p></div><div emoji="✏️"><p><span>✏️</span></p><p><span>I want some practical tools to use</span></p></div></div><h2><span id="burnout-definition">Burnout definition</span></h2><p>Burnout is not a standalone mental health diagnosis, though the World Health Organisation does recognise it as a type of occupational hazard in its own right.</p><p>Burnout is also not depression, even if many of its symptoms overlap. Most notably, burnout is not just being a bit tired or even very tired, from normal everyday workplace stress.</p><p>Burnout is a debilitating affliction normally defined as a triad of emotions occurring together: <strong>exhaustion, negativity, and ineffectiveness</strong>.</p><p>Basically, if Tom is burned out, his work will feel to him simultaneously arduous and unimportant. Every working day, he'll feel irritable, tired, cynical, short-tempered, slow, and about as sharp as a broken pencil. He'll look around at people and fail to understand why they look so animated. Everything will seem far, far away. He'll feel sad, indeed crushed, as if something critical and very deep inside him had simply... given up. In so far as he can think at all, he'll think "what's the point" and "I can't do this" and he will feel, because he'll <em>be</em>, broken.</p><p>Burnout is to humans what sand is for gears: if it doesn't exactly bring the whole system to a halt, it will noticeably decrease its performance.</p><div><p><span>💡</span></p><p>Burnout can look and feel a lot like depression, but is purely associated with work and the symptoms don’t go as far.</p></div><p><span>
      <span></span>
  <img alt="Burnout depression tiredness venn diagram" title="Burnout depression tiredness venn diagram" src="https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/f0628/burnout-depression-tiredness-venn-diagram.png" srcset="https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/8c2ab/burnout-depression-tiredness-venn-diagram.png 300w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/3f01f/burnout-depression-tiredness-venn-diagram.png 600w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/f0628/burnout-depression-tiredness-venn-diagram.png 1200w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/57025/burnout-depression-tiredness-venn-diagram.png 1800w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/8252b/burnout-depression-tiredness-venn-diagram.png 2400w,https://www.spill.chat/static/8ecfeb1e285e23b6e6f22a68e1ab7709/7d015/burnout-depression-tiredness-venn-diagram.png 4283w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
    </span></p><h2><span id="employee-burnout-symptoms">Employee burnout symptoms</span></h2><p>This decreased performance is the second thing that everyone in Tom's team will notice, including his manager. (The first will be his disheveled look of chronic exhaustion.) The third thing they'll notice, consciously or unconsciously, will be his increased and marked negativity.</p><p>In short, while Tom is feeling exhausted, hopeless, and overwhelmed, others will see him as lethargic, cynical, and stupider than before. His team will feel confused, worried, irritated, inconvenienced, and eventually demoralised.</p><p>It’s also worth watching out for the kind of phrases you might hear Tom saying, either in passing or in one-to-ones. These phrases are typical of someone going through burnout.</p><table><thead><tr><th>Burnout Symptom</th><th>💛 Employee feels</th><th>💬 Employee says</th><th>👀 Manager spots...</th></tr></thead><tbody><tr><td>Fatigue</td><td>Exhausted (I'm tired, exhausted, unfocused)</td><td>"I just feel so tired all the time"</td><td>Lethargy (Low energy, slow, quiet, withdrawn)</td></tr><tr><td>Negativity</td><td>Hopeless (I'm bad, the world is bad, my future is bleak)</td><td>"I can't see a way out of this"</td><td>Cynicism (Hopeless, downbeat, critical, quick to see the worst)</td></tr><tr><td>Ineffectiveness</td><td>Powerless (I can't win at this game)</td><td>"I just don't care anymore"</td><td>Slowdown (Less switched on, missing things)</td></tr></tbody></table><h2><span id="burnout-symptoms-test">Burnout symptoms test</span></h2><p>Because burnout isn’t a medical condition, there’s no official ‘yes or no’ diagnosis. However, the Maslach Burnout Index is the most widely used tool for assessing burnout severity. We’ve condensed it down to three questions for a quicker version.</p><hr></article></div>]]>
            </description>
            <link>https://www.spill.chat/burnout/burnout-symptoms</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824291</guid>
            <pubDate>Mon, 13 Jul 2020 18:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will the Horvath Epigenetic Clock Help Us Reverse Aging?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824258">thread link</a>) | @mehdiyac
<br/>
July 13, 2020 | https://www.mehdiyacoubi.com/post/horvath-clock | <a href="https://web.archive.org/web/*/https://www.mehdiyacoubi.com/post/horvath-clock">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.3"><div dir="ltr"><div><p id="viewer-foo"><em>Scientists developed a new way to measure biological age and finally help us find what really rejuvenates us</em></p><div id="viewer-b8qne"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.mehdiyacoubi.com/post/horvath-clock" data-pin-media="https://static.wixstatic.com/media/a27d24_2b252ab3ddeb4cc99ea61da57c4bc369~mv2.jpeg/v1/fit/w_4000,h_2630,al_c,q_80/file.png" src="https://static.wixstatic.com/media/a27d24_2b252ab3ddeb4cc99ea61da57c4bc369~mv2.jpeg/v1/fit/w_300,h_300,al_c,q_5/file.jpeg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-9agtr">Remember your grandma telling you orange juice is healthy and good for you? It will make you strong and help you fight the winter flu!</p><p id="viewer-efm44">Orange juice is a good example of something that many of us believed (or still believe) healthy <a href="https://www.nytimes.com/2018/07/07/opinion/sunday/juice-is-not-healthy-sugar.html" target="_top" rel="noopener"><u>but is not</u></a>.</p><p id="viewer-b8ui9">Today there is an increasing focus on increasing lifespan and healthspan. Health advice is everywhere. They aim at helping us live the healthiest and longest life possible. But how helpful they really are?</p><p id="viewer-ddklf">Some people will tell you a Vegan diet is the best solution for your health. Others will say the exact opposite and promote eating only beef. You may think studies could help figure out who is right and who is wrong. But you would be wrong on that one. Just watch the Joe Rogan Experiment about the <a href="https://www.youtube.com/watch?v=s0zgNY_kqlI" target="_top" rel="noopener"><u>Game Changers</u></a> Documentary.</p><p id="viewer-3gmfs">People, even scientists, are more and more dogmatic about their knowledge. For many of them, there will always be a reason to explain why a study that contradicts their beliefs is wrong: industry-funded, not enough participants, questionable study design, “correlation doesn’t mean causation”, not enough parameters measured… you name it!</p><p id="viewer-f3386">Just like many other aspects of the public debate, science is getting more about identity and less about facts.</p><p id="viewer-c4o50">This is a real problem because people are starting to be lost in the ocean of health-related advice. They came to find ways to be healthier and in better shape, and they leave lost and not knowing what to do.</p><p id="viewer-62pic">This may change soon with a clear measure of <em>how well</em> your body is aging.</p><h2 id="viewer-cn1i"><strong>The longevity approach</strong></h2><p id="viewer-dr26j">Over the last century, we managed to <a href="https://ourworldindata.org/life-expectancy" target="_top" rel="noopener"><u>double</u></a> the lifespan, from 35 years old to more than 70 today. We did incredible progress at making people live longer. But the additional years are usually not healthy years.</p><p id="viewer-d23cc">When you want to do something to promote your health and longevity, in most cases you will start practices that improve a proxy for longevity. For example, you will start exercising because it will make your cardiovascular system in better shape, and this is associated with better longevity. You are not directly targeting your longevity but you are targeting something that is correlated with delayed aging.</p><p id="viewer-7j7hf">Until now, we didn’t have the means to measure directly how something is affecting longevity.</p><p id="viewer-1ljmf">In 2013, Steve Horvath, a professor at UCLA, developed a new kind of clock: an <a href="https://en.wikipedia.org/wiki/Epigenetic_clock" target="_top" rel="noopener"><u>epigenetic clock</u></a>. It took a few years to go from the concept to an actual product that can be used, but it’s finally here.</p><h2 id="viewer-8k5or"><strong>What is an Epigenetic Clock?</strong></h2><p id="viewer-d0ecs">First, we have to understand what the epigenome is. David Sinclair, a Professor in the Department of Genetics at Harvard Medical School, used a great analogy in his book <a href="https://lifespanbook.com/" target="_top" rel="noopener"><u>Lifespan</u></a>: Why We Age and Why We Don’t Have To:</p><blockquote id="viewer-fi7kp"><p><em>“If the genome were a computer, the epigenome would be the software. It instructs the newly divided cells on what type of cells they should be”. He then explains: “Without epigenetic information, cells would quickly lose their identity and new cells would lose their identity, too. If they did, tissues and organs would eventually become less and less functional until they failed”.</em></p></blockquote><p id="viewer-c4ilj">Horvath developed the epigenetic clock by using DNA methylation (a process by which methyl groups are added to the DNA molecule and that can change the activity of a DNA segment without changing the sequence) to accurately predict age.</p><p id="viewer-6ftti">The Horvath clock is really powerful because it gives a complementary measure of age that is, according to this <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5076441/" target="_top" rel="noopener"><u>study</u></a>, “ associated with age-related health outcomes above and beyond chronological age. For example, we and others have shown that individuals whose epigenetic age was greater than their chronological age (i.e., individuals exhibiting epigenetic “age acceleration”) were at an increased risk for death from all causes”.</p><p id="viewer-bbsv8">After all, the chronological age is just a number, it doesn’t take into consideration the molecular mechanisms happening in your body. This is why some people look 20 years younger and some others look 20 years older than their age.</p><p id="viewer-42aet"><em>Let’s dive a little bit in the theory to understand why this clock can predict aging and longevity better the chronological age.</em></p><h2 id="viewer-64nlv"><strong>The Information Theory of Aging</strong></h2><p id="viewer-6icgg">In his book Lifespan, Pr. David Sinclair explains what he calls the “Information Theory of Aging”. He explains that what leads to aging is a loss of information. He uses an analogy with the Information Theory of Communication from Claude Shannon: the compact disc that is our genome gets damaged over time such as cells can’t read the right genes (the epigenome) at the right time.</p><p id="viewer-t5ju">In addition to that, Pr. Sinclair explains that we always keep a backup copy of the original placement of the methyl groups on the epigenome. In an <a href="https://peterattiamd.com/davidsinclair2/" target="_top" rel="noopener"><u>interview</u></a> with Dr. Peter Attia, Sinclair explains:</p><blockquote id="viewer-6v9pm"><p><em>“But what I think exists in cells and we have some evidence is that, like Shannon suggested for the internet or information, is that if you have a backup copy… and now going back to the genome… there seems to be something in cells that tells them these methyl groups, the programs that were laid down when you were a baby are still there and cells can access that somehow to say: ‘All these other things that have happened since you were born or since you were a teenager, that’s just noise… Ignore that.’” -David Sinclair, Ph.D</em></p></blockquote><p id="viewer-blo2">This opens a completely new horizon on the perspectives of delaying the onset of aging.</p><h2 id="viewer-lov2"><strong>What will that change?</strong></h2><p id="viewer-59ppn">This new theory of aging and the Horvath clock is a huge step forward in the field of aging and longevity. The Information Theory of Aging presents aging as a disease in itself, like any other one. If we can manage to limit the loss of information, this disease will be delayed, potentially for years, decades or even more.</p><p id="viewer-6cre4">But how useful is this theory if we don’t have a way to measure the rate of aging? That’s exactly what the Horvath clock enables us to do now and it will be used by both scientists and the general public to get feedback on how an intervention affects the biological age.</p><h2 id="viewer-en8ov"><strong>For scientists</strong></h2><p id="viewer-7pjtr">The identification of compounds and activities that promotes health and longevity was always limited by the lack of non-invasive metrics that can predict the life expectancy of the subjects of the study. With the Horvath clock, scientists now have a way to measure aging and find cures and lifestyle interventions to delay aging.</p><h2 id="viewer-5ns1l"><strong>For you</strong></h2><p id="viewer-b7nsr">Health and longevity depend on so many parameters, so even if science is getting better at understanding the mechanisms promoting longevity, it will never be sure that those findings apply perfectly to <em>you.</em> Because that’s what interests you, right? A given diet may benefit 90 percent of the population, but you might be in those last 10 percent. A HIIT workout may be one of the best tools for longevity but it may leave you feeling awful. You get the point — certain things must be adapted to your body and your lifestyle. Hence, the Horvath clock could be used as an indicator of how you are doing in your quest to delay aging. If you measure it once a year, for example, you can witness if your epigenetic clock is slower than your chronological one. This will tell you that your lifestyle is good regarding longevity.</p><p id="viewer-3tksn">Now let’s get into some longevity-promoting practices you can try for yourself.</p><h2 id="viewer-blg5g"><strong>How to slow down aging</strong></h2><p id="viewer-7se5t">According to the prominent longevity specialists, here are some things you could try to delay the onset of aging:</p><ul><li id="viewer-d1tj4"><p><a href="https://medium.com/lifetizr/from-eating-4-meals-a-day-to-fasting-20h-aef9e9214444" target="_top" rel="noopener"><u>Fasting</u></a>: Through promoting autophagy, fasting has been shown to be good for longevity.</p></li><li id="viewer-aqlpi"><p>Exercise: In particular <a href="https://www.cell.com/cell-metabolism/comments/S1550-4131(17)30099-2" target="_top" rel="noopener"><u>HIIT training</u></a></p></li><li id="viewer-4m6c"><p>Cold: By stimulating hormesis, cold immersion, cold showers and cold stress are <a href="https://www.foundmyfitness.com/reports/cold-stress.pdf" target="_top" rel="noopener"><u>promoting</u></a> longevity.</p></li><li id="viewer-7tudn"><p>Sauna bathing: It has been <a href="https://www.ncbi.nlm.nih.gov/pubmed/25705824" target="_top" rel="noopener"><u>shown</u></a> that people having four 20 minutes sessions of Sauna per week were <a href="https://www.ncbi.nlm.nih.gov/pubmed/25705824" target="_top" rel="noopener"><u>50 percent</u></a> less likely to die from a cardio-vascular related cause</p></li></ul><p id="viewer-99hed">Today more than ever, we have the tools and the information to try things for our health and wellbeing and measure the effect on our mind and body. Adopting a proactive and preventive approach to health and longevity can help you develop essential knowledge about what works for you and what doesn’t. It’s a personal journey, a journey of trials and errors, and a journey of self-quantification, and when taken with an open mind and without dogmatic scientific beliefs can really lead to the best version of your health.</p><p id="viewer-9sn3c"><a href="https://mehdiyacoubi.substack.com/" target="_blank" rel="noopener"><u>If you'd like to receive future articles by email, and weekly updates where I share the most valuable things I've learned in the week, subscribe to my newsletter!</u></a></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.mehdiyacoubi.com/post/horvath-clock</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824258</guid>
            <pubDate>Mon, 13 Jul 2020 18:56:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Environmental Impact Disclosure – Nine9s Uptime Monitoring]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23824226">thread link</a>) | @sonicrocketman
<br/>
July 13, 2020 | https://nine9s.cloud/kb/infrastructure?ref=hn | <a href="https://web.archive.org/web/*/https://nine9s.cloud/kb/infrastructure?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<div>
  <div>
    <div>
      
      <p>Nine9s is hosted by <a href="https://www.linode.com/">Linode</a> and currently runs exclusively in their London, UK Data Center. All checks are made from there. This may change in the future if Nine9s were to implement worldwide checks.</p>
<p>You may notice slower that normal ping times reported by Nine9s. This is because, while Nine9s is developed in California, it's running an ocean away in the good ol' U.n. of K. 🇬🇧 For more information on why Nine9s isn't running in the U.S., see the section below.</p>
<h2>🌲 Nine9s and the Environment</h2>
<p><small>
💡 Nine9s emits <a href="https://nine9s.cloud/static/kb/Nine9s.cloud-Environmental-Survey.pdf">~0.115 mtCO2e per year</a> (the same as <a href="https://www.epa.gov/energy/greenhouse-gas-equivalencies-calculator">driving a typical car for 285 miles</a>).
</small></p>

<p>Since Nine9s runs on virtual servers in a crowded data center, it's hard to know the exact environmental impact of running the service. That said, by <a href="https://www.linode.com/community/questions/17513/whats-my-linodes-carbon-footprint#answer-69637">Linode's most recent estimates</a>, the energy cost of running a 4GB instance, which is what powers Nine9s today, is about 0.064 kWh/day. While this isn't much in the grand scheme of things, that would <a href="https://www.eia.gov/tools/faqs/faq.php?id=74&amp;t=11">burn approximately 21.5lbs of natural gas per year</a> (~1.4 mtCO2e). Thankfully, a few of Linode's Data Center partners have significant commitments to sustainability.</p>
<p><small>
💡 This page will be updated as Nine9s grows. Please check back for the most recent stats on Nine9s' Environmental Impact.
</small></p>

<p>While the Web isn't physical, the servers and infrastructure that power it definitely are. With the effects of Climate Change getting worse every year, Nine9s is committed to doing whatever it can to not worsen the crisis. Nine9s is hosted in London because of the fact that <a href="https://www.equinix.co.uk/data-centers/design/green-data-centers/">Equinix</a>, Linode's European provider, has <a href="https://equinix.app.box.com/embed/s/4fwyabb231nh3wpjsxca05hyyhsyt42h">committed to a 100% clean and renewable energy goal and has so far reached 92%</a>. If Nine9s needs to expand to cover more places in the world, it will expand to Linode's sustainable partners first.</p>
<hr>
<p>This data is entirely extrapolated from the sources linked by this article, but I can't guarantee that they're 100% accurate. There's a lot of layers between burning fuel and running servers on the cloud, but I've done the best I can.</p>
    </div>
  </div>
</div>

      </div></div>]]>
            </description>
            <link>https://nine9s.cloud/kb/infrastructure?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824226</guid>
            <pubDate>Mon, 13 Jul 2020 18:52:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advertising an onion service with Onion-Location]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23824214">thread link</a>) | @ramino
<br/>
July 13, 2020 | https://schu.be/til-onion-location.html | <a href="https://web.archive.org/web/*/https://schu.be/til-onion-location.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="site-content"><article><p>Many websites make themselves available through Tor as hidden services to help users preserve their privacy and circumvent blocks and censorship. A sample follows.</p><table><thead><tr><th>Clearnet domain</th><th>Onion domain</th></tr></thead><tbody><tr><td><a href="https://duckduckgo.com/">duckduckgo.com</a></td><td><a href="http://3g2upl4pq6kufc4m.onion/">3g2upl4pq6kufc4m.onion</a></td></tr><tr><td><a href="https://www.torproject.org/">www.torproject.org</a></td><td><a href="http://expyuzz4wqqyqhjn.onion/">expyuzz4wqqyqhjn.onion</a></td></tr><tr><td><a href="https://www.propublica.org/">www.propublica.org</a></td><td><a href="http://propub3r6espa33w.onion/">propub3r6espa33w.onion</a></td></tr><tr><td><a href="https://facebook.com/">facebook.com</a></td><td><a href="http://facebookcorewwwi.onion/">facebookcorewwwi.onion</a></td></tr><tr><td><a href="https://keybase.io/">keybase.io</a></td><td><a href="http://keybase5wmilwokqirssclfnsqrjdsi7jdir5wy7y7iu3tanwmtp6oid.onion/">keybase5wmilwokqirssclfnsqrjdsi7jdir5wy7y7iu3tanwmtp6oid.onion</a></td></tr><tr><td><a href="https://protonmail.ch/">protonmail.ch</a></td><td><a href="http://protonirockerxow.onion/">protonirockerxow.onion</a></td></tr><tr><td><a href="https://schu.be/">schu.be</a></td><td><a href="http://b5ec6jsfe2oyrqlt4od67bw7lyk2v77paixokjoq32xsdilvcuyeh5id.onion/">b5ec6jsfe2oyrqlt4od67bw7lyk2v77paixokjoq32xsdilvcuyeh5id.onion</a></td></tr></tbody></table><p>Until recently it has been a challenge to discover the hidden service address for any website. Some advertise their onion service in their footer (Keybase, Protonmail), but it is otherwise usually hard to find out. Thankfully the latest version of the Tor browser (version 9.5) implements <a href="https://gitweb.torproject.org/tor-browser-spec.git/tree/proposals/100-onion-location-header.txt">the Onion-Location spec</a>. As explained by the Tor Project’s <a href="https://community.torproject.org/onion-services/advanced/onion-location/">helpful explanation</a> it allows websites to use either an HTTP response header or an HTML meta tag to advertise an onion address for a website. Once set up, visitors who reach the clearnet website will be shown a nice button which redirects them to the onion service. The browser can also be configured to do this always, automatically.</p><img src="https://schu.be/assets/onion-available.png" alt="The Tor browser’s address bar, showing a URL from the Tor Project’s website and a bright button reading “.onion available”." width="693" height="38"><p>Again, this can be triggered in two ways. Either the HTTP response from the webserver includes the <em>Onion Location</em> header as follows.</p><code>Onion-Location: <span>someonionaddress.onion</span></code><p>Alternatively, the same behaviour can be obtained by adding a meta tag in the HTML document itself.</p><code>&lt;<span>meta</span><br>&nbsp;&nbsp;http-equiv=<span>"onion-location"</span><br>&nbsp;&nbsp;content=<span>"someonionaddress.onion"</span>&gt;</code><p>Of course this is now enabled on this website!</p><p><time datetime="2020-07-09">July 9, 2020</time></p></article></section></div>]]>
            </description>
            <link>https://schu.be/til-onion-location.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23824214</guid>
            <pubDate>Mon, 13 Jul 2020 18:51:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Re-Modeling a “Man Cave” into an Office (For Under $3k)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823987">thread link</a>) | @kenhara
<br/>
July 13, 2020 | https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/ | <a href="https://web.archive.org/web/*/https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I’m becoming a dad. Well, technically I’m already a dad. But our first — a baby girl! — is due in September and this means changes for our home. It also presented a once-in-a-lifetime opportunity for me to binge 140+ episodes of an ancient history podcast. More on that later.</p>



<p>When I quit a job to work for myself, my wife and I knew we had having kids on our radar. I wanted to have more free time to work on projects like this, help with childcare, go to sports practices, and generally be around as a dad. </p>



<p>Most things I did in this project, I did for the first time. Which meant doing lots of research, asking handy friends, and giving myself a lot of time. I kept track of every receipt and will share that later in the <strong>Budget</strong> section. For now, the total project budget came to: $2,934.09 — not including the cost of my time.</p>



<p>Here’s a quick look at the before and after:</p>







<h2>Before</h2>



<p>Our house is a typical <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Minimal_Traditional" target="_blank">Minimal Traditional</a> post-war build. Many of these houses were built in Denver after World War II as the city grew from ~400,000 residents to over 1 million over the course of 25 years. There are many homes like it, but this one is ours. </p>



<div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><figure><img data-attachment-id="2798" data-permalink="https://harriskenny.com/before_2/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1526730627&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.67&quot;,&quot;iso&quot;:&quot;89&quot;,&quot;shutter_speed&quot;:&quot;0.0083389999989713&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="before_2" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?w=700" srcset="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?strip=info&amp;w=600 600w,https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?strip=info&amp;w=900 900w,https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg?strip=info&amp;w=960 960w" alt="" data-height="960" data-id="2798" data-link="https://harriskenny.com/before_2/" data-url="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg" data-width="1280" src="https://harriskenny.files.wordpress.com/2020/07/before_2.jpeg"></figure></div></div></div></div>



<p>There’s this a particularly ugly “man cave” extension built onto the back. I’m not sure when it was built. The worst/best feature is the animal prints. Zoom in to the picture above and see if you can find any pheasant or deer.</p>



<p>My current office is becoming a nursery. Which means that this gem of a space is meant to be my new office. Previously it had been functioning as an exercise space (since moved that to the basement).</p>



<h2>Teardown</h2>



<div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><figure><img data-attachment-id="2770" data-permalink="https://harriskenny.com/teardown_2/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg" data-orig-size="960,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1585493485&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;32&quot;,&quot;shutter_speed&quot;:&quot;0.0060606060606061&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="teardown_2" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?w=225" data-large-file="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?w=700" srcset="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?strip=info&amp;w=600 600w,https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?strip=info&amp;w=900 900w,https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?strip=info&amp;w=1200 1200w,https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg?strip=info&amp;w=1280 1280w" alt="" data-height="1280" data-id="2770" data-link="https://harriskenny.com/teardown_2/" data-url="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg" data-width="960" src="https://harriskenny.files.wordpress.com/2020/07/teardown_2.jpeg"></figure></div></div></div></div>



<p>Good news (not pictured): There was sufficient insulation and a good foundation under the space. I didn’t find anything majorly problematic in the teardown but did see some mildew,  light water damage, and some unsightly gaps that they’d covered up with the paneling and trim.</p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><li><figure><img data-attachment-id="2777" data-permalink="https://harriskenny.com/teardown-cont-1/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1586719367&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;1000&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="teardown-cont-1" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=700" src="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=1024" alt="" data-id="2777" data-link="https://harriskenny.com/teardown-cont-1/" srcset="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-1.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img data-attachment-id="2778" data-permalink="https://harriskenny.com/teardown-cont-2/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1586979608&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;2000&quot;,&quot;shutter_speed&quot;:&quot;0.055555555555556&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="teardown-cont-2" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=700" src="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=1024" alt="" data-id="2778" data-link="https://harriskenny.com/teardown-cont-2/" srcset="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-2.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img data-attachment-id="2779" data-permalink="https://harriskenny.com/teardown-cont-3/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1587231959&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0081967213114754&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="teardown-cont-3" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=700" src="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=1024" alt="" data-id="2779" data-link="https://harriskenny.com/teardown-cont-3/" srcset="https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/teardown-cont-3.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li></ul></figure>



<p>Decided to do the drywall repair and removing the carpet and under layment in parallel. Also took out the light fixtures. Making great progress. Though tearing things down is always easier than building things up, much work to be done still.</p>



<h2>Sidebar: The History of Rome Podcast</h2>



<div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><figure><img data-attachment-id="2782" data-permalink="https://harriskenny.com/the_history_of_home-podcast-album-art/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg" data-orig-size="328,328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the_history_of_home-podcast-album-art" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=328" src="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=328" alt="" srcset="https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg 328w, https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/the_history_of_home-podcast-album-art.jpg?w=300 300w" sizes="(max-width: 328px) 100vw, 328px"></figure><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}">
<p>I’d be remiss if I didn’t mention Mike Duncan’s <em><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/The_History_of_Rome_(podcast)" target="_blank">The History of Rome</a></em> podcast.</p>



<p>At the time of writing this, I’ve listened to over 140 episodes of this incredible podcast. I’ve learned so much and I can’t recommend it highly enough. </p>



<p>It will take me through finishing the nursery and bathroom re-model that are both also nearly complete. </p>
</div></div>



<h2>Preparing to Build Back Up</h2>







<p>There were lots of gaps in the previous drywall work that they covered up with the treated wood trim. Gap filling foam did a wonder on those spots, which will help keep out insects and provide additional insulation. After inspecting further, it seems the water damage was from past events and was not severe enough to damage the subfloor. Hit it with a coat of primer.</p>



<h2>Installing the Flooring</h2>



<div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:8912680,&quot;permalink&quot;:&quot;https:\/\/harriskenny.com\/2020\/07\/13\/re-modeling-a-man-cave-into-an-office-for-under-3k\/&quot;}"><figure><img data-attachment-id="2787" data-permalink="https://harriskenny.com/flooring-1/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1588148971&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.002&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="flooring-1" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?w=700" srcset="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?strip=info&amp;w=600 600w,https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?strip=info&amp;w=900 900w,https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg?strip=info&amp;w=960 960w" alt="" data-height="960" data-id="2787" data-link="https://harriskenny.com/flooring-1/" data-url="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg" data-width="1280" src="https://harriskenny.files.wordpress.com/2020/07/flooring-1.jpeg"></figure></div></div></div></div>



<p>I’m using this room as an office for my business, but it could be used for any number of things. I decided to go with vinyl because of the ease of maintenance and ability to have the room be a few different things in the future. </p>



<p>After deciding on vinyl, I started with a cork underlayment to help with insulation, cushioning, and noise dampening. </p>



<p>This was a full day of work. I was exhausted at the end.</p>



<p>I will need to do acoustic testing, but I’m planning on recording <em><a href="https://helloblinkshow.com/">Hello Blink Show</a></em> episodes in this space. The room is not dedicated for audio, so I’m not going all-in on that use case (like with black foam). If I need to add additional furniture, curtains, or other things to help with echo later, I will cross that bridge later. </p>



<h2>Electrical</h2>







<p>Here’s where I got a little out of hand. I wanted to make sure that the ceiling fan would work with the ceiling pitch. I rediscovered geometry and went to town. I had a licensed electrician install the fixtures and add a hardwired smoke detector (not pictured). </p>



<p>The fans themselves were extremely difficult to install and took more time than expected. The boxes did need to be replaced with weight bearing ones UL-graded to hold the fans up, but that didn’t take long. Installing the smoke detector was also more difficult than expected and required an insane drill bit which the electrician fortunately had in the van.</p>



<p>These are two-in-one fixtures with clean LED light (looks slightly yellow in the photo) and reversible caged fan for different seasons. I’m definitely satisfied with how they’re working so far.</p>



<h2>Side Quest: Door Hardware and Signage</h2>







<p>The door hardware wasn’t in good shape. The surface on the door knob was worn down, the hinges were a different finish, and there wasn’t any sort of door stop. There were also gaps in the door frame from a previously botched lock install.</p>



<p>None of this was strictly necessary to fix. But if you’re doing something, might as well do it right. I bought and installed new hardware to address all of these issues.</p>



<p>I’m planning on using this as a formal office, so I decided to have fun with it by installing an eye viewer and door knocker (pictured below). I also bought numbers for a half address that I’ll put up later. (The outside needs touching up, too.)</p>



<p>This was a lot harder than I expected. Doors are very sensitive and getting the alignment just right took real effort. We’ll see how it lines up when temperatures change in the winter… I’m expecting to have to revisit this.</p>



<h2>Trim, Caulk, Texture</h2>







<p>This ended up being as difficult as I expected. Which is to say it was massively time consuming, but I love how it came out. I went with PVC trim because the room is not square, the flexibility there made it much easier to finish it without that being too obvious.</p>



<p>There were a number of varying dimensions I had to keep in mind when installing this, so I ended up sticking with this particular style for the entire room for consistency sake. This allowed me to account for the height of outlets, the basement window, and the door frame without having to do custom cutouts required to install a more typical trim selection. I do think the lower profile trim looks nice too.</p>



<h2>After</h2>



<figure><img data-attachment-id="2799" data-permalink="https://harriskenny.com/done-1/" data-orig-file="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.4&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 11 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1593779145&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.54&quot;,&quot;iso&quot;:&quot;25&quot;,&quot;shutter_speed&quot;:&quot;0.0081967213114754&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="done-1" data-image-description="" data-medium-file="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=300" data-large-file="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=700" src="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=700" alt="" srcset="https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=700 700w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=150 150w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=300 300w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=768 768w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg?w=1024 1024w, https://harriskenny.files.wordpress.com/2020/07/done-1.jpeg 1280w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<p>All set! (Minus the electrical outlet plates, not shown in this picture that I installed later). You can also see the new storm door, boxed and laying flat there.</p>



<p>I initially set a deadline to have the office, the bathroom re-model, and the nursery all done by August 1. This was done just after July 1 and the nursery will be done within the week. So it feels good to be ahead of schedule without blowing out the budget (more on that next).</p>



<h2>Budget</h2>



<figure><table><thead><tr><th>Item</th><th>Cost (↓)</th></tr></thead><tbody><tr><td>Electrician Labor</td><td>$620.00</td></tr><tr><td>Vinyl Flooring</td><td>$479.54</td></tr><tr><td>Electrical Fixtures</td><td>$438.97</td></tr><tr><td>Storm Door</td><td>$320.20</td></tr><tr><td>Consumables*</td><td>$269.67</td></tr><tr><td>PVC Trim</td><td>$211.94</td></tr><tr><td>Hand Tools</td><td>$201.71</td></tr><tr><td>Door Hardware &amp; Signage</td><td>$158.73</td></tr><tr><td>Paint</td><td>$120.83</td></tr><tr><td>Cork Underlayment</td><td>$112.50</td></tr><tr><td><strong>Total</strong></td><td><strong>$2,934.09</strong></td></tr></tbody></table></figure>



<p>Here are all the individual items that ended up costing over $100, ranked in Descending order of cost. Consumables include things like painter’s tape, gap filling foam, drywall tape, caulk. </p>



<p>One thing that’s not included in this budget is that I borrowed a nail gun and shop vac from a friend. Those, a drill, and an impact driver are the only power tools I used during this project. </p>



<p>I mentioned above in the <strong>Electrical</strong> section but worth re-iterating that the major driver of the electrician labor was the fact that the fans themselves were extremely difficult to install. They also had to replace the boxes to bear the weight of the fans. Installing the smoke detector was also a chore, too. Definitely glad I had a professional take care of these things.</p>



<p>I’m not sure what this would have cost to have done professionally. If you know, let me know! But I really enjoyed it and look forward to spending time in this re-modeled space. </p>



<h2>Unfinished Business</h2>



<p><strong>Blinds:</strong> I need to do more research on which blinds, how much light they allow in, etc. and because of how much time I take researching things… I’m putting this off for now. The nursery and bathroom re-model beckon.</p>



<p><strong>Heat:</strong> There is space for electrical floorboard heaters. Haven’t had those installed yet, but we do have room in the breaker if-needed as they will require having a dedicated line installed because of the power draw. I’m planning on seeing how drafty it is in the winter. </p>



<p><strong>Storm Door: </strong>I bought a better storm door that will help with insulation. When that’s installed, I’ll repaint the exterior threshold. I’d also like to look into installing a rubber gasket to totally seal the door, though it’s arguably overkill since the storm door and rebuilt threshold get that job done. </p>



<p><strong>Exterior: </strong>The outside of the extension needs some touch up work for sure. After that’s done, I’ll mount the “1/2” sign for our address as a fun finishing touch.</p>



<p><strong>Decor:</strong> Oh yeah, I need to move in and decorate the thing. Don’t have a lot of time for that now, so will keep it basic. I may revisit this with another post when it’s fully decorated and looks how I want it to look.</p>



<h2>Lessons Learned</h2>



<ul><li><strong>The Good</strong><ul><li>Satisfaction of a job well done.</li><li>Look at all that natural light!</li><li>Grateful for people who I could ask questions along the way, especially in the beginning.</li><li>Hard commitments. There’s a degree of inevitability when there is a baby on the way! That made sure I finished the job.</li><li>Stores like the Home Depot, Ace Hardware, and Sherwin Williams did a great job over the last few months ensuring customer safety.</li><li>There are many great American companies who make high quality tools and construction materials, I was proud to support as many as I could throughout this project. </li></ul></li><li><strong>The Bad</strong><ul><li>So. Much. Painters. Tape. Between. Steps.</li><li>I hit a bit of a wall before installing the trim or applying the drywall texture because I’d never done either before. That was the emotional “low point” for sure.</li><li>Electrical is expensive to get right and even more expensive to get wrong. </li><li>Paint isn’t very forgiving. The …</li></ul></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/">https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/</a></em></p>]]>
            </description>
            <link>https://harriskenny.com/2020/07/13/re-modeling-a-man-cave-into-an-office-for-under-3k/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823987</guid>
            <pubDate>Mon, 13 Jul 2020 18:32:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vessel Finder]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23823963">thread link</a>) | @Mosiout1936
<br/>
July 13, 2020 | https://marinetraffic24.com/pt/vesselfinder/ | <a href="https://web.archive.org/web/*/https://marinetraffic24.com/pt/vesselfinder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://marinetraffic24.com/pt/vesselfinder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823963</guid>
            <pubDate>Mon, 13 Jul 2020 18:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to learn to code 10x faster]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823899">thread link</a>) | @sameerkapur
<br/>
July 13, 2020 | https://blog.thecodex.me/how-to-code-10x-faster/ | <a href="https://web.archive.org/web/*/https://blog.thecodex.me/how-to-code-10x-faster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            



            <section>
                <div>
                    <h3 id="what-i-ve-learned-from-teaching-500-000-students-to-code-and-building-dozens-of-projects-">What I've learned from teaching 500,000 students to code and building dozens of projects.</h3><p>Avi here. Since I started programming, a question that I've been asked again and again from my students is, "How do I learn faster?" Here's the answer: <strong>Build projects.</strong></p><p>Let me explain with a story of my own. I started programming when I was 10-years-old after a friend showed me that she had built a Python weather dashboard that told her exactly when it would rain. I was astounded. I spent the next day figuring out how I could write my own Python Script to crawl Yahoo's Weather API and 24 hours later I had built my first program. If you had told me I had to take an 8-week long bootcamp to learn how to code or watch monotonous YouTube videos until it clicked, I might have never started in the first place. No one forced me to get into programming - I discovered my passion because I wanted to build this cool idea. StackOverflow became my best friend as I achieved my goal. Along the way, I learned about a variety of concepts from calling APIs in Python to parsing JSON and had plenty of practice applying them in my project. The lesson here: <strong>use projects as motivators to learn. </strong></p><p>Okay so we got that out of the way. Building projects are the key to learning things faster. Now what? How do I pick the right projects? Where do I even start?</p><p>The next big takeaway:<strong> Work on projects that matter to you. </strong>My first project was a simple weather script because my ten-year-old brain thought that was wicked cool, but you probably have other passions and interests. Don't compromise. Build projects around your interests and hobbies. If you are starting a project, make sure that it is something that you deeply resonate with. If you are into cars, build a car speed comparison tool. If you are into productivity, build a time tracker to help you be more productive. Even better, build things you want. When those ideas for a cool app or website pop up in your head, START BUILDING IT because motivation is perishable. As the saying goes, the best time to start was yesterday, the next best time to start is now.</p><p>Good things happen to those who are patient. Here are three magic words: <strong>Repetition, Compounding, and Consistency.</strong> These three words are the key to solidifying programming fundamentals and truly understanding new concepts and ideas as you apply them in projects. You've heard how important spaced repetition is for learning - the same thing applies when learning how to code. Try coding for an hour a day. Don't have an hour a day? Code for 30 minutes. Can't do 30 minutes consistently? Try for 15 minutes. Break tasks down into smaller tasks and knock them out.</p><p>Last but not the least, the tip that changed my life: Teach what you learn. Yes, it sounds simple - teach what you learn - but I can't repeat it enough. Explaining concepts allow you to improve your understanding and solidify your learning. Teaching has positive externalities as well. After I started teaching others how to code and began posting videos on <a href="https://www.youtube.com/c/TheCodex">Youtube</a>, I not only understood each and every concept better, but thousands of others used my videos to learn how to code. My AP Stats teacher had a philosophy that to truly understand any concept you must "learn one, do one, and teach one." Teaching others has helped me hold myself accountable to truly understanding concepts until I feel ready to share my knowledge and it's paved my path in becoming a professional Python Developer and Data Scientist.</p><p>For those of you interested in project walkthroughs: Every Tuesday, I'm releasing a new Python/Data Science Project tutorial. I was honestly just tired of watching webcasted lectures and YouTube videos of instructors droning on with robotic voices teaching pure theory, so I started recording my own fun and practical projects. I posted the first project walkthrough on building a Weather API Dashboard with Flask and you can build the whole project for free <strong><a href="https://thecodex.me/projects/weather-api-dashboard-with-python-and-flask">here</a>.</strong></p><p>Want to get notified every time a new project launches? Click <strong><a href="https://cdn.forms-content.sg-form.com/a9d3bb34-c4a3-11ea-a1ea-52b70f2fc72a">here</a></strong>.</p><hr><p>Hey! I'm Avi - your new Python and data science teacher. I've taught over 500,000 students around the world not just how to code, but how to build real projects. I'm on a mission to help you jumpstart your career by helping you master python and data science. Start your journey on TheCodex here: <a href="https://thecodex.me/">https://thecodex.me/</a></p><figure><img src="https://blog.thecodex.me/content/images/2020/07/avi-emailtxt-min-2.jpg" alt="" srcset="https://blog.thecodex.me/content/images/size/w600/2020/07/avi-emailtxt-min-2.jpg 600w, https://blog.thecodex.me/content/images/size/w1000/2020/07/avi-emailtxt-min-2.jpg 1000w, https://blog.thecodex.me/content/images/size/w1600/2020/07/avi-emailtxt-min-2.jpg 1600w, https://blog.thecodex.me/content/images/2020/07/avi-emailtxt-min-2.jpg 1616w" sizes="(min-width: 720px) 720px"><figcaption>new projects and courses coming soon :)</figcaption></figure>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.thecodex.me/how-to-code-10x-faster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823899</guid>
            <pubDate>Mon, 13 Jul 2020 18:25:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dealing with Non-ASCII Characters]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823749">thread link</a>) | @chmaynard
<br/>
July 13, 2020 | https://blog.jpalardy.com/posts/dealing-with-non-ascii-characters/ | <a href="https://web.archive.org/web/*/https://blog.jpalardy.com/posts/dealing-with-non-ascii-characters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  

  

  <h2 id="problem">Problem</h2>

<p>Quick: why is this JSON not valid?</p>

<div><div><pre><code>{
  “user”: {
    “username”: “jpalardy”,
    “first_name”: “Jonathan”,
    “last_name”: “Palardy”
  }
}
</code></pre></div></div>

<details>
  <summary>[reveal the answer]</summary>

  

  <p>
  <a href="https://typographyforlawyers.com/straight-and-curly-quotes.html">Curly quotes!</a>
  </p>

  <p>
  Trick question? Yes and no... this happened to me and it was difficult to troubleshoot <em>visually</em>.
  </p>
</details>

<h2 id="a-class-of-problems">A Class of Problems…</h2>

<p>Many text formats, programming languages and other machine-parsed texts have rules about
what characters are allowed and not.</p>

<p>When in doubt, the lowest common denominator is usually <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a>:</p>

<div><div><pre><code>The decimal set:

  0 nul    1 soh    2 stx    3 etx    4 eot    5 enq    6 ack    7 bel
  8 bs     9 ht    10 nl    11 vt    12 np    13 cr    14 so    15 si
 16 dle   17 dc1   18 dc2   19 dc3   20 dc4   21 nak   22 syn   23 etb
 24 can   25 em    26 sub   27 esc   28 fs    29 gs    30 rs    31 us
 32 sp    33  !    34  "    35  #    36  $    37  %    38  &amp;    39  '
 40  (    41  )    42  *    43  +    44  ,    45  -    46  .    47  /
 48  0    49  1    50  2    51  3    52  4    53  5    54  6    55  7
 56  8    57  9    58  :    59  ;    60  &lt;    61  =    62  &gt;    63  ?
 64  @    65  A    66  B    67  C    68  D    69  E    70  F    71  G
 72  H    73  I    74  J    75  K    76  L    77  M    78  N    79  O
 80  P    81  Q    82  R    83  S    84  T    85  U    86  V    87  W
 88  X    89  Y    90  Z    91  [    92  \    93  ]    94  ^    95  _
 96  `    97  a    98  b    99  c   100  d   101  e   102  f   103  g
104  h   105  i   106  j   107  k   108  l   109  m   110  n   111  o
112  p   113  q   114  r   115  s   116  t   117  u   118  v   119  w
120  x   121  y   122  z   123  {   124  |   125  }   126  ~   127 del

(courtesy of `man ascii`, a reference never too far)
</code></pre></div></div>

<p>And while “curly quotes” might seem like a made-up problem<sup id="fnref:made-up"><a href="#fn:made-up">1</a></sup>, there are other insidious examples:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Dash#En_dash">en dash</a>, <a href="https://en.wikipedia.org/wiki/Dash#Em_dash">em dash</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Non-breaking_space">non-breaking space</a> and <a href="https://en.wikipedia.org/wiki/Tab_key#Tab_characters">tab</a> (to a lesser extent)</li>
  <li><a href="https://en.wikipedia.org/wiki/Carriage_return">carriage return</a> and <a href="https://en.wikipedia.org/wiki/Newline">newline</a></li>
  <li>in general: <a href="https://en.wikipedia.org/wiki/Homoglyph">homoglyphs</a> (<a href="https://en.wikipedia.org/wiki/IDN_homograph_attack">other examples</a>)</li>
</ul>

<h2 id="solutions">Solutions</h2>

<p>There is no general solution to all the problems, only an assortment of tricks:</p>

<ul>
  <li>“weird spacing” is often flagged or fixed by text editors; details will vary</li>
  <li>file formats: can be fixed with <a href="https://waterlan.home.xs4all.nl/dos2unix.html">dos2unix</a> or similar</li>
  <li>external linters can be your sanity check:</li>
</ul>

<figure><pre><code data-lang="bash"><span>&gt;</span> jq <span>.</span> invalid.json
parse error: Invalid numeric literal at line 2, column 13
<span>&gt;</span>
<span># better than nothing? 🤔</span></code></pre></figure>

<h3 id="the-non-visible-ascii-regexp-trick">The Non-Visible ASCII regexp Trick</h3>

<p>If what’s allowed is “visible ASCII”, what’s <em>not allowed</em> is “non-visible ASCII”:</p>



<p>described in words: all characters not between “space” and “tilde”<br>
(I don’t remember where I picked up this trick. I would appreciate a link if you know.)</p>

<p>Why does this work? Referring back to the ASCII table from above:</p>

<div><div><pre><code>  0 nul    1 soh    2 stx    3 etx    4 eot    5 enq    6 ack    7 bel
  8 bs     9 ht    10 nl    11 vt    12 np    13 cr    14 so    15 si
 16 dle   17 dc1   18 dc2   19 dc3   20 dc4   21 nak   22 syn   23 etb
 24 can   25 em    26 sub   27 esc   28 fs    29 gs    30 rs    31 us
     /--- start here
 32 sp    33  !    34  "    35  #    36  $    37  %    38  &amp;    39  '
 40  (    41  )    42  *    43  +    44  ,    45  -    46  .    47  /
 48  0    49  1    50  2    51  3    52  4    53  5    54  6    55  7
 56  8    57  9    58  :    59  ;    60  &lt;    61  =    62  &gt;    63  ?
 64  @    65  A    66  B    67  C    68  D    69  E    70  F    71  G
 72  H    73  I    74  J    75  K    76  L    77  M    78  N    79  O
 80  P    81  Q    82  R    83  S    84  T    85  U    86  V    87  W
 88  X    89  Y    90  Z    91  [    92  \    93  ]    94  ^    95  _
 96  `    97  a    98  b    99  c   100  d   101  e   102  f   103  g
104  h   105  i   106  j   107  k   108  l   109  m   110  n   111  o
112  p   113  q   114  r   115  s   116  t   117  u   118  v   119  w
120  x   121  y   122  z   123  {   124  |   125  }   126  ~   127 del
                                              stop here ---/
</code></pre></div></div>

<p>What is before space? various non-visible characters…<br>
What is after tilde? <code>del</code>, but also <em>ALL other Unicode characters!</em></p>

<p>Why is this useful? Many text editors can highlight based on regular expressions:</p>

<p><img src="https://blog.jpalardy.com/assets/dealing-with-non-ascii/curlies-in-vim.png" alt="curly quotes highlighted in vim"><br>
(this is vim; use <code>:set hlsearch</code> to turn this on)</p>

<p>This trick works everywhere regular expressions work:</p>

<p><img src="https://blog.jpalardy.com/assets/dealing-with-non-ascii/curlies-in-grep.png" alt="curly quotes highlighted in grep"></p>

<hr>

<p>Footnotes:</p>




  <section>
    <h3>Discuss on Twitter</h3>
    <section>
      
      <a href="https://twitter.com/jpalardy" data-show-count="false">Follow @jpalardy</a>
      
    </section>
  </section>
</section></div>]]>
            </description>
            <link>https://blog.jpalardy.com/posts/dealing-with-non-ascii-characters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823749</guid>
            <pubDate>Mon, 13 Jul 2020 18:12:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ETL: Navigating the Cloud Transition (Architectures & Factors to consider)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823680">thread link</a>) | @ibains
<br/>
July 13, 2020 | https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition | <a href="https://web.archive.org/web/*/https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.prophecy.io/blogs/etl-navigating-the-cloud-transition</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823680</guid>
            <pubDate>Mon, 13 Jul 2020 18:06:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Give some love to your PR]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823554">thread link</a>) | @elleflorio
<br/>
July 13, 2020 | https://www.florio.dev/20200712-pr-love/ | <a href="https://web.archive.org/web/*/https://www.florio.dev/20200712-pr-love/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>After hours of work, you finally get there. Your code is ready. Time to submit a Pull Request (PR) and get your baby reviewed. There is a PR template to fill… Ufff, that’s annoying! Please, don’t waste my time with this stuff and just look at my code!!! </p>
<p>Let’s be honest: we have been there more than once. PRs with a poorly filled template, or (even worst) no template and an extremely useless description. “Add this”. “Fix that”. </p>
<p>But we know it is not the right way to ship our code. In this article, I want to point out the importance of providing an amazing PR, with a complete and useful description, and all the information the reviewers will need to provide great feedback. No templates here, or rules to follow. <strong>My goal is to inspire you to give some love to your PR</strong>.</p>
<p><span>
      <a href="https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/275bf/pr-love-cover.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="meme" title="meme" src="https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/fcda8/pr-love-cover.png" srcset="https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/12f09/pr-love-cover.png 148w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/e4a3f/pr-love-cover.png 295w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/fcda8/pr-love-cover.png 590w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/efc66/pr-love-cover.png 885w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/c83ae/pr-love-cover.png 1180w,
https://www.florio.dev/static/562a96b40da191319dbfc231f5f9831d/275bf/pr-love-cover.png 4973w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>Why your PR deserves some love</h2>
<p>You may wonder why you should spend time crafting a PR full of love. The reason is quite simple: <strong>your work, your reviewers, and you deserve it!</strong></p>
<h3>Your work deserves it</h3>
<p>Every line of code, every commit, every test is a unique piece of work. It deserves the best possible presentation. What’s the point of crafting something without put some care in its presentation? Give some love to your work presenting it in a way other people will appreciate it too.</p>
<p>Image to visit an art gallery. You have the chance to quickly chat with the author of the masterpiece you are observing and that you would like to buy: the amazing portrait of a dead tomato on a sunny beach. So full of meaning! You ask the author some information on how he had such an inspiration, and he answers: “Meh, I took some colours and I panted that”. Not the best way to sell the artwork, right?</p>
<p>With your PR is the same story: you cannot pretend others to appreciate your work if you don’t spend some time <strong>properly presenting it</strong>.</p>
<h3>Your reviewers deserve it</h3>
<p>Put yourself in the shoes of the reviewers. </p>
<p>Oh, a notification! Someone requested a review from me, great! Let me check…</p>
<ul>
<li>20 new files</li>
<li>15 modifications</li>
<li>5 files deleted</li>
<li>Title: updated module</li>
<li>Description: Updated the module to implement ticket 1234.</li>
</ul>
<p>What the f**k…</p>
<p>Back to the art gallery example. You are the critic that should provide a review of that famous “Sad Tomato in a Happy Place”, the masterpiece everyone is talking about. You go around the art gallery looking for it, and you find the artwork still in it’s packaging with a small label saying: “tomato”. To review it you would need to unpack the artwork, ask around for information about it, ask the author about his choices about the colours, etc. Doesn’t sound appealing, right?</p>
<p>Remember that <strong>the time of your reviewers is as much as valuable as yours</strong>. Also, it is quite hard to provide a proper review without having some context. <strong>Help your reviewers help you</strong>: give some love to your PR with a meaningful title and a proper description of what you have done. We will get back on this later…</p>
<h3>You deserve it</h3>
<p>You spent hours if not days working on a task. Several commits, tests, failures, and successes. Do you want to submit a PR without showing the care you put in your work? Without explaining the choices you made after several thoughts?</p>
<p>Back to the art gallery example. This time, you are the author of “Sad Tomato in a Happy Place”. It has been not easy to come up with such a complex masterpiece, for sure. You want people to appreciate your work, understand how hard you worked on that, all the passion you put in it. I think you won’t put the artwork in a dark corner, without a frame, just above the fire extinguisher, and near the ladies bathroom. You want to put it under the best possible light, with an amazing frame and in the most important place of the gallery.</p>
<p>You want to do the same with your PR. You deserve that your reviewers can <strong>understand and appreciate</strong> your work! Their review will be much better, and this will help YOU in providing even more value. As I said before: <strong>help them help YOU</strong>.</p>
<h2>How to give some love to your PR</h2>
<p>I think now we all agree that our PR deserves some love. How to do that? Well, it doesn’t require a lot of hard work, just to <strong>pay attention to details</strong>.</p>
<p><span>
      <a href="https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/6af66/pr-love-meme.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="meme" title="meme" src="https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/fcda8/pr-love-meme.png" srcset="https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/12f09/pr-love-meme.png 148w,
https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/e4a3f/pr-love-meme.png 295w,
https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/fcda8/pr-love-meme.png 590w,
https://www.florio.dev/static/53c24ba41915f6362cbe4ab0701d1634/6af66/pr-love-meme.png 640w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>Keep it small</h3>
<p>Please, <strong>keep your PR as small as possible</strong>. I understand that sometimes the task/feature requires a lot of work, but if it is possible please split it in smaller and very focused PRs. It will be easier for you to focus on that specific part of the business logic, and your reviewers will provide a better review. That’s a lot easier to understand the logic and provide feedback when you don’t have to look at 20 files.</p>
<h3>Give some ❤️ to commits too</h3>
<p>Commits are the building blocks of your PR, and <strong>they deserve some love as well</strong>. When you commit, provide useful information on what the commit is about. I won’t spend much time on this topic since you can find plenty of articles with good tips on the internet. I like the suggestions from Chris Beams that he describes in <a href="https://chris.beams.io/posts/git-commit/#imperative">this</a> nice article.</p>
<h3>First things first: the title</h3>
<p>The title of the PR is the first thing your reviewers will see and <strong>can provide a lot of useful information</strong>. Is it a feature? A fix? A simple chore? State that clearly in the title along with few words on the task the PR is focused on.</p>
<div data-language="text"><pre><code>Chore: upgrade log4j to version 2.3.4</code></pre></div>
<p>is a better title than</p>

<p>don’t you think?</p>
<h3>Provide a good description</h3>
<p>After the title, it comes the description. It is not important how you structure it, it can be a list of bullet points, a checklist, an informal description, a photo romance… what is important are <strong>the information you provide</strong>. In my humble opinion, the description should comprehend:</p>
<ul>
<li><strong>Topic</strong>: what are you trying to accomplish with this PR? How are you achieving your goal?</li>
<li><strong>Motivation</strong>: why are you submitting this PR? If it is related to a ticket/task, provide a link to it.</li>
<li><strong>Breaking changes</strong>: does this PR introduces some breaking changes? Why? Your reviewers may put extra attention if they know this PR will potentially break stuff.</li>
<li><strong>Additional information</strong>: is there any other information useful to know for the reviewer? An example may be the reasons behind a particular decision on a piece of code that may sound weird.</li>
</ul>
<p>Let me be clear and repeat it: it is not important the format, but the quality of information you provide with your description. If you can provide high-quality information in 3 lines of text, well, great!</p>
<h3>Make tests first-class citizens</h3>
<p>Did you test your PR? I assume (<em>hope</em>) you are used to doing it. Describe briefly what kind of tests you did, and if it is appropriate what is required to test the PR. I know that tests maybe are visible in the file list, but I think your reviewers will be happy to have a <strong>summary</strong>.</p>
<p>Also, a PR could be not just code that you can test explicitly. Suppose you added some scripts to the repo. The best thing you can do is to write the command you used to test it and copy &amp; paste the output. This is just an example, I am sure you can find others.</p>
<h3>Highlight dependencies</h3>
<p>Your PR may have dependencies as well as other tasks that should be done <em>after</em> it is merged. It can be another PR that should be merged before this one, a value that should be updated in the database, or some resources that should be cleaned because no more needed after the PR is merged. You should always <strong>state clearly the dependencies of your PR</strong>. Why? Well, first of all, this will be a good reminder for you! It will be also helpful to your reviewers, that will validate them as well as the PR itself.</p>
<h2>Conclusion</h2>
<p>Ok, guys, that’s it. I said it already, I didn’t want to provide a set of rules on how to do a PR. These are just some suggestion that I hope will be useful to you. Time to get back to your PRs and give them some ❤️!</p>
<p><em>photo by</em>  <a href="https://unsplash.com/@jamie452?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" title="Download free do whatever you want high-resolution photos from Jamie Street"><span><svg xmlns="http://www.w3.org/2000/svg" style="height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white" viewBox="0 0 32 32"><title>unsplash-logo</title><path d="M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z"></path></svg></span><span>Jamie Street</span></a></p></section></div>]]>
            </description>
            <link>https://www.florio.dev/20200712-pr-love/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823554</guid>
            <pubDate>Mon, 13 Jul 2020 17:55:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Harold Lloyd Filmed "Safety Last!"]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823505">thread link</a>) | @gus_massa
<br/>
July 13, 2020 | https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/ | <a href="https://web.archive.org/web/*/https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg"><img data-attachment-id="2371" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg" data-orig-size="1853,2365" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="108 – T Lloyd Safety Last Tally’s Broadway Theatre below 2 crp" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=235" data-large-file="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=640" src="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=118&amp;h=150" alt="108 - T Lloyd Safety Last Tally's Broadway Theatre below 2 crp" width="118" height="150" srcset="https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=118&amp;h=150 118w, https://silentlocations.files.wordpress.com/2012/02/108-t-lloyd-safety-last-tallys-broadway-theatre-below-2-crp.jpg?w=236&amp;h=300 236w" sizes="(max-width: 118px) 100vw, 118px"></a>The image of Harold Lloyd hanging desperately from the hands of a skyscraper clock during <em>Safety Last! </em>(1923) is one of the great icons of film history.&nbsp; Using maps, aerial views, and vintage photographs, my book <a href="http://www.amazon.com/Silent-Visions-Discovering-Hollywood-Through/dp/1595800573/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1330485203&amp;sr=1-1"><em>Silent Visions</em></a> shows how Harold filmed each of his five stunt-climbing comedies within the downtown Los Angeles Historic Core, while documenting the burgeoning urban skyline as it appears in the background of his films. [Note: <span>I will be introducing <em>Safety Last!</em> on June 25, 2016</span> at the Orpheum Theater as part of the Los Angeles Conservancy’s <a href="https://www.laconservancy.org/events/safety-last-orpheum-theatre">Last Remaining Seats</a>.]</p>
<div data-shortcode="caption" id="attachment_6143"><p><a href="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg"><img aria-describedby="caption-attachment-6143" data-attachment-id="6143" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/pan-04-9/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg" data-orig-size="1800,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="pan 04" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640" src="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640&amp;h=223" alt="On the roof of 908 S. Broadway from Safety Last! and the YouTube video clip" width="640" height="223" srcset="https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=640&amp;h=223 640w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=1278&amp;h=446 1278w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=150&amp;h=52 150w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=300&amp;h=105 300w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=768&amp;h=268 768w, https://silentlocations.files.wordpress.com/2012/02/pan-04.jpg?w=1024&amp;h=357 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p><p id="caption-attachment-6143">The closing scene from <em>Safety Last!</em> (left) was filmed on the roof of 908 S. Broadway, the same building where the clock stunt climbing set was built. The same roof (right), now supporting the steel girder foundation for a large antennae, appears during the Criterion Collection <a href="http://youtu.be/tnrjyjKH5OU"><em>Locations and Effects</em> mini clip</a>.</p></div>
<p>The slides below show how the many <em>Safety Last!</em> stunts were created, and may be downloaded further below as a 14 MB PowerPoint presentation.&nbsp; You can also access a <a href="https://silentlocations.files.wordpress.com/2016/06/los-angeles-conservancy-harold-lloyd-safety-last-tour-bengtson-2016.pdf">self-guided walking tour</a> of the downtown locations appearing in <em>Safety Last!</em>, <em>Never Weaken, </em>and <em>Feet First. </em><a href="https://silentlocations.files.wordpress.com/2019/10/complete-list-of-all-harold-lloyd-stunt-climbing-buildings-updated-2019.pdf">(In all Lloyd employed 17 downtown buildings during his “thrill” comedies – see a PDF list of descriptions here</a><em><a href="https://silentlocations.files.wordpress.com/2019/10/complete-list-of-all-harold-lloyd-stunt-climbing-buildings-updated-2019.pdf">)</a>.<br>
</em></p>
<p>[Note: on the ground, Charlie Chaplin, Buster Keaton and Harold Lloyd <a href="https://silentlocations.com/chaplin-keaton-lloyd-alley/">filmed scenes from their masterpieces <em>The Kid</em> (1921), <em>Cops</em> (1922) and <em>Safety Last!</em> at the same Hollywood alley you can still visit today</a>.]</p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg"><img data-attachment-id="7315" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_01/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_01" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640&amp;h=480" alt="SL short blog_Page_01" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_01.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg"><img data-attachment-id="7316" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_02/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_02" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640&amp;h=480" alt="SL short blog_Page_02" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_02.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg"><img data-attachment-id="7317" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_03/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_03" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640&amp;h=480" alt="SL short blog_Page_03" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_03.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg"><img data-attachment-id="7318" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_04/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_04" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640&amp;h=480" alt="SL short blog_Page_04" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_04.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg"><img data-attachment-id="7319" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_05/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_05" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640&amp;h=480" alt="SL short blog_Page_05" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_05.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg"><img data-attachment-id="7320" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_06/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_06" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640&amp;h=480" alt="SL short blog_Page_06" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_06.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg"><img data-attachment-id="7321" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_07/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_07" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640&amp;h=480" alt="SL short blog_Page_07" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_07.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg"><img data-attachment-id="7322" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_08/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_08" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640&amp;h=480" alt="SL short blog_Page_08" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_08.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg"><img data-attachment-id="7323" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_09/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_09" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640&amp;h=480" alt="SL short blog_Page_09" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_09.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg"><img data-attachment-id="7324" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_10/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_10" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640&amp;h=480" alt="SL short blog_Page_10" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_10.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg"><img data-attachment-id="7325" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_11/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_11" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640&amp;h=480" alt="SL short blog_Page_11" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_11.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg"><img data-attachment-id="7326" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_12/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_12" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640&amp;h=480" alt="SL short blog_Page_12" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_12.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p><a href="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg"><img data-attachment-id="7327" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/sl-short-blog_page_13/" data-orig-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg" data-orig-size="2000,1500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SL short blog_Page_13" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640" src="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640&amp;h=480" alt="SL short blog_Page_13" width="640" height="480" srcset="https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=640&amp;h=480 640w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=1280&amp;h=960 1280w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=150&amp;h=113 150w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=300&amp;h=225 300w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=768&amp;h=576 768w, https://silentlocations.files.wordpress.com/2015/02/sl-short-blog_page_13.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 640px) 100vw, 640px"></a></p>
<p>Here is the link to download the PowerPoint.&nbsp; Most of the slides are animated, so wait a moment each time before clicking the “next” button.</p>
<div data-shortcode="caption" id="attachment_2367"><p><a href="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg"><img aria-describedby="caption-attachment-2367" data-attachment-id="2367" data-permalink="https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/untitled/" data-orig-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg" data-orig-size="609,644" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="Untitled" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=284" data-large-file="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=609" title="Untitled" src="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=283&amp;h=300" alt="" width="283" height="300" srcset="https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=283&amp;h=300 283w, https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=566&amp;h=600 566w, https://silentlocations.files.wordpress.com/2012/02/untitled.jpg?w=142&amp;h=150 142w" sizes="(max-width: 283px) 100vw, 283px"></a></p><p id="caption-attachment-2367">The recent multiple Oscar-winning movie <em>Hugo</em> pays tribute to <em>Safety Last!</em>; first by including a clip of the Lloyd movie within the film, and also when the young hero Hugo Cabret finds himself hanging from a train station clock. <em>Hugo</em> (C) 2011 Paramount Pictures</p></div>
<p><a href="https://silentlocations.files.wordpress.com/2012/02/how-harold-lloyd-filmed-safety-last-by-john-bengtson.ppt">How Harold Lloyd Filmed Safety Last by John Bengtson</a></p>
<p>You will need a PowerPoint viewer to watch the show, and can download a PowerPoint viewer at this <a href="http://www.microsoft.com/downloads/en/details.aspx?displaylang=en&amp;FamilyID=cb9bf144-1076-4615-9951-294eeb832823">site</a>.</p>
<p>You can also check out <a href="https://silentlocations.wordpress.com/category/safety-last/">my other posts about <em>Safety Last! </em>here</a>.</p>
<p>A short segment from the <em>Locations and Effects</em> 2013 documentary with Academy-Award winning effects supervisor Craig Barron and the author filmed for the <a href="http://www.criterion.com/films/28446-safety-last">Criterion Collection release of the <em>Safety Last!</em> Blu-ray </a>appears below.</p>
<p><span><iframe width="560" height="315" src="https://www.youtube.com/embed/tnrjyjKH5OU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p><p><span>To see where Harold filmed his amazing comedies, be sure to check out my book <a href="https://www.amazon.com/Silent-Visions-Discovering-Hollywood-Through/dp/1595800573/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1533680311&amp;sr=1-1&amp;keywords=john+bengtson+silent"><em>Silent Visions</em></a>.&nbsp; </span></p>
<p><span>If you need a good laugh, or want to raise your spirits, just listen to Michael Mortilla’s audio-only recording of the audience laughing and squealing with delight while watching <em>Safety Last!</em>&nbsp; It’s great to play as background music <span>– the swells and squeals of laughter just grow and grow.</span></span></p>
<p><a href="http://www.midilifecrisis.com/Music_and_Sound/SafetyLast_Audience_Michael_Mortilla_Piano.mp3">Michael Mortilla accompanying Safety Last!</a></p>
<p>HAROLD LLOYD images and the names of Mr. Lloyd’s films are all trademarks and/or service marks of Harold Lloyd Entertainment Inc. Images and movie frame images reproduced courtesy of The Harold Lloyd Trust and Harold Lloyd Entertainment Inc.</p>
<p><img data-attachment-id="15216" data-permalink="https://silentlocations.com/chaplin-keaton-lloyd-alley/chaplin-keaton-lloyd-sign/" data-orig-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg" data-orig-size="1570,211" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Chaplin-Keaton-Lloyd-sign" data-image-description="" data-medium-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=300" data-large-file="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640" src="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640" alt="Chaplin-Keaton-Lloyd-sign" srcset="https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=640 640w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=1280 1280w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=150 150w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=300 300w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=768 768w, https://silentlocations.files.wordpress.com/2019/11/chaplin-keaton-lloyd-sign.jpg?w=1024 1024w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>Please help support naming the <a href="https://silentlocations.com/chaplin-keaton-lloyd-alley/">Chaplin Keaton Lloyd alley</a> in Hollywood by posting a review on <a href="https://goo.gl/maps/NGK6JpvncU3ejLDX7">Google Maps</a>. Prototype alley sign design by noted Dutch graphic artist – <a href="http://pietschreuders.com/">Piet Schreuders</a>. Download a 4-page brochure <a href="https://silentlocations.files.wordpress.com/2020/02/honor-the-chaplin-keaton-lloyd-alley.pdf">HERE</a>.</p>
<p>The site of the clock set, built on the roof of 908 S. Broadway on Google Maps.</p>

											</div></div>]]>
            </description>
            <link>https://silentlocations.com/2012/02/29/how-harold-lloyd-filmed-safety-last/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823505</guid>
            <pubDate>Mon, 13 Jul 2020 17:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I started working in the cloud in a matter of days]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823272">thread link</a>) | @markothedev
<br/>
July 13, 2020 | https://microtica.com/an-outstanding-cloud-automation-experience/ | <a href="https://web.archive.org/web/*/https://microtica.com/an-outstanding-cloud-automation-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p><a href="https://microtica.com/" target="_blank" rel="noreferrer noopener">Microtica</a> has the goal to provide the best cloud automation experience for developers from its very beginnings. We are so happy when we hear a success story, especially from developers who weren’t familiar with cloud automation previously.&nbsp;</p>



<p>This is why we decided to bring to you a series of interviews with our customers that experience the benefits of our solution. They jumped into a whole new world in a matter of days instead of months. </p>



<p>We are calling it: <strong>Developers Say.&nbsp;</strong></p>



<p>The first developer we talked to is Marko, a full-stack developer from <a href="https://vertt.ch/">Vertt</a>.&nbsp;</p>



<p><em>You can read more about how Vertt accelerated its DevOps processes with Microtica <a href="https://microtica.com/case-studies/accelerating-devops-processes/" target="_blank" rel="noreferrer noopener">here</a>.</em></p>



<h2><strong>What’s the product you’re developing?</strong></h2>



<p><a href="https://vertt.ch/">Vertt</a> is a Swiss ride-hailing startup that provides a reliable, responsible and secure transportation experience. As a service, Vertt wants to fill in the voids that exist in the Swiss transportation system. We innovate all the time, in order to provide society with a one-stop mobility solution.&nbsp;</p>



<h2><strong>Which technologies did you use when developing the solution?&nbsp;</strong></h2>



<p>You could say we actually have <strong>five applications</strong>. Four are mobile-native iOS and Android applications, two for the passenger experience, and two are for the drivers. We also have <strong>one web application </strong>which is the admin panel for our business team, developed in Angular.</p>



<p>As for the backend and infrastructure part, the solution is built on the latest <strong>microservice technology with AWS as a cloud provider</strong>. The backend is developed in Node.js.&nbsp;</p>



<div><figure><img src="https://media-exp1.licdn.com/dms/image/C5603AQFmUaDjB8TNSg/profile-displayphoto-shrink_800_800/0?e=1599696000&amp;v=beta&amp;t=5D8Bl17XcfwZ91kQIRTsD-_mg_ag4O9jwwGWIAs4Nuc" alt=""><figcaption>Marko from Vertt</figcaption></figure></div>



<h2><strong>Can you tell us about your background as a developer?&nbsp;</strong></h2>



<p>I am a full-stack developer with two years of experience. Vertt is my first major project and my first time working on a project of this magnitude. This project is where <strong>I gained most of my knowledge and learned about the big picture.</strong> I’m developing <strong>the backend logic in NodeJS</strong> for the entire system. I’m also working on the dashboard for our business team in Angular. I’ve worked on just a few projects prior to this. They were mostly small websites that didn’t require a backend component or scalability features.</p>



<h2><strong>Why did you choose a microservice infrastructure for this particular project?</strong></h2>



<p>We often see startups <a href="https://microtica.com/why-transition-from-monolith-to-microservices/" target="_blank" rel="noreferrer noopener">kicking off with a monolithic application</a> just to get something out there. However, when they expand, they face <strong>various problems related to scalability and continuous integration</strong>.&nbsp;</p>



<p><em>We wanted to do it the right way. </em>The <a href="https://microtica.com/everything-about-microservices/" target="_blank" rel="noreferrer noopener">benefits of the microservice architecture</a> are well-known. <strong>Different codebases, separate deployable units performing separate functionalities</strong>, and the most important for us—<strong>scaling individually</strong>.&nbsp;</p>



<h2><strong>How did you deliver software before discovering Microtica?</strong></h2>



<p>We started using <strong>Jenkins </strong>as part of our DevOps process. As our team consists of full-stack and mobile developers, we were really <strong>struggling with all the setup and integration of numerous plug-ins.</strong> We were using Jenkins as a build orchestration tool. We soon became very <strong>limited by the release management</strong> that Jenkins has to offer. Issues like access control management, configuration usability, and scaling began to overwhelm us and defocus us from our daily tasks.</p>



<p>As the team began to grow, tracking and accountability of various team members became a great issue. As we did most deployments and builds via a single user,<strong> tracking was only at the code level </strong>through our source control tool Git.&nbsp;</p>



<h2><strong>What was the biggest challenge you had as a developer working with cloud automation?</strong></h2>



<p>The main challenge for any beginner or intermediate developer is <strong>connecting all pieces together </strong>and making them work as one. Understanding how the entire system is designed and managed behind the curtain in the cloud is a continuous process that consists of <strong>constant learning and hands-on effort.</strong> Coming across stuff like cloud automation, scaling, and continuous delivery is always challenging, especially if you don’t have much experience to get started.&nbsp;</p>



<h2><strong>How did Microtica help you overcome these challenges?</strong></h2>



<p>Microtica made deploying our entire system extremely<strong> easy and effortless.</strong> With just a few clicks and a few extra files, we set up and deployed our entire system consisting of 13 microservices.&nbsp;</p>



<p>After <a href="https://microtica.com/start-creating-infrastructure-on-aws-like-a-pro/" target="_blank" rel="noreferrer noopener">setting up our initial development environment</a> <strong>it only took us one hour to get the test and production environments up and running.</strong> For this, we used the Clone Environment feature. This was really important to us because we wanted to fully migrate to Microtica before going to production.</p>



<p>The integration went <strong>smoothly and pretty fast</strong>. We only needed to create a couple of files in each microservice to create and guide the deployment pipeline. Now we can change parameters and redeploy our services within minutes and with almost no downtime.</p>



<p>It was extremely helpful that we could use their ready-to-use components. This eliminated the need to write complex CloudFormation templates for simple AWS resources. It allowed us to reuse the components by using just the UI.</p>



<h2><strong>How did Microtica help you grow as a developer?</strong></h2>



<p>Before working with Microtica, I didn’t have much experience and knowledge in the cloud automation space. Microtica gave me <strong>an initial push</strong>.  It made me confident enough to <strong>set up and maintain a fully functional system with three environments.</strong> I could create custom infrastructure and deploy microservices in the cloud <strong>in a matter of days.</strong> It allowed me to focus more on the actual development and less on infrastructure maintenance.</p>



<h2><strong>What kind of challenges are ahead of you and your team?</strong></h2>



<p>Our system is expanding on a daily basis along with its complexity. With a new feature every month, it’s crucial for us to have a firm grasp of<strong> the entire system at any time</strong>. Since we made a production release, <strong>stability has become our number one priority.</strong> It’s also probably the biggest challenge that we will face in the future.</p>



<figure><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101"><img src="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg" alt="Start with cloud automation" srcset="https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1024x614.jpg 1024w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-300x180.jpg 300w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-768x461.jpg 768w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-1536x922.jpg 1536w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01-667x400.jpg 667w, https://mk0microtica2di3k2co.kinstacdn.com/wp-content/uploads/2020/07/asdlasflsdag-01.jpg 2000w" sizes="100vw"></a></figure>



<h2><a href="https://portal.microtica.com/register#_ga=2.13603763.541818503.1594369331-624050701.1579084101" target="_blank" rel="noreferrer noopener">Sign up for Microtica</a> and start with cloud automation today.</h2>
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:identifier="https://microtica.com/an-outstanding-cloud-automation-experience/"
    dc:title="Developers Say: An Outstanding Cloud Automation Experience"
    trackback:ping="https://microtica.com/an-outstanding-cloud-automation-experience/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://microtica.com/an-outstanding-cloud-automation-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823272</guid>
            <pubDate>Mon, 13 Jul 2020 17:31:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling WebSocket in Go and Beyond]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823132">thread link</a>) | @FZambia
<br/>
July 13, 2020 | https://centrifugal.github.io/centrifugo/blog/scaling_websocket/ | <a href="https://web.archive.org/web/*/https://centrifugal.github.io/centrifugo/blog/scaling_websocket/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              

                
                  <a href="https://github.com/centrifugal/centrifugo/edit/master/docs/content/blog/scaling_websocket.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                  
                
                
                
<p><img alt="gopher-broker" src="https://i.imgur.com/QOJ1M9a.png"></p>
<p>I believe that in 2020 WebSocket is still an entertaining technology which is not so well-known and understood like HTTP. In this blog post I'd like to tell about state of WebSocket in Go language ecosystem, and a way we could write scalable WebSocket servers with Go and beyond Go.</p>
<p>We won't talk a lot about WebSocket transport pros and cons – I'll provide links to other resources on this topic. Most advices here are generic enough and can be easily approximated to other programming languages. Also in this post we won't talk about ready to use solutions (if you are looking for it – check out <a href="https://www.leggetter.co.uk/real-time-web-technologies-guide/">Real-time Web Technologies guide</a> by Phil Leggetter), just general considerations. There is not so much information about scaling WebSocket on the internet so if you are interested in WebSocket and real-time messaging technologies - keep on reading.</p>
<p>If you don't know what WebSocket is – check out the following curious links:</p>
<ul>
<li><a href="https://hpbn.co/websocket/">https://hpbn.co/websocket/</a> – a wonderful chapter of great book by Ilya Grigorik</li>
<li><a href="https://lucumr.pocoo.org/2012/9/24/websockets-101/">https://lucumr.pocoo.org/2012/9/24/websockets-101/</a> – valuable thoughts about WebSocket from Armin Ronacher</li>
</ul>
<p>As soon as you know WebSocket basics – we can proceed.</p>
<h2 id="websocket-server-tasks">WebSocket server tasks<a href="#websocket-server-tasks" title="Permanent link">¶</a></h2>
<p>Speaking about scalable servers that work with many persistent WebSocket connections – I found several important tasks such a server should be able to do:</p>
<ul>
<li>Maintain many active connections</li>
<li>Send many messages to clients</li>
<li>Support WebSocket fallback to scale to every client</li>
<li>Authenticate incoming connections and invalidate connections</li>
<li>Survive massive reconnect of all clients without loosing messages</li>
</ul>
<div>
<p>Note</p>
<p>Of course not all of these points equally important in various situations.</p>
</div>
<p>Below we will look at some tips which relate to these points.</p>
<p><img alt="one_hour_scale" src="https://i.imgur.com/4lYjJSP.png"></p>
<h2 id="websocket-libraries">WebSocket libraries<a href="#websocket-libraries" title="Permanent link">¶</a></h2>
<p>In Go language ecosystem we have several libraries which can be used as a building block for a WebSocket server.</p>
<p>Package <a href="https://godoc.org/golang.org/x/net/websocket">golang.org/x/net/websocket</a> is considered <strong>deprecated</strong>.</p>
<p>The default choice in the community is <a href="https://github.com/gorilla/websocket">gorilla/websocket</a> library. Made by Gary Burd (who also gifted us an awesome <a href="https://github.com/gomodule/redigo">Redigo</a> package to communicate with Redis) – it's widely used, performs well, has a very good API – so in most cases you should go with it. Some people think that library not actively maintained at moment – but this is not quite true, it implements full WebSocket RFC, so actually it can be considered done.</p>
<p>In 2018 my ex-colleague Sergey Kamardin open-sourced <a href="https://github.com/gobwas/ws">gobwas/ws</a> library. It provides a bit lower-level API than <code>gorilla/websocket</code> thus allows reducing RAM usage per connection and has nice optimizations for WebSocket upgrade process. It does not support WebSocket <code>permessage-deflate</code> compression but otherwise a good alternative you can consider using. If you have not read Sergey's famous post <a href="https://www.freecodecamp.org/news/million-websockets-and-go-cc58418460bb/">A Million WebSockets and Go</a> – make a bookmark!</p>
<p>One more library is <a href="https://github.com/nhooyr/websocket">nhooyr/websocket</a>. It's the youngest one and actively maintained. It compiles to WASM which can be a cool thing for someone. The API is a bit different from what <code>gorilla/websocket</code> offers, and one of the big advantages I see is that it solves a problem with a proper WebSocket closing handshake which is <a href="https://github.com/gorilla/websocket/issues/448">a bit hard to do right with Gorilla WebSocket</a>.</p>
<p>You can consider all listed libraries except one from <code>x/net</code> for your project. Take a library, follow its examples (make attention to goroutine-safety of various API operations). Personally I prefer Gorilla WebSocket at moment since it's feature-complete and battle tested by tons of projects around Go world.</p>
<h2 id="os-tuning">OS tuning<a href="#os-tuning" title="Permanent link">¶</a></h2>
<p>OK, so you have chosen a library and built a server on top of it. As soon as you put it in production the interesting things start happening.</p>
<p>Let's start with several OS specific key things you should do to prepare for many connections from WebSocket clients.</p>
<p>Every connection will cost you an open file descriptor, so you should tune a maximum number of open file descriptors your process can use. An errors like <code>too many open files</code> raise due to OS limit on file descriptors which is usually 256-1024 by default (see with <code>ulimit -n</code> on Unix). A nice overview on how to do this on different systems can be found <a href="https://docs.riak.com/riak/kv/2.2.3/using/performance/open-files-limit.1.html">in Riak docs</a>. Wanna more connections? Make this limit higher.</p>
<p>Nice tip here is to limit a maximum number of connections your process can serve – making it less than known file descriptor limit:</p>
<div><pre><span></span><code><span>//&nbsp;ulimit&nbsp;-n&nbsp;==&nbsp;65535</span>
<span>if</span> <span>conns</span><span>.</span><span>Len</span><span>()</span> <span>&gt;=</span> <span>65500</span> <span>{</span>
    <span>return</span> <span>errors</span><span>.</span><span>New</span><span>(</span><span>"connection&nbsp;limit&nbsp;reached"</span><span>)</span>
<span>}</span>
<span>conns</span><span>.</span><span>Add</span><span>(</span><span>conn</span><span>)</span>
</code></pre></div>

<p>– otherwise you have a risk to not even able to look at <code>pprof</code> when things go bad. And you always need monitoring of open file descriptors.</p>
<p>Keep attention on <em>Ephemeral ports</em> problem which is often happens between your load balancer and your WebSocket server. The problem arises due to the fact that each TCP connection uniquely identified in the OS by the 4-part-tuple:</p>
<div><pre><span></span><code>source ip | source port | destination ip | destination port
</code></pre></div>

<p>On balancer/server boundary you are limited in 65536 possible variants by default. But actually due to some OS limits and sockets in TIME_WAIT state the number is even less. A very good explanation and how to deal with it can be found <a href="https://making.pusher.com/ephemeral-port-exhaustion-and-how-to-avoid-it/">in Pusher blog</a>.</p>
<p>Your possible number of connections also limited by conntrack table. Netfilter framework which is part of iptables keeps information about all connections and has limited size for this information. See how to see its limits and instructions to increase <a href="https://morganwu277.github.io/2018/05/26/Solve-production-issue-of-nf-conntrack-table-full-dropping-packet/">in this article</a>.</p>
<p>One more thing you can do is tune your network stack for performance. Do this only if you understand that you need it. Maybe start <a href="https://gist.github.com/mustafaturan/47268d8ad6d56cadda357e4c438f51ca">with this gist</a>, but don't optimize without full understanding why you are doing this. </p>
<h2 id="sending-many-messages">Sending many messages<a href="#sending-many-messages" title="Permanent link">¶</a></h2>
<p>Now let's speak about sending many messages. The general tips follows.</p>
<p><strong>Make payload smaller</strong>. This is obvious – fewer data means more effective work on all layers. BTW WebSocket framing overhead is minimal and adds only 2-8 bytes to your payload. You can read detailed dedicated research in <a href="https://crossbario.com/blog/Dissecting-Websocket-Overhead/">Dissecting WebSocket's Overhead</a> article. You can reduce an amount of data traveling over network with <code>permessage-deflate</code> WebSocket extension, so your data will be compressed. Though using <code>permessage-deflate</code> is not always a good thing for server due to <a href="https://github.com/gorilla/websocket/issues/203">poor performance of flate</a>, so you should be prepared for a CPU and RAM resource usage on server side. While Gorilla WebSocket has a lot of optimizations internally by reusing flate writers, overhead is still noticeable. The increase value heavily depends on your load profile.</p>
<p><strong>Make less system calls</strong>. Every syscall will have a constant overhead, and actually in WebSocket server under load you will mostly see read and write system calls in your CPU profiles. An advice here – try to use client-server protocol that supports message batching, so you can join individual messages together.</p>
<p><strong>Use effective message serialization protocol</strong>. Maybe use code generation for JSON to avoid extensive usage of reflect package done by Go std lib. Maybe use sth like <a href="https://github.com/gogo/protobuf">gogo/protobuf</a> package which allows to speedup Protobuf marshalling and unmarshalling. Unfortunately Gogo Protobuf <a href="https://github.com/gogo/protobuf/issues/691">is going through hard times
</a> at this moment. Try to serialize a message only once when sending to many subscribers.</p>
<p><strong>Have a way to scale to several machines</strong> - more power, more possible messages. We will talk about this very soon.</p>
<h2 id="websocket-fallback-transport">WebSocket fallback transport<a href="#websocket-fallback-transport" title="Permanent link">¶</a></h2>
<p><img alt="ie" src="https://i.imgur.com/IAOyvmg.png"></p>
<p>Even in 2020 there are still users which cannot establish connection with WebSocket server. Actually the problem mostly appears with browsers. Some users still use old browsers. But they have a choice – install a newer browser. Still, there could also be users behind corporate proxies. Employees can have a trusted certificate installed on their machine so company proxy can re-encrypt even TLS traffic. Also, some browser extensions can block WebSocket traffic.</p>
<p>One ready solution to this is <a href="https://github.com/igm/sockjs-go/">Sockjs-Go</a> library. This is a mature library that provides fallback transport for WebSocket. If client does not succeed with WebSocket connection establishment then client can use some of HTTP transports for client-server communication: <a href="https://hpbn.co/server-sent-events-sse/">EventSource aka Server-Sent Events</a>, XHR-streaming, Long-Polling etc. The downside with those transports is that to achieve bidirectional communication you should use sticky sessions on your load balancer since SockJS keeps connection session state in process memory. We will talk about many instances of your WebSocket server very soon.</p>
<p>You can implement WebSocket fallback yourself, this should be simple if you have a sliding window message stream on your backend which we will discuss very soon.</p>
<p>Maybe look at <a href="https://grpc.io/docs/what-is-grpc/introduction/">GRPC</a>, depending on application it could be better or worse than WebSocket – in general you can expect a better performance and less resource consumption from WebSocket for bidirectional communication case. My measurements for a <strong>bidirectional</strong> scenario showed 3x win for WebSocket (binary + GOGO protobuf) in terms of server CPU consumption and 4 times less RAM per connection. Though if you only need RPC then GRPC can be a better choice. But you need additional proxy to work with GRPC from a browser. </p>
<h2 id="performance-is-not-scalability">Performance is not scalability<a href="#performance-is-not-scalability" title="Permanent link">¶</a></h2>
<p>You can optimize client-server protocol, tune your OS, but at some point you won't be able to use only one process on one server machine. You need to scale connections and work your server does over different server machines. Horizontal scaling is also good for a server high availability. Actually there are some sort of real-time applications where a single isolated process makes sense - for example multiplayer games where limited number of players play independent game rounds.</p>
<p><img alt="many_instances" src="https://i.imgur.com/8ElqpjI.png"></p>
<p>As soon as you distribute connections over several machines you have to find a way to deliver a message to a certain user. The basic …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://centrifugal.github.io/centrifugo/blog/scaling_websocket/">https://centrifugal.github.io/centrifugo/blog/scaling_websocket/</a></em></p>]]>
            </description>
            <link>https://centrifugal.github.io/centrifugo/blog/scaling_websocket/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823132</guid>
            <pubDate>Mon, 13 Jul 2020 17:19:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SemVer Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23823043">thread link</a>) | @aaronblohowiak
<br/>
July 13, 2020 | https://jolynch.github.io/posts/semver_considered_harmful/ | <a href="https://web.archive.org/web/*/https://jolynch.github.io/posts/semver_considered_harmful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>In the past ten years or so, <a href="https://semver.org/">Semantic Versioning</a> a.k.a
“SemVer” has become extremely popular in the software development world. The
idea is that libraries and services can convey information to users about how
the application programming interface
(<a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a>) of
that library/package/service is evolving just using the version number. This
information is conveyed through three dotted numbers that form a logical clock
for totally ordering changes to the software API:</p>

<center><h3>Semantic Version Numbers</h3></center>
<div><pre><code data-lang="text">====================== Specification ========================

Version = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;

Major: this number goes up when the public API breaks
Minor: this number goes up when the public API changes
Patch: this number goes up when the public API doesn't change

====================== Examples =============================

# A Minor API change happened, safe to upgrade
1.4.5 -&gt; 1.5.0

# API breakage, probably unsafe to upgrade
1.7.0 -&gt; 2.0.0

# Who knows what will happen
0.182.13 -&gt; 0.182.14
=============================================================</code></pre></div>

<p>Armed with this information, software developers can theoretically upgrade
without fear of the new version breaking their code.</p>



<p>I believe that this versioning scheme, in practice, is problematic and creates
a large amount of pain in our industry. Three concrete failure modes I witness
frequently are:</p>

<ol>
<li>Most packaging systems (deb, rpm, python, ruby, java, etc …) cannot
simultaneously install multiple major versions of the same package name.
This often leaves users unable to upgrade to the latest major version due to
(reasonable) fear of breakages.</li>
<li>Frequent major version bumps frequently break functional code, leading
to <a href="https://en.wikipedia.org/wiki/Dependency_hell">dependency hell</a> where
library/service authors mix and match min, max, and exact version pins on
major versions to try to work around various incompatibilities. These pins
inevitably conflict.</li>
<li>There is still no standard way to derive the source code which produced the
artifact or seeing the difference between two versions. This makes it hard
to verify how the API is breaking or whether it will break specific usage
patterns.</li>
</ol>

<p>There is also the somewhat annoying issue of the plethora of <code>0.X</code> artifacts,
which happen because developers, somewhat reasonably, don’t want to release
a public API they will have to stand behind until they can be certain they
can.</p>

<p>Ultimately these factors lead to software developers, myself included, viewing
dependency upgrades with great trepidation. Quite reasonably developers defend
themselves from breakage by either not upgrading their dependencies (unless
they are forced to), vendoring dependent code, or skipping dependencies all
together and just writing it themselves.</p>

<h2 id="reduce-the-fear-breaking-versions-must-cohabitate">Reduce the Fear: Breaking Versions Must Cohabitate</h2>

<p>The use of the major version number in SemVer to indicate API breakage is by
far the most problematic aspect of the design. In an ideal world, packaging
systems and programming languages would automatically namespace different major
versions, and code that depends on a particular major version would have all
references specifically reference the major version namespace. Unfortunately,
we do not live in an ideal world and most packaging systems simply don’t
support this.  Three examples that I personally struggle with frequently:</p>

<p><strong>Debian packages (<code>apt</code>/<code>aptitude</code> in particular)</strong>: You only get one version
and the higher one is almost always chosen even if that may break less-than
pins. A common practice with debian packages to work around these limitations
is to release new packages with a different name.</p>

<p><strong>Java libraries (<code>mvn</code>/<code>gradle</code> in particular)</strong>: In a given class path you
can only have one implementation of a given package. Even if you manage to
convince gradle or maven to pull down multiple versions of a <code>.jar</code>, good luck
getting the JVM to not pick one implementation arbitrarily. As a result, Java
developers often resort to hacks like
<a href="https://imperceptiblethoughts.com/shadow/">package path rewriting</a>.</p>

<p><strong>Python libraries (<code>pip</code> in particular)</strong>: While the Python community has
moved towards isolated virtual environments which does make this issue slightly
less of an issue (and with tools like <code>docker</code> or
<a href="https://github.com/spotify/dh-virtualenv"><code>dhvirtualenv</code></a> it gets even
better), you still can’t install multiple versions of the same package in the
same virtualenv. Most Python projects I am aware of either don’t work around
this and break all the things, or release multiple package names.</p>

<p>These problems are even worse for client libraries, where the library is wrapping a
remote (often backwards incompatible) API change. For me this has been one of the
hardest parts of upgrading distributed datastores that I work on because we
often can’t use the vanilla client libraries during migration (e.g.
<a href="https://curator.apache.org/">Curator</a> 2 vs Curator 4, Elasticsearch 2 vs 5,
etc …). In my experience with most client library upgrades you have to create
an internal company fork that renames and relocates the package so we can run
both datastore APIs at the same time and have the client gracefully migrate
from the old version to the new one.</p>

<p>In an ideal world, remote APIs would remain backwards compatible for at least a
single major version to give users an upgrade path, but I find that many
developers argue that they don’t need to remain backwards compatible across a
major version (this is what SemVer says after all …). I wish this argument
was soundly rejected.</p>

<p>How can we fix this problem given the current constraints we operate under?
Well, we are left with a reasonably simple option: <strong>put the API version
semantics in the name of the package.</strong> Some example API migrations where I
have been able to take advantage of this technique are:</p>

<ul>
<li><code>boto</code> to <code>boto3</code> (Python,
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">docs</a>):
An extremely prevalent library for accessing AWS services</li>
<li><code>elasticsearch</code> to <code>elasticsearch2</code> (Python, <a href="https://github.com/elastic/elasticsearch-py/issues/515">motivation</a>): A Python client library for the
Elasticsearch search engine.</li>
<li>Every Linux kernel package ever (the Linux kernel has this figured out!). The
Kernel not only prohibits breaking user-space, but they give their users a
great way to install multiple kernels at the same time.</li>
<li>Cassandra’s Thrift API
(<a href="https://github.com/Netflix/Astyanax">Netflix Astyanax</a>)
to Cassandra’s CQL API
(<a href="https://github.com/datastax/java-driver">Datastax Java Driver</a>): The client
drivers for the Cassandra database.</li>
</ul>

<h2 id="reduce-the-fear-binary-versions-can-be-traced-to-source">Reduce the Fear: Binary Versions Can be Traced to Source</h2>

<p>In my experience, software engineers spend a non trivial amount of time trying
to figure out “what actually changed between these two released versions”. One
of the explicit goals of <code>SemVer</code> was to help developers reason about change.
As a developer myself I accidentally break things in minor versions all the
time, so I understand that this can happen. I don’t mind the breakage as much
as being unable to debug what broke, since projects use many different ways of
relating released versions to code.</p>

<p>Some projects do use <a href="https://git-scm.com/book/en/v2/Git-Basics-Tagging">git
tags</a> to achieve this
auditability, but this isn’t mandatory so some (many?) projects don’t do it.
The commit id may, in some cases, be a better identifier since the commit id
must exist and <code>git</code> has a really easy way to view <a href="https://git-scm.com/docs/git-diff">changes between two
commits</a>. In fact, as far as I know, the
commit id is always easily comparable in practically every source control
system.</p>

<p><a href="https://en.wikipedia.org/wiki/Changelog">Changelogs</a> are also <em>nice</em>, but
while I can typically assume projects use source control since it is strictly
easier than not using source control, I don’t think it is reasonable to expect
developers, often working for free, to take the time to summarize their
software changes into English changelogs. Writing clear and actionable English
is difficult, potentially more difficult than the code itself. Certainly, I
appreciate every project maintainer who takes the time to summarize changes in
a release, but I don’t think it’s fair to <em>expect</em> it in the same way most
consumers of software expect producers to use source control.</p>



<p>Both of these problems can be remedied with a straightforward evolution to
<code>SemVer</code> in which we make some small changes to include a great deal more
semantic information in the package name and version number. I call it
semantic package names and it consists of two changes:</p>

<ol>
<li>Use package (=module) names to indicate an API has broken, not versions.</li>
<li>Attempt to include a source identifier in the version.</li>
</ol>

<p>For example, <code>elasicsearch5</code> is the python library that functions with the
Elasticsearch server version 5.  Applications such as Elasticsearch or
Cassandra release named packages that unambiguously communicate the major
version API that is supported by that package. One possible example for Apache
Cassandra might be <code>cassandra-21x</code>, <code>cassandra-30x</code>, <code>cassandra-311x</code>, and
<code>cassandra-40x</code> for the <code>2.1</code>, <code>3.0</code>, <code>3.11</code>, <code>4.0</code> branches respectively.</p>

<p>I know this is not new, many software projects already follow this kind of scheme
such as the Linux kernel (a.k.a “Never break userspace”) or the Go
<a href="https://golang.org/cmd/go/#hdr-Module_compatibility_and_semantic_versioning">programming language</a>.
I just believe that if every software project and language I interacted with
followed this pattern the whole industry would become more efficient and spend
less time fearing dependency updates. I have also found myself using this
technique internally to every company I’ve worked at to manage software change.</p>

<p>In addition to using semantic package names, I prefer when packages include a
fourth piece of metadata in their version number indicating the source version
that produced the artifact. Depending on the packaging system this is usually
either another dotted version (making it a four-tuple) or a <code>-</code> suffix.</p>

<center><h3> Better Semantic Versioning </h3></center>

<div><pre><code data-lang="text">====================== Specification ========================
&lt;Package Version&gt; = &lt;Package Name&gt;:&lt;Version Number&gt;
&lt;Version Number&gt;  = &lt;Major&gt;.&lt;Minor&gt;.&lt;Patch&gt;&lt;Identifier&gt;

Package Name: This name changes when the public API breaks
Major: this number goes up with "major" public API additions
Minor: this number goes up with "minor" public API additions
Patch: this number goes up on every release
Identifier: For packaging systems that support it, this
            string relates directly to a specific source
            code that produced the artifact.

An example of an identifier in git would be the first 8</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jolynch.github.io/posts/semver_considered_harmful/">https://jolynch.github.io/posts/semver_considered_harmful/</a></em></p>]]>
            </description>
            <link>https://jolynch.github.io/posts/semver_considered_harmful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823043</guid>
            <pubDate>Mon, 13 Jul 2020 17:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Econometrics with R]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23823031">thread link</a>) | @ethanwillis
<br/>
July 13, 2020 | https://www.econometrics-with-r.org/index.html | <a href="https://web.archive.org/web/*/https://www.econometrics-with-r.org/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">
<p>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span>selecting it with the cursor</span> and then click the <i></i> on the pop-up menu. You can also see the annotations of others: click the <i></i> in the upper right hand corner of the page 
</p>

<div id="preface">

<hr>
<center>
<img src="https://www.econometrics-with-r.org/images/cover.png">
</center>
<div><p> Chair of Econometrics <img src="https://www.econometrics-with-r.org/images/logo_claim_en_rgb.png"> <br> Department of Business Administration and Economics <br> University of Duisburg-Essen <br> Essen, Germany <br> <a href="https://www.econometrics-with-r.org//%22mailto:info@econometrics-with-r.org?subject=Econometrics%20with%20R\%22">info@econometrics-with-r.org</a></p><p> Last updated on Friday, August 30, 2019
</p>
</div>
<hr>
<p>Over the recent years, the statistical programming language R has become an integral part of the curricula of econometrics classes we teach at the University of Duisburg-Essen. We regularly found that a large share of the students, especially in our introductory undergraduate econometrics courses, have not been exposed to any programming language before and thus have difficulties to engage with learning R on their own. With little background in statistics and econometrics, it is natural for beginners to have a hard time understanding the benefits of having R skills for learning and applying econometrics. These particularly include the ability to conduct, document and communicate empirical studies and having the facilities to program simulation studies which is helpful for, e.g., comprehending and validating theorems which usually are not easily grasped by mere brooding over formulas. Being applied economists and econometricians, all of the latter are capabilities we value and wish to share with our students.</p>
<p>Instead of confronting students with pure coding exercises and complementary classic literature like the book by <span>Venables &amp; Smith (<a href="#ref-venables2010" role="doc-biblioref">2010</a>)</span>, we figured it would be better to provide interactive learning material that blends R code with the contents of the well-received textbook <em>Introduction to Econometrics</em> by <span>Stock &amp; Watson (<a href="#ref-stock2015" role="doc-biblioref">2015</a>)</span> which serves as a basis for the lecture. This material is gathered in the present book <em>Introduction to Econometrics with R</em>, an empirical companion to <span>Stock &amp; Watson (<a href="#ref-stock2015" role="doc-biblioref">2015</a>)</span>. It is an interactive script in the style of a reproducible research report and enables students not only to learn how results of case studies can be replicated with R but also strengthens their ability in using the newly acquired skills in other empirical applications.</p>
<div id="conventions-used-in-this-book">
<h4>Conventions Used in this Book</h4>
<ul>
<li><p><em>Italic</em> text indicates new terms, names, buttons and alike.</p></li>
<li><p><tt>Constant width text</tt> is generally used in paragraphs to refer to <tt>R</tt> code. This includes commands, variables, functions, data types, databases and file names.</p></li>
<li><p><code>Constant width text on gray background</code> indicates <tt>R</tt> code that can be typed literally by you. It may appear in paragraphs for better distinguishability among executable and non-executable code statements but it will mostly be encountered in shape of large blocks of <tt>R</tt> code. These blocks are referred to as code chunks.</p></li>
</ul>
</div>
<div id="acknowledgement">
<h4>Acknowledgement</h4>
<p>We thank the <em>Stifterverband für die Deutsche Wissenschaft e.V.</em> and the <em>Ministry of Science and Research North Rhine-Westphalia</em> for their financial support. Also, we are grateful to Alexander Blasberg for proofreading and his effort in helping with programming the exercises.
A special thanks goes to Achim Zeileis (University of Innsbruck) and Christian Kleiber (University of Basel) for their advice and constructive criticism. Another thanks goes to Rebecca Arnold from the Münster University of Applied Sciences for several suggestions regarding the website design and for providing us with her nice designs for the book cover, logos and icons. We are also indebted to all past students of our introductory econometrics courses at the University of Duisburg-Essen for their feedback.</p>
<p><br>
<img src="https://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by-nc-sa.eu.svg" alt="Creative Commons License"></p>
<p>This book is licensed under the <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
</div>
</div>
<h3>References</h3>
<div id="refs">
<p>Stock, J. H., &amp; Watson, M. W. (2015). <em>Introduction to Econometrics, Third Update, Global Edition</em>. Pearson Education Limited.</p>

</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://www.econometrics-with-r.org/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23823031</guid>
            <pubDate>Mon, 13 Jul 2020 17:09:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do the fundamentals well. Do them consistently. Do them with style]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822955">thread link</a>) | @designthinker
<br/>
July 13, 2020 | https://jwgoerlich.com/frameworks-fade-but-security-is-eternal-design-monday/ | <a href="https://web.archive.org/web/*/https://jwgoerlich.com/frameworks-fade-but-security-is-eternal-design-monday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<p>Frameworks fade but security is eternal. Said with apologies to Yves Saint Laurent.</p>



<p><a href="https://en.wikipedia.org/wiki/Yves_Saint_Laurent_(designer)">Yves Saint Laurent</a> was a dominant force in fashion from the 1960s through to end of the century. His strengths stemmed from three areas. First, seeing the underlying fundamentals and being able to re-envision them across genders, across times, and across trends. Second, the ability to cross artforms for inspiration, most notably with Piet Mondrian and geometrical shapes. Finally, the ability to reformulate high fashion at couture for mass production. Yves Saint Laurent was the first to open a ready-to-wear line in Paris. He was a designer who mastered how to take the pieces apart and put them back together for new tastes and new markets. It Yves Saint Laurent who once famously said, “fashion fades but style is eternal.”</p>



<p>Last week, we looked at how the adoption of a control — <a href="https://jwgoerlich.com/ahead-of-the-curve-design-monday/">doing something right but rare</a> — has surprising stopping power against common attacks. But the fast-changing early adoption must be balanced with slow-changing fundamentals.</p>



<p>CyberSecurity can be a bit too much like fashion. Every major event, there’s a new trend. The media buzz will say that new threats appear every day. The buzz is that our ways of defending become dated and ineffective as quickly as they’re implemented. New frameworks cry out that the old ways were wrong.</p>



<p>This last bit is particularly on my mind in 2020. A new version of the CIS Critical Security Controls came out late last year. NIST is releasing a new version of its standard for security and privacy controls (NIST SP 500-53B). And the new PCI DSS (Data Security Standard) for credit card security is due any time now. Each framework will be accompanied by a wave of press on how everything has changed. The last version is so last season, and simply won’t do.</p>



<p>But is it? Is it really?</p>



<p>Like style, fundamentals in security remain the same even while the specifics evolve. We need to know our people and our technology. We need visibility into what’s happening and what’s changing. We need to think in terms of lifecycles and act in terms of incidents. We need to make sure the simple habits that result in defensible positions are done regularly. Finally, we need to understand the adversary’s objectives and tactics. From mainframes to data centers to cloud infrastructures to tomorrow, the fundamentals hold true.</p>



<p>A security architecture is comprised of a series of building blocks. Some building blocks should be innovative and ahead of our peers. Most building blocks should do the fundamentals and broadly cover the frameworks. </p>



<p>Do the fundamentals well. Do them consistently. Do them with style.</p>



<figure><img src="https://jwgoerlich.com/wp-content/uploads/2020/05/Yves-Saint-Laurent-Piet-Mondrian.png" alt="" srcset="https://jwgoerlich.com/wp-content/uploads/2020/05/Yves-Saint-Laurent-Piet-Mondrian.png 1024w, https://jwgoerlich.com/wp-content/uploads/2020/05/Yves-Saint-Laurent-Piet-Mondrian-300x169.png 300w, https://jwgoerlich.com/wp-content/uploads/2020/05/Yves-Saint-Laurent-Piet-Mondrian-768x432.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<hr>



<p><em>This article is part of a series on designing cyber security capabilities. To see other articles in the series, including a full list of design principles,&nbsp;</em><a href="https://jwgoerlich.com/principles-for-designing-security-capabilities/"><em>click here</em></a><em>.</em></p>
																		<p><span>Posted </span><a href="https://jwgoerlich.com/frameworks-fade-but-security-is-eternal-design-monday/" title="6:00 am" rel="bookmark"><time datetime="2020-07-13T06:00:00-04:00" pubdate="">July 13, 2020</time></a> by 					</p></div></div>]]>
            </description>
            <link>https://jwgoerlich.com/frameworks-fade-but-security-is-eternal-design-monday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822955</guid>
            <pubDate>Mon, 13 Jul 2020 17:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Should I Learn to Code? 17 Reasons to Learn Programming]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822952">thread link</a>) | @mdziubek
<br/>
July 13, 2020 | https://codersbible.com/why-should-i-learn-to-code-17-reasons-to-learn-programming/ | <a href="https://web.archive.org/web/*/https://codersbible.com/why-should-i-learn-to-code-17-reasons-to-learn-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://codersbible.com/why-should-i-learn-to-code-17-reasons-to-learn-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822952</guid>
            <pubDate>Mon, 13 Jul 2020 17:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula Webinar: Infrastructure as Code in OpenNebula using Terraform]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822942">thread link</a>) | @amarti
<br/>
July 13, 2020 | https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw | <a href="https://web.archive.org/web/*/https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Terraform, the open source Infrastructure as Code software tool created by HashiCorp, is a solution for building, changing, and versioning infrastructure safely and efficiently. It allows infrastructure to be expressed as code in a simple, human readable language called HCL. Terraform reads configuration files and provides an execution plan of changes, which can be reviewed for safety and then applied and provisioned automatically.</p><p>What to expect from this webinar?</p><p>- Learn about Terraform’s Infrastructure as Code approach and about its basic uses and capabilities, including the value it provides for managing the full lifecycle of your infrastructure, plan and predict changes, and create reproducible environments.</p><p>- Discover the new version and future roadmap of the OpenNebula Provider, through which cloud admins can use Terraform to interact with OpenNebula cluster resources.</p><p>- Watch a live demo on how this amazing integration is being used in an actual cloud, and how to simplify a real infrastructure workflow by using the OpenNebula Provider for Terraform.</p><p>This webinar will be presented by Michael Abdou (Customer Success Manager at OpenNebula). Our guest speakers for this event will be Taylor Dolezal (Senior Developer Advocate at HashiCorp) and Jean-Philippe Fourès (Cloud Product Manager at Iguane Solutions).</p><p>Press and media, please contact: events@opennebula.io
</p></div></div>]]>
            </description>
            <link>https://us02web.zoom.us/webinar/register/1415946280488/WN_wWYG2H3tQjOEdUnAGPVeQw</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822942</guid>
            <pubDate>Mon, 13 Jul 2020 17:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effecftive Poster Design for Science Communication [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23822939">thread link</a>) | @pabloem
<br/>
July 13, 2020 | http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf | <a href="https://web.archive.org/web/*/http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://mkweb.bcgsc.ca/poster.design/poster.guidelines.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822939</guid>
            <pubDate>Mon, 13 Jul 2020 17:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Document your Theory of The Program as a team]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822892">thread link</a>) | @bckmn
<br/>
July 13, 2020 | https://www.joshbeckman.org/2020/07/12/on-theory-building-as-an-engineering-team/ | <a href="https://web.archive.org/web/*/https://www.joshbeckman.org/2020/07/12/on-theory-building-as-an-engineering-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p>Recently, I was reading <a href="http://brooker.co.za/blog/2020/06/23/code.html">Marc Booker’s post</a> about the need for documentation outside of the codebase.
<a href="https://news.ycombinator.com/item?id=23751652">A thoughtful comment</a> on the post led me to <a href="http://pages.cs.wisc.edu/~remzi/Naur.pdf">Peter Naur’s paper on Programming as Theory Building</a>, which I recommend reading<sup id="fnref:1"><a href="#fn:1">1</a></sup>.
In it, Naur argues that the act of programming is not a practice of writing code but the work of creating a theory of the problem at hand and a theory of the system to address it.
As a team exercise, we practiced documenting our theories of the OfficeLuv system and found it very rewarding.</p>

<p>In my mind, there is a hierarchy of explanatory documentation that programmers pass between each other.
At the bottom there is the pulse of the commit history.
This documentation is a permanent record, but the explanations themselves are brief, incomplete, and ephemeral.</p>

<p>The next level consists of comments in the code itself.
These explanations are often even more brief, but sit in plain sight and directly beside their subjects.</p>

<p>Above comments, we have <a href="http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions">Architecture Decision Records</a> (ADRs).
These are structured stories about features or services that are written and read outside of the actual program material.
We’ve begun adopting this level of documentation at OfficeLuv over the last couple months (with several benefits, which I’ll probably write about in the future).
I would also lump Requests for Comment (RFCs) and documents like that into this level.</p>

<p>I think Naur’s idea of Theory Building fits as a flavor of documentation one level higher.
The central assumptions about what our system should handle and what it operates on are foundational.
These read like laws of physics, but for the worldview and inner-workings of the system.
This documentation informs other contributors on how to best extend the current program, and which rules we would hesitate to violate.</p>

<p>I’ve never read this kind of documentation at the level of a program or system before.
The closest that comes to mind are Rails’ “<a href="https://en.m.wikipedia.org/wiki/Convention_over_configuration">Convention over configuration</a>”, the <a href="https://en.m.wikipedia.org/wiki/Zen_of_Python">Zen of Python</a> guiding principles, or even OfficeLuv’s <a href="https://github.com/officeluv/heart-of-a-developer">Heart of a Developer</a> proverbs.
But these just provide a breezy direction as to how we should go about our programming.
The <em>Theory of The Program</em> can be much more direct about the boundaries and patterns of the worldview from within our specific program.</p>

<p>To that end, I had the OfficeLuv engineering team practice documenting our own theories of our system.
Each of us took a couple days and wrote up our individual theories, which we then shared together.
Multiple theories overlapped between us, which reassured us that we agreed on what a theory should be.
Tenets that applied only to a subsystem we decided to extract as ADRs.
We now have a Theory of The OfficeLuv System at the top level of our documentation and we’ll continue to evolve it as we build.</p>

<p>I wish we had started this practice earlier - I would <em>love</em> to read what our previous teams had held as theory.
Contrasting the worldview from two years ago would be interesting to measure against the problems we face now.
This document will be used during onboarding and for guidance in feature-building as we grow.
And having these theories on hand for our next hire will allow them to begin contributing more effectively on day one.</p>

<h2 id="tips-for-writing-your-own-theories">Tips for Writing Your Own Theories</h2>

<p>Naur recommends identifying a clear metaphor as the best way to convey the Theory of The Program.
I found this exceedingly difficult, even for a startup like OfficeLuv.
I could readily think of metaphors for subsystems, but I wouldn’t recommend spending too much time finding a metaphor for a sufficiently large project.
If you can find one, congrats.</p>

<p>I think it’s key to have each team member write their theories on their own.
This increases the diversity of ideas that you can combine into your group theories.
The diversity also prompts you to coalesce similar theories into higher-level rules that become more powerful and applicable.</p>

<p>Don’t spend time trying to pull a single Grand Unifying Theory of The Program out of several individual theories.
Our document ended up as a series of sentences and paragraphs, along with a few references and examples.
Again, I think this may be possible at the subsystem level, but unlikely to exist at the level of a sufficiently complex product.</p>



  
</div>

    </div></div>]]>
            </description>
            <link>https://www.joshbeckman.org/2020/07/12/on-theory-building-as-an-engineering-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822892</guid>
            <pubDate>Mon, 13 Jul 2020 16:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Open Source, licenses and changes]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 26 (<a href="https://news.ycombinator.com/item?id=23822732">thread link</a>) | @nfrankel
<br/>
July 13, 2020 | https://blog.frankel.ch/on-opensource-licenses-changes/ | <a href="https://web.archive.org/web/*/https://blog.frankel.ch/on-opensource-licenses-changes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting"> <meta itemprop="mainEntityOfPage" content="//on-opensource-licenses-changes/"> <meta itemprop="description" content="">  <figure itemscope="" itemprop="image" itemtype="http://schema.org/ImageObject"> <meta itemprop="url" content="https://blog.frankel.ch/assets/resources/open-source-licenses-changing/OSI_Standard_Logo_0.svg"> </figure> <section> <div itemprop="articleBody"> <p>The subject of Open Source and OS licenses has been waxing and waning over time. Recently, it became hot again. In this post, I’d like to do a quick recap to set the stage. Then, I’ll analyze reasons for license changes.</p> <div> <h2 id="the-rise-of-open-source">The rise of Open Source</h2> <div> <p>Before I actually started my career - even I was before even born - software was provided with its source code. The value was in the hardware. Most customers - if not every one of them - modified and adapted the source code to their hardware. Then, in 1969, the United States' government ruled (against IBM) that the bundling of software and hardware together was <em>anticompetitive</em>. The value moved from hardware to software because of an unexpected side-effect of the previous ruling. Thus began the rise of Microsoft Windows. Interestingly enough, that also changed the way software was delivered. Customers only got the binaries, not the source code. Of course, this is mostly the case today.</p> <p>Around ten years later, a new trend started in reaction to that: some with Richard Stallman decided that releasing the source code was the only <em>right</em> way to deliver software. Furthermore, their position was that software should be free. Because that tiny initiative became a respectable model, this view on things is more than relevant today. Today, Open Source means different things in the mind of different people.</p> </div> </div> <div> <h2 id="open-source-is-a-loaded-term">Open Source is a loaded term</h2> <div> <p>Literally, Open Source is only the delivery of the source code along the binary. No more, no less. For commercial software, if carefully worded in the purchasing contract, that means that the customer should be able to maintain the software if the vendor doesn’t anymore (<em>e.g.</em> goes bankrupt). Yet, according to Stallman’s definition, software needs to be free:</p> <div> <blockquote> <ul><li><span>Free as a bird</span></li><li><span>Free as a beer</span></li></ul> </blockquote> </div> <p>To avoid any confusion, I’d rather use the expression Free Open-Source Software <em>a.k.a.</em> FOSS.</p> </div> </div> <div> <h2 id="what-qualifies-as-open-source">What qualifies as Open Source</h2> <div> <p>This gap in the terms were deeply materialized in tensions in the community between tenants of the business-compatible Open Source and FOSS as defined above. From the former group was born the <a href="https://en.wikipedia.org/wiki/Open_Source_Initiative" target="_blank" rel="noopener">Open Source Initiative</a>. The importance of this organization cannot be understated: it decides what licenses are considered Open Source, based on the <a href="https://en.wikipedia.org/wiki/The_Open_Source_Definition">Open Source definition</a>. Criteria are:</p> <ol><li><span>Free Redistribution</span></li><li><span>Source Code</span></li><li><span>Derived Works</span></li><li><span>Integrity of The Author’s Source Code</span></li><li><span>No Discrimination Against Persons or Groups</span></li><li><span>No Discrimination Against Fields of Endeavor</span></li><li><span>Distribution of License</span></li><li><span>License Must Not Be Specific to a Product</span></li><li><span>License Must Not Restrict Other Software</span></li><li><span>License Must Be Technology-Neutral</span></li></ol> <p>As of the time of writing of this post, licenses that are allowed to be qualified as Open Source are <a href="https://opensource.org/licenses/alphabetical" target="_blank" rel="noopener">limited in number</a>. Here’s a couple of them:</p> <ul><li><span><a href="https://opensource.org/licenses/Apache-2.0">Apache License 2.0</a></span></li><li><span><a href="https://opensource.org/licenses/gpl-license">GNU General Public License (GPL)</a></span></li><li><span><a href="https://opensource.org/licenses/lgpl-license" target="_blank" rel="noopener">GNU Library or "Lesser" General Public License (LGPL)</a></span></li><li><span><a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener">MIT license</a></span></li></ul> <p>Here are two counter-examples:</p> <ul><li><span>The <a href="https://github.com/climate-strike/license" target="_blank" rel="noopener">Climate Strike License</a> is not Open Source, as it’s not in the list above</span></li><li><span><a href="https://creativecommons.org/licenses/">Creative Commons licenses</a> are not Open Source, as they don’t apply to software only</span></li></ul> </div> </div> <div> <h2 id="monetizing-open-source">Monetizing Open Source</h2> <div> <p>Open Source began as a community of like-minded people who wanted to create something together, and were willing to put on the extra effort, after office hours. However, today, the main contributors on the main projects are paid by private companies: they code during office hours. The reason for that is that Open Source - not FOSS - is compatible with business.</p> <p>There are a couple of ways to monetize Open Source software:</p> <div> <dl> <dt>Training and consulting</dt> <dd> <p>If you provide a great software, companies will start using it. At some point, there are chances they will need consulting, for advanced usage. After that, they will also need training to level up their workforce. It has been the traditional way to make money with Open Source. Unfortunately, this doesn’t scale.</p> </dd> <dt>Support</dt> <dd> <p>While consulting is planned, support comes in handy when the sh…​ has already hit the fan. Picture this: it’s 10PM, the monitoring Open Source stack your company uses has crashed, and refuse to start again. One definitely needs support in this case. <em>In general</em>, managers don’t like to use any kind of software - whether FOSS, Open Source or something else - if they don’t have an associated support contract.</p> </dd> <dt>Open Source core</dt> <dd> <p>The software offers features that are Open Source. A set of features available via extensions/plugins operate under a commercial (<em>i.e.</em> paying) license. The respective size of each depends on one’s strategy. The more features in the Open Source part, the more people will use it, but the less money one will get. This is a fine balance to find.</p> </dd> <dt>Dual license</dt> <dd> <p>The software is available under two different licenses, one Open Source, the other commercial. When one uses the software, one needs to choose which license should apply. For this model to work, and companies to decide to pay a license fee, the Open Source license should be a deterrent. The <a href="https://opensource.org/licenses/gpl-license" target="_blank" rel="noopener">GNU General Public License</a> is a solid choice: it mandates that software that embeds the GPL software should be released under the GPL license itself <em>i.e.</em> for free.</p> </dd> </dl> </div> </div> </div> <div> <h2 id="service-wrapping">Service-wrapping</h2> <div> <p>It’s no mystery that "the Cloud" has become ubiquitous since a couple of years, whether you like it or not. As more companies moved their IT-systems to the Cloud, the Cloud service providers became a force to be reckoned with. With that power, they bargained with software vendors on ways to provide the latter’s software on their infrastructure. In general, the deal was pretty much one-sided: Cloud providers got a larger portfolio of services, while software vendors got "free advertisement" for their software, and in the best of case, crumbs of the revenue.</p> <p>But even that was not enough. Some cloud providers became so bold as to stop pretending it was even a deal. They just got they greedy hands on the Open Source software, and service-wrapped it. It was completely legal, as none of the licenses prevents that. However, it raises the question of revenue sharing: one company is paying to develop the software, while another company is getting the biggest share of the revenues, because it controls the marketplace.</p> <p>Because of that, some software vendors decided to change their license to prevent service wrapping. The issue is that no Open Source license is able to achieve that. Hence, those new licenses are not considered Open Source, as per the Open Source Initiative definition.</p> </div> </div> <div> <h2 id="other-license-changes">Other license changes</h2> <div> <p>Changing one’s license is in general not a great idea. When somebody uses your software, they need to be able to trust they can use it in the future under the same terms. The anti-service wrapping changes made sure that was the case.</p> <p>Interestingly enough, I saw recently a license change unrelated to service wrapping. In the light of the CoVid-19 pandemics, somebody thought it would be a good idea to change the license to a new one:</p> <div> <blockquote> <p>CoronaVirus License :</p> <p>The coronavirus is coming to you. It’s coming at an exponential speed: gradually, and then suddenly. It’s a matter of days. Maybe a week or two. When it does, your healthcare system will be overwhelmed. Your fellow citizens will be treated in the hallways. Exhausted healthcare workers will break down. Some will die. They will have to decide which patient gets the oxygen and which one dies. The only way to prevent this is social distancing today. Not tomorrow. Today. That means keeping as many people home as possible, starting now.</p> <p>To use this program, you must</p>  <p>2) Apply social distancing</p> <p>If you live in UK, Europe, North &amp; South America, Iran, Japan, Korea…​ and if you refuse to do so, please uninstall Dummy from your system and do not use this service anymore.</p> </blockquote> </div> <p>While the intention behind this change was commendable, the change was not. This is a sure sign the license cannot be trusted. If it changes today, why cannot it change tomorrow, for other reasons? I’d advise everybody in this situation not to do that.</p> <div> <table> <tbody><tr> <td> <i title="Important"></i> </td> <td> The license change was rollbacked as it was considered at least partially unlawful. </td> </tr> </tbody></table> </div> </div> </div> <div> <h2 id="conclusion">Conclusion</h2> <div> <p>In this post, we described the origin of Open Source Software. We looked at the semantics of the expression "Open Source", and described the difference with <abbr title="Free Open Source Software">FOSS</abbr>. Then, we wrote about the Open Source Initiative, the characteristics it applies to define Open Source, and some licenses that fit this definition. We proceeded to list some ways on how to monetize FOSS. Finally, we described the problematic behavior of some Cloud providers, and how changing the license is a way to avoid it. Other reasons for license changes might break the contrast of trust between a software vendor and its users.</p> </div> </div>    </div> </section>   </article> </div> </div></div>]]>
            </description>
            <link>https://blog.frankel.ch/on-opensource-licenses-changes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822732</guid>
            <pubDate>Mon, 13 Jul 2020 16:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weird Wide Webring]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822684">thread link</a>) | @lowmemcpu
<br/>
July 13, 2020 | https://weirdwidewebring.net/join.html | <a href="https://web.archive.org/web/*/https://weirdwidewebring.net/join.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>If you wish the web were simpler, more fun, and all around more weird, this might be for you. Head over to <a href="https://github.com/jackmcdade/weird-wide-webring">github</a> for instructions on how to submit your site.</p>
        <p>← Go back to the <a href="https://weirdwidewebring.net/">sites</a>.</p>
    </div></div>]]>
            </description>
            <link>https://weirdwidewebring.net/join.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822684</guid>
            <pubDate>Mon, 13 Jul 2020 16:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loading environment variables from a secrets manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23822681">thread link</a>) | @makethetick
<br/>
July 13, 2020 | https://www.viadog.com/replacing-environment-variables-aws-secrets | <a href="https://web.archive.org/web/*/https://www.viadog.com/replacing-environment-variables-aws-secrets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p><em>Although this solves our use case of developing with Amplify, loading your environment variables from a secret store is a great way to conveniently manage all your environments from one place.</em></p><p>When working with NodeJS applications, using <code>.env</code> is the go-to method for storing environment variables however it starts to fall down with <a href="https://aws.amazon.com/amplify/" target="_blank" rel="noreferrer">Amplify</a> when you have multiple lambda functions that all need a common environment, and even more so if you want to quickly switch between Amplify backend environments.</p><p>Storing your environment variables within <a href="https://aws.amazon.com/secrets-manager/" target="_blank" rel="noreferrer">AWS Secrets Manager</a> is a great way to setup your backend environments once and not have to worry about it again, it also gives the added bonus of not having your secrets easily readable within the AWS Lambda console.</p><h2 id="setting-up-your-environments">Setting up your environments</h2><p>Let’s get started by first creating a JSON file containing the required environment variables. You can create as many environments as you like, we recommend using one environment per developer with the addition of staging and production.</p><p>Alternatively, you could create an environment per feature branch but this didn’t work for us. See more about <a href="https://docs.amplify.aws/cli/teams/overview" target="_blank" rel="noreferrer">teams environments</a>. Note, this can also be done through the AWS console.</p><p>Create the file <code>[ENVIRONMENT].json</code>.</p><div><pre><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"API_ID"</span><span>:</span><span> </span><span>"123"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>"API_KEY"</span><span>:</span><span> </span><span>"ABC"</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>"ENDPOINT_URL"</span><span>:</span><span> </span><span>"https://example.com/endpoint"</span><span></span></p><p><span>5</span><span></span><span>}</span></p></pre></div><p>Then push the variables to AWS Secrets Manager.</p><div><pre><p><span>1</span><span>aws secretsmanager create-secret --name </span><span>[</span><span>PROJECT</span><span>]</span><span>/amplify-dev/</span><span>[</span><span>ENVIRONMENT</span><span>]</span><span> --secret-string file://</span><span>[</span><span>ENVIRONMENT</span><span>]</span><span>.json --profile </span><span>[</span><span>PROFILE</span><span>]</span></p></pre></div><p>We like to use a naming convention to cover:</p><ul><li>Project name.</li><li>Development or production (this makes it easier for setting IAM permisions).</li><li>Environment name.</li></ul><p>Which ends up like this: <code>[PROJECT]/amplify-[STAGE]/[ENVIRONMENT]</code>.</p><p>We might end up with the following secret names:</p><ul><li>project-name/amplify-dev/dev1</li><li>project-name/amplify-dev/dev2</li><li>project-name/amplify-prod/prod</li></ul><p>The environment names above need to exactly match your Amplify environments, these can be added with the following.</p><div><pre><p><span>1</span><span>amplify </span><span>env</span><span> </span><span>add</span><span> </span><span>[</span><span>ENVIRONMENT</span><span>]</span><span></span></p><p><span>2</span><span>amplify push</span></p></pre></div><h2 id="accessing-aws-secrets-from-nodejs">Accessing AWS Secrets from NodeJS</h2><p>We now need to create a helper file which will be used by each of our Lambda functions. By default Lambda will give us the region (<code>process.env.REGION</code>) and Amplify environment name (<code>process.env.ENV</code>). <a href="https://gist.github.com/deanbarrow/c8df24e822fbaca5dd4c86c4205d5831" target="_blank" rel="noreferrer">View as a Gist</a>.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>AWS</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'aws-sdk'</span><span>)</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> </span><span>getSecretValue</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> region </span><span>=</span><span> process</span><span>.</span><span>env</span><span>.</span><span>REGION</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> env </span><span>=</span><span> process</span><span>.</span><span>env</span><span>.</span><span>ENV</span><span> </span><span>||</span><span> </span><span>'dev'</span><span></span></p><p><span>6</span><span>  </span><span>const</span><span> secretPath </span><span>=</span><span> env </span><span>===</span><span> </span><span>'prod'</span><span> </span><span>?</span><span> </span><span>'prod'</span><span> </span><span>:</span><span> </span><span>'dev'</span><span></span></p><p><span>7</span><span>  </span><span>const</span><span> secretName </span><span>=</span><span> </span><span>`[PROJECT]/amplify-</span><span>${</span><span>secretPath</span><span>}</span><span>/</span><span>${</span><span>env</span><span>}</span><span>`</span><span></span></p><p><span>8</span><span></span></p><p><span>9</span><span>  </span><span>var</span><span> client </span><span>=</span><span> </span><span>new</span><span> </span><span>AWS</span><span>.</span><span>SecretsManager</span><span>(</span><span>{</span><span> region </span><span>}</span><span>)</span><span></span></p><p><span>10</span><span></span></p><p><span>11</span><span>  </span><span>return</span><span> </span><span>new</span><span> </span><span>Promise</span><span>(</span><span>(</span><span>resolve</span><span>,</span><span> reject</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>12</span><span>    client</span><span>.</span><span>getSecretValue</span><span>(</span><span>{</span><span> </span><span>SecretId</span><span>:</span><span> secretName </span><span>}</span><span>,</span><span> </span><span>function</span><span>(</span><span>err</span><span>,</span><span> data</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>if</span><span> </span><span>(</span><span>err</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>        </span><span>reject</span><span>(</span><span>err</span><span>)</span><span></span></p><p><span>15</span><span>      </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>16</span><span>        </span><span>let</span><span> secret</span></p><p><span>17</span><span>        </span><span>if</span><span> </span><span>(</span><span>'SecretString'</span><span> </span><span>in</span><span> data</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>18</span><span>          secret </span><span>=</span><span> data</span><span>.</span><span>SecretString</span><span></span></p><p><span>19</span><span>        </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>20</span><span>          </span><span>let</span><span> buff </span><span>=</span><span> </span><span>new</span><span> </span><span>Buffer</span><span>(</span><span>data</span><span>.</span><span>SecretBinary</span><span>,</span><span> </span><span>'base64'</span><span>)</span><span></span></p><p><span>21</span><span>          secret </span><span>=</span><span> buff</span><span>.</span><span>toString</span><span>(</span><span>'ascii'</span><span>)</span><span></span></p><p><span>22</span><span>        </span><span>}</span><span></span></p><p><span>23</span><span>        </span><span>resolve</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>secret</span><span>)</span><span>)</span><span></span></p><p><span>24</span><span>      </span><span>}</span><span></span></p><p><span>25</span><span>    </span><span>}</span><span>)</span><span></span></p><p><span>26</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>27</span><span></span><span>}</span><span></span></p><p><span>28</span><span></span></p><p><span>29</span><span></span><span>const</span><span> </span><span>setSecretEnvs</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>30</span><span>  </span><span>const</span><span> secrets </span><span>=</span><span> </span><span>await</span><span> </span><span>getSecretValue</span><span>(</span><span>)</span><span></span></p><p><span>31</span><span>  </span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>secrets</span><span>)</span><span>.</span><span>forEach</span><span>(</span><span>function</span><span>(</span><span>key</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>32</span><span>    process</span><span>.</span><span>env</span><span>[</span><span>key</span><span>]</span><span> </span><span>=</span><span> secrets</span><span>[</span><span>key</span><span>]</span><span></span></p><p><span>33</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>34</span><span>  </span><span>return</span><span> secrets</span></p><p><span>35</span><span></span><span>}</span><span></span></p><p><span>36</span><span></span></p><p><span>37</span><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>38</span><span>  setSecretEnvs</span></p><p><span>39</span><span></span><span>}</span></p></pre></div><p>This function will do the following:</p><ol><li>Automatically generate the secrets name based on the project and environment information.</li><li>Get the secret from the same backend region as the Amplify environment.</li><li>Inject each key value pair into <code>process.env</code>.</li></ol><p>The next step is to call this code everytime your application starts. Keep in mind that this will cost $0.05/10,000 calls, if this starts to get expensive or if it adds too much latency you can always introduce Redis.</p><p>In your main function, call <code>setSecretEnvs</code> as early as you can.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>{</span><span> setSecretEnvs </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'path/to/secrets/helper'</span><span>)</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>setSecretEnvs</span><span>(</span><span>)</span><span></span></p><p><span>4</span><span>  </span><span>.</span><span>then</span><span>(</span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span>    </span><span></span></p><p><span>7</span><span>    </span><span></span></p><p><span>8</span><span></span></p><p><span>9</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>10</span><span>  </span><span>.</span><span>catch</span><span>(</span><span>(</span><span>err</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>11</span><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'Error getting secrets'</span><span>,</span><span> err</span><span>)</span><span></span></p><p><span>12</span><span>    process</span><span>.</span><span>exit</span><span>(</span><span>)</span><span></span></p><p><span>13</span><span>  </span><span>}</span><span>)</span><span></span></p><p><span>14</span><span></span></p><p><span>15</span><span></span><span></span></p><p><span>16</span><span></span></p><p><span>17</span><span></span><span>try</span><span>{</span><span></span></p><p><span>18</span><span>  </span><span>await</span><span> </span><span>setSecretEnvs</span><span>(</span><span>)</span><span></span></p><p><span>19</span><span></span></p><p><span>20</span><span>  </span><span></span></p><p><span>21</span><span>  </span><span></span></p><p><span>22</span><span></span></p><p><span>23</span><span></span><span>}</span><span>catch</span><span>(</span><span>err</span><span>)</span><span>{</span><span></span></p><p><span>24</span><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'Error getting secrets'</span><span>,</span><span> err</span><span>)</span><span></span></p><p><span>25</span><span>  process</span><span>.</span><span>exit</span><span>(</span><span>)</span><span></span></p><p><span>26</span><span></span><span>}</span></p></pre></div><p>You will now find that <code>process.env</code> contains all the variables from the JSON file you imported earier.</p><p>If you want to switch to a new local Amplify environment, all you need to do is run the following and the correct secrets store will be used automatically.</p><div><pre><p><span>1</span><span>amplify </span><span>env</span><span> checkout </span><span>[</span><span>ENVIRONMENT</span><span>]</span></p></pre></div><p>This worked for us to solve the problem of managing environment variables across multiple functions/developers in a set and forget fashion, it also helped to centralise and secure the variable values as an added bonus which is actually very convenient.</p><h2 id="alternative-secret-managers">Alternative secret managers</h2><p>If you’re not using AWS, it wouldn’t be difficult to adapt the above code to work with other providers.</p><ul><li><a href="https://cloud.google.com/secret-manager" target="_blank" rel="noreferrer">Google Secret Manager</a></li><li><a href="https://azure.microsoft.com/en-us/services/key-vault/" target="_blank" rel="noreferrer">Azure Key Vault</a></li><li><a href="https://docs.docker.com/engine/swarm/secrets/" target="_blank" rel="noreferrer">Docker Secrets</a></li></ul></div></article></div>]]>
            </description>
            <link>https://www.viadog.com/replacing-environment-variables-aws-secrets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822681</guid>
            <pubDate>Mon, 13 Jul 2020 16:37:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cambridge History of China]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23822660">thread link</a>) | @jeffreyrogers
<br/>
July 13, 2020 | https://rhinopoetry.org/reviews/the-cambridge-history-of-china-vol-2-the-six-dynasties-220589-edited-by-lbert-e-dienkeith-n-knapp-reviewed-by-anthony-madrid | <a href="https://web.archive.org/web/*/https://rhinopoetry.org/reviews/the-cambridge-history-of-china-vol-2-the-six-dynasties-220589-edited-by-lbert-e-dienkeith-n-knapp-reviewed-by-anthony-madrid">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-af16ad1ab5a569388183"><p><strong><em>The Cambridge History of China, Vol. 2: The Six Dynasties, 220–589</em></strong><br>Edited. by Albert E. Dien and Keith N Knapp<br>Cambridge University Press, 2019. 897 pages.<br>Reviewed by Anthony Madrid</p></div><div data-block-type="2" id="block-e5f3520b58c042c10f76"><div><p>How to even begin to explain. The book under review is the next-to-last “brick” of a monumental project:&nbsp;<em>The Cambridge History of China</em>. As always happens in enterprises that take thirty or forty years to complete, the volumes were published out of sequence. The book pictured above is Volume Two (2019). Volume (e.g.)&nbsp;<em>Seven</em>&nbsp;was published in 1988. It’s like that. There are fifteen “volumes” (seventeen separate books) in the series.</p><p>As of this writing, you&nbsp;<em>still</em>&nbsp;can’t purchase the entire set. Volume Four remains missing. But even if Volume Four came out tomorrow, no one, not even Bill Gates and Donald Trump put together, could afford it. Their checks would bounce. And suppose they broke into a research library and&nbsp;<em>stole</em>&nbsp;a set? OK, their brains would explode. They’d be dead. Or anyway Gates’s brain would explode; I don’t know what would happen to Trump. I’m saying every volume is between $150 and $350, and each one contains enough information to keep a team of million-IQ weirdos busy for a decade.</p><p>I shouldn’t speak about the other volumes, actually. I’ve never had one in my hands. I know, from other books, they’re considered standard reference works. One is always being directed to them. And there must be at least a few people out there who have the Tang volume or maybe the Han one. It’s all about what period you’re psycho for! Me, I like Six Dynasties poetry a lot, so you may imagine my feelings when I discovered that one of the two volumes in the History that was still missing was the one that would tell me ’bout the politics, language, religion, technology, etc of my pet period.</p><p>No more. This thing has 900 pages; 105 of that is bibliography. It uses the pinyin transliteration system and not the Wade-Giles (first CHC volume to do this), and it begins with an up-to-the-minute survey of how research on the period has been going, for, oh, the last fifty or sixty years. The book is&nbsp;<em>sexy</em>.</p><p>The level of awareness of every single thing published (in a half dozen languages) on the subject of China between the fall of the Han Dynasty and the advent of the Sui–Tang is off the scale. Just the twenty-four pages of the Introduction could send somebody on a hundred happy errands. Right out of the gate, I learned a lot about 20th-century Chinese historians; I had never heard of any of these cats. The Cambridge people basically give you a field guide.&nbsp;</p><p>Also, one finds out about exciting archaeological discoveries of the last twenty-five years—about which I, anyway, knew nothing. For example, apparently in 2009 Cao Cao’s tomb was discovered in Anyang. (I don’t even know what to compare that to. It’s like Biblical scholars finding the gravesite of Moses. ’Cept it’s&nbsp;<em>better</em>&nbsp;than that, ’cuz if they found Moses it would just be bones; whereas, Cao Cao’s tomb was more like Tutankhamun’s.)</p><p>Another thing. One can finally sharpen up all those vague ideas one’s picked up over the years about the period. For example: you know Buddhism and Daoism went from being piddly little trickles to universal practices, studied everywhere, during the Six Dynasties. You’ve always wondered how exactly that went down. This book will straighten out your shit. And it’s just how you like it: essentials, bold strokes. Also, one knows these centuries are called “The Period of Disunity” for a reason; one knows the non-Han tribes or armies or whatever they are—are important. Wanna get all that straight, once and for all? This book is 4 U.</p><p>I mean let’s be honest. During Covid, almost the only thing that literary people are&nbsp;<em>doing</em>&nbsp;is shopping online. Anything that unfolds a vista of new buying opportunities is most welcome. So reference works like this are good. You check the footnotes constantly to see if there’s anything down there you need to order.&nbsp;<em>Family Instructions for the Yen Clan</em>—you’ve been wondering if you actually need to&nbsp;<em>buy</em>&nbsp;that. Well, guess what, you do! Or you can get excerpts from it in Swartz’s&nbsp;<em>Early Medieval China: A Sourcebook</em>&nbsp; (Columbia 2014). See, I didn’t know that&nbsp;<em>Sourcebook</em>&nbsp;existed, until I saw the CHC footnote. Hello, <a href="http://www.bookfinder.com/">www.bookfinder.com</a>! Hello&nbsp; once again,&nbsp;<em>Midtown Scholar</em>&nbsp;in Pennsylvania! Hello, more and more treasures!</p></div></div><div data-block-type="2" id="block-58ed2c38fb345ec844ca"><p>ANTHONY MADRID lives in Victoria, Texas. His poems have appeared in Best American Poetry 2013, Boston Review, Fence, Harvard Review, Lana Turner, LIT, and Poetry. His second book is called TRY NEVER (Canarium Books, 2017).&nbsp;</p></div></div>]]>
            </description>
            <link>https://rhinopoetry.org/reviews/the-cambridge-history-of-china-vol-2-the-six-dynasties-220589-edited-by-lbert-e-dienkeith-n-knapp-reviewed-by-anthony-madrid</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822660</guid>
            <pubDate>Mon, 13 Jul 2020 16:36:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personalization Can Become Your Customer Engagement Engine]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822658">thread link</a>) | @josias
<br/>
July 13, 2020 | https://pirsonal.com/2020/07/08/customer-engagement-engine/ | <a href="https://web.archive.org/web/*/https://pirsonal.com/2020/07/08/customer-engagement-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage"><p>Every organization needs a customer engagement engine. Why? Easier than you thought. Without customers, your organization dies. Customers need to be constantly engaged with your brand. Are your product a good fit for your customers? What about your team and culture? One more question… Are you talking to your customers’ hearts?</p><p>Customer-centric organizations constantly connect with their customers. To their values. If you want happy customers, this is the way to go. if you want customers to buy more, there is no better way long-term. If you want your customers to bring referrals, customer engagement is the key.</p><p>A customer engagement engine gives your company constant customer feedback. It’s a source of knowledge that helps you improve your offering. A great customer engagement strategy helps you refine your business model. Customer engagement keeps at the top of your market a few meters away from your competition.</p><p><img src="https://pirsonal.com/wp-content/uploads/customer-engagement.jpg" alt="Customer Engagement To Drive Loyal Clients" width="700" height="480" srcset="https://pirsonal.com/wp-content/uploads/customer-engagement.jpg 700w, https://pirsonal.com/wp-content/uploads/customer-engagement-768x526.jpg 768w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://pirsonal.com/wp-content/uploads/customer-engagement.jpg 700w, https://pirsonal.com/wp-content/uploads/customer-engagement-768x526.jpg 768w" data-src="https://pirsonal.com/wp-content/uploads/customer-engagement.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Exhaustive knowledge of your customers is really helpful here. This starts with a mindset. A mindset that is based on proactive knowledge of your customers. This proactive knowledge of your customers naturally leads you to personalization. Personalization shows you the right path for marketing messages that are aligned with each customer.</p><p>No matter the angle, personalization is one of the most profitable tools for your business. Especially in times of crisis. In this article, you will learn how personalization is a key part of a customer engagement strategy. And, most importantly, how to get started.</p><p>If you already have a customer engagement strategy structure in place, a financial crisis won’t be as hard on you. If you are just starting, you have bigger challenges ahead. You can still make it. What happens if you do nothing? Prepare to close the doors of your business in the short or mid-term. 12-24 months. Even less. It seems like a long time, but time flies.</p><h2><span id="What%E2%80%99s_An_Engine_And_How_It_Affects_Your_Customer_Engagement_Strategy"></span>What’s An Engine And How It Affects Your Customer Engagement Strategy<span></span></h2><p>You need to learn from your customers. Each one of them needs you to have a personal approach to what matters to them. Personalization is not a nice-to-have anymore. It becomes a must-have for every wise organization. Growth is then in the little details. The little details are in what you know about your customers. On how you use this information to be relevant to their needs. To resonate with what matters to them, individually.</p><p>To be honest, it’s even simpler. If you don’t know your customers, you can not serve them as they deserve or at least as they want.</p><p>Let me stop for a moment to talk about engines.</p><p>I’m far from being an engineer but at least I love technology. Here is what Wikipedia says about<a href="https://en.wikipedia.org/wiki/Engine"> what an engine is</a>:</p><blockquote><p>An engine or motor is a machine designed to convert one form of energy into mechanical energy.</p></blockquote><p><img src="https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1.jpg" alt="Segmentation and personalization" width="700" height="480" srcset="https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1.jpg 700w, https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1-768x526.jpg 768w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1.jpg 700w, https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1-768x526.jpg 768w" data-src="https://pirsonal.com/wp-content/uploads/segmentation-and-personalization-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>Engines are at the core of all the things that surround you. Engines are the heart of your car. Even of your bike. Not to mention your computer or your marketing automation software. In one or another way, engines are vital for everything we do.</p><p>Here is another definition I like. This time for “<a href="https://en.wikipedia.org/wiki/Mechanical_energy">mechanical energy</a>“:</p><blockquote><p>In&nbsp;<a title="Outline of physical science" href="https://en.wikipedia.org/wiki/Outline_of_physical_science">physical sciences</a>,&nbsp;<b>mechanical energy</b>&nbsp;is the sum of&nbsp;<a title="Potential energy" href="https://en.wikipedia.org/wiki/Potential_energy">potential energy</a>&nbsp;and&nbsp;<a title="Kinetic energy" href="https://en.wikipedia.org/wiki/Kinetic_energy">kinetic energy</a>. It is the macroscopic&nbsp;<a title="Energy" href="https://en.wikipedia.org/wiki/Energy">energy</a>&nbsp;associated with a system. The principle of conservation of mechanical energy states that if an isolated system is subject only to&nbsp;<a title="Conservative force" href="https://en.wikipedia.org/wiki/Conservative_force">conservative forces</a>, then the mechanical energy is constant. If an object moves in the opposite direction of a conservative net force, the potential energy will increase; and if the&nbsp;<a title="Speed" href="https://en.wikipedia.org/wiki/Speed">speed</a>&nbsp;(not the&nbsp;<a title="Velocity" href="https://en.wikipedia.org/wiki/Velocity">velocity</a>) of the object changes, the kinetic energy of the object also changes.</p></blockquote><p>Ok. Maybe that one was too much for most of us.</p><p>The thing is that engines are crucial. Engines make things happen. Engines are all about movement. About power. Engines multiply your efforts. When talking about customer engagement, engines will keep your business up and running. Even when some customers need to run away because there is no way they can pay for your service anymore.</p><p>Let me ask you something…</p><h2><span id="Understand_What%E2%80%99s_The_Engine_Of_Your_Organization"></span>Understand What’s The Engine Of Your Organization<span></span></h2><p>What’s the engine of your organization? I’m not talking about your vision or mission statement. I’m not talking about your team and the values behind them. All that is certainly important. You miss it there, the sooner the later your business dies as well.</p><p>No matter what you sell. If your customers are not connected to your organization, you are in trouble. At the end of the day, we all have options. We buy from people. You buy from the guy that was just amazing at customer support. Even if it’s not always the same person. You buy from the local coffee shop that knows what you want the moment you get there.</p><p>Define the different engines your organization has. This will help you know where you should invest your time and resources. I’m not only talking about a budget. I mainly talk about your brain. Your thoughts. Your ideas. And yes, also your money.</p><p>If your customers are not an intrinsic part of your organization’s engine, something is wrong.</p><p>How can you emulate that personal touch through your digital channels? This is one of the reasons why people love video. Especially videos that keep it personal. Because these videos are from a human to another human. Obviously, there are times when this is not possible. Times where emails will work just fine. There are times where you’ll use SMS. WhatsApp messages are also becoming more popular.</p><p>No matter the communication channel you use to communicate with customers. It needs to be a channel that is aligned with your engine. In the same way, your message needs to be aligned with your customers. If you have a personalization mindset, this becomes easier.</p><h3><span id="Examples_Of_Customer_Engagement_Strategies"></span>Examples Of Customer Engagement Strategies<span></span></h3><p>Customer engagement starts way before a customer becomes a customer.</p><p>Let me give you a simple example.</p><p>Want more? Ok. Let me give you two examples of companies with a customer engagement strategy that I know that works.</p><h4><span id="Recording_Videos_For_Leads_and_Customers"></span>Recording Videos For Leads and Customers<span></span></h4><p>I use personalized videos to engage with some leads after we’ve had a call. There are different types of personalized videos:</p><ul><li>Videos that are recorded one by one</li><li>Videos that you can create automatically from a CSV, CRM, or marketing automation tool.</li></ul><p>Pirsonal creates this second type of <a href="https://pirsonal.com/individualized-videos/">personalized videos automatically</a>.</p><p><a href="https://pirsonal.com/">Pirsonal</a> is a remote-first company. People buy from people. They want to see a face, hear a voice, and feel that I understand their goals and concerns. I do my best so that this happens and video helps me explain things a bit better. So I record a video for these leads.</p><p>At Pirsonal we also have a free 1:1 onboarding service. We treat our leads as if they were customers. As a result, we learn a ton from them, which helps us improve our offering. It also helps us to serve them better. Since the experience was great as leads, they are confident to work with us.</p><p>A couple of months ago, one of my colleagues interviewed some of the leads and customers that were in touch with me. I’m the CEO at Pirsonal. I work in product development. Since this is my company and I’m a marketer, I also do sales. Because of this, I try to talk to as many people as I can. This way, I learn more about product, marketing, and sales. This helps us to improve our offering.</p><p>What he found was positively shocking.<img src="https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal.jpg" alt="Customer Engagement Example by Pirsonal" width="700" height="372" srcset="https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal.jpg 700w, https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal-300x159.jpg 300w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal.jpg 700w, https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal-300x159.jpg 300w" data-src="https://pirsonal.com/wp-content/uploads/customer-engagement-example-pirsonal.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>In the interviews, he learned that the reason why these leads and customers love Pirsonal. It was because of this personal approach. It happens that our customers are customers that like a personal approach. This personal approach is part of our engine at Pirsonal.</p><p>There are times when recording video by video it’s not practical at all. That’s when you can use a <a href="https://pirsonal.com/">personalized video marketing software</a> like Pirsonal. It helps you to interact with hundreds or thousands of individuals. No matter the tool you use. The point is, make sure to understand what your customer engagement engine is. You will help your customers succeed.</p><p>As brands, we also love serving people we know. It just makes it easier. Let’s face it. Sometimes this or that customer it’s not the easiest person to deal with. There are times when that account just drives you nuts. There are times when this other account is not even managed by the same person you initially engaged with. But guess what? You still think about that person and want to make it work to honor that other person.</p><p>Earlier I mentioned that with Pirsonal you can create personalized videos. You can easily create them using a CSV, CRM or any marketing tool. I recorded this video to show you how to this with a CSV:</p><p><iframe title="Creating Personalized Videos From A CSV With Campaign By Pirsonal" width="1140" height="641" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-src="https://www.youtube.com/embed/d3QR5JHUcRw?feature=oembed" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p><h4><span id="Using_Personalized_Videos_For_A_Customercentric_Strategy_In_The_Travel_Industry"></span>Using Personalized Videos For A Customer-centric Strategy In The Travel Industry<span></span></h4><p>Here is the second example of a customer engagement strategy that works.</p><div class="page" title="Page 1"><div><div><div><p><a href="http://flightcentre.co.za/">Flight Centre</a> <a href="https://pirsonal.com/2018/08/17/use-personalized-video-marketing-to-improve-your-sales/">accelerates its sales process by using personalized video marketing</a> powered by Pirsonal. This happens when leads request a quote. The brand automatically creates a personalized video, personalized landing page, and custom in- video call-to-action. All this multimedia content is personalized using the information provided by the lead. They use data such as name, the reason to travel, or destination. This makes these personalized videos and emails totally relevant to each individual.</p><p><iframe title="Personalized Video Example for a Travel Agency" width="1140" height="641" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-src="https://www.youtube.com/embed/fDAfTryXEpc?feature=oembed" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p><p>When they do this, Flight Centre increases lead engagement. This lead engagement moves these leads to buy more and faster. Every personalized video is instantly sent by email. This increases customer engagement and builds stronger relationships. At the same time, this translates into higher levels of loyalty and into more revenue.</p><p>Why do I like this strategy? It’s aligned with the personal touch of the company. This happens through all communication channels. It is part of their value proposition. Check the image below to see their value proposition.</p><p><img src="https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency.png" alt="Customer Engagement - Online Travel Agency" width="1088" height="388" srcset="https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency.png 1088w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-300x107.png 300w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-1024x365.png 1024w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-768x274.png 768w" sizes="(max-width: 1088px) 100vw, 1088px" data-srcset="https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency.png 1088w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-300x107.png 300w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-1024x365.png 1024w, https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency-768x274.png 768w" data-src="https://pirsonal.com/wp-content/uploads/customer-engagement-online-travel-agency.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div></div></div></div><p>Seems obvious? Make sure that your customers are at the core of your customer engagement engine.</p><h2><span id="Why_Customer_Engagement_Needs_To_Be_The_Engine_Of_Your_Organization"></span>Why Customer Engagement Needs To Be The Engine Of Your Organization<span></span></h2><h3><span id="Customer_Engagement_Creates_A_Healthy_Working_Place"></span>Customer Engagement Creates A Healthy Working Place<span></span></h3><p>See? …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pirsonal.com/2020/07/08/customer-engagement-engine/">https://pirsonal.com/2020/07/08/customer-engagement-engine/</a></em></p>]]>
            </description>
            <link>https://pirsonal.com/2020/07/08/customer-engagement-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822658</guid>
            <pubDate>Mon, 13 Jul 2020 16:36:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Default Sorting in Your Eloquent Models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822570">thread link</a>) | @stehenjude
<br/>
July 13, 2020 | http://stephenjude.me/articles/getting-started-with-default-sorting-in-your-eloquent-models | <a href="https://web.archive.org/web/*/http://stephenjude.me/articles/getting-started-with-default-sorting-in-your-eloquent-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div v-pre="">
    <p><a href="https://github.com/stephenjude/default-model-sorting" target="_blank">Default Model Sorting </a>package is a mini Laravel package I published recently. By default, Laravel Eloquent models return queries that are ordered by the <code>id</code> column of the model table. </p><p>With this package, you can set default order by in your Eloquent model so you don't have to call the orderBy Eloquent builder.</p><pre spellcheck="false"><span>&lt;?php</span>

Article::orderBy(<span>'title'</span>, <span>'asc'</span>)-&gt;get(); 


Art﻿icle::all(); 

</pre><h2>Installation</h2><p>First you have to install this package via composer.</p><pre spellcheck="false">composer <span>require</span> stephenjude/<span>default</span>-model-sorting
</pre><h2>Usage</h2><p><span>Using the&nbsp;</span><code>DefaultOrderBy</code><span>&nbsp;trait of this package, you can set the default column you want to sort by.</span></p><p><span>For example, if you want to set the default order column for </span><code>Article</code><span> model (assuming you are building a blog).  You will use the </span><code>DefaultOrderBy</code><span> trait and set the </span><code>$orderByColumn</code><span> property inside your </span><code>Article</code><span> model.</span></p><pre spellcheck="false"><span>use</span> <span>Stephenjude</span>/<span>DefaultModelSorting</span>/<span>Traits</span>/<span>DefaultOrderBy</span>;

<span><span>class</span> <span>Article</span> <span>extends</span> <span>Model</span>
</span>{
    <span>use</span> <span>DefaultOrderBy</span>;

    <span>protected</span> <span>static</span> $orderByColumn = <span>'title'</span>;
}
</pre><p>Now your <code>Article</code> model queries will be ordered by title column in ascending order.</p><p>You can also set the <code>$orderByColumnDirection</code> property. This property is set to <code>asc</code> as the default value.</p><pre spellcheck="false"><span>protected</span> <span>static</span> $orderByColumnDirection = <span>'asc'</span>;
</pre><p>To set the global default <code>$orderByColumnDirection</code> property, publish the package configuration file.</p><pre spellcheck="false"><span>php</span> artisan vendor:publish --provider=<span>"Stephenjude\DefaultModelSorting\DefaultModelSortingServiceProvider"</span> --tag=<span>"config"</span>
</pre><p>Now you can update the configuration file as you desire.</p><pre spellcheck="false">
﻿<span>return</span> [    
    
    <span>'order_by'</span> =&gt; <span>'asc'</span>,
];
</pre><h2>Under The Hood</h2><p>This package is has a trait <code>DefaultOrderBy</code> that adds a <code>default_order_by</code> global scope  to the <code>boot()</code> method of your Eloquent model.</p><pre spellcheck="false"> <span>&lt;?php</span>
﻿ ...
 <span>protected</span> <span>static</span> <span><span>function</span> <span>boot</span><span>()</span>
 </span>{
     <span>parent</span>::boot();

     
     $column = <span>Self</span>::$orderByColumn;

     
     $direction = <span>isset</span>(<span>Self</span>::$orderByColumnDirection)
            ? <span>Self</span>::$orderByColumnDirection
            : config(<span>'default-model-sorting.order_by'</span>);
     
     
     <span>static</span>::addGlobalScope(<span>'default_order_by'</span>, <span><span>function</span> <span>(Builder $builder)</span> <span>use</span> <span>($column, $direction)</span> </span>{
            $builder-&gt;orderBy($column, $direction);
        });
} 
</pre><p>If you don't want to use the package, you can add this code to your Eloquent model.</p><p>If you find this package helpful please give it a start on <a href="https://github.com/stephenjude/default-model-sorting" target="_blank">Github</a>. </p>
</div></div>]]>
            </description>
            <link>http://stephenjude.me/articles/getting-started-with-default-sorting-in-your-eloquent-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822570</guid>
            <pubDate>Mon, 13 Jul 2020 16:28:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas Are Worthless]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822473">thread link</a>) | @graiz
<br/>
July 13, 2020 | https://gregraiz.com/ideas-are-worthless/ | <a href="https://web.archive.org/web/*/https://gregraiz.com/ideas-are-worthless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main"><article id="post-620"><div><div><p>You may thinkyou have the best, most amazing idea but I’m sorry to tell you that your idea is worthless…. But it’s Ok, most ideas are worthless.</p><p>Now before I get too deep, I’ve seen hundreds of pitches with a wide range of ideas and I’ve signed stacks and stacks of NDA’s to keep someone’s ideas secrets. Want to know the best secret idea I’ve ever heard?</p><p>There are none. We’re you listening at the beginning? Ideas are worthless and I’ve never been blown away by an amazing idea. Never! I’ve heard interesting ideas and clever ideas but most of the time amazing ideas are not the exciting part.</p><p>If you just think about the ideas behind the world’s most successful companies, the ideas aren’t that exciting.</p><ul><li>A phone that doesn’t have any buttons</li><li>A car that uses electricity instead of a motor</li><li>A new search engine</li></ul><p>These ideas by themselves have no value and even if you were able to rewind the clock 20 years, the ideas themselves weren’t worth anything without the entrepenours to drive them.</p><p>Nokia had phones without buttons before Apple. There were plenty of electric golf-carts before Tesla, and Google was late to the game as far as search engines go.</p><p>It’s the execution that creates value and these companies executed exceptionaly well.</p><p>While ideas are worthless, working on your idea is the thing that starts to create value. Some examples of value creation:</p><ul><li>A list of potential customers willing to try or buy a finished product</li><li>Sales or purchase orders for a product or service</li><li>A prototype of the future product</li><li>Testimonials from people who have tried the prototype/product</li><li>Partners willing to stock or sell the product/service</li><li>Patents on the product/technology. (<a href="https://www.youtube.com/watch?v=Jmvle3M1_4g">more on patents here</a>)</li></ul><p>You don’t have to be an engineer or designer to make progress on an idea, but you need to take action.</p><p>The other reason that ideas are worthless is that the idea instantly changes as soon as you start working on it. Once you put a pencil to paper your idea starts to spawn new ideas. Once you have a customer using the product you start to get feedback on the idea and what needs to change about it. Once you try to sell a product you learn all the reasons people don’t want it. It’s this learning/feedback cycle that creates real value because it’s based on real applications, not just theoretical ones.</p><p>The execution of the idea is the essence of the idea. Want to make something amazing, take action to make it real.</p><figure><p> <iframe title="Ideas are WORTHLESS!" width="580" height="326" data-src="https://www.youtube.com/embed/m4gMd7Rw1ps?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><figcaption>Why are ideas worthless</figcaption></figure></div></div></article></div></div>]]>
            </description>
            <link>https://gregraiz.com/ideas-are-worthless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822473</guid>
            <pubDate>Mon, 13 Jul 2020 16:20:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Gordian knot of identity and achievement]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822339">thread link</a>) | @khehy
<br/>
July 13, 2020 | https://radreads.co/identity-achievement/ | <a href="https://web.archive.org/web/*/https://radreads.co/identity-achievement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 itemprop="name"><span itemprop="dateCreated">11 Jul<meta itemprop="interactionCount" content="UserComments: 0"></span> The Gordian knot of identity and achievement</h2><p>“Stress is a perverted relationship to time.” These words from <a href="https://onbeing.org/programs/john-odonohue-the-inner-landscape-of-beauty-aug2017/">the late Irish poet, John O’Donohue</a> are truthfully incisive.</p><p>And whether it’s using <a href="https://radreads.co/text-expander/">Text Expanders</a> or doing Tabata Burpee workouts – I’ve always been in the hot pursuit of more time.</p><p>The chase is straight forward. More free time equals <em>more time to do stuff</em>. Doing more stuff means notching <em>more income, subscribers, accolades</em>… <strong>and achievements.</strong></p><p>The result is a deep intertwining of identity and achievement. A terrifying twosome that leads to FOMO, <a href="https://radreads.co/the-paradox-of-self-employment-burnout/">burnout</a>, and anxiety.</p><p>Separating identity from achievement is an <em>involved problem:</em> <strong>untangling a Gordian Knot.</strong></p><div><figure><img src="https://embed.filekitcdn.com/e/soCyR57pgxv3XZJLXQFY1r/ciefdDdbKt6m66cgM7Z6zY/email" alt="" width="400" height="367" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div><p>Now this ain’t a knock on striving. We’ve all stared for hours at that seemingly intractable problem – then experienced the bliss of discovering the elusive solution.</p><p>Applying your skills to your craft brings a deep sense of satisfaction and fulfillment. As the poet David Whyte writes in <a href="https://amzn.to/2DxWsTa">Crossing the Unknown Sea: Work as a Pilgrimage</a>:</p><blockquote><p><em>Good work, done well, for the right reasons.</em></p></blockquote><p>But we get tripped up by “for the right reasons” when we integrate our sense of <strong>self-worth</strong> with our identity.</p><p>Like the stock market, accomplishments <strong>ebb and flow</strong>. They <strong>come and go</strong>. You may be able to control the inputs (a la <a href="https://qz.com/890093/trust-the-process-how-three-years-of-losing-on-purpose-turned-the-philadelphia-76ers-into-winners/">Trust the Process</a>); but the outputs are subject to a high degree of randomness. Pegging our identity this noisy stochastic process can heap unnecessary suffering into our lives</p><h2>Is self-love conditional?</h2><p>But there’s something even more pernicious at play. Would you ever tell your child “I’ll only love you if you get into straight As?” Would you ever tell your BFF “I’ll only be your homie if you get promoted to partner?”</p><p><strong>If that sounds silly, consider the preconditions you set for loving yourself.</strong></p><p>How do you <a href="https://radreads.co/negative-self-talk/">talk to yourself</a> when your striving falls short? Or when you botch a big presentation? In one of his most famous posts, Seth Godin rhetorically asks who is <a href="https://seths.blog/2010/12/the-worlds-worst-boss/">the world’s worst boss</a>?</p><p>His answer: <strong>It’s you.</strong> Why? Says Godin:</p><blockquote><p><em>If you had a manager that talked to you the way you talked to you, you’d quit.</em></p></blockquote><p>Untangling the Gordian Knot of identity and achievement means dropping the construct of conditional love for ourselves. In Shirzad Chamine’s wonderful book <a href="https://amzn.to/3ekmENM">Positive Intelligence</a> he writes:</p><blockquote><p><em>The most damaging lie is that we are not worthy of love or respect by just being who we are. Instead, it forces us to constantly perform; this forms the construct of “conditional love.” But conditional love is not real love.</em></p></blockquote><p>Chamine offers a nostalgic recommendation to “shift your brain” to feel empathy and caring for yourself:</p><blockquote><p><em>Visualize yourself as a child in a setting where your essence is shining through. Perhaps you are holding a puppy, building a sandcastle, chasing a bunny, or snuggling with a loved one. Put that picture on your desk or on your phone or computer so that you see it frequently. This image will be a reminder that your true essence is worthy of unconditional caring and empathy when you are feeling beaten down by yourself, others, or the troubles of life. </em></p></blockquote><div><div id="tve_tcb2_blank" data-state="2" data-form-state=""><div data-tl-type="shortcode_580"><div><div id="tve_editor"><div data-css="tve-u-05d5f19b06f29a"><p data-tag="h2"><h2 data-css="tve-u-15d5f19b06f2d4">Stop letting Monday ruin Sunday</h2></p><p data-css="tve-u-35d5f19b06f343">Join 17,115 RadReaders who kissed the&nbsp;<em>Sunday Scaries</em>&nbsp;goodbye!</p></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://radreads.co/identity-achievement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822339</guid>
            <pubDate>Mon, 13 Jul 2020 16:11:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Residential Proxies vs. Data Center Proxies in Web Scraping]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822331">thread link</a>) | @Himanshi
<br/>
July 13, 2020 | https://scrapinghub.zoom.us/webinar/register/6015946565371/WN_RRP09QSRSHSazeDgVuhTOQ | <a href="https://web.archive.org/web/*/https://scrapinghub.zoom.us/webinar/register/6015946565371/WN_RRP09QSRSHSazeDgVuhTOQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><label for="timezone">Time Zone:</label>&nbsp;&nbsp;

</p>
</div>
</div></div>]]>
            </description>
            <link>https://scrapinghub.zoom.us/webinar/register/6015946565371/WN_RRP09QSRSHSazeDgVuhTOQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822331</guid>
            <pubDate>Mon, 13 Jul 2020 16:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From scratch to the first 10 customers. How I launched my SaaS product]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23822081">thread link</a>) | @valerione
<br/>
July 13, 2020 | https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/ | <a href="https://web.archive.org/web/*/https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                <div>
                                    <div>
                                        
<p>Creating a successful software as a service (SaaS) product is the dream for many entrepreneurial-minded programmers. </p>



<p>In the process of launching my own SaaS I discovered that sharing and<br>comparing experiences with other founders is an essential part of this journey, and without this, I probably would never have created it at all. </p>



<p>In this article, I’ll share the mental and practical process that led me to create a SaaS product from scratch, and how I gained my first paying customers.</p>



<p>Whether you are thinking about creating a new product or you have already launched, this article can help you compare your own strategies and methods with the ones that worked for me, and possibly adapt them for yourself.</p>



<p>I personally dedicate up to five hours per week researching the experiences of other founders. I’m always looking for new ideas and ways to avoid mistakes, and evaluating new strategies that could help me obtain concrete results (that is, improve the product and increase customers’ happiness).</p>



<p>For this reason, I decided to work in a completely frank and transparent way and share everything about my path — including what has been working and what has not — with the aim of helping one another through direct and rational discussion.</p>



<p>The article is divided into seven chronological sections, following every phase of the work I have done:</p>



<ul><li>Detecting the problem</li><li>Quantifying the problem</li><li>Evaluating competitors and their approach to the problem</li><li>Developing the first prototype</li><li>Throwing everything away and starting again</li><li>Getting the first subscription</li><li>How to move forward</li></ul>



<p>The SaaS product I built is <a href="https://www.inspector.dev/">Inspector</a>, a real-time monitoring tool which helps software developers to avoid losing customers and money due technical problems in their applications.</p>



<h2>Detecting the problem</h2>



<p>Spending the last 10 years working with software development teams made me realize how complicated it is for developers to handle technical problems which affect applications every day.</p>



<p>Development teams have close relationships with their customers, and this is a high risk for companies which produce software, because with problems you realize how fragile this bond really is.</p>



<p>Users do not like problems! It seems obvious, but this aspect is constantly underestimated. This is an uncomfortable truth. No one likes to be in trouble, and it is instinctive to minimize the problem.</p>



<p>But by denying reality you could annoying the customer even more, to the point where they may even reconsider whether or not they “should” even pay you. </p>



<p>Customers do not spend their time reporting problems and application errors. No one cares about helping us resolve bugs. They just leave our application, and it will probably take years before we see them again.</p>



<p>Despite this, every team I have worked with used the best-known method of figuring out whether applications were working properly or not:</p>



<blockquote><p><em>“If an angry customers calls you, the software is not working.”</em></p></blockquote>







<p>It is not exactly a technological solution…</p>



<p>Maybe it seems ridiculous, but beyond the perception tycoons of technology project on our jobs, insiders know that urgency, limited budget, pressing customers, managers, forcing developers to constantly work under pressure, and adopting Band-Aid solutions (to temporarily fix a problem) as a survival strategy.</p>



<p>Working this approach for 10 years helped me realize there is clearly a problem.</p>



<h2>Quantifying the problem</h2>



<p>At the beginning of 2019 I had just finished some important projects and I was expecting to enjoy a little period of calm.</p>



<p>During the last years I have used these moments to look for business opportunities which allow me to put my technical skills to good use with the hope of finding the right conditions to launch my own business idea.</p>



<p>I knew from my experience as a developer that an easy and immediate monitoring instrument would be enough to help development teams to stay up-to-date about the performance of applications, instead of relying on customer calls to know when the software was creating problems.</p>



<p>On the other hand, I did not need a tool to monitor everything, as everything often means nothing.</p>



<p>And I didn’t want it to be complicated — I did not want to spend a month learning how it worked or need to hire expert engineers just for this job.<br>My life had to be made easier than before. It was necessary to have a ready-to-go developer tool.</p>



<p>The first step was to understand if there already were solutions trying to solve this problem, so I googled “<em>application monitoring</em>” and 941,000,000 results appeared:</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2020/07/google-results.png" alt="" srcset="https://www.inspector.dev/wp-content/uploads/2020/07/google-results.png 1011w, https://www.inspector.dev/wp-content/uploads/2020/07/google-results-300x60.png 300w, https://www.inspector.dev/wp-content/uploads/2020/07/google-results-768x154.png 768w, https://www.inspector.dev/wp-content/uploads/2020/07/google-results-980x197.png 980w" sizes="(max-width: 1011px) 100vw, 1011px"></figure>



<p>Wow. That’s a very huge amount of contents for a problem that probably is huge.<br>But how huge, exactly?</p>



<p>Software development team inefficiency is a problem I have always faced directly, but there is a big difference between estimating a job task and quantifying the economic impact of a problem. </p>



<p>It is even more difficult on a large scale. </p>



<p>This tweet captured my attention:</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2019/09/1_A_aGsKJKY5I9y5KzJOsCdg.png" alt="" srcset="https://www.inspector.dev/wp-content/uploads/2019/09/1_A_aGsKJKY5I9y5KzJOsCdg.png 635w, https://www.inspector.dev/wp-content/uploads/2019/09/1_A_aGsKJKY5I9y5KzJOsCdg-300x240.png 300w" sizes="(max-width: 635px) 100vw, 635px"></figure>



<p><strong>The 50% of developers declare to spend up to 50% of time just to constantly verify that applications are working.</strong></p>



<p>Software development is work mostly paid by the time technicians spend working on a project, and if there are periods in which developers spend 50 percent of their time checking that everything is okay, a tool which<br>completely automates this job could be useful enough to buy.</p>



<p><strong>So why aren’t they so common to so many developers?</strong></p>



<h2>Evaluating competitors and their approach to the problem</h2>



<p>I thought about the two main parameters a company looks at when it has to decide which tools use to increase productivity:</p>



<ol><li><em>Simplicity </em>(ease of installation and use)</li><li><em>Efficacy </em>(I spend x to solve a problem which is worth x+10, so I gain the +10)</li></ol>



<p>Using these parameters, I spent about a week creating an evaluation sheet of the most well-known monitoring instruments and I placed them in a graphic:</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2020/07/market-en-1024x533.png" alt="" srcset="https://www.inspector.dev/wp-content/uploads/2020/07/market-en-1024x533.png 1024w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en-300x156.png 300w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en-768x400.png 768w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en-1536x800.png 1536w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en-980x510.png 980w, https://www.inspector.dev/wp-content/uploads/2020/07/market-en.png 1841w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>After days of putting information together, a look at the graphic was enough to realize where the problem was.</p>



<p>Easy instruments do not provide enough value to the majority of developers. </p>



<p>More complete instruments, instead, are thought of as being for big organizations, and they need skilled staff who dedicate themselves to their installation, configuration and use, complicating team operations rather<br>than simplifying them.</p>



<p><strong>In my vision, the problem is not the monitoring itself but the development team efficiency.</strong></p>



<p>For a massive adoption, it would be necessary to have a product which requires a minute for the installation, no configurations and, at the same time, that provides complete and easy information to consult that would allow even medium-size development teams to fix the real-time monitoring problem.</p>



<p>And of course, it has to be cool.</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-1024x533.png" alt="" srcset="https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-1024x533.png 1024w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-300x156.png 300w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-768x400.png 768w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-1536x800.png 1536w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en-980x510.png 980w, https://www.inspector.dev/wp-content/uploads/2020/07/positioning-en.png 1841w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Developing the first prototype</h2>



<p>Finally, I decided to try. The last work experience had gone well and I thought that it would not be impossible for me to create this tool.</p>



<p>So, I immediately informed my partners that I wanted to build an MVP for the following two or three months. </p>



<p>When I explained it to them, it was hard to make them understand the problem because they are not technicians involved at the same level I am. They gave me the okay based 90 percent on trust, and I thank them for this.</p>



<p>Over the course of three months I was able to create this prototype:</p>



<figure><img src="https://www.inspector.dev/wp-content/uploads/2020/07/proto.gif" alt=""></figure>



<p>While working on the implementation, I gradually understood the problems of realizing this kind of tool and even problems users would encounter during its use.</p>



<p>From a technical point of view, a monitoring product has to be designed to work with huge quantities of data and I also wanted to deal with these data in real-time.</p>



<p>I had to spend longer than I predicted for the backend part —in other words, the part which cannot be seen, or the backstage of an in-cloud software — leaving out the graphic interface (as you can see above), which is the part users see and use.</p>



<h2>Throwing everything away and starting again</h2>



<p>In the last few years, the dream of launching a product on the market pushed me to constantly study and apply marketing strategies which are particularly adept for SaaS software, to different projects (even the failed ones).</p>



<p>I started to write articles for my blog with the aim of publishing them on different websites and social media to collect the first feedback.</p>



<p>Although I wrote horrible content in English with writing mistakes because English is not my mother tongue, feedback started to come.</p>



<ul><li>I do not understand what I can do with it;</li><li>How can I install it?</li><li>Why use it rather than XXX?</li><li>What does it offer which makes it different from any other one?</li><li>Etc…</li></ul>



<p>It was not easy to be objective while looking at developers’ responses and comments. <em>Emotional reaction</em> could always take advantage and it was really hard for me to understand where the mistake was because I am not a sales agent or a seller, but I am a damn good technician.</p>



<h3>Lesson 1 – Selling sucks</h3>



<p>Thanks to my technical skills on the matter, I did not need to sell. Rather, I just needed to learn how to communicate the problems I faced every day and how I fixed them with my tools.</p>



<p>I spent an entire month writing the most important things I knew about the monitoring and application scalability problems and the reasons why I decided to start this project, the difficulties I had been encountering during the development of a product, how I fixed them and moved forward,<br>code examples, technical guides, my best practices, and more.</p>



<p>Then I gave everything to <a href="https://www.fiverr.com/robinoo/professionally-proofread-1000-words?context=recommendation&amp;context_alg=recently_ordered%7Cco&amp;context_referrer=homepage&amp;context_type=gig&amp;mod=rep&amp;pckg_id=1&amp;pos=1&amp;source=recently_and_inspired&amp;tier_selection=recommended&amp;ref_ctx_id=1bf19e6d-aa27-407d-86ea-f8ca268b8131" target="_blank" rel="noreferrer noopener">Robin</a>, a Canadian copywriter found on Fiverr, who corrected all the content, including the website text, and polished the writing into native-level English.</p>



<h3>Lesson 2 – Insufficient product</h3>



<p>The fear of leaving out the user interface turned out to be a well-founded fear. What I did was not enough …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/">https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/</a></em></p>]]>
            </description>
            <link>https://www.inspector.dev/from-scratch-to-the-first-10-customers-how-i-designed-and-launched-a-saas-product/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23822081</guid>
            <pubDate>Mon, 13 Jul 2020 15:52:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Metric for determining quantitative product market fit]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821916">thread link</a>) | @firatcan
<br/>
July 13, 2020 | https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit | <a href="https://web.archive.org/web/*/https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5d47b84bb0f5980001a8659e" data-item-id="5d47b84bb0f5980001a8659e">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1564981747123" id="item-5d47b84bb0f5980001a8659e"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_86260"><div><h2>About the author</h2><p><a href="https://www.linkedin.com/in/jeff-chang-82467459/" target="_blank">Jeff Chang</a>&nbsp;(<a href="https://twitter.com/JeffChang30" target="_blank">@JeffChang30</a>) is a growth technical leader at Pinterest and angel investor. If your US based software startup is looking for an angel investor who can help with all things growth, please send over an <a href="mailto:jeff@growthengblog.com" target="_blank">email</a>!</p><h2>Intro</h2><p>There are many definitions of product market fit:</p><ul data-rte-list="default"><li><p>Product market fit is your NPS score</p></li><li><p>Product market fit is when 40% of your users would be “very disappointed” if they no longer have access to your product</p></li><li><p>Product market fit is a feeling</p></li><li><p>You need a good distribution channel to have product market fit</p></li><li><p>… and the list goes on</p></li></ul><p>Most of these definitions are pretty good - you can be successful using them and none of them are “wrong”. However, I think cohort retention rate is the most important product market fit metric, so I would recommend using it <strong>along with</strong> any other frameworks you use. This blog post describes what makes a good product market fit metric, evaluates a few definitions, and explains why cohort retention rate is a great metric to use.</p><p>Caveat: This only applies to multiple-use or subscription products, which is the vast majority of products. Examples of single-use products are mortgages and other types of loans, where a user is likely only going to purchase one over a long period of time.</p><p>Prior to product market fit, you should be focused on making the product better for your existing users. When a product has “product market fit”, it means that the product is good enough to start shifting focus from improving the product to growing distribution channels. If you distribute a product that isn’t great, even if you are able to get a lot of initial users, a few months down the road your user base won’t grow significantly or may even decline. So, you can also think of product market fit as “time to start building scalable acquisition channels”.</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_18093"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1565021640768-FHT3J2F1MRWQ0QDWK1C0/ke17ZwdGBToddI8pDm48kHTnMI9GKb6BUNDIc1KZu2Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqZFlQdVp7vViofexDEbEjBU2kxk2iQDc_of-xO2WgiWAAEOXDqVf-TecXDYuKLRw/growthenblog-PMF.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1565021640768-FHT3J2F1MRWQ0QDWK1C0/ke17ZwdGBToddI8pDm48kHTnMI9GKb6BUNDIc1KZu2Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqZFlQdVp7vViofexDEbEjBU2kxk2iQDc_of-xO2WgiWAAEOXDqVf-TecXDYuKLRw/growthenblog-PMF.png" data-image-dimensions="2500x1413" data-image-focal-point="0.5,0.5" alt="After you reach product market fit, you can spend more effort building scalable acquisition channels" data-load="false" data-image-id="5d4855bf511aa1000170d8a1" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1565021640768-FHT3J2F1MRWQ0QDWK1C0/ke17ZwdGBToddI8pDm48kHTnMI9GKb6BUNDIc1KZu2Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qqZFlQdVp7vViofexDEbEjBU2kxk2iQDc_of-xO2WgiWAAEOXDqVf-TecXDYuKLRw/growthenblog-PMF.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>After you reach product market fit, you can spend more effort building scalable acquisition channels</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_88416"><div><p>A good product market fit metric will have a low rate of false positives and false negatives. It won’t tell you that you should start distributing when your product <strong>isn’t</strong> good enough, and it won’t tell you that you shouldn’t start distributing when it <strong>is</strong> good enough.</p><p>The risk with false positives is that you work on distribution when you should be working on making the product better, which results in wasted distribution efforts due to churned users. The risk of false negatives is that you don’t work on distribution early enough to compete with competitors or meet goals needed to raise your next round before you run out of runway.</p><p>To summarize, a good product market fit metric:</p><ul data-rte-list="default"><li><p>Will tell you when the product is good enough to work acquisition channels</p></li><li><p>Minimizes false positives - won’t tell you to work on acquisition channels when the product needs more improvement</p></li><li><p>Minimizes false negatives - will tell you to on acquisition channels as soon as the product is good enough, to maximize growth</p></li></ul><p>Let’s evaluate some product market fit definitions based these points.</p><h2>Top tech companies in the world are able to grow with bad NPS</h2><p>NPS is sometimes used as a product market fit metric, but some of the biggest tech companies in the world have terrible NPS, but are still able to grow to over a billion users:</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_22020"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981498537-28F6C1E0ZFG1YBVPT7HD/ke17ZwdGBToddI8pDm48kNwP3op2XcRFs5h0t7BO7VcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmg0eN-jBGCjq7e1B29HVcy1u46tppJcCjeNJYG1KqgdCjLISwBs8eEdxAxTptZAUg/PMF-NPS.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981498537-28F6C1E0ZFG1YBVPT7HD/ke17ZwdGBToddI8pDm48kNwP3op2XcRFs5h0t7BO7VcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmg0eN-jBGCjq7e1B29HVcy1u46tppJcCjeNJYG1KqgdCjLISwBs8eEdxAxTptZAUg/PMF-NPS.png" data-image-dimensions="1518x808" data-image-focal-point="0.5,0.5" alt="Source:  https://customer.guru/net-promoter-score/top-brands" data-load="false" data-image-id="5d47b8fa48c3ef0001914224" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981498537-28F6C1E0ZFG1YBVPT7HD/ke17ZwdGBToddI8pDm48kNwP3op2XcRFs5h0t7BO7VcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmg0eN-jBGCjq7e1B29HVcy1u46tppJcCjeNJYG1KqgdCjLISwBs8eEdxAxTptZAUg/PMF-NPS.png">
          </p>
        
          
        

        
          
          <figcaption>
            
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_102815"><div><p>NPS as a product market fit metric has both false positives and false negatives.</p><h2>Other survey based metrics are better, but have a few flaws</h2><p>“40% of your users would be ‘very disappointed’ if they could no longer use your product” is a commonly used metric that most recently was used by <a href="https://firstround.com/review/how-superhuman-built-an-engine-to-find-product-market-fit/" target="_blank">Superhuman</a> to find product market fit, with great success. This is a much better metric than NPS and if you end up using this and reach it, you probably do have product market fit. However I think there are some flaws with survey based metrics:</p><p>Response bias - it’s really hard to get everyone to fill out a survey. As a result, you might find that that the distribution of survey results don’t actually match the true distribution of results if everyone answered due to the missing responses.</p><p>It’s a single snapshot in a long user journey - when is the best time to ask this question? If you ask it in the beginning, maybe their opinion will change over time. When a user signs up for a product, generally their intent is high. So, you should ask it later in the flow. However, if you ask it later, some users already dropped off so you are biasing results to higher intent users, which are the ones that stay.</p><p>Responses don’t match behavior - If you’ve worked on product or growth for a while, you should be familiar that what users aren’t always accurate at predicting their future behavior. For example, you could build a feature that a lot of users say they would use if available, but then after you launch, they might not actually use it.</p><p>While this metric is one of the best out there, I think that it can produce some false negatives, meaning you might have product market fit even if this number is not 40%.</p><h2>Distribution shouldn’t be a requirement for product market fit</h2><p>Some definitions of product market fit include a distribution aspect. I actually don’t think distribution is part of product market fit, because there is enough data on what distribution channels generally work, <a href="https://www.growthengblog.com/blog/the-2-most-popular-scaled-growth-channels-for-unicorn-consumer-companies-part-1-seo" target="_blank">SEO</a> and <a href="https://www.growthengblog.com/blog/the-2-most-popular-scaled-growth-channels-for-unicorn-consumer-companies-part-2-referral" target="_blank">referrals</a> for example. If you’re a consumer company, at least one of these channels should work for you. These two channels also have some sort of a moat - it takes a <strong>lot</strong> of effort and time to outrank current SEO “winners”, and referrals become a stronger channel the bigger userbase you have. Paid will also work to some degree, but shouldn’t be relied on as a scalable channel long term for most companies (unless your LTV is high and payback period is short). I’ve never met with a startup where after studying the product, my conclusion was “there are no distribution channels that will work for this startup”. In my opinion, any product with great cohort retention rate can be distributed with good growth strategy and execution.</p><h2>What is cohort retention rate?</h2><p>There are many methods of measuring retention rate but I think cohort retention rate is the one to use. Any sort of retention rate metric that mixes differently tenured users doesn’t make sense because the retention rates vary drastically between a new user and long term user. Here’s my definition:</p><p>Cohort retention rate - given a group of users who joined around the same time, the % of those users that stay long term</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_124121"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988916522-8VO65CW6QWP0LB2K0SC9/ke17ZwdGBToddI8pDm48kO_YhcHfcgYMoj0_UHY-iE9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxC1T2QDlrFhzAg5RRZ1oHSO7oIfdgckfXb5vveEdSKzgjBXZ6MOJz-yy4NEMKvr4s/cohort_retention_good.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988916522-8VO65CW6QWP0LB2K0SC9/ke17ZwdGBToddI8pDm48kO_YhcHfcgYMoj0_UHY-iE9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxC1T2QDlrFhzAg5RRZ1oHSO7oIfdgckfXb5vveEdSKzgjBXZ6MOJz-yy4NEMKvr4s/cohort_retention_good.png" data-image-dimensions="597x367" data-image-focal-point="0.5,0.5" alt="This is an example of a cohort retention graph for a single cohort. The cohort retention rate is around 30% because that’s where the graph flattens out." data-load="false" data-image-id="5d47d5f41c7ed7000177606d" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988916522-8VO65CW6QWP0LB2K0SC9/ke17ZwdGBToddI8pDm48kO_YhcHfcgYMoj0_UHY-iE9Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxC1T2QDlrFhzAg5RRZ1oHSO7oIfdgckfXb5vveEdSKzgjBXZ6MOJz-yy4NEMKvr4s/cohort_retention_good.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>This is an example of a cohort retention graph for a single cohort. The cohort retention rate is around 30% because that’s where the graph flattens out.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_119783"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988901319-JJ1GA3BZIKG7M0IEDJDM/ke17ZwdGBToddI8pDm48kAy5zisSUbAQSoB4q23pwuVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxvX7ZUME6r9ofLwPn30uTZsYn3Ty3SmCFIWGDEreIyhIIxsTGkOokFDROPJbuS4sk/cohort_retention_bad.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988901319-JJ1GA3BZIKG7M0IEDJDM/ke17ZwdGBToddI8pDm48kAy5zisSUbAQSoB4q23pwuVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxvX7ZUME6r9ofLwPn30uTZsYn3Ty3SmCFIWGDEreIyhIIxsTGkOokFDROPJbuS4sk/cohort_retention_bad.png" data-image-dimensions="590x365" data-image-focal-point="0.5,0.5" alt="If the graph never flattens out, then the cohort retention rate is 0%" data-load="false" data-image-id="5d47d5e5cdea4800010b6758" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564988901319-JJ1GA3BZIKG7M0IEDJDM/ke17ZwdGBToddI8pDm48kAy5zisSUbAQSoB4q23pwuVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxvX7ZUME6r9ofLwPn30uTZsYn3Ty3SmCFIWGDEreIyhIIxsTGkOokFDROPJbuS4sk/cohort_retention_bad.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>If the graph never flattens out, then the cohort retention rate is 0%</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_129312"><div><p><br>For more information on how to measure this, check out my other blog post: <a href="https://www.growthengblog.com/blog/the-most-important-growth-metric-for-early-startups" target="_blank">The most important growth metric for early startups</a></p><p><br>As you improve your product, newer cohorts will have high cohort retention rates. So, it’s important to have a cohort retention “triangle” chart to track progress:</p></div></div><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1564981306071_25917"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981669190-6YSFKD4PJ6X1OJBOCJEL/ke17ZwdGBToddI8pDm48kL6wKJO5xswp1GN6ZUAjbU0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc-ZNOdv7znCZeqvcIGhArM8FzjHIVKNMD0FHDIDHtAMlJJ9L3ZnrDX1YlJpwIZE9C/cohort_triangle.png" data-image="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981669190-6YSFKD4PJ6X1OJBOCJEL/ke17ZwdGBToddI8pDm48kL6wKJO5xswp1GN6ZUAjbU0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc-ZNOdv7znCZeqvcIGhArM8FzjHIVKNMD0FHDIDHtAMlJJ9L3ZnrDX1YlJpwIZE9C/cohort_triangle.png" data-image-dimensions="1324x604" data-image-focal-point="0.5,0.5" alt="Sample cohort retention “triangle” chart. This product has healthy retention for certain consumer verticals, bottoming out at around 30%. From the chart, you can see that product improvements were shipped around the week of 4/5 that improved retention of newer cohorts." data-load="false" data-image-id="5d47b9a41c7ed70001768d0f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5ac3325c36099b0503c61815/1564981669190-6YSFKD4PJ6X1OJBOCJEL/ke17ZwdGBToddI8pDm48kL6wKJO5xswp1GN6ZUAjbU0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc-ZNOdv7znCZeqvcIGhArM8FzjHIVKNMD0FHDIDHtAMlJJ9L3ZnrDX1YlJpwIZE9C/cohort_triangle.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Sample cohort retention “triangle” chart. This product has healthy retention for certain consumer verticals, bottoming out at around 30%. From the chart, you can see that product improvements were shipped around the week of 4/5 that improved retention of newer cohorts.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1564981306071_107802"><div><p>Once you have a few cohorts that level off at a vertical-specific number, then you’ve achieved product market fit!</p><p>Different types of products have different “points” of product market fit, so it’s important to <strong>find the retention rate of some comparable products</strong> that have been able to significantly grow to find the right benchmark for you.</p><p>A good rule of thumb is for consumer products, 25% is a good floor and and for B2B SaaS products, 70% is a good floor. Floor meaning if your cohort retention is below these numbers, you probably do not have product market fit. You’ll likely want a lot better though, with a lot of great consumer products having over 40% long term retention and B2B over 80%</p><h2>Why cohort retention rate is a great product market fit metric</h2><p>There are several advantages that cohort retention rate has over survey based product market fit metrics:</p><ul data-rte-list="default"><li><p>No response bias - you get information from all users, not just the ones with high enough intent to fill out a survey</p></li><li><p>Full user lifecycle data - if you run a survey to collect a metric at a specific point in the user lifecycle, that metric may be different later on, but unknown</p></li><li><p>Measuring actual user behavior - don’t run into the problem where survey responses don’t match behavior</p></li></ul><p>All of this being said, it would be great to use both cohort retention and survey based metrics, but at the …</p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit">https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit</a></em></p>]]>
            </description>
            <link>https://www.growthengblog.com/blog/the-best-metric-for-determining-quantitative-product-market-fit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821916</guid>
            <pubDate>Mon, 13 Jul 2020 15:40:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: PiHole As-a-Service (On Steroids)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821863">thread link</a>) | @microkernel
<br/>
July 13, 2020 | https://www.gardion.de/english-intro | <a href="https://web.archive.org/web/*/https://www.gardion.de/english-intro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><img src="https://www.gardion.de/assets/svg/devices-37.svg" height="48" alt="Icon"></p><h3>My internet!</h3>
        <p>Facebook is breathing down your neck? Your Xiaomi mobile is spying
          on you? Your app is reporting where you go and which flight you take? Not anymore. Gardion is a filtering VPN
          with the sole purpose to keep you safe and your data private.<mark>Gardion is your internet „invisibility
            cloak“.</mark></p>
      </div><div>
        <p><img src="https://www.gardion.de/assets/svg/science-15.svg" height="48" alt="Icon"></p><h3>Anytime, anywhere</h3>
        <p>Gardion works on all devices, anywhere; be it your smartphone (iOS, Android),
          your tablet or your laptop. Being geeks we made sure that BSD, Linux and other open systems can interface as
          well. <mark>The only requirement: Support for IPSEC or Wireguard</mark>. It works at home, while travelling,
          via WIFI and mobile network.
        </p>
      </div><div>
        <p><img src="https://www.gardion.de/assets/svg/communications-16.svg" height="48" alt="Icon"></p><h3>Trust, instead of Panama</h3>
        <p>The other VPN providers reside in Panama, Romania or the Netherlands Antilles.
          With Gardion you are on the safe side: When you want to work in a strong and trustworthy jurisdiction Germany
          is your choice. <mark>Our headquarter is in Freiburg/Germany and our servers are in Germany as well. No AWS,
            no Google cloud</mark>.
        </p>
      </div></div>]]>
            </description>
            <link>https://www.gardion.de/english-intro</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821863</guid>
            <pubDate>Mon, 13 Jul 2020 15:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brazil hid the data for Covid-19. Then volunteer developers got to work]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821862">thread link</a>) | @danso
<br/>
July 13, 2020 | https://restofworld.org/2020/brazil-data-transparency-covid19/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/brazil-data-transparency-covid19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>L</span>ike any other software developer, Álvaro Justen used to spend most of his waking hours in front of a screen, moving around in his chair, while writing code, working with databases, and processing spreadsheets. But since the first Covid-19 cases sprouted in his native Brazil, Justen’s routine changed significantly. He now works full time, without pay, on what was once a small side project that has become the comprehensive source for measurements of the pandemic’s impact in his country.</p>



<p>@turicas, as colleagues and <a href="https://twitter.com/turicas">Twitter followers</a> know Justen, founded his nonprofit <a href="https://brasil.io/home/">Brasil.IO</a> in 2018 as an initiative to make public data in Brazil more accessible. Now, he is focusing on information — or lack thereof — about the novel coronavirus in the country, one of the pandemic’s epicenters.</p>



<p>“If I’m awake, I’m probably working on the site. On Saturdays, Sundays, holidays,” he told <em>Rest of World</em>. He started his site by publishing lists — <a href="https://brasil.io/dataset/eleicoes-brasil/candidatos/">candidates for public office</a> or <a href="https://brasil.io/dataset/socios-brasil/socios/">business owners in the country</a> — in a user-friendly format.</p>



<p>Currently, the site’s <a href="https://brasil.io/covid19/">Covid-19 series</a> features an independent daily monitor of cases with breakdowns by state and city. More than 40 volunteer developers and data enthusiasts work on the project, gathering updates, identifying patterns, and creating datasets.</p>



<p><strong>Read: <a href="https://restofworld.org/2020/brazil-social-platforms-glorify-shooters/">Inside the online communities where young Brazilians glorify school shooters</a></strong></p>



<p>Collecting data can be a difficult, manual task. The volunteers work to cover more than 5,000 Brazilian cities. “Sometimes, data is only available in internal systems, and we have to request it,” Justen explained. “Or the data is available, but not in an easy format to work with.” The challenge is to turn these massive tranches of information — which can come in large spreadsheets or loose PDFs — into lighter files or user-friendly tables and graphics.</p>



<p>By 2018, data transparency had come a long way in Brazil. Since the military rule ended in 1985, the country has witnessed breakthroughs like the 2011 approval of the <a href="https://www.gov.br/acessoainformacao/pt-br">Access to Information Law</a>, akin to the U.S. Freedom of Information Act.&nbsp;</p>



<p>But experts, like Fernanda Campagnucci, executive director of <a href="https://www.ok.org.br/">Open Knowledge Brasil</a>, say that data transparency is not a priority for the Bolsonaro administration. Instead, it seems to prefer an unspoken policy to conceal, question, or take down any data that doesn’t agree with its narrative. “A posture toward restraining access [to information] is gaining ground, which was not typical of Brazil,” she told<em> Rest of World</em>.</p>



<p>These efforts began last year. In April 2019, the Bolsonaro administration took down the Brazilian Observatory on Drug Information’s website, which showed the number of illicit drug use among the population. Later, in August, the director of the <a href="http://www.inpe.br/">Brazilian National Institute for Space Research</a> was fired after <a href="https://www.nytimes.com/2019/08/02/world/americas/bolsonaro-amazon-deforestation-galvao.html">coming under </a>attack for showing that Amazon deforestation increased 68% in the first two weeks of July when compared to the same time period in the previous year. Earlier in the year, the government <a href="https://exame.com/brasil/apos-definir-cortes-ibge-propoe-reduzir-questoes-do-censo-2020/">cut the national census’ budget</a>, which led to a proposal to reduce population survey questions by almost a third.</p>



<p><strong>Read: <a href="https://restofworld.org/2020/brazil-favela-chat-groups/">Brazil’s grassroots chat groups succeed where public services fail</a></strong></p>



<p>The coronavirus pandemic threw this informal policy out in the open. Addressing this gap became a “matter of survival,” according to Justen. He grew skeptical of the numbers from the Brazilian government, once he noticed its site going offline for a few hours and coming back up with incomplete datasets. The site also took about two months to publish breakdowns by city.&nbsp;&nbsp;</p>



<p>Justen’s suspicions turned out to be right. As the number of Covid-19 infections grew exponentially, the <a href="https://covid.saude.gov.br/">official government website for Covid-19</a> statistics went offline on June 5, 2020. When a new version went live, it featured only numbers from the past 24 hours, and the cumulative data were gone. Three days later, the ministry was forced to restore the website on the orders of the Supreme Court.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-40x21.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-400x211.png 400w, https://restofworld.org/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-600x316.png 600w, https://restofworld.org/wp-content/uploads/2020/07/Screen-Shot-2020-07-09-at-9.42.37-PM-1600x843.png 1600w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://brasil.io/covid19/" target="_blank" rel="noopener noreferrer">https://brasil.io/covid19/</a></span>
			</figcaption>
		</figure>


<hr>



<p><strong>As news of</strong> the Covid-19 data <a href="https://www.bloomberg.com/news/articles/2020-06-07/brazil-s-covid-data-blackout-is-a-tragedy-ex-health-chief-says">blackout</a> spread, the number of unique daily visitors to Brasil.IO skyrocketed from 4,000 to 30,000. Meanwhile, tensions at the Ministry of Health boiled over: Disagreements with Bolsonaro had led two <a href="https://noticias.uol.com.br/politica/ultimas-noticias/2020/05/15/nelson-teich-pede-demissao-do-governo-bolsonaro.htm">previous ministers to leave their posts</a>; the president, in turn, appointed an army general as interim minister. The government also pushed back its daily Covid-19 press briefing from 5 p.m. to 10 p.m. hush-hush <a href="https://www.saude.gov.br/noticias/agencia-saude/47173-coronavirus-brasil-registra-927-292-pessoas-recuperadas">press releases</a> that led with the numbers of recovered patients, which was widely suggested to be an attempt to stop them from being <a href="https://www1.folha.uol.com.br/equilibrioesaude/2020/06/acabou-materia-no-jornal-nacional-diz-bolsonaro-sobre-atraso-em-divulgacao-de-boletim-da-covid-19.shtml">featured in prime-time news broadcasts</a> and print newspapers.&nbsp;&nbsp;</p>



<p>As drama embroiled the executive branch, independent data collectors continued their work. They did so using an information network<strong> </strong>that integrates Brazil’s universal healthcare system with its epidemiological surveillance department. When doctors on the ground identify a case from a list of diseases, including Covid-19, they report it to a monitor at the Ministry of Health. Each state then consolidates the data and publishes daily epidemiological bulletins that are open to the public. “If states stopped doing that, an initiative like Brasil.IO’s Covid-19 project would not be able to exist,” Campagnucci said.&nbsp;</p>



<p>When operating as intended, this integrated system responds quickly to local- and federal-level health emergencies. It was crucial during the 2015 Zika epidemic, when it uncovered the initial surge in cases of microcephaly, a condition in which a baby is born with a smaller head than normal. That allowed researchers in Brazil to identify, early on, the link between Zika infection and microcephaly among newborns. “Microcephaly was only the tip of the iceberg. And the response to it was praiseworthy,” said Wayner Vieira, a Brazilian epidemiologist.</p>



<p>While developing Brasil.IO, Justen and his team incorporated this integrated system into their work. Groups of volunteers covered specific states, with the help of local health departments. Every day, a bot sends the volunteers updates. Volunteers work separately to upload the most recent information into Brasil.IO’s platform. If their numbers don’t match, the system sends out an alert. In a country like Brazil, such differences in official statistics are relatively common. States publish epidemiological bulletins at different times of the day or even use different methodologies. “Sometimes [local governments] publish a PDF file or an image, or the numbers are part of a press release,” Justen told <em>Rest of World</em>. “Automatizing this process is very hard.”&nbsp;</p>



<p>Alarmed by the Covid-19 data blackout, the Brasil.IO team posted its consolidated reports on Twitter as an alternative to the federal bulletins. Its <a href="https://twitter.com/turicas/status/1269425532241879041">first one</a> came out on June 6, immediately after the blackout, when it was still unclear whether the federal government would restore access to the cumulative data gathered for Covid-19 thus far. “Our work is to advocate for governments to open data because this is their responsibility. Independent initiatives [like Brasil.IO] emerge only because the government fails to do so,” Campagnucci said.</p>



<p>With the help of bots and dozens of volunteers, as of July 11, Brasil.IO has published 36 bulletins so far. They have joined other organizations’ calls for better transparency.&nbsp;</p>



<p>As the number of Covid-19 cases in Brazil continues to rise — as of July 8, it was over 1,700,000 people<strong> </strong>—<strong> </strong>and even president Bolsonaro <a href="https://www.washingtonpost.com/world/the_americas/coronavirus-brazil-bolsonaro-tests-positive/2020/07/07/5fa71548-c049-11ea-b4f6-cb39cd8940fb_story.html">tested positive for Covid-19</a>,<strong> </strong>independent data collectors have a long way to go. Brasil.IO continues to build datasets and now plans to research the pandemic’s economic impact in the country. “A lot of the available information still cannot be easily managed by laypeople, unless they are experts in data analysis,” Justen said. “In this case, it is as if the data was not available at all.”</p>



<p><em>Like our stories? Follow Rest of World on&nbsp;<a rel="noreferrer noopener" href="https://www.facebook.com/readrestofworld/" target="_blank">Facebook</a>,&nbsp;<a rel="noreferrer noopener" href="https://twitter.com/restofworld" target="_blank">Twitter (@RestofWorld)</a>&nbsp;and&nbsp;<a rel="noreferrer noopener" href="https://www.instagram.com/restofworld/" target="_blank">Instagram</a></em>,<em> and let us know how we’re doing.</em></p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/brazil-data-transparency-covid19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821862</guid>
            <pubDate>Mon, 13 Jul 2020 15:35:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deschooling Society (1970)]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 179 (<a href="https://news.ycombinator.com/item?id=23821855">thread link</a>) | @minerjoe
<br/>
July 13, 2020 | https://davidtinapple.com/illich/1970_deschooling.html | <a href="https://web.archive.org/web/*/https://davidtinapple.com/illich/1970_deschooling.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="700">
				<tbody><tr>
					<td><span size="+2">DESCHOOLING SOCIETY</span><p>
						
						&nbsp;
						IVAN ILLICH</p><p>
						
						&nbsp;
						
						&nbsp;
						Contents</p><p>
						
						&nbsp;
						
						Introduction xix </p><p>
						
						<a href="#1">1. Why We Must Disestablish School</a></p><p>
						
						<a href="#2">2. Phenomenology of School<br>
						</a><br>
						<a href="#3">3. Ritualization of Progress<br>
						</a><br>
						<a href="#4">4. Institutional Spectrum</a></p><p>
						
						<a href="#5">5. Irrational Consistencies</a></p><p>
						
						<a href="#6">6. Learning Webs</a></p><p>
						
						<a href="#7">7. Rebirth of Epimethean Man</a></p><p>
						
						&nbsp;
						
						
						
						
						&nbsp;
						
						Introduction</p><p>
						
						
						&nbsp;
						
						I owe my interest in public education to Everett Reimer. Until we first met in Puerto Rico in 1958, I had never questioned the value of extending obligatory schooling to all people. Together we have come to realize that for most men the right to learn is curtailed by the obligation to attend school. The essays given at CIDOC and gathered in this book grew out of memoranda which I submitted to him, and which we discussed during 1970, the thirteenth year of our dialogue. The last chapter contains my afterthoughts on a conversation with Erich Fromm on Bachofen's Mutterrecht.</p><p>
						
						
						Since 1967 Reimer and I have met regularly at the Center for Intercultural Documentation (CIDOC) in Cuernavaca, Mexico. Valentine Borremans, the director of the Center, also joined our dialogue, and constantly urged me to test our thinking against the realities of Latin America and Africa. This book reflects her conviction that the ethos, not just the institutions, of society ought to be "deschooled."</p><p>
						
						
						Universal education through schooling is not feasible. It would be no more feasible if it were attempted by means of alternative institutions built on the style of present schools. Neither new attitudes of teachers toward their pupils nor the proliferation of educational hardware or software (in classroom or bedroom), nor finally the attempt to expand the pedagogue's responsibility until it engulfs his pupils' lifetimes will deliver universal education. The current search for new educational funnels must be reversed into the search for their institutional inverse: educational webs which heighten the opportunity for each one to transform each moment of his living into one of learning, sharing, and caring. We hope to contribute concepts needed by those who conduct such counterfoil research on education--and also to those who seek alternatives to other established service industries.</p><p>
						
						
						On Wednesday mornings, during the spring and summer of 1970, I submitted the various parts of this book to the participants in our CIDOC programs in Cuernavaca. Dozens of them made suggestions or provided criticisms. Many will recognize their ideas in these pages, especially Paulo Freire, Peter Berger, and Jos? Maria Bulnes, as well as Joseph Fitzpatrick, John Holt, Angel Quintero, Layman Allen, Fred Goodman, Gerhard Ladner, Didier Piveteau, Joel Spring, Augusto Salazar Bondy, and Dennis Sullivan. Among my critics, Paul Goodman most radically obliged me to revise my thinking. Robert Silvers provided me with brilliant editorial assistance on Chapters 1, 3, and 6, which have appeared in The New York Review of Books.</p><p>
						
						
						Reimer and I have decided to publish separate views of our joint research. He is working on a comprehensive and documented exposition, which will be subjected to several months of further critical appraisal and be published late in 1971 by Doubleday &amp; Company. Dennis Sullivan, who acted as secretary at the meetings between Reimer and myself, is preparing a book for publication in the spring of 1972 which will place my argument in the context of current debate about public schooling in the United States. I offer this volume of essays now in the hope that it will provoke additional critical contributions to the sessions of a seminar on "Alternatives in Education" planned at CIDOC in Cuernavaca for 1972 and 1973.</p><p>
						
						
						I intend to discuss some perplexing issues which are raised once we embrace the hypothesis that society can be deschooled; to search for criteria which may help us distinguish institutions which merit development because they support learning in a deschooled milieu; and to clarify those personal goals which would foster the advent of an Age of Leisure (schole) as opposed to an economy dominated by service industries. </p><p>
						
						
						IVAN ILLICH</p><p>
						
						
						&nbsp;
						
						
						CIDOC</p><p>
						
						
						Cuernavaca, Mexico</p><p>
						
						
						November, 1970<br>
						<a name="1"></a>.</p><a href="#top"><span size="-1">index&nbsp;</span></a><span size="+1">1.  Why We Must Disestablish School</span><p>
						
						
						&nbsp;
						
						
						Many students, especially those who are poor, intuitively know what the schools do for them. They school them to confuse process and substance. Once these become blurred, a new logic is assumed: the more treatment there is, the better are the results; or, escalation leads to success. The pupil is thereby "schooled" to confuse teaching with learning, grade advancement with education, a diploma with competence, and fluency with the ability to say something new. His imagination is "schooled" to accept service in place of value. Medical treatment is mistaken for health care, social work for the improvement of community life, police protection for safety, military poise for national security, the rat race for productive work. Health, learning, dignity, independence, and creative endeavor are defined as little more than the performance of the institutions which claim to serve these ends, and their improvement is made to depend on allocating more resources to the management of hospitals, schools, and other agencies in question.</p><p>
						
						
						In these essays, I will show that the institutionalization of values leads inevitably to physical pollution, social polarization, and psychological impotence: three dimensions in a process of global degradation and modernized misery. I will explain how this process of degradation is accelerated when nonmaterial needs are transformed into demands for commodities; when health, education, personal mobility, welfare, or psychological healing are defined as the result of services or "treatments." I do this because I believe that most of the research now going on about the future tends to advocate further increases in the institutionalization of values and that we must define conditions which would permit precisely the contrary to happen. We need research on the possible use of technology to create institutions which serve personal, creative, and autonomous interaction and the emergence of values which cannot be substantially controlled by technocrats. We need counterfoil research to current futurology.</p><p>
						
						
						I want to raise the general question of the mutual definition of man's nature and the nature of modern institutions which characterizes our world view and language. To do so, I have chosen the school as my paradigm, and I therefore deal only indirectly with other bureaucratic agencies of the corporate state: the consumer-family, the party, the army, the church, the media. My analysis of the hidden curriculum of school should make it evident that public education would profit from the deschooling of society, just as family life, politics, security, faith, and communication would profit from an analogous process.</p><p>
						
						
						I begin my analysis, in this first essay, by trying to convey what the deschooling of a schooled society might mean. In this context, it should be easier to understand my choice of the five specific aspects relevant to this process with which I deal in the subsequent chapters.</p><p>
						
						
						Not only education but social reality itself has become schooled. It costs roughly the same to school both rich and poor in the same dependency. The yearly expenditure per pupil in the slums and in the rich suburbs of any one of twenty U.S. cities lies in the same range-and sometimes is favorable to the poor. Rich and poor alike depend on schools and hospitals which guide their lives, form their world view, and define for them what is legitimate and what is not. Both view doctoring oneself as irresponsible, learning on one's own as unreliable, and community organization, when not paid for by those in authority, as a form of aggression or subversion. For both groups the reliance on institutional treatment renders independent accomplishment suspect. The progressive underdevelopment of self- and community-reliance is even more typical in Westchester than it is in the northeast of Brazil. Everywhere not only education but society as a whole needs "deschooling."</p><p>
						
						
						Welfare bureaucracies claim a professional, political, and financial monopoly over the social imagination, setting standards of what is valuable and what is feasible. This monopoly is at the root of the modernization of poverty. Every simple need to which an institutional answer is found permits the invention of a new class of poor and a new definition of poverty. Ten years ago in Mexico it was the normal thing to be born and to die in one's own home and to be buried by one's friends. Only the soul's needs were taken care of by the institutional church. Now to begin andend life at home become signs either of poverty or of special privilege. Dying and death have come under the institutional management of doctors and undertakers.</p><p>
						
						
						Once basic needs have been translated by a society into demands for scientifically produced commodities, poverty is defined by standards which the technocrats can change at will. Poverty then refers to those who have fallen behind an advertised ideal of consumption in some important respect. In Mexico the poor are those who lack three years of schooling, and in New York they are those who lack twelve.</p><p>
						
						
						The poor have always been socially powerless. The increasing reliance on institutional care adds a new dimension to their helplessness: psychological …</p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidtinapple.com/illich/1970_deschooling.html">https://davidtinapple.com/illich/1970_deschooling.html</a></em></p>]]>
            </description>
            <link>https://davidtinapple.com/illich/1970_deschooling.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821855</guid>
            <pubDate>Mon, 13 Jul 2020 15:34:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I just created this 1-page Python Cheat Sheet for ease of learning]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821752">thread link</a>) | @zweig
<br/>
July 13, 2020 | https://blog.finxter.com/concise-python-cheat-sheet/ | <a href="https://web.archive.org/web/*/https://blog.finxter.com/concise-python-cheat-sheet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">

		
		
<p>Do you want to learn Python but you’re overwhelmed and you don’t know where to start? Learn with Python cheat sheets! They compress the most important information in an easy-to-digest 1-page format. </p>



<p>Here’s the new Python cheat sheet I just created—my goal was to make it the world’s most concise Python cheat sheet!</p>



<div><figure><a href="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.pdf" target="_blank" rel="noopener noreferrer"><img src="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.jpg" alt="Python Ultimate Cheat Sheet" width="720" height="960" srcset="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.jpg 720w, https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet-225x300.jpg 225w" sizes="(max-width: 720px) 100vw, 720px" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.jpg" data-srcset="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.jpg 720w, https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet-225x300.jpg 225w"></a></figure></div>



<div>
<div><p><a href="https://blog.finxter.com/wp-content/uploads/2020/07/Finxter_WorldsMostDensePythonCheatSheet.pdf" target="_blank" rel="noreferrer noopener">Download PDF Now</a></p></div>
</div>




</div></div>]]>
            </description>
            <link>https://blog.finxter.com/concise-python-cheat-sheet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821752</guid>
            <pubDate>Mon, 13 Jul 2020 15:26:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create a GitHub profile readme]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821665">thread link</a>) | @jerodsanto
<br/>
July 13, 2020 | https://www.aboutmonica.com/blog/how-to-create-a-github-profile-readme | <a href="https://web.archive.org/web/*/https://www.aboutmonica.com/blog/how-to-create-a-github-profile-readme">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><article><header><p> <span> <!-- -->🍿 3 min. read</span></p></header><p>GitHub recently released a feature that allows users to create a profile-level README to display prominently on their GitHub profile. This article walksthrough how to access this new feature. I'll also be sharing some fun GitHub profiles I've seen so far. I'd love it if you shared yours with me on Twitter <a href="https://twitter.com/waterproofheart">@waterproofheart</a>.</p><p><img src="https://www.aboutmonica.com/media/monica-github-readme-edit.gif">
<em>The above GIF shows what my README looks like at the time of this writing. You may notice I was recently selected to be <a href="https://stars.github.com/">GitHub star</a>!</em></p><h2 id="why-readmes"><a href="#why-readmes" aria-label="why readmes permalink"></a>Why READMEs?</h2><p>The GitHub profile-level README feature allows more content than the profile bio, supports markdown which means you can play around with the content more visually (Did someone say GIFs!?) and the README is significantally more visible as it is placed above pinned repositories and takes up as much space above the fold of the webpage as you like.</p><p>A solid README is a core-component of well-documented software and often encourages collaboration by sharing helpful context with contributors. In my opinion, a profile-level README seems like a great extension of a convention a lot of GitHub users are already familiar with. If you're looking to make project-level READMEs more awesome and helpful check out <a href="https://github.com/matiassingers/awesome-readme">matiassingers/awesome-readme</a> for resources and examples of compelling READMEs.</p><h2 id="how-do-i-create-a-profile-readme"><a href="#how-do-i-create-a-profile-readme" aria-label="how do i create a profile readme permalink"></a>How do I create a profile README?</h2><p>The profile README is created by creating a new repository that’s the same name as your username. For example, my GitHub username is m0nica so I created a new repository with the name m0nica. Note: at the time of this writing, in order to access the profile README feature, the letter-casing <strong>must</strong> match your GitHub username.</p><p>If you already have a project in a repo-named username/username and are interested in setting up a profile-level README, then I recommend either <a href="https://docs.github.com/en/github/administering-a-repository/renaming-a-repository">re-naming that repository</a> or re-purposing the existing project's README based on what makes the most sense in your particular situation.</p><ol><li><p>Create a new repository with the same name (including casing) as your GitHub username: <a href="https://github.com/new">https://github.com/new</a></p></li><li><p>Create a README.md file inside the new repo with content (text, GIFs, images, emojis, etc.)</p></li><li><p>Commit your fancy new README!</p><ul><li>If you're on GitHub's web interface you can choose to commit directly to the repo's main branch (i.e., <code>master</code> or <code>main</code>) which will make it immediately visible on your profile)</li></ul></li><li><p>Push changes to GitHub (if you made changes locally i.e., on your computer and not github.com)</p></li></ol><p><img src="https://www.aboutmonica.com/media/create-repository.jpg"></p><h2 id="fun-readmes"><a href="#fun-readmes" aria-label="fun readmes permalink"></a>Fun READMEs</h2><p>The GitHub README profiles are written in Markdown which means you aren't just limited to texts and links, you can include GIFs and images. Need to brush up on Markdown Syntax? <a href="https://guides.github.com/pdfs/markdown-cheatsheet-online.pdf">Check out this Markdown Cheatsheet</a>.</p><blockquote data-dnt="true">— Jason Lengstorf (@jlengstorf) <a href="https://twitter.com/jlengstorf/status/1281026687103168512">July 9, 2020</a></blockquote><blockquote data-dnt="true"><p lang="en" dir="ltr">It's not as creative as <a href="https://twitter.com/sudo_overflow">@sudo_overflow</a>'s readme, but here's what I came up with. I also plan on adding some text below the image with links to my resume, etc. <a href="https://t.co/C6b8tNDo1z">pic.twitter.com/C6b8tNDo1z</a></p>— donavon "#BLM" west (@donavon) <a href="https://twitter.com/donavon/status/1281231777475026945">July 9, 2020</a></blockquote><blockquote data-dnt="true"><p lang="en" dir="ltr">Is this how we suppose use github's readme? <a href="https://t.co/XvLvCUC6iD">pic.twitter.com/XvLvCUC6iD</a></p>— Pouya (@Saadeghi) <a href="https://twitter.com/Saadeghi/status/1281111778290786310">July 9, 2020</a></blockquote><p>If you're really ambitious you can use <a href="https://github.com/features/actions">GitHub actions</a> or other automation like bdougieYO or simonw to dynamically pull data into your README:</p><blockquote data-dnt="true"><p lang="en" dir="ltr">Check it out. I made MySpace but on <a href="https://twitter.com/github">@github</a>.<a href="https://t.co/p4DWP4DxRR">https://t.co/p4DWP4DxRR</a> - My list is power by a GitHub Action workflow 😏 <a href="https://t.co/PN80mFCqOE">pic.twitter.com/PN80mFCqOE</a></p>— Brian Douglas (@bdougieYO) <a href="https://twitter.com/bdougieYO/status/1281699715466199040">July 10, 2020</a></blockquote><blockquote data-dnt="true"><p lang="en" dir="ltr">Made myself a self-updating GitHub personal README! It uses a GitHub Action to update itself with my latest GitHub releases, blog entries and TILs <a href="https://t.co/Eve7FOrwYK">https://t.co/Eve7FOrwYK</a> <a href="https://t.co/oJPXLtFdgM">pic.twitter.com/oJPXLtFdgM</a></p>— Simon Willison (@simonw) <a href="https://twitter.com/simonw/status/1281435464474324993">July 10, 2020</a></blockquote><p>Serverless functions can also be used to dynamically generate information (for example your current Spotify activity):</p><blockquote data-dnt="true">— Nate Moore (@n_moore) <a href="https://twitter.com/n_moore/status/1282326538990563329">July 12, 2020</a></blockquote><p>I'm a huge proponent that folks should maintain a website they have complete ownership over (even if it's a no-code website solution) but this is tempting...</p><blockquote data-dnt="true"><p lang="en" dir="ltr">I just created my <a href="https://twitter.com/github">@github</a> profile README as well with a bunch of badges. This is really a brilliant idea. We may no longer need to maintain our personal website. We can write blogs as issues, manage Wiki and task board, free traffic analytics and CI/CD. <a href="https://t.co/zSXZKT6a20">https://t.co/zSXZKT6a20</a> <a href="https://t.co/mK9OWXG9iH">pic.twitter.com/mK9OWXG9iH</a></p>— Yuan Tang (@TerryTangYuan) <a href="https://twitter.com/TerryTangYuan/status/1281590275660537858">July 10, 2020</a></blockquote><blockquote data-dnt="true"><p lang="en" dir="ltr">hey, so we heard ya &amp; are trying out a thing where you CAN have a readme on your <a href="https://twitter.com/github">@github</a> profile... <a href="https://twitter.com/mikekavouras">@mikekavouras</a> built it btw! re:  <a href="https://t.co/UC6q3qHjjR">https://t.co/UC6q3qHjjR</a> <a href="https://t.co/kB0kafgovY">pic.twitter.com/kB0kafgovY</a></p>— kathy ☁️ (@pifafu) <a href="https://twitter.com/pifafu/status/1265773172520914944">May 27, 2020</a></blockquote><p>I've been inspired by the creative READMEs I've seen so far and am looking forward to seeing all kinds of profiles in the upcoming months.</p> <p>This article was published on <!-- -->July 11, 2020<!-- -->.</p><hr><hr><nav><br></nav><br></article></main></div></div>]]>
            </description>
            <link>https://www.aboutmonica.com/blog/how-to-create-a-github-profile-readme</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821665</guid>
            <pubDate>Mon, 13 Jul 2020 15:18:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Auth Bottleneck Pattern]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821624">thread link</a>) | @mooreds
<br/>
July 13, 2020 | https://fusionauth.io/blog/2020/07/08/auth-and-the-bottleneck-architecture | <a href="https://web.archive.org/web/*/https://fusionauth.io/blog/2020/07/08/auth-and-the-bottleneck-architecture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://fusionauth.io/blog/2020/07/08/auth-and-the-bottleneck-architecture</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821624</guid>
            <pubDate>Mon, 13 Jul 2020 15:15:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privacy friendly website analytics also will be blocked by default]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23821623">thread link</a>) | @l1am0
<br/>
July 13, 2020 | https://simon-frey.com/blog/privacy-friendly-website-analytics-also-will-be-blocked-by-default/ | <a href="https://web.archive.org/web/*/https://simon-frey.com/blog/privacy-friendly-website-analytics-also-will-be-blocked-by-default/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wtr-content" data-bg="#FFFFFF" data-fg="#f44813" data-width="5" data-mute="" data-fgopacity="0.5" data-mutedopacity="0.5" data-placement="top" data-placement-offset="0" data-content-offset="0" data-placement-touch="top" data-placement-offset-touch="0" data-transparent="" data-touch="" data-non-touch="1" data-comments="0" data-commentsbg="#ffcece" data-location="page" data-mutedfg="#f44813" data-rtl="">
<p><strong>First things first: I love the movement to use more privacy-friendly website analytics tools. More and more small startups are popping up and help you to move away from Google Analytics. And each and every website not using Google Analytics anymore is a win for the free internet</strong></p>
<p><strong>BUT</strong> Please dear privacy-friendly analytics developers: Stop telling me your tool is better because Google Analytics is getting blocked by more and more browsers/ad blockers.</p>
<p>This seems to be the current No.1 marketing story for these tools as I think I read the 5th blog post about this topic today. This it the TLDR for all of them: “Browser start blocking Google Analytics. Use my tool if you really want to track all users as my tool is not blocked”</p>
<p>In itself this statement is not per se wrong. Yes more and more browsers are blocking Google Analytics as of why the tracking will produce numbers that are off compared to the real visitor count of your website.</p>
<p>But the second part is what annoys me. The tracking script provided by these small new analytics tools is not blocked by browsers and ad blockers <strong>at this moment</strong> because of only one reason: The analytics tools is not widely known enough to be a big problem and to be recognized by the big ad blockers, browser and blocking list providers.</p>
<p>In the very second the goal of these startups works, and they get more users they will have the exact same problem with being blocked by default. And I assume these tools will be even blocked more as they do not have the same influence like google does to negotiate with the certain browser providers for certain deals.</p>
<p>Talking users into changing to a tool with this reasoning seems not transparent and honest to me.</p>
<p>Please don’t stop providing and using alternatives to google analytics, but stop catching users with false claims.</p>
<hr>
<p>As you might see in your ad blocker I do not use Google Analytics but a self-hosted version of <a href="https://matomo.org/">Matomo</a>, an open source analytics tools which is as easy to install and use as WordPress (Jepp, both run with MariaDB and PHP)</p>
<p>Normally Matomo is blocked by ad blockers even in a self-hosted version as the ad blockers identify it by its query parameters. To circumvent this blocking I did build a small script which can be bought on <a href="https://byrly.com/mcab">Gumroad</a>. With the help of this script you can run a self-hosted version of Matomo which is not blocked by ad blockers, now and forever (as long as your custom Matomo domain e.g. ‘l1am0.uber.space’ is not blocked)</p>
<p>So did I only write this blog post to sell you my script and undermine my credibility with this action? No! The script can be found MIT licensed on <a href="https://github.com/simonfrey/matomo_circumvent_adblock">GitHub</a>. With purchasing the support license for a few bucks you help me to keep working on it. The lifetime license is less than a single month in all other privacy-friendly analytics.</p>
</div></div>]]>
            </description>
            <link>https://simon-frey.com/blog/privacy-friendly-website-analytics-also-will-be-blocked-by-default/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821623</guid>
            <pubDate>Mon, 13 Jul 2020 15:15:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Virgin YouTube vs. the Chad PeerTube]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23821616">thread link</a>) | @antepodius
<br/>
July 13, 2020 | https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3 | <a href="https://web.archive.org/web/*/https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://videos.lukesmith.xyz/videos/watch/2de152be-1346-4ab4-b377-bf008408ebc3</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821616</guid>
            <pubDate>Mon, 13 Jul 2020 15:15:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[8 rituals I followed to be a better programmer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821485">thread link</a>) | @arpitbbhayani
<br/>
July 13, 2020 | https://arpitbhayani.me/blogs/better-programmer | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/better-programmer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>"How to get better at programming?" is the question I had been asked quite a few times, and today I lay down the 8 rituals I have been following, and action items for each, to be good and get better at programming.</p>

<p>Doing something repeatedly always helps and writing a lot of code will develop our ability to</p>
<ul>
<li>write code while we think</li>
<li>think faster, think better</li>
<li>foresee requirement changes and possible logic extensions</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>One significant contribution to a project every two weeks</li>
<li>Solve at least two programming questions (from <a href="https://www.codechef.com/">Codechef</a>, <a href="https://www.spoj.com/">Spoj</a> or <a href="https://www.hackerrank.com/">HackerRank</a>) every week, till we solve at least 300 questions</li>
</ul>

<p>If we don't do something repeatedly, it becomes extremely hard to get good at it. Writing code consistently helps us</p>
<ul>
<li>define the programmatic and algorithmic flow quickly</li>
<li>build a habit of programming and thinking analytically</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>make one small contribution to anyone project every three days</li>
</ul>

<p>Solving programming questions is about developing logic but things become a little trickier when we build a complex system, as it requires us to take our programming skills to go up a notch. Some examples of complex systems are - a Library management system, a <a href="https://twitter.com/">Twitter</a> clone, an <a href="https://www.instagram.com/">Instagram</a> clone, etc. Building a complex system</p>
<ul>
<li>widens our tech stack</li>
<li>makes us keep our code flexible, extensible and reusable</li>
<li>helps us understand how to split our code into independent segments that work in harmony</li>
</ul>
<h3>Action Items</h3>
<ul>
<li>build one complex system every 4 months</li>
</ul>

<p>After we spend some time writing programs and solving problems, things become monotonous and do not seem to challenge us anymore, so to spice things up a bit we should model something from the real world, like</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Projectile_motion">projectile motion</a></li>
<li><a href="https://en.wikipedia.org/wiki/Double_pendulum">double pendulum</a></li>
<li><a href="https://en.wikipedia.org/wiki/Numerical_model_of_the_Solar_System">solar system simulation</a></li>
</ul>
<p>There are lots of libraries and framework like <a href="https://p5js.org/">p5.js</a> that makes visual programming simple.</p>
<h3>Action Items</h3>
<ul>
<li>once every 6 months model a physical phenomenon</li>
</ul>

<p>It is not only writing code that improves our programming skills but it is reading some quality code written by expert programmers that make the difference. Reading code written by experts improve our programming vocabulary and by doing this we</p>
<ul>
<li>learn the best programming practices</li>
<li>discover the new programming paradigms</li>
<li>find ways to properly structure our code for extensibility</li>
</ul>
<p>The best way to start doing it is by picking up an open-source project and start skimming the code. It is okay to not understand it in the first go but it is important to skim it a few times and get acquainted. After a few skim, everything will fall in place, the code becomes familiar and we start to understand the flow and business logic.</p>
<h3>Action Items</h3>
<ul>
<li>pick an open-source project every 6 months and skim its code once every two months</li>
<li>pick a tiny open-source utility, from an experienced developer, every month and skim it</li>
</ul>

<p>There is always someone sitting on the other side of the globe, who knows a thing or two more than us. Look for them and collaborate on a project. The developer community is filled with super smart and super enthusiastic developers who love to share and collaborate. Use websites like <a href="https://dev.to/">Dev.to</a>, <a href="https://hashnode.com/">Hashnode</a> and <a href="https://twitter.com/">Twitter</a> to find and interact with like-minded people.</p>
<h3>Action Items</h3>
<ul>
<li>collaborate on a project once a year</li>
<li>be active on platforms like <a href="https://dev.to/">Dev.to</a>, <a href="https://hashnode.com/">Hashnode</a> and <a href="https://twitter.com/">Twitter</a></li>
</ul>

<p>A programming language is just a tool to express business logic. While learning a programming language we should try to understand the constructs and paradigms used - for example: <a href="https://en.wikipedia.org/wiki/Functional_programming">Functional programming</a>, <a href="https://en.wikipedia.org/wiki/Polymorphism_(computer_science)">Polymorphism</a>, <a href="https://en.wikipedia.org/wiki/Event-driven_programming">Event driven programming</a>, <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a>, etc. It is important to do so because we could pick constructs from one language and use it in another to solve our problem. For example: picking Functional programming (Callbacks) from Javascript and using it in Python to create generic action functions.</p>
<h3>Action Items</h3>
<ul>
<li>learn one design pattern every month and build a simulation around it</li>
<li>pick a language construct and implement it in some other language</li>
</ul>

<p>Writing code before putting in some thought is degraded the code more often than not. The code written like this lacks simplicity, reusability, and extensibility. Spending some time thinking about problem statement or task at hand and having a rough execution plan always helps.</p>
<h3>Action Items</h3>
<ul>
<li>always define the scope of implementation, create an execution plan and then code</li>
</ul>

<p>These rituals have helped me get better at programming with time and in parallel, I pick at max 3 and act on the action items. Programming is simple but being better than most is difficult. Doing it consistently makes one get better by the day.</p>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/better-programmer</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821485</guid>
            <pubDate>Mon, 13 Jul 2020 15:03:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Income/savings calculator for moving to Canada]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23821323">thread link</a>) | @senecaso
<br/>
July 13, 2020 | https://boomstick.games/northward/index.html | <a href="https://web.archive.org/web/*/https://boomstick.games/northward/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://boomstick.games/northward/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821323</guid>
            <pubDate>Mon, 13 Jul 2020 14:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling to Assembly from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23821305">thread link</a>) | @halst
<br/>
July 13, 2020 | https://keleshev.com/compiling-to-assembly-from-scratch | <a href="https://web.archive.org/web/*/https://keleshev.com/compiling-to-assembly-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        

<p><span id="home"><a title="Home" href="https://keleshev.com/">☰</a></span></p>



<!--



md5-79bfa919c595b8f7aa78f6d429bc2a15


-->

<center><img id="cover" src="https://keleshev.com/compiling-to-assembly-from-scratch.jpg" width="200" height="300"></center>

<center><p> <a href="https://transactions.sendowl.com/products/78310234/604B9EF1/purchase" rel="nofollow"> Pre-order •  <b>$27</b> </a></p></center>

<center><em>TypeScript — ARM  — August 2020</em></center>

<p><big><em>So, you’ve been trying to learn how compilers and programming languages work?</em> </big></p>

<p>Perhaps, you’ve learned about compiling to JavaScript,
or about building an interpreter? Or, maybe, about
compiling to bytecode? All good steps.</p>

<p><em>But there’s a tension building up.</em></p>

<p>Because it feels a bit like cheating.
Because you know that somewhere, somehow, the code you write
is translated to assembly instructions. To the machine language.
That’s where the rubber hits the road. That’s where it gets hot.
And, oh-so-many resources are hesitant to cover this part.
But not this book.</p>

<p>This ebook will show you in detail
how you can build a compiler from scratch
that goes all the way from <em>source</em> to <em>assembly</em>.</p>

<p>The example code is written in <strong>TypeScript</strong>, a dialect of <strong>JavaScript</strong>.
The book describes the design and implementation of a compiler that emits
32-bit <strong>ARM</strong> assembly instructions.</p>



<blockquote>
  <h2>Pre-order and get a draft!</h2>
  
  
  
  <p><strong><em>You get now:</em></strong></p>
  
  <ul>
  <li>Draft <em>(contains full Part I of the book)</em></li>
  <li>PDF-only</li>
  <li>DRM-free</li>
  <li>Source code <em>(link in the book)</em></li>
  <li>Discourse forum: book’s private community <em>(invite in the book)</em></li>
  </ul>
  
  <p><strong><em>You get later</em></strong> <em>(ETA–August 2020)<strong></strong></em><strong><em>:</em></strong></p>
  
  <ul>
  <li>Complete book</li>
  <li>All future revisions</li>
  <li>PDF, EPUB <em>(other formats on request)</em></li>
  <li>DRM-free</li>
  </ul>
  
  <p><em>Note, $27 is pre-order–only price with 40% discount. When the book is out it will be $45.</em>
  <br></p>
</blockquote>



<h2>Why ARM?</h2>

<p>In many ways, the ARM instruction set is what makes this book possible.</p>

<p>Compared to Intel x86-64, the ARM instruction set is a work of art.</p>

<p>Intel x86-64 is the result of evolution from an 8-bit processor,
to a 16-bit one, then to a 32-bit one, and finally to a 64-bit one.
At each step of the evolution, it accumulated complexity and cruft.
At each step, it tried to satisfy conflicting requirements.</p>

<ul>
<li>Intel x86-64 is based on <em>Complex Instruction Set Architecture</em> (CISC),
which was initially optimized for writing assembly by hand.</li>
<li>ARM, on the other hand, is based on <em>Reduced Instruction Set Architecture</em> (RISC),
which is optimized for writing compilers.</li>
</ul>

<p><em>Guess which one is an easier target for a compiler?</em></p>

<p>If this book targeted Intel x86-64 instead of ARM, it would have been two times as long
and — more likely — never written.
Also, with 160 <em>billion</em> devices shipped, we better get used to the fact
that ARM is the dominant instruction set architecture today.</p>

<p>In other words… ARM is a good start.
After learning it, you will be better equipped
for moving to x86-64 or the new ARM64.</p>

<p><em>Will you be able to run the code your compiler produces?</em></p>

<p>I bet you will! The Appendix will contain a bazillion ways
to execute ARM code, starting from Raspberry Pi,
cloud VM, to various ways to emulate ARM on Linux, Windows, and macOS.</p>

<h2>Why TypeScript?</h2>

<p>First of all, you will be able to follow this book in any reasonable programming language.
For me, it was tough to pick one for this job, and I’m pleased I’ve chosen TypeScript.</p>

<p>TypeScript is probably nobody’s favorite, but it’s a good compromise:</p>

<ul>
<li>Are you coming from a dynamic language like JavaScript, Python, or Ruby?
Then if you close your eyes at the
type annotations, TypeScript is just modern-day JavaScript.</li>
<li>If you’re coming from Java or C#, then you will feel right at home,
since TypeScript
is brought to you by the same people who brought you C# <em>(and Turbo Pascal!)</em>.</li>
</ul>

<p>Don’t worry if you’ve never seen TypeScript code before.
If you can read the following, you will most likely be able to pick it up,
as the book goes <em>(real code from the book here!)</em>:</p>

<pre><b>class </b>Label {
  <b>static </b>counter = 0;
  value: number; <em>// Type annotation
</em>
  <b>constructor</b>() {
    <b>this</b>.value = Label.counter++;
  }

  toString() {
    <b>return </b>'.L' + <b>this</b>.value;
  }
}
</pre>

<p>I avoided using any TypeScript- or JavaScript-specific
language features in the code.</p>

<p>If you’re into statically-typed functional programming
languages (Haskell, OCaml, or Reason ML),
you will find that the class structure I used
has a nice translation to an algebraic data type.
It is, in fact, how I wrote it first.</p>



<h2>Book Contents</h2>

<p>The book consists of two parts. Part I
presents a <em>detailed</em>, <em>step-by-step</em> guide on how
to develop a small “baseline” compiler that can compile simple
programs to ARM assembly.</p>

<p>By the end of Part I, you will have a working compiler that can
compile simple functions like this one:</p>

<!--table>
<tr>
<td>


md5-73395652867122248e3299aa94c98c61


</td>
<td>
</td>
</tr>
</table-->

<pre><b>function </b>factorial(n) {
  <b>if </b>(n == 0) {
    <b>return </b>1;
  } <b>else </b>{
    <b>return </b>n * factorial(n - 1);
  }
}
</pre>

<p>Into ARM assembly code like this:</p>

<pre>.global factorial
factorial:
  <b>push </b>{fp, lr}
  <b>mov </b>fp, sp
  <b>push </b>{r0, r1}
  <b>ldr </b>r0, =0
  <b>push </b>{r0, ip}
  <b>ldr </b>r0, [fp, #-8]
  <b>pop </b>{r1, ip}
  <b>cmp </b>r0, r1
  <b>moveq </b>r0, #1
  <b>movne </b>r0, #0
  <b>cmp </b>r0, #0
  <b>beq </b>.L1
  <b>ldr </b>r0, =1
  <b>b </b>.L2
.L1:
  <b>ldr </b>r0, =1
  <b>mov </b>r1, r0
  <b>ldr </b>r0, [fp, #-8]
  <b>sub </b>r0, r0, r1
  <b>bl </b>factorial
  <b>mov </b>r1, r0
  <b>ldr </b>r0, [fp, #-8]
  <b>mul </b>r0, r0, r1
.L2:
  <b>mov </b>sp, fp
  <b>pop </b>{fp, pc}
</pre>

<p>This code won’t win any awards, and an optimizing compiler
could do much better, but it’s a start!</p>

<p>Part II talks about <em>more advanced</em> topics in <em>less details</em>.
It explores several different (often mutually exclusive)
directions in which you can take your compiler.</p>

<center>⁂</center>

<center><a id="excerpt" href="https://keleshev.com/excerpt-compiling-to-assembly-from-scratch.pdf"><img id="excerpt" src="https://keleshev.com/book-preview.png" width="400" height="300"></a></center>

<center><a href="https://keleshev.com/excerpt-compiling-to-assembly-from-scratch.pdf"> Read Excerpt </a></center>

<center><img src="https://keleshev.com/keleshev.jpg" width="200" height="200"></center>

<h2>About me</h2>

<p>My name is Vladimir Keleshev,
I have worked with compilers both commercially
and in open-source.
My fondness of ARM assembly stems from
my previous work in embedded systems.
Currently, I work in finance
with domain-specific languages.
I’m <a href="https://twitter.com/keleshev">@keleshev</a> on Twitter.</p>



<blockquote>
  <h2>Be the first to know when the book is finalized!</h2>
  
  <center>Reading a draft is not your style? I get it. Subscribe to be notified when the book is finalized (and related news about the book and compilers).</center>
  
  <center><a href="https://sellfy.com/p/bkz0pv/" id="bkz0pv" data-text="Pre-order"></a></center>
  
  
  
  <center><small>You can unsubscribe at any time</small></center>
</blockquote>

<!--


md5-7ee03ea5643bff2df00890120280d45e



When I write blog posts I usually spent the first half
of the time writing the code and develoing the idea, and
the second half on the prose.
This book will be no exception.

At the moment I have finished writing
the code, and I am very happy with the results.
I expect the book to be ready early summer 2020, and a draft to
be available even sooner.

-->



<center><img src="https://keleshev.com/dragon.png" width="256" height="260"></center>

<center><em>Illustrations by <a href="https://twitter.com/PbKatiuska">@PbKatiuska</a></em></center>

    

</div>]]>
            </description>
            <link>https://keleshev.com/compiling-to-assembly-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821305</guid>
            <pubDate>Mon, 13 Jul 2020 14:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I made $11,673 in 5 days with an open-source project]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23821220">thread link</a>) | @samuelstancl
<br/>
July 13, 2020 | https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/ | <a href="https://web.archive.org/web/*/https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div v-pre="">
            <p>At the end of June, I launched a business-focused extension to my open-source project. <a href="https://tenancyforlaravel.com/saas-boilerplate/">The multi-tenant SaaS boilerplate for Laravel</a>.</p>

<p>The sales completely exceeded my expectations.</p>

<p>$4,980 within the first 24 hours and $11,673 within the first 5 days.</p>

<p>🤯</p>

<p>Here’s the story leading to this.</p>

<h2>Story of the project</h2>

<p>Exactly 2 years ago (June 2018), I was 16 and I decided to start building my first SaaS application. It was meant to be an e-commerce platform focused on B2B sales.</p>

<p>After working on the project for 9 months, I needed to implement <a href="https://www.indiehackers.com/post/what-is-multi-tenancy-why-you-might-need-it-8a0d64f161">multi-tenancy</a>. I looked at the existing solutions (Laravel packages) and they all felt extremely confusing and complex.</p>

<p>I decided to do the naive thing and write my own package. See, I wasn’t very experienced with Laravel at this point. I’ve only been using it since around July 2018. And this was at the beginning of 2019.</p>

<p>The main thing that I disliked about the existing solutions was that they pretty much required that you rebuild your entire application around their package.</p>

<p>That felt horrifying to me — again, I wasn’t a very experienced developer.</p>

<p>I felt like there should be a solution that just works with an existing application. The basic idea of multi-tenancy is letting customers have separate databases. Why would I have to rewrite my entire application for this? Why can’t I just tell the app to use database X after identifying the customer?</p>

<h3>Version 1</h3>

<p>I released v1 of the package in February. It was limited in features, but it fulfilled my needs. I didn’t have to rewrite my app anymore.</p>

<p>The package didn’t get much traction at this point.</p>

<p><img src="https://samuelstancl.me/assets/img/tenancy-stars-v1.png" alt="The star count for version 1"></p>

<p>On February 17, it got the first star on GitHub. 3 months later, it only had 60 stars.</p>

<p>And my SaaS wasn’t succeeding either. I decided to abandon the project basically immediately after I wrote the multi-tenancy package. I realized how bad the code was. The product market fit was there, but I didn’t want to work on this codebase anymore.</p>

<p>I started some other projects instead. They of course got abandoned too, after a few months. Such is the life of SaaS.</p>

<h3>Version 2</h3>

<p>In July, I decided to double down on the package. I started working on version 2. It added a lot more features and made it less proof-of-concept-y and more production ready. Fulfilled more business needs.</p>

<p>In August, I created a landing page for the project. I started <strong>treating it more as a product</strong>.</p>

<p><img src="https://i0.wp.com/wp.laravel-news.com/wp-content/uploads/2019/10/stancl-tenancy.jpg?fit=2220%2C1125&amp;ssl=1?resize=2200%2C1125" alt="The first landing page">
<small>The first landing page.</small></p>

<p>By the end of August, the project had some 216 stars.</p>

<p>I doubled down on the marketing side of things, got some articles written and by the end of October, the project was at 476 stars.</p>

<h3>Burnout</h3>

<p>At this point, I took a hiatus from the project. I was juggling multiple projects at once and was starting to get severely burnt out.</p>

<p>For the following two months, I got basically zero work done. On any projects. This was the darkest time for me, work and focus-wise.</p>

<p>There’s a positive side to it, though. Experiencing a strong burnout for a manageable period of time is good — if you analyze it well. Teaches you what <strong>not</strong> to do and how much it sucks to be burnt out. After an experience like that, you’ll focus very hard on not getting burnt out.</p>

<p><img src="https://builtwithtailwind.s3.amazonaws.com/237/conversions/tenancy.samuelstancl.me_-featured.jpg" alt="The second landing page">
<small>I finished this period of focusing on the package with a second, better-designed landing page.</small></p>

<h3>The lockdown</h3>

<p>The coronavirus pandemic was a blessing in disguise when it comes to side projects.</p>

<p>Instead of school, I got to stay at home.</p>

<p>In the past few months I didn’t do much work. So working now was actually refreshing!</p>

<p>The timing really couldn’t have been any better. School got closed first week of March. About 2 weeks after I could (and did) legally get my sole proprietor license.</p>

<p>I took on a bit of client work, started making a bit of $ from that, but mostly <strong>I again focused on the package</strong>.</p>

<p>There were some quirks I didn’t like about the architecture of the code. I also didn’t like that the package was making an impression of being too opinionated and not enterprise™ enough.</p>

<p>So I focused on fixing exactly that.</p>

<p>I contacted a person who was interested in me adding some more enterprise-y features back in October. I explained that I’m focusing on the package again and that I’d like to add a lot of things to it.</p>

<p>He was very glad to hear this. We talked for a while and he offered <strong>sponsoring me to add specific features to the open-source package</strong>:</p>

<blockquote>
  <p>Let me know if €5,000 is a good price for you.</p>
</blockquote>

<p>This was huge.</p>

<p>See, the project was released in February 2019. And there were <strong>no donations whatsoever</strong> until October.</p>

<p><img src="https://docs.google.com/spreadsheets/d/e/2PACX-1vSJCo55YgQmuVaJCuyfsKmSs23UIemGD3g198A5fvYhSQeMdzBI7NA7z9NEx0VwbNSEYdj_N4uZEsBx/pubchart?oid=1707722928&amp;format=image" alt="Donations between launch (February 2019 and March 2020)"></p>

<p>And even until March, the donations totaled $111.</p>

<p>5,000 EUR felt massive.</p>

<p>This was at the end of April.</p>

<p>I accepted the offer, expressed great gratitude and got to work.</p>

<p>I decided to focus <strong>FULLY</strong> on the package.</p>

<p>I was writing code and documentation all <strike>days</strike> nights long. Quarantine did its thing on my sleep schedule, but I was happy. Got a ton of work done.</p>

<p>Woke up at 16:00, went to bed at 8:00. Every day.</p>

<p>On May 13th (about 2-3 weeks after the donation) I announced a closed beta.</p>

<p>Why closed? Continue reading.</p>

<h3>Competition</h3>

<p>Like I said, there were other packages.</p>

<p>The project that made me create my own package also had a sister package. It was in development for seemingly forever.</p>

<p>However, in May, Spatie — a web development agency that’s very famous in the Laravel world for their open-source work — started writing their own multi-tenancy package.</p>

<p>This made the other project hurry development too. So in May, these packages were being released:</p>

<ul>
<li>My package’s version 3</li>
<li>Spatie’s new package</li>
<li>tenancy.dev’s new package</li>
</ul>

<p>This got stressful fast.</p>

<p>The Spatie package was built on the same principles as my package. Automatic, no changes needed. Except it was a lot simpler version.</p>

<p>That was no good!</p>

<p>Also remember when I said that I was trying to focus my package more on the enterprise-y needs, like flexibility? That’s what the tenancy.dev package is about, to a large degree.</p>

<p>Hence the closed beta. I ain’t showing no code to competition!</p>

<p><img src="https://samuelstancl.me/assets/img/tenancy-stars-comparison.svg" alt="Comparison of GitHub stars between the packages">
<small>The evolution of GitHub stars — <span>blue</span> is my package, <span>green</span> is the older competing package, <span>yellow</span> is Spatie's new package.</small></p>

<h3>The boilerplate</h3>

<p>With the beta done, it was time to focus on the commercial product.</p>

<p>The idea was this: Even though the package does all the heavy lifting for you, you still need to implement it. And many apps will implement it in the same way.</p>

<p>So there was a place for another project. A boilerplate with all the stuff you’d be writing anyway. This means customer (tenant) onboarding flow, billing logic, an admin panel, domain management, customer HTTPS certificate management etc.</p>

<p>And it also fit perfectly into my beta. I had a beta that I wanted users to test. I also wanted to build an app that would use the package. This would make me see all the missing parts, from the perspective of a <strong>user</strong> of the package.</p>

<p>This took about a month of half-work to build.</p>

<p>Why half-work? Motivation was slowly disappearing, the beta &amp; new marketing website was out, so competition was sort of taken care of. Also a bunch of personal stuff happening.</p>

<h2>The launch</h2>

<p>I was on a family vacation in Southern Europe. I originally wanted to finish all my work before going there, but you know how IT projects are.</p>

<p>I spent the first week doing fun stuff — working out, walking, reading, listening to audiobooks and podcasts.</p>

<p>But after a week of spending my time completely differently than I normally do, I decided to finish the work. So, I spent 3 days inside the apartment. There was no time to go outside, I <strong>had</strong> to finish this.</p>

<p>I was finishing the package’s features alongside the boilerplate.</p>

<p>The package was ready for release. And so was the boilerplate.</p>

<p>This was at <strong>3 AM in the morning</strong>. I was severely overworked and it was time to write an announcement.</p>

<p>I didn’t have enough energy to send an email, do a Twitter thread, make a launch discount or any of the other stuff. Nor did I have the confidence in my abilities to do it well at 3 AM.</p>

<p>But I was glad I managed to get the marketing site done! In some form anyway.</p>

<p>So I went with a <strong>safer approach</strong>. I announced the release on my Discord server. This way only a small portion of my users saw it and if anything was wrong, I’d manage to extinguish the fire before it got too big.</p>

<p>So I made an announcement and went to bed. I didn’t expect much. I actually <strong>don’t know</strong> what I expected.</p>

<p>But I can say that <strong>waking up to $600 in sales surprised me</strong>.</p>

<p>I woke up, went to the bathroom, and went straight to the computer. Inviting people who bought the project to the private community (no automated process — gotta do that MVP!). Improving the marketing page.</p>

<p>Then I got to scheduling a <a href="https://twitter.com/samuelstancl/status/1277920614670577672">Twitter thread</a> on Hypefury and writing a marketing email on Mailchimp.</p>

<p>Then both went out.</p>

<p>And the sales started coming in.</p>

<p>A lot of them.</p>

<p>A <strong>LOT</strong> of them.</p>

<p>My inbox quickly got filled with tens of emails with the subject line of:</p>

<blockquote>
  <p>New sale of Multi-tenant SaaS boilerplate for Laravel - Standard version</p>
</blockquote>

<p><img src="https://i.imgur.com/SaBSah1.png" alt="https://i.imgur.com/SaBSah1.png"></p>

<p>I was incredibly happy.</p>

<p>The first day concluded with a bit over $5000 in sales.</p>

<h2>The selling process</h2>

<p>The product was sold in two tiers. Standard and Enterprise.</p>

<p>The difference between the two versions was that the Enterprise version got priority support and could be used by companies with an annual revenue of $60k and higher. This is the same model <a href="http://nova.laravel.com/">Laravel Nova</a> uses.</p>

<p>I launched the product with <strong>two launch discounts</strong>.</p>

<p>A “generic” one, that I haven’t yet decided when it will end.</p>

<p>And a better one, that <strong>only lasted the first 48 hours</strong>.</p>

<p>The prices were:</p>

<ul>
<li>Standard: $299 -&gt; $199 (generic) -&gt; <strong>$149 (48 hour)</strong></li>
<li>Enterprise: $499 -&gt; $379 (generic) -&gt; <strong>$349 (48 hour)</strong></li>
</ul>

<p>I think given the sales, I hit the nail on the head with the pricing.</p>

<p>It was pretty affordable for solo projects, while also being high enough for the enterprise version.</p>

<p>My project is in this strange space where there are one-man indie hacker projects on one side of the income spectrum, and huge enterprises on the other side of the spectrum. Very little in between.</p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/">https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/</a></em></p>]]>
            </description>
            <link>https://samuelstancl.me/blog/how-i-made-11k-in-5-days-with-an-open-source-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821220</guid>
            <pubDate>Mon, 13 Jul 2020 14:38:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create custom ReactJS hooks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821212">thread link</a>) | @PetraIgnjatovic
<br/>
July 13, 2020 | https://www.bornfight.com/blog/how-to-create-custom-reactjs-hooks/ | <a href="https://web.archive.org/web/*/https://www.bornfight.com/blog/how-to-create-custom-reactjs-hooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<div>

<h3>Quite some time has passed since we introduced hooks in the codebase of our projects. Because of them, it has made the code reusable, cleaner, more readable and more satisfying to write. </h3>
<p>Hooks present the future of development with ReactJs — that is for sure.</p>
<p>Other than the basic hooks provided by the library itself, you can also write your own little hook (or a big one)! Those kinds of hooks are named Custom hooks. Taken straight from the React docs — a custom Hook is a JavaScript function whose name starts with <strong>”use”</strong> and that may call other Hooks. </p>
<p><strong>In this little how-to, I will be showing how you can do just that! (…and with TypeScript too).</strong></p>
<h4>A state hook (counter custom hook)</h4>
<p>In this example, I’ll show you how to implement a simple counter custom hook. Internally, it uses React’s <strong>useState</strong> and returns it along with a couple of other functions inside an object. The returned object is written with shorthand property names syntax.</p>
<pre>const useCount = () =&gt; {
  const [count, setCount] = useState&lt;number&gt;(0);

  const increment = () =&gt; setCount(count + 1);
  const decrement = () =&gt; setCount(count - 1);
  const increaseBy = (increaser: number) =&gt; setCount(count + increaser);
  const decreaseBy = (decreaser: number) =&gt; setCount(count + decreaser);

  return { count, increment, decrement, increaseBy, decreaseBy };
};</pre>
<p><strong>Now, this hook can be used anywhere within a function component. Here’s an example:</strong></p>
<pre>const { count, increment, decrement, increaseBy, decreaseBy } = useCount();
&lt;div&gt;
     &lt;div&gt;{count}&lt;/div&gt;
     &lt;button onClick={increment}&gt;increment&lt;/button&gt;
     &lt;button onClick={decrement}&gt;decrement&lt;/button&gt;
     &lt;button onClick={() =&gt; increaseBy(20)}&gt;increase by 20&lt;/button&gt;
     &lt;button onClick={() =&gt; decreaseBy(20)}&gt;decrease by 20&lt;/button&gt;
&lt;/div&gt;</pre>
<h4>A useEffect hook (custom fetch hook)</h4>
<p>This example will show how you can use <strong>useEffect</strong> inside a custom hook. By using something like this, you could improve your fetch… or you can write a custom hook if you add a ton of event handlers!</p>
<pre>const useFetch = (requestUrl: string) =&gt; {
  // set your fetch data and error types instead of any
  const [data, setData] = useState&lt;any&gt;(null);
  const [error, setError] = useState&lt;any&gt;(null);
const [isLoading, setIsLoading] = useState&lt;boolean&gt;(true);

  React.useEffect(() =&gt; {
      const fetchData = async () =&gt; {
      setIsLoading(true);
      try {
          const response = await fetch(`${requestUrl}`);
          const json = await response.json();
          setData(json);
      } catch (err) {
          setError(err);
      }
      setIsLoading(false);
    };
  }, [requestUrl]);

  return { data, error, isLoading };
};</pre>
<p>UseEffect custom hooks can be really viable and useful. Check out this <a href="https://codesandbox.io/s/kx83n7201o?file=/src/use-why-did-you-update.js" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">useWhyDidYouUpdate</a> hook, originally from <a href="https://twitter.com/brunolemos/status/1090377532845801473" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Bruno Lemos</a>.</p>
<h4>Will you start using JS hooks?</h4>
<p>As you can see from these small and compact examples, these hooks are plentifully useful. And the best thing about them is that they are super reusable even throughout different projects. If you create an awesome hook, you can use it in any future project!</p>
<p>On top of that, any hook desired, needed or thought of can be created. If you see a repeating pattern in your code which is using state or reacts to a certain event, you can easily put it in a custom hook.</p>
<p><strong>Here are a couple of references to great hooks others have made, so check it out if you’re interested in learning more:<br></strong>• <a aria-label="undefined (opens in a new tab)" href="https://usehooks.com/" target="_blank" rel="noreferrer noopener">usehooks.com</a><br>• <a aria-label="undefined (opens in a new tab)" href="https://github.com/rehooks/awesome-react-hooks" target="_blank" rel="noreferrer noopener">Awesome React hooks</a></p>
<p>_____<br><strong>We’re available for partnerships and open for new projects.<br><a rel="noreferrer noopener" href="https://bornfight.com/contact/" target="_blank">If you have an idea you’d like to discuss, share it with our team!</a></strong></p>
</div>
</div>
</section></div>]]>
            </description>
            <link>https://www.bornfight.com/blog/how-to-create-custom-reactjs-hooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821212</guid>
            <pubDate>Mon, 13 Jul 2020 14:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are not prisoners of groupthink]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23821180">thread link</a>) | @henriquez
<br/>
July 13, 2020 | https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html | <a href="https://web.archive.org/web/*/https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <h2>
            <a href="https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">
                We are not prisoners of groupthink.
            </a>
        </h2>
        <h3>How I stopped worrying about "cancel culture" with this one weird tip.</h3>
        
        <p><em>This is a response to the Gareth Roberts essay titled
<a href="https://unherd.com/2020/07/why-the-prisoner-is-more-accurate-than-orwell/">"We are all prisoners of groupthink".</a></em></p>
<p>A common theme on the Internet is selection bias. We seek out content and
interactions that fit our sensibilities, beliefs and emotional disposition.
Social networks have exploited this tendency, drawing us into
<a href="https://en.wikipedia.org/wiki/Filter_bubble">filter bubbles</a> where we are
algorithmically bombarded with content designed to maximize our "engagement"
with no regard to damage done in terms of our psychological well-being or
intellectual isolation. This makes us better consumers, but reinforces
divisions between individuals and poisons any possibility of meaningful
discourse, instead favoring shit-flinging competitions between so-called
<a href="https://twitter.com/realdonaldtrump/status/1261126114799468549?lang=en">"keyboard warriors."</a>
This is well-documented, the social media companies are aware of it,
and they don't care because <a href="https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499">division makes money.</a></p>
<p>Our filter bubbles are designed to comfort and placate us while we're force-fed
promoted content and offers and idealized imagery. Our collective ability
to think critically has been siphoned away; anything that remotely challenges
our beliefs is seen as a threat or an attack. Over time this has lead to the
ridiculous notion that "words are violence," and from this, the rise of
<a href="https://en.wikipedia.org/wiki/Online_shaming#Call-outs_and_cancellation">cancel culture</a>,
the First World pastime of mobbing, doxing, and socially destroying
anyone who dares to voice an unpopular opinion or do something stupid. This cancel
culture was born of social media. Sure, some might blame other factors like liberal
arts education but really they're nothing new to society. But I'll tell you what changed.</p>

        
            
<p>Back in the good old days (when you didn't need 32gb of
memory to browse the web), Twitter and Facebook used to display a chronological
feed of your friends' posts. This was very functional, but ended up creating a problem
for the social media companies: in order to maximize the amount of time you spend on
their sites they needed you to friend/follow tons of people (even people you aren't really
friends with). But if you did that, your feed would turn into a shitshow, with too
much content for any person keep up with. So Facebook and Twitter went back to the
drawing board and came up with a fantastic innovation: the algorithmic content feed
(aka. the death of society and end of the Internet). The feed algorithm could "get
into your head" with <a href="https://en.wikipedia.org/wiki/Psychographics">psychographic microtargeting</a>,
allowing the machine to recommend content and advertisements that <em>you</em> are likely to
"engage" with—click, like, share,
anything to keep you on the site and viewing more ads a little longer.</p>
<p>The deprecation of the chronological timeline in favor of the
machine-curated content feed had major psychological side effects for everyone involved.
When the machine decided what content to recommend it would favor content that is most
likely to create engagement; this trends toward content that creates an emotional
response, which on the Internet is most often outrageous content that evokes fear or
anger. By bombarding people with upsetting shit and exposing them to "communities" of other
people <a href="https://knowyourmeme.com/memes/circle-jerk">circlejerking</a> about how upsetting
everything is, the machine dialed the filter
bubble effect up to 11, essentially dividing people into groups and then radicalizing
them with increasingly extremist content. And in the process,
<strong>Facebook and Twitter radicalized the actual publishers of content.</strong></p>
<p>Remember when you could pick up a newspaper or turn on
your television and get news coverage that seemed at least superficially factual
and unbiased? Obviously those days are gone. Newspapers are mostly out of business,
TV viewership is down, and the dying husk of our mainstream media is increasingly
obsessed with a contrived "culture war." Traditional media has been superceded by
the Internet, and with social media dominating peoples' time spent on
the Internet, Facebook and Twitter have become gatekeepers between the
publishers and their viewers. Factual and unbiased reporting is simply not engaging
enough and will not appear on peoples' feeds. Only breathless hyperbolic
fear-mongering and rage porn will break through the algorithm and get clicks.
Mainstream publishers have been forced to shift their entire media strategies
around <em>online engagement</em> as they desperately attempt to stay relevant on the Internet.
And what's more engaging than a controversy? Thus,
mainstream publishers have "picked sides" that resonate with their
audiences'
filter bubbles in the artifical culture war, promoting non-newsworthy events
into manufactured controversies, and sparking mob action with headlines like
<a href="https://www.cnn.com/2020/07/11/us/goya-foods-unanue-trump-hispanic-market/index.html">"Here's why [food CEO's] meeting with [world leader] is prObLeMaTiC."</a></p>
<p>And that brings us to recent months, where
after locking every person of fighting age in closet-sized apartments, where peoples' only
access to the outside world was filtered through the toxic lens of social media, and
where the only information available was underpinned by fear and outrage, people
lost their shit. And now we're collectively hand-wringing about cancel culture (but
being real careful not to upset the mob.)</p>
<p>But here's the thing: cancel culture is irrelevant if you don't give a fuck.
You are not a prisoner of groupthink. You might be a prisoner of your belief
that you should give a fuck. But that is under your control. We are not living
a George Orwell hellscape, memes like
<em>"<a href="https://en.wikipedia.org/wiki/Nineteen_Eighty-Four">1984</a> was a warning, not
an instruction manual"</em> fall flat. The premise that we should care what a bunch
of larpy wannabe do-gooders think on Twitter and Facebook is false.
It doesn't matter—you can't lose a game you don't play. Cancel culture was born
of social media. <strong>If we cancel Facebook and Twitter</strong>, we can break the cycle of
extreme division and hyperbolic microtargeting, shatter the filter bubbles,
and reclaim our access to information from monopolistic ad targeting algorithms.
By divorcing our attention from these toxic echo chambers, manufactured controversies
will become less profitable,
people will be able to think more critically and talk to each other more sincerely,
and cancel culture will end organically. There are really no major drawbacks.</p>
<p>So much of our time online is <em>wasted</em> creating, curating, and "defending"
these perfectly plastic personas, avatars, idealized identities that represent
some vague notion of a persistent sense of self on the Internet. And for what?
Do you really talk to your 600 Facebook friends? Do you even give a shit about
who your 10,000 Instagram followers are? Do they give a shit about you? No.
People waste so much of their lives trying to stake out an online identity that
they start to believe it actually matters, <em>but it doesn't.</em>
<strong>A persistent online identity is a liability, not an asset.</strong></p>
<p>We are all tempted by the lie that social networks base their existence on:
that we need to put our "selves" online for all to see. This lie is a mental hack,
exploiting our human need for meaningful interactions with other people,
as well as the dark aspects of human nature: ego, anger and trauma. As society
increasingly isolates and divides humans from one another physically and
socially, we are tempted by the lie that our online personas form a meaningful
extension of our real-world selves.</p>
<p>Sadly, the vast majority of our interactions on social media are hollow, and the
few glimmers of meaningful connections with others that <em>do</em> occur
instill a Pavlovian-style hope, an addictive draw to keep us infinitely scrolling
through our algorithmically-curated content feeds in the vain hope that the
machine will bring meaning to the emptiness of our lives. But social media is little more
than mental masturbation. The service is free but the price we pay is dear.</p>
<p>When you put your real self online, you open yourself up to attack.
Like a federal indictment, the mob can come for anyone at any time. Whether or
not you are a good person is irrelevant, and trying to craft your online persona
to appease the mob is a loser's game. As the filter bubbles increasingly divide-and-circlejerk
people into more extreme viewpoints, what passes for acceptable
behavior today could be heresy tomorrow. And when your name, your employer, and
your family are all connected to your social media presence, you put yourself in
real world danger for very little real world benefit.</p>
<p>So what can you do? <strong>Cancel yourself.</strong> Delete your social media presence.
Sever the link between your online self and your real-world self. Seriously.
<em>You can't lose a game you don't play.</em></p>
<p>But wait, <em>isn't this extreme?</em> Maybe it is, or maybe you're just addicted to
social media. I've talked to a lot of people about this and heard some common
excuses people use to rationalize addictive behavior to themselves.</p>
<ul>
<li><strong>"But social media is an important part of my professional network."</strong></li>
</ul>
<p>I can only speak anecdotally. I've built a successful career without using LinkedIn
or other social networks to promote myself. My work ethic, skill and reputation have
carried me
as far as I care to go in my field. Also anecdotally, when I hired a contractor
to remodel my basement, I didn't check her Facebook page; I saw her work at a
neighbor's house and asked them to put me in touch. She did a great job on
my basement (and later posted photos of it to her Instagram). Good work
promotes itself.</p>
<p>But what doesn't work is when the line between personal and professional gets
blurred, which is almost inevitable on a medium designed around social
interaction. The tension between <em>being a professional</em> and <em>having an opinion</em> is
overwhelming for some people. The person who lists in their Twitter bio that
they "work for Google" and "bash the fash" isn't doing themself or their employer
any favors. Such tact only works for those who stay in the good graces of the mob,
which is, again, a loser's game.</p>
<ul>
<li><strong>"But I use social media to keep in touch with my school friends."</strong></li>
</ul>
<p>No you …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html">https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html</a></em></p>]]>
            </description>
            <link>https://www.obsessivefacts.com/blog/2020-07-10-we-are-not-prisoners-of-groupthink.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821180</guid>
            <pubDate>Mon, 13 Jul 2020 14:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Be More Unlikeable]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 70 (<a href="https://news.ycombinator.com/item?id=23821121">thread link</a>) | @elijahmurray
<br/>
July 13, 2020 | https://www.gritlist.co/be-unlikeable/ | <a href="https://web.archive.org/web/*/https://www.gritlist.co/be-unlikeable/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            


                <section>
                    <div>
                        <blockquote>"The reasonable man adapts himself to the world; the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man." - George Bernard Shaw</blockquote><p>I grew up in a family where I was taught to be likable. To please, to impress, and to make others happy. Seems like a pretty good idea, right?</p><p>While likeability is a good trait if you want to be popular it isn't ideal if you want to achieve. Let me explain.</p><p>Popularity feels good. Being liked feels good. Humans evolved as social creatures and we crave attention from each other. This pattern plays out over and over in schoolyards, bars, and workplaces, or anywhere humans meet. And the cooperation needed for our survival can only happen if you're accepted by your tribe.</p><p>However, praise by the masses won't make you successful, let alone fulfilled. Actually it's more likely that <em>popularity will prevent you from being successful.</em></p><p>Movie stars, professional athletes, and a business visionaries–we all want to be them. We grow up trying to be them. Personally, I've long idolized Steve Jobs and Elon Musk. But most of our heroes got to where they are by being unlikeable, not likable.</p><p>We love these men and women for being unique yet we internally berate ourselves for being different. These heroes have been described as annoying, difficult, stubborn, and unreasonable. Not exactly what we strive to read about ourselves in peer reviews. Sure, they have some popularity, but it's not all rainbows. Was Gandhi liked? Yes, but he also had millions of people who were against him, and ultimately murdered him. So if it's the oddballs that we look up to, why do we try to be so likable?</p><p>This aversion to difference starts early. Bullies throughout life pick on the kid who is different, on the easy target. Additionally modern culture has decided that the best path in life is to do as you're told; follow the rules, stay in line, and smile. Follow the leader and be a good girl/boy. The scripture of conformity is pervasive.</p><p>And there is true merit to fitting in. Society can't exist without collectively agreed upon rules. Early on we learn that being a three year old hellion is unacceptable has consequences. If I spit out my Cheerios one more time mom will be angry mom, so I'm going to be nice.</p><p>So we're taught to fit in. Be likable and hide your "flaws". Like the only white fish in a school of black fish you don't want to be the different one when a shark is on the prowl. Blend in and don't stand out. Seek group acceptance.</p><p>While conformity has its place in keeping society running, too much conformity stunts progress.</p><p>Differences are what make you, you and me, me. They're what make change possible. Change comes from differences, not from more of the same. After all, a species evolves based on small aberrations, on "flaws", that turn into strengths and a better way of being.</p><p>All progress comes from those who see the world differently. First they act differently and then they convince others to see differently as well. They don't accept the status quo and they don't assimilate.</p><p>Generally speaking this results in being unpopular. Many of the people who helped change the world aren't liked even in the height of their success. But they kept pushing their indomitable will against the world, and eventually, the world shifted ever so slightly.</p><p>Practice being unreasonable this week. Don't "yes" your way through life, following someone else's path for you. Be a bit more of a jerk. Be more demanding. Piss a few people off.</p><p>And be okay with it. Be okay with people being angry or mad or annoyed with you. Cultivate your ability to keep pushing towards your goals despite what others say.</p><p>And who knows, maybe you'll see the world shift ever so slightly.</p>
                    </div>
                </section>



        </article></div>]]>
            </description>
            <link>https://www.gritlist.co/be-unlikeable/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821121</guid>
            <pubDate>Mon, 13 Jul 2020 14:28:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A/B capital for cloud infrastructure and enterprise software]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23821049">thread link</a>) | @ekhornung
<br/>
July 13, 2020 | https://upside.fm/saurabh-sharma-jump-capital/ | <a href="https://web.archive.org/web/*/https://upside.fm/saurabh-sharma-jump-capital/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="target-id5f0fc631733a6"><p>Saurabh Sharma 0:00<br> All of us come from all varying backgrounds. And I would say that DNA kind of flows in somewhat automatically. You want to roll up your sleeves even to help the companies to the extent they need, right. We’re not enforcing this. And I would say that combined with I would say, yeah, to some extent, and midwest primarily them in building these businesses. I do think that differentiates.</p><p>Jay Clouse 0:20<br> The startup investment landscape is changing. and world class companies are being built outside of Silicon Valley. We find them, talk with them and discuss the upside of investing in them. Welcome to Upside.</p><p>Hello, hello. Hello, and welcome back to the upside podcast, the first podcast finding upside outside of Silicon Valley. I’m Jay Clouse, and I’m accompanied by my co host, mister money mustache himself Eric Hornung.</p><p>Eric Hornung 1:00<br> Unfortunately, Jay, maybe you can’t see it through this pop filter, but the mustache is no longer.</p><p>Jay Clouse 1:06<br> It’s a little stubbly.</p><p>Eric Hornung 1:08<br> Yeah, it’s a little stubbly it’s, it’s my, it’ll be my first full shave. Since I got rid of the mustache. I did the first two months of quarantine with the beard and the mustache. I was doing my best Jay Clouse. And then I said, You know what, I’m just not a beard guy. It’s not. It’s itchy. It’s, um, I think I’ve described it previously on the podcast as pube.</p><p>Jay Clouse 1:32<br> And I cringe every time you say the word pube on the podcast.</p><p>Eric Hornung 1:34<br> Yeah, it’s I’ve probably said it too many times on the podcast, I would say, yeah, once you get rid of once you get rid of the beard, and you’re looking yourself in the mirror and you say, Can I pull this off? If I walk out of this bathroom? Will my fiance kill me? And you just go for it. It’s a magical moment. Jay. When there’s a there’s a shriek and then an acceptance of this is who I am now. I’m a moustache guy.</p><p>Jay Clouse 1:59<br> You sent me the photo and I was like, Oh, I’m so glad that you shaved it in this order and took the time to get a photo of this before it’s gone. And then it stuck around six weeks.</p><p>Eric Hornung 2:09<br> Yeah.</p><p>Jay Clouse 2:10<br> Was it really there for six weeks?</p><p>Eric Hornung 2:11<br> It might have been five weeks but yeah, something like that.</p><p>Jay Clouse 2:13<br> Wow. And and Colleen was okay with it.</p><p>Eric Hornung 2:17<br> I think she liked it better than the beard.</p><p>Jay Clouse 2:20<br> Wow.</p><p>Eric Hornung 2:21<br> Yeah. So it was a nice mustache. I won’t lie we got trimmed it up. I gave it a little bit of love. It’s just you know it the mustache life is tough, Jay because you drink a little bit of milk. Yeah, mustache in your milk, milk in your mustache. Whatever is it.</p><p>Jay Clouse 2:34<br> I actually don’t experience many of the mustache pains myself because my mustache is the weakest part of my beard.</p><p>Eric Hornung 2:39<br> Hmm.</p><p>Jay Clouse 2:40<br> So yeah, I go on enumerate on the number of moose mustache problems.</p><p>Eric Hornung 2:45<br> Yeah, yeah, very eating a hot wing with a mustache. You got hot wing for the next four hours because it’s not leaving your mustache. Anyway, yeah. So the mustache the whole That whole that whole phases is behind me, Jay, but it lives on in memoriam.</p><p>Jay Clouse 3:05<br> Well, I’m glad that you made the jump into not only trying the beard but trying a mustache. And speaking of jump, today we are talking with Saurabh Sharma. He is a partner at Jump Capital, a thesis led sector focused and operating centric venture capital firm specializing in series A and B in growth stage investments, Jump Capital invest in data driven technology companies within the FinTech, B2B SaaS, IT data infrastructure and media sectors. They’re based in both Chicago and New York. Eric, how do we find them capital,</p><p>Eric Hornung 3:43<br> I got connected with Jump Capital, indirectly, I think two years ago, maybe it was via Twitter or via an email or something. And so I don’t exactly remember how it happened. But I’ve been in contact via email with a few of the partners there just because I really like the way that they are structured and set up and what they focus on. And they’re very explicit about what they do, which I find to be refreshing in the venture capital space. And we wanted to have a conversation with them. And you know, we got to have one today.</p><p>Jay Clouse 4:13<br> Jump Capital has invested in a previous Pod Co Balto, they’ve invested in Personal Capital, just to name a couple of companies that you’ve heard of also Lisnr in Cincinnati. He talked about them being explicit and what they actually invest in. They also say on their website that they invest $1 to $10 million in their first investment, when companies have a $1 to $5 million revenue run rate. And typically, less than $10 million of investment so far today, so yeah, very explicit on their website in terms of industry, what types of companies are looking for, even at what stage? You know, the investment, the investment terms are?</p><p>Eric Hornung 4:51<br> Yeah, they have a operating partner model which is much more like private equity than it is a lot of the venture capital firms. We talked to the platform model almost. So when you’re very specific about the types of companies that you’re going to invest in, I think that operating model becomes stronger because you can get the best people to do the specific thing that needs to be done in these four focus areas in that very specific space where its product market fit has been met and it is growth time.</p><p>Jay Clouse 5:21<br> All right. Well, we’d love to hear your thoughts on this episode with Saurabh as we go through, you can tweet at us @UpsideFM or email us Hello@upside.FM. And we’ll get into that interview right after this. This episode of upside is sponsored by Tresta. Tresta is an app for iPhone and Android that lets you do business calling and texting from anywhere with no hardware. Just a smartphone you’re already using. Tresta is the best business phone app on the market. Whether you’re a founder or freelancer, just starting your business or you’re already established. Growing your network and your business is all about communication. You’ve got to be available no matter where you are. Tresta offers the call management features that empower you to communicate smarter and more efficiently, like auto attendance, call recording, user groups and more. And you don’t need any special equipment, just the smartphone you’re already using. Tresta is easy to configure. So you can set everything up yourself all online. Tresta’s virtual phone system makes it easier and more affordable than ever to set up a fully functioning mobile office. It’s just $15 per user per month with no contract. So start your free 30 day trial today at www.tresta.com/upside. That’s www.tresta.com/upside. Saurabh welcome to the show.</p><p>Saurabh Sharma 6:08<br> Thank you folks. Great to be here.</p><p>Eric Hornung 6:47<br> Let’s take it on a rocket ship. How did you get to Jump Capital.</p><p>Saurabh Sharma 6:51<br> Yeah, I mean it’s a kind of an unconventional path. I don’t think I was looking misery your venture capitalist. From a career perspective. I think it’s a three organic way down. Journey has been a little bit all over the place, which I think bodes well to venture frankly, just kind of amalgamation of a bunch of things. But you know, I’m fundamentally I’m an engineer by training and science, grew up in India in engineering there, got a scholarship to Apollo undergrad in France. Finish that became a computer science researcher in France, in the National Research Labs, got an opportunity to come to my masters and possibly a PhD at Cornell, where they’re in just kind of got brainwashed of Academia, by Wall Street, being brothers and all the banks that just go to campus and hire quantum computer science guys, so I just finished my Master’s in Cornell, join Lehman Quanta Algo trading desk was there, you know, the hay days and just perfect time as they’re even open to await the peak of Lehman. And so you know, phenomenal times, obviously, ranging from fairly very large scale architectures for competition trading in New York, London, and some phenomenal desks in the Ritz trading. Bring meeting go face. Solid tobacco was there almost to the end not exactly to the end I had an opportunity to apply for business schools which I had been pushing off and I thought really good time. After 07, there are some signs they might be weaker and then I got my admit I got took some time off and moved to India back to this small snippet of equity for business school, but I didn’t know it was gonna go up. It kind of blew up premier the first week I started my business school in Chicago booths. So the next year was kind of experimenting, starting my own company a bunch of my friends. And then you know, I’m preparing to started doing them for them and post that went back to Wall Street a little bit works on capitals with Bob Lehman at the time realized probably wasn’t for me back Michael was the chief quite a bit to join early stage uncle life Bank of Chicago Southern by April kowski Radke local mountain nurse in the region funded that a startup that I was involved in earlier. And then it allowed us to spend some time with light bank, Eric ended up being the Groupon CEO asked me to come along during some times to kind of turn around the story. And so another kind of run at pretty phenomenal setup of interesting projects of turning around the business. I was involved in an internal data science team run mobile relevant strategy, and then Mary Barra fashion conference in New York. So running operations and marketing for that, for that business in an intersection folks a jump and it was kind of good amalgamation a jump, as we will talk about more it has some relevance to so creating groups, very computational focus. So that can all put it together. You know, I’m actually in background I’ve been venture, I’ve been in tech and to join the joint jump for about four and a half years ago. So again, somewhat unconventional but but took me multiple paths. But I think all that is super …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://upside.fm/saurabh-sharma-jump-capital/">https://upside.fm/saurabh-sharma-jump-capital/</a></em></p>]]>
            </description>
            <link>https://upside.fm/saurabh-sharma-jump-capital/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821049</guid>
            <pubDate>Mon, 13 Jul 2020 14:21:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debunking the Myth of 10% Brain Usage]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23821046">thread link</a>) | @iuliangulea
<br/>
July 13, 2020 | https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>The human brain is a marvel of biological engineering. It allowed us to accumulate and pass on the knowledge of many prior generations throughout millennia, resulting in a civilization that went into space, taught computers to see and speak, and that continually discovers and investigates the laws of the Universe.</p>
<p>Its complexity is astounding, and we do not fully understand it yet. And because of that, occasionally, myths about the functioning of the brain pop out. Among the most prominent such legends is the one that claims we are dormant geniuses. But before analyzing and debunking that, let’s discuss some brain facts.</p>
<h2 id="size-does-not-matter">Size Does Not Matter</h2>
<p>For instance, did you know that the brain weighs around 1300-1400 grams? It represents only 2% of the total body weight of a 150 pound or 70kg human. However, it requires:</p>
<ul>
<li>15% of total cardiac output (the blood that flows in our body);</li>
<li>20% of total body oxygen;</li>
<li>25% of total body glucose utilization</li>
</ul>
<p><img src="https://iuliangulea.com/images/brain-energy-consumption.png" alt="Human brain weight vs. energy consumption"></p>
<p>That is quite an energy-hungry organ inside our skull! But even that fades away when comparing to children: at around five years old, the human brain takes up as much as 50% of oxygen consumption<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>Surprisingly, the brain’s level of oxygen consumption does not significantly vary when you are resting vs. when you do some cognitively intense work. Overall, measures of the whole brain changes in blood flow during intense mental activity have failed to demonstrate any change. Even <em>local changes</em> in blood flow of the regions involved most in a cognitive task are often 5% or less.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>Conversely, it is well known and demonstrated that glucose is the brain’s “fuel,” therefore increases in blood glucose levels can positively impact cognitive performance in some tasks.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<h2 id="the-mystical-brain-myth">The Mystical Brain Myth</h2>
<p>There is a popular myth that we use our brains at only 10% of its capacity, thus boldly affirming that we have a whopping 90% of dormant potential that we can awaken and become geniuses.</p>
<p>Unlike other widespread myths that started from a single event, or unscientific claims from poorly designed research studies (e.g., <a href="https://en.wikipedia.org/wiki/Andrew_Wakefield">Andrew Wakefield</a> and his fraudulent study than falsely claimed a link between vaccines and autism), the myth that humans use only 10% of their brains started at the end of the nineteenth century and was gradually strengthened by many people since then. The <a href="https://en.wikipedia.org/wiki/Ten_percent_of_the_brain_myth#Origin">Wikipedia</a> article on the subject has a lengthy explanation of the potential origin and evolution of the myth throughout the years.</p>
<h3 id="a-small-confession">A Small Confession</h3>
<p>Before moving on, I have a revelation to make. Occasionally, I might buy a cloth item and wear it once or twice. If I recall correctly, there might have been one or two items in my experience that I have not worn at all. Do you know anyone with similar oddities?</p>
<p>This makes my wardrobe much like the brain described in the myth: I am using around 10% of it, and I can “tap into” the rest of my wardrobe should such need arise.</p>
<h3 id="your-brain-is-not-a-wardrobe">Your Brain Is Not A Wardrobe</h3>
<p>But our brain is not a collection of cloth items. Though there are still unanswered questions regarding some brain functions, brain mapping physiology demonstrates that all its areas have a purpose. And you do not have to be a neuroscientist to prove that, simply recall from your anatomy classes that the brain has different regions, such as the frontal lobe, occipital lobe, cerebellum, and the fact that each of those lobes has its role.</p>
<h2 id="debunking-the-myth">Debunking The Myth</h2>
<p>Let’s address that myth in a more scientific manner.</p>
<p>If we are using only 10% of our brains, that means a person would be fine if the other 90% of the brain got removed. 10% of the 1400g average brain is 140g—that’s the size of a sheep’s brain.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Since I doubt sheep have their own 90% hidden potential myth, it makes no sense that humans have advanced so far as a civilization by using only part of their brains equivalent in size to a sheep’s brain.</p>
<p>There are instances in history when people were injured and got parts of their brain removed (although not as close as even 10%), the most prominent (and among the first recorded ones) being the case of <a href="https://en.wikipedia.org/wiki/Phineas_Gage">Phineas Gage</a>, who survived an accident where a large iron rod was driven through his left part of the head, from the bottom of the cheek, through his left eye and frontal lobe all the way to the top of his head. He lived 12 years more after that accident. There are varying opinions on his recovery, but it took him ~10 years to recover from the unfortunate event.</p>
<p>Another example is the case of <a href="https://en.wikipedia.org/wiki/Lev_Zasetsky">Lev Zasetsky</a>. A bullet entered his left parieto-occipital area and resulted in a long coma. Following this, he became unable to perceive the right side of things. Objects he did see often appeared as fragmented pieces rather than whole objects. He did not recover in the 50 years he lived after the injury.</p>
<p>As mentioned in <a href="https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">How People Learn—The Brain Basics</a>, our brains can rewire through a process called <em>neuroplasticity,</em> which can help regain some of the lost functions as a result of an accident. Unfortunately, that is not always the case. Researchers have found that only 27% of people recover from a <em><strong>concussion.</strong></em><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> That means almost 3 out of 4 people do not fully recover! And this is “just” a concussion—your brain does not lose any of its parts.</p>
<p>If 90% of the brain were unnecessary, it is highly unlikely that we would not have evolved such big brains with irrelevant matter in the first place. There are several factors for that:</p>
<ul>
<li>Historical risk of childbirth deaths due to the big skull size would stress out the selection of offspring with smaller brain sizes.</li>
<li>Natural selection favors characteristics that offer an advantage of some sort over the other. There is no way such a big brain would have formed in the first place if it wouldn’t be necessary for survival.</li>
<li>As already mentioned, the brain requires an enormous amount of energy. Even if we had 90% of the brain unused and suddenly were to “wake” it, we couldn’t provide our brains with enough power, as it already consumes 20%-25% of the entire body resources.</li>
</ul>
<p>All this scientific evidence works against this myth. We indeed use only some areas of the brain at any given time, but throughout the day, we use all of it, not just 10%. And next time you hear about this myth, recall the sheep brain weight.</p>
<hr>
<p>If you liked this article, feel free to subscribe below to be among the first to receive future updates and follow me on twitter (<a href="https://twitter.com/iuliangulea">@iuliangulea</a>) as well.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Kennedy C, Sokoloff L. <a href="https://pubmed.ncbi.nlm.nih.gov/13449166/">An adaptation of the nitrous oxide method to the study of the cerebral circulation in children; normal values for cerebral blood flow and cerebral metabolic rate in childhood.</a> J. Clin. Invest. 1957;36:1130–1137. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>The Effect Of Mental Arithmetic On Cerebral Circulation And Metabolism by Sokoloff L., Mangold, R., Wechsler, R., Kennedy, C. &amp; Kety, S. S. (1955) <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Rachael T. Donohoe, David Benton—<a href="https://www.researchgate.net/profile/David_Benton/publication/12840251_Cognitive_functioning_is_susceptible_to_the_level_of_blood_glucose/links/5489df990cf225bf669c75e5.pdf">Cognitive functioning is susceptible to the level of blood glucose</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Differences Between Human And Sheep Brains—<a href="https://animals.mom.com/differences-between-human-and-sheep-brains-3500869.html">animals.mom.com</a> <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://www.braininjuryaustralia.org.au/research-recovery-concussion/">How Many Make A Full Recovery From A Concussion?</a>—BrainInjuryAustralia.org.au <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    
    
        
    

</div></div>]]>
            </description>
            <link>https://iuliangulea.com/blog/debunking-the-myth-of-ten-percent-brain-usage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23821046</guid>
            <pubDate>Mon, 13 Jul 2020 14:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SWR – Data Fetching for React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820970">thread link</a>) | @arunoda
<br/>
July 13, 2020 | https://getstarted.sh/with/swr | <a href="https://web.archive.org/web/*/https://getstarted.sh/with/swr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>How do you fetch and manage data in a React app?</p><p>You could try using <a target="_blank" href="https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API">fetch</a> directly and work with built-in React hooks like <span>useEffect</span>.</p><p>Then what if you want to:</p><p>📋 cache data between components
<br>🌎 sync data between browsers
<br>🔄 check for new updates
<br>💨 add optimistic UI support</p><p>Then you have to add more custom logic to handle these cases.</p><p>What if there's a library that does all of these(and more) for you. That's <a target="_blank" href="https://swr.vercel.app/">SWR</a>.
</p><p>Have a look at the following example. That's what we are building in this lesson.</p><div id="container"><p>Play Now</p><p><img src="https://img.youtube.com/vi/n3h19yvLOS0/maxresdefault.jpg" width="100%"></p></div></div></div></div>]]>
            </description>
            <link>https://getstarted.sh/with/swr</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820970</guid>
            <pubDate>Mon, 13 Jul 2020 14:12:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a DIY Pen Plotter: MidTbot]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820926">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Earlier this year, I built a DIY pen plotter (mostly) from scratch. I'd been
meaning to post a build log, because this was one of the more enjoyable hardware
projects I've worked on recently. However, it's taken a while to write-up this
project because, well,
<a href="https://benjamincongdon.me/blog/2020/03/24/March-Updates/">there was a lot of stuff going on</a>.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter_hu26049e58bcb0e8f71afc8b124b2c5223_266932_0x400_resize_q75_box.jpg" alt="Completed Plotter with Ruler for Scale"> </a><figcaption>
        <p>Completed Plotter with Ruler for Scale</p>
    </figcaption>
    </figure>

<h2 id="why-build-a-plotter">Why Build a Plotter?</h2>
<p>So, why is it worth building a pen plotter? The short answer is, “they're cool”.
The longer answer is that, despite commercial printers (ink jet, laser, etc.)
working better for general purpose printing, the quality of a pen-plotted image
is noticeably different than something that's been traditionally printed.
Plotted images can have a more natural, organic feeling to them, because they're
produced by raising and lowering a pen manually, like a human does.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>I've also had a persistent curiosity with
<a href="https://benjamincongdon.me/blog/2019/03/07/Generative-Doodling/">generative art</a>. Much of the community
built around generative art (colloquially,
<a href="https://twitter.com/hashtag/plottertwitter">#plottertwitter</a>) uses pen plotters
to turn “bits into atoms”. While most folks opt to buy a commercial plotter like
the <a href="https://axidraw.com/">Axidraw</a> or restore vintage plotters from the 1980's,
there's a growing community of people building their own plotters.</p>
<h2 id="assembling-the-components">Assembling the Components</h2>
<p>The first step in the project was collecting the bill of materials (BOM).
There's a well-researched BOM on the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/Docs/mechanical_BOM.md">project Github</a>.
Other than the midTbot PCB, which is for sale
<a href="https://www.tindie.com/products/33366583/midtbot-esp32-v2-controller-kit/">on Tindie</a>,
I had to order:</p>
<ul>
<li>Linear shafts and Linear Bearings (Amazon)</li>
<li>Pulleys and Idler Pulleys (Amazon)</li>
<li>Rubber Timing Belt (Amazon)</li>
<li>2 Stepper Motors (Amazon)</li>
<li>Stepper Motor Controllers (Amazon)</li>
<li>12V 3A Power Supply (Already had one)</li>
<li>Basic Hobby Servo Motor (Already had one from previous Arduino projects)</li>
<li>Assorted M3/M5 Head Screws (Home Depot, Ali Express)</li>
</ul>
<p>I was pleasantly surprised how available most of the parts were online –
everything except for the screws/nuts were available on Amazon.</p>
<p>Once I received my midTbot PCB, there was some soldering and assembly to do. I
followed
<a href="https://github.com/bdring/midTbot_esp32/wiki/Controller-Kit-Assembly-Instructions">these instructions</a>
to attach the homing switches, power supply, and header pins to the board.</p>
<h3 id="printing-the-chassis">Printing the Chassis</h3>
<p>The chassis of the midTbot is entirely 3D printed. There are ~7 things that you
need to print
(<a href="https://github.com/bdring/midTbot_esp32/tree/master/STL">source files</a> on
Github), and they're all fairly simple shapes, so the prints were easy to do.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/completed_print_hu632932bafc371cef54c7ef30f19a742b_135778_0x400_resize_q75_box.jpg" alt="Completed prints of the &amp;lsquo;feet&amp;rsquo; and tailblock pieces"> </a><figcaption>
        <p>Completed prints of the ‘feet’ and tailblock pieces</p>
    </figcaption>
    </figure>

<p>The hardest thing to print (and the most finicky part of the project in general)
was the
<a href="https://github.com/bdring/midTbot_esp32/blob/master/STL/midt_esp32_pen_mnt.stl">pen mount</a>.
This piece has some overhangs on it, so it was important to configure the
printer to add support material.</p>
<h2 id="assembly">Assembly</h2>
<p>With the PCB assembled, mechanical parts purchased, and chassis pieces printed,
it was time to do the final assembly. Again, I followed the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Assembly-Instructions">assembly instructions</a>
on the project Github.</p>
<p>The assembly process was straightforward: the PCB gets screwed into one of the
printed pieces, the pulleys and linear rods get screwed in to the “feet” and
carriage block pieces, and the stepper motors are secured to the chassis with
the PCB “sandwiched” in between the chassis and the motors.</p>
<p>One difficult step was attaching the stepper motors to the PCB. Per the project
instructions, you're supposed to solder the stepper motor wires into plastic
<a href="https://en.wikipedia.org/wiki/Pin_header">pin sockets</a>, so you can easily
detach the motors from the PCB. But, after I tried and failed several times to
solder the stepper motors into the female socket block, I simply soldered the
female sockets to the board directly and soldered the stepper motor wires onto
solid-core jumper wires. The end result wasn't as clean as what's shown in the
project instructions, but still allowed me to hot-swap the motors if needed.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/electronics_hu69d27adac9c276a7c142cb42ce695fc5_460646_0x400_resize_q75_box.jpg" alt="Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)"> </a><figcaption>
        <p>Controller (Bottom Left), Motor Drivers (Top Left), Stepper Motors (Right)</p>
    </figcaption>
    </figure>

<p>Once the main “chunk” of the plotter was assembled (pictured above), the only
things left to do were to thread the timing belt around the pulleys, and attach
both ends of the belt to the pen head with a small amount of tension.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/full_plotter2_hubcee09c1499dfeaed0cdedbd52521e35_510199_0x400_resize_q75_box.jpg" alt="Belt Attach Points (circled)"> </a><figcaption>
        <p>Belt Attach Points (circled)</p>
    </figcaption>
    </figure>

<p>The last step in assembly (and, unfortunately the most fiddly part of the whole
process) was attaching the pen holder to the “head” block. The long screw that
makes the joint between the pen holder and “head” block needs to be tuned
meticulously: If the screw is too tight, then the pen can get stuck in the “up”
position – not returning to the “down” position when the servo retracts. On the
other hand, if the screw is too loose, then this translates to “slop” in the
pen's position, which results in wiggly drawings that are unusable.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/servo_hu041824ca24038cc947b7d5fa7334f321_403811_0x400_resize_q75_box.jpg" alt="Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)"> </a><figcaption>
        <p>Pen Lift Servo Mechanism, Joint Screw/Nut (Arrow)</p>
    </figcaption>
    </figure>

<p>At this point, the bot was assembled! I powered it on and installed a specific
version of the <a href="https://github.com/bdring/Grbl_Esp32">Grbl_Esp32</a> firmware
designed for the midTbot per the
<a href="https://github.com/bdring/midTbot_esp32/wiki/Compiling-Firmware-for-the-MidTBot">project instructions</a>.
Grbl_Esp32 is a really nifty piece of software: it allows you to upload an run
Gcode (basically, machine readable instructions for how to move the pen) on the
plotter's Esp32 controller. Since the Esp32 has built-in wifi (and bluetooth),
its able to serve a basic web UI:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui.png">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/webui_hu659f08144d7f460a1e53d6a3f50b9a17_60893_0x400_resize_box_2.png" alt="Grbl_Esp32 Web UI"> </a><figcaption>
        <p>Grbl_Esp32 Web UI
            <a href="https://github.com/luc-github/ESP3D-WEBUI">Source: Github</a></p>
    </figcaption>
    </figure>

<p>The Web UI is sufficient for most tasks: homing, minor positioning adjustments,
starting/pausing/resuming prints. There are only a few tasks – like calibration
– that require you to drop down to the Grbl “command line”.</p>
<p>It took me a while to get my midTbot calibrated. The project documentation was a
bit light on the specifics, so there was a lot of trial-and-error and
troubleshooting.</p>
<h2 id="plotting-software">Plotting, Software</h2>
<p>Now that I had a functioning plotter bot, the next thing to do was try it out.
Of course, to do so you need to actually produce Gcode that the bot can use.
There are tons of tools to do this – and a full discussion of Gcode/plotter
software is worth a whole other post. Suffice it to say, there are a variety of
resources on the <a href="https://drawingbots.net/knowledge/tools">Drawing Bots</a>
community page that serve as a good starting point.</p>
<p>I spent most of my time working with <a href="https://inkscape.org/">Inkscape</a>‘s
Gcodetools plugin. Axidraw (which makes a commercial pen plotter) also has some
useful
<a href="https://wiki.evilmadscientist.com/Axidraw_Software_Installation">Inkscape plugins</a>,
although some of the functionality won't work with the midTbot. Gcodetools
nominally allows you to translate SVGs to Gcode, however this is a tedious
process. <em>Not just any</em> SVG will work well with it; the SVG basically already
needs to be a line drawing for Gcodetools to have any hope of working correctly.
It has basic support for infilled regions too, but again you have to be careful
with it – any slight hiccup, and it produces unusable Gcode.</p>
<p>To be honest, the software aspect of pen plotting is the most frustrating part
of the workflow. I haven't yet found a great toolchain for the “art” -&gt; Gcode
pipeline, so there's a lot of finicky steps. (It doesn't help that Inkscape is a
second-class X11 app on macOS…)</p>
<h2 id="additional-hardware-modifications">Additional Hardware Modifications</h2>
<p>After I ordered a midTbot PCB, the creator added me to a Slack group. Some of
the other folks who'd built midTbots contributed back modifications they'd made
to their builds. I took a couple of these and added them to my bot too:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/pen_mount_hu1f2dbe1c25aab483c480e60644105b8f_437548_0x400_resize_q75_box.jpg" alt="Magnetic Pen Mount with Thumb Screw"> </a><figcaption>
        <p>Magnetic Pen Mount with Thumb Screw</p>
    </figcaption>
    </figure>

<p>First, I ordered heftier thumb screws for the pen attachment (as pictured); the
screws in the original BOM are tricky to manipulate by hand. Second, I printed a
magnetic detachable pen holder (as pictured) which makes it easier to add/remove
pens without disturbing the rest of the setup. If you want to do multicolor
prints, this modification is a must. Finally, I printed wider supports for the
bots frame. Supposedly, this allows you to increase the available print size of
the bot (if you also order longer linear rods). I didn't get around to actually
increasing my bot's print size, but the wider supports made the bot more stable,
and easier to attach to a work table.</p>
<h2 id="results">Results</h2>
<p>After an afternoon of calibrating the bot and installing the mods I discussed
above, I got some prints that I'm pretty happy with.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/triangle_hu7abfc5bba89b65ef467a92e89d404d38_647220_0x400_resize_q75_box.jpg" alt="SierpiÅ„ski triangle"> </a><figcaption>
        <p><a href="https://en.wikipedia.org/wiki/Sierpi%C5%84ski_triangle">SierpiÅ„ski triangle</a></p>
    </figcaption>
    </figure>

<p>Sierpinski's triangle (above) is a single line, but has a lot of intricate
detail. This is a good exercise of the precision of the stepper motors, which as
you can see is quite good. The precision also requires the pen mount to be
calibrated correctly, so that there isn't any “slop” between the pen and the
body of the plotter.</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/cube_hu4580d2579ea2776d604d9e44b4623042_575462_0x400_resize_q75_box.jpg" alt="Isometric Cube"> </a><figcaption>
        <p>Isometric Cube
            <a href="https://github.com/wblut/isogrid">Source: Github</a></p>
    </figcaption>
    </figure>

<p>This was a slightly harder pattern for the bot to draw. The lines are all
straight, but there are a fair number of pen raises. Generally, the more pen
up/down cycles a print has, the greater the likelihood of failure.</p>
<p>I've also noticed that <em>where</em> the pattern is in the print area of the bot makes
a difference. The closer the pen head is to the main bot chassis, the more the
pen is pulled away from the paper due to the counterweight of the “tail”
section. As such, I tried to position the prints as close to the middle of the
print area as possible. Below is what happens when the pen holder misbehaves:</p>
<figure>
    <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader.jpg">
        
        
        
        
        
        
        <img src="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/space_invader_hu1a98c8f9a4b8a7a0c3eafda2f5f8180d_194935_0x400_resize_q75_box.jpg" alt="Somewhat failed &amp;lsquo;Space Invaders&amp;rsquo; Print (Note the discontinous/missing lines)"> </a><figcaption>
        <p>Somewhat failed ‘Space Invaders’ Print (Note the discontinous/missing lines)
            <a href="https://github.com/abey79/vpype">Source: vpype Example Code</a></p>
    </figcaption>
    </figure>

<p>The plot isn't a complete failure, but many of the lines don't get drawn or only
get partially drawn. This is often caused by the pen mount screw being too
tight, causing the pen …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/">https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</a></em></p>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/07/12/Building-a-DIY-Pen-Plotter-midTbot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820926</guid>
            <pubDate>Mon, 13 Jul 2020 14:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Grok with Elasticsearch to add structure to your data]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820793">thread link</a>) | @alexmarquardt
<br/>
July 13, 2020 | https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/ | <a href="https://web.archive.org/web/*/https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div id="primary">
	<main id="main" role="main">
		
<article id="post-1351" class="page">
	<!-- .entry-header -->

	
	<div>
		<p>July 13, 2020</p><p>As well as being a search engine, Elasticsearch is also a <a href="https://www.elastic.co/blog/intro-to-aggregations">powerful analytics engine</a>. However in order to take full advantage of the near-real-time analytics capabilities of Elasticsearch, it is often useful to add structure to your data <em>as it is ingested</em> into Elasticsearch. The reasons for this are explained very well in the <a href="https://www.elastic.co/blog/schema-on-write-vs-schema-on-read">schema on write vs. schema on read</a> article, and for the remainder of this blog, when I talk about structuring data, I am referring to <em>schema on write</em>.</p>

<p>Because of the importance of structuring your data, in this blog I will show you how to add structure to unstructured documents by using an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/ingest.html">ingest node</a> with the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok Processor</a>. Then, I will describe a simple method to construct new Grok patterns, and a method that can be used to debug errors in existing Grok patterns. Finally I will provide links to some publicly available Grok patterns and then briefly mention the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/dissect-processor.html">Dissect Processor</a> as a possible alternative to Grok.</p>

<p>As a side note, if you are going to put in the effort to structure your data, you should consider structuring your data so that it conforms to the <a href="https://www.elastic.co/blog/introducing-the-elastic-common-schema">Elastic Common Schema</a>, which will facilitate the analysis of data from diverse sources.</p>



<p>It is not uncommon to see documents sent to Elasticsearch that are similar to the following.:</p>

<pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre>

<p>The message field in the above document contains unstructured data. It is a series of words and numbers that are not suitable for near-real-time analytics. In order to take full advantage of the powerful analytics capabilities of Elasticsearch, we should parse the message field to extract relevant data. For example, we could extract the following fields from the above message:</p>

<pre>"host.ip": "55.3.244.1"&nbsp;<br>"http.request.method": "GET"<br>"url.original": "/index.html"<br>"http.request.bytes": 15824<br>"event.duration": 0.043</pre>

<p>Adding such a structure will allow you to unleash the full power of Elasticsearch on your data.</p>



<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok</a> is a tool that can be used to extract structured data out of a given text field within a document. You define a field to extract data from, as well as the Grok pattern for the match. Grok sits on top of <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a>. However, unlike regular expressions, Grok patterns are made up of <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">reusable patterns</a>, which can themselves be composed of other Grok patterns.&nbsp;</p>

<p>Before going into details of how to build and debug your own Grok patterns, we first give a quick overview of what a Grok pattern looks like, how it can be used in an ingest pipeline, and how it can be simulated. Don’t worry if you don’t fully understand the details of the Grok expression yet, as these details will be discussed in-depth in the following sections of this blog.</p>

<p>In the previous section we presented an example document that looks as follows:</p><pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p><br>The desired structure can extracted from this example message field by using the following Grok expression:</p>

<pre>%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}</pre>

<p>And we define a pipeline which contains this Grok pattern inside a Grok processor.</p>

<pre>PUT _ingest/pipeline/example_grok_pipeline<br>{<br>  "description": "A simple example of using Grok",<br>  "processors": [<br>    {<br>      "grok": {<br>        "field": "message",<br>        "patterns": [<br>          "%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}"<br>        ]<br>      }<br>    }<br>  ]<br>}</pre>

<p>We can then <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/simulate-pipeline-api.html">simulate the above pipeline</a> with the following command.</p>

<pre>POST _ingest/pipeline/example_grok_pipeline/_simulate<br>{<br>  "docs": [<br>    {<br>      "_source": {<br>        "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>      }<br>    }<br>  ]<br>}</pre>

<p>Which responds with a structured document that looks as follows:&nbsp;</p>

<pre>{<br>  "docs" : [<br>    {<br>      "doc" : {<br>        "_index" : "_index",<br>        "_type" : "_doc",<br>        "_id" : "_id",<br>        "_source" : {<br>          "host" : {<br>            "ip" : "55.3.244.1"<br>          },<br>          "http" : {<br>            "request" : {<br>              "method" : "GET",<br>              "bytes" : 15824<br>            }<br>          },<br>          "message" : "55.3.244.1 GET /index.html 15824 0.043 other stuff",<br>          "event" : {<br>            "duration" : 0.043<br>          },<br>          "url" : {<br>            "original" : "/index.html"<br>          }<br>        },<br>        "_ingest" : {<br>          "timestamp" : "2020-06-24T22:41:47.153985Z"<br>        }<br>      }<br>    }<br>  ]<br>}</pre><p><br>This document contains the original unstructured&nbsp; message field, and it also contains all of the additional fields which have been extracted from the message. We now have a document that contains structured data!</p>



<p>In the above example we <em>simulated</em> execution of an <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/pipeline.html">ingest pipeline</a> that contains our Grok pattern, but didn’t actually run it on any real documents. An ingest pipeline is designed to process documents at ingest time, as described in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/ingest.html">ingest node documentation</a>. One way to execute an ingest pipeline is by adding the pipeline name to the <em>PUT</em> command as follows:&nbsp;</p>

<pre>PUT example_index/_doc/1?pipeline=example_grok_pipeline<br>{<br>&nbsp;&nbsp;"message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p>And the document that has been written can be seen by executing:</p><pre>GET example_index/_doc/1</pre><p>Which will respond with the following:</p><pre>{<br>  "_index" : "example_index",<br>  "_type" : "_doc",<br>  "_id" : "1",<br>  "_version" : 2,<br>  "_seq_no" : 2,<br>  "_primary_term" : 1,<br>  "found" : true,<br>  "_source" : {<br>    "host" : {<br>      "ip" : "55.3.244.1"<br>    },<br>    "http" : {<br>      "request" : {<br>        "method" : "GET",<br>        "bytes" : 15824<br>      }<br>    },<br>    "message" : "55.3.244.1 GET /index.html 15824 0.043 other stuff",<br>    "event" : {<br>      "duration" : 0.043<br>    },<br>    "url" : {<br>      "original" : "/index.html"<br>    }<br>  }<br>}</pre><p>Alternatively (and likely preferably), the ingest pipeline can be applied by default to all documents that are written to a given index by adding it to the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/index-modules.html#dynamic-index-settings">index settings</a>:</p>

<pre>PUT example_index/_settings<br>{<br>&nbsp;&nbsp;"index.default_pipeline": "example_grok_pipeline"<br>}</pre>



<p>After adding the pipeline to the settings, any documents that are written to <em>example_index</em> will automatically have the <em>example_grok_pipeline</em> applied to them.&nbsp;</p>

<p>This can be verified by writing a new document to <em>example_index</em> as follows:</p>

<pre>PUT example_index/_doc/2<br>{<br>&nbsp;&nbsp;"message": "66.3.244.1 GET /index.html 500 0.120 new other stuff"<br>} </pre>

<p>And the document that has been written can be seen by executing:</p>

<pre>GET example_index/_doc/2</pre>

<p>Which, as expected will return the document that we just wrote. This document has the new fields that were extracted from the message field:</p>

<pre>{<br>  "_index" : "example_index",<br>  "_type" : "_doc",<br>  "_id" : "2",<br>  "_version" : 3,<br>  "_seq_no" : 2,<br>  "_primary_term" : 1,<br>  "found" : true,<br>  "_source" : {<br>    "host" : {<br>      "ip" : "66.3.244.1"<br>    },<br>    "http" : {<br>      "request" : {<br>        "method" : "GET",<br>        "bytes" : 500<br>      }<br>    },<br>    "message" : "66.3.244.1 GET /index.html 500 0.120 new other stuff",<br>    "event" : {<br>      "duration" : 0.12<br>    },<br>    "url" : {<br>      "original" : "/index.html"<br>    }<br>  }<br>}</pre>



<p>In the previous section, we presented an example document with the following structure:</p><pre>{<br>  "message": "55.3.244.1 GET /index.html 15824 0.043 other stuff"<br>}</pre><p>And we then used the following Grok pattern to extract structured data from the message field:</p>

<pre>"%{IP:host.ip} %{WORD:http.request.method} %{URIPATHPARAM:url.original} %{NUMBER:http.request.bytes:int} %{NUMBER:event.duration:double} %{GREEDYDATA}"</pre>

<p>As described in the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.8/grok-processor.html">Grok Processor documentation</a>, the syntax for Grok patterns comes in three forms: <em>%{SYNTAX:SEMANTIC}, %{SYNTAX}, %{SYNTAX:SEMANTIC:TYPE}</em>, all of which we can see in the above Grok pattern.&nbsp;</p><ul><li>The <em>SYNTAX</em> is the name of the pattern that will match your text. Built-in <em>SYNTAX</em> patterns <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">can be seen on github</a>.</li><li>The <em>SEMANTIC</em> is the name of the field that will store the data that matches the <em>SYNTAX</em> pattern.</li><li>The <em>TYPE</em> is the data type you wish to cast your named field.</li></ul>

<p>The first part of the Grok pattern is the following:</p>

<pre>%{IP:host.ip}</pre>

<p>This declaration matches an IP address (corresponding to the <em>IP</em> Grok pattern) and stores it in a field called <em>host.ip</em>. Four our example data, this will extract a value of <em>55.3.244.1</em> and store it in the <em>host.ip</em> field.</p>

<p>If we want more details on the <em>IP</em> Grok pattern, we can look into the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a>, and we will see the following definition:&nbsp;</p>

<pre>IP (?:%{IPV6}|%{IPV4})</pre>

<p>This means that the <em>IP</em> pattern will match one of the <em>IPV6</em> or <em>IPV4</em> Grok patterns. To understand what the <em>IPV6</em> and <em>IPV4</em> patterns are, once again we can look into the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a> to see their definitions, and so on.&nbsp;</p>

<p>The next part of the Grok pattern is a single whitespace character followed by the following expression:</p>

<pre>%{WORD:http.request.method}</pre>

<p>This portion of the Grok expression extracts the word <em>GET</em> from the <em>message</em>&nbsp;and stores it into the <em>http.request.method</em> field. If we want to understand the definition of the <em>WORD</em> pattern, we can look at the <a href="https://github.com/elastic/elasticsearch/blob/7.8/libs/grok/src/main/resources/patterns/grok-patterns">Grok patterns on Github</a>.&nbsp;</p>

<p>One can do the same kind of analysis to understand the patterns that match the <em>url.original</em>, <em>request.bytes</em> and <em>event.duration</em> fields, which we leave as an exercise for the reader</p>

<p>Finally, the last statement in the Grok pattern is the following:</p>

<pre>%{GREEDYDATA}</pre>

<p>This expression does not have a <em>SEMANTIC</em> part, which means that the matching data is not stored into any field.&nbsp; Additionally, the <em>GREEDYDATA</em> Grok pattern will consume as much text as it can, which means that in our example it will match everything after the <em>event.duration</em> field. The <em>GREEDYDATA</em> expression will come in handy when debugging complex Grok patterns, as discussed in the following sections of this blog.&nbsp;&nbsp;</p>



<p>When constructing a new Grok pattern, it is often easiest to construct the Grok pattern incrementally starting from the left and working towards the right side of the unstructured text that we are trying to match.&nbsp;</p>

<p>Two tools that can be helpful for building and …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/">https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/</a></em></p>]]>
            </description>
            <link>https://alexmarquardt.com/using-grok-with-elasticsearch-to-add-structure-to-your-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820793</guid>
            <pubDate>Mon, 13 Jul 2020 13:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reaching 1K Subscribers in Two Weeks]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820773">thread link</a>) | @marz0
<br/>
July 13, 2020 | https://www.radletters.com/blog/how-blogging-for-devs-reached-1k-subscribers-in-under-2-weeks | <a href="https://web.archive.org/web/*/https://www.radletters.com/blog/how-blogging-for-devs-reached-1k-subscribers-in-under-2-weeks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2><strong>Hi there! Who are you and whatâ€™s your background?</strong></h2>

<p>Hey! My nameâ€™s Monica and I run <a href="https://bloggingfordevs.com/">Blogging for Devs</a>. </p>

<p>As for my background, I learned to code at a super young age (weâ€™re talking single-digits here). I was building websites on my own domain in the late 90s, uploading files with CoffeeCup FTP and coding in Notepad on a Windows 98 machine. Simpler times, eh?</p>

<p>Despite growing up glued to the computer, working in tech was an afterthought for me.</p>

<p>One of the things that surprises people most is that I actually studied Latin and Ancient Greek in University. I also studied French and Japanese. But by the end of my four years, I got burnt out from studying languages and being in school in general.</p>

<p>So converting my student job as a web developer into a full-time role was somehow the path of least resistance. </p>

<p>After 10 years in tech and a cross-continent move from the United States to Germany, I quit my role as the frontend engineering lead at a startup in Berlin to build my own company. For a long time, my goal was â€œnot to have a boss by the time I turn 30â€� and somehow, I managed :)</p>

<p>Today, the company is my main focus. Itâ€™s a conversion-rate optimization tool for affiliate marketers, called <a href="https://affilimate.com/">Affilimate</a>. Apart from that Iâ€™ve got numerous side projects, including my newsletter.</p>

<h2><strong>Whatâ€™s your newsletter about?</strong></h2>

<p>Blogging for Devs teaches developers how to grow their blogs through writing and SEO.</p>

<p>It begins as a free 7-day email challenge to help developers go from concept to keyword research, writing, and distributing an excellent blog post. After completing the challenge, the reader is subscribed to the newsletter.</p>

<p>Every week the newsletter starts with some of my own writing. Sometimes itâ€™s educational, sometimes itâ€™s motivational, but itâ€™s always geared towards trying to help people ACT and take that next step towards creating a successful blog.</p>

<p><img src="https://www.radletters.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBcFFDIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--0bde7b8ae0a51feba66439fe45c3fb1507276381/blogging-for-devs-homepage.png" alt="blogging-for-devs"></p>

<p>In addition, I share and create a variety of resources around blogging in different formats. For example, Iâ€™ve done a screencast on keyword research, an interview with a well-known tech blogger, and written blog posts about launching a newsletter and SEO for Gatsby websites. I also include links to great content created by my subscribers whenever possible.</p>

<p>Itâ€™s a pretty new newsletter so Iâ€™m still experimenting and learning more about what people find most interesting and helpful.</p>

<p>Besides just wanting to help people, I also started the newsletter as a sort of way to get exposure: both that Iâ€™m building Affilimate and establish myself as someone who knows about blogging and SEO. This has worked really well.</p>

<h2><strong>When did you get started writing your newsletter? What motivated you to get started?</strong></h2>

<p>Iâ€™d learned a ton about blogging from building a profitable travel blog over the last few years.</p>

<p>When a number of friends in tech asked me for advice about how to grow their own blogs, it was super fun for me to teach them all the techniques Iâ€™d learned: ranking content in Google, collecting email subscribers, and writing articles people love engaging with.</p>

<p>So it kind of dawned on me that developers as a whole could find the topic interesting, too.</p>

<p>Iâ€™m generally not a competitive person (I prefer to compete with myself), but the desire to get my articles on the first page of Google really drives me to create something 100x better than whatâ€™s out there.</p>

<p>My hypothesis was that developers could actually <em>grow</em> to love blogging and SEO like I did, if only it was explained in a way that appealed to them as developers instead of the typical marketing angle.</p>

<p>It seems my hypothesis was right. After an initial launch at the end of May, over â…” of people who shared feedback on the 7-day challenge mentioned how much they liked the lessons about SEO and keyword research (and that it was way more interesting than they expected!).</p>

<h2><strong>What does the process of writing your newsletter look like for you?</strong></h2>

<p>I keep a backlog of ideas in Asana. Every week I decide on an angle or a theme, and I collect links to interesting news related to blogging in that issue.</p>

<p>For example, last weekâ€™s edition was about â€œHow to Market Yourself (When You Hate Marketing)â€�. I opened with a bit of writing about how developers may hate marketing, but how important it is for their career to become visible and create things in public. Then I also include original resources by myself and others about how to do that.</p>

<p>In total, it takes me about 2-3 hours to write the newsletter and compose it.</p>

<p>I typically write it at a fixed time on Thursday, and then I sleep on it and edit it on Friday before sending it out.</p>

<h2><strong>What are some of the difficulties youâ€™ve encountered in running your newsletter?</strong></h2>

<p>My only real difficulty was when I launched my newsletter, it picked up so many subscribers (I know, an absurd thing to complain about), and my welcome email solicited so many responses, that I was receiving dozens if not over 100 emails per day.</p>

<p>But since everyone wrote me such long, personal emails, I couldnâ€™t feel good about sending canned responses to people.</p>

<p>So I spent <em>hours</em> writing individual responses to everyone who emailed me (as well as replies to replies). It took me several hours a day for about a week to get through them and regain control over my inbox.</p>

<p>Of course, this is a good problem to have. Iâ€™m really grateful that people felt they could share their personal motivations and struggles with me, because it helps me create something that will serve them better.</p>

<h2><strong>Whatâ€™s your favorite part about writing your newsletter?</strong></h2>

<p>Hands down, my favorite part is being able to give advice and see people <em>actually execute it</em>.</p>

<p>Anyone can consume books, blog posts, watch YouTube videos, or whatever.</p>

<p>But what stands out is when I see someone consistently acting on my advice and then showing me the results of doing that.</p>

<p>It motivates me to go further and see how I can help them even more.</p>

<p>Those are the people Iâ€™m writing my newsletter for, because I know that the combination of my experience and their drive will deliver results.</p>

<h2><strong>How do you grow your audience?</strong></h2>

<p>Blogging for Devs recently surpassed 1,500 subscribers after launching it about a month and a half ago.</p>

<p>I did <a href="https://bloggingfordevs.com/launch-a-newsletter/">an analysis</a> of where my subscribers came from, and found that the primary source was Twitter (about 75%) followed by word of mouth.</p>

<p><img src="https://www.radletters.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBcE1DIiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--bd1b72d5fbdc53f3cee30e1e265858b5d1c2ea10/subscriber-chart.png" alt="subscriber-analysis"></p>

<p>Anecdotally, a lot of people write to me and say the newsletter was personally recommended to them, which is a great feeling.</p>

<p>I havenâ€™t done any additional marketing after the initial launch, but my plan is to both promote articles I write on the newsletterâ€™s blog via Twitter and ultimately (of course) to rank some of the articles in Google.</p>

<h2><strong>What are some of your favorite newsletters, books, and podcasts?</strong></h2>

<p>I donâ€™t subscribe to many newsletters (ironic, I suppose?), but one I always enjoy getting in my inbox is <a href="https://marketingexamples.com/">Marketing Examples</a> by Harry Dry. I love how crisp and concise his delivery is. He inspires me to delete unnecessary fluff from everything I write.</p>

<p>As for books, I read mostly product and marketing-focused books these days. My recent favorite is <a href="https://www.amazon.com/dp/B07PPW5V9C">Obviously Awesome</a> (a book about product positioning), and Iâ€™m currently reading <a href="https://www.amazon.com/dp/B00CS5FR62">Predatory Thinking</a> (a series of short stories about out-thinking your competition written by a famous ad exec).</p>

<p>Lately, Iâ€™ve been listening to a lot of <a href="https://www.startupsfortherestofus.com/">Startups for the Rest of Us</a> by Rob Walling. He talks a lot about the reality of building bootstrapped companies, which is highly relevant for me as a founder myself. There are also over 500 episodes so you can really binge on it if thatâ€™s your thing.</p>

<p>For people who write newsletters, I definitely recommend Kate Dosterâ€™s <a href="https://www.katedoster.com/inbox-besties/">Inbox Besties</a>. Her podcast is easily the funniest one I listen to and the episodes are bite-sized.</p>

<h2><strong>What goals do you have for the future?</strong></h2>

<p>My goal is to grow Blogging for Devs to 5,000 subscribers this year. Iâ€™m not sure if thatâ€™s a lot or a little, but itâ€™s my plan! Ultimately, I want to create a community of developers who can help and support each other in their blogging journeys. Iâ€™m just figuring out the right way to go about that right now.</p>

<p>As for me personally, my goal is to build my company to the point where itâ€™s worth acquiring. Still a long way to go before that point :) Iâ€™ve got a lot of other projects and goals for them, but those are secondary to my main focus.</p>

<h2><strong>Where can readers go to learn more about you and your newsletter?</strong></h2>

<p>My newsletterâ€™s website is simply <a href="https://bloggingfordevs.com/">https://bloggingfordevs.com</a>. If people are interested in following along the journey of building the newsletter and my other projects, they can find me on Twitter at <a href="https://twitter.com/monicalent">@monicalent</a>.</p>

    </div></div>]]>
            </description>
            <link>https://www.radletters.com/blog/how-blogging-for-devs-reached-1k-subscribers-in-under-2-weeks</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820773</guid>
            <pubDate>Mon, 13 Jul 2020 13:54:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Danes to sort trash into ten types under new green deal]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820760">thread link</a>) | @jmartinpetersen
<br/>
July 13, 2020 | https://www.thelocal.dk/20200617/danes-to-sort-trash-into-ten-types-under-new-green-deal | <a href="https://web.archive.org/web/*/https://www.thelocal.dk/20200617/danes-to-sort-trash-into-ten-types-under-new-green-deal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://storage.googleapis.com/ddos-shield.appspot.com/shield-logo-mono-darktext.svg" width="250px" height="50px" alt="Project Shield Logo"></p><p>You will be connected to <b>www.thelocal.dk</b> in just a moment...</p><p><a href="https://g.co/shield">Learn about Project Shield</a></p></div></div>]]>
            </description>
            <link>https://www.thelocal.dk/20200617/danes-to-sort-trash-into-ten-types-under-new-green-deal</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820760</guid>
            <pubDate>Mon, 13 Jul 2020 13:54:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple devices are leaking sensitive data over BLE]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23820589">thread link</a>) | @dchest
<br/>
July 13, 2020 | https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/ | <a href="https://web.archive.org/web/*/https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
										
						<p>By <a href="http://perso.citi-lab.fr/gcelosia/">Guillaume Celosia</a> and <a href="https://perso.citi-lab.fr/mcunche/index.html">Mathieu Cunche</a></p>
<h4><a href="https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf"><strong>Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols</strong></a></h4>

<p>We found that Apple devices are leaking sensitive information in the BLE wireless signals they emit. Those issues are associated with the Apple Continuity services and are affecting all Apple devices as well as devices compatible with the Continuity framework. Based on a reverse engineering of Continuity, we identified that the Bluetooth Low Energy (BLE) messages emitted by Apple devices include unencrypted data that can expose sensitive information. We discovered that those data can be easily collected by an eavesdropper and processed in order to: track users, monitor activities in a smarthome, obtain phone number, email addresses and Apple Voice Assistant, Siri, commands, and more.</p>
<p><img src="https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy.png" alt="" width="822" height="385" srcset="https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy.png 822w, https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy-300x141.png 300w, https://team.inria.fr/privatics/files/2019/10/Discontinued-Privacy-768x360.png 768w" sizes="(max-width: 822px) 100vw, 822px"></p>

<h2>BLE advertising</h2>
<p>In BLE, devices broadcast short messages, called Advertising Packets, to announce their presence and feature to nearby devices (those messages can be observed from an Android device using an application like <a href="https://play.google.com/store/apps/details?id=com.contextis.android.BLEScanner&amp;hl=en">Ramble</a>). Advertising Packets can include the name of the device, its type, but can also include custom data in a field called Manufacturer specific. This field is typically used by vendors to transmit data for application. Apple make use of this field to include data for its Continuity Protocols.</p>
<h2>Apple Continuity Protocols</h2>
<p>Apple has developed a number of features, called <a href="https://support.apple.com/en-us/HT204681"><i>Continuity</i></a>, that are designed to increase the usability of its products. Those features include: activity transfert, file transfert (airDrop), Wi-Fi password sharing, etc. The communication between nearby devices, required by Continuity services, is done by using BLE. Continuity data are embedded in BLE advertising packets and are broadcast to be picked up by nearby devices.</p>

<h2>Data exposed in cleartext</h2>
<p>We found that, even though some elements are encrypted, most of the data included in Continuity messages is sent in plain text. The exposed data can thus be passively collected by an eavesdropper and exploited to mount one of the attack presented below.</p>
<h2>Tracking users (iPhones, iPad, airpods …)</h2>
<p>We found that the content of <i>Apple Continuity </i>BLE messages can be used to track the device despite the use address randomization. We have identified several elements that remain constant over time or that can undermine the anti-tracking feature mechanism (i.e. address randomization). For instance, we found that messages emitted by earpods include information (battery levels and lid open counter) that can be exploited to track the earpod set. We also discovered a novel attack that would allow tracking by actively replaying BLE messages. An passive attacker could exploit this information to track the the location of individuals in spite of address randomization, the anti-tracking feature of BLE.</p>
<h2>Linking device belonging to the same iCloud account</h2>
<p>We discovered that it is possible to link together devices associated to the same iCloud account. This attack relies on the replay of messages that will trigger a response only from devices associated to the same <i>iCloud</i> account. An attacker could exploit this to identify all the device belonging to a person, and could narrow down its home if some device are left there.</p>
<h2>Monitoring activities in a smart home (Homekit)</h2>
<p>We found that messages emitted by <i>Homekit</i>-compatible devices can betray the activity in a smart-home. <a href="https://developer.apple.com/homekit/"><i>Homekit</i></a> is a smart-home framework developed by <i>Apple</i> and found in <a href="https://www.apple.com/fr/shop/accessories/all-accessories/homekit">devices</a> of <i>Apple</i> and other vendors (…). <i>Homekit</i> devices using BLE continuously emit messages that include an indicator reflecting the device state. For instance, in the case of a lightbulb, this indicator changes only when it is either turned on or turned off. Similarly, in an infrared movement detector, the indicator changes only when a person crosses the detection field. In-lab experiments showed that a passive attacker can leverage Homekit BLE messages to track the evolution of devices in a household and thus monitor the activities of the occupants.</p>
<h2>Device model, software version and more</h2>
<p>We found that a number of messages expose a wide variety of information on the emitting device characteristics and state: device model, OS version, device color, cellular connectivity, battery level, current activity etc.</p>
<h2>E-mail address and Phone numbers (Airdrop &amp; Nearby)</h2>
<p>We found that when using features such as Airdop and Nearby, devices emit messages from which email addresses and phone numbers can be extracted. Continuity services allow to seamlessly share resources with nearby devices: Airdrop to share files, Nearby to share Wi-Fi network credential. Prior exchange of information, the devices establish their identity by exchange identifiers over BLE: email addresses and/or phone numbers. Those identifiers are not sent in clear but are rather hashed using a cryptographic hash-function. This obfuscation can be bypassed in most cases and the identifiers recovered.</p>
<h2>Voice assistant commands (Siri)</h2>
<p>We found that when activated via voice, the Siri voice assistant will generate a message including a digital fingerprint of the command. Although the raw audio signal cannot be reconstructed from it, the fingerprint could be leveraged to infer the command.</p>

<p>The vulnerabilities identified were reported to Apple, Osram and Eve on May 29 th , 2019.</p>

<p>This work was supported by the <a href="http://www.citi-lab.fr/chairs/iot-chair/">INSA Lyon – SPIE ICS IoT chair</a> and the H2020 <a href="https://www.sparta.eu/">SPARTA</a> Cybersecurity Competence Network project.</p>
<p><img src="https://team.inria.fr/privatics/files/2019/10/logo-chaire-e1570022002577.jpg" alt="" width="200" height="66"><img src="https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-150x150.jpg" alt="" width="150" height="150" srcset="https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-150x150.jpg 150w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-300x300.jpg 300w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg-144x144.jpg 144w, https://team.inria.fr/privatics/files/2019/12/sparta_logo_jpg.jpg 400w" sizes="(max-width: 150px) 100vw, 150px"></p>

<p>The corresponding research paper, <a href="https://petsymposium.org/2020/files/papers/issue1/popets-2020-0003.pdf"><u>Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols</u></a>, will be presented at the <a href="https://petsymposium.org/2020/index.php">20th Privacy Enhancing Technologies Symposium (PETS 2020)</a> on 14-18 July 2020 in Montreal, Canada.</p>
<h3><a name="citeme"></a>APA style citation and bibtex entry</h3>
<p>You can use the following APA style citation or bibtex entry to reference our paper:</p>
<pre>Celosia, G., &amp; Cunche, M. (2020).Discontinued Privacy: Personal Data Leaks
in Apple Bluetooth-Low-Energy Continuity Protocols. <i>Proceedings on Privacy
Enhancing Technologies, 2020</i>(1), 26-46. De Gruyter Open.
@article{celosia2020close,
    title={Discontinued Privacy: Personal Data Leaks in Apple Bluetooth-Low-Energy Continuity Protocols},
    author={Celosia, Guillaume and Cunche, Mathieu},
    journal={Proceedings on Privacy Enhancing Technologies},
    volume={2020},
    number={1},
    pages={26--46},
    year={2020},
    publisher={De Gruyter Open}
}</pre>
<p><a href="http://creativecommons.org/licenses/by/4.0/">Creative Com</a></p>
								</div></div>]]>
            </description>
            <link>https://team.inria.fr/privatics/apple-devices-are-leaking-sensitive-data-over-ble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820589</guid>
            <pubDate>Mon, 13 Jul 2020 13:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to pick the best health insurance plan?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820565">thread link</a>) | @doglov
<br/>
July 13, 2020 | https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance | <a href="https://web.archive.org/web/*/https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>1. Type of coverage. </strong>There are many different ways you can obtain coverage. They can be grouped into four main categories:</p><ul role="list"><li>Through a <em>job</em>: private insurance (Blue Cross Blue Shield, Aetna, etc.)</li><li>Through the <em>government</em>: Medicare, Medicaid</li><li>Through the <em>individual exchange: </em>"ObamaCare" plan</li><li>Through <em>lower-cost supplemental and short-term plans: healthcare (Mira).</em></li></ul><p><strong><em>2. </em>Eligibility:</strong> all health insurance plans have eligibility criteria. They depend on your income, age, employment, and where you live.</p><p><strong>3.</strong> <strong>Monthly cost:</strong> The monthly premium for each plan can range from no-cost (Medicaid) to a few thousand dollars for a family Gold plan (individual exchange). Premiums must be paid monthly, regardless if you use the insurance or not.</p><p><strong>4. Type of plans:</strong> plans can have different tiers of pricing and/or how broad or narrow the network is. This may also correlate with how high the monthly premium is. For example, a broader network may cost more. </p><p><strong>5. Enrollment period: </strong>this is when you can enroll in a health insurance plan. Some plans have a specific time frame for when you can enroll and for other plans, you can enroll anytime of the year as long as you're eligible. </p></div><div><p>Picking the best suited plan for you comes down to three things: </p><p><strong>1) What are you eligible for? </strong>Try to determine what options you are eligible for. Sometimes, you are qualified for more options than you think.</p><p><strong>2) What are your healthcare needs?</strong> If you are relatively healthy, getting the top-tier plan may not make sense if you have to bear the cost. Meanwhile, if you have a chronic condition and need expensive treatments, getting a catastrophic plan may not be the best option for you. Most preventative care services like wellness visits and flu shots are covered at no out of pocket costs.</p><p><strong>3) What can you afford?</strong> Of course everyone wants to get the lowest-cost and most comprehensive plan, but healthcare is expensive. Look at your financial situation as a whole and see which options make the most sense from a financial perspective. </p><h3>Is there a penalty to go without insurance?</h3><p>Effective 2019 tax year, the individual mandate was repealed at the federal level. This means you will not be fined for not having or cannot afford health insurance. </p><p>Some states like Massachusetts, New Jersey, California, Rhode Island, or the District of Columbia reinstated this at the state tax level. The penalty itself is not an actual cash fine but a reduction of your annual tax refund (at the state level). In California, the tax refund reduction is $62/month. <strong>There is no individual mandate/fine in New York State.</strong>‍</p><h3>Is there an alternative if I can't afford any plans?<br></h3><p>Last but not least, if you can’t afford any plan, understand that being uninsured is not a shame but a financial decision. Depending on your monthly budget, getting a plan that is more expensive than rent and groceries bills may not be sustainable. </p><p>If you just go to the doctor <strong><em>once or twice a year,</em></strong> <a href="https://www.talktomira.com/">Mira </a>may make a good option. Mira helps you get affordable doctor visits, lab tests, and prescription drugs without insurance, for $25-45/mo. Below you will find a guide that explains the basics of several types of health insurance and health care plans. <a href="https://www.talktomira.com/">Learn more. </a><br></p><p>‍</p><p><strong>Who is eligible:</strong> Typically employees of companies with 50+ people will be eligible for private insurance. If you get laid off from a company, you will be eligible for COBRA, but you will be responsible to pay 100% of the monthly premiums. </p><p><strong>Monthly Cost/Cost-sharing: </strong></p><ul role="list"><li>In 2019, <em>annual premiums </em>were $7,188 for single coverage and $20,576 for family coverage.</li><li>Employers often pay for 80% of the cost, leaving the average monthly contribution for an employee at $100-$200 for an individual health plan.</li></ul><p><strong>Type of plans:</strong> Health Maintenance Organization (HMO), Prefered Provider Organization (PPO), Point of Service (POS), High Deductible Health Plan (HDPL)</p><p><strong>Enrollment period: </strong></p><ul role="list"><li>You are eligible to enroll when you start your job.</li><li>Every year, there is an annual renewal. This period depends on your employer and usually lasts about 60 days. </li></ul><p><strong>Notable companies</strong>: Cigna, Aetna, UnitedHeealth, Anthem &amp; Blue Cross Blue Shield, Humana</p><p>‍</p><p><strong>Who is eligible:</strong> Low income individuals (typically &lt;$20K annually), families, children, pregnant women, the elderly and people with disabilities.</p><p><strong>Monthly Cost/Cost-sharing:</strong> The cost depends largely on the state, as each state has the option of setting premiums. Medicaid is often the lowest to no-cost option for health insurance. </p><p>Individuals on Medicaid that earn a higher wage, meaning those with incomes at or above 150% of the poverty level, may pay more for the following health services:</p><ul role="list"><li>For prescriptions, it’s possible that states will charge coinsurance for up to 20% of each drug’s cost in order to encourage the use of lower-cost drugs.</li><li>Additionally, if individuals in this group use the emergency room in a non-emergency situation, they may potentially be charged up to full price for care. In this case, it is up to the hospital’s physicians to determine whether the visit was an emergency.</li></ul><p><strong>Type of plans: </strong>Public Medicaid and Managed Medicaid.</p><p><strong>Enrollment period: </strong>Anytime of the year as long as the individual or family is eligible. </p><p>‍</p><p><strong>Who is eligible:</strong> Citizens and residents aged 65+ as well as those with disabilities and people with End Stage Renal Disease.</p><p><strong>Monthly Cost/Cost-sharing:</strong> <a href="https://www.talktomira.com/post/how-much-will-medicare-for-all-cost-you">There are three types of Medicare coverage:</a> </p><ul role="list"><li>Part A (for hospital) is free if you paid more than 7.5 years of taxes.</li><li>Part B (for doctor visits) costs on average $144 a month.</li><li>Part D (drugs) costs on average $34 a month.</li></ul><p><strong>Type of plans:</strong> Public Medicare, and Medicare Advantage.</p><p><strong>Enrollment period: </strong>When an individual is first eligible for Medicare, they will have a 7-month Initial Enrollment Period to sign up for Part A and/or Part B. If they’re eligible for Medicare when they turn 65, they are able to sign up during the 7-month period that:</p><ul role="list"><li>Begins 3 months before the month they turn 65.</li><li>Includes the month they turn 65.</li><li>Ends 3 months after the month they turn 65.</li></ul><p>‍</p><p><strong>Who is eligible:</strong> Under the Affordable Care Act, Individuals who live in the United States and are U.S. citizens. Although anyone can enroll, the federal subsidy is available for those who make less than ~$48,000. </p><p><strong>Monthly Cost/Cost-sharing:</strong> According to AARP, the average health insurance cost for single coverage premiums in 2020 is $388 per month.</p><p><strong>Type of plans:</strong> Bronze, Silver, Gold, Platinum.</p><p><strong>Enrollment period: </strong>The Open Enrollment period for 2021 is November 1, 2020- January 21, 2021. If you don’t enroll during the Open Enrollment period, you must wait for the next Open Enrollment period. There are also special enrollment period if you recently moved or lost a job. </p><p><strong>Notable companies:</strong> OscarHealth, Fidelis, Oxford Health Plan, Blue Cross Blue Shield</p><p>‍</p><p>‍<strong>Who is eligible: </strong>Supplemental plans are additional plans that fill coverage gaps from your other health insurance plan. Anyone is eligible for a supplemental plan; however, there are different types of supplemental plans for varying needs. There are several supplemental plans for individuals with medicare, such as Medigap plans and Medicare part D, and several plans for senior-specific needs. <br></p><p><strong>Monthly Cost/Cost-sharing: </strong>Cost varies depending on the type of supplemental plan you are getting and what this plan covers. According to research from eHealth Medicare, in 2019 the average medicare supplemental plan premium was approximately $152. <br></p><p><strong>Type of plans:</strong> There are many types of supplemental plans depending on your needs as a patient. Some of these options include a membership with Mira, critical illness insurance, disability insurance, dental insurance and life insurance. </p><p>‍<strong>Enrollment period: </strong>You can add a supplemental health insurance plan at any time and do not need to wait for the open enrollment period. They can be purchased from a private marketplace or an insurance company.</p><p>‍</p><p><strong>Who is eligible:</strong> Health share programs or ministries are groups of people who opt to share each other’s monthly medical expenses. These groups are usually created based on religious organizations; however, there are now medical cost sharing plans that do not require any religious affiliation. <br></p><p><strong>Monthly Cost/Cost-sharing: </strong>The appeal of health shares is that they may cost families less each month. According to <a href="https://www.kitces.com/blog/healthcare-sharing-program-review-chm-medicare-lhs-samaritan-health-share-plans/">Kitces article</a> on Healthcare Sharing Programs, these plans can cost families $300-$500/month. This can save families up to 50% each month. <br></p><p><strong>Type of plans: </strong>Medical cost sharing plans are not insurance plans. Thus, the legalities and terminology may differ from a typical health insurance plan. For more information on a sharing plan, it is best to contact an affiliate of the organization.<br></p><p><strong>Enrollment period: </strong>There is no enrollment period for health sharing plans, as they are not insurance plans. For more information on when you can enroll in a specific sharing plan, contact the organization directly. </p><p>Notable companies: Christain Healthcare Ministries, Liberty Healthshare, Medi-Share, Zion, Trinity Healthshares, and Samaritan Ministries. </p><p>‍</p><ol start="1" role="list"><li><strong>Penalty without insurance</strong>: the individual mandate was effectively repealed for the 2019 tax year at the federal level. Some states like CA,&nbsp;NJ, MA, and the District of Columbia reinstated it at the state-level. The penalty is not an actual cash penalty but a reduction of your annual tax refund.</li><li><strong>"$0 after deductible":</strong> many health plans choose to use this phase but it can be misleading. $0 after deductible does not mean the service is free for you, you are still responsible to pay full cost or negotiated <strong>until</strong> deductible is met. Deductible is the amount you have to pay out-of-pocket before your insurance starts paying </li><li><strong>"Unlimited preventative care"</strong>: under the Affordable Care Act, certain preventative care services like wellness visits, flu shots, and STD testing are available at no cost. However, there are limits on how many you can use them a year. For example, the first STD test may be free, but not if you want to be tested every other month. Sick visits like urgent care visits are not considered preventative care services. </li><li><strong>Medicare is …</strong></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance">https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance</a></em></p>]]>
            </description>
            <link>https://www.talktomira.com/post/how-to-pick-the-best-health-insurance-plan-how-much-is-health-insurance</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820565</guid>
            <pubDate>Mon, 13 Jul 2020 13:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad Habits]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820496">thread link</a>) | @fizentech
<br/>
July 13, 2020 | https://fizentech.com/bad-habits/ | <a href="https://web.archive.org/web/*/https://fizentech.com/bad-habits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Does your organization have habits that are detrimental to their success?&nbsp; The answer of course, is yes - all organizations and their people, have embedded routines and habits that are limiting their success.&nbsp; Changing a habit is challenging and often we don't even realize we have a habit that is limiting our ability to improve.</p>
<p>In the groundbreaking book, The Power of Habit, Charles Duhigg points out that in a paper published by a Duke University researcher, it was <em>found that more than 40 percent of the actions people performed each day weren't due to decision making, but were habits. In a sense, that's alarming because when we're in the middle of a habit, we're thinking less.</em></p>
<p>Well ... hold on, we do NOT want our IT professionals thinking less, we want them actively thinking through problems and critically finding ways to improve the experience of end users.&nbsp; That can become a challenge when working on an IT Help Desk becomes routine, or a strong willed Project Manager is not listening to the input of the team; and resources disengage and come to expect to be led rather than to lead.</p>
<p>As an technology provider, we provide IT Services to a broad range of industries.&nbsp; The variation in organizations we serve has helped us work with many different people, in a variety of geographical areas and countries.&nbsp; We have found that leaders with good habits naturally attract and retain employees with good habits.&nbsp; The culture of the organizations we serve and the attitudes and routines of its employees, often reflect the attitudes, routines and habits of their executive teams and owners.&nbsp; It can be hard medicine to accept, but it is true - you lead from the top (but that doesn't mean you can't be a positive agent for change, whatever your position is within a group).</p>
<p>Starbucks has often been cited for the system they developed for exceptional customer service, now referred to as the LATTE System.&nbsp; They encourage their employees to,</p>
<ul>
<li>Listen to the Customer</li>
<li>Acknowledge their complaint</li>
<li>Take action by solving the problem</li>
<li>Thank them</li>
</ul>
<p>Customers can be a wonderful and often <a href="https://fizentech.com/help-wanted/">free source of advice</a> on what your organization is or is not doing well.&nbsp; We have added an additional ingredient to this wonderful formula, and that is returning back to our customer to make sure systems are still operating as discussed.&nbsp; We want to be sure they are still happy with the outcome; perhaps easier for us as our clients are typically part of ongoing managed service agreements.</p>
<p>A few years ago we were required to roll out endpoint management to a very large customer base.&nbsp; Our product offering includes endpoint monitoring and protection for mobile devices and workstations, and when you're working with large user groups; coordinating the installations can be a real challenge.&nbsp; Nobody wants to be inconvenienced or disrupted by a software installation.</p>
<p>Our client had previous experiences with MDM and RMM roll outs that did not go very well, and we found ourselves listening to their experiences and brainstorming how we could avoid the common approaches used by other IT vendors; forcing installation and maintenance windows on end users.</p>
<p>We found if we put the power of scheduling the installations for end users into their own hands, rather than falling back on the common habit in IT organizations to force installation and maintenance windows; the installation process not only went smoother but completed faster.&nbsp; By providing end users scheduling options they were empowered with autonomy and enjoyed controlling their own downtime.</p>
<p>Willpower is the biggest and most important element of developing good habits for an organization.&nbsp; An essential element of willpower, is autonomy.&nbsp; &nbsp;Everyone wants to believe and feel that they are in control of their lives, schedule and organization.&nbsp; When we take away someone's choices, they become frustrated - but when we provide choices, we find that our ability to coordinate and deliver for a client grows tenfold.</p>
<p>We need to reflect on the processes, systems and rule-sets that are governing how our organizations operate; and by listening to our stakeholders, find new ways to innovate and empower them to be apart of our mission; to keep their IT systems running smoothly.&nbsp; Find ways to engage with your user base, and use their feedback to drive innovative IT Services within their organization; they will thank you.</p>

</div></div>]]>
            </description>
            <link>https://fizentech.com/bad-habits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820496</guid>
            <pubDate>Mon, 13 Jul 2020 13:28:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How reframing discounts led to a 4x increase in yearly plans]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820462">thread link</a>) | @Mnlfrgr
<br/>
July 13, 2020 | https://manuel.friger.io/blog/reframing | <a href="https://web.archive.org/web/*/https://manuel.friger.io/blog/reframing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <div>
            <p><!--block-->Back in May my wife and I decided to move out of our flat in Bristol.</p>

<p>By then we had already been living for a couple of months with my in-laws and it didn't make sense to keep paying £1k+/month in rent.</p>

<p>After some discussion, we decided to throw some money at the problem and put all our stuff in a storing facility.</p>

<p>I started googling storage companies in Bristol and I was quickly overwhelmed by the number of options (pro tip: don't start a storage business, it's ridicolously competitive).</p>

<p>Every company allowed me you to get an online quote by entering the size of the storing unit and how long I wanted to rent it for.</p>

<p>But one company did things differently.</p>

<p>On top of asking me the same two questions, UK Storage Company also <strong>asked me to choose a discount</strong>.</p>

<div>
<p><span data-trix-cursor-target="left" data-trix-serialize="false">ï»¿</span><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/205/content_Screenshot_2020-07-10_Your_storage_quote_is_below%281%29.png"></p></div>

<p>At first, I was confused.</p>

<p>I wondered why they would allow me to choose my own discount. Then I realised it was the good ol' "the longer you commit, the less you pay" gimmick.</p>

<p><strong>Same technique, different framing.</strong><br>
UK Storage Company put me in the driver's seat and empowered me to make my decision.</p>

<p>That's when my brain started whirring and buzzing, and one question began to form in my head: what if I used the same framing <a href="https://referralhero.com/">for my SaaS product</a>?</p>

<p>After all, cash-flow is king for (bootstrapped) startups and having people commit to yearly plans helps to lower churn.</p>

<p>Would that have any effect on how many people choose the longer plans (biannual or annual) over the monthly one?</p>

<p>That same day I <a href="https://twitter.com/manuel_frigerio/status/1264609587413553155">tweeted about it</a> and updated the checkout page of my app as shown below.</p>

<p><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/206/content_Screenshot_2020-07-10_ReferralHero_-_Advanced_Referral_Marketing_Software_.png"></p>



<h2><!--block-->The results</h2>

<p><!--block-->After 7 weeks the experiment has been a great success.<br>
With the new framing, the percentage of people who chose the biannual or annual plan <strong>has gone from 4.8% to 19%</strong>, a rather nice <strong>395% increase</strong>.<br>
<span data-trix-cursor-target="right" data-trix-serialize="false"><img alt="" src="https://s3.amazonaws.com/manuel.friger.io/app/public/ckeditor_assets/pictures/207/content_chart.png"></span><br>
I've done several pricing experiments over the years but none of them has been as successful and in such short space of time.</p>

<p>Perhaps even more interesting is that <strong>more than twice as many people chose the annual plan over the biannual plan</strong>.</p>

<p>My hunch is that this is due to the higher discount rate of the annual plan (35% for 12 months vs 15% for 6 months means an extra 5% discount when you choose the annual plan), which increases the perceived value.</p>

<h2><!--block-->Never stop experimenting</h2>

<p><!--block-->There's a small handful of levers you can pull to grow a business and <a href="https://manuel.friger.io/blog/charge-more">pricing is probably the most underutilised one</a>. Most SaaS businesses choose a pricing model and rarely, if ever, review it.</p>

<p>A better (and more profitable) approach is to run small experiments. If they work, incorporate them. If they don't, try something else.</p>

<p>Some people are scared that changing things will upset their customers but the truth is:</p>

<ol>
	<li>
	<p><!--block-->you are allowed to change whatever you want about your business.</p>
	</li>
	<li>
	<p><!--block-->you can always revert back. Nothing is fixed.</p>
	</li>
	<li>
	<p><!--block-->in reality, nobody cares.</p>
	</li>
</ol>

<h2><!--block-->Do it yourself</h2>

<p><!--block-->If you want to try this experiment in your business, here are a couple of suggestions:</p>

<ul>
	<li>
	<p><!--block-->don't <a href="https://medium.com/@FlorentGeerts/the-jam-experiment-how-choice-overloads-makes-consumers-buy-less-d610f8c37b9b">overload people</a> with options; have maximum 3.</p>
	</li>
	<li>
	<p>to nudge people towards one option, offer a substantially higher discount (like I did with the yearly plan)</p>
	</li>
	<li>
	<p>Don't try to be sneaky and word the options properly. As you can see in my example, people know exactly what they get and how much they pay.</p>
	</li>
	<li>
	<p>ask people immediately after sign-up when they are in the right frame of mind. In my experience, asking people to switch to yearly plans a couple of months after they have used your product triggers many more questions in their mind, whereas by asking them before they try your product you're putting them in front of a simple decision: do I want to save money?</p>
	</li>
</ul>

<p><!--block-->As people who work in the tech industry, we are all exposed to the same ideas, patterns and filters. This is why there's so little innovation and everyone just copies what everyone else is doing.</p>

<p>Sometimes all you need to do is to look at what companies in completely different industries operate. You might be suprised what a storage company can teach you.</p>

<p><strong>PS:</strong> If you do try this experiment, <a href="https://manuel.friger.io/cdn-cgi/l/email-protection#4e232f203b2b220e283c27292b3c602721">let me know how it goes</a>.</p>

<p><strong>PPS:</strong> You probably want to know if we did hire that storing company in the end. The answer is NO. Eventually, we decided to hire a removal company and have all our stuff with us.</p>

          </div>
        </div>
        
      </div><div>
        <h3>Did you enjoy this?</h3>
        <p>Then you will like <a target="_blank" href="https://manuel.friger.io/join">ðŸ”¥The Fireside</a>, a monthly-ish newsletter about psychology, business, technology and the intersection of those plus any new articles I publish on this blog.</p>
      </div></div>]]>
            </description>
            <link>https://manuel.friger.io/blog/reframing</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820462</guid>
            <pubDate>Mon, 13 Jul 2020 13:24:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surviving Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820449">thread link</a>) | @kiwicopple
<br/>
July 13, 2020 | https://supabase.io/blog/2020/07/10/surviving-hacker-news | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/07/10/surviving-hacker-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://supabase.io/blog/2020/07/10/surviving-hacker-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820449</guid>
            <pubDate>Mon, 13 Jul 2020 13:23:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russ v7.0 – Services framework/library for Unix sockets]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23820398">thread link</a>) | @johnmdev
<br/>
July 13, 2020 | https://expl.info/display/RUSS/Home | <a href="https://web.archive.org/web/*/https://expl.info/display/RUSS/Home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-type="normal">
<div>
<p>RUSS is a protocol and framework for building service-oriented servers using UNIX/Domain sockets.</p><p>RUSS is an alternative to HTTP/web technologies for services running on UNIX/Linux.</p><p>RUSS is built on some familiar ideas:</p><ul><li>orthogonal operations: execute, help, list</li><li>service path: /-separated list of strings identifying a service and how to get there</li><li>ordered list of string arguments (aka positional arguments)</li><li>unordered collection of string attritubes as key=value pairs (like environment variables)</li><li>exit/return value</li><li>stream I/O over file descriptors (stdin, stdout, stderr)</li></ul><p>The benefits of using UNIX/Domain sockets are:</p><ul><li>performance</li><li>standard part of UNIX/Linux (no kernel modules needed)</li><li>credentials are mediated by the OS</li><li>connection between independent processes (even between different users)</li><li>passing of descriptors between independent processes (even between different users)</li></ul><p>Get started with&nbsp;<a href="https://expl.info/display/RUSS/RUSS+v7+-+Quickstart+Setup">RUSS v7 - Quickstart Setup</a>.</p><p>Further information for users and developers is available in the&nbsp;<a href="https://expl.info/display/RUSS/Documentation">Documentation</a>&nbsp;section:</p><ul><li><a href="https://expl.info/display/RUSS/RUSS+Specification">RUSS Specification</a></li><li><a href="https://expl.info/display/RUSS/RUSS+v7+-+Tools">RUSS v7 - Tools</a></li><li><a href="https://expl.info/display/RUSS/RUSS+v7+-+Core+Servers">RUSS v7 - Core Servers</a></li><li><a href="https://expl.info/pages/viewpage.action?pageId=40501388">pyruss - RUSS for the Python Programming Language</a></li><li><a href="https://expl.info/display/RUSS/goruss+-+RUSS+for+the+Go+Programming+Language">goruss - RUSS for the Go Programming Language</a></li></ul><h2 id="Home-Firstthings">First things</h2><ul><li><code>+</code>&nbsp;-&nbsp;the area that system servers register at; usually under&nbsp;<code>/var/run/russ/services</code><span><code><br></code></span></li><li><span><code>ruls</code>&nbsp;- command line tool to list servers/services (think&nbsp;<code>ls</code>)<br></span></li><li><span><code>ruhelp</code>&nbsp;- command line tool to get help information (think&nbsp;<code>man</code>)</span></li><li><span><code>ruexec</code>&nbsp;- command line tool to execute a service</span></li><li><span><code>pyruss</code>&nbsp;- Python bindings for the C API</span></li><li><span><code>rubb</code>&nbsp;- manage servers/services</span></li></ul><h2 id="Home-ListingServers/Services">Listing Servers/Services</h2><p>What's available?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruls +
debug
exec
plus
proc
set
ssh
tee</pre>
</div></div><p>What services does the&nbsp;<code>debug</code>&nbsp;server provide?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruls +/debug
chargen
conn
daytime
discard
echo
env
exit
request
session
spath</pre>
</div></div><h2 id="Home-GettingHelp-BuiltinManPage">Getting Help - Built in Man Page</h2><p>How do I use the&nbsp;<code>debug</code>&nbsp;services?</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruhelp +/debug
Provides services useful for debugging.

/chargen[/...]
    Generate and send characters following the RFC 864 character
    generator protocol sequence.

/conn[/...]
    Report connection information.

/daytime
    Report the date and time.

/discard[/...] [--perf]
    Discard all data received from stdin. If --perf is specified,
    performance feedback is reported to stderr.

/echo[/...]
    Simple echo service: read from stdin and write back to stdout.

/env
    Report server side environ entries.

/exit &lt;value&gt;
    Return with given exit value (between 0 and 255).

/request[/...]
    Report request information.

/session[/...]
    Report session information.

/spath[/...]
    Report service path information.</pre>
</div></div><h2 id="Home-RunningaService">Running a Service</h2><p>Try the character generator:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/debug/chargen
!"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefgh
"#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghi
#$%&amp;'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghij
^C</pre>
</div></div><p>Show "request" information (as received and sent back by the server):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec -a X=123 -a Y=abc +/debug/request hello there world
protocol string (0010)
spath (/request)
op (execute)
opnum (2)
attrv[0] (X=123)
attrv[1] (Y=abc)
argv[0] (hello)
argv[1] (there)
argv[2] (world)</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/debug/daytime
Friday, February 16, 2018 11:45:50-GMT</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service on another machine "buddy" (<code>ssh</code>&nbsp;must work without user interaction):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ ruexec +/ssh/buddy/+/debug/daytime
Friday, February 16, 2018 11:46:55-GMT</pre>
</div></div><p>Call the&nbsp;<code>daytime</code>&nbsp;service from Python:</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ PYTHONPATH=/usr/lib/russng python2
&gt;&gt;&gt; import pyruss
&gt;&gt;&gt; rv, ev, out, err = pyruss.execv_wait_inouterr_timeout(1000, "+/ssh/buddy/+/debug/daytime")
&gt;&gt;&gt; print out
Friday, February 16, 2018 11:48:23-GMT</pre>
</div></div><p>Echo a message, hopping through three machines "buddy", "bobby", and "bibby" (as before,&nbsp;<code>ssh</code>&nbsp;must work without user interaction):</p><div data-hasbody="true" data-macro-name="noformat"><div>
<pre>$ echo "hop hop hop" | ruexec +/ssh/buddy/+/ssh/bobby/+/ssh/bibby/+/debug/echo
hop hop hop</pre>
</div></div></div>
</div></div>]]>
            </description>
            <link>https://expl.info/display/RUSS/Home</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820398</guid>
            <pubDate>Mon, 13 Jul 2020 13:16:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Project over Money, Team over Project]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23820390">thread link</a>) | @strdr4605
<br/>
July 13, 2020 | https://strdr4605.github.io/project-over-money-team-over-project | <a href="https://web.archive.org/web/*/https://strdr4605.github.io/project-over-money-team-over-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><h2>Project over money, team over project</h2><p><time>11.07.2020</time> — <a href="https://strdr4605.github.io/tags/motivation">motivation</a> — <span>2<!-- --> min read</span></p><section><p>Behind any work stands a motivation. Sometimes work is a pleasure, other times you do things that are unpleasant just because you have to.
But in the end motivations like money, common goal, future achievements drive us to work.
When choosing a job as a software engineer, things that motivate me and probable you are the <strong>project</strong> what I will work on,
<strong>team</strong> what I will work with and <strong>money</strong> for my personal need.
When making the final decision I usually value <strong>project over money, team over project</strong>.</p><h2>Team</h2><p>For me, the team that I will work with is the most important aspect when searching for a new job.</p><blockquote><p>“If you are the smartest person in the room, then you are in the wrong room.” ― Confucius</p></blockquote><p>Being in a team with people that are more experienced than you is the key to fast-growing.
But don't just stay and wait when their knowledge will be transferred to you.</p><ul><li>Observe their behaviors</li><li>Make proposals and wait for feedback</li><li>Ask for advice</li><li>Ask "Why?" when they make a decision. "Why this database?" "Why this service?" ...</li></ul><p>Make sure to not push too hard on them. As this can defocus and irritate some people.</p><p>Even if your teammates aren't more experienced than you they may share interesting articles, tips, thoughts.</p><p>In the end, if you have a hard situation, maybe the project is not that interesting (at the moment) or you have problems with finishing a task,
with a great team, you can carry on and pass any issues.</p><h2>Project</h2><p>At this moment in my career, I am really focused on the technical part of a project.
I enjoy learning new tools, libraries that will increase productivity, and when coding I am trying to create a piece of art.</p><p>But also the idea and the product may still be a good motivation and even if the tech stack is not that good,
with a great team, you will refactor everything as long as you believe in the product idea.</p><p>Even if the team is not that good or you don't have a team at all, enjoying the tech stack or believing in the product
will make you continue working and loving your job.</p><p>While at the interview, I try to discover as much as possible about the project stack and idea to understand if
I am willing to accept an offer bellow my initial expectations.</p><h2>Money + benefits</h2><p>Money is important as everyone has their needs and money represent your value as a software engineer.
Employee benefits like included food, gym, short commute time may be also added to the total compensation pack.</p><p>If you have a family and bills to pay money may be a decisive factor.
But still, put everything on the table and before making the final decision ask yourself a question.</p><blockquote><p>What will be your next job after this one?</p></blockquote><p>In other words: Where will this job lead you? How much will your professional skills increase?
Will this job have temporary benefits you will bust your entire career?</p><p>Does it worth an additional 100% salary increase to work with a 5+ year old legacy codebase, old tech stack, and maybe a bad team?</p><h2>Conclusion</h2><p>As everyone has a price I will try to conclude with some compensation examples.</p><p>If I am enjoying the project and/or the team at my current job, I would not accept a 5-15% salary increase offer,
as after 3-6 months I may get even more increase at my current job.
If I don't like the project or the team is toxic, I may accept a lower job offer just because
I will gain more from the new team or new tech stack.</p><p>Focus on your professional skills, gain maximum value from your team (don't forget to also give back and share your knowledge with teammates),
learn your tech stack, enjoy your software engineering career and the money will eventually come to you.</p></section></div></div>]]>
            </description>
            <link>https://strdr4605.github.io/project-over-money-team-over-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820390</guid>
            <pubDate>Mon, 13 Jul 2020 13:15:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Querying 40k Datasets with SQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820382">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/40k-sql-datasets | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/40k-sql-datasets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#introduction" as="#introduction">Introduction</a></li><li><a href="#data-should-be-discoverable-and-composable" as="#data-should-be-discoverable-and-composable">Data should be discoverable and composable</a></li><li><a href="#mounting-vs-cloning-data" as="#mounting-vs-cloning-data">Mounting vs. Cloning Data</a></li><li><a href="#mounting-data-in-splitgraph-cloud" as="#mounting-data-in-splitgraph-cloud">Mounting data in Splitgraph Cloud</a></li><li><a href="#avoiding-the-pull-of-data-gravity" as="#avoiding-the-pull-of-data-gravity">Avoiding the pull of Data Gravity</a></li><li><a href="#looking-to-the-future" as="#looking-to-the-future">Looking to the future</a></li></ol></nav><section><h2 id="introduction">Introduction</h2><p><a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">Splitgraph</a> is a tool and platform for building, versioning, querying and sharing datasets. Inspired by Docker and Git, it works on top of PostgreSQL and integrates seamlessly with anything that uses PostgreSQL. Our <a href="https://www.splitgraph.com/explore" as="https://www.splitgraph.com/explore">data catalog</a> already includes over 40,000 datasets from government open data portals, all queryable via SQL.</p><p>The Splitgraph catalog classifies these datasets as <a href="https://www.splitgraph.com/docs/splitgraph-cloud/external-repositories">external repositories</a>. These are different from the default <a href="https://www.splitgraph.com/docs/concepts/repositories">Splitgraph repositories</a>, which are collections of <a href="https://www.splitgraph.com/docs/concepts/images">Splitgraph images</a>. Yet Splitgraph allows you to query them in the same way as you do Splitgraph images. For example, you can use SQL to query any repository or <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals" as="/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals"><code>JOIN</code> between multiple of them</a>. Or you can use Splitfiles to <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#splitfile" as="/docs/ingesting-data/socrata#splitfile">build reproducible datasets</a> from them. And every external repository includes an <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">auto-generated PostgREST API</a>.</p><p>External repositories allow Splitgraph Cloud to index live data without actually ingesting it. This way, you can use the catalog to discover live data. But you only need to ingest it when you're ready to query it, or snapshot it as part of a Splitgraph image.</p></section><section><h2 id="data-should-be-discoverable-and-composable">Data should be discoverable and composable</h2><p>Many services exist for cataloging data and making it discoverable. For example, <a href="https://datasetsearch.research.google.com/" as="https://datasetsearch.research.google.com/">Google Dataset Search</a> provides a nice interface for searching and discovering datasets (in fact, <a href="https://datasetsearch.research.google.com/search?query=opd%20crimes&amp;docid=jrM9a8yTUXMZaY1QAAAAAA%3D%3D" as="https://datasetsearch.research.google.com/search?query=opd%20crimes&amp;docid=jrM9a8yTUXMZaY1QAAAAAA%3D%3D">it even includes Splitgraph repositories</a>). The problem is, the data is fragmented and siloed across different data portals. It's nice to be able to search for data and download a CSV file. But most datasets are uninteresting in isolation. The real power comes from the ability to combine datasets and query them together.</p><p>Splitgraph does not only provide an index for discovering open data. It also provides the tools for composing open datasets together. For example, mounting the data from the <a href="https://data.cambridgema.gov/" as="https://data.cambridgema.gov">Cambridge</a> and <a href="https://data.cityofchicago.org/" as="https://data.cityofchicago.org">Chicago</a> data portals is as simple as running two commands:</p><pre><code metastring=""><span><span>$</span> <span>sgr <span>mount</span> socrata chicago -o <span>'{"domain": "data.cityofchicago.org"}'</span></span></span>
<span>Connecting to remote server...
Mounting Socrata domain...
Getting Socrata metadata
warning: Requests made without an app_token will be subject to strict throttling limits.
Loaded metadata for 504 Socrata tables

</span><span><span>$</span> <span>sgr <span>mount</span> socrata cambridge -o <span>'{"domain": "data.cambridgema.gov"}'</span></span></span>
<span>Connecting to remote server...
Mounting Socrata domain...
Getting Socrata metadata
warning: Requests made without an app_token will be subject to strict throttling limits.
Loaded metadata for 137 Socrata tables
</span></code></pre><p>At this point, all the datasets in these two data portals are available for querying. You can query them in isolation, or you can query them together. You can use a Splitfile, <code>sgr sql</code>, or any standard SQL client:</p><p><a href="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png" as="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png"><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0300_ingesting-data/images/socrata/1_dbeaver_overview.png" alt="DBeaver overview"></a></p><p>Here's how you can compare daily COVID cases in Chicago and Cambridge (from two separate data portals) with a standard <code>JOIN</code> query:</p><pre><code metastring=""><span>SELECT</span>
    cambridge_cases<span>.</span><span>date</span> <span>AS</span> <span>date</span><span>,</span>
    chicago_cases<span>.</span>cases_total <span>AS</span> chicago_daily_cases<span>,</span>
    cambridge_cases<span>.</span>new_positive_cases <span>AS</span> cambridge_daily_cases
<span>FROM</span>
    chicago<span>.</span>covid19_daily_cases_and_deaths_naz8_j4nc chicago_cases
<span>FULL</span> <span>OUTER</span> <span>JOIN</span>
    cambridge<span>.</span>covid19_cumulative_cases_by_date_tdt9_vq5y cambridge_cases
<span>ON</span>
    date_trunc<span>(</span><span>'day'</span><span>,</span> chicago_cases<span>.</span>lab_report_date<span>)</span> <span>=</span> cambridge_cases<span>.</span><span>date</span>
<span>ORDER</span> <span>BY</span> <span>date</span> <span>ASC</span><span>;</span>
</code></pre><p>(For more details and in-depth instructions, see the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW documentation</a>.)</p><p>Note that this is not limited to combining multiple public datasets. Often, the work of a data analyst includes combining internal data with public or licensed datasets from external vendors. The same semantics of "mounting" data in Splitgraph apply.</p></section><section><h2 id="mounting-vs-cloning-data">Mounting vs. Cloning Data</h2><p>With Splitgraph, there are two primary ways to ingest data: cloning it or mounting it.</p><p><a href="https://www.splitgraph.com/docs/working-with-data/clone-vs-checkout">"Cloning" (and checking-out)</a> an image means downloading a versioned data image, which is a snapshot of a database comprised of delta-compressed diffs. For example, the result of running a Splitfile is an image.</p><p>"Mounting" means establishing a connection to a live data source. The term comes from the idea of "mounting" a filesystem. A mounted table uses a <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction">foreign data wrapper</a> (FDW), and you don't ingest data from it until you query it. For example, the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW</a> translates SQL queries to <a href="https://dev.socrata.com/docs/queries/" as="https://dev.socrata.com/docs/queries/">SoQL queries</a> and forwards them to the Socrata server.</p><p>(For more details on mounting data, FDWs and custom mount handlers, read our recent <a href="https://www.splitgraph.com/blog/foreign-data-wrappers">"foreign data wrappers" blog post</a>.)</p></section><section><h2 id="mounting-data-in-splitgraph-cloud">Mounting data in Splitgraph Cloud</h2><p>Mounting is the key abstraction that allows Splitgraph Cloud to index external repositories with features like an auto-generated REST API. On the backend, the "query API" (a subject for a later post) uses the Splitgraph library and Socrata mount handler to mount repositories on demand. Then it exposes the mounted schemata to a customized version of <a href="http://postgrest.org/" as="http://postgrest.org/">PostgREST</a> which creates the API.</p><p>Separately, a periodic Airflow task queries the Socrata metadata API to discover and index over 40,000 repositories. Conveniently, the same Socrata software powers over 200 government open-data portals, so one mount handler provides a large catalog of useful live data.</p></section><section><h2 id="avoiding-the-pull-of-data-gravity">Avoiding the pull of Data Gravity</h2><p>Mounting is a powerful abstraction because it allows you to interact directly with upstream data sources, avoiding the need for ETL. In 2010, GE Engineer Dave McCrory coined the term "<a href="https://datagravitas.com/2010/12/07/data-gravity-in-the-clouds/" as="https://datagravitas.com/2010/12/07/data-gravity-in-the-clouds/">data gravity</a>." In his blog post, he observed that "data if large enough can be virtually impossible to move."</p><p>Splitgraph, as a data versioning solution, should work with all your data, not just the subsets of it that you can move. Traditional ETL tools force you to ingest or duplicate your data before you can interact with it. With Splitgraph, you only need to pull upstream data into your images at query time. This allows incremental adoption and quick experimentation; there is no need to move your data warehouse to start using Splitgraph. Instead, you only need to setup an FDW.</p><p>Note that the idea of data gravity applies to versioned data images (which you clone) as much as it does to upstream, live data (which you mount). What if you want to import only a subset of data from a large image? This is the use case for <a href="https://www.splitgraph.com/docs/large-datasets/layered-querying">layered querying</a>, which allows you to "check out" an image without downloading it. Instead, Splitgraph creates an FDW that queries only the "layers" of the image necessary to satisfy the query. You can think of layered querying like a mount handler for Splitgraph images.</p></section><section><h2 id="looking-to-the-future">Looking to the future</h2><p>At the moment, Splitgraph Cloud only uses the <a href="https://www.splitgraph.com/docs/ingesting-data/socrata">Socrata FDW</a> as a mount handler for external repositories, since the <a href="https://www.tylertech.com/products/socrata" as="https://www.tylertech.com/products/socrata">Socrata data platform</a> powers most government open-data portals.  In the future, it could use additional mount handlers to provide access to a wider array of upstream sources. To create an external repository, Splitgraph just needs a suitable FDW and a way to index the upstream data. For example, it's easy to imagine indexing Google BigQuery datasets. More interestingly, an on-premise version of Splitgraph could index private databases or data warehouses behind a firewall.</p><p>Our goal for Splitgraph is to make tools for data science as easy and pleasurable to use as tools for coding. That's why our main philosophy is to "stay out of the way." Mounting data is a great example of this philosophy in action. Why force your data warehouse to talk to Splitgraph, when Splitgraph can talk to your data warehouse?</p><p>In the meantime, make sure to <a href="https://www.splitgraph.com/explore">explore data</a> on Splitgraph. If you know SQL, you can <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">get started</a> in less than 10 minutes.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/40k-sql-datasets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820382</guid>
            <pubDate>Mon, 13 Jul 2020 13:14:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The two commandments for undergrad math]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820344">thread link</a>) | @iunternik
<br/>
July 13, 2020 | https://linus.space/posts/2020-07-13-undergrad-courses.html | <a href="https://web.archive.org/web/*/https://linus.space/posts/2020-07-13-undergrad-courses.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="content">
            <article>
    
    
    <section>
        <p>I’ve only been tutoring in theoretical computer science undergrad courses for about three semesters now (and of course taken a fair share of them) but I’ve thought quite a bit about how to do it <em>right</em>. Of course, there’s a lot of subjective opinion in that: how do you explain something, and is <span>0 ∈ ℕ</span>? But I think there are some objective things you should look out for. These (in my opinion) are the two commandments for undergrad math courses:</p>
<ol type="1">
<li>Be kind.
<ul>
<li>Have the right attitude towards your students.</li>
<li>Reduce stress on your students. Value your student’s time.</li>
<li>Consider that your subject is hard.</li>
</ul></li>
<li>Be predictable.
<ul>
<li>Connect your lecture to your assignments and your assignments to your exam. If you are a bigger team, coordinate these clearly.</li>
<li>Keep a consistent level of exactness.</li>
</ul></li>
</ol>
<p>Fortunately, a lot of people do these right. I’ve had great courses that were kind and predictable. But important details tend to go wrong in some courses in my experience.</p>
<h3 id="be-kind">1. Be kind</h3>
<h4 id="have-the-right-attitude-towards-your-students-reduce-stress">Have the right attitude towards your students, reduce stress</h4>
<p>I noticed that some people running undergrad courses have the general (maybe implicit) attitude that students are lazy, stupid, and always tempted to take the shortcut, even if it involves cheating or breaking other rules. Not only is this often taken as explanation that the course is not rated well by the students or the exam has a 70% fail rate, but it’s also often taken into a <em>predisposition</em> towards the students. This results in paranoid measures like forcing assignment groups of three students to return their assignments in three different handwritings (to prove that everyone was working?), letting students stand up and turn around while handing out exam sheets, or having a general (and often very explicit) “if you spot a mistake, it’s probably your fault” attitude in exam reviews. If you have taken maths undergrad courses you can probably name another example off the top of your head. Some of the measures that I’ve seen were not only completely unnessecary, but actively harmful: Being paranoid about cheating <em>encourages</em> cheating (and no “anti-cheating” measure is very hard to get around). Also, a general level of distrust against students is really harmful for their mental health and level of confidence in continuing to study.</p>
<p>So: trust that your students don’t take shortcuts. You can’t prevent it anyways, and if they do, it’s going to be a learning experience for them later on. And try to make your students understand that they can understand the subject, even if it’s hard. Of course, that is a hard thing to actually go and do, but it’s not impossible.</p>
<h4 id="value-your-students-time-consider-that-your-subject-is-hard">Value your student’s time, consider that your subject is hard</h4>
<p>Even if you trust your students being intelligent and hard-working, consider how many hours students spend on the course. Having a hard exercise sometimes is a good learning factor, of course. A math course is always a test in persistence and motivation. But also consider that the students have different things to do, and they also need some work-life-balance. Finding the sweet spot here is crucial. Additionally, professors and assistants tend to forget that their subjects are actually really hard, especially in mathematics, where basic topics are so internalized that it might seem wild that someone wouldn’t understand what a homomorphism does. This feeds into the topic of how to <em>really</em> explain something in the lecture, but it also has to do with how hard you can reasonably make the exercises and exams.</p>
<h3 id="be-predictable">2. Be predictable</h3>
<h4 id="connect-your-lecture-to-your-assignments">Connect your lecture to your assignments…</h4>
<p>This seems obvious, but is often not the case, especially when different people are working on the assignments, the lecture and the exam. This starts at the lecture, assignments and exam using different notation respectively, but you should also ask yourself if the assignments can be understood by consulting the lecture. Also, having tutorials where students can ask questions about exercises is helpful here.</p>
<h4 id="and-your-assignments-to-your-exam">…and your assignments to your exam</h4>
<p>Students should be able to pass the exam by having done the exercises. They should also get a glimpse into what the exam will look like, for instance by a test exam. Of course, the whole point of an exam is that it’s unpredictable what will be asked of the students, but it should rather be too predictable than not predictable enough. An exam is a stress situation for most students, and you shouldn’t ask them to find all-new solutions to all-new problems.</p>
<h4 id="keep-a-consistent-level-of-exactness">Keep a consistent level of exactness</h4>
<p>This is more specific to math courses, I think, than the other points. The students should know what is asked of them when an exercise is to prove or explain something. If you only do “this is trivial” and “you can see this by looking very hard”-ish proofs in your lectures, don’t ask your students to prove something by induction on three pages in the exam. It’s also not an argument that students <em>should have learned to prove something</em> in another lecture, if they haven’t seen any proofs in yours, they will just mimic what the lecture does, as is sensible of any human being. Make it clear in the exercises and exam how exact you want the explanation and proof to be.</p>
<h3 id="in-conclusion">In conclusion</h3>
<p>There are probably many more things that need to be said about undergrad courses. This is just what I had on my mind in the last semester. <a href="https://www.reddit.com/r/math/comments/hqcb8v/the_two_commandments_for_undergrad_math_tcs/">Here’s the link to the reddit discussion about this post.</a> Thanks for reading!</p>
    </section>
</article>

        </div>
        </div></div>]]>
            </description>
            <link>https://linus.space/posts/2020-07-13-undergrad-courses.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820344</guid>
            <pubDate>Mon, 13 Jul 2020 13:09:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Track Dark Mode Usage with Google Tag Manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820306">thread link</a>) | @justus_bluemer
<br/>
July 13, 2020 | https://hume.dev/articles/dark-mode/ | <a href="https://web.archive.org/web/*/https://hume.dev/articles/dark-mode/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
    <div>
      <div>
        <article>
          <p>Dark Mode for all the things is all the rage these days and if you don’t offer a dimly lit version of your website or app, you suck. Apparently.
While I do use dark mode on my phone (where it can <a href="http://mobileenerlytics.com/dark-mode/">save significant power and thereby improve battery life</a>), I think most other uses are the Matrix Raining Code screen saver of our time and actively supporting it is a waste of development resources.</p>
<p>If you, too, want to support or refute this assertion, this is how you can track the usage of Dark Mode on your website with Google Tag Manager and Google Analytics as a custom dimension:</p>
<h2 id="create-a-google-tag-manager-variable">Create a Google Tag Manager variable</h2>
<p>Using the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/matchMedia">matchMedia</a> interface of the <code>window</code> object wie can check the <code>prefers-color-scheme</code> media feature to detect whether or not the user has configured the system with a light or a dark color scheme.</p>
<p>This Custom JavaScript variable will return <code>dark</code> true if dark mode is active and <code>light</code> if it isn’t.</p>
<div><pre><code data-lang="javascript"><span>function</span>(){
    <span>return</span> (window.<span>matchMedia</span> <span>&amp;&amp;</span> window.<span>matchMedia</span>(<span>'(prefers-color-scheme: dark)'</span>).<span>matches</span>) <span>?</span> <span>"dark"</span> <span>:</span> <span>"light"</span>
}
</code></pre></div><p>Paste this into GTM like so:</p>

<figure>
    <a href="https://hume.dev/img/articles/dark-mode/colorscheme-js-variable.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/colorscheme-js-variable.jpg" loading="lazy" alt="Google Tag Manager Dark Mode variable">
    </a>
    
</figure>


<h2 id="update-google-analytics-configuration">Update Google Analytics configuration</h2>
<p>First, make sure you have a spare Google Analytics custom dimension and make note of the variable index you want to use (marked in red):</p>

<figure>
    <a href="https://hume.dev/img/articles/dark-mode/analytics-dimension-color-scheme.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/analytics-dimension-color-scheme.jpg" loading="lazy" alt="Google Tag Manager Dark Mode custom dimension">
    </a>
    
</figure>


<p>If you’re not sure which <a href="https://support.google.com/analytics/answer/2709828?hl=en">scope</a> is right for you, use “Hit”.</p>
<p>Now, back in Google Tag Manager, edit your Google Analytics tag or your Google Analytics settings variable to incorporate the <code>dark</code> or <code>light</code> value into your tracking request:</p>

<figure>
    <a href="https://hume.dev/img/articles/dark-mode/color-scheme-settings.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/color-scheme-settings.jpg" loading="lazy" alt="The updated Google Tag Manager settings variable settings the value of the appropriate dimension index">
    </a>
    
</figure>


<p>Great, that’s it, you can go ahead and publish your GTM container! If you want to validate right away if your implementation was successful, check our your Google Analytics request to see the custom dimension parameter:</p>

<figure>
    <a href="https://hume.dev/img/articles/dark-mode/request-dark.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/request-dark.jpg" loading="lazy" alt="A screenshot of the Google Analytics request with dark mode enabled">
    </a>
    
</figure>



<figure>
    <a href="https://hume.dev/img/articles/dark-mode/request-light.jpg">
        <img src="https://hume.dev/img/articles/dark-mode/request-light.jpg" loading="lazy" alt="A screenshot of the Google Analytics request with dark mode disabled">
    </a>
    
</figure>


<h2 id="track-dark--light-mode-switch">Track dark / light mode switch</h2>
<p>If you really want to go all in, you can also track changes to the preferred color scheme and push an event to dataLayer in case the user decides to update her or his preferences:</p>
<div><pre><code data-lang="javascript">window.<span>matchMedia</span>(<span>'(prefers-color-scheme: dark)'</span>).<span>addEventListener</span>(<span>'change'</span>, <span>e</span> =&gt; {
    <span>var</span> <span>newColorScheme</span> <span>=</span> <span>e</span>.<span>matches</span> <span>?</span> <span>"dark"</span> <span>:</span> <span>"light"</span>;
    window.<span>dataLayer</span> <span>=</span> window.<span>dataLayer</span>&nbsp;<span>||</span>&nbsp;[]
    window.<span>dataLayer</span>.<span>push</span>({
        <span>event</span><span>:</span> <span>"colorScheme"</span>,
        <span>newColorScheme</span><span>:</span> <span>newColorScheme</span>
    })
});
</code></pre></div><p>Considering this will almost never happen, it’s pretty pointless though.</p>
<p>How many of your users use Dark Mode?</p>

        </article>
      </div>
    </div>
  </div>
</section></div>]]>
            </description>
            <link>https://hume.dev/articles/dark-mode/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820306</guid>
            <pubDate>Mon, 13 Jul 2020 13:04:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Wall]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820222">thread link</a>) | @noch
<br/>
July 13, 2020 | https://dev.theportal.dev/wall/ | <a href="https://web.archive.org/web/*/https://dev.theportal.dev/wall/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="paragraph-content">
        <p>
            Edward Witten in Physics and Geometry, 1987:<br>
            &nbsp;&nbsp;&nbsp;&nbsp;"If one wants to summarise our knowledge of physics in the briefest possible terms, there are three really fundamental observations:
        </p>
        <p>(i) Space-time is a pseudo-Riemannian manifold $M$, endowed with a metric tensor and governed by geometrical laws.</p>
        <p>(ii) Over $M$ is a vector bundle $X$ with a nonabelian gauge group $G$.</p>
        <p>(iii) Fermions are sections of $(\hat{S}{+} \otimes V{R}) \oplus (\hat{S}_ \otimes V_{\bar{R}})$. $R$ and $\bar{R}$ are not isomorphic; their failure to be isomorphic explains why the light fermions are light and presumably has its origins in representation difference $\Delta$ in some underlying theory.</p>
        <p>All of this must be supplemented with the understanding that the geometrical laws obeyed by the metric tensor, the gauge fields, and the fermions are to be interpreted in quantum mechanical terms."</p>
    </div></div>]]>
            </description>
            <link>https://dev.theportal.dev/wall/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820222</guid>
            <pubDate>Mon, 13 Jul 2020 12:53:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wallet fingerprinting nearly a third of all Bitcoin transactions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820109">thread link</a>) | @b10c
<br/>
July 13, 2020 | https://b10c.me/mempool-observations/3-blockchaincom-recommendations/ | <a href="https://web.archive.org/web/*/https://b10c.me/mempool-observations/3-blockchaincom-recommendations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <p>Transactions sent with Blockchain.com wallets make up for about a third of all
Bitcoin transactions. A methodology to identify these transactions is described
and used. Insights about the wallet-usage are derived from the resulting
dataset. The privacy implications and possible improvements are discussed.</p>
<hr>
<p>One of the first observations made when building the <a href="https://mempool.observer/monitor">Bitcoin Transaction
Monitor</a> was that many transactions precisely follow the recommendations of
a feerate estimator. These transactions appear as horizontal bands, which rise
and sink as the feerate recommendations change.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/bands.png" alt="Transactions following the Blockchain.com feerate recommendations">
    <figcaption><center></center></figcaption>
</figure>
    
<p>Most of these transactions share the same fingerprint. Only P2PKH outputs are
spent. No SegWit and neither multisig are spent. With every transaction, either
one or two outputs are created. When two outputs are created, then at least one
of them is a P2PKH output. The transactions are not time-locked, have a version
of one, and do not signal <a href="https://github.com/bitcoin/bips/blob/master/bip-0125.mediawiki">BIP-125 replaceability</a>. However, all are
<a href="https://github.com/bitcoin/bips/blob/master/bip-0069.mediawiki">BIP-69</a> compliant.</p>
<p>This matches the fingerprint of the Blockchain.com wallets: namely a Web, an
iOS, and an Android wallet. The wallets can only receive and spend P2PKH
outputs. While users can pay to all address formats<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the change-output, if
created, is a P2PKH output. The wallets construct the transactions with a
locktime of zero and a transaction version of one. The inputs and outputs are
all lexicographically sorted as specified by BIP-69.</p>
<p>The wallets use the Blockchain.com feerate estimator, which is publicly
accessible via <a href="https://b10c.me/blog/003-a-list-of-public-bitcoin-feerate-estimation-apis/#blockchaininfo-api">an API</a>. The API returns two feerate estimates: <em>priority</em>
and <em>regular</em>. The <em>priority</em> feerate aims for confirmation in the next hour
and the <em>regular</em> feerate for confirmation in an hour or more. By default,
the wallets follow the recommendations closely. Users can set a custom feerate,
but a warning is displayed.</p>
<h3 id="methodology">Methodology</h3>
<p>Combining the feerate estimates and the transaction fingerprints makes it
possible to identify transactions sent with one of the Blockchain.com wallets.
While the majority of the Blockchain.com transactions pay exactly the
recommended feerate, some under- or overpay by a fixed percentage. This is
caused by incorrect assumptions about the transaction size during the
calculation of the transaction fee. The transaction fee is the product of the
targeted feerate and the assumed transaction size. The final and actual
transaction size is only known after adding the signature to the transaction.</p>
<pre>fee  =  target feerate  ×  assumed transaction size
</pre>
<p>All underpaying transactions have two outputs. However, during the fee
calculation, the size of a one-output transaction is assumed. For example, for a
P2PKH <em>1in ⇒ 2out</em> transaction (226 bytes), the size of a <em>1in ⇒ 1out</em>
transaction (192 bytes) is used. This incorrect assumption results in the
transaction only paying around 85% (192 byte / 226 byte) of the recommended
feerate. As the transaction inputs make up for a large part of the transaction
size, the effect is smaller for transactions with more inputs. This behavior was
only present in the Blockchain.com Web wallet. A fix was <a href="https://github.com/blockchain/blockchain-wallet-v4-frontend/releases/tag/v4.32.6">released</a> on
April 21st, 2020.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/over-underpaying.png" alt="Transactions over- and underpaying by a fixed percentage">
    <figcaption><center></center></figcaption>
</figure>
    
<p>The overpaying transactions all have a single output. For these, a second output
is assumed during the fee calculation. To calculate the fee of a P2PKH
<em>1in ⇒ 1out</em> transaction (192 bytes), the size of a <em>1in ⇒ 2out</em> transaction
(226 bytes) is used. This results in the transaction paying about 118% (226 byte
/ 192 byte) of the recommended feerate. Similar to the underpaying transactions,
the effect is smaller for transactions with more inputs. These transactions are
assumed to originate from the Blockchain.com iOS wallet. This has not yet been
confirmed.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/methodology.png" alt="Visual explainer for methodology used to identify Blockchain.com transactions">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    Out of the set of transactions with the Blockchain.com wallet fingerprint, the
transactions paying the feerate recommended by the Blockchain.com feerate
estimator are selected. Transactions broadcast on April 19th, 2020, are shown.
The y-axis is centered around the <em>regular</em> recommendation, which was 3
sat/vbyte for most of the day. Between 12:00 UTC and 17:00 UTC, the <em>regular</em>
recommendation briefly jumped to 4 sat/vbyte for a few minutes each. On other
days the feerate recommendations are usually  more volatile. April 19th is a
Sunday. Sundays are known for less network activity compared to weekdays. This
day has been specifically chosen to showcase the methodology.
</p>
<p>Identifying Blockchain.com wallet transactions with this methodology is not
assumed to be perfectly accurate or reliable. For example, transactions send
with a custom feerate can not be identified and are false negatives.
Transactions constructed by different wallets that pay a similar feerate and
share the fingerprint could be identified as false positives. When the
recommended feerate is volatile, which is often the case for the <em>priority</em>
recommendation (for example, shortly after <a href="https://b10c.me/mempool-observations/2-bitmex-broadcast-13-utc/">the daily BitMEX broadcast</a>),
then some transactions might pay a feerate not recoded by the Bitcoin
Transaction Monitor. Additionally, the wallets could construct a transaction
using an older recommendation, which is different from the recommendation at the
time the transaction is broadcast. These transactions are false negatives as
well.</p>
<h3 id="observations">Observations</h3>
<p>The described methodology is used to identify the transactions send with
Blockchain.com wallets between April 1st and May 20th, 2020. The resulting
dataset spans over 50 days and contains about 4 million transactions. These pay
a total fee of 445.73 BTC and account for about 1.34 GB of block space. Roughly
two-thirds of the Blockchain.com wallet transactions target the <em>regular</em> feerate
while the remaining third targets the <em>priority</em> feerate.</p>
<p>Roughly the same number of outputs are created as are spend. Blockchain.com
wallet transactions have either a single payment-output or a payment-output and
a change-output. As the change-outputs are always P2PKH outputs, it is possible
to determine the payment-output type. Out of all outputs created about 31.7% are
P2PKH, 23.3% are P2SH, 0.34% are P2WPKH, and less than 0.01% are P2WSH
payment-outputs. The remaining 45.5% are P2PKH change-outputs. The most commonly
used input-output combinations are <em>P2PKH ⇒ P2PKH + P2PKH</em> with 33%,
<em>P2PKH ⇒ P2SH + P2PKH</em> with 26%, and <em>P2PKH ⇒ P2PKH</em> with around 7%.</p>
<br>
<!-- raw HTML omitted -->
<p>Users of the Blockchain.com wallet are most active between 15:00 UTC and 18:00
UTC and least active between 4:00 UTC and 5:00 UTC. At around 5:00 UTC, the
number of transactions per minute starts to rise. At this time it is 8am in
Moscow, and 7am in central Europe. Between 5:00 UTC and 10:00 UTC, the number
of transactions per minute rises from about 30 to just above 60. The
transactions per minute remain constant until rising again at noon UTC, which is
8am on the US east coast. The daily maximum is reached at around 16:00 UTC with
just above 75 transactions per minute. From there on, the activity declines
until reaching the minimum number of transactions per minute at around 4:00 UTC
again.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/time-of-day.png" alt="Activity hours of Blockchain.com wallet users.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    The transactions broadcast per minute with Blockchain.com wallets are shown. The
error bands show the standard deviation. The time between 8am and 8pm is
marked for central Asia, Europe, and eastern US timezones.
</p>
<br>
<!-- raw HTML omitted -->
<p><a href="https://thecryptofeed.net/articles/blockchain-com-says-they-account-for-a-third-of-all-bitcoin-transactions/">Reportedly</a>, Blockchain.com claims that their wallets are responsible for
one-third of all Bitcoin transactions. They <a href="https://www.blockchain.com/charts/my-wallet-n-tx">publish</a> the daily number of
transactions sent by their wallets. This lead to a discussion on the accuracy
and correctness of these numbers. The described dataset can be used to verify
this claim. The number of daily transactions in the dataset and the published
numbers can be compared. The total number of transactions sharing the
fingerprint with the Blockchain.com wallet transactions acts as an upper-bound.
The total transactions per day are retrieved from <a href="https://transactionfee.info/charts/transactions-per-day/">transactionfee.info</a> to
calculate Blockchain.com’s share of the network.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/one-third.png" alt="Showing that the Blockchain.com published numbers could be reasonably accurate.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>The daily transaction count published by Blockchain.com translates into a
network share of 30% to 35%. The share of the transactions with the same
fingerprint, the upper-bound, is on average about three absolute percent higher.
The share of the identified transactions in the dataset is about four to five
absolute percent lower than the Blockchain.com reported numbers at around 27% on
average. The transactions account for about 13% of the daily fees paid, and 20%
of the daily block space used.</p>
<p>However, the numbers reported by Blockchain.com still lie in a reasonable range.
There are multiple reasons why the described dataset could contain fewer
transactions than are reported by Blockchain.com. Some users might send
transactions with a custom feerate. These are not picked up by the described
methodology. Furthermore, it’s not clear if the reported numbers include
transactions send with the <a href="https://www.blockchain.com/de/api/blockchain_wallet_api">Blockchain.com Wallet API</a>. The API allows
users to construct transactions sending to multiple recipients which are not
accounted for in the described dataset.</p>
<br>
<!-- raw HTML omitted -->
<p>With the knowledge that the Blockchain.com Web wallet underpaid the recommended
feerate for transactions with two outputs, and the iOS wallet
overpays on transactions with one output, the wallet’s shares can be estimated.
For this, the assumption that the ratio of two-output to one-output transactions
is similar in all wallets must hold. The Web wallet accounts for one-third and
the iOS wallet for half of the Blockchain.com wallet transactions. The Android
wallet probably accounts for a majority of the remaining 17%. However, this can
not be verified as no data is indicating the share of the Android wallet.</p>
<figure>
    <img src="https://b10c.me/data/mo/mo3-blockchaincom-recommendations/web-wallet-share.png" alt="Share of Web wallet transactions with two outputs.">
    <figcaption><center></center></figcaption>
</figure>
    
<p>
    Between April 1st and April 22nd, the two-output transactions send with the Web
wallet made up for about a third of all two-output transactions send with
Blockchain.com wallets. The shown mean is weighted with the transaction counts.
A fix <a href="https://github.com/blockchain/blockchain-wallet-v4-frontend/releases/tag/v4.32.6">released</a> on April 21st resolved the underpaying behavior for
two-output transactions in the Web wallet. It took a few days until the release
got deployed.
</p>
<figure></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://b10c.me/mempool-observations/3-blockchaincom-recommendations/">https://b10c.me/mempool-observations/3-blockchaincom-recommendations/</a></em></p>]]>
            </description>
            <link>https://b10c.me/mempool-observations/3-blockchaincom-recommendations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820109</guid>
            <pubDate>Mon, 13 Jul 2020 12:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing a type-safe Stripe client for serverless using TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23820024">thread link</a>) | @protoduction
<br/>
July 13, 2020 | https://guido.io/posts/using-stripe-in-serverless-typescript/ | <a href="https://web.archive.org/web/*/https://guido.io/posts/using-stripe-in-serverless-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
<p>In my current project I am trying to go full origin-less: everything runs in a CloudFlare worker script, there is no centralized server. These serverless Javascript environments often don’t run on Node, so there are a lot of libraries you can’t use.</p>
<p>This makes going fully serverless painful, so far I had to implement the client code for <a href="https://guido.io/posts/sending-email-from-cloudflare-workers">Mailgun</a>, BigQuery and Stripe myself. Each of these has a great SDK for Node, but unfortunately we can’t use those. This is a big downside of going fully serverless: you end up implementing these clients or finding workarounds instead of building your own application.</p>
<p>Fortunately, it turns out that for Stripe it’s easy to write a type-safe client without too much code. <strong>This is where Typescript really shines.</strong></p>
<h2 id="setup">Setup<a href="#setup">#</a></h2>
<p>First we install the Stripe Node client, we will only use its typings so we can install it as a dev dependency.</p>
<pre><code>npm install --save-dev stripe
</code></pre><p>Also we’ll be using the <code>qs</code> NPM package, we use it to turn arbitrarily nested JSON objects into query strings.</p>
<pre><code>npm install --save qs
</code></pre><h2 id="writing-our-own-client">Writing our own client<a href="#writing-our-own-client">#</a></h2>
<p>Below is all there is to the client. It currently only implements a single operation (for creating customers), but it’s trivial to add more.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span></code></pre></td>
<td>
<pre><code data-lang="typescript"><span>import</span> { <span>Stripe</span> } <span>from</span> <span>"stripe"</span>;
<span>import</span> { <span>stringify</span> } <span>from</span> <span>"qs"</span>;

<span>const</span> <span>STRIPE_SECRET_KEY</span> <span>=</span> <span>"please-dont-actually-hardcode-your-api-secret-here-but-store-it-more-safely"</span>;
<span>const</span> <span>STRIPE_API_URL</span> <span>=</span> <span>"https://api.stripe.com"</span>;


<span>export</span> <span>async</span> <span>function</span> <span>createCustomer</span>(<span>body</span>: <span>Stripe.CustomerCreateParams</span>) {
    <span>return</span> <span>fetchStripe</span>(<span>"/v1/customers"</span>, <span>body</span>, {
        <span>method</span><span>:</span> <span>"POST"</span>,
    });
}

<span>async</span> <span>function</span> <span>fetchStripe</span>(<span>endpoint</span>: <span>string</span>, <span>body?</span>: <span>any</span>, <span>init</span>: <span>RequestInit</span> <span>=</span> {})<span>:</span> <span>Stripe</span>.<span>Customer</span> {
    <span>init</span> <span>=</span> {
        ...<span>init</span>,
        <span>body</span>: <span>body</span> <span>?</span> <span>stringify</span>(<span>body</span>) <span>:</span> <span>undefined</span>,
        <span>headers</span><span>:</span> {
            ...<span>init</span>.<span>headers</span>,
            <span>"Accept"</span><span>:</span> <span>"application/json"</span>,
            <span>"Content-Type"</span><span>:</span> <span>"application/x-www-form-urlencoded"</span>,
            <span>"Authorization"</span><span>:</span> <span>`Bearer </span><span>${</span><span>STRIPE_SECRET_KEY</span><span>}</span><span>`</span>
        },
        
    }
    <span>const</span> <span>url</span> <span>=</span> <span>STRIPE_API_URL</span> <span>+</span> <span>endpoint</span>;
    <span>const</span> <span>response</span> <span>=</span> <span>await</span> <span>fetch</span>(<span>url</span>, <span>init</span>);

    <span>// Note this line will throw in case we can't reach Stripe, error handling could be improved!
</span><span></span>    <span>const</span> <span>j</span> <span>=</span> <span>await</span> <span>response</span>.<span>json</span>();

    <span>if</span> (<span>!</span><span>response</span>.<span>ok</span> <span>||</span> <span>response</span>.<span>status</span>.<span>toString</span>()[<span>0</span>] <span>!==</span> <span>"2"</span>) {
        <span>throw</span> <span>new</span> Error(<span>`Stripe API call failed to </span><span>${</span><span>endpoint</span><span>}</span><span> (</span><span>${</span><span>response</span>.<span>status</span><span>}</span><span>): </span><span>${</span><span>JSON</span>.<span>stringify</span>(<span>j</span>)<span>}</span><span>`</span>);
    }
    <span>return</span> <span>j</span>;
}
</code></pre></td></tr></tbody></table>
</div>
</div><h3 id="using-it">Using it<a href="#using-it">#</a></h3>
<p>Now we can call the above code like this to create a new customer:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="typescript"><span>const</span> <span>customer</span> <span>=</span> <span>await</span> <span>createCustomer</span>({<span>name</span><span>:</span> <span>"Jane Doe"</span>, <span>email</span><span>:</span> <span>"jane@example/com"</span>});
<span>console</span>.<span>log</span>(<span>`Customer created with id </span><span>${</span><span>customer</span>.<span>id</span><span>}</span><span>`</span>);
</code></pre></td></tr></tbody></table>
</div>
</div><p>The nice thing is that as we are using Typescript this will actually be typechecked as we are using the typings from the official Stripe NPM package. What that means is that your code-editor can autocomplete the fields, and if you add fields that are invalid the Typescript compiler will tell you.</p>


    
  </article></div>]]>
            </description>
            <link>https://guido.io/posts/using-stripe-in-serverless-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23820024</guid>
            <pubDate>Mon, 13 Jul 2020 12:30:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GNU: A Heuristic for Bad Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23819964">thread link</a>) | @some_furry
<br/>
July 13, 2020 | https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>If you see the letters GNU in a systems design, and that system intersects with cryptography, I can almost guarantee that it will be badly designed to an alarming degree.</p>



<p>This is as <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">true of GnuPG (and PGP in general)</a> as it is of designs like the proposed <a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html">GNU Name System</a> (IETF draft) and cryptographic libraries like GnuTLS and libgcrypt. In fact, I cannot recall single GNU-branded cryptography project that isn’t a roaring dumpster fire.</p>



<p>I will elaborate.</p>



<h2>Problems with the GNU Name System’s Cryptography</h2>



<h3>Asymmetric Cryptography</h3>



<p>The GNS (GNU Name System) uses an unconventional construction for zones:</p>



<blockquote><p>A zone in GNS is defined by a public/private ECDSA key pair (d,zk), where d is the private key and zk the corresponding public key. GNS employs the curve parameters of the twisted edwards representation of Curve25519 [<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC7748">RFC7748</a>] (a.k.a. edwards25519) with the ECDSA scheme ([<a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#RFC6979">RFC6979</a>]).</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-zones">GNU Name System IETF Draft, section 2</a></cite></blockquote>



<p>This is beyond weird: Going out of your way to use the edwards25519 curve from RFC 7748, but not use the Ed25519 signature algorithm, but still choosing to use deterministic ECDSA (RFC 6979).</p>



<p>(If you’re lost, I wrote about digital signature algorithms in <a href="https://soatok.blog/2020/04/26/a-furrys-guide-to-digital-signature-algorithms/">a previous blog post</a>.)</p>



<p>The authors acknowledge the unconventional nature of their design choice in section 9.1 of the RFC draft:</p>



<blockquote><p>GNS uses ECDSA over Curve25519. This is an unconventional choice, as ECDSA is usually used with other curves. However, traditional ECDSA curves are problematic for a range of reasons described in the Curve25519 and EdDSA papers. <strong>Using EdDSA directly is also not possible, as a hash function is used on the private key which destroys the linearity that the GNU Name System depends upon.</strong> We are not aware of anyone suggesting that using Curve25519 instead of another common curve of similar size would lower the security of ECDSA. GNS uses 256-bit curves because that way the encoded (public) keys fit into a single DNS label, which is good for usability.</p><cite><a href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-cryptography">GNU Name System IETF Draft, section 9.1</a></cite></blockquote>



<p><s>The bold statement (my emphasis) is nonsense: In any design that uses digital signature algorithms, your system should map a private key (some opaque byte string) to a public key (some other opaque byte string) and signatures should also be opaque byte strings. The inclusion of a hash function under the hood of the signature algorithm is a moot point, especially since RFC 6979 also uses HMAC-SHA2 to generate deterministic nonces, thereby rendering their choice of RFC 6979 a contradiction of their stated goal.</s> Edit: <a href="#update-2020-07-09">see below</a>.</p>



<p>Using Ed25519 with a 32-byte private key (instead of a 64-byte private key) is also trivial. To wit: Libsodium offers <a href="https://libsodium.gitbook.io/doc/public-key_cryptography/public-key_signatures#key-pair-generation">crypto_sign_seed_keypair()</a> for this purpose.</p>



<p>But even worse: ECDSA is less secure and slower than EdDSA, even when you use the same curves, due to how the algorithms are implemented. The authors of the RFC do not defend this design choice beyond this hash function non sequitur.</p>



<div><figure><img data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I can’t be the only one feeling this way right now. Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.</figcaption></figure></div>



<h4 id="update-2020-07-09">(Update) “But They Need Hierarchical Keys”</h4>



<p>After I initially posted this, Redditor Steve132 informed me that <a href="https://www.reddit.com/r/crypto/comments/hnlyp1/gnu_a_heuristic_for_bad_cryptography/fxdbez4/">I overlooked the reason they made this design decision</a>.</p>



<blockquote><p>Take a look at Section 6.1&nbsp;<a rel="noreferrer noopener" href="https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion" target="_blank">https://tools.ietf.org/id/draft-schanzen-gns-01.html#name-recursion</a></p><blockquote><p>From here, the following steps are recursively executed, in order: Extract the right-most label from the name to look up. Calculate q using the label and zk as defined in Section 4.1.</p></blockquote><p>So then if you go to section 4.1, they do h=H(&lt;address string&gt;), (r,R) is some root keypair, then they do C (a child public key), C=hR, then q=H(C).</p><p>the idea behind the calculation of q is to use the root public key to derive a child public key from ONLY the root public key, exploiting the linearity property that in elliptic curves, if bG=B, then (b+s)G=(sG+B)</p><p>This allows a third party to derive child public keys without any knowledge of the private keys for the root. This technique is also used in bitcoin’s bip32 (<a rel="noreferrer noopener" href="https://en.bitcoin.it/wiki/BIP_0032" target="_blank">https://en.bitcoin.it/wiki/BIP_0032</a>) for ‘unhardened’ derivation scheme.</p><cite>Part of Steve132’s correction</cite></blockquote>



<p>I fully admit, I didn’t absorb this detail in my first pass of the RFC draft. It wasn’t clearly spelled out in Section 9 (which aims to justify their cryptography decisions), and I didn’t read the other sections as carefully. This was my mistake.</p>



<p>However, even with this explanation in mind, my original point that this design choice is both unconventional and unnecessary still stands, because <a href="https://ieeexplore.ieee.org/abstract/document/7966967?section=abstract">BIP32-Ed25519</a> already exists (albeit, it still needs <a href="https://forum.web3.foundation/t/key-recovery-attack-on-bip32-ed25519/44">a carefully designed implementation</a> to be secure against active attackers). </p>



<p>Therefore, the GNU Name System developers didn’t need to roll their own design, they could have used one that’s already seen real-world deployment instead. Why take on unnecessary risk?</p>



<p>Furthermore, trying to push through an implementation of ECDSA over edwards25519 isn’t just unnecessary and weird, it’s also probably dangerous, as Thai Duong noted:</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">While I don't agree that ECDSA is worse than Ed25519 – both have pros and cons — it takes courage to implement ECDSA over Edward25519. Do you know if they published any code?  This unfortunate marriage may introduce fun and unique bugs</p>— thaidn (@XorNinja) <a href="https://twitter.com/XorNinja/status/1281041946538938368?ref_src=twsrc%5Etfw">July 9, 2020</a></blockquote></div>
</div><figcaption>Thai Duong–author of the BEAST attack against SSL/TLS, among <a href="https://github.com/google/tink">other</a> <a href="https://github.com/google/wycheproof">things</a></figcaption></figure>



<p>Of course, all cryptography development can be said to be dangerous, but there are other problems fundamental to the GNU Name System design that makes any departure from a well-tread path very suspect.</p>



<h3>Symmetric Cryptography</h3>



<p>The GNU Name System project doesn’t stop there. It further throws <a href="https://tonyarcieri.com/all-the-crypto-code-youve-ever-written-is-probably-broken">IND-CCA2 security</a> out the window and specifies encrypting with AES and TwoFish in a cipher cascade, using Cipher Feedback (CFB) mode.</p>



<p>The authors do not even attempt to defend this decision. Typically this happens when the authors do not understand the risks involved. I sincerely doubt they’ve heard the words “adaptive chosen-ciphertext attack” in the course of their self-study.</p>



<p>(Because, y’know, attackers will surely never be able to replay UDP traffic if a runtime exception occurs because of corrupted data.)</p>



<h4>“Why Is This Bad?”</h4>



<p>Cipher cascades are usually the result of “we want to defend against a backdoored or broken cipher”. Bear in mind, the cipher itself is rarely the first part of a cryptosystem to be broken.</p>



<p>On that note, TwoFish isn’t <a href="https://blog.cryptographyengineering.com/2012/10/09/so-you-want-to-use-alternative-cipher/">the worst choice</a> of a cascade partner for AES, but I’d prefer a design that employed a different paradigm (since AES is a SPN permutation block cipher, an ARX-based stream cipher like Salsa20 or ChaCha seems reasonable).</p>



<p>AES is a boring choice, because it’s the industry standard. I’m not <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">particularly fond of AES</a> (due to it not being fast and constant-time in pure software implementations), but if you use it in an authenticated mode (AES-GCM, AES-CCM, AES-EAX, AES-OCB3, … I dunno, Poly1305-AES? Just use an AEAD mode!), it’s fine.</p>



<p><strong>Cipher Feedback (CFB) mode is not an authenticated mode.</strong></p>



<p>If you’re publishing a cryptography design in 2020 that fails the <a href="https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html">Cryptographic Doom Principle</a>, you need to go back to the drawing board.</p>



<h4>“But They Use Digital Signatures”</h4>



<p><a href="https://blog.cryptographyengineering.com/2016/03/21/attack-of-week-apple-imessage/">Cough.</a></p>







<h2>Other GNU Projects</h2>



<p>If you want to learn about why GnuPG (and the PGP ecosystem in general) is terrible, I recommend <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">Latacora’s takedown</a>.</p>



<p>GnuTLS is an SSL/TLS library created by the same people who created (and then abandoned) libmcrypt, which was the scourge of <a href="https://meta.stackoverflow.com/questions/293930/problematic-php-cryptography-advice-in-popular-questions">bad cryptography in the PHP ecosystem</a> for many years (until it was <a href="https://wiki.php.net/rfc/mcrypt-viking-funeral">finally excised in PHP 7.2</a>). Consequently, the project’s <a href="https://www.gnutls.org/security-new.html">CVE history</a> should be no surprise.</p>



<p><strong>Quick story:</strong> Many years ago, a few timing attacks were discovered in libgcrypt by regular chatters in Freenode’s ##crypto channel. This led a lot of us <a href="https://lists.gnupg.org/pipermail/gcrypt-devel/2015-November/003618.html">to look at libgcrypt for more bugs</a>.</p>



<p>The general consensus of the ensuing IRC discussion was, roughly, “We probably shouldn’t try to fix them all, because a) that’s way too much effort because there’s too much badness and b) this library will be a ripe target for upcoming cryptanalysis researchers to get their first papers published for many years”. And, indeed, the attack papers that have come out over the years that affect libgcrypt <a href="https://eprint.iacr.org/2020/432">haven’t disappointed</a>.</p>



<p>To be clear, at the time this happened, I was garbage at writing C (and somehow even less confident than capable) and barely making ends meet, so “drop everything and volunteer to fix all the libgcrypt badness” wasn’t a tenable option for me. And since the world is largely moving away from GnuPG and libgcrypt, it honestly isn’t worth the effort trying to fix all the bad when an easier fix is “use something good instead”.</p>



<h2>Takeaway</h2>



<p>If you see the letters GNU anywhere in a project that intersects with cryptography–except for its public license–it’s almost certainly an error-prone cryptographic design.</p>



<p>Or, as my friend Kye calls it:</p>



<figure><div>

</div><figcaption>The Dunning-GNUger Effect.</figcaption></figure>



<h2>What To Use Instead?</h2>



<p>To replace GPG, you want <a href="https://age-encryption.org/">age</a> and <a href="https://jedisct1.github.io/minisign/">minisign</a>.</p>



<p>To replace GnuTLS or libgcrypt, depending on what you’re using it for, you want one of the following: s2n, OpenSSL/LibreSSL, or Libsodium.</p>



<p>For embedded systems, BearSSL is a good options today and <a href="https://www.reddit.com/r/crypto/comments/hdc4o6/new_results_on_gimli_fullpermutation/fvmpnym/">libhydrogen v2</a> will be an attractive choice when it’s released.</p>



<hr>



<p>Header image, like the GnuNet logo <a href="https://commons.wikimedia.org/wiki/File:Official_logo_of_the_GNUnet_project.svg">found here</a>, is available under the&nbsp;<a href="https://en.wikipedia.org/wiki/en:Creative_Commons">Creative Commons</a>&nbsp;<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">Attribution-Share Alike 4.0 International</a>&nbsp;license.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/07/08/gnu-a-heuristic-for-bad-cryptography#resubmit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819964</guid>
            <pubDate>Mon, 13 Jul 2020 12:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Download 3D Capture Data]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819949">thread link</a>) | @harryhuge
<br/>
July 13, 2020 | https://blog.display.land/blog/how-to-download-3d-capture-data | <a href="https://web.archive.org/web/*/https://blog.display.land/blog/how-to-download-3d-capture-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="Top"><div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5dcdcdee9b5db73a7e73c483_display_land_logo_alt.png" srcset="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5dcdcdee9b5db73a7e73c483_display_land_logo_alt-p-500.png 500w, https://assets.website-files.com/5dcbeae998ba40131bdc3053/5dcdcdee9b5db73a7e73c483_display_land_logo_alt.png 729w" sizes="(max-width: 767px) 50vw, (max-width: 991px) 364px, 470px" alt=""></p></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>You can easily access and download your OBJ, GLTF, or PLY files as well as your capture videos directly from the Display.land app or any Display.land link on the web. ‍Please note, you may not be able to download the 3D mesh files on some older captures.</p><p><strong>To Download 3D Mesh in App:&nbsp;</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the share button on your capture</li><li>Click the Download Mesh icon</li><li>Select the file type you wish to download ( PLY, GLTF, or OBJ are the current options) and click the “Send Link” button next to your selection</li><li>Decide which method you want to use to share the download link (email, text message, etc)</li><li>Send the link</li><li>Download your files upon receipt as the links expire after one hour&nbsp;</li></ol><p>Downloads will contain the model for your full capture. Any cropping or 3d object additions will not be represented in your mesh download. If you are on iOS, the easiest way to share the file is through AirDrop.</p><p>‍</p><p>‍</p><figure id="w-node-e6c233e781d3-7dd620db"><p><img src="https://assets.website-files.com/5dcbef1d294b88f5b63cc7b8/5efe126ffeee90470943d2dd_VwNAsIKviU7T2bxBVE_uWBfk0WmAIht0mSsyYJahcIBktL0pJyDS0YggfcUNiqVasGBxwRPiLCroraCAGR3KE1-U1L2Tl8rYnCZDsRLxRzFn6Cb9W1O2h6l1eSd5l3PGF7JLsDZZ.gif" alt=""></p></figure><p><strong>To Download Videos in App</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the Share button on your capture</li><li>Click the Download Video button</li></ol><p><strong>To Download 3D Mesh and Videos on Desktop:&nbsp;</strong></p><ol role="list"><li>Share the link of any capture with yourself and open it in the browser</li><li>Click login and then enter the phone number or email you used to sign up for Display.land</li><li>You will be sent a one time code, enter the code to login&nbsp;</li><li>Click the download icon on the top right hand corner&nbsp;</li><li>Download the video or 3D mesh</li></ol><p>‍</p></div></div></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>It’s been a wild three months.</p><p>From graffiti filled streets in Spain to underground bunkers in Sausalito, subway stations in Tokyo to industrial kitchens in Texas, the <a href="http://display.land/" target="_blank">Display.land</a> community has been blowing our minds every morning by capturing, sharing and exploring each others’ spaces from around the world during our early access period.</p></div><p>Capture any space with the device you already own — from as small as a courtyard to entire city blocks</p><p><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb33727eef326_5dcf4fc0ef6ed980fcb238cf_SpaceLog.gif" alt=""></p><p>Edit insanely fast — changes you make to your spaces are rendered and saved in real time.</p><p><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb3d565eef327_image1.gif" alt=""><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb3434ceef32a_5dcf5532edfe6a4895625067_Crop.gif" alt=""><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb359d0eef32c_5dcf66bc0336825220e906e3_Notes2%202.gif" alt=""></p><p>Instantly share your spaces via web links and videos, or freely export them as 3D models</p><p><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb3b5c3eef329_5dcf6523b8df8173b2281bf2_MEshDownload.gif" alt=""></p><p>Explore the world and join a community of global explorers in 50 countries</p><p><img src="https://assets.website-files.com/5e204e3e5cacb34d33eef33e/5e204e3e5cacb3d3c2eef32b_5dcf61a3c5a7ed55b2508d7f_locations.gif" alt=""></p><p>We started U6 with the mission to unlock new ways for people to create and connect in the physical spaces they care about, such as our <a href="https://www.nbcbayarea.com/news/tech/SFMOMA-is-Putting-the-AR-in-Art-With-Augmented-Reality-Exhibits-490879581.html" target="_blank">PlaySFMOMA space</a> last year.</p><div><p>To create that experience, we captured the SF MOMA’s physical space in 3D using a commodity smartphone, edited and authored it remotely in a web browser, and allowed hundreds of people to browse and experience the sandbox together in real time from their own devices onsite in AR, and remotely via desktop and webVR browsers.</p><p>With today’s release, we’re beginning to put those same tools in everybody’s hands, with the goal of building and improving our roadmap in public with our community.</p></div><p><em>Unlocking a new digital canvas for creativity and shared experiences.</em></p><div><p><em>‍</em>Our goal is to grow <a href="http://display.land/" target="_blank">Display.land</a> into a destination where people can create, share and explore together in new, immersive and interactive ways.</p><p>We believe the best way to achieve this is by releasing often and publicly, supporting our earliest creators, and constantly increasing access to creative tools only previously available to high end gaming, graphics and 3D professionals. In the coming months, you can expect to see regular updates along this path.</p><p>‍<a href="http://display.land/" target="_blank">Display.land</a> is for those of us who see art in reality. If this sounds like something you’re interested in working on, shoot us a note! We’re working on some of the hardest challenges in computer vision, graphics and multiplayer networking <a href="http://ubiquity6.com/careers/" target="_blank">and are hiring actively.<p>‍</p></a>-Anjney &amp; Ankit<br>Co-founders, Ubiquity6<br>‍</p></div></div></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>Creators! Did you know that you can download any of your captures as a 3D model?&nbsp;</p><p>We currently support OBJ, GLTF, and PLY file formats, which make it possible to use captures from Display.land in Blender, Cinema4D, Unity, Unreal, Maya, and most other popular creative software applications.<br></p></div><p><img src="https://assets.website-files.com/5e2087d429083a49637cf369/5e2087d429083a4abd7cf39e_image5.gif" alt=""></p><div><p>To download the 3D mesh, just open one of your captures in a desktop web browser, and click the download button in the upper-right corner of the screen. You’ll need to be logged in to see it.<br>‍<br>If you are on iOS, the easiest way to open your capture in a browser is through AirDrop. You can AirDrop yourself the link to the desired capture by opening the Share Menu and pressing “More.” From there, a new menu will open giving you the option to airdrop the link.&nbsp;<br>‍<br>If you are on Android, we find it is easiest to email yourself the link. Open the Share Menu and press “More.” From there, choose email or whatever the best option is for you.</p><p>Note: Your download will contain the model for your full capture. Any cropping or 3d object additions will not be represented in your mesh download.</p></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5dd2cb02c54c887bca1c6e9f_image1.gif" alt=""></p><div><p>Once your 3D mesh has downloaded, this is where the magic begins. You now have the opportunity to create phenomenal artwork using captured physical reality. Try challenging the mundane by drawing in the absurd. </p><p>Or, experiment with contrasting elements. The opportunities are endless and the boundaries are limitless. Check out what our creators have made with Display.land below.</p></div></div><p><img src="https://assets.website-files.com/5e2087d429083a49637cf369/5e2087d429083a79467cf3a2_image9.gif" width="293" alt=""><img src="https://assets.website-files.com/5e2087d429083a49637cf369/5e2087d429083ae1467cf3a3_image11.gif" width="268" alt=""></p><p>We absolutely love to see what our Creators create using their Display.land meshes. In fact, we have an entire Discord channel dedicated to them! You can find this channel here: <a href="https://discord.gg/b2vxQpu">https://discord.gg/b2vxQpu</a>.<br>We can’t wait for you to join and to see how Display.land has inspired you. ✨<br></p></div></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>You can easily access and download your OBJ, GLTF, or PLY files as well as your capture videos directly from the Display.land app or any Display.land link on the web. ‍Please note, you may not be able to download the 3D mesh files on some older captures.</p><p><strong>To Download 3D Mesh in App:&nbsp;</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the share button on your capture</li><li>Click the Download Mesh icon</li><li>Select the file type you wish to download ( PLY, GLTF, or OBJ are the current options) and click the “Send Link” button next to your selection</li><li>Decide which method you want to use to share the download link (email, text message, etc)</li><li>Send the link</li><li>Download your files upon receipt as the links expire after one hour&nbsp;</li></ol><p>Downloads will contain the model for your full capture. Any cropping or 3d object additions will not be represented in your mesh download. If you are on iOS, the easiest way to share the file is through AirDrop.</p><p>‍</p><p>‍</p><figure id="w-node-e6c233e781d3-7dd620db"><p><img src="https://assets.website-files.com/5dcbef1d294b88f5b63cc7b8/5efe126ffeee90470943d2dd_VwNAsIKviU7T2bxBVE_uWBfk0WmAIht0mSsyYJahcIBktL0pJyDS0YggfcUNiqVasGBxwRPiLCroraCAGR3KE1-U1L2Tl8rYnCZDsRLxRzFn6Cb9W1O2h6l1eSd5l3PGF7JLsDZZ.gif" alt=""></p></figure><p><strong>To Download Videos in App</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the Share button on your capture</li><li>Click the Download Video button</li></ol><p><strong>To Download 3D Mesh and Videos on Desktop:&nbsp;</strong></p><ol role="list"><li>Share the link of any capture with yourself and open it in the browser</li><li>Click login and then enter the phone number or email you used to sign up for Display.land</li><li>You will be sent a one time code, enter the code to login&nbsp;</li><li>Click the download icon on the top right hand corner&nbsp;</li><li>Download the video or 3D mesh</li></ol><p>‍</p></div></div></div></div></div><div><div><div><p><h2>How to Download 3D Capture Data</h2></p><div><div><p>You can easily access and download your OBJ, GLTF, or PLY files as well as your capture videos directly from the Display.land app or any Display.land link on the web. ‍Please note, you may not be able to download the 3D mesh files on some older captures.</p><p><strong>To Download 3D Mesh in App:&nbsp;</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the share button on your capture</li><li>Click the Download Mesh icon</li><li>Select the file type you wish to download ( PLY, GLTF, or OBJ are the current options) and click the “Send Link” button next to your selection</li><li>Decide which method you want to use to share the download link (email, text message, etc)</li><li>Send the link</li><li>Download your files upon receipt as the links expire after one hour&nbsp;</li></ol><p>Downloads will contain the model for your full capture. Any cropping or 3d object additions will not be represented in your mesh download. If you are on iOS, the easiest way to share the file is through AirDrop.</p><p>‍</p><p>‍</p><figure id="w-node-e6c233e781d3-7dd620db"><p><img src="https://assets.website-files.com/5dcbef1d294b88f5b63cc7b8/5efe126ffeee90470943d2dd_VwNAsIKviU7T2bxBVE_uWBfk0WmAIht0mSsyYJahcIBktL0pJyDS0YggfcUNiqVasGBxwRPiLCroraCAGR3KE1-U1L2Tl8rYnCZDsRLxRzFn6Cb9W1O2h6l1eSd5l3PGF7JLsDZZ.gif" alt=""></p></figure><p><strong>To Download Videos in App</strong></p><p>Once you’ve created and published your capture (Public or Personal):</p><ol role="list"><li>Click the Share button on your capture</li><li>Click the Download Video button</li></ol><p><strong>To Download 3D Mesh and Videos on Desktop:&nbsp;</strong></p><ol role="list"><li>Share the link of any capture with yourself and open it in the browser</li><li>Click login and then enter the phone number or email you used to sign up for Display.land</li><li>You will be sent a one time code, enter the code to login&nbsp;</li><li>Click the download icon on the top right hand corner&nbsp;</li><li>Download the video or 3D mesh</li></ol><p>‍</p></div><div><div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf1c35d8bac609f16a41d_image3.png" alt=""></p></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf2a0dec349712cccc551_image10.png" alt=""></p><div><h4>+ CLIP =</h4><p>Clips your trailer so you can insert more than one series of frames into your trailer</p></div></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf1c4c1617c1da77921f5_image5.png" alt=""></p><div><h4>+ DELETE =</h4><p>Undoes the last action or series of actions that you took</p></div></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf29fb26089c6ab3fafac_image7.png" alt=""></p><div><h4>CLEAR =</h4><p>Clears everything you have done (you can not undo this action, so be careful!)</p></div></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf1c4dec34956f7ccb968_image6.png" alt=""></p><div><h4>PLAY =</h4><p>At any time during your custom trailer creation, you can hit the play button to see how your trailer is coming together.</p></div></div><div><p><img src="https://assets.website-files.com/5dcbeae998ba40131bdc3053/5e4bf29fd87988654de420bd_image8.png" alt=""></p><div><h4>SAVE (only shows up once you hit the play button to preview your trailer) =</h4><p>Saves the progress on your freshly created custom trailer!</p></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://blog.display.land/blog/how-to-download-3d-capture-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819949</guid>
            <pubDate>Mon, 13 Jul 2020 12:21:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Douglas Mason: How to Build ML Solutions for Twitter, Pinterest and Amazon Music]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819921">thread link</a>) | @FHMS
<br/>
July 13, 2020 | https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We caught up with <a href="https://www.linkedin.com/in/douglas-mason-9a500713/"><strong>Douglas Mason</strong></a>, data scientist and CEO of <a href="https://www.koyotescience.com/">Koyote Science</a>, where he is building machine learning models to predict COVID-19 outbreaks. He freely shared his wisdom and lessons he has learned from over a decade of data science work, ranging from his PhD at Harvard to his time at large companies such as Pinterest, Twitter, and AWS (Amazon).</p><h2><strong>Douglas’s background</strong></h2><p>Douglas took a unique path to becoming a data scientist. Although computers were always part of his household growing up, he thought they were boring, and he told his family he would “never study computer science.”</p><p>Instead, Douglas went to USC to study filmmaking, thinking he’d follow his dream of becoming a film director. Soon, he realized that filmmaking school wasn’t all he’d imagined it would be, and he took up classical guitar instead. From there, he accidentally discovered a passion for theoretical physics, which he found fascinating (and which paid more than guitar playing).</p><p>Not long after, Douglas discovered his interest in data science and climbed the ranks until he was heading engineering and data science teams at Twitter, Pinterest, and AWS. He describes working in the field as feeling like he’s living in a science fiction film.</p><blockquote>“When I work on that kind of stuff, I feel like Doctor Strange — as if I’m in the Multiverse. You actually get to live this Rick and Morty parallel-universe life.”</blockquote><p>But Douglas wasn’t content with using his expertise to improve revenue at large corporations, so he went on to found his own business, Koyote Science. He’s currently focused on building COVID-19 models to predict outbreaks.</p><h2><strong>Lessons learned from shipping machine learning projects</strong></h2><p>Douglas’s success hasn’t come without some hard-earned lessons. He told us about some of the challenges he’s seen across many of the teams and projects he’s worked on.</p><h3><strong>Lesson 1: Use machine learning to work with users instead of taking over&nbsp;</strong></h3><p>At Twitter, Douglas worked on a feature called “who to follow.” This gives Twitter users personalized recommendations about which accounts might be interesting for them. As a data scientist, Douglas discovered that people used this feature a lot. At first, it seemed great — people were following nearly everyone it recommended. But in the longer term, people who used this feature <strong>visited Twitter less</strong>.&nbsp;</p><p>Their feeds were filled with tweets chosen <strong>by an algorithm</strong>, rather than tweets from people they chose<strong> </strong>themselves — and there were just too many of them.</p><p>By reducing<strong> </strong>the number of “who to follow” recommendations, Douglas improved <strong>long-term</strong> engagement.</p><p>It’s common knowledge that long-term and short-term goals often conflict, but Douglas discovered a deeper lesson here. As machine learning solutions become more capable, it’s often tempting to use them to do too much. This is almost always a mistake. Douglas says:</p><blockquote>“I aim to build products that work with the user rather than trying to take over from the user.”</blockquote><p>AI as depicted in science fiction — with human-level intelligence — is probably to blame for the fact that many people try to <strong>do too much </strong>with machine learning. In many cases, it’s best used to <strong>augment </strong>human actions rather than replace them.</p><h3><strong>Lesson 2: Data pipelines and good engineering are more important than math and algorithms</strong></h3><p>People get very excited about <strong>new machine learning algorithms</strong>. First we had neural networks (NNs), then convolutional neural networks (CNNs), then generative adversarial networks (GANs), transformers, and more. Algorithms are fun and exciting to talk about and explore.</p><p>But Douglas, a self-confessed math nerd, has learned that the math and algorithms tend to get far too much attention, while real success comes from <strong>good data, good engineering, focusing on the customer’s problem, </strong>and <strong>not getting trapped in the math.</strong> He says:</p><blockquote>“It's very, very rare for the algorithm to make the difference. It's almost always the data pipeline. In my work, I have been able to reduce errors by 90% with a data pipeline, compared to 75% with a better algorithm. And yet everyone wants to talk to me about the algorithm, but no one wants to talk about the data pipeline.”</blockquote><p>We use metaphors that associate machine learning algorithms with neuroscientists and data pipelines with plumbing, so it’s not surprising which one grabs popular attention. Douglas found success by focusing on the less glamorous aspects of machine learning. In most cases, deciding <strong>what data to use </strong>and <strong>how to present it to the algorithm</strong> is more important than the algorithm itself.</p><h4>Focus on the customer’s goals</h4><p>Many “AI startups” today talk far more about <strong>the solutions they provide</strong> than the <strong>problems they solve</strong>, and Douglas has learned to maintain a laser focus on customer goals. Sometimes this means pulling himself away from the more enticing theoretical aspects of machine learning. He says:&nbsp;</p><blockquote>“As a mathematician, I love all the nuances of the math, and easily get lost in it. But the reality is that there's an infinite amount of math out there to learn. It's not feasible to lock myself in my room and learn all the math before I focus on customer goals.”</blockquote><p>The truth that many data scientists don’t want to hear is that successful machine learning solutions are not usually about creating something new, powerful, and exciting. More often, seeing problems from the correct angle and using tried and tested approaches is what you need.</p><h4>Work with and learn from experienced engineers</h4><p>Douglas has personally engineered many successful machine learning solutions and led teams of software engineers, but he remains modest about his engineering ability and emphasizes the <a href="https://datarevenue.com/en-blog/hiring-machine-learning-engineers-instead-of-data-scientists">importance of <strong>solid engineering</strong></a>.</p><blockquote>“At Amazon, I let the engineers do as much as possible, because they're better than me at engineering. I would love to give you another answer, but they're efficient, they're thoughtful, they've seen these structures before, so they know about implementation details.”</blockquote><p>It’s not all smooth sailing though. Douglas acknowledges the difficulties of getting different experts to work with each other, especially when highly technical people tend to have very strong opinions about tiny decisions.</p><p>The best way he’s found to get everyone on the same page is by constantly releasing Minimal Viable Products (MVPs), which takes us to our next lesson.</p><h3><strong>Lesson 3: Always build Minimum Viable Products (MVPs)</strong></h3><p>Douglas swears by MVPs, which demonstrate core pieces of a solution, even if many of the features are missing. When developing a machine learning solution, he’ll aim to deliver a new MVP <strong>every week.</strong></p><p>He uses these to:&nbsp;</p><ul role="list"><li><strong>Avoid traps: </strong>If a project is taking too long, the difficulty of building even an MVP can be used to argue that the project should be cut early, before years of effort are wasted. Douglas says:</li></ul><p>“If something ends up being way harder and I keep doing MVPs and never reach the goals, then that gives us information about the difficulty of what we're attempting to do.”</p><ul role="list"><li><strong>Communicate</strong>: Both technical and non-technical people tend to better understand things they can see and use, rather than abstract ideas.</li></ul><p>“People's response to an abstract concept of something is often completely different to their response when they see something real. That's why I'm always putting out MVPs. People who are looking from a higher-level perspective can gain the required intuition to give me feedback.”</p><p>It’s better to have to trash two weeks of work than two months, and MVPs can help with this.</p><p>MVPs have other benefits too. By releasing stripped-down versions of a solution, Douglas often discovers that less is more.</p><blockquote>“What you end up delivering is often much simpler than the thing you originally intended to do, but it's refined.”</blockquote><p>Of course, customers are sometimes unhappy when it turns out that the best solution was the simplest one. Douglas compares building machine learning solutions to creating art: it’s about the time that went into development, not the effort required for the final product.</p><blockquote>“There’s a classic Zen story about a king who hires an artist. The artist works for a year, but then paints the final painting in only three seconds. When the king complains, the artist says, ‘Oh, I spent a year trying to paint much harder things.’”</blockquote><p>MVPs keep you open to finding a <strong>better, simpler </strong>solution, even late in the development process, and it’s important to stay agile so you can pivot to these better solutions if necessary.</p><p>People often think something has to be <strong>complicated </strong>in order to be <strong>powerful</strong>,<strong> </strong>but in fact the opposite is often true.</p><h3><strong>Lesson 4: Control and precision are more important than size and power</strong></h3><p>Large machine learning models, such as GPT-3, are exciting and often make their way into headline news. But Douglas compares large models to early (failed) attempts to build planes. These planes competed against the famous, successful plane built by the Wright Brothers. What made them different? The Wright Brothers focused on <strong>control</strong>,<strong> </strong>while their competitors were going for <strong>size and power.</strong></p><blockquote>“What the Wright brothers did that was so ingenious was that they didn’t go for bigger engines. They were bicycle mechanics. They didn't even use powerful engines. And instead, what they focused on was control.”</blockquote><p>This is similar to machine learning models. As Douglas says:&nbsp;</p><blockquote>“We made the biggest model that does all this stuff. But then people ask, ‘How do I interpret this stuff?’ ‘How do I control it?’ ‘How do I make sure that my models don't go off the rails?’”</blockquote><p>Large machine learning models might often be more powerful, but unless they solve real problems, they’re not useful. If a model produces amazing results <strong>unpredictably</strong> and only <strong>some of the time</strong>, that’s not useful. If a model produces accurate results but we don’t <strong>understand why</strong> and can’t be sure the results will <strong>always be accurate</strong>, then that’s also not useful.</p><p>Instead, smaller, simpler, and arguably less powerful models that offer more <strong>interpretability</strong> and <strong>consistency</strong> are more valuable in nearly every case. Just like with flying, we need to be able to steer and to land, not just to go fast.</p><h2><strong>Shipping machine learning projects …</strong></h2></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects">https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/douglas-mason-how-to-ship-machine-learning-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819921</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards a Data Delivery Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819918">thread link</a>) | @mildbyte
<br/>
July 13, 2020 | https://www.splitgraph.com/blog/data-delivery-network | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/data-delivery-network">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#how-content-delivery-networks-work" as="#how-content-delivery-networks-work">How content delivery networks work</a></li><li><a href="#why-do-you-need-a-backend-anyway" as="#why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</a><ol><li><a href="#alternatives-to-crud-services" as="#alternatives-to-crud-services">Alternatives to CRUD services</a></li><li><a href="#splitgraphs-architecture" as="#splitgraphs-architecture">Splitgraph's architecture</a></li></ol></li><li><a href="#data-delivery-network" as="#data-delivery-network">Data delivery network</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p>Serverless and edge computing have allowed application developers to bring their applications closer to the end user.</p><p>Instead of maintaining a group of servers in a single location, developers can let companies like Cloudflare, Fastly or Akamai handle their content delivery.</p><p>With <a href="https://en.wikipedia.org/wiki/Function_as_a_service" as="https://en.wikipedia.org/wiki/Function_as_a_service">Function as a service</a>, companies pay for what they use. They can avoid having to provision a server that stays idle most of the time.</p><p>In this article, we want to talk about these trends and how we can apply them to databases. We'll also talk about our decision to make the API for our Splitgraph registry work over a public SQL connection. We'll use this experience to propose the idea of a <strong>data delivery network</strong>.</p><section><h2 id="how-content-delivery-networks-work">How content delivery networks work</h2><p>Content delivery networks provide a straightforward way to scale a read-only HTTP layer. They use existing HTTP cache semantics like the Cache-Control header. The developer only needs to point their DNS records to use the CDN's nameservers. The CDN handles everything else for them. It has points of presence around the world and peering agreements with other ISPs. It can selectively cache data, handle DDoS protection and offer extra services on top.</p><p>The value proposition behind edge computing is simple. For a lot of companies, scaling compute is not their core competency. They can spend time and money provisioning servers and configuring something like Varnish. Or, they can use services that will handle scaling and caching for them.</p><p>However, applications still need to run SQL queries. A CDN doesn't completely help an application that performs client-side rendering. The database becomes the next performance bottleneck in scaling a service.</p><p>There are many ways to scale a database, for example, replication or sharding. But again, this requires specialist knowledge about a database that is easy to get wrong.</p></section><section><h2 id="why-do-you-need-a-backend-anyway">Why do you need a backend, anyway?</h2><p>Let's change gears and consider a classic Web application. It consists of the frontend, the backend and the database.</p><p>There are several purposes that a backend serves:</p><ul><li><p><strong>Business logic</strong>. The backend converts higher level API calls into low-level SQL queries. It prepares data for presentation and writes it back when needed.</p></li><li><p><strong>Authorization</strong>. The backend acts as a security barrier, validating API calls. This is necessary because the frontend is running on the user's machine: the client is not trusted.</p></li><li><p><strong>Multiplexing</strong>. A database connection has a larger overhead than an HTTP connection. A backend can shunt hundreds of simultaneous clients over to a few database connections.</p></li></ul><section><h3 id="alternatives-to-crud-services">Alternatives to CRUD services</h3><p>One big issue with writing RESTful backends is that there's a lot of boilerplate. The programmer has to write very similar code to handle every action. They have to care of validation, typechecking and handling edge cases.</p><p>Libraries like <a href="https://postgrest.org/en/latest/" as="https://postgrest.org/en/latest/">PostgREST</a> and <a href="https://www.graphile.org/postgraphile/" as="https://www.graphile.org/postgraphile/">Postgraphile</a> have helped developers decrease iteration times. They introspect database schemas and generate REST and GraphQL APIs for them.</p><p>PostgREST and Postgraphile perform their authorization using database methods like <a href="https://postgrest.org/en/v7.0.0/auth.html" as="https://postgrest.org/en/v7.0.0/auth.html">row level security</a>. In essence, they decrease the size of the <a href="https://en.wikipedia.org/wiki/Trusted_computing_base" as="https://en.wikipedia.org/wiki/Trusted_computing_base">"trusted computing base"</a>.</p><p>Often, services that use these kinds of tools don't even have a separate backend. Client side code can call the automatically generated GraphQL/REST API directly.</p></section><section><h3 id="splitgraphs-architecture">Splitgraph's architecture</h3><p>The database can perform a lot of work that the backend does more quickly and more efficiently.</p><p>We use this idea in the API for the Splitgraph registry that allows you to push and pull <a href="https://www.splitgraph.com/docs/concepts/images">data images</a>. A <a href="https://www.splitgraph.com/docs/architecture/sgr-client">Splitgraph client</a> can access it over a normal PostgreSQL connection to <code>postgresql://data.splitgraph.com:5432/sgregistry</code>.</p><p>Our API implements all <strong>business logic</strong> as PostgreSQL functions. This has a few immediate advantages:</p><ul><li>Lets PostgreSQL precompile them</li><li>Avoids an extra hop from the backend, decreasing latency</li><li>Makes basic validation and type checking trivial. It's not possible to call a function with a wrong number of arguments or different types.</li></ul><p>For more complex logic, we wrote it in higher-level languages like <a href="https://www.postgresql.org/docs/current/plpython.html" as="https://www.postgresql.org/docs/current/plpython.html">PL/Python</a> or PL/Lua. PostgreSQL even supports languages like C or JavaScript.</p><p>We solved the problem of <strong>multiplexing and authorization</strong> by adding <a href="https://www.pgbouncer.org/" as="https://www.pgbouncer.org/">PgBouncer</a>, a connection pooler, in front of our database. Our fork of PgBouncer injects a signed cookie into every transaction as a local variable. Downstream procedures validate this cookie for authentication and authorization. This lets us decouple PostgreSQL users from application users. Multiple inbound sessions can use the same connection.</p><p>Our fork of PgBouncer even inspects queries on the fly and filters them. This makes sure that the client can only call Splitgraph SQL API functions.</p><p>For the web frontend at <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com/">www.splitgraph.com</a>, we use Postgraphile. Besides not having to write an extra API server, it lets us generate TypeScript client code.</p></section></section><section><h2 id="data-delivery-network">Data delivery network</h2><p>We can apply these ideas and concepts to the problem of building a <strong>"data delivery network"</strong>. Such a network would completely abstract away all the issues around making sure that data is available at the edge. It can also provide plenty of other useful services.</p><p>Here's a quick sketch of what a DDN's administration interface would look like:</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/blog/images/20200713-data-delivery-network/admin-panel.png"></p><p>To use a DDN, a developer would create a read-only account on their database and give the DDN the credentials. It will then make a few services available:</p><p>The DDN will create an <strong>SQL endpoint</strong>. Any existing SQL client or application will be able to connect to it and run queries.</p><p>Besides SQL, the DDN will also be able to introspect the origin database and provide <strong>REST and GraphQL API endpoints</strong>. A client, running in the user's web browser, can use these endpoints instead of a backend server.</p><p>The DDN will be able to <strong>cache</strong> read-only SQL transactions with configurable policies. It will only forward the query to the origin database if there's a cache miss or expiry.</p><p>The client code doesn't need to be trusted. The DDN can intercept and <strong>firewall</strong> queries or <strong>rate limit</strong> them. To simplify migrations, the DDN can <strong>rewrite</strong> queries on the fly before forwarding them.</p><p>The DDN's work doesn't need to stop at handling queries. It can also manage <strong>data imports and exports</strong>. For example, it can make data from other services available to clients. Or, it can export data to Google Sheets or a data warehouse.</p><p>In the case of Splitgraph, we envision you being able to even run a <code>JOIN</code> across a public Splitgraph image and your private data.</p></section><section><h2 id="conclusion">Conclusion</h2><p>The database is the next frontier of serverless and edge computing. One of Splitgraph's goals is building a data delivery network to handle these problems.</p><p>If you're interested in learning more about Splitgraph, you can check our <a href="https://www.splitgraph.com/docs/getting-started/frequently-asked-questions">frequently asked questions</a> section, follow our <a href="https://www.splitgraph.com/docs/getting-started/five-minute-demo">quick start guide</a> or visit our <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com">website</a>.</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/data-delivery-network</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819918</guid>
            <pubDate>Mon, 13 Jul 2020 12:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp GUI Toolkits]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819896">thread link</a>) | @ogogmad
<br/>
July 13, 2020 | https://lispcookbook.github.io/cl-cookbook/gui.html | <a href="https://web.archive.org/web/*/https://lispcookbook.github.io/cl-cookbook/gui.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" <p=""><p>Lisp has a long and rich history and so does the development of
Graphical User Interfaces in Lisp. In fact, the first GUI builder was
written in Lisp (and sold to Apple. It is now Interface Builder).</p>

<p>Lisp is also famous and unrivalled for its interactive development
capabilities, a feature even more worth having to develop GUI
applications. Can you imagine compiling one function and seeing your
GUI update instantly? We can do this with many GUI frameworks today,
even though the details differ from one to another.</p>

<p>Finally, a key part in building software is how to build it and ship
it to users. Here also, we can build self-contained binaries, for
the three main operating systems, that users can run with a double
click.</p>

<p>We aim here to give you the relevant information to help you choose
the right GUI framework and to put you on tracks. Don’t hesitate to
<a href="https://github.com/LispCookbook/cl-cookbook/issues/">contribute</a>, to
send more examples and to furnish the upstream documentations.</p>



<p>In this recipe, we’ll present the following GUI toolkits:</p>

<ul>
  <li><a href="https://www.tcl.tk/">Tk</a> with <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a></li>
  <li><a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a> with <a href="https://github.com/Shinmera/qtools">Qtools</a></li>
  <li><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> with <a href="https://github.com/lispnik/iup/">lispnik/iup</a></li>
  <li><a href="https://www.gtk.org/">Gtk3</a> with <a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a></li>
  <li><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> with <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a></li>
</ul>

<p>In addition, you might want to have a look to:</p>

<ul>
  <li>the <a href="http://www.lispworks.com/products/capi.html">CAPI</a> toolkit (Common Application Programming Interface),
which is proprietary and made by LispWorks. It is a complete and cross-platform
toolkit (Windows, Gtk+, Cocoa), very praised by its users. LispWorks
also has <a href="http://www.lispworks.com/products/lw4mr.html">iOS and Android
runtimes</a>. Example
software built with CAPI include <a href="https://scorecloud.com/">ScoreCloud</a>. It is possible to
try it with the LispWorks free demo.</li>
  <li><a href="https://franz.com/products/allegro-common-lisp/acl_ide.lhtml">Allegro CL’s IDE and Common Graphics windowing system</a> (proprietary): Allegro’s IDE is a general environment for developing applications. It works in concert with a windowing system called Common Graphics. The IDE is available for Allegro CL’s Microsoft Windows, on x86 Linux platforms, and on the Mac.</li>
  <li><a href="https://ccl.clozure.com/docs/ccl.html#the-objective-c-bridge">CCL’s built-in Cocoa
interface</a>,
used to build applications such as <a href="https://opusmodus.com/">Opusmodus</a>.</li>
  <li><a href="https://github.com/plkrueger/CocoaInterface/">CocoaInterface</a>, a
Cocoa interface for Clozure Common Lisp. Build Cocoa user interface
windows dynamically using Lisp code and bypass the typical Xcode
processes.</li>
  <li><a href="https://common-lisp.net/project/mcclim/">McCLIM</a> and <a href="https://github.com/earl-ducaine/cl-garnet">Garnet</a> are toolkit in 100% Common Lisp. McClim even has <a href="https://techfak.de/~jmoringe/mcclim-broadway-7.ogv">a prototype</a> running in the browser with the Broadway protocol and Garnet has an ongoing interface to Gtk.</li>
  <li><a href="https://github.com/Shirakumo/alloy">Alloy</a>, another very new toolkit in 100% Common Lisp, used for example in the <a href="https://github.com/shinmera/kandria">Kandria</a> game.</li>
  <li><a href="https://notabug.org/cage/nodgui">nodgui</a>, a fork of Ltk, with syntax sugar and additional widgets.</li>
  <li><a href="https://gitlab.com/eql">eql, eql5, eql5-android</a>, embedded Qt4 and Qt5 Lisp, embedded in ECL, embeddable in Qt. Port of EQL5 to the Android platform.</li>
  <li>this <a href="https://github.com/defunkydrummer/abcl-jazz">demo using Java Swing from ABCL</a></li>
  <li><a href="https://github.com/mifpasoti/Gtk-Demos">examples of using Gtk without C files with SBCL</a>, as well as GTK-server.</li>
  <li>and, last but not least, <a href="http://ceramic.github.io/">Ceramic</a>, to ship a cross-platform web app with Electron.</li>
</ul>

<p>as well as the other ones listed on <a href="https://github.com/CodyReichert/awesome-cl#Gui">awesome-cl#gui</a> and <a href="https://www.cliki.net/GUI">Cliki</a>.</p>

<h2 id="tk-ltk">Tk (Ltk)</h2>

<p><a href="https://www.tcl.tk/">Tk</a> (or Tcl/Tk, where Tcl is the programming language) has the
infamous reputation of having an outdated look. This is not (so) true
anymore since its version 8 of 1997 (!). It is probably better than
you think:</p>

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/gui/ltk-on-macos.png" alt=""></p>

<p>Tk doesn’t have a great choice of widgets, but it has a useful canvas,
and it has a couple of unique features: we can develop a graphical
interface <strong>fully interactively</strong> and we can run the GUI <strong>remotely</strong>
from the core app.</p>

<p>So, Tk isn’t fancy, but it is an used and proven GUI toolkit (and
programming language) still used in the industry. It can be a great
choice to quickly create simple GUIs, to leverage its ease of deployment, or
when stability is required.</p>

<p>The Lisp binding is <a href="http://www.peter-herth.de/ltk/ltkdoc/">Ltk</a>.</p>

<ul>
  <li><strong>Written in</strong>: Tcl</li>
  <li>
    <p><strong>Portability</strong>: cross-platform (Windows, macOS, Linux).</p>
  </li>
  <li>
    <p><strong>Widgets</strong>: this is not the fort of Tk. It has a <strong>small set</strong> of
default widgets, and misses important ones, for example a calendar. We
can find some in extensions (such as in <strong>Nodgui</strong>), but they don’t
feel native, at all.</p>
  </li>
  <li>
    <p><strong>Interactive development</strong>: very much.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no</p>
  </li>
  <li><strong>Other features</strong>:
    <ul>
      <li><strong>remote execution</strong>: the connection between Lisp and Tcl/Tk is
done via a stream. It is thus possible to run the Lisp program on
one computer, and to display the GUI on another one. The only
thing required on the client computer is tcl/tk installed and the
remote.tcl script. See <a href="http://www.peter-herth.de/ltk/ltkdoc/node46.html">Ltk-remote</a>.</li>
    </ul>
  </li>
  <li><strong>Bindings documentation</strong>: short but complete. Nodgui too.</li>
  <li><strong>Bindings stability</strong>: very stable</li>
  <li><strong>Bindings activity</strong>: low to non-existent.</li>
  <li><strong>Licence</strong>: Tcl/Tk is BSD-style, Ltk is LGPL.</li>
  <li>Example applications:
    <ul>
      <li><a href="https://notabug.org/cage/fulci/">Fulci</a> - a program to organise your movie collections.</li>
      <li><a href="https://github.com/mijohnson99/ltk-small-games">Ltk small games</a> - snake and tic-tac-toe.</li>
      <li><a href="https://github.com/vindarel/cl-torrents">cl-torrents</a> - searching torrents on popular trackers. CLI, readline and a simple Tk GUI.</li>
    </ul>
  </li>
</ul>

<p><strong>List of widgets</strong></p>

<p>(please don’t suppose the list is exhaustive)</p>

<pre><code>Button Canvas Check-button Entry Frame Label Labelframe Listbox
Menu Menubutton Message
Paned-window
Radio-button Scale
Scrollbar Spinbox Text
Toplevel Widget Canvas

Ltk-megawidgets:
    progress
    history-entry
    menu-entry
</code></pre>

<p>Nodgui adds:</p>

<pre><code>treelist tooltip searchable-listbox date-picker calendar autocomplete-listbox
password-entry progress-bar-star notify-window
dot-plot bar-chart equalizer-bar
swap-list
</code></pre>



<p>Do we need to present Qt and <a href="https://doc.qt.io/archives/qt-4.8/index.html">Qt4</a>? Qt is huge and contains
everything and the kitchen sink. Qt not only provides UI widgets, but
numerous other layers (networking, D-BUS…).</p>

<p>Qt is free for open-source software, however you’ll want to check the
conditions to ship proprietary ones.</p>

<p>The <a href="https://github.com/Shinmera/qtools">Qtools</a> bindings target Qt4. The Qt5 Lisp bindings are
yet to be created.</p>

<p>A companion library for Qtools, that you’ll want to check out once you
made your first Qtool application, is
<a href="https://github.com/Shinmera/qtools-ui">Qtools-ui</a>, a collection of
useful widgets and pre-made components. It comes with short
<a href="https://www.youtube.com/playlist?list=PLkDl6Irujx9Mh3BWdBmt4JtIrwYgihTWp">demonstrations
videos</a>.</p>

<!-- possible future: gobject-introspection -->

<ul>
  <li><strong>Framework written in</strong>: C++</li>
  <li><strong>Framework Portability</strong>: multi-platform, Android, embedded systems, WASM.</li>
  <li>
    <p><strong>Bindings Portability</strong>: Qtools runs on x86 desktop platforms on Windows, macOS and GNU/Linux.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: Web browser, a lot more.</p>
  </li>
  <li><strong>Bindings documentation</strong>: lengthy explanations, a few examples. Prior Qt knowledge is required.</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: active</li>
  <li><strong>Qt Licence</strong>: both commercial and open source licences.</li>
  <li>Example applications:
    <ul>
      <li>https://github.com/Shinmera/qtools/tree/master/examples</li>
      <li>https://github.com/Shirakumo/lionchat</li>
      <li>https://github.com/shinmera/halftone - a simple image viewer</li>
    </ul>
  </li>
</ul>

<h2 id="gtk3-cl-cffi-gtk">Gtk+3 (cl-cffi-gtk)</h2>

<p><a href="https://www.gtk.org/">Gtk+3</a> is the primary library used to build <a href="https://www.gnome.org/">GNOME</a>
applications. Its (currently most advanced) lisp bindings is
<a href="https://github.com/Ferada/cl-cffi-gtk/">cl-cffi-gtk</a>. While primarily created for GNU/Linux, Gtk
works fine under macOS and can now also be used on Windows.</p>

<ul>
  <li><strong>Framework written in</strong>: C</li>
  <li>
    <p><strong>Portability</strong>: GNU/Linux and macOS, also Windows.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: large.</p>
  </li>
  <li><strong>Graphical builder</strong>: yes: Glade.</li>
  <li>
    <p><strong>Other features</strong>: web browser (WebKitGTK)</p>
  </li>
  <li><strong>Bindings documentation</strong>: very good: http://www.crategus.com/books/cl-gtk/gtk-tutorial.html</li>
  <li><strong>Bindings stability</strong>: stable</li>
  <li><strong>Bindings activity</strong>: low activity, active development.</li>
  <li><strong>Licence</strong>: LGPL</li>
  <li>Example applications:
    <ul>
      <li>an <a href="https://github.com/ralph-schleicher/atmosphere-calculator">Atmosphere Calculator</a>, built with Glade.</li>
    </ul>
  </li>
</ul>

<h2 id="iup-lispnikiup">IUP (lispnik/IUP)</h2>

<p><a href="http://webserver2.tecgraf.puc-rio.br/iup/">IUP</a> is a cross-platform GUI toolkit actively developed
at the PUC university of Rio de Janeiro, Brazil. It uses <strong>native
controls</strong>: the Windows API for Windows, Gtk3 for GNU/Linux. At the
time of writing, it has a Cocoa port in the works (as well as iOS,
Android and WASM ones). A particularity of IUP is its <strong>small API</strong>.</p>

<p>The Lisp bindings are <a href="https://github.com/lispnik/iup/">lispnik/iup</a>. They are nicely
done in that they are automatically generated from the C sources. They
can follow new IUP versions with a minimal work and the required steps
are documented. All this gives us good guarantee over the bus
factor.</p>

<p>IUP stands as a great solution in between Tk and Gtk or Qt.</p>

<ul>
  <li><strong>Framework written in</strong>: C (official API also in Lua and LED)</li>
  <li>
    <p><strong>Portability</strong>: Windows and Linux, work started for
Cocoa, iOS, Android, WASM.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: medium.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: yes: <a href="http://webserver2.tecgraf.puc-rio.br/iup/en/iupvisualled.html">IupVisualLED</a></p>
  </li>
  <li>
    <p><strong>Other features</strong>: OpenGL, Web browser (WebKitGTK on GNU/Linux), plotting, Scintilla text editor</p>
  </li>
  <li><strong>Bindings documentation</strong>: good examples and good readme, otherwise low.</li>
  <li><strong>Bindings stability</strong>: alpha (but fully generated and working nicely).</li>
  <li><strong>Bindings activity</strong>: low but steady, and reactive to new IUP versions.</li>
  <li><strong>Licence</strong>: IUP and the bindings are MIT licenced.</li>
</ul>

<p><strong>List of widgets</strong></p>

<pre><code>Radio, Tabs, FlatTabs, ScrollBox, DetachBox,
Button, FlatButton, DropButton, Calendar, Canvas, Colorbar, ColorBrowser, DatePick, Dial, Gauge, Label, FlatLabel,
FlatSeparator, Link, List, FlatList, ProgressBar, Spin, Text, Toggle, Tree, Val,
listDialog, Alarm, Color, Message, Font, Scintilla, file-dialog…
Cells, Matrix, MatrixEx, MatrixList,
GLCanvas, Plot, MglPlot, OleControl, WebBrowser (WebKit/Gtk+)…
drag-and-drop
</code></pre>

<!-- editor's note: found missing a list view with columns. -->

<p><img src="https://lispcookbook.github.io/cl-cookbook/assets/iup-demo.png" alt=""></p>

<h2 id="nuklear-bodge-nuklear">Nuklear (Bodge-Nuklear)</h2>

<p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a small <a href="https://en.wikipedia.org/wiki/Immediate_mode_GUI">immediate-mode</a> GUI toolkit:</p>

<blockquote>
  <p><a href="https://github.com/Immediate-Mode-UI/Nuklear">Nuklear</a> is a minimal-state, immediate-mode graphical user interface toolkit written in ANSI C and licensed under public domain. It was designed as a simple embeddable user interface for application and does not have any dependencies, a default render backend or OS window/input handling but instead provides a highly modular, library-based approach, with simple input state for input and draw commands describing primitive shapes as output. So instead of providing a layered library that tries to abstract over a number of platform and render backends, it focuses only on the actual UI.</p>
</blockquote>

<p>its Lisp binding is <a href="https://github.com/borodust/bodge-nuklear">Bodge-Nuklear</a>, and its higher level companions <a href="https://github.com/borodust/bodge-ui">bodge-ui</a> and <a href="https://github.com/borodust/bodge-ui-window">bodge-ui-window</a>.</p>

<p>Unlike traditional UI frameworks, Nuklear allows the developer to take
over the rendering loop or the input management. This might require
more setup, but it makes Nuklear particularly well suited for games,
or for applications where you want to create new controls.</p>

<ul>
  <li><strong>Framework written in</strong>: ANSI C, single-header library.</li>
  <li>
    <p><strong>Portability</strong>: where C runs. Nuklear doesn’t contain
platform-specific code. No direct OS or window handling is done in
Nuklear. Instead <em>all input state has to be provided by platform
specific code</em>.</p>
  </li>
  <li>
    <p><strong>Widgets choice</strong>: small.</p>
  </li>
  <li>
    <p><strong>Graphical builder</strong>: no.</p>
  </li>
  <li>
    <p><strong>Other features</strong>: …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lispcookbook.github.io/cl-cookbook/gui.html">https://lispcookbook.github.io/cl-cookbook/gui.html</a></em></p>]]>
            </description>
            <link>https://lispcookbook.github.io/cl-cookbook/gui.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819896</guid>
            <pubDate>Mon, 13 Jul 2020 12:13:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“johnyj12345” exposing self-hosted Gitlab's secrets to the public]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819885">thread link</a>) | @ferruck
<br/>
July 13, 2020 | https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/ | <a href="https://web.archive.org/web/*/https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <h2><a href="https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" rel="bookmark">Possible Gitlab Hack</a></h2>
                <p>Today I noticed a new and unknown user on our company's Gitlab
instance: "johnyj12345". We immediatly took down our instance as it
seems as if that Johny was able to extract our secrets. You should
probably do so, too.</p>
                <p><i>Published <time datetime="2020-07-13T12:05:42+02:00">Monday, 13 July 2020</time> by <a href="https://blog.philipp-trommler.me/author/philipp-trommler.html">Philipp Trommler</a>. This article has also been translated to: <a href="https://blog.philipp-trommler.me/de/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/" hreflang="de">de</a>.</i></p>
                <p>Searching the web <a href="https://www.google.com/search?q=johnyj12345">for the
username</a> (attention: Google link!)
reveals that many self-hosted Gitlab instances are affected. The publicly
visible procedure is always the same: Johny creates one or more issues that are
linked with each other and at the end of the link cascade there's either an
attached file or a link to a file which holds Gitlab's <code>secrets.yml</code>.</p>
<p>From the web search it seems like the hack started on Saturday, though that may
be a false conclusion. In any case, you should probably take down your Gitlab
instance if you're affected since the <code>secrets.yaml</code> contains Gitlab's base key
and the database encryption key which should better be private AFAIK. This may
or may not be an immediate attack surface, but better safe than sorry,
especially since the files can be easily found via Google.</p>
<p>We're currently looking for a sane and safe way of rotating the keys within that
file. Any help would be appreciated.</p>
                <p><i>Filed under <a href="https://blog.philipp-trommler.me/category/security.html">Security</a>. Tags: <a href="https://blog.philipp-trommler.me/tag/git.html">git</a>, <a href="https://blog.philipp-trommler.me/tag/gitlab.html">gitlab</a>, <a href="https://blog.philipp-trommler.me/tag/hacking.html">hacking</a>, <a href="https://blog.philipp-trommler.me/tag/web.html">web</a>.</i></p>
                <p><i>Want to comment on this article? Write me at blog [at] philipp-trommler [dot] me!</i></p>
            </article></div>]]>
            </description>
            <link>https://blog.philipp-trommler.me/posts/2020/07/13/security-possible-gitlab-hack-johnyj12345/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819885</guid>
            <pubDate>Mon, 13 Jul 2020 12:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go Small]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819825">thread link</a>) | @webdva
<br/>
July 13, 2020 | https://rogerkirkness.com/go-small | <a href="https://web.archive.org/web/*/https://rogerkirkness.com/go-small">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<main>
			<b>Go Small</b>
<b>October 2018</b>
<hr>
<p>Maybe itâ€™s just the people I surround myself with, but I hear â€œmight as well go bigâ€� or some variation of it all the time. People say it about their personal life, and their business life. Iâ€™m not sure whether itâ€™s good specific advice, but itâ€™s generally terrible generic advice. My thinking on this is the opposite: go as small as you can. Risk is bad and you should try to make protect yourself from as many eventualities as you can.</p>

<p>The first example Iâ€™d offer is dating. Go big means marry the first person you think you can make it work with. Beyond the obvious failings of this approach, letâ€™s break down the math. The statistics shows you should probably date a certain number of people before you even start sampling whether someone is a good fit for the long haul. I read a study about how once you have dated 8 people, meeting a 9th person who is better than the first 8 is a strong indication you should marry them. Youâ€™d have to date over 100 more people to find a 10th who was stronger still. So at first, you are just gaining information, and eventually you make a choice. It requires an extremely incremental attitude to commitment, and lots of conviction.</p>

<p>Another example is business. Going big on the first idea you think is a good one is generally a terrible idea. One commonality among successful entrepreneurs is generally that they started many, many companies before they started the one that made them a success. Itâ€™s a safe assumption that most companies anyone starts will fail by conventional definitions. If you go small, you get more at bats in your life, which means you have a higher probability of success. The trade off is that if you give up too soon or donâ€™t go deep enough, you wonâ€™t know if it worked. There are many ways to validate an idea before pursuing it. The lean startup is falling out of favor because all the low hanging fruit is gone. That thesis is only half true, though. Easy ideas may be gone, but that doesnâ€™t mean you canâ€™t validate a hard/valuable idea in less time. Go small, figure out if there is traction, then expand incrementally. Behind every giant company, is a scientific approach to going small at first to figure out if the idea is worth the time.</p>

<p>There arenâ€™t many areas of your life where incremental learning is harmful. And there is nothing wrong with going small. Many more people regret going big and losing everything than regret going small in the early days of a risk based venture (marriage and business being but two examples). You can always scale your commitment up later, and do so with vastly higher confidence. Might as well go small.</p>

<hr>


		</main>
	</div></div>]]>
            </description>
            <link>https://rogerkirkness.com/go-small</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819825</guid>
            <pubDate>Mon, 13 Jul 2020 12:03:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semi-Supervised Learning in Computer Vision]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819812">thread link</a>) | @amitness
<br/>
July 13, 2020 | https://amitness.com/2020/07/semi-supervised-learning/ | <a href="https://web.archive.org/web/*/https://amitness.com/2020/07/semi-supervised-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>Semi-supervised learning methods for Computer Vision have been advancing quickly in the past few years. Current state-of-the-art methods are simplifying prior work in terms of architecture and loss function or introducing hybrid methods by blending different formulations.</p>
<p>In this post, I will illustrate the key ideas of these recent methods for semi-supervised learning through diagrams.</p>
<h2 id="1-self-training"><strong>1. Self-Training</strong></h2>
<p>In this semi-supervised formulation, a model is trained on labeled data and used to predict pseudo-labels for the unlabeled data. The model is then trained on both ground truth labels and pseudo-labels simultaneously.</p>
<p><img src="https://amitness.com/images/ssl-self-training.png" alt="Idea of Self-Training"></p>
<h3 id="a-pseudo-label">a. Pseudo-label</h3>
<p><a href="http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf" title="Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks">Dong-Hyun Lee</a> proposed a very simple and efficient formulation called “Pseudo-label” in 2013.</p>
<p>The idea is to train a <span>model</span> simultaneously on a batch of both labeled and unlabeled images. The <span>model</span> is trained on labeled images in usual supervised manner with a cross-entropy loss. The same model is used to get predictions for a batch of unlabeled images and the <span>maximum confidence class</span> is used as the <span>pseudo-label</span>. Then, cross-entropy loss is calculated by comparing <span>model</span> predictions and the pseudo-label for the unlabeled images .</p>
<p><img src="https://amitness.com/images/ssl-pseudo-label.png" alt="Pseudo-Label for Semi-supervised Learning"></p>
<p>The total loss is a weighted sum of the labeled and unlabeled loss terms.</p>

<p>To make sure the model has learned enough from the labeled data, the  term is set to 0 during the initial 100 training steps. It is then gradually increased up to 600 training steps and then kept constant.
<img src="https://amitness.com/images/ssl-pseudolabel-alpha-increase.png" alt="Impact of alpha on semi-supervised loss"></p>
<h3 id="b-noisy-student">b. Noisy Student</h3>
<p><a href="https://arxiv.org/abs/1911.04252" title="Self-training with Noisy Student improves ImageNet classification">Xie et al.</a> proposed a semi-supervised method inspired by Knowledge Distillation called “Noisy Student” in 2019.</p>
<p>The key idea is to train two separate models called <span>“Teacher”</span> and <span>“Student”</span>. The <span>teacher model</span> is first trained on the labeled images and then it is used to infer the pseudo-labels for the unlabeled images. These pseudo-labels can either be soft-label or converted to hard-label by <span>taking the most confident class</span>. Then, the labeled and unlabeled images are combined together and a <span>student model</span> is trained on this combined data. The images are augmented using RandAugment as a form of input noise. Also, model noise such as Dropout and Stochastic Depth are incorporated in the student model architecture.</p>
<p><img src="https://amitness.com/images/ssl-noisy-student.png" alt="Noisy Student"></p>
<p>Once a <span>student model</span> is trained, it becomes the new <span>teacher</span> and this process is repeated for three iterations.</p>
<h2 id="2-consistency-regularization"><strong>2. Consistency Regularization</strong></h2>
<p>This paradigm uses the idea that <span>model</span> predictions on an unlabeled image should remain the same even after adding noise. We could use input noise such as Image Augmentation and Gaussian noise. Noise can also be incorporated in the architecture itself using Dropout.</p>
<p><img src="https://amitness.com/images/fixmatch-unlabeled-augment-concept.png" alt="Consistency Regularization Concept"></p>
<h3 id="a-π-model">a. π-model</h3>
<p>This model was proposed by <a href="https://arxiv.org/abs/1610.02242" title="Temporal Ensembling for Semi-Supervised Learning">Laine et al.</a> in a conference paper at ICLR 2017.</p>
<p>The key idea is to create two random augmentations of an image for both labeled and unlabeled data. Then, a <span>model with dropout</span> is used to predict the label of both these images. The <span>square difference</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The total loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-pi-model.png" alt="PI Model"></p>
<h3 id="b-temporal-ensembling">b. Temporal Ensembling</h3>
<p>This method was also proposed by <a href="https://arxiv.org/abs/1610.02242" title="Temporal Ensembling for Semi-Supervised Learning">Laine et al.</a> in the same paper as the pi-model. It modifies the π-model by leveraging the <span>Exponential Moving Average(EMA)</span> of predictions.</p>
<p>The key idea is to use the <span>exponential moving average</span> of past predictions as one view. To get another view, we augment the image as usual and a <span>model with dropout</span> is used to predict the label. The <span>square difference</span> of <span>current prediction</span> and <span>EMA prediction</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-temporal-ensembling.png" alt="Temporal Ensembling"></p>
<h3 id="c-mean-teacher">c. Mean Teacher</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1703.01780" title="Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results">Tarvainen et al.</a>. The general approach is similar to Temporal Ensembling but it uses Exponential Moving Average(EMA) of the model parameters instead of predictions.</p>
<p>The key idea is to have two models called <span>“Student”</span> and <span>“Teacher”</span>. The <span>student</span> model is a regular model with dropout. And the <span>teacher</span> model has the same architecture as the <span>student</span> model but its weights are set using an <span>exponential moving average</span> of the weights of <span>student</span> model. For a labeled or unlabeled image, we create two random augmented versions of the image. Then, the <span>student</span> model is used to predict <span>label distribution</span> for first image. And, the <span>teacher</span> model is used to predict the <span>label distribution</span> for the second augmented image. The <span>square difference</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-mean-teacher.png" alt="Mean Teacher"></p>
<h3 id="d-virtual-adversarial-training">d. Virtual Adversarial Training</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1704.03976" title="Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning">Miyato et al.</a>. It uses the concept of adversarial attack for consistency regularization.</p>
<p>The key idea is to generate an adversarial transformation of an image that will change the model prediction. To do so, first, an image is taken and an adversarial variant of it is created such that the KL-divergence between the model output for the original image and the adversarial image is maximized.</p>
<p>Then we proceed as previous methods. We take a labeled/unlabeled image as first view and take its adversarial example generated in previous step as the second view. Then, the same <span>model</span> is used to predict <span>label distributions</span> for both images. The <span>KL-divergence</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we also calculate the <span>cross-entropy loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span></span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-virtual-adversarial-training.png" alt="Virtual Adversarial Training"></p>
<h3 id="e-unsupervised-data-augmentation">e. Unsupervised Data Augmentation</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/1904.12848" title="Unsupervised data augmentation for consistency training">Xie et al.</a> and works for both images and text. Here, we will understand the method in the context of images.</p>
<p>The key idea is to create an augmented version of a unlabeled image using AutoAugment. Then, a same <span>model</span> is used to predict the label of both these images. The <span>KL-divergence</span> of these two <span>predictions</span> is used as a <span>consistency loss</span>. For labeled images, we only calculate the <span>cross-entropy loss</span> and don’t calculate any <span>consistency loss</span>. The final loss is a weighted sum of these two loss terms. A weight <span>w(t)</span> is applied to decide how much the consistency loss contributes in the overall loss.</p>
<p><img src="https://amitness.com/images/ssl-unsupervised-data-augmentation.png" alt="Unsupervised Data Augmentation"></p>
<h2 id="3-hybrid-methods"><strong>3. Hybrid Methods</strong></h2>
<p>This paradigm combines ideas from previous work such as self-training and consistency regularization along with additional components for performance improvement.</p>
<h3 id="a-mixmatch">a. MixMatch</h3>
<p>This holistic method was proposed by <a href="https://arxiv.org/abs/1905.02249" title="Mixmatch: A holistic approach to semi-supervised learning">Berthelot et al.</a>.</p>
<p>To understand this method, let’s take a walk through each of the steps.</p>
<p>i. For the labeled image, we create an augmentation of it. For the unlabeled image, we create K augmentations and get the model <span>predictions</span> on all K-images. Then, the <span>predictions</span> are <span>averaged</span> and <span>temperature scaling</span> is applied to get a final pseudo-label. This pseudo-label will be used for all the K-augmentations.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-1.png" alt="Preparing Pseudo-label in MixMatch"></p>
<p>ii. The batches of augmented labeled and unlabeled images are combined and the whole group is shuffled. Then, the first N images of this group are taken as , and the remaining M images are taken as .</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-2.png" alt="Shuffling labeled and unlabeled images"></p>
<p>iii. Now, Mixup is applied between the augmented labeled batch and group . Similarly, mixup is applied between the M augmented unlabeled group and the  group. Thus, we get the final labeled and unlabeled group.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-3.png" alt="Applying Mixup trick in MixMatch"></p>
<p>iv. Now, for the labeled group, we take model predictions and compute <span>cross-entropy loss</span> with the ground truth mixup labels. Similarly, for the unlabeled group, we compute model predictions and compute <span>mean square error(MSE) loss</span> with the mixup pseudo labels. A weighted sum is taken of these two terms with  weighting the MSE loss.</p>
<p><img src="https://amitness.com/images/ssl-mixmatch-part-4.png" alt="MixMatch overall pipeline"></p>

<h3 id="b-fixmatch">b. FixMatch</h3>
<p>This method was proposed by <a href="https://arxiv.org/abs/2001.07685" title="FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence">Sohn et al.</a> and combines pseudo-labeling and consistency regularization while vastly simplifying the overall method. It got state of the art results on a wide range of benchmarks.</p>
<p>As seen, we train a supervised model on our labeled images with cross-entropy loss. For each unlabeled image, <span>weak augmentation</span> and <span>strong augmentations</span> are applied to get two images. The <span>weakly augmented image</span> is passed to our model and we get prediction over classes. The probability for the most confident class is compared to a <span>threshold</span>. If it is above the <span>threshold</span>, then we take that class as the ground label i.e. <span>pseudo-label</span>. Then, the <span>strongly augmented</span> image is passed through our model to get a prediction over classes. This <span>prediction</span> is compared to ground truth <span>pseudo-label</span> using cross-entropy loss. Both the losses are combined and the model is optimized.</p>
<p><img src="https://amitness.com/images/fixmatch-pipeline.png" alt="Overall Architecture of FixMatch"></p>
<p>If you want to learn more about FixMatch, I have an <a href="https://amitness.com/2020/03/fixmatch-semi-supervised/">article</a> that goes over it in depth.</p>
<h2 id="comparison-of-methods">Comparison of Methods</h2>
<p>Here is a high-level summary of the differences between all the above-mentioned methods.</p>
<table>
<thead>
<tr>
<th>Method Name</th>
<th>Year</th>
<th>Unlabeled Loss</th>
<th>Augmentation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pseudo-label</td>
<td>2013</td>
<td>Cross-Entropy</td>
<td>Random</td>
</tr>
<tr>
<td>π-model</td>
<td>2016</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Temporal Ensembling</td>
<td>2016</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Mean Teacher</td>
<td>2017</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Virtual Adversarial Training(VAT)</td>
<td>2017</td>
<td>KL-divergence</td>
<td>Adversarial transformation</td>
</tr>
<tr>
<td>Unsupervised Data Augmentation(UDA)</td>
<td>2019</td>
<td>KL-divergence</td>
<td>AutoAugment</td>
</tr>
<tr>
<td>MixMatch</td>
<td>2019</td>
<td>MSE</td>
<td>Random</td>
</tr>
<tr>
<td>Noisy Student</td>
<td>2019</td>
<td>Cross-Entropy</td>
<td>RandAugment</td>
</tr>
<tr>
<td>FixMatch</td>
<td>2020</td>
<td>Cross-Entropy</td>
<td>CTAugment / RandAugment</td>
</tr>
</tbody>
</table>
<h2 id="common-evaluation-datasets">Common Evaluation Datasets</h2>
<p>To evaluate the performance of these semi-supervised methods, the following datasets are commonly used. The authors simulate a low-data regime by using only a small portion(e.g. 40/250/4000/10000 examples) of the whole dataset as labeled and treating the remaining as the unlabeled set.</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Classes</th>
<th>Image Size</th>
<th>Train</th>
<th>Validation</th>
<th>Unlabeled</th>
<th>Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
<td>10</td>
<td>32*32</td>
<td>50,000</td>
<td>10,000</td>
<td>-</td>
<td>Subset of tiny images dataset</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-100</a></td>
<td>100</td>
<td>32*32</td>
<td>50,000</td>
<td>10,000</td>
<td>-</td>
<td>Subset of tiny images dataset</td>
</tr>
<tr>
<td><a href="http://ai.stanford.edu/~acoates/stl10/">STL-10</a></td>
<td>10</td>
<td>96*96</td>
<td>5000</td>
<td>8000</td>
<td>1,00,000</td>
<td>Subset of …</td></tr></tbody></table></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amitness.com/2020/07/semi-supervised-learning/">https://amitness.com/2020/07/semi-supervised-learning/</a></em></p>]]>
            </description>
            <link>https://amitness.com/2020/07/semi-supervised-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819812</guid>
            <pubDate>Mon, 13 Jul 2020 12:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foundations of Separation Logic]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819707">thread link</a>) | @matt_d
<br/>
July 13, 2020 | https://chargueraud.org/teach/verif/ | <a href="https://web.archive.org/web/*/https://chargueraud.org/teach/verif/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="page-div"><table><tbody><tr><td id="page-col-menu"></td><td id="page-col-content"><div><h2>Foundations of Separation Logic</h2><p>The <i>Foundations of Separation Logic</i> course presents the foundations of Separation Logic for sequential programs and the construction of a practical program verification tool based on Separation Logic.</p><p>The course material is entirely developed in the Coq proof assistant, following the style of the <a href="https://softwarefoundations.cis.upenn.edu/">Software Foundations</a> volumes.</p><div><ul><li><a href="https://chargueraud.org/research/2020/seq_seplogic/seq_seplogic.pdf"><b>Dowload the summary paper</b></a> entitled <i>Separation Logic for Sequential Programs</i>. This paper, presented at ICFP'20, covers most of the material with the notable exception of the weakest precondition generator.</li><li><a href="https://chargueraud.org/teach/verif/slf/index.html"><b>Browse the course files</b></a>, in HTML format.</li><li><a href="https://chargueraud.org/teach/verif/slf.tar.gz"><b>Download the course material</b></a>, which includes Coq and HTML files.</li><li>The files have been tested for compilation with all versions from Coq v8.8 to coq v8.12.</li><li>Compilation issues warnings with versions 8.10 or above; these warnings may be safely ignored.</li><li>See the README file for instructions.</li></ul></div><p>Solutions are available on demand. Contributions to the material are welcome.</p><h2><br>Older material: Master course on Separation Logic</h2><p>I taught from 2013 until 2017 at the <a href="https://wikimpri.dptinfo.ens-cachan.fr/doku.php">MPRI</a> (Parisian Master of Research in Computer Sciences), the program verification course, together with Claude Marché. The course covered  the following chapters:</p><div><ul><li>Heap predicates, heap entailment, interpretation triples, derivation rules.</li><li>Representation predicates for list and trees, nested mutable data structures, ownership transfer.</li><li>Reasoning about loops, frame during loops, higher-order functions, iterators.</li><li>Arrays, records and objects, frame over individual cells, data structures with sharing.</li><li>Extensions of Separation Logic for read-only permissions, parallelism, concurrency, and amortized analysis.</li><li>Characteristic formulae for integrating Separation Logic in Coq.</li></ul></div><p>Here are the slides from Febuary 2017:</p></div></td></tr></tbody></table></div></div></div>]]>
            </description>
            <link>https://chargueraud.org/teach/verif/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819707</guid>
            <pubDate>Mon, 13 Jul 2020 11:47:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Trade Wars Are Class Wars]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819673">thread link</a>) | @Ericson2314
<br/>
July 13, 2020 | https://phenomenalworld.org/reviews/trade-wars | <a href="https://web.archive.org/web/*/https://phenomenalworld.org/reviews/trade-wars">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <div>
          
          
<p><span>by Matthew C. Klein and Michael Pettis</span>
</p>
<p><span>Yale University Press, 2020</span>
</p>
<p>Good writing on international macroeconomics reads like a detective novel. There’s a suspicious event—hundreds of millions of dollars in <a href="https://www.bloomberg.com/news/audio/2019-10-25/the-great-whodunit-of-taiwanese-life-insurers-podcast">phantom FX swaps</a>, a container port’s worth of <a href="https://www.bis.org/speeches/sp190410.pdf">missing exports</a>—and an enormous cast of closely-linked characters. But instead of a preternatural ability to see the clear-cut means, motive, and opportunity of fictional characters in a pulp whodunit, the macroeconomic detective is armed with the knowledge that balance sheets always balance. This simple insight, that every transaction has two sides, means that there are certain aggregate relationships between transactions that must obtain for the world economy. Knowing this, it’s possible to chase actors across seemingly unrelated balance sheets to find where the system as a whole was forced to balance. From here, the skillful economist can identify the long-run tendencies that a given balance is likely to create. (Wynne Godley famously <a href="http://www.levyinstitute.org/pubs/sevenproc.pdf">predicted</a> the Global Financial Crisis in just this way, following US mortgage debt around the world and back.) This kind of detective work is difficult, and often unpopular. The balance sheet approach cuts through political and media platitudes to reveal who the winners and losers are in a given regime. By taking this approach to examining trade policy, Michael Pettis and Matthew Klein have, with <em><a href="https://yalebooks.yale.edu/book/9780300244175/trade-wars-are-class-wars">Trade Wars Are Class Wars</a></em>, written the ideal book for understanding the long-run trends that have shaped our dysfunctional present.</p>
<p>Pettis and Klein tell a broad story about the last fifty years of global economic development, which links the dynamics of global supply chains and tax evasion, and the historical shift from wage-led to profit-led growth. </p>
<p>The book argues that elites in all countries want to capture economic output while developing the capital stock of their economies. To do this, they invest massively, which mechanically creates savings. Rather than sharing those savings with the household sector in the form of wage increases, the elites hoard and move them offshore. This destroys local demand for the goods produced by their capital investments. At this point, they turn to the export market to make up for the missing local sales. The problem is that, to be competitive exporters, they have to produce tradeable goods at a lower unit cost than their competitors. Capitalists must then further suppress domestic wages to ensure those lower unit costs, and thus increase their dependency on export markets.</p>
<p>The problem is, not every country—or bloc, in the case of the Eurozone—can be a net exporter. This spells trouble, if every country’s capitalists are dependent on the export markets to validate their investments. Absent a country willing to import everyone else’s surplus, this kind of arrangement would set the capitalists of all countries against one another before falling apart. It’s at this point, however, that the US steps in to backstop the global order as a hegemonic debtor, allowing nearly every other country to be a net exporter. As many have <a href="https://phenomenalworld.org/analysis/the-class-politics-of-the-dollar-system">pointed out</a>, this is the natural role for the US to play, given nearly all transactions the world over are denominated in its currency. To update Robert Triffin, if the whole world uses your currency for trade, then the whole world economy needs you to issue dramatically more debt than your domestic economy requires. This extra debt, combined with massive offshoring of profits, means that annual US investment flows abroad—in dollar terms, not physical ones—vastly outstrip the rest of the world's annual investment in the US. This capital account surplus produces a matching current account deficit. The imports that make up this current account deficit are largely manufactured goods that the US used to produce domestically. Such an influx in turn hollows out domestic production in tradeable goods, and the industrial middle class of the US, brought into being by the second world war, falls apart into opiates, suicide, and nativism. By acting as debtor to the world, the <a href="https://twitter.com/quantian1/status/1260387202871287809">US benefits</a> from imported goods, while elites of all countries—the US included—win at the expense of all workers.</p>
<p>This story is a novel one because most economists and popularizers envision macroeconomics as the simple aggregation of microeconomic decisions: in a vacuum, all the actors come to their own conclusions about how to behave, and the sum of these decisions is expressed in macroeconomic figures. What those decisions add up to is ultimately a residual, only useful as a measurement of how well agents in general are making decisions, and how good some countries are at producing certain kinds of goods. In this view, for example, the Chinese simply <em>prefer</em> to save more, and Americans simply <em>prefer</em> to save less. Chinese workers will work for less money, and individual US consumers will decide that they prefer imports over American-made goods. In reality, individuals make decisions from the space of options dictated by macroeconomic conditions. To take this fact seriously, as Pettis and Klein do, means working from balance sheets—adhering to the accounting identities of the world economy and reconstructing the interrelated financial and real flows within it. </p>
<p>Without going through sets of T-accounts like a first-year accounting student, consider the following example. Someone buys a television. The buyer doesn’t have cash on hand and puts the \$500 purchase on a credit card. The consumer gains a television and a debt of \$500. The credit card company gives \$500 to the store and gains a debt of \$500 from the buyer. The store gains \$500 from the credit card company but loses a television. Simple enough. But say the store has to pay its international suppliers, and the credit card company chooses to sell the debt of the original purchaser. Now some chunk of the original $500 is going through foreign exchange (whose rate has been hedged, naturally) to a Chinese company that keeps some portion in a bank, which in turn keeps some portion in properly hedged US Treasuries. At the same time, the debt held by the credit card company is securitized and sold to a European bank looking for exposure to that particular kind of risk.</p>
<p>The simplest transaction can become very complex in a financial economy, if one maps every other transaction it touches. It can also fan out into accumulations of seemingly unrelated financial products, as participants hedge away unwanted risks and speculators demand exposure. But it is always possible to trace these relationships through to find their financing and final funding. Goods and money must come from somewhere, and every sale is also a purchase. Someone is always ultimately using credit, and someone else is ultimately providing credit. These kinds of transactions happen billions of times per day—hedged to one another, and contracted forwards and backwards in time—and are individually relatively unimportant. The promise of economics as a field of study is that, when aggregated together through a constellation of balance sheets, the functional relationships between different economic and financial quantities can be identified.</p>
<p>Some of these outcomes are set endogenously by parameters internal to the model, and some exogenously by the world at large. Although all financial variables are ultimately endogenous to nature and society, some can be treated as exogenous to—set externally and without reference to the calculations of—the model. In this approach, the trick is to find which incentives and patterns of behavior are sufficiently strong to be exogenously given in the model, such that the model closes by adjusting endogenous variables. Strong exogenous factors are often historical, political, or social events, and endogenous changes—whose movements condense into new trends—are often hard to see clearly or quickly.</p>
<p>When, for example, the rest of the world wants to accumulate assets denominated in US dollars, and the US government does not want to run a budget deficit, those assets have to come from somewhere. They could come just as easily from the rest-of-world banking sector in the form of Eurodollar loans as they could from dissaving in the US private sector. Postkeynesian economists associated with Stock-Flow Consistent modelling often take this approach to understanding the world of <a href="http://www.levyinstitute.org/pubs/wp_891.pdf">international finance</a>, which can uncover these endogenous changes. Wynne Godley, Hyman Minsky, and the sectoral balances framework for macroeconomics lurk behind the scenes for much of <em>Trade Wars Are Class Wars</em>, while Keynes himself is cited throughout.</p>
<p>Readers already invested in international macroeconomics will recognize many of the names and arguments in the book, which functions as a brilliant primer on the field. It’s almost like a reverse <em>Freakonomics</em>. Instead of claiming that a couple of economics papers provide the only valid method for answering every question, and that every human activity is simply a veil for econ 101-style supply and demand, Pettis and Klein pull in insights from a variety of nearby disciplines—corporate finance, tax accounting, supply chain management—to actually explain the economy. The arguments, citations, and allusions here—Brad Setser, Hyun Song Shin, <a href="https://press.princeton.edu/books/paperback/9780691170817/the-box">Marc Levinson</a>, a past-life <a href="https://econpapers.repec.org/article/eeeinecon/v_3a8_3ay_3a1978_3ai_3a3_3ap_3a445-456.htm">Paul Krugman</a>—provide a great starting point for a deep and flexible understanding of the global economy.</p>
<p>Common approaches to trade policy take an overly literal view of bilateral trade balances. The folk-Ricardian story—still dominant in American political discourse—is that countries that are not good at making things have to import lots of things. Importer countries become indebted to their trading partner, see their exchange rate devalued and their interest rates rise, until eventually a plague of locusts overtakes them for their inability to be sufficiently productive. In this shopworn story, the correct policy response is to apply tariffs on goods from the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://phenomenalworld.org/reviews/trade-wars">https://phenomenalworld.org/reviews/trade-wars</a></em></p>]]>
            </description>
            <link>https://phenomenalworld.org/reviews/trade-wars</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819673</guid>
            <pubDate>Mon, 13 Jul 2020 11:42:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Engineering != Coding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819607">thread link</a>) | @FailMore
<br/>
July 13, 2020 | https://taaalk.co/t/software-engineering-coding#upvote | <a href="https://web.archive.org/web/*/https://taaalk.co/t/software-engineering-coding#upvote">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <div id="tlk-section-read">
    



<div>

    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I'm a recently trained full stack developer who want's to understand the FULL stack. Right now I think of that as backend + frontend code, but I hear there is more to it than that...</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <div>
  <p>I am the founder of multiple bootstrapped companies. They include web, mobile and infrastructure development agency <a href="https://www.solidstategroup.com/">Solid State Group</a>, virtual office business <a href="https://www.hoxtonmix.com/">The Hoxton Mix</a> and, most recently, developer friendly feature flag tool <a href="https://bullet-train.io/">Bullet Train</a>. I've been involved with many more than that, watching some succeed and others fail.</p>
</div>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

</div>

  </div>







  <div>

      <div id="1">
        <div>
          
          <p>Joshua Summers</p>
          <p>15:58, 26 Jun 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Why did you ask for this?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="2">
        <div>
          
          <p>Ben Rometsch</p>
          <p>12:36, 03 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right so yes I've spent over 25 years writing software for people in a professional capacity. As time has gone by, and I've learnt more about the process, I've slowly realised that actually writing code is actually quite a small part of the process. When I was a junior developer I probably spent 90% of my working day sat in front of an editor writing code. And I thought that was the job. Turns out it really isn't!Â&nbsp;</p></div><div><p>I think people both inside and outside of the industry fixate on coding for a number of reasons, and it's quite interesting to ruminate on those, but building software is so much more than writing code. Talking to users, agreeing on features, designing the interface, setting up the infrastructure, testing the platform for bugs, testing it for performance, providing support for it. These are all messy, imprecise things that have very human factors.Â&nbsp;</p></div><div><p>If you are a software engineer you can often seek solace in the code itself. Code is truth. You can't really argue with it. You can't argue with your compiler. It's really easy to fall into the trap of avoiding all work other than coding for these very reasons. But I would suggest that this makes you a really bad engineer! Engineering means getting your hands dirty, either literally in the case of Brunel, or from a human interaction point of view where software is concerned.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="3">
        <div>
          
          <p>Joshua Summers</p>
          <p>14:15, 10 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So you are sort of saying that an engineer solves problems, and problems are experienced (mostly) by people, so to solve problems effectively you a) have to deal with people and b) have to really know how to solve the problem (e.g. dealing with infrastructure, performance, etc.) instead of only the parts you are comfortable with. Is that correct?</p></div><div><p>How much of this comes down to the attitude of the engineer? And how much of this comes down to actively studying?Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="4">
        <div>
          
          <p>Ben Rometsch</p>
          <p>10:22, 13 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>In my experience, almost 100% of that learning comes from hard won experience.Â&nbsp;</p></div><div><p>When I studied at university, I was really surprised to discover that the "Computing" courses that I was interested in were labelled as "Software Engineering". I thought it was odd at the time; I never really had thought it about it before, and I was even a bit worried that I might have been signing up for the wrong course!Â&nbsp;</p></div><div><p>I don't think many universities at the time offered "Computer Science" as an undergrad course; it's a very different discipline.Â&nbsp;</p></div><div><p>It took me a LONG time to get my head around the fact that one of the words in the job was "engineering". And really the only way I realised that was after years of working building software. At some point the penny dropped that I was an engineer, and that writing code was only 1 aspect of that job.Â&nbsp;</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="5">
        <div>
          
          <p>Joshua Summers</p>
          <p>12:00, 15 Jul 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So based on your experience, where do you feel the greatest value lies in the spectrum of what it means to be an engineer? Or is it person dependent?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>

  </div>








  

  





    </div></div>]]>
            </description>
            <link>https://taaalk.co/t/software-engineering-coding#upvote</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819607</guid>
            <pubDate>Mon, 13 Jul 2020 11:34:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alpha Wolf Concept]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819529">thread link</a>) | @CaptainActuary
<br/>
July 13, 2020 | https://davemech.org/wolf-news-and-information/ | <a href="https://web.archive.org/web/*/https://davemech.org/wolf-news-and-information/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article class="page" itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text"><h2>News</h2>
<p>The most current, accurate, and objective wolf news can be found on the website of the International Wolf Center (<a href="http://www.wolf.org/">www.wolf.org</a>)</p>
<p><img src="http://davemech.org/wp-content/uploads/wolfreadsbook-300x228.jpg" alt="Wolf reading book." width="300" height="228" srcset="https://davemech.org/wp-content/uploads/wolfreadsbook-300x228.jpg 300w, https://davemech.org/wp-content/uploads/wolfreadsbook-768x584.jpg 768w, https://davemech.org/wp-content/uploads/wolfreadsbook.jpg 800w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h2><a href="http://davemech.org/wolf-news-and-information/books/">Mech books</a></h2>
<h2>Mech articles</h2>
<ul>
<li><a href="http://davemech.org/wp-content/uploads/technical-publications.pdf">Scientific publications</a> (.pdf)</li>
<li><a href="http://davemech.org/wp-content/uploads/popular-publications.pdf">Popular publications</a> (.pdf)</li>
<li><a href="http://www.wolf.org/wolf-info/basic-wolf-%C2%A0info/in-depth-resources/scientific-publications/">Downloadable articles</a></li>
</ul>
<h2><a href="http://davemech.org/wolf-news-and-information/schenkels-classic-wolf-behavior-study-available-in-english/">Schenkel’s 1948 Wolf Expression Studies</a></h2>
<h2>Alpha Wolf Concept</h2>
<p>The concept of the alpha wolf is well ingrained in the popular wolf literature, at least partly because of my book “The Wolf: Ecology and Behavior of an Endangered Species,” written in 1968, published in 1970, republished in paperback in 1981, and currently still in print, despite my numerous pleas to the publisher to stop publishing it. Although most of the book’s info is still accurate, much is outdated. We have learned more about wolves in the last 40 years then in all of previous history.</p>
<p>One of the outdated pieces of information is the concept of the alpha wolf. “Alpha” implies competing with others and becoming top dog by winning a contest or battle. However, most wolves who lead packs achieved their position simply by mating and producing pups, which then became their pack. In other words they are merely breeders, or parents, and that’s all we call them today, the “breeding male,” “breeding female,” or “male parent,” “female parent,” or the “adult male” or “adult female.” In the rare packs that include more than one breeding animal, the “dominant breeder” can be called that, and any breeding daughter can be called a “subordinate breeder.”<br>
For details, see <a href="http://www.wolf.org/wp-content/uploads/2013/09/267alphastatus_english.pdf" target="_blank" rel="noopener">www.wolf.org/wp-content/uploads/2013/09/267alphastatus_english.pdf</a> and <a href="http://www.wolf.org/wp-content/uploads/2013/08/247Leadership.pdf" target="_blank" rel="noopener">www.wolf.org/wp-content/uploads/2013/08/247Leadership.pdf</a></p>
<h2>Alpha Wolf videos</h2>
<p><a href="https://www.youtube.com/watch?v=tNtFgdwTsbU" data-rel="lightbox-video-0">Mech explains</a><br>
<iframe width="500" height="375" src="https://www.youtube.com/embed/tNtFgdwTsbU?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
<p><a href="https://www.youtube.com/watch?v=YTyQgwVvYyc" data-rel="lightbox-video-1">Cartoon explanation of Mech and the Alpha concept</a> (cartoon starts at minute 1)<br>
<iframe width="500" height="281" src="https://www.youtube.com/embed/YTyQgwVvYyc?feature=oembed" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p>
</div></article></main></div></div></div>]]>
            </description>
            <link>https://davemech.org/wolf-news-and-information/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819529</guid>
            <pubDate>Mon, 13 Jul 2020 11:24:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS Big Sur is flatter than ever]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819485">thread link</a>) | @elorant
<br/>
July 13, 2020 | https://www.andrewdenty.com/blog/2020/07/10/why-macos-big-sur-is-flatter-than-ever.html | <a href="https://web.archive.org/web/*/https://www.andrewdenty.com/blog/2020/07/10/why-macos-big-sur-is-flatter-than-ever.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p><img src="https://www.andrewdenty.com/blog/assets/img/why-macos-big-sur-is-flatter-than-ever.png" alt="Catalina vs Big Sur"></p>
<p>Forget skeuomorphism, or even the newly coined neumorphism.</p>
<p>macOS Big Sur is flatter than ever.</p>
<p>In the last few weeks there have been a lot of suggestions that this is the start of a <a href="https://applypixels.com/blog/comeback" target="_blank">new “fun” era of visual design</a> and that Apple is returning to skeuomorphism, or even a new thing called <a href="https://www.inputmag.com/design/apple-macos-big-sur-the-rise-of-neumorphism" target="_blank">neumorphism</a>. Neumorphism is a design trend that focuses on creating an impression of a realistic 3D environment using shadow and lighting effects.</p>
<p>The times may well be changing, but in my view we are not returning to an age of textured writing paper and
stitched leather. This is why.</p>
<h3 id="icons-icons-icons">Icons, icons, icons</h3>
<p>Since the unveiling of macOS Big Sur a lot has been made of its new iOS shaped icon set. Everyone seems to either love or hate the new icons.</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-flat/macos-big-sur-icons.jpg"><img src="https://www.andrewdenty.com/blog/assets/img/macos-flat/macos-big-sur-icons.jpg" alt="macOS Big Sur icons"></a></p>
<p>Don’t be mislead by the icons - macOS icons have always been richer and more detailed than iOS icons. They have also used shadows and to create a sense of depth. In my view desktop interfaces are often more detailed as desktop users tend to use them for longer periods of undistracted time compared to mobile devices. Therefore adding more detail and richness is appropriate. In short, for as long as technology has allowed, macOS icons have been rich, detailed and realistic looking. Here are a selection of macOS Catalina’s icons to illustrate this:</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-flat/depth-in-macos-catalina.png"><img src="https://www.andrewdenty.com/blog/assets/img/macos-flat/depth-in-macos-catalina.png" alt="Detailed macOS Catalina icons"></a></p>
<p>The new icon set in Big Sur is simply a convergence of the existing highly detailed macOS icons with the consistent shape of iOS icons. During the WWDC 20 keynote, Alan Dye, Apples VP of Human Interface explained the rationale behind the new icons:</p>
<blockquote>
<p>“We wanted consistency throughout the ecosystem so users can move fluidly between their Apple devices, but we also love that Mac icons have a deep history and a distinct look and feel. So we retained many of the highly crafted details and th playful elements that make Mac icons unique”</p>
</blockquote>
<p>It’s also worth remembering that in many places the icons in macOS are simpler than before as Apple is porting its unified language of symbols from iOS. This means that in many places, existing detailed icons have become simple, monochrome 2D icons.</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-new-ui/apple-music-podcasts/5-podcasts-preferences-macos-catalina-big-sur-comparison.png"><img src="https://www.andrewdenty.com/blog/assets/img/macos-new-ui/apple-music-podcasts/5-podcasts-preferences-macos-catalina-big-sur-comparison.png" alt="Icons in Podcast app's preferences"></a></p>
<h3 id="big-sur-is-flatter-than-ever">Big Sur is flatter than ever</h3>
<p>This may surprise a few people, but if you look at the user interfaces in macOS Big Sur and compare it to the current release Catalina you won’t see richer shading and detailing. Also, while macOS Big Sur uses transparency, and shadows to create the impression of layers in the UI, this isn’t a new thing for macOS.</p>
<p>Actually, you’ll see a lot of the detail, texture and shadows have been removed. As a whole, macOS Big Sur’s interface is cleaner and more minimalist than ever. One of the aspects I’ve noticed most is there tends to be less contrast between UI elements. Apple has also completely dropped the aluminium inspired window chromes which can be traced back to Quicktime in the 1990s.</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-flat/finder-toolbar-comparison.png"><img src="https://www.andrewdenty.com/blog/assets/img/macos-flat/finder-toolbar-comparison.png" alt="Comparison of Finder toolbars between macOS Catalina and Big Sur"></a></p>
<p>Take for example the notes app. The faux-paper texture has finally been completely removed. The toolbar buttons no longer have containers and there is no background separator between the toolbar and writing area.</p>
<p><a href="https://www.andrewdenty.com/blog/assets/img/macos-flat/notes-compared.png"><img src="https://www.andrewdenty.com/blog/assets/img/macos-flat/notes-compared.png" alt="Comparison of Notes app between macOS Catalina and Big Sur"></a></p>
<h3 id="if-anything-the-design-trend-is-convergence-with-ios">If anything the design trend is convergence with iOS</h3>
<p>This is not a new paradigm in visual design, but a shift towards unification between platforms. There is increasingly less separation between iOS and macOS. Both in hardware with Apple’s switch to an all ARM architecture and software where iPhones and iPads can now do many of the tasks once reserved for desktop computing.</p>
<p>In many ways the interface changes in macOS Big Sur reflect this transition. The iOS glyph icon set, the removal of distinct buttons and increasingly rounded corners. Apple has clearly been asking why interface elements on an iPad and a Mac should look different, and come to the conclusion there’s no longer a good reason for this.</p>
<p>On the topic of conversion, one interesting question will be how much further this transition goes. Can we expect to see touch enabled laptops? Dual booting iPads? iPhones with docking stations?</p>
<h3 id="but-what-about-fun-design---isnt-that-coming-back">But what about fun design - isn’t that coming back?</h3>
<p>As a designer I’ve often found the trend towards flat, minimalist design frustrating. I pretty much always have an urge to add little embellishments or extra layers to work. I then subsequently almost always end up removing them. Either due to what I’ve learned when testing the design with users, or just realising that these extra details often end up detracting from the bigger picture.</p>
<p>This doesn’t mean there’s no value in intricate detailing. If you are a designer and you can inject a fun details into your work in a way which delights and enriches your users lives then I implore you to do this. I just don’t think that macOS Big Sur is the signal we’ve all been waiting for to bring out those shadows, textures and bevels.</p>
</div>
</article></div>]]>
            </description>
            <link>https://www.andrewdenty.com/blog/2020/07/10/why-macos-big-sur-is-flatter-than-ever.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819485</guid>
            <pubDate>Mon, 13 Jul 2020 11:14:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding the Importance of Abstractions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819435">thread link</a>) | @dwltz
<br/>
July 13, 2020 | https://www.donnywals.com/understanding-the-importance-of-abstractions/ | <a href="https://web.archive.org/web/*/https://www.donnywals.com/understanding-the-importance-of-abstractions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As developers, we constantly deal with layers of abstractions that make our lives easier. We have abstractions over low level networking operations that allow us to make network calls with <code>URLSession</code>. Core Data provides an abstraction over data persistence that can be used to store information in an sqlite database. And there are many, many more abstractions that we all use every day.</p><p>Over the past few weeks I have seen many people ask about using Core Data in pure SwiftUI projects created in Xcode 12. These projects no longer require an App- and SceneDelegate, and the checkbox to add Core Data is disabled for these projects. Some folks immediately thought that this meant Core Data can't be used with these projects since Xcode's template always initialized Core Data in the <code>AppDelegate</code>, and since that no longer exists it seems to make sense that Core Data is incompatible with apps that don't have an <code>AppDelegate</code>. How else would you initialize Core Data?</p><p>Fortunately, this isn't true. It's still possible to use Core Data in projects, even if they don't have an <code>AppDelegate</code>. In fact, the only thing that <code>AppDelegate</code> has to do with Core Data is that Apple decided that they wanted to setup Core Data in the <code>AppDelegate</code>.</p><p>They didn't have to make that choice. Core Data can be initialized from anywhere in your app.</p><p>However, this got me thinking about abstractions. Folks who have built a layer of abstraction between their app and Core Data probably already know that you don't need Xcode to generate a Core Data stack for you. They probably also already know that you can initialize Core Data anywhere.</p><p>While thinking about this, I started thinking more about abstractions. Adding the right abstractions to your app at the right time can help you build a more modular, portable and flexible code base that can quickly adapt to changes and new paradigms.</p><p>That why in this week's post, I would like to talk about abstractions.</p><h2>Understanding what abstractions are</h2><p>Abstractions provide a seperation between the interface you program against and the underlying implementation that performs work. In essence you can think of most, if not all, frameworks you use every day on iOS as abstractions that make working with something complex easier.</p><p>In programming, we often work with abstractions on top of abstractions on top of more abstractions. And yet, there is value in adding more abstractions yourself. A good abstraction does not only hide complexity and implementation details. It should also be reusable. When your abstraction is reusable it can be used in multiple projects with similar needs.</p><p>I could try to make the explanation more wordy, fancy or impressive but that wouldn't help anybody. Abstractions wrap a complex interface and provide an (often simpler) inferface while hiding the wrapped, complex interface as an implementation detail. Good abstractions can be reused.</p><h2>Knowing when to write an abstraction</h2><p>Earlier I wrote that adding your own abstractions has value. That said, it's not always obvious to know when you should write an abstraction. Especially since there are no hard or clear rules.</p><p>A good starting point for me is to determine whether I will write a certain block of tedious code more than once. Or rather, whether I will write similar blocks of tedious code multiple times. If the answer is yes, it makes sense to try and create a lightweight abstraction to wrap the tedious code and make it less annoying to work with.</p><p>Another method I often use to determine whether I should write an abstraction is to ask myself how easily I want to be able to swap a certain mechanism in my app out for testing or to replace it entirely.</p><p>Usually the answer to this question is that I want to be able to swap things out as easily as possible. And more often than not this means that I should add an abstraction.</p><p>For instance, when I write code that uses Core Data I always wrap it in a small abstraction layer. I don't want my entire app to depend directly on Core Data. Instead, my app uses the abstraction to interface with a persistence layer. The code in my app doesn't know how the persistence layer works. It just knows that such a layer exists, and that it can fetch and save objects of certain types.</p><p>Creating an abstraction like this allows me to easily change the underlying storage mechanism in my persistence layer. I could switch to Realm, use sqlite directly, or even move from local persitence to persisting data on a server or in iCloud. The app shouldn't know, and the app shouldn't care. That's the beauty of abstractions.</p><h2>Designing an abstraction</h2><p>Once you've decided that you want to write an abstraction, you need to design it. The first thing I always do is make sure that I decide which properties and methods should be publicly available. I then define a protocol that captures this public API for my abstraction. For example:</p><pre><code>protocol TodoItemPersisting {
  func getAllTodoItems() -&gt; Future&lt;[TodoItem]&gt;
  func getTodoItem(withId id: UUID) -&gt; Future&lt;TodoItem?&gt;
  func updateItem(_ item: TodoItem)
  func newTodoItem() -&gt; Future&lt;TodoItem&gt;
}</code></pre><p>This is a very simple protocol that exposes nothing about the underlying persistence layer. In the rest of my code I will always refer to <code>TodoItemPersisting</code> when I want to use my persistence abstraction:</p><pre><code>struct TodoListViewModel {
  private let itemStore: TodoItemPersisting
}</code></pre><p>In this example I defined a <code>ViewModel</code> that has an <code>itemStore</code> property. This property conforms to <code>TodoItemPersisting</code> and the object that creates an instance of <code>TodoListViewModel</code> gets to decide which concrete implementation of <code>TodoItemPersisting</code> is injected. And since the protocol for <code>TodoItemPersisting</code> uses <a href="https://www.donnywals.com/using-promises-and-futures-in-combine/">Combine Futures</a>, we know that the persistence layer does work asynchronously. The <code>ViewModel</code> doesn't know whether the persistence layer goes to the network, file system, Core Data, Realm, Firebase, iCloud or anywhere else for persistence.</p><p>It just knows that items are fetched and created asynchronously.</p><p>At this point you're free to create objects that implement <code>TodoItemPersisting</code> as needed. Usually you'll have one or two. One for the app to use, and a second version to use while testing. But you might have more in your app. It depends on the abstraction and what it's used for.</p><p>For instance, if your app uses In-App Purchases to provide syncing data to a server you might have a local persistence abstraction, and a premium local + remote persistence abstraction that you can swap out depending on whether the user bought your premium IAP.</p><p>By desiginig abstractions as protocols you gain a lot of flexibility and power. So whenever possible I always recommend to design and define your abstractions as protocols.</p><h2>Things to watch out for when writing abstractions</h2><p>Once you get the hang of abstracting code, it's very tempting to go overboard. While abstractions provide a lot of power, they also add a layer of indirection. New members of your team might understand the things you've abstracted really well, but if you added to many layers your code will be really hard to understand and your abstractions will be in the way of understanding the code base.</p><p>It's also possible that you didn't design your abstractions properly. When this happens, you will find that your abstractions are holding you back rather than helping you write code that does exactly what you want it to do. When you find you're fighting your abstractions it's time to revise your design and make improvements where needed.</p><p>And the last word of warning I want to give you is that it's important to limit the levels of abstractions you add. No matter how good your abstractions are, there will come a point where it'll get harder and harder to understand and debug your app when something is wrong. There's no hard cutoff point but eventually you'll develop a sense for when you're going too far. For now it's good to know that you can abstract too much.</p><h2>In Summary</h2><p>In this week's post you learned about abstractions in programming. You learned what an abstraction is, what abstractions are used for and how you can determine whether you should write an abstraction of your own.</p><p>You learned that abstractions can be extremely useful when you want to write code that's testible, flexible, and maintainable. Good abstractions make difficult work easier, and allow you to hide all implementation details of the thing or process you've written your abstraction for. You also learned that protocols are a fantastic tool to help you define and design your abstraction. Lastly, I gave you some things to watch out for when writing abstractions to make sure you don't overcomplicate matters or abstract too much.</p><p>If you have any questions for me, or if you have feedback about this week's post make sure to reach out to me on <a href="https://twitter.com/donnywals">Twitter</a>.</p><div><hr><div><h4>Practical Combine</h4><p>Learn everything you need to know about Combine and how you can use it in your projects with my new book <a href="http://practicalcombine.com/" target="_blank">Practical Combine</a>. You'll get thirteen chapters, a Playground and a handful of sample projects to help you get up and running with Combine as soon as possible.</p><p>The book is available as a digital download for just <strong>$24.99</strong>!</p> <p><a href="https://practicalcombine.com/" target="_blank">Get Practical Combine</a></p></div><hr></div></div></div>]]>
            </description>
            <link>https://www.donnywals.com/understanding-the-importance-of-abstractions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819435</guid>
            <pubDate>Mon, 13 Jul 2020 11:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tangling Code from Hugo Content with Raku – Brian Wisti]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819371">thread link</a>) | @lizmat
<br/>
July 13, 2020 | https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/ | <a href="https://web.archive.org/web/*/https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

      <p>Let’s say I have a file.
The one you’re reading, perhaps.
Well, its original Markdown content.</p>
<p>It has a shortcode in it.</p>
<div><pre><code data-lang="go-html-template"><span>{{</span><span>&lt;</span><span> </span><span>code</span><span> </span><span>file</span><span>=</span><span>"hello.py"</span><span> </span><span>&gt;</span><span>}}</span>
print("Hello")
<span>{{</span><span>&lt;</span><span> </span><span>/</span><span>code</span><span> </span><span>&gt;</span><span>}}</span>
</code></pre></div><p>I based <code>{{&lt; code &gt;}}</code> here on a shortcode from the <a href="https://github.com/gohugoio/hugoDocs/blob/master/layouts/shortcodes/code.html">hugo docs</a>. It presents highlighted code with additional context.</p>






  









<p>Really handy when you’re writing about code.  Thing is, now I have two copies.  There’s one here in
the shortcode, and another in a <code>hello.py</code> file that I’m writing about.  I’d prefer there was only a
single copy.  That way they don’t get out of sync.</p>
<p>I <em>could</em> use Hugo’s <a href="https://gohugo.io/functions/readfile/"><code>readFile</code></a> function in a new shortcode, including the contents of
<code>hello.py</code> in this Markdown file. Something like this:</p>
<div><pre><code data-lang="go-html-template"><span>{{</span><span>&lt;</span><span> </span><span>include</span><span> </span><span>file</span><span>=</span><span>"hello.py"</span><span> </span><span>&gt;</span><span>}}</span>
</code></pre></div>
<p>But that still breaks up the writing flow a little bit. I’m writing the code over here, and
writing <em>about</em> it over there. It’s a tiny complaint, but working with <a href="https://randomgeekery.org/tags/org">Org mode</a> has spoiled me. I
get to write the code in the same document that I’m writing about it in. Everything stays in sync,
more or less.</p>
<p>What I want is to write about <code>hello.py</code> here, and with a command have <code>hello.py</code> appear on my
filesystem, containing the Python code I’ve been describing.</p>
<p>And I want to do it without disturbing Hugo. Let it turn Markdown into HTML.</p>
<h2 id="tangling">Tangling</h2>
<p>This process is called “tangling,” and it’s popular in the admittedly small world of <a href="http://literateprogramming.com/index.html">Literate
Programming</a>. The code is interleaved throughout some kind of document, and a tool like <a href="https://www.cs.tufts.edu/~nr/noweb/">noweb</a> or
<a href="https://orgmode.org/worg/org-contrib/babel/intro.html">Babel</a> parses the document to create code files. Could be any kind of file, really. The process can get
fancy.</p>
<p>But the start is not fancy: given a text file containing a <code>{{&lt; code file="(something)" &gt;}}</code>,
write the contents of that shortcode to the named file.</p>






  





<div id="tangle.raku"><p><a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/tangle.raku" title="Download tangle.raku" aria-label="Download">
          
        </a>tangle.raku
    </p>
    <pre><code data-lang="raku">sub MAIN() {
  my $filename = "index.md";
  my $opener = '{{&lt; ';
  my $closer = ' &gt;}}';
  my regex shortcode {
    $opener
      code \s
      'file="' $&lt;filename&gt; = .+? '"'  # Remember the filename
      .*?
    $closer
    \n                # Ignore leading newline
    $&lt;content&gt; = .+?  # Remember everything else in the block
    \n                # Ignore leading newline
    $opener '/code' $closer
  }

  my $markdown = slurp $filename;

  if $markdown.match(/ &lt;shortcode&gt; /) {
    my $tangle-file = $/&lt;shortcode&gt;&lt;filename&gt;;
    my $tangle-content = $/&lt;shortcode&gt;&lt;content&gt;;
    spurt $tangle-file, $tangle-content;
    say "Tangled to $tangle-file";
  }
}</code></pre>
  
  </div>



<p>I love Raku’s approach to <a href="https://docs.raku.org/language/regexes">regular expressions</a>.  For starters, the syntax looks a bit more like
describing a grammar.  I can break the funny regex characters up with spaces, and clarify them with
comments.  In fact, I could someday build this up to a real <a href="https://docs.raku.org/language/grammars">grammar</a>.</p>
<p>Secondly, it addresses the fact that most text we look at these days contains multiple lines.
I didn’t have to worry about any special multiline flags to get this working.</p>
<p>Finally, getting at the named captures was — I wouldn’t say “obvious,” but at least “coherent.”
I can treat the match variable <code>$/</code> as a nested <a href="https://docs.raku.org/language/hashmap">Hash</a>.
The important bits look something like this:</p>
<pre><code>shortcode =&gt;
  filename =&gt; ｢hello.py｣
  content =&gt; ｢print("Hello")｣
</code></pre><p>I can grab the named capture <code>filename</code> of my matched <code>shortcode</code> regex with
<code>$/&lt;shortcode&gt;&lt;filename&gt;</code> — or <code>~$&lt;shortcode&gt;&lt;filename&gt;</code>, depending on your preferred syntax.</p>
<p>This is all possible in languages like Perl with assorted flags, but I haven’t seen parsing treated
so well by default since maybe <a href="https://randomgeekery.org/tags/rebol">REBOL</a>.</p>
<p>Anyways, let’s run this thing.</p>



<div><pre><code>$ raku tangle.raku
Tangled to hello.py
$ bat hello.py
───────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────
       │ File: hello.py
───────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────
   1   │ print("Hello")
───────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────</code></pre>
</div>

<p>Sweet.</p>
<p>Except — this Markdown file I’m writing.
It has <em>two</em> file code blocks now.
I want to tangle both of them.</p>
<h2 id="multiple-output-files">Multiple output files</h2>
<p>This requires a couple changes, since I’m writing code about Hugo shortcodes in a Hugo post.</p>
<p>To show shortcode directives without Hugo evaluating them, they need to look like shortcode
comments. Their contents will get passed straight through as part of your post.
To show <code>{{&lt; shortcode &gt;}}</code> in a post, your Hugo content needs <code>{{&lt;/* shortcode */&gt;}}</code>.</p>
<p>So that’s lovely and all, but can be a headache of its own for this specific situation of extracting
code from a blog post.</p>
<p>I need to remember this commented shortcode syntax.</p>










<div id=""><p><em>Define commented shortcodes</em></p>
    <pre><code data-lang="raku">  my $commented-opener = '{{' ~ '&lt;/* ';
  my $commented-closer = ' */&gt;' ~ '}}';</code></pre>
  
  </div>




<p>That way I can replace those commented shortcode delimiters with their normal counterparts when I tangle later.</p>










<div id=""><p><em>Replace commented shortcodes</em></p>
    <pre><code data-lang="raku">      my $tangle-content = $block&lt;shortcode&gt;&lt;content&gt;
        .subst(:global, / $commented-opener /, $opener)
        .subst(:global, / $commented-closer /, $closer);</code></pre>
  
  </div>



<p>Now that I have that particular detail out of the way, tangle every block? Sure! Make a regular
expression match <code>:global</code> and it returns a list containing every match.</p>










<div id=""><p><em>Tangle every block</em></p>
    <pre><code data-lang="raku">  my $markdown  = slurp $filename;
  my @fragments = $markdown.match(/&lt;shortcode&gt;/, :global);

  for @fragments -&gt; $block {
    my $tangle-file = $block&lt;shortcode&gt;&lt;filename&gt;;
    «replace-commented-shortcodes»
    spurt $tangle-file, $tangle-content;
    say "Tangled to $tangle-file";
  }</code></pre>
  
  </div>



<p>I think that about covers it. The shortcode recognition logic can stay the same.</p>






  





<div id="tangle-multi.raku"><p><a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/tangle-multi.raku" title="Download tangle-multi.raku" aria-label="Download">
          
        </a>tangle-multi.raku
    </p>
    <pre><code data-lang="raku">sub MAIN() {
  my $filename = "index.md";
  my $opener = '{{&lt; ';
  my $closer = ' &gt;}}';

  my regex shortcode {
    $opener
      code \h
      'file="' $&lt;filename&gt; = .+? '"'  # Remember the filename
      .*?
    $closer
    \n                # Ignore leading newline
    $&lt;content&gt; = .+?  # Remember everything else in the block
    \n                # Ignore trailing newline
    $opener '/code' $closer
  }

  «define-commented-shortcodes»

  «tangle-every-block»
}</code></pre>
  
  </div>



<p>And it works!</p>
<pre><code>$ raku tangle-multi.raku
Tangled to hello.py
Tangled to tangle.raku
$ bat tangle.raku
───────┬──────────────────────────────────────────────────────────────────────────────────────────────────────────────
       │ File: tangle.raku
───────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────
   1   │ sub MAIN() {
   2   │   my $filename = "index.md";
   3   │   my $opener = '{{&lt; ';
   4   │   my $closer = ' &gt;}}';
   5   │   my regex shortcode {
   6   │     $opener
   7   │       code \s
   8   │       'file="' $&lt;filename&gt; = .+? '"'  # Remember the filename
   9   │       .*?
  10   │     $closer
  11   │     \n                # Ignore leading newline
  12   │     $&lt;content&gt; = .+?  # Remember everything else in the block
  13   │     \n                # Ignore leading newline
  14   │     $opener '/code' $closer
  15   │   }
  16   │
  17   │   my $markdown = slurp $filename;
  18   │
  19   │   if $markdown.match(/ &lt;shortcode&gt; /) {
  20   │     my $tangle-file = $/&lt;shortcode&gt;&lt;filename&gt;;
  21   │     my $tangle-content = $/&lt;shortcode&gt;&lt;content&gt;;
  22   │     spurt $tangle-file, $tangle-content;
  23   │     say "Tangled to $tangle-file";
  24   │   }
  25   │ }
───────┴──────────────────────────────────────────────────────────────────────────────────────────────────────────────
</code></pre><p>Unfortunately, I’m not quite done yet.</p>
<h2 id="multiple-fragments">Multiple fragments</h2>
<p>I’m not done yet because I don’t like to describe my code a full file at a time. I’d rather talk
about this bit here, explain that bit over there, then mash it all up in the end.</p>
<p>Consistency counts, so I need to pick a syntax. Well — you’ve been reading along. You can see that I
already made my choice.  I got used to <code>&lt;&lt;fragment-text&gt;&gt;</code> in Babel, where the attribute is called
<code>name</code>. Might as well keep doing that over here. Oh but hang on. I want it to stand out a bit. I’ll
use angle quotes <code>«‥»</code>.</p>
<div>
  <p>Note</p>

  <p>On a US keyboard using <a href="https://randomgeekery.org/tags/vim">Vim or Neovim</a>, <code>«</code> is a <a href="https://vimhelp.org/digraph.txt.html#digraph.txt">digraph</a> which can be entered via <code>Control-k</code> followed by <code>&lt;</code> <code>&lt;</code>.
Or if you’ve set up a <a href="https://en.wikipedia.org/wiki/Compose_key">Compose</a> key, it’s <code>Compose</code> followed by <code>&lt;</code> <code>&lt;</code> in any editor.</p>
<p><code>»</code> is the same, but <code>&gt;</code> <code>&gt;</code> instead.</p>
<p><em>Or</em> you can use <code>&lt;&lt;…&gt;&gt;</code> in your code and ignore my recent obsession with fancy characters.</p>
<p>Yes, I know I could practically write it <em>all</em> with fancy characters in Raku. One step at a time.</p>
</div>

<p>Let’s go back to the Python code because it’s still so small.</p>
<p>Say I want to demonstrate the delightful <a href="https://rich.readthedocs.io/en/latest/">Rich</a> terminal library for Python.</p>










<div id=""><p><em>Import libraries</em></p>
    <div><pre><code data-lang="python"><span>from</span> <span>rich</span> <span>import</span> <span>print</span>
<span>from</span> <span>rich.panel</span> <span>import</span> <span>Panel</span>
<span>from</span> <span>rich.markdown</span> <span>import</span> <span>Markdown</span></code></pre></div>
  
  </div>



<p>But before I really use it in my code, I spend 1,500 words singing its praises.</p>
<p>It’s nice. I like it.</p>
<p>Okay, done singing. Time to write the rest of the program.</p>






  





<div id="rich-hello.py"><p><a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/rich-hello.py" title="Download rich-hello.py" aria-label="Download">
          
        </a>rich-hello.py
    </p>
    <div><pre><code data-lang="py"><span>«</span><span>import</span><span>-</span><span>libraries</span><span>»</span>

<span>md</span> <span>=</span> <span>Markdown</span><span>(</span><span>"**Hello**, *World*."</span><span>)</span>
<span>print</span><span>(</span><span>Panel</span><span>(</span><span>md</span><span>))</span></code></pre></div>
  
  </div>



<p>I identify the fragment with a <code>name</code> attribute:</p>
<div><pre><code data-lang="go-html-template"><span>{{</span><span>&lt;</span><span> </span><span>code</span><span> </span><span>name</span><span>=</span><span>"import-libraries"</span><span> </span><span>lang</span><span>=</span><span>"python"</span><span> </span><span>&gt;</span><span>}}</span>
from rich import print
from rich.panel import Panel
from rich.markdown import Markdown
<span>{{</span><span>&lt;</span><span> </span><span>/</span><span>code</span><span> </span><span>&gt;</span><span>}}</span>
</code></pre></div><p>My <code>code</code> block references the <code>import-libraries</code> fragment by name when I’m ready for it.</p>
<div><pre><code data-lang="go-html-template"><span>{{</span><span>&lt;</span><span> </span><span>code</span><span> </span><span>file</span><span>=</span><span>"rich-hello.py"</span><span> </span><span>&gt;</span><span>}}</span>
«import-libraries»

md = Markdown("**Hello**, *World*.")
print(Panel(md))
<span>{{</span><span>&lt;</span><span> </span><span>/</span><span>code</span><span> </span><span>&gt;</span><span>}}</span>
</code></pre></div>
<h3 id="rounding-up-fragments-to-tangle">Rounding up fragments to tangle</h3>
<p>Recognizing an additional parameter doesn’t make my regular expression <em>that</em> much more
complicated, but I can see things getting more complex — or me finding a better pattern later — so
let’s give the params their own named regex for some encapsulation.</p>










<div id=""><p><em>Shortcode params regex</em></p>
    <pre><code data-lang="raku">  my regex params {
      'file="' $&lt;filename&gt; = .+? '"'
      ||
      'name="' $&lt;fragment&gt; = .+? '"'
  }</code></pre>
  
  </div>



<p>That way I can drop it in <code>shortcode</code> to say “oh and look for <code>params</code> …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/</a></em></p>]]>
            </description>
            <link>https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819371</guid>
            <pubDate>Mon, 13 Jul 2020 10:56:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Explained: A Weekly Newsletter for React Learners]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819302">thread link</a>) | @jwworth
<br/>
July 13, 2020 | https://www.getrevue.co/profile/react-explained/ | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/react-explained/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="profile">
<div>
<section id="profile-info">
<section id="profile-image">
<figure title="React Explained"><img alt="React Explained" src="https://s3.amazonaws.com/revue/profiles/images/000/061/011/thumb/Twitter_Profile.png?1593093658"></figure>
</section>
<section id="profile-signup">
<header>
<hgroup>

<address>By Jake Worth</address>
<h2 title="React Explained - Do you want to really (really!) learn React, while staying current on this exploding ecosystem? Subscribe to React Explained, a weekly newsletter of amazing, curated React news and resources, simply explained. It’s free! Subscribe now."><p>Do you want to really (really!) learn React, while staying current on this exploding ecosystem? Subscribe to React Explained, a weekly newsletter of amazing, curated React news and resources, simply explained. It’s free! Subscribe now.</p></h2>
</hgroup>
</header>
<section id="profile-stats">
<span>60 subscribers</span>
<span><a href="#archive">9 issues</a></span>
<span><span>
<a target="_blank" href="http://twitter.com/reactexplained"><span></span>
</a></span>
</span>
<section>
<form id="new_member" action="/profile/react-explained/add_subscriber" accept-charset="UTF-8" method="post">
<div id="profile-form">
<div id="profile-form-fields">
<p><label for="member_email">Subscribe to our newsletter</label></p><div>

</div>
<p><label for="confirm_UWu7i7">This thingy has to be empti pwieshh</label>

</p>

</div>
</div>
</form></section>



</section>
</section>
</section>
</div>
</article></div>]]>
            </description>
            <link>https://www.getrevue.co/profile/react-explained/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819302</guid>
            <pubDate>Mon, 13 Jul 2020 10:46:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Mock Interviews – learn about data and SQL by solving interview tasks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23819221">thread link</a>) | @makaronich
<br/>
July 13, 2020 | https://www.sqlhabit.com/about-mock-interviews | <a href="https://web.archive.org/web/*/https://www.sqlhabit.com/about-mock-interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<div>
  <div>
    <section>
      
<div>
  

  <div><p>
    Mock Interviews will help you to get ready for an upcoming SQL interview. It's also a great way to learn and practice Data Analytics with SQL. The format is simple:
    </p>
  </div>

  <p><a href="https://www.sqlhabit.com/signup">
    Try Mock Interviews <br>for free
</a></p></div>

    </section>

    <section>
      <div>
        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews@2x-7a6e7ee7be9670546e04b57481518131981519804003b13c30b96beb72b70db9.jpg 2x">
    <img alt="Prepare for an interview" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/mock_interviews-08cd71776b51b7295bba81e2e72288d7f928fb2ada2f77bccef5e37bdf4484c4.jpg">
  </picture>

  <div>
    <h2>
      Prepare for an interview
</h2>
    <p>
      Mock Interviews are based on SQL challenges from Data Analysis, Product Management and Marketing interviews. Youâ€™ll have 45 minutes to solve 2 challenges varying in difficutly: easy, medium, hard and hardcore. <img title=":rocket:" alt="ðŸš€" src="https://twemoji.maxcdn.com/2/svg/1f680.svg">

    </p>
  </div>
</div>

        </div>

        

        <div>
          
<div>
  <picture>
    <source data-srcset="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg 1x, https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents@2x-b68c6ed4cd81b4a5d61ed804f4a8960e4ad180d40ff917f40e5e5deba66ba0fa.jpg 2x">
    <img alt="Master Data Analysis with SQL Habit course" data-src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg" src="https://d1fag1gal8cbac.cloudfront.net/assets/features_screenshots/contents-72283d8b77d40e4405092d7f5cf193e803de639ba61ac9facf8b3be8e699a85d.jpg">
  </picture>

  <div>
    <h2>
      Master Data Analysis with SQL Habit course
</h2>
    <p>
      Go beyond Mock Interviews and learn specifics of Data Analysis with SQL Habit course. Youâ€™ll not only master SQL, but learn how to apply it in different scenarios from Product Management and Marketing. All based on a story of a startup. <img title=":books:" alt="ðŸ“š" src="https://twemoji.maxcdn.com/2/svg/1f4da.svg">

    </p>
  </div>
</div>

        </div>
      </div>
    </section>

    <section>
      
<div id="pricing">
  <h2>
    Buy unlimited access to SQL Habit
  </h2>

  <div>
    <div>
      
<div>
  <p>
    FUNDAMENTALS
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>25 free</strong> lessons and exercises
          </p>
        </div>
        
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://www.sqlhabit.com/signup">Sign up</a></p><p>
        *no credit card required
      </p>

  </div>
</div>

    </div>
    <div>
      
<div>
  <p>
    COMPLETE PACKAGE
  </p>

  <div>
    <div>
        <div>
          


          <p><strong>200+</strong> lessons and exercises
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to SQL Habit, forever
          </p>
        </div>
        <div>
          


          <p><strong>Unlimited access</strong> to Mock Interviews
          </p>
        </div>
        <div>
          


          <p>
            Verified <strong>LinkedIn certificate</strong>
          </p>
        </div>
        <div>
          


          <p>
            A <strong>private Telegram group</strong> with the author and your fellow course participants
          </p>
        </div>
        <div>
          


          <div>
            <p><strong>Monthly live Q&amp;A sessions</strong>, next one is scheduled for August, 1 </p>

          </div>
        </div>
        <div>
          


          <p><strong>1 year of Datagrip</strong> for free
          </p>
        </div>
    </div>

    

    <p><a data-gumroad-single-product="true" href="https://gum.co/kwYeT">Buy now</a></p>

  </div>
</div>

    </div>
  </div>
</div>

    </section>

    <section>
        <section>
          <div>
  <h2>
    Reviews
  </h2>

  

  <div>
      <div>
        <p><span>SQL habit is the best online course I have done! It is my number one recommendation when it comes to learn SQL, for a beginner or even an advanced user.</span>

Anatoli has a gift to teach through examples in a very fun and playful way. The course covers real life example of the data analysis function of a company, starting with accessible SQL (read no prior experience needed), to very advanced SQL (yes, I mean...
        </p>

          
      </div>
      <div>
        <p><span>I am so excited that I have finally learnt SQL and realised how much I can gain from it in my daily work! The course gave me a better understanding of Marketing and Product Analytics</span> â€” how data is tracked, stored and interpreted â€” on web and for mobile apps. I can't wait to put my new skills into practice! I have tested few SQL courses and I would highly recommend SQL Habit without a doubt! Thank you very...
        </p>

          <p>
            Artur, Marketing Analyst @ Babbel
          </p>
      </div>
      <div>
        <p>
          SQL was something I never touched before starting this course. But being a Product Designer, I often asked my colleagues about how many users saw a specific landing page, where did they come from, how many people signed up, etc. It made me want to learn more about the data behind those magic numbers I got from them all the time. <span>This course was an incredible help to understand exactly that and it made me way more...
        </span></p>

          <p>
            Franziska, Product Designer
          </p>
      </div>
  </div>
</div>

        </section>
    </section>

    <section>
      
<div>
  <h2>
    Frequently Asked Questions
  </h2>

  <div>

      <div>
    <p>Can I try the course for free?</p>

    <p>Absolutely. The first 33 lessons and exercises are free. Just <a href="https://www.sqlhabit.com/users/new">signup</a> with your email, no credit card info required.</p>
  </div>
  <div>
    <p>Do you accept PayPal purchases?</p>

    <p>SQL Habit uses Gumroad to accept payment and Gumroad supports PayPal.</p>
  </div>
  <div>
    <p>Can I get an invoice?</p>

    <p>Absolutely! Right after purchasing youâ€™ll get a receipt which includes a link to generate an invoice with any extra information you need to add for your own accounting purposes.</p>
  </div>
  <div>
    <p>Do you have monthly subscription?</p>

    <p>Nope, one time purchase allows you to access it <strong>forever</strong>. Honestly, I believe itâ€™ll take you 1-2 months to really develop this strong SQL Habit. <img draggable="false" title=":muscle:" alt="ðŸ’ª" src="https://twemoji.maxcdn.com/2/svg/1f4aa.svg"></p>
  </div>
  <div>
    <p>Can I purchase SQL Habit for my team/company?</p>

    
  </div>
  <div>
    <p>What if I realize itâ€™s not for me?</p>

    <p>No problem! Ping me at <a href="mailto:support@sqlhabit.com">support@sqlhabit.com</a> and youâ€™ll be refunded in full, no questions asked (except feedback).</p>
  </div>

  </div>
</div>

    </section>
  </div>
</div>

    </div></div>]]>
            </description>
            <link>https://www.sqlhabit.com/about-mock-interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819221</guid>
            <pubDate>Mon, 13 Jul 2020 10:32:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A $50.000/year streaming service]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23819201">thread link</a>) | @gianlucahmd
<br/>
July 13, 2020 | https://blog.gianlucamauro.com/post/harvard-online-learning/ | <a href="https://web.archive.org/web/*/https://blog.gianlucamauro.com/post/harvard-online-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <section>
  
</section>










        

<section>

    <section id="articleHero">
    <div>
        <header>
            
            <div>
                <div>
                    


    
            
    



<p>
                    July 10, 2020
                     • 3 min read
                </p></div>
            </div>
        </header>
        
        
        
    </div>
</section>

    

    <article id="articleContent">
        <p>Harvard University announced that next academic year will be 100% online.</p>
<p>And the tuition won’t be a dime cheaper.</p>
<p><img src="https://blog.gianlucamauro.com/images/harvard.png" alt=""></p>
<p>Why does it matter?</p>
<p>I don’t want to question the worthiness of such an investment. Yet, I can’t help but wonder if you’ll loose some of your returns by switching from the Harvard University halls to your web browser.</p>
<p>When you give $50.000 to a University like Harvard, you’re paying for a bunch of stuff. Mainly:</p>
<ul>
<li>Prestige</li>
<li>The network (your network is your net worth, right?)</li>
<li>Learning, obviously</li>
</ul>
<p>How will the new experience impact these aspects?</p>
<p>The prestige will stay intact. You can show off your Harvard badge on LinkedIn without having to specify where you studied.</p>
<p>I don’t think that you’ll get exposure to the same network as with physical classes. Human connection is paramount to build strong social ties. Yes, you can talk to people trough Zoom and stuff. But let’s stop hiding: Zoom is a poor quality proxy for face to face interaction. Hopefully when Covid will be over students will catch up with the social interactions they missed.</p>
<p>Let’s talk about learning now.</p>
<p>For years, online learning has been seen as a “second choice” learning format. Yes, it’s more comfortable and democratic than “real” university learning, but at the cost of some quality. I have to admit, I was guilty myself of this bias a few years ago.</p>
<p><strong>By changing medium without touching its price tag, Harvard changed the game. Harvard stated loud and clear that online learning is still learning. And it’s worth as much.</strong></p>
<p>This is a huge win for people like me that work hard to create the best online educational content possible.</p>
<p>This legitimates online learning. It acknowledges that the medium does not devaluate the knowledge, passion and teaching skills of the teacher.</p>
<p>Among all the change that Covid has brought to our lives, some will stick forever. Once the stigma around online learning will be gone, we’ll be left with a more democratic way of learning.</p>
<p>Who has something to teach will be free of sharing his experience without fear. Who wants to improve herself will be free to do so without the entry barriers of the Harvard halls.</p>
<p>And my biggest wish of all: <strong>companies will treat people that built their education online with the same respect of who spent $200.000 to sit in Harvard’s classrooms.</strong></p>
<blockquote>
<p>Let the future tell the truth, and evaluate each one according to his work and accomplishments - Nikola Tesla</p>
</blockquote>

    </article>
    
    

<section id="subscriptionSection">
    <div>
        <div>
            <h3>
                Get my thoughts in your inbox
            </h3>
            <p>
                Join my subscribers to get curated emails with my posts. 
                No spam, no marketing bullshit. Opt-out at anytime. You have my word I won't not spam your inbox or share your email with any third parties.
            </p>


            

        </div>
    </div>
</section>











    
    
    
        
    




<section id="articleNext">
    
    
    
</section>


</section>







 

        
        
    

    </div></div>]]>
            </description>
            <link>https://blog.gianlucamauro.com/post/harvard-online-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819201</guid>
            <pubDate>Mon, 13 Jul 2020 10:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meddling Middlemen of Academia]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 50 (<a href="https://news.ycombinator.com/item?id=23819130">thread link</a>) | @Topolomancer
<br/>
July 13, 2020 | https://bastian.rieck.me/blog/posts/2020/middlemen/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/middlemen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>One of the strangest phenomena in academia is the reliance on publishing
companies. In this article, I want to outline some of the issues that
arise when working with publishers. I shall also endeavour to provide
some solutions to improve this collaboration.</p>
<p>Before we start, a brief <strong>disclaimer</strong>: this article will use an
amalgamation of different incidents that involved either myself, my
colleagues, or my friends.  Names&nbsp;(of the publishing companies)
have been withheld because I do not think it fair to use my ‘soapbox’
without giving the <em>other</em> side a chance to respond. Moreover,
everything I write here pertains to publishing your research in
a journal. Conference publishing—at least in machine learning—is
a joy<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. Plus, there <em>are</em> good examples of journals for machine
learning papers, foremost of them the <a href="http://www.jmlr.org/">Journal of Machine Learning
Research</a>. The ‘adversaries’ in this article are
rather the ‘big’ publishing companies and their practices. With that out
of the way, let us take a look at the state of the art!</p>

<p>If you are new to science, at some point, you will probably have to deal
with an established publishing company to get your article published.
The deal usually works like this:</p>
<ol>
<li>
<p>You look for a journal you want to publish in and submit your article
to the journal. This already often involves jumping through some
hoops. Without knowing the eventual fate of your article, you often
already have to abide by certain arbitrary formatting guidelines or
completely ‘butcher’ your article for the submission<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> by shifting
content around. However, this can be all accepted and endured because
of course, you want something from <em>them</em>, i.e. a published,
citable publication!</p>
</li>
<li>
<p>The journal then receives your submission—often through a web
interface that was developed with all the UX/UI knowledge of the
1980s<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> and has <em>never</em> been updated since—and this is where it gets
slightly <em>murky</em>. Another person—typically the editor of the
journal—now decides whether to accept the paper for reviewing, or
whether to provide you with a desk reject. A desk reject usually cannot
be appealed. It just shows you the door and leaves you to try again
with another journal&nbsp;(more murkiness here). For early-career
researchers like Ph.D. students submitting their first paper,
this can be highly discouraging. I see the reason for reducing the
workload on reviewers, of course, but I also heard of academic feuds
that were carried out on the backs of Ph.D. students and their
publications.</p>
</li>
<li>
<p>Assuming your paper ‘survived’ the desk reject, it will now be sent
to reviewers or referees. Their job is to review your paper
thoroughly, provide feedback, and in general give this whole business
a formal veneer. Setting aside problems in the reviewing
process—which I discussed <a href="http://bastian.rieck.me/blog/posts/2019/reviewing/">in another blog post</a>—this again opens up a portal into
a strange dimension: working as a reviewer for a journal is usually
a job that is provided for free&nbsp;(same goes for editorial
duties). Notice that this is <em>despite</em> the fact that those journals
are charging money to readers and universities. ETH Zurich, my
current employer, describes their experiences of the <a href="https://www.library.ethz.ch/en/Services/Using-ordering-resources/National-negotiations-with-publishers-Read-publish-reorganised">negotiations
with
publishers</a>
and mentions an expenditure of 6.4 million EUR&nbsp;(roughly 7.25
million USD) per year for being allowed to access journal articles.
That is a lot of money.</p>
<p>Setting aside the actual numbers here, let me just point out how
strange it is that companies are relying on <em>unpaid labour</em>, and this
reliance is <em>crucial</em> to their business model. They often do not
employ people that are qualified to judge the content that they want
to publish! But of course, reviewers and editors get the benefit of
<em>exposure</em>—that wonderful currency that is supposed to help your
career along! Even stranger: journals often charge hefty sums for
accessing your own research articles. To me, it is super weird that
research that is often <em>funded</em> by the taxpayer cannot be <em>accessed</em>
by the taxpayer.</p>
</li>
<li>
<p>Supposing your article got sufficiently good reviews to be published,
the next stage of the process starts. This is where the <em>meddling</em>
begins in earnest. After a little back and forth, you article will be
changed according to some arbitrary rules: the last period of every
sentence in an image caption will be removed, footnotes will be put
into the text—because for some reason, footnotes are permitted in
virtually every template and publishing medium, but deemed somewhat
uncouth by certain publishers—and you might have to redo certain
parts of your paper because of subtle font changes or what have you.</p>
<p>Again, lest you think of me as a particularly cranky person prone to
grumbling and finding faults, you are getting the wrong idea here.
I do not object to these changes, but I <em>do</em> object to the fact that
these meddlesome changes often decrease the quality of your paper.
Here are some irksome changes:</p>
<ul>
<li>
<p>Footnotes will be inserted willy-nilly into the text, regardless of
whether they make sense or not. That might break the flow of your
paper, but that is <em>your</em> problem.</p>
</li>
<li>
<p>Some ‘publisher house rules’ conflict with proper nomenclature in
a field. For example, the journal might have the ‘rule’ that all
fields in a table have to be capitalised. If this clashes with
nomenclature in your field, it is—you guessed it—<em>your</em> problem.</p>
</li>
<li>
<p>Your equations will typically be typeset yet
another time for you<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, which might introduce subtle changes: symbols
will change and you have to be go through your own paper once again
line-by-line to see whether anything untoward happened. Again, I am
primarily objecting to the substandard quality of this meddling:
the work that you put into writing your equations is completely
ignored, and now you have to chase—often very subtle—changes in
your own text. For mathematical typesetting, precision is crucial,
and it is unbecoming when people who do not <em>care</em> about this
precision create more work for you.</p>
</li>
<li>
<p>As a last example, your figures might be meddled with: you might be
forced to convert them into obsolete file formats&nbsp;(because
apparently, EPS is still the best format available), or, more
appallingly, vector graphics might be converted to raster
images&nbsp;(judging from the experiences of my friends and myself,
this is unfortunately relatively common!). This might sound like a tiny
problem again, but it decreases readability and accessibility for
some readers, and, more to the point of this post, it is somewhat
unnecessary meddling.</p>
</li>
</ul>
<p>Let me re-iterate my main point: I do not object to changing my
paper, I merely object to meddlesome changes that are just generating
useless work. For example, there is no need whatsoever to typeset
your equations again—this is quite literally the definition of
negative work.</p>
</li>
<li>
<p>If you survived this ordeal intact, you now must <em>pay</em>. To be fair,
not all journals charge you for normal articles, but <em>most</em> of them
charge you for open access publishing. In other words: if I want my
research, which is generously funded<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> by the Swiss taxpayers, to
be available to those selfsame taxpayers, I have to pay. The amounts
vary a little bit, of course, but we are talking upwards of a few
hundred USD at least. Luckily, this is <em>not</em> a problem for my
research group; my postdoctoral adviser, <a href="https://bsse.ethz.ch/mlcb/karsten.html">Prof. Karsten
Borgwardt</a> ensures that
sufficient funds for open access publications are available.</p>
<p>Interestingly, sometimes the cost is fielded by a conference; this
happens when the conference has a contract that ensures that its
publications will be available as special issue of some journal.
This might seem nice because it <em>shifts</em> the costs away from authors,
but it is also somewhat non-transparent; conference costs being high
already, I find it strange that some of the money goes into the
pockets of another party.</p>
<p>After all this negativity, it is time for a <em>positive example</em>:
NeurIPS, one of the flagship machine learning conferences, is
partnered with a publisher and makes <em>all</em> papers available for free
online. I <em>gladly</em> pay the conference fee for this!</p>
</li>
</ol>

<p>How can this process be improved? I have a few suggestions:</p>
<ol>
<li>
<p><strong>Transparency</strong>: publishers should make it clear <em>where</em> the funds are
going. Are we increasing shareholder value by working for free? How
are profits split and used?</p>
</li>
<li>
<p><strong>Giving back</strong>: it is generally understood that everyone needs to eat
and no one should have to work for free. Why is then that this
completely different in publishing? Almost all the profits are
essentially generated because editors and reviewers work for free.
I know that being remunerated for your reviewing work might raise
some questions about impartiality etc., so I think <em>paying</em> people to
write reviews might be somewhat problematic.</p>
<p>However, closely related to my point about transparency, publishers
could be more upfront about how they user their funds and <em>give back</em>
to the community. For example, publishers could sponsor students so
that they can visit a conference for free, or publishers could
sponsor the conferences themselves.</p>
<p>If you, as a publisher, engage the community and give back a little,
the community will be all the more happy to work with you. We need
you, but you also need us. Without the scientists, you cannot be
a scientific publisher.</p>
</li>
<li>
<p><strong>Commitment to excellence</strong>: publishers should commit to the highest
quality and the highest standards. Employ people that are capable of
working <em>with</em> the scientists, not <em>for</em> the scientists. Train your
employees to be experts in typography, typesetting, and pair them
with domain experts so that they do not create more work for the
authors by inadvertently destroying equations, figures, and so on.</p>
<p>This goal is not necessarily orthogonal to maximising your profits,
by the way: if you lower your standards, your reputation as
a publisher will suffer, meaning that scientists in the long
run&nbsp;(!) might not be willing to publish with you any more. If
you commit to excellence, by contrast, we will flock to you.</p>
<p>I know that working with a publisher that <em>cares</em> about the end
product as much as I do is a heavenly match! So we should endeavour
to make such …</p></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bastian.rieck.me/blog/posts/2020/middlemen/">https://bastian.rieck.me/blog/posts/2020/middlemen/</a></em></p>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/middlemen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23819130</guid>
            <pubDate>Mon, 13 Jul 2020 10:16:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Real World Programming in SWI-Prolog]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23818901">thread link</a>) | @luu
<br/>
July 13, 2020 | http://www.pathwayslms.com/swipltuts/ | <a href="https://web.archive.org/web/*/http://www.pathwayslms.com/swipltuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>This is a hopefully ever expanding collection of tutorials on aspects of the SWI-Prolog environment.
Our emphasis is on learning to write <b>real world</b> applications in SWI-Prolog.</p>

<ol>
<li><a href="http://www.pathwayslms.com/swipltuts/dcg/index.html">Definite Clause Grammars</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/html/index.html">Web Applications</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/clpfd/clpfd.html">Constraint Logic Programming over Finite Domains</a> by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/message/index.html">Printing Messages in SWI-Prolog</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
<li><a href="http://www.pathwayslms.com/swipltuts/chr/index.html">Constraint Handling Rules</a>by <a href="mailto:annie@theelginworks.com">Anne Ogborn</a></li>
</ol>

<h2>Stuff that's in the general vein of the <i>Real World</i> tutorials, but are by others</h2>
<ul>
<li>There is a <a href="http://swish.swi-prolog.org/example/dict.swinb">SWISH tutorial on the dict structure</a> that was introduced with revision 7.0</li>
<li>There is a <a href="http://swish.swi-prolog.org/example/tabling.swinb">SWISH tutorial on tabling</a> that was introduced with 7.2.3</li>
<li>Michael Richter maintains a tutorial on using modules with SWI-Prolog <a href="http://chiselapp.com/user/ttmrichter/repository/gng/doc/trunk/output/tutorials/swiplmodtut.html">Using Modules with SWI-Prolog</a></li>
<li>Michael Hendricks has a tutorial for his vastly nifty pack "Julian" for reasoning about dates and times <a href="http://mndrix.github.io/julian/index.html">Julian tutorial</a></li>
<li>The Amzi Corporation maintains a useful introduction to expert systems <a href="http://www.amzi.com/ExpertSystemsInProlog/">Expert Systems in Prolog</a></li>
</ul>

<h2>Other stuff by me (Anne Ogborn) about Prolog</h2>
<li><a href="http://www.pathwayslms.com/swipltuts/student/index.html">FAQ For The ##Prolog Channel</a> by Anne Ogborn and Michael Richter</li>
<li>A little story about <a href="http://www.pathwayslms.com/swipltuts/teacher/index.html">teaching Programming Languages courses that include Prolog</a></li>
<li><a href="https://www.youtube.com/watch?v=JmOHV5IlPyU">Youtube video (35 mins) of my tutorial on Pengines at Strange Loop 2014</a></li>
<li><a href="https://www.youtube.com/watch?v=G_eYTctGZw8">Youtube video (40 mins)</a> of Michael Hendricks' talk on Production Prolog, with great hints on practical Prolog</li>
<li>I gave a workshop on SWI-Prolog web development at <a href="https://thestrangeloop.com/">Strangeloop 2013</a> The workshop materials were basically the set of html tutorials collected into a single program. <a href="https://github.com/Anniepoo/strangeloop">You can get them here</a>.</li>

<h2>Selected other folks' tutorials and info about prolog</h2>
<ul>
<li>Roman Bartok maintains a great <a href="http://kti.ms.mff.cuni.cz/~bartak/prolog/index.html">tutorial introduction to Prolog</a></li>
<li>The introductory book <a href="http://lpn.swi-prolog.org/lpnpage.php?pageid=online">Learn Prolog Now</a> is online, and has embedded SWISH so you can run the examples right in the text</li>
<li>Help, my brain is melting <a href="http://www.pathwayslms.com/swipltuts/())).pl">())).pl</a></li>
</ul>

<h2>Contribute!</h2>
<p>We'd love to have more contributors of tutorials. Areas we'd love to see covered: Pldoc, The IDE, CLP, Expert Systems, aggregator library, and whatever else excites you.</p>



</div>]]>
            </description>
            <link>http://www.pathwayslms.com/swipltuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818901</guid>
            <pubDate>Mon, 13 Jul 2020 09:37:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dark Web Price Index 2020]]>
            </title>
            <description>
<![CDATA[
Score 282 | Comments 197 (<a href="https://news.ycombinator.com/item?id=23818727">thread link</a>) | @known
<br/>
July 13, 2020 | https://www.privacyaffairs.com/dark-web-price-index-2020/ | <a href="https://web.archive.org/web/*/https://www.privacyaffairs.com/dark-web-price-index-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><b>The dark web has a longstanding reputation as a haven for the worst kinds of criminal activity. This reputation is not wholly unjustified, as there are indeed terrible things happening around the world that can be bought and sold on the dark web. </b></p><p><span>The privacy offered by software such as TOR creates an environment where criminals can sell their wares on the dark web without the worry of law enforcement.</span></p><p><span>What’s more, many will have heard the horror stories of people’s bank accounts being cleaned out, or their identity stolen and turning up in custody in Mexico. Again, not unjustified horror.</span></p><p><span>You might be asking yourself, just how easy is it to obtain someone else’s personal information, documents, account details?&nbsp;</span></p><p><span>We certainly were.</span></p><p><span>To see just how prevalent such items of personal data are being listed, and at what price, we sent our researchers on a data-gathering mission into the dark web.</span></p><table><tbody><tr><td>Category</td><td>Product</td><td>Avg. dark web Price (USD)</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#2">Credit Card Data</a></td><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td></td><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td></td><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td></td><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td></td><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td></td><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td></td><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td></td><td>Walmart account with credit card attached</td><td>$10</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#3">Payment processing services</a></td><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td></td><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td></td><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td></td><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#4">Forged documents</a></td><td>US driving license, average quality</td><td>$70</td></tr><tr><td></td><td>US driving license, high quality</td><td>$550</td></tr><tr><td></td><td>Auto insurance card</td><td>$70</td></tr><tr><td></td><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td></td><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td></td><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td></td><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td></td><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td></td><td>Europe national ID card</td><td>$550</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#5">Social Media</a></td><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td></td><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td></td><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td></td><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td></td><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td></td><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td></td><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td></td><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td></td><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td></td><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td></td><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td></td><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td></td><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td></td><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td></td><td>Instagram likes x 1000</td><td>$6</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#6">Malware</a></td><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td></td><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td></td><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td></td><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td></td><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td></td><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td></td><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td></td><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td></td><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td></td><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td></td><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td></td><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td></td><td>Android x 1000</td><td>$600</td></tr><tr><td></td><td>Premium x 1000</td><td>$6000</td></tr><tr><td><a href="https://www.privacyaffairs.com/dark-web-price-index-2020/#7">DDoS Attack</a></td><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td></td><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td></td><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table></section><div><section id="1"><h2>What We Found</h2><p>Whilst there are many marketplaces on the dark web, there are even more forum posts warning of scammers. This makes verified prices difficult to obtain without ordering the items to find out, which of course we didn’t.</p><p>Our methodology was to scan dark web marketplaces, forums, and websites, to create an index of the average prices for a range of specific products.</p><p>We were only interested in products and services relating to personal data, counterfeit documents, and social media.</p><p>This is what we found.</p></section><section id="2"><h2>Cloned credit cards and associated data</h2><table><tbody><tr><td>Product</td><td>Average dark web Price (USD)</td></tr><tr><td>Cloned Mastercard with PIN</td><td>$15</td></tr><tr><td>Cloned American Express with PIN</td><td>$35</td></tr><tr><td>Cloned VISA with PIN</td><td>$25</td></tr><tr><td>Credit card details, account balance up to $1000</td><td>$12</td></tr><tr><td>Credit card details, account balance up to $5000</td><td>$20</td></tr><tr><td>Stolen online banking logins, minimum $100 on account</td><td>$35</td></tr><tr><td>Stolen online banking logins, minimum $2000 on account</td><td>$65</td></tr><tr><td>Walmart account with credit card attached</td><td>$10</td></tr></tbody></table><p>Credit card details usually come in the format CC|MM|YY|CVV|HOLDER_NAME|ZIP|CITY|ADDRESS|EMAIL|PHONE with the first 4 sections being the details on the card and the rest the details of the account holder. This will definitely cause a major inconvenience, but the prospect of someone using your online banking logins to gain full access to your account is far more daunting.</p><p><a href="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png"><img src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" data-src="https://mk0privacyaffaidetc8.kinstacdn.com/wp-content/uploads/2020/05/Screenshot-1040-e1590230436263.png" alt="Dark web credit card price" width="840" height="447"></a></p><p>Vendors tend to offer a guarantee of 80%. Meaning that two of every ten cards either won’t work or will have less than the advertised balance. We didn’t order any so can’t verify whether this is true, but the prevalence of these claims alongside the well documented increase in identity fraud cases suggests that there is a high turnover of such data.</p></section><section id="3"><h2>Payment processing services</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Stolen PayPal account details, minimum $100</td><td>$198.56</td></tr><tr><td>PayPal transfer from stolen account, $1000 – $3000</td><td>$320.39</td></tr><tr><td>PayPal transfers from stolen account, $3000+</td><td>$155.94</td></tr><tr><td>Western Union transfer from stolen account, above $1000</td><td>$98.15</td></tr></tbody></table><p>PayPal account details were easily the most common items listed, and extremely cheap. More expensive was actual transfers from a hacked account.</p><p>Another very common item for sale was guides on how to “cash out” – actually get the money in a way that doesn’t alert the authorities. These guides go for a few cents, but whether or not they actually work is not what we were looking for.</p></section><section id="4"><h2>Forged documents</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>US driving license, average quality</td><td>$70</td></tr><tr><td>US driving license, high quality</td><td>$550</td></tr><tr><td>Auto insurance card</td><td>$70</td></tr><tr><td>AAA emergency road service membership card</td><td>$70</td></tr><tr><td>Wells Fargo bank statement</td><td>$25</td></tr><tr><td>Wells Fargo bank statement with transactions</td><td>$80</td></tr><tr><td>Rutgers State University student ID</td><td>$70</td></tr><tr><td>US, Canada, or Europe passport</td><td>$1500</td></tr><tr><td>Europe national ID card</td><td>$550</td></tr></tbody></table><p>These documents came with a range of guarantees and are available with any details the buyer chooses. With just a few pieces of real information about someone, a criminal could create a whole file of official documents to be used for all sorts of fraudulent activities. This one way in which an identity is stolen.</p><h3>Counterfeit money</h3><p>Counterfeit banknotes are extremely common, mainly in 20 or 50 denominations.</p><p>We came across USD, EUR, GBP, CAD, AUD most often. Some come with a UV pen test guarantee. The “quality” ones tend to cost around 30% of the banknote value.</p></section><section id="5"><h2>Social media</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Hacked Facebook account</td><td>$74.5</td></tr><tr><td>Hacked Instagram account</td><td>$55.45</td></tr><tr><td>Hacked Twitter account<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$49</td></tr><tr><td>Hacked Gmail account</td><td>$155.73</td></tr><tr><td>Instagram followers x 1000</td><td>$7</td></tr><tr><td>Spotify followers x 1000</td><td>$3</td></tr><tr><td>Twitch followers x 1000</td><td>$6</td></tr><tr><td>Tick Tok followers x 1000</td><td>$15</td></tr><tr><td>LinkedIn followers x 1000</td><td>$10</td></tr><tr><td>LinkedIn company page followers x 1000</td><td>$10</td></tr><tr><td>Pinterest followers x 1000</td><td>$5</td></tr><tr><td>Soundcloud plays x 1000</td><td>$1</td></tr><tr><td>Daily Motion views x 1000</td><td>$2</td></tr><tr><td>Twitter retweets x 1000</td><td>$25</td></tr><tr><td>Instagram likes x 1000</td><td>$6</td></tr></tbody></table><p>Offers to hack accounts or sell them were relatively scarce, but not non-existent. Perhaps due to a lack of demand for the product coupled with increased security practices. Hackers trying to get the social media credentials from their victims mostly have to resort to using <a href="https://www.getsafeonline.org/blog/what-is-pii-and-how-do-you-keep-it-private/">social engineering techniques</a>, which have a very high effort input for relatively low success ratio.</p><p>The extremely low cost for social engagement should seriously make you question an account’s validity before blindly trusting their wealth of social currency.</p></section><section id="6"><h2>Malware</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Global low quality, slow speed, low success rate x 1000</td><td>$70</td></tr><tr><td>Europe low quality, slow speed, low success rate x 1000</td><td>$300</td></tr><tr><td>USA, CA, UK, AU low quality, slow speed, low success rate x 1000<a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$800</td></tr><tr><td>Global med quality, 70% success rate x 1000</td><td>$80</td></tr><tr><td>Europe med quality, 70% success rate x 1000</td><td>$700</td></tr><tr><td>USA only med quality, 70% success rate x 1000</td><td>$900+</td></tr><tr><td>USA, CA, UK, AU med quality, 70% success rate x 1000</td><td>$1300</td></tr><tr><td>Europe fresh high quality x 1000</td><td>$2300</td></tr><tr><td>Europe aged high quality x 1000</td><td>$1400</td></tr><tr><td>USA high quality x 1000</td><td>$1700</td></tr><tr><td>CA high quality x 1000</td><td>$1500</td></tr><tr><td>UK high quality x 1000</td><td>$2000</td></tr><tr><td>Android x 1000</td><td>$600</td></tr><tr><td>Premium x 1000</td><td>$6000</td></tr></tbody></table><p>Malicious tools are installed on comprised systems (Windows, Android and others) which gives attackers access to the system. Initial installation is via fake online casino, FB/social networks, warez websites etc.</p><p>Some forms of malware may simply use your computer’s resources for activities such as cryptocurrency mining. Others may be used to steal credentials as you enter them on a website. For each 1000 installs, hackers can often steal tens of thousands of dollars.</p></section><section id="7"><h2>DDoS attack</h2><table><tbody><tr><td>Product</td><td>&nbsp;Average dark web Price (USD)</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 hour</td><td>$10</td></tr><tr><td>Unprotected website, 10-50k requests per second, 24 hours</td><td>$60</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 week<br> <a id="mcegrid91" href="https://www.privacyaffairs.com/wp-admin/post.php?post=7083&amp;action=edit#" data-mce-x="1" data-mce-y="9"></a></td><td>$400+</td></tr><tr><td>Unprotected website, 10-50k requests per second, 1 month</td><td>$800+</td></tr><tr><td>Premium protected website, 20-50k requests per second, multiple elite proxies, 24 hours</td><td>$200</td></tr></tbody></table><p>A distributed denial of service (DDoS) attack aims to take a website offline by sending thousands of requests per second in order to overload the website’s server, causing it to crash.</p></section><section id="8"><h2>Why This Data Is Important</h2><p>For the average person, underground market data isn’t necessarily going to provide much use as they most likely aren’t shopping around for stolen card data or PayPal accounts. Though this is true, the prices at which these items sell provide a powerful perspective.</p><p>If someone gets their hands on your financial details or social media credentials, the prices mentioned above is basically what it’s worth to them. There’s a good chance that you value these things much more than they do, as to them you’re just another mark for a quick buck.</p><p>For far less than the amount your data would sell for on the black market, you can protect it from ever having to reach their hands with a couple of simple rules and habits. With this knowledge, there’s no excuse not to do what you can to protect your data.</p><p>Nothing is foolproof however, and …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.privacyaffairs.com/dark-web-price-index-2020/">https://www.privacyaffairs.com/dark-web-price-index-2020/</a></em></p>]]>
            </description>
            <link>https://www.privacyaffairs.com/dark-web-price-index-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818727</guid>
            <pubDate>Mon, 13 Jul 2020 09:08:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial sites treating FreeBSD like a Linux distro]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 77 (<a href="https://news.ycombinator.com/item?id=23818702">thread link</a>) | @todsacerdoti
<br/>
July 13, 2020 | https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/ | <a href="https://web.archive.org/web/*/https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div property="articleBody">
<p>On the Gold Coast in January, Deb Goodkin from the FreeBSD Foundation began her Linux.conf.au talk with an intentionally-provocative slide: <em>FreeBSD, that’s just another Linux distro, right?</em> It was said in jest to highlight what a common misconception it is.</p>
<p>One way this manifests is through introductory FreeBSD guides online, usually on blogs with the words sysadmin, cookbook, or tutorial in their names; you know the ones I’m talking about. Invariably they advise updating the base system and pkgng, then immediately installing bash, nano, htop, lsof, coreutils, proc, and more. Some go as far as aliasing these over the built-in tools, and even setting bash as the root shell. From then on, you barely have to touch the FreeBSD userland.</p>
<p>Like a poorly-maintained cheese utensil, this used to grate. If you’re installing an entire GNU toolchain, why not use a Linux distribution, or Debian/kFreeBSD, or a Nexenta-like OS that’s built specifically for those tools? You’re not learning about FreeBSD’s features, nor are you taking advantage of any of its benefits beyond the kernel and base. It’s wasted opportunity, and could render future project contributions more difficult because of misunderstood assumptions about how the system works.</p>
<p><img src="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg" srcset="https://rubenerd.com/files/2020/usebsd-pillow@1x.jpg 1x, https://rubenerd.com/files/2020/usebsd-pillow@2x.jpg 2x" alt="A photo of a pillow saying: Use BSD"></p>
<p>I’ve since changed my tune somewhat, with a caveat. I also want to take this opportunity— not a sponsor—to spruik Jay Patel’s <a href="https://www.redbubble.com/people/jaypatelani/shop">RedBubble store</a> for your BSD laptop and loungeroom. I’ve already added some to next sticker batch.</p>
<p>What was I talking about?</p>
<p>We should be encouraging Linux people to try FreeBSD, and if giving them their familiar tooling gets their foot in the door, it’s worth it. I personally learn things the quickest by jumping in the deep end, but I know others want to take things a step at a time.</p>
<p>What also gets lost in the fray is FreeBSD, even with all those Linux-focused tools, is still a compelling and useful operating system. It’s a feature not a bug to be able to have all these tools available, and at times run them faster than Linux could on the same hardware. It may even integrate better into shops that otherwise entirely run Linux, given the motivation to write portable, POSIX-compliant code and applications is no longer a priority for most people (sadface).</p>
<p>So rather than saying those guides aren’t useful or even misrepresent FreeBSD, we need to reframe them. Instead of <em>introductions to FreeBSD</em>, say they’re <em>FreeBSD for Linux people</em>. This shouldn’t be constued as criticism; the latter kinds of post would be <em>hugely</em> useful. It’s also then easier to introduce BSD-specific tools and ideas, either inline after each Linuxism you introduce, or in a follow-up post where you compare and contrast.</p>
<p>We need more bridge-building and outreach between the two communities, and anything to make FreeBSD relatable to people coming from Linux, or any other operating system, is useful.</p>
</div></div>]]>
            </description>
            <link>https://rubenerd.com/tutorial-sites-treating-freebsd-like-a-linux-distro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818702</guid>
            <pubDate>Mon, 13 Jul 2020 09:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Erasmus University Rotterdam builds first virtual campus in the Netherlands]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23818681">thread link</a>) | @vinrob92
<br/>
July 13, 2020 | https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands | <a href="https://web.archive.org/web/*/https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-history-node-id="61036"><p><span><p><time datetime="2020-07-09T12:13:58Z">Thursday, 9 Jul 2020</time></p> </span><span><p>Press release</p> </span></p> <figure> </figure><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Erasmus University Rotterdam (EUR) has re-created their Woudestein campus in the Minecraft platform to provide students and staff a sense of purpose and community during the Covid-19 crisis, a first for the Netherlands. The first blocks of the campus were laid by a small team of enthusiastic students and the project has since then mushroomed to include all buildings on campus, a secret underground labyrinth which players need to find, a treasure hunt for the 17 SDGs (de UN Sustainable Development Goals) and much more. </span></span></span></span></span></span></span></p><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Expansion plans are in the works for the Erasmus Medical Centre and the Erasmus University College. Through this project, EUR aims to fight the Covid-19 setback to the start of the academic year 2020-2021, by giving a platform to the Erasmus community to engage with each other.</span></span></span></span></span></span></span></p><div> <article data-video-provider="YouTube" data-video-id="cQ_Ke1z_Cjo"><div> <picture> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=7Ncx-0nR 1x" media="(min-width: 992px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_desktop/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=pjuiFzAV 1x" media="(min-width: 768px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_tablet/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=SqdQGgEy 1x" media="(min-width: 480px)" type="image/png"> <source srcset="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ 1x" type="image/png"> <img src="https://www.eur.nl/sites/corporate/files/styles/video_still_mobile/public/2020-07/schermafbeelding-2020-07-08-om-16.08.10.png?h=8e0346e5&amp;itok=38IaSabQ" alt="Introducing The Virtual Campus - Erasmus University Rotterdam"> </picture></div><div> <h2>Introducing The Virtual Campus - Erasmus University Rotterdam</h2></div></article></div><div><h2>Campus recreated brick by brick</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>It started off as a project to provide students an opportunity for social engagement outside of the Zoom-filled lectures after the Covid-19 pandemic brought universities to a physical shutdown. After a research the Erasmus University Rotterdam (EUR) conducted into the effects of the Corona Crisis on the well-being of its students and staff members, the results strongly pointed towards the need for something to keep the Erasmus community together. People started to feel lonely and missed the ability to socially interact with each other, exactly that what a physical campus is able to provide a podium for. In an attempt to tackle this issue, ErasmusX – a disruptive innovative unit of the university – launched a creative project whereby students and staff could recreate their beloved Woudestein campus in the virtual gaming platform Minecraft. The very first building blocks were laid by members of the student-led Erasmus E-sports Community, and thereafter a professional Minecraft building team helped polish up the final product.</span></span></span></span></span></span></span></p></div><div><h2>"What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale"</h2></div><div><div><h2>Woudestein: a place to meet friends</h2><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>To the EUR community, the campus is not just a place you go to in order to study and work. It is a place where you meet your friends (that perhaps have become like family), where you develop yourself as a human being, where you hang out and where you dream about the opportunities life has in store for you. It almost feels like a small village. “This feeling was so apparent when we saw the many emotional reactions from students and colleagues when they first see the virtual campus – they tell us that navigating the campus makes them feel like they are there again”, states Alexander Whitcomb, a project team member. “What is so unique and creates this sense of truly being there, is that the building is done on a 1:1 scale. So walking from one end of the campus to the other with your avatar in Minecraft takes exactly the same amount of time as it would do in real life.“</span></span></span></span></span></span></span></p></div></div><div><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>The Minecraft campus has two main purposes. First it will be used for various planned activities such as onboarding all new incoming students during the famous EurekaWeek 2020, virtual tours for prospective students and the ErasmusX team is also exploring the game platform for educational and research purposes. Secondly, the campus is designed as a creative space, a way for students and staff to design their own interactions and discover new, innovative ways of engaging with one another through the virtual campus. The platform will be moderated by the Erasmus E-sports Community and all ideas are welcomed.</span></span></span></span></span></span></span></p><p><span><span><span><span><span lang="EN-US" xml:lang="EN-US"><span><span>Ultimately, the campus in Minecraft is there to strengthen the community of Erasmians, in an academic year where physical interactions are limited by Covid-19, and a ‘normal’ university experience remains unavailable until further notice.</span></span></span></span></span></span></span></p></div></div></div></div></div>]]>
            </description>
            <link>https://www.eur.nl/en/news/erasmus-university-rotterdam-builds-first-virtual-campus-netherlands</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818681</guid>
            <pubDate>Mon, 13 Jul 2020 08:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Remote Control Keypad Silicone Oil Problem (2008)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818632">thread link</a>) | @edgartaor
<br/>
July 13, 2020 | http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html | <a href="https://web.archive.org/web/*/http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content">
<p><img src="http://www.michaelshell.org/img/dish_remote_80x250.png" width="80" height="250" alt="Echostar 3000 remote control"></p>
<p id="first_paragraph">
The symptoms are all too familiar - the buttons of a remote control
require very hard presses to be recognized, and the problem only
gets worse with time. Many, many, millions of remotes are replaced
and/or discarded because of this problem. Upon investigating the cause,
I found the presence of an oily substance between the rubber keypad
and the printed circuit board (PCB) it makes contact with. At first, I thought
it was the result of a spill or perhaps even a buildup of hand oil
(and there are technicians who can never be convinced otherwise).
However, the oil did not seem to be petroleum-based as it was highly
resistant to detergent. It reminded me a lot of DOT 5 silicone brake fluid.
And in fact, that is exactly what it turned out to be - silicone oil.
Here is a quote from section 7.0 of the
<span>Silicone Rubber Components Manual</span>
of the Danish company J.D. Friderichsen A/S (which does not exist any more as it was
purchased by the Danish company
<a href="http://www.fst.dk/">Fritz Schur Teknik</a>
in 1999, and the manual is now available only as an
<a href="http://web.archive.org/web/20020225183655/http://www.jdf.dk/esilman/esilman6.htm">internet archive</a>),
which among other things, manufactured silicone rubber keypads:
</p>

<div>
<p>
<strong>7.0 Quality</strong>
</p>
<p>
It is a matter of confidence to buy silicone rubber components, because the
purchaser has to has be certain that the silicone oil is baked out of the
keypad, in order to ensure that quarts don't form on the circuit board and
thereby disrupt the connection. Most of us have probably had this experience
with a remote control at home. (However an incident such as this can also
happen in situations where the OEM are using conductive ink instead of contact
pillars in order to reduce the cost). The only way to control if the silicone
is baked out properly is to check if the keypad has lost some weight after it
has been baked. The current problem is that many far east manufacturers are
used to manufacturing components for cheap products such as one dollar
calculators, and are having difficulties recognizing the requirements set by
western manufacturers. They might not "forget" it for the first few supplies,
but maybe later. The result will surface a few years down the line, so you are
required to know your supplier well. It is equally important that the printed
symbols is baked into the keys, to ensure they don't wear off. A large variety
of qualities are available to the buyer on the market, and you will probably
experience that our price is DKK 0,25 higher than our competition. You are
however welcome to test our quality with an eraser.
</p>
</div>

<p>
I posted about this issue on December 8, 2000 in the thread
<a href="http://groups.google.com/group/sci.electronics.repair/browse_thread/thread/c14d8e962b605e97/ff097119b1b968b1">"Do remote keypads sweat silcone oil?"</a>
(dang it, I misspelled "silicone" in the title) to the Usenet group sci.electronics.repair
and have received email about that post years thereafter. The solution is easy enough - to clean
and degrease the internals of the remote. And this will have to be repeated every
few years, although the interval will become longer as the amount
of oil trapped in the rubber keypad decreases. The remote for my old
Dish Network 3000 satellite receiver (shown at the upper right) was a major offender
and required cleaning every year. My more recent Dish Network 3900 remote, requires
cleaning every 3-5 years. Based on my experience, most remotes with silicone
rubber keypads cannot go a decade without needing to be cleaned. The pressure
generated by pressing a button rather than time itself appears to be the trigger
by which oil is released. So, all things being equal, a remote that is used more often
releases more oil. In theory, it should be possible to bake the oil out yourself
as silicone rubber can take high temperatures (spark plug boots are made out of it).
However, I don't know what temperature is needed or how well the conductive rubber
contacts can withstand this heat without an oxygen-free environment.
</p>

<p>
Now, it is true that silicone oil contamination is not the only cause of
unreliable remotes. Other common problems include bad solder connections
(especially at the LED and battery terminals), worn contacts on the
keypad or PCB, or microbreaks of the PCB traces. While you have the remote apart,
be on the lookout for these other problems. If spotted, bad solder connections
are easy enough to fix by reflowing the solder with a soldering iron. Broken PCB
traces can be really tough to find, but fortunately this normally does
not happen unless the remote has been abused. Worn keypad contacts
are tough to fix. There are conductive rubber repair kits for this
purpose, but they can involve careful cutting and gluing. Sometimes
fine (1000 grit) sandpaper can be used to clean oxides off of the contact
surfaces, but it is all too easy to destroy the conductive rubber contacts
and does not seem to be necessary, so I don't recommend this. You could
try it on stubborn keys if you've tried everything else and have nothing
to loose if it ruins the remote.
</p>


<!-- Amazon Electronics General Bestsellers Ad -->
<!--[if !IE]> <-->

<!----> <!--[endif]---->
<!--[if IE]>
<div class="amazon_ad_ie">
<iframe src="http://rcm-na.amazon-adsystem.com/e/cm?t=micshesweb-20&amp;o=1&amp;p=15&amp;l=bn1&amp;mode=electronics&amp;browse=172282&amp;fc1=000000&amp;lt1=&amp;lc1=3366FF&amp;bg1=FFFFFF&amp;f=ifr" style="border:none;" marginwidth="0" marginheight="0" width="468" height="240" border="0" frameborder="0" scrolling="no">
</iframe>
</div>
<![endif]-->



<h2>Opening and Cleaning the Remote</h2><p>
It isn't the easiest thing in the world to open a remote. First, open the battery
compartment, remove the batteries and unscrew any case screws that are visible.
Using a flat-bladed screwdriver, press fairly hard (take care that you don't stab
yourself should it slip) into the seam between the two halves to
disengage the plastic catches and then twist to snap them apart. Some areas of the
remote are easier to do than others. So, if one place is tough, move to another
position. Once you've got one area unsnapped, work your way all around the remote
until both halves are separated. No matter how careful you are, the screwdriver may
leave raised areas that will make the remote feel terrible in the hand. Shave these
"pips" off with a razor blade knife until they cannot be felt. If you break too many
plastic catches (often caused by not pressing inward to help disengage them before
twisting the screwdriver), you'll have to use something such as silicone sealer (which
will allow the case to be reopened without further damage, but does require a day
to cure) to hold the two halves together when you reassemble it. My open Dish Network
3000 remote and its rubber keypad is shown in figure 1:
</p><div>
<p><img src="http://www.michaelshell.org/img/dish_remote_open_oil_600x392.jpeg" width="600" height="392" alt="An open Dish Network remote control"></p><p>Figure 1: An open Dish Network remote showing silicone oil.</p>
</div><p>
Note the oil just running down the keypad. A closeup is shown in figure 2:
</p><div>
<p><img src="http://www.michaelshell.org/img/dish_remote_oil_closeup_600x300.jpeg" width="600" height="300" alt="closeup of the oil"></p><p>Figure 2: A closeup view of the oil.</p>
</div><p>
This is not the result of a spill, but comes from inside the rubber. Clean and degrease
the entire remote (both case halves inside and outside, both sides of the rubber keypad,
and both sides of the PCB) using a strong detergent (such as 409, dish detergent or
Simple Green) and a toothbrush. Thoroughly scrub the parts with the toothbrush and flush
them with a strong stream of warm water to help push the oil off. You may have to repeat
this as the oil can be stubborn to remove. Thoroughly dry the parts. Blowing them off
with compressed air and letting them dry overnight is perhaps the best approach. Lay the
keypad and filter window in their proper positions and resnap the case together. Reinstall
any screws and the batteries. If your work was successful, you'll be amazed at how
sensitive the keys are compared to the way they were before and you can congratulate
yourself for saving some money. Good luck.



</p></div></div>]]>
            </description>
            <link>http://www.michaelshell.org/gadgetsandfixes/keypadsiliconeoil.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818632</guid>
            <pubDate>Mon, 13 Jul 2020 08:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Exploratory Data Analysis (EDA)? An Introduction with Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818607">thread link</a>) | @fabdrnd
<br/>
July 13, 2020 | https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/ | <a href="https://web.archive.org/web/*/https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.deepflow.ai/content/images/size/w300/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 300w,
                            https://www.deepflow.ai/content/images/size/w600/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 600w,
                            https://www.deepflow.ai/content/images/size/w1000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 1000w,
                            https://www.deepflow.ai/content/images/size/w2000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.deepflow.ai/content/images/size/w2000/2020/07/1-p-Rsob3HmkLmRs0g5fV-FQ.jpeg" alt="What is Exploratory Data Analysis? Yes, another post on EDA">
            </figure>

            <section>
                <div>
                    <p><em>Christophe Pere is a senior NLP researcher and a Deepflow advisor. His post was originally published on <a href="https://towardsdatascience.com/what-is-eda-yes-another-post-on-eda-d8b5c06269a9">Medium</a>. Cover picture: <a href="https://unsplash.com/@markusspiske">Markus Spiske</a> — <a href="https://unsplash.com/s/photos/math">Unsplash</a></em></p><blockquote>A notebook containing all the relevant code is available on <a href="https://github.com/Christophe-pere/EDA" rel="noopener nofollow">GitHub</a>.</blockquote><p>Yes, this is a new post among many that address the subject of EDA. This step is the most important of a Data Science project. Why? Because it allows you to acquire knowledge about your data, ideas, and intuitions to be able to model it later.</p><p>EDA is the art of making your data speak. Being able to control their quality (missing data, wrong types, wrong content …). To be able to determine the correlation between the data. To be able to know the cardinality.</p><p>But not only, EDA is not just about exploring data. When you have a target, a column containing label (supervised learning) you also have feature selection and Feature Importance. Without, you have Feature Extraction (unsupervised learning).</p><p>For years, the best way was to tirelessly code the same functions to calculate correlations, plot variables, manually explore the columns to calculate interesting variables, etc…</p><p>But now there are simpler, faster, and more efficient ways to do all of this:</p><h2 id="ia-pandas-profiling">Ia. Pandas-profiling</h2><p>The first, <a href="https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/introduction.html" rel="noopener nofollow">pandas-profiling</a>, can create reports in HTML format with a very nice interface of the content of a <em>dataframe</em>. Based on pandas, it allows with exceptional performance (up to a million lines, recommendation to be taken into account) to make a complete exploration of the data. This report can be integrated via a widget in <em>jupyter lab </em>or <em>notebook</em>. Or, it can also be presented as a frame.</p><p>As the authors indicate, you’ll the relative information:</p><blockquote><strong>Type inference</strong>: detect the types of columns in a dataframe.</blockquote><blockquote><strong>Essentials</strong>: type, unique values, missing values</blockquote><blockquote><strong>Quantile statistics</strong> like minimum value, Q1, median, Q3, maximum, range, interquartile range</blockquote><blockquote><strong>Descriptive statistics</strong> like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness</blockquote><blockquote><strong>Most frequent values</strong></blockquote><blockquote><strong>Histograms</strong></blockquote><blockquote><strong>Correlations</strong> highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices</blockquote><blockquote><strong>Missing values</strong> matrix, count, heatmap, and dendrogram of missing values</blockquote><blockquote><strong>Duplicate rows</strong> List the most occurring duplicate rows</blockquote><blockquote><strong>Text analysis</strong> learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data</blockquote><blockquote>source: <a href="https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/introduction.html" rel="noopener nofollow">pandas-profiling</a></blockquote><p>You can find examples on the <strong><em>GitHub </em></strong>page of the library like:</p><ul><li><a href="https://pandas-profiling.github.io/pandas-profiling/examples/master/meteorites/meteorites_report.html" rel="noopener nofollow">NASA Meteorites landing</a> this report is the output of the function profil_report() and it shows how powerful is this library.</li></ul><p>How to use it? In a few line of code, let me show you:</p><p>It takes a few seconds to compute compare to something hardcoded to get an impressive result.</p><p>The result when you show the report in a widget:</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-BdW-PIF8PlLUB0njavhjxA.png 1005w" sizes="(min-width: 720px) 720px"><figcaption>Pandas-profiling profile report in widget (rendering)</figcaption></figure><p>The result when you show the report in a frame inside the notebook:</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-QgXO0ueoUd-fCfVT5bo51w.png 1004w" sizes="(min-width: 720px) 720px"><figcaption>Pandas-profiling HTML in a frame (rendering)</figcaption></figure><h2 id="ib-dataprep-eda">Ib. Dataprep.eda</h2><p>Another great library is <strong><em>dataprep</em></strong> with module <strong><em>eda</em></strong>. What is doing?</p><p>You have three main functions:</p><ul><li><strong>plot</strong></li></ul><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-1DI3azqH2ENkiircwvWmAQ.png 1044w" sizes="(min-width: 720px) 720px"><figcaption>plot function of the dataprep.eda package on the Boston House Prices data set</figcaption></figure><p>This function will show you a histogram for each feature. Each plot is interactive based on the <strong>bokeh </strong>library. You have different parameters that allow you to show information on the data you want.</p><ul><li><strong>plot_correlation</strong></li></ul><p>The function allows you to compute three sorts of the correlation matrix (Pearson, Spearman, and KendallTau). The advantage is that the plot is also interactive and you can see the values just putting the cursor on it.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-ZqLi8cHnCYnPf0XtgDsyHg.png" alt=""><figcaption>plot_correlation on Boston House Prices data set</figcaption></figure><ul><li><strong>plot_missing</strong></li></ul><p>This last function is very interesting like the picture below shows you. It allows you to visualize where the missing data are in the column and the percentage of them.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-6qEJdtUj4v_ITqSEHlW05Q.png" alt=""><figcaption>plot_missing function</figcaption></figure><h2 id="ic-sweetviz">Ic. Sweetviz</h2><p>The last interesting library is <a href="https://github.com/fbdesignpro/sweetviz" rel="noopener nofollow">sweetviz</a>. Based on pandas-profiling the library permits to compare different columns or the train and test part of your data to determine if the test set is representative of the train. Like pandas-profiling, you have tons of information per columns. The picture below shows the dashboard of the HTML report generated by the library.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-0JzgLNzOUvAYTIAbsulRPA.png 1592w" sizes="(min-width: 720px) 720px"><figcaption>Comparison between train and test with Sweetviz</figcaption></figure><p>EDA is not just a focus on what is inside the data. You can also go deeper into the analysis with the following parts. The feature selection is a manner to reduce the number of features present in your dataset.</p><p>Here, I just present three ways to do it. The <a href="https://scikit-learn.org/" rel="noopener nofollow">sklearn </a>library has powerful modules to do what you want in terms of selecting or extracting data.</p><h2 id="iia-removing-feature-with-low-variance">IIa. Removing Feature with low variance</h2><p>This technique simply makes it possible to select the features which have a threshold lower than that fixed. It removes all features whose variance doesn’t meet some threshold. By default, it removes all zero-variance features, i.e. features that have the same value in all samples. In the code below, the columns with more than 80% missing data are automatically deleted. This method doesn’t look to the prediction variable y so it can be used in an unsupervised way.</p><pre><code>from sklearn.feature_selection import VarianceThresholdthreshold = 0.8 # 80% of low variance

fe_low_variance = VarianceThreshold(threshold=(threshold * (1 - threshold)))
X_variance = fe_low_variance.fit_transform(X)</code></pre><h2 id="iib-univariate-selection">IIb. Univariate Selection</h2><p>In supervised learning, you have a target feature (commonly named <strong><em>y</em></strong>). The goal of the univariate selection is simple, to take one feature to make a variation on it, and see how it affects the estimated target. In the end, the univariate select will select the best feature based on the univariate statistical test.</p><p>With sklearn, you have 4 methods to do it.</p><ul><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest" rel="noopener nofollow"><strong>SelectKBest</strong></a>: This will select the best <strong><em>k</em></strong> (manually chooses by the user) features of your dataset and removes the others. This function needs a scorer, a metric function to apply the selection. The commonly used scorer function is <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2" rel="noopener nofollow"><strong><em>chi2</em></strong></a>.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile" rel="noopener nofollow"><strong>SelectPercentile</strong></a>: Same as <em>SelectKBest </em>you need to pass a scorer, but instead of a <strong><em>k</em></strong> number of features, you pass a percentile value.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFpr.html#sklearn.feature_selection.SelectFpr" rel="noopener nofollow"><strong>SelectFpr</strong></a><strong>/</strong><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFdr.html#sklearn.feature_selection.SelectFdr" rel="noopener nofollow"><strong>SelectFdr</strong></a><strong>/</strong><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFwe.html#sklearn.feature_selection.SelectFwe" rel="noopener nofollow"><strong>SelectFwe</strong></a>: selection by the <strong><em>pvalues</em></strong> based on the false positive rate, the false discovery rate, and the family-wise error.</li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html#sklearn.feature_selection.GenericUnivariateSelect" rel="noopener nofollow"><strong>GenericUnivariateSelect</strong></a>: Here you can customize your estimator with configurable strategy.</li></ul><p>In the code below I use <strong><em>SelecKBest </em></strong>with <strong><em>chi2 </em></strong>scorer:</p><pre><code>from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

#apply SelectKBest class to extract top 10 best features
select_best_features = SelectKBest(score_func=chi2, k=10) # where k is the number of features you want
fit = select_best_features.fit(X,y)
df_scores = pd.DataFrame(fit.scores_)
df_columns = pd.DataFrame(X.columns) # where X is your data
#concat two dataframes for better visualization
feature_scores = pd.concat([df_columns,df_scores],axis=1)
feature_scores.columns = ['Specs','Score']  #naming the dataframe columns
print(feature_scores.nlargest(10,'Score'))  #print 10 best features</code></pre><h2 id="iic-recursive-feature-elimination">IIc. Recursive Feature Elimination</h2><p>As the picture below shows, the principle of the RFE is simple. The estimator fit the data and compute the feature importance, it’s the weight of the data on the target. At each iteration, the model will remove the feature with lower importance until reach the number of <strong><em>k</em></strong> features needed.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-AWnrEWagQiol5hUeqe52kw.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-AWnrEWagQiol5hUeqe52kw.png 1074w" sizes="(min-width: 720px) 720px"><figcaption>Schema of the RFE</figcaption></figure><p>How could we code this? I show here an implementation for <strong><em>SVM </em></strong>and <strong><em>Logistic Regression</em></strong>.</p><p><strong>SVM:</strong></p><pre><code>from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_selection import RFECV

# SVM implementation
svc = SVC(kernel="linear")
# The "accuracy" scoring is proportional to the number of correct

rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(5),            scoring='accuracy')rfecv.fit(X, y)

print("Optimal number of features : %d" % rfecv.n_features_)</code></pre><p><strong>Logistic Regression:</strong></p><pre><code># Feature Extraction with RFE
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(solver='lbfgs', max_iter=5000)
rfe = RFE(model, 3)
fit = rfe.fit(X, Y)
print("Num Features: %d" % fit.n_features_)
print("Selected Features: %s" % fit.support_)
print("Feature Ranking: %s" % fit.ranking_)</code></pre><h2 id="iid-selectfrommodel">IId. SelectFromModel</h2><p>This last method is a generalization of the previous because <strong><em>SelectFromModel </em></strong>takes an <strong><em>estimator </em></strong>and returns a new matrice containing the reduced dimension.</p><p>The code below shows how to implement it:</p><pre><code>from sklearn.svm import LinearSVC
from sklearn.feature_selection import SelectFromModel

lsvc = LinearSVC(C=0.01, penalty="l1", dual=False) # estimatorlsvc.fit(X, y)
model = SelectFromModel(lsvc, prefit=True)
X_new = model.transform(X)
print(f"The new number of feature is {X_new.shape[1]}")</code></pre><h2 id="iiia-principal-component-analysis-pca-">IIIa. Principal Component Analysis (PCA)</h2><p>The Principal Component Analysis is a method used to reduce the dimension of a dataset. The principle is simple, the PCA will fit a line or a plane to the points to create another representation of the data.</p><figure><img src="https://www.deepflow.ai/content/images/2020/07/1-lh5TKadyKILDVlaazuE1UA.png" alt="" srcset="https://www.deepflow.ai/content/images/size/w600/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 600w, https://www.deepflow.ai/content/images/size/w1000/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 1000w, https://www.deepflow.ai/content/images/2020/07/1-lh5TKadyKILDVlaazuE1UA.png 1227w" sizes="(min-width: 720px) 720px"><figcaption>PCA projection</figcaption></figure><p>The code is simple to use. You just have to specify the N_var parameter which represents the number of dimensions you want.</p><pre><code>from sklearn.decomposition import PCA
N_var = 2
pca = PCA(n_components=N_var)
X_pca = pca.fit_transform(X)
df_pca = pd.DataFrame(data = X_pca, columns = ['PC1', 'PC2'])</code></pre><h2 id="iiib-independent-component-analysis-ica-">IIIb. Independent Component Analysis (ICA)</h2><p>ICA is a powerful technique to separate multivariable independent signals linearly mixed. This technique can permit us to separate different signals in signal processing.</p><p>The code below shows an implementation of a <strong><em>FastICA</em></strong>:</p><pre><code>from sklearn.decomposition import FastICA
N_var = 2
ica = FastICA(n_components=N_var)
X_ica = ica.fit_transform(X)</code></pre><h2 id="iiic-linear-discriminant-analysis-lda-">IIIc. Linear Discriminant Analysis (LDA)</h2><p>I share here the abstract of the original paper explaining LDA.</p><blockquote>We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/">https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/</a></em></p>]]>
            </description>
            <link>https://www.deepflow.ai/what-is-exploratory-data-analysis-yes-another-post-on-eda/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818607</guid>
            <pubDate>Mon, 13 Jul 2020 08:49:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM64 Popcount in Golang and Assembler]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23818574">thread link</a>) | @fanf2
<br/>
July 13, 2020 | https://barakmich.dev/posts/popcnt-arm64-go-asm/ | <a href="https://web.archive.org/web/*/https://barakmich.dev/posts/popcnt-arm64-go-asm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Apropos of Apple’s ARM announcment, I thought I might write up a post on a recent bit of code I wrote that specifically looks at ARM64, and its benchmarks on various hardware.</p><p>I’ve been implementing some compact data structures for a project. One of the CPU hotspots for the implementation is the need to run a quick population count across a potentially large bit of memory.</p><p>If you’ve never seen population count before, it’s the count of the number of set 1 bits in a byte (or list of bytes) – for example:</p><div><pre><code data-lang="text">0xF3 == 0b11110011
popCount(0xF3) == 6
</code></pre></div><p>Now, every reasonable x86_64/amd64<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> CPU in the past decade or so has a built-in instruction for this: <a href="https://en.wikipedia.org/wiki/SSE4#POPCNT_and_LZCNT"><code>POPCNT</code></a>. It works like this (in Go Assembler):</p><div><pre><code data-lang="text">MOV    $0xF3, R10  // Store a constant
POPCNT   R10, AX   // AX now equals 6
</code></pre></div><p>Go uses the built-in instruction for this in the <code>math/bits</code> via SSA compiler rewrites (which it added in 1.9), but only up to a uint64 at a time; using assembly to loop over a <code>[]byte</code> is considerably more efficient</p><p><a href="https://github.com/tmthrgd"><code>@tmthrgd</code></a> created a really nice little x86_64-assembly-optimized package at <a href="https://github.com/tmthrgd/go-popcount">github.com/tmthrgd/go-popcount</a>. It works great, works around a weird little Intel bug (see the helpful comments) and is still faster than looping and using the Go standard library, which it helpfully benchmarks as well.</p><p>Recently, I picked up one of the new 8GB Raspberry Pi 4s. Loaded it up with the nice new <a href="https://manjaro.org/">Manjaro 20.06</a> and set up my usual environment. As a test, I wanted to try my latest WIP data structure code.
Of course, the bottleneck was right where I expected it to be: in the population count.</p><h3 id="implementing-it">Implementing it</h3><p>I discovered that ARM64 has a <code>POPCNT</code>-like instruction, logically enough called <code>CNT</code>. I thought, since I’ve been playing with Go assembly for memmove, why not try my hand at the new architecture?</p><p>Go already has the SSA-rewrite for OnesCount on ARM (added in 1.11), but again, only a uint64 at a time. There might be some performance on the table.</p><p><a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">Official architecture guide</a> at the ready, I got to work. And there was a lot to learn. Some notes:</p><h4 id="1-its-part-of-the-vector-suite-neon">1. It’s part of the vector suite, NEON</h4><p>NEON is the name for the addition of vector instructions to the ARM architecture, so I’d be working with both an unfamiliar architecture <em>and</em> its vector instructions.</p><p>In x86-land, <code>POPCNT</code> and vectorization are two separate concepts. <code>POPCNT</code>, as an instruction, deals with everyday, 64-bit integer registers, and not the vector registers (even though it appeared approximately the same time as the addition to vector instructions, SSE4)<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p><p>ARM/NEON did <code>CNT</code> differently. Since you can load an array of items (say, 16 bytes, in the ARM64 vector registers), <code>CNT</code> will count them individually. In fact, you can <em>only</em> do it in vectors of single bytes.</p><p>So this means that the following signatures are approximately the way to think about it:</p><div><pre><code data-lang="go"><span>func</span> <span>popCountx86</span><span>(</span><span>in</span> <span>uint64</span><span>)</span> <span>uint64</span> <span>// register-at-a-time, 64-bit (8 bytes)
</span><span></span>
<span>func</span> <span>popCountNeon</span><span>(</span><span>in</span> <span>[</span><span>16</span><span>]</span><span>byte</span><span>)</span> <span>[</span><span>16</span><span>]</span><span>uint8</span> <span>// 16 bytes all counted in parallel.
</span></code></pre></div><p>This ends up being really effective, as it turns out (below).</p><h4 id="2-gos-assembler-documentation-is-barebones">2. Go’s assembler documentation is barebones</h4><p>Writing instructions so that Go’s assembler is happy with the instructions you’re giving it is a bit frustrating.</p><p>There’s a good gloss at <a href="https://golang.org/pkg/cmd/internal/obj/arm64/">golang.org/pkg/cmd/internal/obj/arm64</a> which gives an overview of many of the differences.
For example, all vector instructions start with <code>V</code>, different than what ARM64 switched to (they used to commonly start with V on 32-bit ARM) – so while I understand the desire for continuity (and even subtly like it, knowing it’s a vector op) it’s just makes another little difference to remember vs. the original documentation.</p><p>But more frustrating is, even if your instruction is supported (and most of them are) knowing how to <em>use</em> the instruction in Go assembler boils down to “assume data goes left-to-right and hope there’s an example <a href="https://github.com/golang/go/blob/master/src/cmd/asm/internal/asm/testdata/arm64enc.s">in the test suite</a>”</p><p>I’m a big Go fan, yet Go’s history into Plan 9 and accompanying assembler (and, relatedly, odd calling conventions) is one of my gripes about Go, even more than lack of generics (which is a topic for another day).
Sure, there were some good ideas in Plan 9 that influenced the design of Go – from a design level, it’s great! – but on the implementation level, this is one place where I kinda wish it had followed precident.
Take whichever side you want in the Intel vs GNU syntax debate, <a href="https://xkcd.com/927/">creating a third option</a> means relearning all the quirks from scratch, and ignoring any documentation that already exists.</p><h3 id="putting-it-all-together">Putting it all together</h3><p>The end result is my friendly fork of <code>go-popcount</code>: <a href="https://github.com/barakmich/go-popcount">github.com/barakmich/go-popcount</a></p><p>Really, it’s more of an extension than a fork – it provides the same API, just with handwritten assembly for ARM64 chips.</p><h4 id="how-it-works">How it works</h4><p>The vectorization works really well. The process is:</p><ul><li>Load a set of vector registers, 16 bytes each</li><li>popCount them</li><li>Vector sum their partial results (up to 32 individual vectors, to fit the 8-bit counts), trying to avoid a data dependency</li><li>Finally, sum (“widening”, in vector terms) the final vector</li><li>Add it to the final output</li></ul><p>The other thing to balance was how much to load from memory vs. how much work to do to optimize throughput. That ended up being about 8 vectors (128 bytes) at a time.
That may vary as a function of CPU, but it’s a good place to start.</p><h4 id="arm64-feels-nice">ARM64 feels nice</h4><p>This is purely subjective, but there were a number of moments where I felt “hey, that’s handy” in writing ARM64 assembly.
Of course modern x86_64 chips account for all of these differences and makes them performant – through deeper instruction pipelines or having <a href="http://sunnyeves.blogspot.com/2009/07/intel-x86-processors-cisc-or-risc-or.html">micro-op instruction queues</a> that ultimately pull the same tricks.
But at the same time, when you’re dropping down to work at the instruction level, it’s kind of a breath of fresh air.</p><h5 id="pre-and-post-increment">Pre-and-post increment</h5><p>A lot of the time when you’re working with an array of whatever you’re pulling a chunk of memory into registers, doing some transform, and putting it back.</p><div><pre><code data-lang="asm"><span>VLD1.P</span> <span>64</span><span>(</span><span>R1</span><span>),</span> <span>[</span><span>V16.B16</span><span>,</span> <span>V17.B16</span><span>,</span> <span>V18.B16</span><span>,</span> <span>V19.B16</span><span>]</span>
</code></pre></div><p>Reads as load 1-byte*size structures into the following vector registers – so far so good, this is similar to the <a href="https://www.felixcloutier.com/x86/movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64"><code>VMOVDQU</code></a> instruction family (though the size-structure variants on that instruction are a recent addition) on x86. It has a similar ability to load many registers in multiple back-to-back instructions through address/offset/size calculation, but ARM has a nice one-liner that way.</p><p>But I really like the auto-increment of <code>R1</code> by the read size (64) after loading – hence post-increment. Many loads from memory have a similar flag. It’s very descriptive and means things like “increment the offset register and decrement the size register and test” things live with their appropriate parts of the code, instead of having to increment later (and finding the optimal time)</p><h5 id="consistency-of-style">Consistency of style</h5><p>This is a holdover from history, but the consistency of having fixed-size instructions is a nice thing when trying to hand-assemble an instruction. I had to do some hand-assembly when <a href="https://github.com/golang/go/issues/39445">I discovered and reported a bug in Go</a>. It was silently writing the wrong version of the instruction while accepting the correct one as input. Kudos to the Go community – it was fixed by an expert within a day or two, so I’m looking forward to the next version that contains the fix!</p><p>Still, this meant with a <a href="https://xkcd.com/378/">steady hand</a> and a copy of <a href="https://static.docs.arm.com/ddi0596/a/DDI_0596_ARM_a64_instruction_set_architecture.pdf">the architecture guide</a> I could feasibly implement any instructions that were missing.</p><p>Also in consistency-land, most binary operations take <code>input1_reg, input2_reg, output_reg</code> with few exceptions. Omitting the output_reg is Go’s assembler syntactic sugar to set output to input2. x86, again for historical reasons (trying to keep instructions small), often has the store-to-the-second-register as the primary or only version of an operation, which can lead to more operations overall (and cognitive overhead IMO).</p><h3 id="benchmarking-on-arm">Benchmarking on ARM</h3><p>So let’s take a look at some benchmarks.
The most interesting thing about looking at population count is that this little routine does something useful and shows tradeoffs between CPU bounds and memory bandwith between the CPU, the on-chip caches, and main memory.
At array sizes small enough to fit into CPU cache (but big enough to run the compute loop a few times), the CPU is the limiting factor – how many bits it can count.
For larger data sizes, the memory bandwidth becomes the bound; the CPU is waiting on getting enough data to crunch through.</p><p>To this end, the benchmark curves in the repository max out in throughput at about 16K (most work possible, while still being in cache) and then trail down into a steady state as memory becomes the bound. So I’ll truncate the full benchmarks to compare peak throughput and long tail.</p><p>Some findings and commentary:</p><h4 id="raspberry-pi-4">Raspberry Pi 4</h4><div><pre><code data-lang="text">Unoptimized (Go implementation):
BenchmarkCountBytesGo/16K              297778          8056 ns/op     2033.78 MB/s
BenchmarkCountBytesGo/512M                  8     279380432 ns/op     1921.65 MB/s

Optimized (My hand-rolled assember):
BenchmarkCountBytes/16K                520807          2303 ns/op     7113.24 MB/s
BenchmarkCountBytes/512M                    8     131214574 ns/op     4091.55 MB/s
</code></pre></div><p>This was my finished product on my local Pi. I may be able to do better, but varying the block sizes between grabbing from memory and doing the vector addition for popcount topped out about here, so I’m fairly satisfied.</p><p>Interestingly, the ~4.1GB/s memory bandwidth follows exactly with <a href="https://hackaday.com/2019/07/10/raspberry-pi-4-benchmarks-processor-and-network-performance-makes-it-a-real-desktop-contender/">initial read benchmarks of the Pi 4</a> suggesting it’s close to saturation, which is good news.</p><h4 id="ampere-emag">Ampere eMag</h4><p>So my next thought was to spin up an ARM64 server with my old friends at <a href="https://packet.net/">Packet</a>. They have a <a href="https://www.packet.com/cloud/servers/c2-large-arm/">c2.large.arm</a> and it’s gonna be great!</p><div><pre><code data-lang="text">Unoptimized:
BenchmarkCountBytesGo/16K      	   69939	     17208 ns/op	 952.09 MB/s
BenchmarkCountBytesGo/512M     	       2	 582293709 ns/op	 921.99 MB/s

Optimized:
BenchmarkCountBytes/16K        	  458394	      2614 ns/op	6267.80 MB/s
BenchmarkCountBytes/512M       	      12	  93371433 ns/op	5749.84 MB/s
</code></pre></div><p>…but I was rather underwhelmed.</p><p>This isn’t necessarily Packet’s fault – they were early onto having ARM hardware available and it’s …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://barakmich.dev/posts/popcnt-arm64-go-asm/">https://barakmich.dev/posts/popcnt-arm64-go-asm/</a></em></p>]]>
            </description>
            <link>https://barakmich.dev/posts/popcnt-arm64-go-asm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23818574</guid>
            <pubDate>Mon, 13 Jul 2020 08:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Consolidation of the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817946">thread link</a>) | @Fizzadar
<br/>
July 13, 2020 | https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/ | <a href="https://web.archive.org/web/*/https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
 
<div>

        <h2>
            On the Consolidation of the Web
            <span>Wed 29 July 2020</span>
        </h2>

        <p>In recent years, the web has been consolidating. From the servers to the apps, a growing majority of the web is controlled by a small pool of companies. When AWS was founded in 2006 I was just starting out with my first VPS, running this blog on WordPress (the good ol' days!). For the last 10 years I have part-run a small VPS (“cloud server”) host called <a href="https://afterburst.com/">Afterburst</a>. Throughout these years I have watched this consolidation, and these are my observations.</p>

<h3>The Pre-Cloud Days</h3>

<p>Way back in 2009 blogs were booming. The market for personal servers was growing rapidly. People often used forums (remember those?) to find providers. Providers would compete to attract the most eyeballs to their sale posts.</p>

<p>The quality and cost of hosting varied wildly. During summer there would be a huge influx of budget “summer hosts” during school holidays. The majority of these would then fold only two months later. Thinking back, it was The While West. Of course there were big players; but the smaller hosts had the cheapest offers and captured the market for personal servers.</p>

<p>I believe that this was a great market for all. Buyers had a wealth of choice of companies tiny to massive. Providers were kept in check by thriving forum communities, leading to better services. The smaller providers would offer a personal touch, often partaking in forums alongside their customers. To me, this was an amazing environment in which I learnt a huge amount about servers but also customer service.</p>

<h3>The Clouds Ascend</h3>

<p>The VPS market was exploding when we started Afterburst in 2010. Shared hosting/PHP was stagnating and the prices had bottomed out. Shared hosting was consolidating fast, hosts were folding daily. Dedicated server and VPS markets remained strong and WebHostingTalk (our “home” forum) was buzzing with activity. The competition for the best VPS was in full swing.</p>

<p>And then came DigitalOcean.</p>

<p>When DO arrived in 2011 everything changed. They managed to make the much hyped “cloud” accessible to everyone where AWS had so far struggled. You could click a button and have a cloud server available within minutes. The all-SSD package, “cloud” marketing and a wave of free launch coupons caused them to explode onto the scene.</p>

<p>It was fascinating to watch the “cloud” hype train. “Cloud servers” were, almost overnight, seen as superior to “VPS”. This is despite most “cloud server” providers offering nothing different to VPS. Now I totally get that The Cloud goes way beyond servers. The offerings today include a staggering number of services. But an individual looking for a server to host their blog? They don’t need any of that, just the server space.</p>

<p>In the years since DO arrived they, AWS and later Azure/GCloud boomed. Cloud was/is the future - we must move everything “to the cloud” many a huge tech company would say. As much as it was marketing hype, the individual started to follow. The cloud was only a little more expensive and came with fancy UI and excellent developer tooling. It was cool to be using the cloud. The small/traditional VPS provider market began to slow, and later reduce. The golden days were over.</p>

<p>Whilst this was very frustrating at the time it also forced us to review and improve our marketing and customer experience. We started marketing cloud servers and optimised the checkout and customer sign-up flow. The competition led to an improved service for existing and new customers.</p>

<h3>So - where are we now?</h3>

<p>10 years later, we’re still here! The consolidation of providers has slowed and many continue to survive. Forums like WHT struggle on but are shadows of their former selves. There’s still a market for individual servers - people have a natural desire to tinker in ways that specific services cannot provide.</p>

<p>I think there will remain a cohort of individual bloggers and websites. But I also believe the web is dividing. On one side a small number of platforms the vast majority of “normal” people consume from and share to. And elsewhere a separate “old style” web of fragmented loosely connected websites/forums/blogs formed by those who tinker. Perhaps something will merge the two together in the future.</p>

<p>It’s like supermarkets consuming ‘Mom and Pop shops’, a trend that goes back decades now. Yet small greengrocers and butchers still live on. There are signs of people returning to these shops in growing numbers. Perhaps this is the start of a reverse trend, could the web follow suit? I’d like to think so.</p>
</div>
    
    </section></div>]]>
            </description>
            <link>https://pointlessramblings.com/posts/On_the_Consolidation_of_the_Web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817946</guid>
            <pubDate>Mon, 13 Jul 2020 07:18:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Profile READMEs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23817930">thread link</a>) | @patelpankaj
<br/>
July 13, 2020 | https://time2hack.com/create-activate-github-profile-readme/ | <a href="https://web.archive.org/web/*/https://time2hack.com/create-activate-github-profile-readme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<p>The <strong>Github Profile README</strong> design was being in twitter conversation for a while. I discovered it with one of the profiles with README in theirs.</p><p>I went ahead and <a href="https://github.com/pankajpatel">added on mine</a> and it looks super awesome 😎 now:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/profile-readme.png" alt=""><figcaption>My <a href="https://github.com/pankajpatel">profile <strong>README</strong></a></figcaption></figure><p>You can also <strong>activate profile README</strong> on yours by simply <a href="https://github.com/new">creating a new repository</a> with same name as your Github profile handle. So for me, it is <code>pankajpatel</code> as the repository name; similar to my Github username.</p><p>You can also see it in the above picture, the <code><strong>README.md</strong></code> is from <code>pankajpatel/README.md</code></p><p>When you will go ahead and <strong>create a repository with same name as your profile handle</strong>; you will see the following message:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/new-repo.png" alt=""></figure><hr><p>Just initialize your repository with a <strong>README</strong> file by checking the checkbox below. Other files in the initialization don't matter for this repository</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/initialize-with-README.png" alt=""></figure><hr><p>Once you hit <code><strong>Create Repository</strong></code> button, you will see the repository with list of files as follows:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/fresh-README-repo.png" alt=""></figure><p>Important thing to note here is the green box on right side:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/readme-repo-edit-readme.png" alt=""></figure><hr><p>Click on <code><strong>Edit README</strong></code> and start editing the Welcome message of your profile. By default, you will see the following contents on your <strong>README</strong> as a hint to get started:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/start-editing-profile-README.png" alt=""></figure><hr><p>You can add content as Markdown or HTML and preview it in the next tab. Once you are done, you can commit the file and your profile will show this <strong>README</strong> above the top/pinned repositories of your profile.</p><p>If you are new to Markdown, you can follow this <a href="https://guides.github.com/features/mastering-markdown/">guide to get started with Markdown</a>.</p><hr><h2 id="for-organizations">For Organizations?</h2><p>Unfortunately, the Organizations are not having this feature but I hope this feature will come there. I tried for time2hack's org on github and it still looks the same:</p><figure><img src="https://res.cloudinary.com/time2hack/image/upload/q_auto:good,f_auto/org-time2hack-readme.png" alt=""></figure><hr><h2 id="conclusions">Conclusions</h2><p><em>Github Profile README</em> is a good way to introduce yourself to your profile visitors.</p><p>This way others can know more about you other than your top repositories and how much you code every day.</p><p><strong>Github Profile README is a nice flavour to Social Coding.</strong></p><p><strong><em>Have you created yours? And How does it look like?</em></strong></p><p>Let me know through comments 💬 or on Twitter at &nbsp;<a href="https://twitter.com/patel_pankaj_">@patel_pankaj_</a> &nbsp;and/or &nbsp;<a href="https://twitter.com/time2hack">@time2hack</a></p><p>If you find this article helpful, please share it with others 🗣</p><p>Subscribe to the blog to receive new posts right to your inbox.</p><hr><h4 id="credits">Credits</h4><p>Icon from <a href="https://icons8.com/icon/52539/github">https://icons8.com/icon/52539/github</a></p><p>Photo by <a href="https://unsplash.com/@yancymin?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Yancy Min</a> on <a href="https://unsplash.com/s/photos/github?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>

<ins data-ad-client="ca-pub-1830015441649630" data-ad-slot="3501574357" data-ad-format="auto" data-full-width-responsive="true"></ins>

</section></div>]]>
            </description>
            <link>https://time2hack.com/create-activate-github-profile-readme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817930</guid>
            <pubDate>Mon, 13 Jul 2020 07:16:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Sourcing Company Culture]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817799">thread link</a>) | @soorajchandran
<br/>
July 12, 2020 | https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/ | <a href="https://web.archive.org/web/*/https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-318">

	

	
	<div>
		
<figure><img data-attachment-id="353" data-permalink="https://blog.oysterhr.com/adobestock_32068789/" data-orig-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png" data-orig-size="1491,1008" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="adobestock_32068789" data-image-description="" data-medium-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300" data-large-file="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=750" src="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024" alt="" srcset="https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=1024 1024w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=150 150w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=300 300w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png?w=768 768w, https://blogoysterhr.files.wordpress.com/2020/07/adobestock_32068789.png 1491w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>TL;DR: <em>Companies that have recently gone fully-remote can draw inspiration from open source. Doing so provides helpful ways to think about attracting talent and building culture.&nbsp;</em></p>



<p><strong>Fully-Distributed is Taking Off</strong></p>



<p>Though the headlines have focused on the <a rel="noreferrer noopener" href="https://www.cnn.com/2020/05/22/tech/work-from-home-companies/index.html" target="_blank">big name companies</a> and their announcements about going remote, events of the last four months have undoubtedly created a lot of new fully-distributed companies you’ve <a rel="noreferrer noopener" href="https://www3.nhk.or.jp/nhkworld/en/news/videos/20200622091038913/" target="_blank">never heard of</a>. This includes organizations that may have been partially or even fully-colocated (office-based) before Coronavirus. And this is happening in part because remote working has worked out so well for so many of them, and in part because it has proven difficult for many companies to scale down to a “reduced” real estate footprint — to serve a subset of their employees. Hybrid is <a rel="noreferrer noopener" href="https://www.linkedin.com/pulse/remote-work-having-moment-future-isnt-hybrid-sid-sijbrandij/" target="_blank">harder</a> than fully-distributed, we keep hearing. And the truth is that returning to the office is still an open discussion (fraught with overwhelming <a rel="noreferrer noopener" href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank">emergent</a><a href="https://www.nytimes.com/2020/06/22/business/virus-office-workplace-return.html" target="_blank" rel="noreferrer noopener"> logistical considerations</a>) even for companies that really want to.</p>



<p>We have also no doubt seen in the last four months an acceleration in the rate of creation of new fully-distributed startups that reject offices altogether, and that do not expect their people to meet physically to get work done. This was already a trend, and any founders who may have been hesitant before Coronavirus because they were worried about investor bias or their own inexperience with remote leadership, now have <a href="https://techcrunch.com/sponsor/oyster/the-dawn-of-the-distributed-age/" target="_blank" rel="noreferrer noopener">enormous encouragement</a> to kick the office to the curb.</p>



<p>This means, however, that now many, many more companies, not just the ones that were already on the fully-distributed bandwagon before COVID-19, are going to face the challenges unique to fully-distributed organizations.</p>



<p><strong>Next-Level Guidance is Needed</strong></p>



<p>There’s been a great outpouring of new content from the community on the basic how-to’s of remote working. We have also seen that the “bibles of remote working” (that have been around for years from the pioneering remote working companies like <a rel="noreferrer noopener" href="https://distributed.blog/" target="_blank">Automattic</a>, <a href="https://about.gitlab.com/company/culture/all-remote/guide/">Gitlab</a>, and <a href="https://basecamp.com/remote-resources">Basecamp</a>, etc) are getting the reference attention they deserve. These basics (like asynchronous communication) are of course essential principles that have to be properly installed for a fully-distributed team to walk and run. But there are other challenges that come with being a fully-remote organization for which there’s less explicit guidance.</p>



<p>Two such challenges we keep hearing about are:</p>



<ul><li>How do you attract and recruit great talent from around the world (<em>whom you may never meet in person</em>)?, and</li><li>How do you create and sustain great culture (<em>when everything is virtual</em>)?</li></ul>



<p><strong>Open Source, a Model of Distributed Success</strong></p>



<p>To these important challenges of fully-distributed organizations, the <a href="https://www.redhat.com/en/topics/open-source/what-is-open-source" target="_blank" rel="noreferrer noopener">principles and history of Open Source</a> would seem to offer a lot.&nbsp;</p>



<p>We often hear that software “eats” things. An aspect of that is that the ways of software development continue to penetrate into the ways other types of work are done. That open source should provide ways of thinking and working that are helpful to fully-distributed organizations may be yet another example of something that started in software development spreading more generally into business. Like <a rel="noreferrer noopener" href="https://agilemanifesto.org/principles.html" target="_blank">Agile</a> and <a rel="noreferrer noopener" href="https://www.agilealliance.org/glossary/kanban/" target="_blank">Kanban</a> have. This keeps happening because these “frameworks from another domain” offer avenues to better ways of working, even when what you’re doing is some other type of knowledge work.&nbsp;</p>



<blockquote><p>Whether or not they are a software company, fully-distributed organizations are going to have to become more like software companies in their ways of working.</p><a href="http://twitter.com/share?&amp;text=Whether%20or%20not%20they%20are%20a%20software%20company%2C%20fully-distributed%20organizations%20are%20going%20to%20have%20to%20become%20more%20like%20software%20companies%20in%20their%20ways%20of%20working.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=HeyOyster" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>This shift will be necessary for non-software development knowledge work to be done well in a fully-distributed organization. Naturally, that has deep implications for how technology will support knowledge work in the future. For that reason, we’re also going to see a pattern where new tools are going to be created that allow non-software developer knowledge workers to work more like developers do. This was also probably a trend well in evidence before Coronavirus, now greatly accelerated.</p>



<p>Once your organization is thinking and working a bit more like a fully-distributed software company (especially if you ARE a software company), it shouldn’t be too difficult to aspire to some of the attributes of an open source project.&nbsp;&nbsp;</p>



<p>Open source is worthy to provide guidance and inspiration to any fully-distributed company because it demonstrates a model through which great talent is not only attracted but also uniquely enabled and remotely synchronized to produce semi-miraculous results.&nbsp;</p>



<p>There is no better example of this than Linux.</p>



<blockquote><p>“Linux was the first project for which a conscious and successful effort to use the entire world as its talent pool was made.”</p><cite><em>Eric Steven Raymond, <a rel="noreferrer noopener" href="http://www.catb.org/~esr/writings/cathedral-bazaar/cathedral-bazaar/ar01s11.html" target="_blank">The Social Context of Open-Source Software</a></em></cite></blockquote>



<p>Successful open source projects like Linux should inspire fully-distributed companies because they demonstrate the extraordinary productivity potential of organized knowledge work performed by a team of people who didn’t ever have to meet in person to accomplish it.</p>



<p><strong>Becoming a Beacon for Global Talent</strong></p>



<p>Organizations who’ve let go of their offices and have recently made the transition to fully-distributed are probably still focused on getting things back on track, and on fostering the healthy continuity of the pre-existing team. Though hiring may not be the present priority, they must surely be thinking about how recruitment will work as a fully-remote company. Whether they are fully-distributed or just have newly-created remote roles, as organizations shift their recruiting perspective from thinking locally to thinking globally, this is going to radically transform the recruiting process as we have known it.&nbsp;</p>



<p>Even for companies that decide they will only hire in a subset of timezones (to facilitate synchronous work, like <a href="https://www.quora.com/q/quora/Remote-First-at-Quora" target="_blank" rel="noreferrer noopener">Quora</a>), the size of the available talent pool would still overwhelm the traditional recruitment approaches of “publishing” their open roles and waiting for “applicants” to express an interest in them. The new pervasiveness of remote working and highly-distributed companies is going to create unprecedented liquidity in the global talent marketplace. This is great for all parties, but it also means that everyone’s game has to change.&nbsp;</p>



<p>Thinking and acting like an open source project may be a good way for fully-distributed companies to evolve their talent acquisition game. Reflect on the Linux example in a post-Coronavirus talent market. When the most talented individuals can work for any company in the world, how will your company compete? How can your company distinguish itself amongst a much larger number of prospective employers?</p>



<blockquote><p>The downside for employers gaining access to the global talent pool is that they are also suddenly competing with every company in the world for talent.</p><a href="http://twitter.com/share?&amp;text=The%20downside%20for%20employers%20gaining%20access%20to%20the%20global%20talent%20pool%20is%20that%20they%20are%20also%20suddenly%20competing%20with%20every%20company%20in%20the%20world%20for%20talent.&amp;url=https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/&amp;via=2hp" target="_blank" rel="noopener noreferrer">Tweet</a></blockquote>



<p>One approach is to become like an open source project, whose first organizing principle is attracting people who care deeply about the same thing. This of course requires knowing what that special thing (of singular and obsessive focus) is for your organization. I think most companies can find their unique <a href="https://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action" target="_blank" rel="noreferrer noopener">Why</a>, if they try. And I think it’s a good thing that prospective global employers should feel they have to produce a thoughtful and compelling expression of their purpose to compete for global talent.</p>



<p><strong>Creating Culture on Purpose</strong></p>



<p>Perhaps your company is bootstrapping its culture for the first time as a brand new fully-distributed startup. Or perhaps you’re an established organization now transitioning from an office-based culture. Either way, you may as a leader be wondering how to develop and nurture culture when everything is virtual and everyone’s remote.</p>



<p>Attracting people who share a common passion is potentially more than just a way to acquire talent. It can also be a terrific way to instantiate culture. But attracting talent like an open source project, however, is not just about having a clear and compelling purpose. It’s also about calling those talented people to come work on that purpose together in a <strong>particular</strong> way.</p>



<blockquote><p>“Culture is a pattern of basic assumptions — invented, discovered, or developed by a given group as it learns to cope with its problems of external adaptation and internal integration — that has worked well enough to be considered valid and, therefore, to be taught to new members as the correct way to perceive, think, and feel in relation to those problems.”</p><cite><em>Edgar Schein, <a rel="noreferrer noopener" href="https://agustinazubair.files.wordpress.com/2013/04/13-organizational_culture_and_leadership_3rd_edition-p-4581.pdf" target="_blank">Organizational Culture and Leadership</a></em></cite></blockquote>



<p>In other words, culture is inherently linked to a particular problem space, and isn’t directly about people or their attributes. Organizational culture is about how people decide to work together on a specific set of problems.</p>



<p>For many office-based companies, the “Our values” plaque that hangs on the wall is just a list of nice ideas. And though that list of values is intended to be the codification of their culture, those values may not relate in any useful way to the work to be done, and therefore probably don’t drive much useful behavior. The experience and the effects of culture, therefore, are organic, accidental, and overly-dependent on physical proximity.</p>



<blockquote><p>“Running a remote work environment effectively, requires amongst other things a deliberate approach to culture development. </p><p>Transitioning from an office to remote is not going to be easy for a lot of companies. The reason for this is leaders took the human proximity, camaraderie, informal comms &amp; ‘water cooler moments’ for granted. </p><p>The majority of CEOs who ran office-based businesses before the pandemic and didn’t invest in their culture unknowingly relied on their office space environment to hold their unwritten culture together.”</p><cite><em>Bretton Putter (via <a rel="noreferrer noopener" href="https://twitter.com/BrettonPutter/status/1263829426258817025" target="_blank">Twitter</a>)</em></cite></blockquote>



<p>As human beings we abhor vacuums, particularly social ones. This is the reason why, in the face of non-deliberate culture, we are able to “fill in” …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/">https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</a></em></p>]]>
            </description>
            <link>https://blog.oysterhr.com/2020/07/10/remote-culture-recruiting-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817799</guid>
            <pubDate>Mon, 13 Jul 2020 06:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting with RF Using RTL-SDR]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817738">thread link</a>) | @ngutman
<br/>
July 12, 2020 | https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/ | <a href="https://web.archive.org/web/*/https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><h2 id="introduction">Introduction</h2>
<p>I was always interested in the RF world, the fact that we are surrounded by an infinite amount of invisible waves that carry information is intriguing. A lot has changed over the years, the technology advanced and today you can easily dive into the electromagnetic realm without fiddling with mountains of equipment and burning your pocket.</p>
<p>In this post we’ll explore using RTL-SDR to read live temperature and humidity stats from cheap 433.92Mhz modules, feeding them to InfluxDB using rtl_433, MQTT and Telegraf on a Raspberry Pi (but any Linux based device can work)</p>
<h2 id="hardware">Hardware</h2>
<p><strong><a href="https://www.amazon.com/gp/product/B011HVUEME/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B011HVUEME&amp;linkCode=as2&amp;tag=rsv0f-20&amp;linkId=b3bd3c48a6a7e921144609cb59359f0e" target="_blank" rel="noopener noreffer">RTL-SDR</a></strong></p>
<p>The definition of SDR is “Software Defined Radio”, it’s a radio-communication system where instead of using components that were traditionally implemented in hardware - software is used, allowing greater flexibility and reducing costs.</p>
<p>RTL-SDR is a high quality USB dongle (but relatively cheap at ~$25) that can be used to scan and receive radio signals from 500Khz (24Mhz for the device I used) up to 1.75Ghz. It was designed and built by the awesome dudes over at <a href="https://www.rtl-sdr.com/about-rtl-sdr/" target="_blank" rel="noopener noreffer">RTL-SDR.com</a> based on DVB-T TV tuner dongles. I ordered <a href="https://www.amazon.com/gp/product/B011HVUEME/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B011HVUEME&amp;linkCode=as2&amp;tag=rsv0f-20&amp;linkId=b3bd3c48a6a7e921144609cb59359f0e" target="_blank" rel="noopener noreffer">this</a> kit which included two modular dipole antennas.</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1_huc616545b0e7314066a2472f01ef5c4d9_1120817_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/1.jpeg" data-sub-html="<h2>images/rtl-sdr/1.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/1_huc616545b0e7314066a2472f01ef5c4d9_1120817_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/1.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2_hu4415df00103010adacdf168ad8b6a4c9_1598270_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/2.jpeg" data-sub-html="<h2>images/rtl-sdr/2.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/2_hu4415df00103010adacdf168ad8b6a4c9_1598270_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/2.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3_hu11fcd6c9e34e3b5d10fc09ac9d03a1d1_1389802_200x0_resize_q75_box.jpeg" title="images/rtl-sdr/3.jpeg" data-sub-html="<h2>images/rtl-sdr/3.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rtl-sdr/3_hu11fcd6c9e34e3b5d10fc09ac9d03a1d1_1389802_200x0_resize_q75_box.jpeg" alt="images/rtl-sdr/3.jpeg">
        </a>
    
</p>

<p><strong><a href="https://www.aliexpress.com/item/33006820989.html?spm=a2g0s.9042311.0.0.1b754c4dDEUyyf" target="_blank" rel="noopener noreffer">RF Wireless Hygrometer + Thermometer</a></strong></p>
<p>Almost any RF based wireless thermometer / humidity sensor is probably readable by <code>rtl_433</code>. Since we’re talking about cheap hardware you can’t really get any assurances, checking the RF frequency is probably enough - if it says 433.92Mhz, you are 99% good. I’ve used <a href="https://www.aliexpress.com/item/33006820989.html?spm=a2g0s.9042311.0.0.1b754c4dDEUyyf" target="_blank" rel="noopener noreffer">this</a> as my indoor sensor and <a href="https://www.aliexpress.com/item/4000872896502.html?spm=a2g0s.9042311.0.0.419a4c4duApRRx" target="_blank" rel="noopener noreffer">this</a> as my outdoor, for monitoring my garden soil humidity level and outdoor temperature</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria_huc9d833e79d7dd2a83277d6401be6cf3b_1248250_200x0_resize_q75_box.jpeg" title="images/sensors/oria.jpeg" data-sub-html="<h2>images/sensors/oria.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/oria_huc9d833e79d7dd2a83277d6401be6cf3b_1248250_200x0_resize_q75_box.jpeg" alt="images/sensors/oria.jpeg">
        </a>
    
        
        <a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor_huc3d583f5dfc3f1b32518ba7724faca9b_1100341_200x0_resize_q75_box.jpeg" title="images/sensors/outdoor.jpeg" data-sub-html="<h2>images/sensors/outdoor.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/sensors/outdoor_huc3d583f5dfc3f1b32518ba7724faca9b_1100341_200x0_resize_q75_box.jpeg" alt="images/sensors/outdoor.jpeg">
        </a>
    
</p>

<p><strong><a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/" target="_blank" rel="noopener noreffer">Raspberry Pi</a></strong></p>
<p>I’ve used a RPi4 that I had lying around loaded with Raspbian Buster.</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi_hu779a99be76e550e5ba32d164eed4fdcf_1769197_400x0_resize_q75_box.jpeg" title="images/rpi.jpeg" data-sub-html="<h2>images/rpi.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/rpi_hu779a99be76e550e5ba32d164eed4fdcf_1769197_400x0_resize_q75_box.jpeg" alt="images/rpi.jpeg">
        </a>
    
</p>

<h2 id="software">Software</h2>
<p><strong><a href="https://cubicsdr.com/" target="_blank" rel="noopener noreffer">CubicSDR for MacOS</a></strong></p>
<p>This is an awesome free open-source software for SDR. It wasn’t easy finding one for MacOS, most of the commonly-used projects are made for Linux and Windows. It’s not really required for decoding 433.92Mhz signals, but I wanted to get my hands dirty and look on live RF, it’s pretty neat (and of course to test the device is actually working!)</p>
<p><strong><a href="https://github.com/merbanan/rtl_433" target="_blank" rel="noopener noreffer">rtl_433</a></strong></p>
<p>An amazing project that can be used to decode a variety of RF-based devices on various frequencies (433.92 MHz, 868 MHz, 315 MHz, 345 MHz, and 915 MHz ISM bands). This is the software that does the heavy lifting.</p>
<p><strong><a href="https://github.com/eclipse/mosquitto" target="_blank" rel="noopener noreffer">Mosquitto</a></strong></p>
<p>Very simple MQTT server and client implementation, we’ll be using that as the output of rtl_433 and input of Telegraf to stream the metrics to a remote InfluxDB instance.</p>
<p><strong><a href="https://github.com/influxdata/telegraf" target="_blank" rel="noopener noreffer">Telegraf</a></strong></p>
<p>Agent for collecting and writing metrics. It will subscribe to our MQTT queue, parse and transmit the metrics to InfluxDB.</p>
<h2 id="getting-a-signal">Getting a signal</h2>
<h3 id="connecting-the-antennas">Connecting the antennas</h3>
<p>Let’s start by quickly testing our shiny RTL-SDR receiver, I’ve used the two short 5cm dipole telescopic antennas for this test, you should definitely read <a href="https://www.rtl-sdr.com/using-our-new-dipole-antenna-kit/" target="_blank" rel="noopener noreffer">this great guide</a> that the awesome dudes over at rtl-sdr.com wrote on using the provided antennas. The antenna used is critical for getting high-quality signal in some cases. For our radio FM test any antenna will probably suffice, but if you want to receive <a href="http://happysat.nl/Setup_Meteor/Setup.html" target="_blank" rel="noopener noreffer">weather satellite signal running on 137Mhz</a>, you’ll have to be more specific.</p>
<p>Hopefully you’ve ended up with something like this:</p>



<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna.jpeg" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna_hud9eea2dece6bfac112cbc216cd3fea82_1405534_400x0_resize_q75_box.jpeg" title="images/antenna.jpeg" data-sub-html="<h2>images/antenna.jpeg</h2><p></p>">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna.jpeg" data-src="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/antenna_hud9eea2dece6bfac112cbc216cd3fea82_1405534_400x0_resize_q75_box.jpeg" alt="images/antenna.jpeg">
        </a>
    
</p>

<h3 id="listening-to-radio">Listening to radio</h3>
<p>Now you can connect the dongle to your usb port, launch CubicSDR, choose “Generic RTL2832U OEM” and hit “Start”, you can ignore the extra settings you see on the right for now. You should see a pretty moving signal heatmap, you can change the center frequency by hovering over it and tapping space (the key), I chose a local FM radio station that is broadcasting on 88Mhz (FM).</p>
<p>Now your bandwidth setting should be set to 200Khz, you should get a nice signal and when you hover your mouse over it the band will “encapsulate” the signal, click and you should start hearing radio!</p>
<h3 id="checking-frequency-43392mhz">Checking Frequency 433.92Mhz</h3>
<p>Let’s get ready to use <code>rtl_433</code> by looking at the frequency and making sure there are devices there. Usually they will transmit information in 30 second bursts, you can change the center frequency to 433.92Mhz and check that you see data. Near the end of the video above you can see the signal bursts when I switch to 433.92Mhz</p>

<p>
  <iframe src="https://www.youtube.com/embed/fnKBjiwZoSw" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="decoding-on-the-rpi">Decoding on the RPi</h2>
<h3 id="installing-and-running-rtl_433-on-our-rpi">Installing and running rtl_433 on our RPi</h3>
<p>I’m assuming you have a working Raspberry Pi with SSH access running Raspbian. We’ll need to compile <a href="https://osmocom.org/projects/rtl-sdr/wiki/Rtl-sdr" target="_blank" rel="noopener noreffer">rtl-sdr</a> and <a href="https://github.com/merbanan/rtl_433" target="_blank" rel="noopener noreffer">rtl_433</a>:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="shell"><span># Install RTL-SDR</span>
mkdir ~/sdr
<span>cd</span> ~/sdr
sudo apt-get update
sudo apt-get install git git-core cmake libusb-1.0-0-dev build-essential
git clone git://git.osmocom.org/rtl-sdr.git
<span>cd</span> rtl-sdr/ <span>&amp;&amp;</span> mkdir build <span>&amp;&amp;</span> <span>cd</span> build/
cmake ../ -DINSTALL_UDEV_RULES<span>=</span>ON -DDETACH_KERNEL_DRIVER<span>=</span>ON
make
sudo make install
sudo ldconfig
</code></pre></td></tr></tbody></table>
</div>
</div><div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="shell"><span># Install rtl_433</span>
<span>cd</span> ~/sdr
git clone https://github.com/merbanan/rtl_433.git
<span>cd</span> rtl_433
mkdir build
<span>cd</span> build <span>&amp;&amp;</span> cmake ../
make
sudo make install
</code></pre></td></tr></tbody></table>
</div>
</div><p>You can now connect the RTL-SDR dongle to the Raspberry Pi and see if you can get some temperature and humidity data! (If you haven’t tested your sensors, now is the time to do it). Run <code>rtl_433</code> and you should get some data like in the video below</p>

<p>
  <iframe src="https://www.youtube.com/embed/2MiUqlUVpNk" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="installing-mosquitto-and-telegraf">Installing Mosquitto and Telegraf</h3>
<h4 id="mosquitto">Mosquitto</h4>
<p>So we’re getting live sensor data, that’s pretty awesome, let’s stream everything to InfluxDB. You can open a free <a href="https://cloud2.influxdata.com/signup" target="_blank" rel="noopener noreffer">Influx Cloud</a> account and we’ll configure Telegraf to stream information to it, after you open the account generate an API key for your bucket.</p>
<p>We’ll use Eclipse Mosquitto as the MQTT server, it’s a very lightweight implementation of MQTT server, providing simple pub/sub service which we’ll use.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="shell">sudo apt-get install mosquitto mosquitto-clients

<span># Enable Mosquitto service and check that it's running</span>
sudo systemctl <span>enable</span> mosquitto
sudo systemctl status mosquitto
</code></pre></td></tr></tbody></table>
</div>
</div><p>The logs are accessible over at <code>/var/log/mosquitto/mosquitto.log</code></p>
<h4 id="telegraf">Telegraf</h4>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="shell">curl -sL https://repos.influxdata.com/influxdb.key <span>|</span> sudo apt-key add -
<span>DISTRIB_ID</span><span>=</span><span>$(</span>lsb_release -c -s<span>)</span>
<span>echo</span> <span>"deb https://repos.influxdata.com/debian </span><span>${</span><span>DISTRIB_ID</span><span>}</span><span> stable"</span> <span>|</span> tee /etc/apt/sources.list.d/influxdb.list

sudo apt-get update
sudo apt-get install telegraf
</code></pre></td></tr></tbody></table>
</div>
</div><p>Before running Telegraf service let’s configure it, you can backup the existing config and paste the contents of my <code>/etc/telegraf/telegraf.conf</code> like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span></code></pre></td>
<td>
<pre><code data-lang="shell">sudo mv /etc/telegraf/telegraf.conf /etc/telegraf/telegraf.conf.bak
sudo bash -c <span>'cat &lt;&lt; EOF &gt; /etc/telegraf/telegraf.conf
</span><span>[agent]
</span><span>  interval = "10s"
</span><span>  round_interval = true
</span><span>  metric_batch_size = 1000
</span><span>  metric_buffer_limit = 10000
</span><span>  collection_jitter = "0s"
</span><span>  flush_interval = "10s"
</span><span>  flush_jitter = "0s"
</span><span>  precision = ""
</span><span>  debug = false
</span><span>  quiet = false
</span><span>  logfile = ""
</span><span>  hostname = ""
</span><span>  omit_hostname = false
</span><span>[[outputs.influxdb_v2]]	
</span><span>  urls = ["CHANGE THIS"]
</span><span>  token = "CHANGE THIS"
</span><span>  organization = "CHANGE THIS"
</span><span>  bucket = "CHANGE THIS"
</span><span>[[inputs.mqtt_consumer]]
</span><span>  servers = ["tcp://127.0.0.1:1883"]
</span><span>  qos = 0
</span><span>  connection_timeout = "30s"
</span><span>  topics = [ "rtl_433/#" ]
</span><span>  client_id = "telegraf"
</span><span>  persistent_session = false
</span><span>  data_format = "json"
</span><span>EOF'</span>

<span># You can now run telegraf manually to make sure the configuration is okay</span>
telegraf --config /etc/telegraf/telegraf.conf

<span># If all went well go ahead and restart the already running service</span>
sudo systemctl restart telegraf
</code></pre></td></tr></tbody></table>
</div>
</div><p>You’ll need to get your InfluxDB endpoint url, token, organization name and bucket from Influx cloud. The MQTT consumer settings specifies connecting to our MQTT server and listening to rtl_433/# topic, which basically says any topic with the prefix rtl_433/ will be sent to InfluxDB.</p>
<p>The expected data should be json (as specified by the <code>data_format</code> option)</p>
<h3 id="running-rtl_433">Running rtl_433</h3>
<p>Now for the last part, just run rtl_433 with mqtt output!, to make sure everything works you can first run a mosquitto subscription client and listen to incoming events by running <code>mosquitto_sub -t "rtl_433/#"</code>, afterwards launch it (I like using screen for that, see the next video):</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre><code data-lang="shell">rtl_433 -C si -F <span>"mqtt://localhost:1883,events=rtl_433[/model][/id]"</span>
<span># You will not get any data in the shell so if you think</span> 
<span># something is not working launch mosquitto_sub and make sure you are getting events</span>
</code></pre></td></tr></tbody></table>
</div>
</div>
<p>
  <iframe src="https://www.youtube.com/embed/lR6ynCU9QYs" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>If all went well data should be flowing to InfluxDB! hurrah!</p>
<h2 id="viewing-your-data">Viewing your data</h2>
<p>Using InfluxDB is outside the scope of this post but you should be able to get funky graphs like this one:</p>
<p><a href="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" title="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" data-thumbnail="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png">
        <img src="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" data-src="images/influx_dashboard.png" data-srcset="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png, images/influx_dashboard.png 1.5x, /posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 2x" data-sizes="auto" alt="/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png" srcset="https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png, https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 1.5x, https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/images/influx_dashboard.png 2x">
    </a></p><h2 id="final-words">Final words</h2>
<p>Using RTL-SDR for decoding RF data is only the tip of the iceberg of what you can do with it, I highly suggest going to <a href="https://www.rtl-sdr.com/" target="_blank" rel="noopener noreffer">rtl-sdr.com</a> and checking some of their amazing tutorials - You can receive live weather satellite data, decode trunked radio systems and see the universe!</p>
</div></div>]]>
            </description>
            <link>https://guti.in/posts/2020-07-11-rtl-sdr-rpi-influxdb-temperature-monitoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817738</guid>
            <pubDate>Mon, 13 Jul 2020 06:46:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scheduling Your Life Like a Computer Engineer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817690">thread link</a>) | @mycpuorg
<br/>
July 12, 2020 | http://www.mycpu.org/scheduling/ | <a href="https://web.archive.org/web/*/http://www.mycpu.org/scheduling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>No matter which stage of career you are in, managing time and tasks become a
matter of utmost priority. Paul Graham’s essay on <a href="http://www.paulgraham.com/makersschedule.html">Maker’s
Schedule</a> explains a good way
to think about typical programmers vs typical managers schedule.</p>

<p>Beyond this, there is a more specific problem that most programmers battle with
intra-project prioritization. You break down a large project into sub tasks and
how would you schedule them? Especially if the project is for a client (assuming
it doesn’t entail a monolithic purpose to it, since this is extremely rare). For
example: it rarely is “Make me a new text editor”</p>

<p>With that said, if you looked into how Operating Systems handle this sort of a
thing we can see the various scheduling policies available. In Linux Kernel,
there are a ton of such policies:</p>
<ul>
  <li>Completely Fair Scheduler (CFS)</li>
  <li>FIFO or FCFS (First In First Out)</li>
  <li>Earliest Deadline First or Deadline Scheduling (EDF)</li>
</ul>

<h2 id="earliest-deadline-first-edf">Earliest Deadline First (EDF)</h2>
<p>EDF has produces an optimal scheme for minimizing the maximum lateness.</p>

<p><img src="http://www.mycpu.org/images/EDD.png" alt="">
<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>If your goal is to simply minimize the amount of lateness only, then this is
it. It is the optimal scheme. However, this has the downside of producing a lot
of tasks can be late albeit by a smaller margin. What if you want to optimize
for minimizing the number of tasks that are late?</p>

<h2 id="moores-algorithm">Moore’s Algorithm</h2>
<p>Moore’s Algorithm optimizes for the number of tasks that are late. It does so by
first ordering the tasks as per EDF scheme then trying to spot a largest job that
results in delaying a later task in the pipeline. It then moves this large job
to the end of the queue.</p>

<p><img src="http://www.mycpu.org/images/MooresAlgo.png" alt="">
<sup id="fnref:1:1"><a href="#fn:1">1</a></sup></p>

<p>You can break down a big problem into smaller tasks, by simply using the better
of these two schemes recursively you have solved your schedule. You have even
mathematically optimized your scheduling scheme. Another important, yet
underrated benefit is that you have drastically reduced your cognitive load on
the planning/scheduling aspect. Instead you get to look deeper into the design
and other technical parts of the project.</p>



      <hr>
      
    </div></div>]]>
            </description>
            <link>http://www.mycpu.org/scheduling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817690</guid>
            <pubDate>Mon, 13 Jul 2020 06:35:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817638">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817638</guid>
            <pubDate>Mon, 13 Jul 2020 06:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Evolutionary Psychology]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817470">thread link</a>) | @ghosthamlet
<br/>
July 12, 2020 | https://www.deepideas.net/introduction-to-evolutionary-psychology/ | <a href="https://web.archive.org/web/*/https://www.deepideas.net/introduction-to-evolutionary-psychology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				<div>
					


<div> <!-- start fusion sticky header wrapper -->
	<div>
		<div>
							<div data-margin-top="31px" data-margin-bottom="0px" data-margin-left="0px" data-margin-right="0px">
			<a href="https://www.deepideas.net/">

						<!-- standard logo -->
			<img src="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png" srcset="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png 1x" width="332" height="102" alt="deepideas.net Logo" data-retina_logo_url="">

			
					</a>
		
<div>
			<h3>
			a blog on cognitive science and artificial intelligence, dedicated to the deep thinkers of this world		</h3>
	</div>
</div>
								
			
					</div>
	</div>
	
</div> <!-- end fusion sticky header wrapper -->
				</div>
				
			</header>
						
			
		
				
			
			

						<main id="main">
				<div>

<section id="content">
			
	
					<article id="post-648">
						
														
						
																									<div>
				<p>Evolutionary psychology is an approach to understand human behavior that combines insights gained from evolutionary biology, the computational sciences and the study of ancestral living conditions. It has been put forward as an opposing view to what Tooby and Cosmides (1992) call the <em>Standard Social Science Model</em> (SSSM), which has dominated the social and behavioral sciences throughout most of the 20th century. According to the SSSM, the mental organization of adult human beings is not caused by human nature. Rather, humans acquire their mental organization almost entirely from their sociocultural and physical environment. Human beings, on this view, only have a minimal amount of innate impoverished drives (like hunger, thirst, sexual motivation, etc.) and, independently of these, a capacity to be socialized through learning.</p>
<p>A prominent argument given in favor of the SSSM is the fact that genetically determined behavior might be maladaptive due to changing environmental conditions, and therefore the mind evolved towards general-purpose and domain-general learning systems. On this view, the phenotype’s behavior is plastic and tailored toward maximizing individual fitness under changing environmental circumstances. The selective pressures of ancestral environments gave rise to this plasticity, but the concrete adaptive problems that have been faced in these environments play only a minor role in explaining the behavior of modern humans. This is the reason why many social scientists study human behavior in modern conditions more or less independently from their evolutionary history.</p>
<p>Evolutionary psychology, in contrast, holds that psychological mechanisms are evolved adaptations to ancestral adaptive problems. An analogy is drawn here between organs in the body and “cognitive programs” or “mental organs”: Analogous to how organs in the body evolved to solve a particular adaptive problem, e.g. digesting food, cognitive programs evolved to solve a particular adaptive information processing problem, e.g. predator/prey distinction, kin detection, language, etc.</p>
<p>In the following, we will break down the individual tenets of evolutionary psychology and review the arguments that are given in support of these tenets. Since not all tenets are shared by all evolutionary psychologists, we will focus here on the formulation given by Cosmides and Tooby (1987) and Tooby and Cosmides (2005). The tenets are not listed explicitly, but can be reconstructed implicitly from these texts. I will go through each tenet in turn and present a reconstruction of the arguments that motivate these tenets.</p>
<h3>Tenet 1: The brain evolved to be a computer that solves information processing problems.</h3>
<p>This tenet is motivated as follows: Environments pose adaptive information processing problems to organisms. Hence, the genes of organisms that successfully solve these information processing problems spread in the gene pool and such organisms are, by definition, computers.</p>
<p>This tenet, Tooby and Cosmides (2005, p. 31) argue, is shared by proponents of the SSSM. Even a domain-general learning mechanism would be an innate information processing mechanism that evolved at some point to solve adaptive problems. For example, operant conditioning presupposes an innate mechanism to alter the probability of behaviors based on their intrinsically reinforcing consequences (like food or pain). Similarly, classical conditioning presupposes innate unconditioned stimuli and a method to calculate contingencies. Consequently, Tooby and Cosmides (2005, p. 32) conclude that “learning is not an alternative explanation to the claim that natural selection shaped the behavior” and that “a behavior can be, at one and the same time, cultural, learned, and evolved”. This means that the commonly perceived controversy between innateness/evolvedness on the one hand and learnedness on the other is based on a false dichotomy. Rather, it is proposed, evolution created programs as learning mechanisms, and these mechanisms are a prerequisite for learning to be able to occur. The disagreement between the SSSM and evolutionary psychology, therefore, only regards the structure of the evolved learning mechanisms, not the question whether such learning mechanisms evolved at all.</p>
<p>When we accept the theory of evolution through natural selection, it arguably becomes theoretically impossible to deny that the brain evolved to be a computer that solves adaptive information processing problems – unless we claim that (A) evolution hasn’t found this path yet, (B) evolution cannot find this path in principle since it would lead through a fitness valley or (C) adaptive problems aren’t information processing problems and therefore a computer would not be the ideal solution. Discussing these possibilities would be beyond the scope of this introduction, so I am going to suppose (A), (B) and (C) to be false for the rest of this discussion. This leads us to accept this tenet.</p>
<h3>Tenet 2: The brain is not a “blank slate” domain-general fitness-maximizing machine.</h3>
<p>Cosmides and Tooby (1987, p. 47) and Tooby and Cosmides (2005, pp. 294- 299) argue that there is no domain-general success criterion that is correlated with fitness and, therefore, a domain-general mechanism would not be successful at actually maximizing fitness and could therefore not have evolved. This argument can be summarized as follows: If no domain-specific innate knowledge is present in the organism, then it can only acquire knowledge that can be inferred from perceptual inputs, without relying on innate perceptual heuristics. Similarly, it can learn behaviors only through trial and error learning, which would amount to generating random sequences of actions, observing the fitness outcome (e.g. the number of produced offspring) and then reinforcing or mitigating behaviors based on this outcome. Proposing instead that the mechanism could rely on perceptual cues like smell or taste as a proxy for expected fitness, they argue, amounts to “admitting domain-specific innate knowledge”.</p>
<p>However, when observing a certain positive or negative fitness outcome (like an increase or decrease in the produced offspring), it is virtually impossible to trace it back to the precise actions or sequences of actions that caused it, since virtually any action taken before in the organism’s life could have caused it. Furthermore, whether a sequence of action promotes fitness is highly context-sensitive. Thus, due to the resulting combinatorial explosion, behaviors cannot reliably be reinforced or mitigated and behavior stays more or less random. Therefore, an organism with adequate innate domain-specific knowledge, perceptual heuristics and perception-action patterns would have a fitness advantage over an organism that only has a domain-general fitness-maximizing mechanism, consequently triggering selection for organisms with these traits.</p>
<h3>Tenet 3:&nbsp;The brain executes innate, domain-specific, functionally isolable cognitive programs that generate particular behaviors in response to particular external or internal informational inputs. Most or even all of these programs evolved as a response to a particular adaptive information processing problem.</h3>
<p>It should be noted that it is not claimed that all cognitive programs generate behavior deterministically based on the current perceptual input. Rather, some of these programs exhibit what is commonly called <em>experience-dependent plasticity</em>: They are able to learn based on the input they receive throughout the organism’s development (Cosmides and Tooby, 1987, p. 284). For example, the language program learns to acquire the language of a person’s surrounding community. The programs, therefore, did not evolve to produce a certain kind of behavior, but they evolved to produce a mapping from current inputs and the sequence of inputs they received throughout development to behaviors. Different programs have different degrees of experience-dependent plasticity, depending on the fitness advantage that plasticity would provide over genetic determinism in the program’s adaptive domain.</p>
<p>In a similar fashion, programs are <em>experience-expectant</em>: They evolved to be able to develop only if they receive certain informational inputs at critical periods throughout development (Tooby and Cosmides, 2005, p. 34-35). This entails that a program’s innateness does not mean that it is present at birth – much like teeth are innate but not present at birth. Rather, a cognitive program can develop at any point in an organism’s life, depending on whether it is relevant at that point in life and whether the developmentally relevant informational inputs have been received. Tooby and Cosmides (2005, p. 35) stress that this developmentally relevant information consists not only of contingencies in physical laws and the behavior of other organisms, but also of the physical and cultural environment. The latter comprise a second inheritance system that co-evolves with the genes, and changes in these environments can lead to significant alterations in the operation of the cognitive programs, or even a failure of certain cognitive programs to develop.</p>
<p>It should also be noted that it is not claimed that the cognitive programs can&nbsp;only generate behavior according to their original adaptive function. For example, the language program, which arose as an adaptation for spoken language, can learn to acquire reading and writing (Tooby and Cosmides, 2005, p. 26). The ability to learn reading and writing is not an adaptation but a by-product of the adaptation for spoken language.</p>
<p>However, it is claimed that the …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepideas.net/introduction-to-evolutionary-psychology/">https://www.deepideas.net/introduction-to-evolutionary-psychology/</a></em></p>]]>
            </description>
            <link>https://www.deepideas.net/introduction-to-evolutionary-psychology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817470</guid>
            <pubDate>Mon, 13 Jul 2020 05:32:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Is Surprisingly Good as a Server Language]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 326 (<a href="https://news.ycombinator.com/item?id=23817464">thread link</a>) | @signa11
<br/>
July 12, 2020 | https://stu2b50.dev/posts/rust-is-surpris76171 | <a href="https://web.archive.org/web/*/https://stu2b50.dev/posts/rust-is-surpris76171">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
      <div id="main">
        

    

    <div>
        
<p>At some point, I got tired of my old static site generator setup for my blogs and other pages. It was annoying to ssh every time I wanted to make a modification, it was annoying to sftp or sshfs all my images, and so forth. And god forbid, if you ever wanted someone else to write something or make an edit, let me tell you, most people are not particularly happy when you tell him "hey, I'll make you a user on my server, give me your public key so you can ssh in".</p>
<p>I wanted something with a <em>little</em> more dynamism. </p>
<p>So that was the project: a small scope blog, where a few, already <em>trusted</em> users can make, edit, and post new pages in markdown (with a nice markdown editor courtesy of <a href="https://simplemde.com/">SimpleMDE</a>). Additionally, I want a built in jank verison of imgur so I can satisfy my need to be self sufficient without going crazy.</p>
<p>So while I could whip something up in an afternoon with Django, I could also experiment with other languages. The project is simple enough that I can't imagine being too limited by any language's ecosystem. And I've been itching to write something substansive in Rust...</p>
<h3>Which framework?</h3>
<p>The biggest framework is probably <code>actix-web</code>. But</p>
<ol>
<li>When I was scoping out my options months ago, actix-web's maintainer quit with a bunch of drama</li>
<li>At least from what I could tell reading the docs, it seems more suited to APIs rather than servers serving templated HTML</li>
<li>With the above, I wanted this to be a weekend project, not a weekly project, so the more batteries included the better</li>
<li>I really don't want to figure out which async library is considered better. And note that with each async library, comes its own ecosystem of libraries, which only work with that async library, so it's a pretty hard decision to reverse after you made it.</li>
</ol>
<p>So Rocket it is. </p>

<p>Something I didn't realize until I started scoping out this project is that on servers... the memory model is actually pretty simple! </p>
<p>Much of your state is just handled by your database. I <em>never</em> actually fought with the borrow checker. I never had to. For the most part, everything had exactly one owner, and exactly one lifetime: the function that's handling the request. </p>
<p>Rocket, too, has a surprising amount of "magic":</p>
<pre><code>#[get("/posts/&lt;slug&gt;/"]
pub fn post_view(slug: String) -&gt; Option&lt;Template&gt; {
    ...
		
    Some(Template::render("/posts/post", hashmap! { "post" =&gt; post}))
}
</code></pre>
<p>As opposed to Flask's</p>
<pre><code>@app.route("/posts/&lt;string:slug&gt;")
def post_view(slug):
    ...
		
    return render_template("posts/post.html", post=post)
</code></pre>
<p>Rust's macro system has really impressed me so far. Not only is there a shocking amount of "just works", but it's all statically typed and compiled.</p>
<p>The closest analogue to Rocket is flask + all the flask adjacent libraries (SQLAlchemy-flask, etc). Rocket, through the power of 3rd party integrations, comes with two template engines (handlebars, and Tera, which is basically Jinja2), database pooling support for quite a few ORMs/DB drivers, and more.</p>
<p>It's still at the point where you have to roll your own auth, though.</p>
<p>While I've heard comparisons to Django/Rails, it doesn't really seem like they're going that direction. Django/Rails purposefully put you, the developer, on the metaphorical rails, dictating best practices from everything from where the files go, to how you update your models and views. Rocket doesn't do that, and I'm not sure it should ever.</p>
<p>I also had, for the most part, the experience that "if it compiles, it works". Most of my runtime errors were in the templates, which incidentally is the only thing that's not statically typed. </p>
<p>I guess that's really what surprised me. For a lot of it, "it just works"! There's not a lot of boilerplate syntax, type inference keeps your functions clean, and I didn't write a <em>single</em> lifetime annotation at any point. My rust server really didn't look that different from my flask server, or my Django server, and honestly it looks cleaner than my Java server. All with no garbage collector or runtime.</p>

<p>Next, I'll talk about Diesel, which as far as I can see, is the most mature ORM available. While I do have my gripes, it's not really anything "objectively" bad. I suppose it's more on tradeoffs, and Diesel chooses to go light on the magic. </p>
<p>For one, it's annoying to make two structs for each table. You need one to represent the table, and one to insert with (with any autogenerated columns like the primary key removed). For instance, I have</p>
<pre><code>#[derive(Identifiable, Queryable, Associations, PartialEq, Debug, Serialize)]
#[belongs_to(BlogPosts, foreign_key="post_id")]
#[table_name = "tags"]
pub struct Tag {
    id: i32,
    tag_name: String,
    post_id: i32,
}

#[derive(Insertable)]
#[table_name = "tags"]
pub struct InsertTag {
    tag_name: String,
    post_id: i32
}
</code></pre>
<p>Additionally, while in some ORMs you write your table models, and the ORM generates your SQL migrations, in Diesel, you write your SQL migrations by hand, and the ORM generates a <code>schema.rs</code> file that contains the mappings. I actually don't mind that one too much.</p>
<p>Diesel also only supports parent-child relationships, and you have to be quite explicit. There's no magic field on your parent, that magically gives you a list of its children. No, you just have to write the query and call it. In some sense it's more like using a slightly fancier query builder.</p>
<p>Dipping down from that level of magic, it's not really a <em>bad</em> thing per se. By being explicit, you prevent users from believing too much in that magic, and shooting themselves in the foot, like N+1 selects. </p>
<p>But I'm not going to say it didn't slow me down quite a bit, either. And to be honest, writing joins was a humongous pain in the ass. Maybe that's how it should be, but maybe that also caused a generation of NoSQL databases. 🤷</p>

<p>Here's how you upload an image in flask</p>
<pre><code>@app.route('/images/upload')
def upload_file():
	files = request.files['file']
	if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))
</code></pre>
<p>Here's the "simpler" example, while using a <em>third party library in addition</em> from abonader</p>
<p><a href="https://github.com/abonander/multipart/blob/master/examples/rocket.rs"><strong>See the whole thing here</strong></a></p>
<pre><code>#[post("/upload", data = "&lt;data&gt;")]
// signature requires the request to have a `Content-Type`
fn multipart_upload(cont_type: &amp;ContentType, data: Data) -&gt; Result&lt;Stream&lt;Cursor&lt;Vec&lt;u8&gt;&gt;&gt;, Custom&lt;String&gt;&gt; {
    // this and the next check can be implemented as a request guard but it seems like just
    // more boilerplate than necessary
    if !cont_type.is_form_data() {
        return Err(Custom(
            Status::BadRequest,
            "Content-Type not multipart/form-data".into()
        ));
    }

    let (_, boundary) = cont_type.params().find(|&amp;(k, _)| k == "boundary").ok_or_else(
            || Custom(
                Status::BadRequest,
                "`Content-Type: multipart/form-data` boundary param not provided".into()
            )
        )?;

    match process_upload(boundary, data) {
        Ok(resp) =&gt; Ok(Stream::from(Cursor::new(resp))),
        Err(err) =&gt; Err(Custom(Status::InternalServerError, err.to_string()))
    }
}

fn process_upload(boundary: &amp;str, data: Data) -&gt; io::Result&lt;Vec&lt;u8&gt;&gt; {
    let mut out = Vec::new();

    // saves all fields, any field longer than 10kB goes to a temporary directory
    // Entries could implement FromData though that would give zero control over
    // how the files are saved; Multipart would be a good impl candidate though
    match Multipart::with_body(data.open(), boundary).save().temp() {
        Full(entries) =&gt; process_entries(entries, &amp;mut out)?,
        Partial(partial, reason) =&gt; {
            writeln!(out, "Request partially processed: {:?}", reason)?;
            if let Some(field) = partial.partial {
                writeln!(out, "Stopped on field: {:?}", field.source.headers)?;
            }

            process_entries(partial.entries, &amp;mut out)?
        },
        Error(e) =&gt; return Err(e),
    }

    Ok(out)
}
</code></pre>
<p>Now, to be fair, Rocket is in version 0.4.5. From <a href="https://github.com/SergioBenitez/Rocket/issues/106"><strong>this github issue</strong></a>, multipart form support is coming in 0.5.0. But it doesn't change the fact that right now, the current libraries are somewhat immature still. They lack some of the edge features, especially for more traditional web servers that serve templated HTML, as opposed to pure API servers, or an SPA. </p>
<hr>
<p>Rust's errors are quite good, usually. But that's before you get into, well, libraries that try to do a bit more. I ran into some... interesting error messages, mostly from macros in Rocket and Diesel. Take a look at this one, for instance.</p>
<pre><code>the trait bound `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32): diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not satisfied

the trait `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer)&gt;, diesel::sqlite::Sqlite&gt;` is not implemented for `(i32, std::string::String, std::string::String, std::string::String, i32, i32, std::string::String, i32, i32)`

help: the following implementations were found:
        &lt;(A, B, C, D, E, F, G, H, I) as diesel::Queryable&lt;(SA, SB, SC, SD, SE, SF, SG, SH, SI), __DB&gt;&gt;
note: required because of the requirements on the impl of `diesel::Queryable&lt;diesel::sql_types::Nullable&lt;(diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Text, diesel::sql_types::Integer, diesel::sql_types::Integer, diesel::sql_types::Text, diesel::sql_types::Integer, …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stu2b50.dev/posts/rust-is-surpris76171">https://stu2b50.dev/posts/rust-is-surpris76171</a></em></p>]]>
            </description>
            <link>https://stu2b50.dev/posts/rust-is-surpris76171</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817464</guid>
            <pubDate>Mon, 13 Jul 2020 05:31:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gödel’s Incompleteness Theorem and Its Implications for Artificial Intelligence]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817462">thread link</a>) | @ghosthamlet
<br/>
July 12, 2020 | https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/ | <a href="https://web.archive.org/web/*/https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
			<header>
				<div>
					


<div> <!-- start fusion sticky header wrapper -->
	<div>
		<div>
							<div data-margin-top="31px" data-margin-bottom="0px" data-margin-left="0px" data-margin-right="0px">
			<a href="https://www.deepideas.net/">

						<!-- standard logo -->
			<img src="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png" srcset="https://www.deepideas.net/wp-content/uploads/2017/08/logo-3.png 1x" width="332" height="102" alt="deepideas.net Logo" data-retina_logo_url="">

			
					</a>
		
<div>
			<h3>
			a blog on cognitive science and artificial intelligence, dedicated to the deep thinkers of this world		</h3>
	</div>
</div>
								
			
					</div>
	</div>
	
</div> <!-- end fusion sticky header wrapper -->
				</div>
				
			</header>
						
			
		
				
			
			

						<main id="main">
				<div>

<section id="content">
			
	
					<article id="post-71">
						
														
						
																									<div>
				<h2>Introduction</h2>
<p>This text gives an overview of Gödel’s Incompleteness Theorem and its implications for artificial intelligence. Specifically, we deal with the question whether Gödel’s Incompleteness Theorem shows that human intelligence could not be recreated by a traditional computer.</p>
<div class="page" title="Page 1">
<div>
<div>
<p>Sections 2 and 3 feature an introduction to axiomatic systems, including a brief description of their historical development and thus the background of Gödel’s Theorem. These sections provide the basic knowledge required to fully understand Gödel’s Theorem and its significance for the history of mathematics – a necessary condition for understanding the arguments to follow. Section 4 features a thorough description of Gödel’s Theorem and outlines the basic idea of its proof. Sections 5 and 6 deal with arguments advocating the view that intelligence has a non-algorithmic component on the grounds of Gödel’s Theorem. In addition to a detailed account of the arguments, these sections also feature a selection of prominent objections to these arguments raised by other authors. The last section comprises a discussion of the arguments and my own objections.</p>
<h2>The Formalization of Mathematics</h2>
<div class="page" title="Page 1">
<div>
<div>
<p>At the beginning of the 20th century, the mathematical community suffered from a crisis regarding the very foundations of mathematics, triggered by the discovery of various paradoxes that called into question the reliability of mathematical intuition and the notion of proof. At that time, some fields of mathematics were grounded on a rigorous formal basis, called an <strong>axiomatic system</strong> (or interchangeably formal system), whereas other fields relied on a certain degree of intuitive insight.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>In a formal way, an axiomatic system is a set of propositions, expressed in a formal language, called axioms. These axioms represent statements that are assumed to be true without proof. The set of axioms is equipped with a set of inference rules which can be used to derive other propositions, called theorems, by applying them to the axioms. Applying the rules of inference boils down to replacing expressions by certain other expressions according to precise syntactical rules. The axioms and the set of inference rules are ideally chosen in such a way that they are intuitively evident. This way, the truth of a complex, non-obvious statement can be accepted by accepting the truth of the axioms and sequentially applying the inference rules until the complex statement in question is deduced.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>An early, prominent example of such an axiomatic system is the Euclidean geometry described by the ancient Greek philosopher Euclid in c. 300 BC (an English translation can be found in [Euc02]). It consists of 5 axioms making trivial statements about points, lines and circles (e.g. that any two points could be connected by a line). From these axioms, Euclid derived 48 non-trivial geometric propositions solely by means of logical inference and without making use of informal geometric intuition or perception.</p>
<div class="page" title="Page 2">
<div>
<div>
<p>Up until modern times, geometry was the only branch of mathematics that was predicated on such a sound axiomatic basis, whereas research and applications in other branches were carried out without a rigid formal notion about which types of inference were allowed and which statements were assumed to be intuitively evident. This was due to the fact that, for most practical purposes, mathematicians saw no need for doing so. However, this changed with the discovery of various paradoxes around the turn of the 20th century. In 1901, the British mathematician Bertrand Russell put forward what later came to be known as <strong>Russell’s paradox</strong> (cf. [Gri04]). This paradox showed an inherent flaw in the informal set theory proposed by German mathematician Georg Cantor, according to which every definable collection of distinct elements is a set. Russell defined the set R of all sets that do not contain themselves, symbolically:</p>
<p>$$\{x \; \mid \; x \not\in x\}$$</p>
<div class="page" title="Page 2">
<div>
<div>
<p>According to Cantor, R is a valid set. The paradox arises when one asks the question whether R contains itself. If R contains itself, then by definition it does not contain itself. If, on the other hand, it does not contain itself then it contains itself by definition. Symbolically:</p>
<p>$$R \in R \; \iff R \not\in R$$</p>
<div class="page" title="Page 3">
<div>
<div>
<p>Therefore, the question whether R contains itself has no well-defined answer. This example shows that the notion of a set defined by Cantor is flawed, even though it seems to be intuitively reasonable. Examples like this lead many mathematicians to recognize that intuition is not a safe guide and that there was a need to supply all branches of mathematics with an axiomatic system that would be sufficient to formally derive all true propositions, a standpoint later termed <strong>formalism</strong> (cf. [NN01] p. 3). Over time, more and more branches, both new and old, were equipped with sets of axioms (e.g. the Zermelo-Fraenkel set theory, cf. [Fra25]).</p>
<div class="page" title="Page 3">
<div>
<div>
<p>It is worth noting that axiomatic systems and formal proofs do not require an intuitive understanding of the entities described or the nature of the proven statements. Consider the following example:</p>
<div class="page" title="Page 3">
<div>
<div>
<blockquote><p><strong>Axiomatic system 1.<br>
</strong>1. Every member of P is contained in exactly two members of L.<br>
2. Every member of L contains exactly two members of P.<br>
3. Every two members of L share exactly one member of P.</p></blockquote>
<div class="page" title="Page 3">
<div>
<div>
<p>This axiomatic system makes statements about some abstract sets L and P , and even though we can understand the axioms per se, we do not associate any meaning with the symbols and we do not have any intuition about the overall structure of L and P. Still, we can deduce theorems from these axioms. For example, it can be shown that every three members of L contain exactly three members of P. Even though the axioms were given informally, they can be translated into second-order logic and the proof for the theorem can be carried out using rules that just replace certain sequences of symbols with other symbols. This way, the proof could be carried out by a computer simply by iteratively applying symbol replacement rules on meaningless sequences of symbols until the theorem is obtained. It is then clear that the theorem follows from the axioms without any intuition as to what the theorem or the axioms actually represent.</p>
<h2>Hilbert’s Program</h2>
<div class="page" title="Page 3">
<div>
<div>
<p>A prominent representative of the formalist standpoint was David Hilbert, who initiated what was later termed <strong>Hilbert’s Program</strong> (cf. [Zac15]). Hilbert advocated the view that all fields of mathematics should be grounded on an axiomatic basis. Furthermore he demanded that every such system should be proven to be consistent, which means that it is impossible to deduce two contradictory theorems from the axioms.</p>
<div class="page" title="Page 3">
<div>
<div>
<p>Proving the inconsistency of an axiomatic system can be done by deducing a contradiction. The question that Hilbert wanted to address, however, was how to prove the consistency, i.e. how to prove the impossibility to deduce a contradiction. One way to do so is to find an interpretation of the axioms, such that they form true statements about some part of reality or some abstract concept of our intuition. A possible model for the axiomatic system 1 is given in the following image:</p>
<p><img data-attachment-id="102" data-permalink="https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/triangle/" data-orig-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1270%2C930&amp;ssl=1" data-orig-size="1270,930" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="triangle" data-image-description="" data-medium-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=300%2C220&amp;ssl=1" data-large-file="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1024%2C750&amp;ssl=1" src="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle-300x220.png?resize=300%2C220" alt="" width="300" height="220" srcset="https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=200%2C146&amp;ssl=1 200w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=300%2C220&amp;ssl=1 300w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=400%2C293&amp;ssl=1 400w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=600%2C439&amp;ssl=1 600w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=768%2C562&amp;ssl=1 768w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=800%2C586&amp;ssl=1 800w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=1024%2C750&amp;ssl=1 1024w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?resize=1200%2C879&amp;ssl=1 1200w, https://i1.wp.com/www.deepideas.net/wp-content/uploads/2017/08/triangle.png?fit=1270%2C930&amp;ssl=1 1270w" sizes="(max-width: 300px) 100vw, 300px" data-recalc-dims="1"></p>
<p>When we interpret the set P as the corners of a triangle and the set L as its edges, then the axioms are invested with meaning and we can verify beyond doubt that all axioms represent true statements about the model by verifying them for each individual element. This can be done easily since there are only finitely many elements. This proves the consistency of the system, because no contradiction can be deduced from true premises.</p>
<div class="page" title="Page 4">
<div>
<div>
<p>However, there are axiomatic systems for which the model-based approach to proving their consistency is open to dispute. If, for example, the axioms require the model to contain an infinite number of elements, then it is impossible to verify the truth of the axioms beyond doubt, since the truth can no longer be verified for each individual element. Moreover, the model-based approach actually only reduces the consistency of one system to the consistency of another system. As regards the triangle example, we established the consistency of the axioms by verifying them for the triangle, but in doing so we implicitly assumed the consistency of geometry. Therefore, we have only shown that if geometry is consistent, then our axiomatic system is also consistent; we have given what is called a <strong>relative proof of consistency</strong>.</p>
<div class="page" title="Page 4">
<div>
<div>
<p>Hilbert urged to find <strong>absolute proofs of consistency</strong>, i.e. proofs that establish the consistency of an axiomatic system without presupposing the consistency of another axiomatic system. Absolute proofs of consistency use structural properties of the axioms and inference rules in order to show that no contradictions can be derived; they are not proofs within the formal axiomatic system itself, but rather proofs about the system. They are, so to speak, proofs in some meta-system. To better understand the concept of a meta-system, consider the statement ”’$p \vee p \rightarrow p$’ is a tautology”. This is not a statement within propositional logic, but a statement in some meta-system <em>about</em> propositional logic, and it can be proved within that meta-system.</p>
<div class="page" title="Page 5">
<div>
<div>
<p>Absolute proofs of consistency have successfully been established for some axiomatic systems, e.g. propositional logic (cf. [NN01] p. 45). This lead Hilbert to believe that such a proof could be found for any consistent axiomatic system, which is where Gödel’s Incompleteness Theorem comes into play: amongst other things, it shows that this is impossible for most of the axiomatic systems.</p>
<h2>Gödel’s Incompleteness …</h2></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/">https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/</a></em></p>]]>
            </description>
            <link>https://www.deepideas.net/godels-incompleteness-theorem-and-its-implications-for-artificial-intelligence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817462</guid>
            <pubDate>Mon, 13 Jul 2020 05:31:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The three levels of Hindu philosophy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817439">thread link</a>) | @paraschopra
<br/>
July 12, 2020 | https://invertedpassion.com/three-levels-of-hindu-philosophy/ | <a href="https://web.archive.org/web/*/https://invertedpassion.com/three-levels-of-hindu-philosophy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-511">
		<!-- .entry-header -->
	<div>
		
		
<p><strong>1/</strong> The first level related to the metaphysical and spiritual domain.</p>



<p>It says that Brahman is all that exists and our material world (Maya) comes from ignorance.</p>



<p>The Brahman is not a God. It is beyond any quality – it isn’t intelligent, good or bad. It just is.</p>



<p><strong>2/</strong> It also suggests that if we strip away all ignorance, we will discover that the self – the atman – is one and the same thing as the Brahman.</p>



<p>At its core, this level denies the duality of subject and object and says they both are the same.</p>



<p><strong>3/</strong> The second level has more religious connotations because, like all religions, its purpose is the stabilization of society.</p>



<p>The concept of Karma and Dharma ensures that society has net positive interactions. And the rituals and idol worship ensures everyone knows who is in the camp.</p>



<p><strong>4/</strong> This level ensures an ethical code exists and that it’s clear who all share that same ethical code.</p>



<p>The symbols – the idols, the chants, the rituals – take a spiritual dimension on their own, but these are subservient to the belief in one Brahman – the essence of the world.</p>



<p><strong>5/</strong> The third level is psychological – to give guidance to an individual on how to live his/her life.</p>



<p>The suggestion in <a href="https://invertedpassion.com/what-gita-teaches-us-and-what-it-doesnt/">Gita</a> that one must do work without an expectation of reward is towards minimizing psychological anguish.</p>



<p><strong>6/</strong> To reiterate, the three levels of Hindu philosophy are:</p>



<ul><li>METAPHYSICAL: <a href="https://en.wikipedia.org/wiki/Mah%C4%81v%C4%81kyas">Tat tvam asi.</a> You’re it [it = Brahman]</li><li>SOCIETAL: Rebirth, Karma, Dharma, and Rituals</li><li>PSYCHOLOGICAL: Expect no reward</li></ul>



<p><strong>7/</strong> Of course, everyone has their interpretation. Unlike Judeo-Christian religions, there are no definitive books on Hindusim.</p>



<p>Rather than a bug, I think it’s a feature.</p>



<p>It ceases to be a philosophy if you can’t interpret it on your own.</p>



<p><strong>8/</strong> There are some beautiful ideas in Hinduism, though I’m not sure I agree with all of them.</p>



<p>If you have your favorite ideas, let me know. I love diving deep into Indian philosophy.</p>



<p><em>This essay is a lightly-edited version of a <a href="https://twitter.com/paraschopra/status/1104658952061681665">Twitter thread I posted</a>.</em></p>



<p>Someone made an image out of the three levels:</p>



<figure><img src="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg" alt="" srcset="https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-756x1024.jpg 756w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-221x300.jpg 221w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-768x1041.jpg 768w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq-1134x1536.jpg 1134w, https://invertedpassion.com/wp-content/uploads/2020/07/EceBh_GU4AEpeEq.jpg 1338w" sizes="(max-width: 756px) 100vw, 756px"><figcaption>Made by <a href="https://twitter.com/nisacharan">@nishacharan</a></figcaption></figure>



<p><span><strong>Have an opinion on this essay?</strong></span> You can send your feedback on <a href="https://invertedpassion.com/cdn-cgi/l/email-protection#deaebfacbfadefe7e6e9f5b7aeb8bbbbbabcbfbdb59eb9b3bfb7b2f0bdb1b3">email</a> to me.


</p>



			</div><!-- .entry-content -->
						<!-- .entry-footer -->
		</article></div>]]>
            </description>
            <link>https://invertedpassion.com/three-levels-of-hindu-philosophy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817439</guid>
            <pubDate>Mon, 13 Jul 2020 05:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Butt Pomodoro – A butt triggered pomodoro timer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817401">thread link</a>) | @Abishek_Muthian
<br/>
July 12, 2020 | https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A need gap of <a href="https://needgap.com/problems/130-remind-me-to-take-break-when-working-from-home-wfh-activity" target="_blank">Remind me to take break when working from home</a> was recently posted. Forgetting to take regular breaks when immersed with work in front of a computer is a common problem, especially when working from home.</p><p>On the flip side, <a href="https://needgap.com/problems/30-getting-things-done-at-individual-level-productivity-taskmanagement" target="_blank">getting distracted from completing a task</a> is also a common problem.</p><h3 id="why-pomodoro">Why pomodoro?</h3><p><a href="https://en.wikipedia.org/wiki/Pomodoro_Technique" target="_blank">Pomodoro technique</a> is to work in 25 minutes intervals called pomodoro, taking 5 minutes break every pomodoro and taking a 30 minutes break after 4 pomodoros.</p><p>This helps in mitigating <a href="https://needgap.com/problems/93-focus-drift-cognitivescience-neuroscience" target="_blank">focus drift</a>, burn outs and enables us to complete our tasks.</p><h3 id="why-butt-triggered">Why butt triggered?</h3><p>There are no dearth of pomodoro timer based apps in the market, but they require manual trigger of the timer each time we are about to start a task, this is a huge overhead as stated by in the first problem statement.</p><p>I personally feel that the activity of constantly interacting with the pomodoro timer is counter-intuitive for productivity and so to address that it needs to be triggered seamlessly without any user action.</p><p>Most of us work with the computer while seated on a chair, I figured that triggering the pomodoro timer with a sensor under the seat would fulfil my goals.</p><h3 id="design-goals">Design goals</h3><h4 id="simple">Simple</h4><p>The solution should be simple enough to be easily reproducible by many, even by those without the technical know-how of the solution.</p><h4 id="portable">Portable</h4><p>Setup should be easily transportable to any chair, be it at home or office. Hence, facial recognition with machine learning based solution is not being considered.</p><h4 id="inexpensive">Inexpensive</h4><p>Components should be easily available and inexpensive.</p><h3 id="design-choices">Design choices</h3><h4 id="sensor">Sensor</h4><p>Sensor is needed to trigger the timer when I sit on the chair, basically to serve as a switch.</p><p>I started with a pressure sensor made with Velostat fabric, since its light weight and could seamlessly fit between the seat cushion and the chair. But the resistance varied too much in my test to serve as a reliable switch and I didn’t like the possibility conductive threads setting my ass on fire if they get shorted.</p><p><amp-accordion id="velostat-accordian" disable-session-states=""><section><h5>Click to see Velostat with Conductive Threads</h5><amp-img alt="Velostat with conductive thread" src="/images/Velostat_Conductive_Thread.jpg" width="3915" height="3813" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="trigger">Trigger</h4><p>Then I experimented with a standard 12mm momentary button switch on a 170 holes mini breadboard and it served the purpose well. Depending upon your chair, seat cushion and your weight; you might have to choose a button which works well for you.</p><p><amp-accordion id="button-accordian" disable-session-states=""><section><h5>Click to see Momentary Button</h5><amp-img alt="Button" src="/images/Momentary_Button.jpg" width="2863" height="3451" layout="responsive"></amp-img></section><section><h5>Click to see Mini Breadboard</h5><amp-img alt="Button" src="/images/Mini_Breadboard.jpg" width="1670" height="1365" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="microcontroller">Microcontroller</h4><p>Microcontroller is needed process the input signal from the button, compute the timers and send message to the notifications.</p><p>ESP8266 based NodeMCU is being used the microcontroller for this as it has WiFi for communication.</p><p><amp-accordion id="nodemcu-accordian" disable-session-states=""><section><h5>Click to see NodeMCU</h5><amp-img alt="NodeMCU" src="/images/ESP8266_NodeMCU.jpg" width="962" height="1451" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="power">Power</h4><p>I’m supplying 5V power over microUSB with 18650 power-bank to the NodeMCU.</p><p><amp-accordion id="powerbank-accordian" disable-session-states=""><section><h5>Click to see 18650 Power-Bank</h5><amp-img alt="18650 Power-Bank" src="/images/18650_Power-Bank.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><p><em>Note: The reliability of this power-bank is questionable as I’ve had failures, so I would suggest using a simple battery holder instead.</em></p><p><amp-accordion id="battery_holder-accordian" disable-session-states=""><section><h5>Click to see the setup with battery holder, terminals secured with solder, hot glue and tape</h5><amp-img alt="Butt Pomodoro with Battery Holder" src="/images/Butt_Pomodoro_Battery_Holder.jpg" width="3456" height="4608" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="computation">Computation</h4><p>My initial plan was to use the NodeMCU itself for computation as that’s what microcontrollers are used for, but stopping the timers at will was bit of a hassle with Arduino code on NodeMCU and decided to leverage the comfort of Go with <a href="https://gobot.io/documentation/platforms/esp8266/" target="_blank">Gobot</a> using Firmata firmware.</p><p>Gobot allows client-server architecture on IoT devices, so NodeMCU can be controlled remotely from a client. The main advantage of using Gobot is that it allows me to modify the code and test it without having to flash it on the NodeMCU each time. I’m running Gobot client on a Raspberry Pi 2 after flashing firmata server on NodeMCU.</p><p><em>Update: Starting and stopping timers with Gobot on NodeMCU within different Goroutines resulted in unnecessary race conditions, deadlocks hence I resorted to calculating elapsed time manually and simple flags to start the timers. I guess, this method could have been easily implemented directly on the NodeMCU with Arduino code, but due to other advantages of using Gobot I’m continuing with it.</em></p><h4 id="communication">Communication</h4><p>I’m using <a href="http://mqtt.org/" target="_blank">MQTT protocol</a> for communication between the devices. <a href="https://appcodelabs.com/introduction-to-iot-build-an-mqtt-server-using-raspberry-pi" target="_blank">A MQTT broker(server) runs on the Raspberry Pi</a> along with the Gobot client which acts as the MQTT publisher.</p><p><a href="https://play.google.com/store/apps/details?id=in.dc297.mqttclpro" target="_blank">MQTT Client android app</a> is the MQTT subscriber. <a href="https://play.google.com/store/apps/details?id=net.dinglisch.android.taskerm" target="_blank">Tasker android app</a> creates a notification when MQTT client receives the message, displays the notification via <a href="https://play.google.com/store/apps/details?id=com.joaomgcd.autonotification" target="_blank">Auto Notification Tasker plugin</a>(paid) and <a href="https://play.google.com/store/apps/details?id=com.rageconsulting.android.lightflow" target="_blank">Light Flow android app</a>(paid) reads out the notification message and creates custom LED light.</p><p>The notification is further received at my desktop smart clock, which is an old android wear smartwatch modified to receive latest Google Play services updates.</p><p><amp-accordion id="communication-accordian" disable-session-states=""><section><h5>Click to see MQTT Client</h5><amp-img alt="MQTT Client" src="/images/MQTT_Client.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Tasker profile</h5><amp-img alt="Tasker Profile" src="/images/Tasker-profile.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Notification Configuration</h5><amp-img alt="Auto Notification Configuration" src="/images/AutoNotification.jpg" width="1080" height="1920" layout="responsive"></amp-img></section><section><h5>Click to see Auto Light Flow Configuration</h5><amp-img alt="Light Flow Configuration" src="/images/LightFlow_configuration.jpg" width="1080" height="1920" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="circuit">Circuit</h4><p><amp-accordion id="circuit-accordian" disable-session-states=""><section><h5>Click to see the circuit diagram</h5><amp-img alt="Butt pomodoro circuit diagram" src="/images/Circuit.png" width="614" height="587" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="setup">Setup</h4><p>Here is the overview of the complete architecture and the setup.</p><p><amp-accordion id="architecture-accordian" disable-session-states=""><section><h5>Click to see the architecture diagram</h5><amp-img alt="Butt pomodoro architecture" src="/images/Butt_pomodoro_architecture.png" width="686" height="660" layout="responsive"></amp-img></section><section><h5>Click to see the Butt pomodoro setup</h5><amp-img alt="Butt pomodoro setup" src="/images/Butt_pomodoro_setup.jpg" width="6000" height="4000" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="code">Code</h4><p>Source code for the Gobot client is available over the <a href="https://github.com/heavyinfo/buttpomodoro" target="_blank">GitHub</a>.</p><h4 id="demo">Demo</h4><h5 id="demo-video-enable-audio">Demo Video (enable audio)</h5><p><amp-accordion id="demo_video-accordian" disable-session-states=""><section><h5>Click to see video from Twitter (Fast loading, requires loading of twitter script)</h5><amp-twitter width="375" height="472" layout="responsive" data-tweetid="1281998220118249472"></amp-twitter></section></amp-accordion></p><p><a href="https://abishekmuthian.com/videos/Butt-Pomodoro-Demo.mp4" target="_blank">Click to see video from local .mp4 source, Slow loading, Requires HTML5 video support</a></p><p><a href="https://abishekmuthian.com/videos/Butt_Pomodoro.webm" target="_blank">Click to see video from local .webm source, Slow loading, Requires HTML5 video support</a></p><h3 id="enhancements">Enhancements</h3><p>Further enhancements which could improve the usability of the Butt Pomodoro -</p><pre><code>* Using a PIR (Passive Infrared) sensor as a trigger for contact less butt detection.

* Using a Bluetooth LE based microcontoller to communicate directly with the smartphone for cutting down the separate compute module.

* Custom app record the data on completed pomodoros, incomplete pomodoros, breaks and displaying it with cool visualisations. Of course, for notifications as well.
</code></pre><p>Tweet to me <a href="https://twitter.com/heavyinfo" target="_blank">@heavyinfo</a>.</p><h3 id="business-plan">Business Plan</h3><p>Do you think Butt Pomodoro is something people want?</p><p>Would you like to build Butt Pomodoro as a commercial product? I have <a href="https://hitstartup.com/business-plans/" target="_blank">business plan at hitstartup</a> to help you get started.</p></div></div>]]>
            </description>
            <link>https://abishekmuthian.com/butt-pomodoro-a-butt-triggered-pomodoro-timer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817401</guid>
            <pubDate>Mon, 13 Jul 2020 05:17:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting audio code from C to rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817392">thread link</a>) | @est31
<br/>
July 12, 2020 | https://jneem.github.io/nnnoiseless/ | <a href="https://web.archive.org/web/*/https://jneem.github.io/nnnoiseless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    <time datetime="2020-07-12T00:00:00+00:00">July 12, 2020</time>
  </header>
<p>I ported a C library to rust last week, and it went pretty smoothly. This is
the story, and <a href="https://github.com/jneem/nnnoiseless">here</a> is the repo.</p>

<p>The library in question is <a href="https://github.com/xiph/rnnoise">RNNoise</a>, a
library for removing noise from audio. It works well, it runs fast, and best of
all it has no knobs that you need to tune. There’s even a <a href="https://github.com/RustAudio/rnnoise-c">rust
binding</a>.</p>

<p>So why bother porting it?
Well, I need to patch it so that it would compile with MSVC, but my PR went
unnoticed for a month. I thought about maintaining my own fork, but it’s been
more than 10 years since I last wrote anything in C or C++.
And that’s how I ended up porting RNNoise to rust. It probably wasn’t the most
efficient use of my time, but I had fun and learned something.</p>

<p>There’s a lot of information out there about porting C to rust, but the most
useful resource for me was the fantastic
<a href="https://github.com/carols10cents/rust-out-your-c-talk">talk</a> by Carol (Nichols
|| Goulding). It lays out a simple process for porting one function
at a time: first, you set up the cargo to compile as a static library and you
set up the C build system to link that static library into the C library
(see the slides for the relevant Makefile and Cargo.toml snippets).
Then you can port one function at time: the C code goes like this:</p>

<div><div><pre><code><span>+</span><span>extern</span> <span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>);</span>
<span>+</span><span>void</span> <span>__celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>-</span><span>void</span> <span>_celt_lpc</span><span>(</span><span>opus_val16</span> <span>*</span><span>_lpc</span><span>,</span> <span>const</span> <span>opus_val32</span> <span>*</span><span>ac</span><span>,</span> <span>int</span> <span>p</span><span>)</span>
<span>{</span>
    <span>/* C body of _celt_lpc */</span>
<span>}</span>
</code></pre></div></div>

<p>and the rust code goes like this:</p>

<div><div><pre><code><span>+</span><span>#[no_mangle]</span>
<span>+</span><span>pub</span> <span>extern</span> <span>"C"</span> <span>fn</span> <span>_</span><span>celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span> <span>ac</span><span>:</span> <span>*</span><span>const</span> <span>f32</span><span>,</span> <span>p</span><span>:</span> <span>c_int</span><span>)</span> <span>{</span>
<span>+</span>    <span>unsafe</span> <span>{</span>
<span>+</span>        <span>let</span> <span>lpc_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts_mut</span><span>(</span><span>lpc</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span><span>);</span>
<span>+</span>        <span>let</span> <span>ac_slice</span> <span>=</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>ac</span><span>,</span> <span>p</span> <span>as</span> <span>usize</span> <span>+</span> <span>1</span><span>);</span>
<span>+</span>        <span>rs_celt_lpc</span><span>(</span><span>lpc_slice</span><span>,</span> <span>ac_slice</span><span>);</span>
<span>+</span>    <span>}</span>
<span>+</span><span>}</span>
<span>+</span>
<span>+</span><span>fn</span> <span>rs_celt_lpc</span><span>(</span><span>lpc</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>],</span> <span>ac</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>])</span> <span>{</span>
<span>+</span><span>// rust body of celt_lpc</span>
<span>+</span><span>}</span>
</code></pre></div></div>

<p>If you’ve watched the talk (which you should), you might notice that this is a
tiny bit different from what they recommend: I’ve renamed the original C
function instead of deleting it. I found that this helped me narrow down porting
mistakes, because it made it easy to switch back and forth between the C and
rust implementations.</p>



<p>Most of the porting process was mechanical and easy. One of the less fun parts was
porting code involving C structs. RNNoise has structs that (when ported to
rust) look like this:</p>

<div><div><pre><code><span>#[repr(C)]</span>
<span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>*</span><span>const</span> <span>RnnModel</span><span>,</span>
    <span>// Various buffers, whose sizes are determined by some subfields of `model`.</span>
    <span>vad_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>*</span><span>mut</span> <span>f32</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>An idomatic rust version might look something like</p>
<div><div><pre><code><span>struct</span> <span>RnnState</span> <span>{</span>
    <span>model</span><span>:</span> <span>&amp;</span><span>'static</span> <span>RnnModel</span><span>,</span>
    <span>vad_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>noise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
    <span>denoise_gru_state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>
<p>but this isn’t layout-compatible with the original C version, and so I need to
stick with the original struct for as long as <code>RnnState</code> is being accessed by
both C and rust code. This increases the amount of <code>unsafe</code> sprinkled around
the rust code, and it was also the source of an annoying bug of the sort that I
thought I had left behind by moving to rust.</p>



<p>At some point during the porting process, my tests started failing in release mode,
but not in debug mode. Most likely some undefined behavior triggered by my amateurish
attempts at unsafe code, but I couldn’t quickly spot the problem and the prospect of
a more careful round of debugging didn’t spark a whole lot of joy. So I did something
that I never would have dared to do in my C/C++ days: I ignored the problem and kept
porting; after all, the tests were still working in debug mode. And sure enough,
a few more ported functions later and <code>rustc</code> found the problem for me: in a function
taking a <code>&amp;RnnState</code> parameter, I was modifying data in the <code>vad_gru_state</code> buffer.
Since I was using unsafe code, <code>rustc</code> didn’t complain at first. But once I ported
the <code>RnnState</code> struct to safe and idiomatic rust, the compiler flagged the problem
immediately.</p>



<p>After getting everything to 100% safe (if not particulary idiomatic) rust, it was time
to check whether performance had suffered.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark.svg" alt="initial benchmark"></p>

<p>Yes, apparently, by about 50%. The most obvious culprit was bounds checking: there was
a lot of indexing in the C code, and some of it wasn’t trivial to convert to a more
rust-friendly, iterator-based version. First priority was the neural network evaluation:</p>

<div><div><pre><code><span>let</span> <span>m</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 114.</span>
<span>let</span> <span>n</span> <span>=</span> <span>...</span><span>;</span> <span>// At most 96.</span>

<span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span><span>;</span>
    <span>for</span> <span>j</span> <span>in</span> <span>0</span><span>..</span><span>m</span> <span>{</span>
        <span>output</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>layer</span><span>.input_weights</span><span>[</span><span>j</span> <span>*</span> <span>n</span> <span>+</span> <span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>*</span> <span>input</span><span>[</span><span>j</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>I can already see you shaking your head. I’m doing naive matrix-vector multiplication
with a 100x100ish matrix in
<a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">column-major format</a>?
Not only is this costing me bounds checks, it’s terrible for memory locality.
Swapping the weights storage from column- to row-major order only made things
about 1.5% faster, but more importantly it made the whole thing iterator-friendly.
Converting to zips and sums bought another 15%, leaving me only about 25-30% slower
than the C code.</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>n</span> <span>{</span>
    <span>let</span> <span>output</span><span>[</span><span>i</span><span>]</span> <span>=</span>
        <span>layer</span><span>.bias</span><span>[</span><span>i</span><span>]</span> <span>as</span> <span>f32</span> <span>+</span> 
        <span>layer</span><span>.input_weights</span><span>[(</span><span>i</span> <span>*</span> <span>m</span><span>)</span><span>..</span><span>((</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>*</span> <span>m</span><span>)]</span>
            <span>.iter</span><span>()</span>
            <span>.zip</span><span>(</span><span>input</span><span>)</span>
            <span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span>
            <span>.sum</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>For my next optimization opportunity, I moved on to the function
that
computes <a href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlations</a>.
The un-optimized version of this function looks like</p>

<div><div><pre><code><span>fn</span> <span>pitch_xcorr</span><span>(</span><span>xs</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>ys</span><span>:</span> <span>&amp;</span><span>[</span><span>f32</span><span>],</span> <span>xcorr</span><span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>f32</span><span>])</span> <span>{</span>
    <span>for</span> <span>i</span> <span>in</span> <span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>()</span> <span>{</span>
        <span>xcorr</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>&amp;</span><span>ys</span><span>[</span><span>i</span><span>..</span><span>])</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>();</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>but the C code contained a massive, manually-unrolled version. I’d skipped
it while porting, but maybe I’d gain something from porting it over. Here’s
an abbreviated version of the optimized function, assuming that all
lengths are a multiple of 4 (the real code also handles the case that they aren’t).</p>

<div><div><pre><code><span>for</span> <span>i</span> <span>in</span> <span>(</span><span>0</span><span>..</span><span>xcorr</span><span>.len</span><span>())</span><span>.step_by</span><span>(</span><span>4</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>c0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>c3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>let</span> <span>mut</span> <span>y0</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>0</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y1</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y2</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>2</span><span>];</span>
    <span>let</span> <span>mut</span> <span>y3</span> <span>=</span> <span>ys</span><span>[</span><span>i</span> <span>+</span> <span>3</span><span>];</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>[(</span><span>i</span> <span>+</span> <span>4</span><span>)</span><span>..</span><span>]</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>

        <span>y0</span> <span>=</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>

        <span>y1</span> <span>=</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>

        <span>y2</span> <span>=</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>c0</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y3</span><span>;</span>
        <span>c1</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y0</span><span>;</span>
        <span>c2</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y1</span><span>;</span>
        <span>c3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y2</span><span>;</span>

        <span>y3</span> <span>=</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Basically, both inner and outer loops have been unrolled four times, and I’ve
exploited the inner loop’s unrolling to optimize the memory access pattern.
Thanks to the amazing <a href="https://github.com/gnzlbg/cargo-asm"><code>cargo asm</code></a>, I
can happily report that there’s no bounds-checking in the inner loop and that
all the arithmetic has been <a href="https://en.wikipedia.org/wiki/Automatic_vectorization">auto-vectorized</a>
to work four <code>f32</code>s at a time. (Maybe it would get even faster if I unrolled 8 times and
compiled with AVX enabled; I haven’t tried that yet.)</p>

<p>This change more than doubled the speed of <code>pitch_xcorr</code>, and gained me about 10% overall.
More importantly, it showed me how to coerce the compiler into auto-vectorizing something
that it hadn’t auto-vectorized before. I went back to the neural network code and
replaced things like</p>

<div><div><pre><code><span>xs</span><span>.iter</span><span>()</span><span>.zip</span><span>(</span><span>ys</span><span>)</span><span>.map</span><span>(|(</span><span>&amp;</span><span>x</span><span>,</span> <span>&amp;</span><span>y</span><span>)|</span> <span>x</span> <span>as</span> <span>f32</span> <span>*</span> <span>y</span><span>)</span><span>.sum</span><span>()</span>
</code></pre></div></div>

<p>with things like</p>

<div><div><pre><code><span>{</span>
    <span>let</span> <span>mut</span> <span>sum0</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum1</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum2</span> <span>=</span> <span>0.0</span><span>;</span>
    <span>let</span> <span>mut</span> <span>sum3</span> <span>=</span> <span>0.0</span><span>;</span>

    <span>for</span> <span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span> <span>in</span> <span>xs</span><span>.chunks_exact</span><span>(</span><span>4</span><span>)</span><span>.zip</span><span>(</span><span>ys</span><span>.chunks_exact</span><span>(</span><span>4</span><span>))</span> <span>{</span>
        <span>sum0</span> <span>+=</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>0</span><span>];</span>
        <span>sum1</span> <span>+=</span> <span>x</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>1</span><span>];</span>
        <span>sum2</span> <span>+=</span> <span>x</span><span>[</span><span>2</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>2</span><span>];</span>
        <span>sum3</span> <span>+=</span> <span>x</span><span>[</span><span>3</span><span>]</span> <span>*</span> <span>y</span><span>[</span><span>3</span><span>];</span>
    <span>}</span>
    <span>sum0</span> <span>+</span> <span>sum1</span> <span>+</span> <span>sum2</span> <span>+</span> <span>sum3</span>
<span>}</span>
</code></pre></div></div>

<p>for another 20% improvement.</p>

<p>Current score: the rust version (still 100% safe) is about 15% faster, and there’s probably plenty more
still on the table.</p>

<p><img src="https://jneem.github.io/images/ported_benchmark_after.svg" alt="final benchmark"></p>

<p>The performance lesson I learned from this is that bounds checking can be expensive in numerical code
and iterator-style code can help a bit, but if you really want faster numerical code then you need
to write in a style that the auto-vectorizer likes. (Or you could use the <a href="https://doc.rust-lang.org/core/arch/index.html">SIMD intrinsics</a>
directly, but that’s another story.)</p>



<p>Like I wrote above, it’s been a while since I did any C/C++, and because of that I’ve started to take tools
like cargo for granted. This little porting project brought back some memories, mostly because about half of the
code in RNNoise was actually “vendored” from <a href="https://gitlab.xiph.org/xiph/opus">opus</a>. I put “vendored”
in quotes because I usually think of vendoring as involving a subdirectory (maybe even a git submodule if
I’m lucky) with its own build artifacts. That’s not what’s going on here, though; I’m just talking about files
that were copied from the source directory of one project to the source directory of another, complete with
never-used functions and never-def’ed ifdefs. The thing is, though, that I understand exactly why they did it:
it’s by far the easiest way to share code between C projects. So I just want to finish by saying a big “thank you”
to <code>cargo</code> and <code>crates.io</code> for making me not have to deal with C dependency management any more.</p>


  
  
</article></div>]]>
            </description>
            <link>https://jneem.github.io/nnnoiseless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817392</guid>
            <pubDate>Mon, 13 Jul 2020 05:14:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Artificial Neural Networks Closer to Animal Brains]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23817347">thread link</a>) | @hardmaru
<br/>
July 12, 2020 | https://maraoz.com/2020/07/12/brains-vs-anns/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/12/brains-vs-anns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p><img src="https://maraoz.com/img/brains-vs-anns/cover.jpg"></p>

<p>Lately, I’ve been thinking and reading a lot about consciousness and how the human mind works. A question that emerges all the time is whether machines can <a href="https://en.wikipedia.org/wiki/Turing_test">emulate human thought</a>. An even more interesting one is whether consciousness (a subjective experience) can arise from a machine, but I’ll leave that discussion for a future post (I’ll need ~20 more years to think about that before I can write about it).</p>

<p>So, how far are we from _behaviorally _imitating a human? Truth is, we achieved a lot in the past 5 years (see <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a>, <a href="https://openai.com/blog/better-language-models/">OpenGPT-2</a>, <a href="https://openai.com/blog/jukebox/">OpenAI Jukebox</a>, <a href="https://en.wikipedia.org/wiki/Tesla_Autopilot">Tesla Autopilot</a>, <a href="https://deepmind.com/blog/article/AlphaStar-Grandmaster-level-in-StarCraft-II-using-multi-agent-reinforcement-learning">Alphastar</a>, <a href="https://openai.com/blog/openai-five-defeats-dota-2-world-champions/">OpenAI Dota2 Team</a>, <a href="https://openai.com/blog/openai-api/">OpenAI API</a>), but we’re still quite not there. My hunch is that we still can learn a lot from biology’s state of the art. I’ve done some research on differences in how human brains work and how we emulate them using deep neural networks, and what follows is a summary of what I’ve found (and some new ideas).</p>

<figure>
  <img src="https://maraoz.com/img/brains-vs-anns/image1.png">
  <figcaption>
    I find it encouraging that John Carmack is studying human brains for his AI research. <a href="https://twitter.com/ID_AA_Carmack/status/1280693213549002752">Source</a>.
  </figcaption>
</figure>

<h2 id="morphology">Morphology</h2>

<p>The most surprising difference between artificial and human brains is how <em>sequential</em> our artificial neural networks (ANN) are, compared to the richly interconnected biological counterparts.</p>

<p>I’m always amazed by the sheer amount of layers that are stacked on top of each other <a href="https://jalammar.github.io/illustrated-gpt2/">in the latest deep learning models</a>. The largest GPT-3 model (with 175B parameters) uses 96 attention layers, each with 96x 128-dimension heads. <a href="https://arxiv.org/pdf/2005.14165.pdf">Their paper</a> shows that language model performance scales as a power-law with model size.</p>

<p>However, this assumes the size of the network can only increase by adding more layers, making it “deeper”. Using layers enables for great performance in training via <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/">backpropagation/ADAM</a>, but I think the current mostly-sequential approach to scaling ANNs is limiting. Some ideas:</p>

<h3 id="wide-vs-deep-neural-networks">Wide (vs. Deep) Neural Networks</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image8.png">
<img src="https://maraoz.com/img/brains-vs-anns/image3.png"></p>

<p>A promising approach is exploring other kinds of architectures, where the concept of “layer” is forgotten, and networks are built more freely (with connections being modelled at the neuron level, and allowing for loops and more complex topologies). This <a href="https://en.wikipedia.org/wiki/Boltzmann_machine">has been somewhat explored in the past</a>, but I haven’t seen recent studies where today’s computing power is thrown at such architectures. Additionally, <a href="https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies">Ken Stanley’s NEAT (2002)</a> and derivatives are a very promising way of finding new topologies via evolution.</p>

<h3 id="neural-grids">Neural Grids</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image6.png"></p>

<p>Another idea worth exploring: grid-like structures where each cell communicates only with its neighbors. In this neural net model, potential is not only passed forward, but also “upward” and “downward”, or even diagonally. This would emulate more closely, I think, a real brain’s connectivity. A related approach is <a href="https://www.mitpressjournals.org/doi/abs/10.1162/artl.2009.15.2.15202">Hypercube-based NEAT (2009)</a>, which allows exploiting the task’s geometry by mapping its regularities onto the topology of the network.</p>

<h3 id="artificial-cortical-columns">Artificial Cortical Columns</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image9.png">
<img src="https://maraoz.com/img/brains-vs-anns/image5.png"></p>

<p>Human’s brain neocortex seems to have a surprisingly self-repeating pattern, called <a href="https://youtu.be/x2mYTaJPVnc?t=98">cortical columns</a>. Each column can be thought of as a reusable ~110 neuron module that appears (with variations) across neocortex areas associated with such different functions as vision, motor control, auditory perception, decision-making, planning, etc. <a href="https://numenta.com/neuroscience-research/cortical-columns/">Studying these structures</a> and applying similar concepts/topologies to ANNs seems like a promising approach. Cortical columns provide amazingly generic hierarchical information processing capabilities, feedback mechanisms, and layered communication with other parts of the brain.</p>

<h3 id="generative-architectures-arising-from-growth">Generative architectures arising from growth</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image10.png"></p>

<p>What if neural net architecture is determined by a generative / procedural algorithm on runtime, instead of being defined by researchers? The seed could be random or evolved through genetic algorithms too. I think that somehow mimicking <a href="https://www.youtube.com/watch?v=BtLyik7oAxc&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=4">neurulation of human embryos</a> via simple models could lead to finding better-performing architectures. Human brains grow into existence, and maybe that matters for high-level intelligence.</p>

<h2 id="function">Function</h2>

<h3 id="evolve-first-learn-later">Evolve first, Learn later.</h3>

<p>Some techniques use <a href="https://www.nature.com/articles/s42256-018-0006-z">neuroevolution used to automate network design</a> or <a href="https://blog.otoro.net/2017/11/12/evolving-stable-strategies/">evolutionary strategies finding network weights instead of gradient descent</a>. It’d be interesting to see hybrid approaches where network structure is evolved and <em>later</em> allowed to learn in an environment (like humans!). Additionally, as I learnt from <a href="https://www.nature.com/articles/s41467-019-11786-6">this fascinating paper by Tony Zador</a> (2019), “A large component of an animal’s behavioral repertoire is not the result of supervised or unsupervised learning, but rather of behavior programs already present at birth”. Learning is actually one of such behaviors, so… shouldn’t researchers be focusing more on optimizing the lower-level mechanism of evolution instead of polishing our “hand-crafted” learning algorithms and architectures?</p>

<p>On a similar ‘meta-learning’ vein, the comically named <a href="http://papers.nips.cc/paper/6461-learning-to-learn-by-gradient-descent-by-gradient-descent.pdf">Learning to learn by gradient descent by gradient descent</a> (2016) paper shows that you can train a network to optimize other networks, and they perform better than hand-crafted learning algorithms like <a href="https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c">ADAM</a> and <a href="https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a">RMSProp</a>.</p>

<h3 id="continuous-vs-discrete-neuron-firing">Continuous (vs. discrete) neuron firing</h3>

<p><img src="https://maraoz.com/img/brains-vs-anns/image4.png"></p>

<p>Instead of processing inputs in discrete events, our networks could ‘stare’ at inputs for a couple iterations, and neurons can ‘store-up’ potential until they fire. This aims to mimic how we humans can look at something we don’t understand, but after a couple of seconds we “get it”. This could also enable the emergence of “memories” in the form of stored potential, too, analogous to the hidden state vector of LSTMs. Check out <a href="https://www.youtube.com/watch?v=lddzHEtu934">Gabriel Kreiman’s related work (2018)</a> on improving object detection in occluded or distorted conditions. Regardless of the specific implementations mentioned above, biological brains clearly have a temporal dimension (for example, <a href="https://www.youtube.com/watch?v=aFrG7KdjUOs&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=32">neurons in the visual motion MT area respond to direction of motion</a>), which we need to understand better to inform construction of artificial ones. Another interesting time-related property of biological brains is <a href="https://youtu.be/fki7AmLma_I?t=450">the difference between tonic vs bursting modes of neuron firing</a>.</p>

<h3 id="connecting-functional-building-blocks">Connecting functional building blocks</h3>

<p>Animal brains are surprisingly pre-wired and connected since birth, and it’s still not clear in general which behaviors are learned through experience and which are innate. Moreover, a big field of study in neuroscience is understanding how the human brain is wired, mostly via <a href="https://en.wikipedia.org/wiki/Tractography">diffusion tractography</a>, and in some cases <a href="https://youtu.be/KFfaBoDANNI?t=134">it’s been shown that connectivity can predict function</a>. However, the fascinating <a href="https://www.youtube.com/watch?v=8Bvblav-BQk&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0&amp;index=65">‘rewired ferrets’ experiments</a> showed that training input also conditions function strongly (newborn ferrets with auditory cortex rewired to receive visual input still learn to see). This implies that animal brains have a very optimized initial configuration, but also the flexibility to adapt to structural damages or drastical environmental condition changes.</p>

<p>Many well-performing techniques simply stack two architectures that work for two separate domains (eg: CNN visual embedder and LSTM language model) and re-train them for a new combined task (eg: image captioning).</p>

<p><img src="https://maraoz.com/img/brains-vs-anns/image7.png">
<img src="https://maraoz.com/img/brains-vs-anns/image2.png"></p>

<p>I suggest trying to mimic what we know today of how the human brain is wired (from <a href="http://www.humanconnectomeproject.org/">the Human Connectome Project</a>, for example), and plugging in some state-of-the-art modules for vision, language, and audio-processing.</p>

<h3 id="slow-and-data-light-learning">Slow and Data-Light Learning</h3>

<p>Humans seem to learn slowly (in real time, it takes a human ~2 years to learn a language at a basic level, and ~18 years to learn advanced level language usage or complex language tasks like translation) but with few examples. Machines, on the other hand, learn very fast (in the order of weeks to achieve state of the art in some tasks) but are very data-hungry. Some techniques require less training data but might take longer to train, like <a href="https://medium.com/@SmartLabAI/a-brief-overview-of-imitation-learning-8a8a75c44a9c">Imitation Learning</a>, <a href="https://openai.com/blog/competitive-self-play/">Competitive Self-Play</a>, and <a href="https://arxiv.org/abs/2005.11212">Symbolic Pregressions (2020)</a> and could be key to getting closer to human intelligence.</p>

<h3 id="intermixing-learning-techniques">Intermixing Learning Techniques</h3>

<p>A combination of learning strategies could be necessary for human-level intelligence, as Yann LeCun suggests with his cake analogy: “If intelligence is a cake, the bulk of the cake is <a href="https://ai.stackexchange.com/a/10624">self-supervised learning</a>, the icing on the cake is <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, and the cherry on the cake is <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>.”</p>

<p>Humans train by learning from others (supervised learning) <em>and</em> experimenting on our own (unsupervised/self-supervised learning). For example, a chess student first talks to a teacher, then plays some games. They wouldn’t go to a chess tournament after just talking to a teacher or playing games alone. Can we combine/emulate these kinds of training efficiently in ML too?</p>

<h2 id="final-words--further-studying">Final words &amp; further studying</h2>

<p>What do you think of these approaches? Have you actually seen any of these used in the wild (with success or otherwise)? Which do you think may have merits? Let me know if you do some experiments to try them out.</p>

<p>If you’ve been intrigued by the potential of imitating biological brains, here are some up-to-date resources to dig deeper, in order of relevance:</p>

<ul>
  <li><a href="https://www.youtube.com/watch?v=i1pdQjdAndc&amp;list=PLyGKBDfnk-iAQx4Kw9JeVqspbg77sfAK0">Nancy Kanwisher’s The Human Brain course on YouTube</a> (2018)</li>
  <li><a href="https://www.youtube.com/watch?v=8-KF0rnhKTU&amp;list=PLTF9h-T1TcJjUxgs0dqyDCaS-glauXcsL&amp;index=2">Ninja Nerd Lectures on Embryology</a> (2019)</li>
  <li><a href="https://www.nature.com/articles/s41467-019-11786-6">A critique of pure learning and what artificial neural networks can learn from animal brains by Anthony M. Zador</a> (2019)</li>
  <li><a href="https://www.youtube.com/watch?v=pkJkHB_c3nA">AI for physics &amp; physics for AI by Max Tegmark</a> (2020)</li>
  <li><a href="https://www.youtube.com/watch?v=x2mYTaJPVnc">Brains Explained video on cortical columns</a> (2017)</li>
  <li><a href="https://www.youtube.com/watch?v=h0InlY2WKc0">Deciphering Brain Codes to Build Smarter AI by Gabriel Kreiman</a> (2020)</li>
</ul>

<p><em>Thanks to Javi Silveira, <a href="https://twitter.com/hardmaru">David Ha (@hardmaru)</a>, <a href="https://twitter.com/alcuadrado">Pato Palladino (@alcuadrado)</a> and <a href="https://twitter.com/itsladywhite">Lady White (@itsladywhite)</a> for providing feedback and pointers.</em></p>

<p><em>Image by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">David Clode on Unsplash</a>.</em></p>


  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/12/brains-vs-anns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817347</guid>
            <pubDate>Mon, 13 Jul 2020 05:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Silicon Valley Translated in the Wizard of Oz]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817205">thread link</a>) | @billybjork
<br/>
July 12, 2020 | https://www.home.vujade.world/dream | <a href="https://web.archive.org/web/*/https://www.home.vujade.world/dream">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="SITE_ROOT" aria-hidden="false"><div id="masterPage" data-mesh-layout="grid"><main tabindex="-1" data-is-mobile="false" data-is-mesh="true" data-site-width="980" data-state="" id="PAGES_CONTAINER"><div id="PAGES_CONTAINERcenteredContent"><div id="PAGES_CONTAINERinlineContent"><div><div data-ismobile="false" data-is-mesh-layout="true" id="fhyds"><div id="fhydsinlineContent"><div id="fhydsinlineContent-gridWrapper" data-mesh-internal="true"><div id="fhydsinlineContent-gridContainer" data-mesh-internal="true"><p data-packed="false" data-vertical-text="false" data-min-height="64" data-hidden="true" id="comp-kcku3nqo"><h3><span><span><span><span>&nbsp;DATA RULES EVERYTHING AROUND ME&nbsp;</span></span></span></span></h3></p><div data-packed="true" data-vertical-text="false" data-hidden="true" id="comp-kbfvr8s7"><p><span><span>We’re not in Kansas anymore.</span></span></p>



<p><span><span>Swept along by the cyclone of innovation, we’ve stumbled into the "information superhighway." At first it appeared we’d found a beautiful land, somewhere over the rainbow. But it's becoming clear our Emerald City isn’t all it was cracked up to be. In this remix film based on The Wizard of Oz, we journey alongside Dorothy down the Yellow Brick Algorithm, decoding the myths surrounding digital culture. DREAM speaks about the media, through the media – finding clarity in a digital space that’s never been so noisy.</span></span></p></div><div data-packed="false" data-vertical-text="false" data-min-height="61" data-hidden="true" id="comp-k9lpk92t"><h5><span><span>FEATURING</span></span></h5>

<p><span><span>The Wizard of Oz</span></span></p>

<p><span><span>Duckwrth&nbsp; &nbsp;The Talking Heads&nbsp; &nbsp;Lou Reed</span></span></p>

<p><span><span>Rod Serling&nbsp; &nbsp;Marshall McLuhan&nbsp; &nbsp;Neil Postman&nbsp; &nbsp;John Perry Barlow</span></span></p>

<p><span><span>Jaron Lanier&nbsp; &nbsp;Douglas Rushkoff&nbsp; &nbsp;Astra Taylor&nbsp; &nbsp;Yosemitebear62&nbsp; &nbsp;Beeple</span></span></p>

<p><span><span>Gary Vee&nbsp; &nbsp;Donald Trump&nbsp; &nbsp;Mark Zuckerberg&nbsp; &nbsp;Bill Gates&nbsp; &nbsp;Alex Jones</span></span></p>

<p><span>PewDiePie&nbsp; &nbsp;Casey Neistat&nbsp; &nbsp;Pepe the Frog&nbsp; &nbsp;Oliver Tree&nbsp; &nbsp;Joe Hollier</span></p>

<p><span><span>And many more</span></span></p></div><p data-packed="false" data-vertical-text="false" data-min-height="61" data-hidden="true" id="comp-ka8xwtkq"><h5><span><span>PROCESS REEL</span></span></h5></p><p data-packed="false" data-vertical-text="false" data-min-height="61" data-hidden="true" id="comp-ka8xy3f6"><h5><span><span>TRAILER</span></span></h5></p><p data-packed="false" data-vertical-text="false" data-min-height="61" data-hidden="true" id="comp-ka8xzfwq"><h5><span><span>SOURCES</span></span></h5></p></div></div></div></div></div></div></div></main></div></div></div>]]>
            </description>
            <link>https://www.home.vujade.world/dream</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817205</guid>
            <pubDate>Mon, 13 Jul 2020 04:34:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$15 HDMI Capture Card Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23817119">thread link</a>) | @rubatuga
<br/>
July 12, 2020 | https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><br>
<video src="https://www.naut.ca/videos/smash60fps.mp4" poster="https://www.naut.ca/videos/smash60fps.jpg" preload="none" controls="" playsinline=""></video>

<p>Above is a sample of 60fps Super Smash Bros Ultimate gameplay (I'm a Jigglypuff main) recorded with the $15 HDMI Capture Card and OBS. This card has been making the rounds last month on <a href="https://twitter.com/Ascii211/status/1268631069051453448">Twitter</a>, as well as on <a href="https://www.youtube.com/watch?v=daS5RHVAl2U">YouTube</a>, mainly due to its low, low price of $15 USD. I've decided to get one myself and take a look. The chipset contained in the card is the MacroSilicon MS2109. Here is the review, as well as a discussion of the potential use-cases.</p>
<h3 id="operatingsystem">Operating System</h3>
<p>This card, surprisingly enough, works on Windows, macOS and Linux! This is because it implements the UVC standard, a USB device that is OS agnostic. Getting it working on Linux is a bit of a hassle, but you can find out how <a href="https://bigl.es/friday-fun-10-hdmi-to-usb-capture/">here</a>.</p>
<p>I noticed that using the capture card on Linux or macOS resulted in significantly more framedrops and synchronization issues, when compared to Windows (although the macOS issues might be due to weak CPU). If you are okay with slightly choppy or stuttery recordings, then feel free to use the card on macOS or Linux. The Windows UVC driver captures more frames, and has the most options of the three. Most of the guide will be focusing on the Windows driver. The controls that are listed in OBS for each operating system are shown below.<br>
<img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-7.13.22-PM.jpg" alt="Screen-Shot-2020-07-09-at-7.13.22-PM"></p>
<h3 id="yuy2vsmjpeg">YUY2 vs MJPEG</h3>
<p>Windows and Linux both support the YUY2 and MJPEG video format, while macOS only supports MJPEG. YUY2 in this context refers to an almost uncompressed form of data (except for colour information), while MJPEG uses lossy JPEG compression on every frame. This means that YUY2 provides a cleaner image with no compression artifacts, while MJPEG has a noisier and blockier image. Compare the two capture formats below:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.33.23-AM.png" alt="Screen-Shot-2020-07-09-at-12.33.23-AM"></p>
<p>As you can see MJPEG has degraded the image data, which is necessary to compress each frame to a small size. Only MJPEG can achieve high framerates with this card because the interface it uses, USB 2.0, caps out around 50 MB/s. For reference, a YUY2 1280x720 60fps signal would exceed 100 MB/s. If you want a card that supports a 60fps YUY2 signal, you can expect to pay in the range of hundreds of dollars.</p>
<p>Both the YUY2 and MJPEG video formats from this card use something called <a href="https://en.wikipedia.org/wiki/Chroma_subsampling">chroma subsampling</a>, a data saving trick that takes advantage of the human eye's decreased colour resolution. It essentially deletes colour data, while keeping brightness data intact. I tested both formats, and they are outputting a 4:2:2 signal (50% of the colour data is deleted). You can see that the horizontal axis changes colour at 2 pixel boundaries, while the vertical axis changes at 1 pixel boundaries.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-12.32.56-AM.png" alt="Screen-Shot-2020-07-09-at-12.32.56-AM"></p>
<h3 id="resolutionandframerate">Resolution and Framerate</h3>
<p>A wide variety of resolutions and framerates are supported on the input side of the device. It even supports input at 4K 60fps! From the NVIDIA Control Panel, here is an abridged list of the resolutions and framerates supported on the <strong>input side</strong>:</p>
<pre><code>4K    60,59,50,30,29,25,24,23Hz
1080p 60,59,50Hz
720p  60,59,50Hz
576p  50Hz
480p  60,59Hz
PC    60Hz
</code></pre>
<p>To clarify, just because this card can accept or capture a 4K signal, does not mean that it can send the full signal to your computer. This card contains a scaler, which scales the image down (or up, depending on the input) in resolution before it is sent. With reference to the OBS properties window, here is an abridged list of the resolutions and max framerates as seen by my Windows PC:</p>
<pre><code>1920x1080 MJPEG:30fps, YUY2:5fps
1600x1200 MJPEG:30fps, YUY2:5fps
1360x768  MJPEG:30fps, YUY2:?
1280x960  MJPEG:50fps, YUY2:?
1280x720  MJPEG:60fps, YUY2:10fps
1024x768  MJPEG:60fps, YUY2:10fps
800x600   MJPEG:60fps, YUY2:20fps
720x480   MJPEG:60fps, YUY2:30fps
</code></pre>
<p>Each resolution dictates a maximum framerate for the device, limited by the bandwidth of the USB interface. To summarize, this card supports an output of 1920x1080 30fps and 1280x720 60fps with the MJPEG format.</p>
<h3 id="resolutionandframeratecaveats">Resolution and Framerate Caveats</h3>
<p>First I'll talk about framerate. I noticed that recording or streaming from the card at 60fps tends to repeat or skip a frame every few seconds, even with buffering on. Make sure to keep buffering on, otherwise you will lose frames at 30fps as well. I have confirmed this by recording videos in OBS and analyzing them frame by frame.</p>
<p>If you want virtually perfect frame capture at both 720p and 1080p, you should use 30fps with buffering!</p>
<p>Also, you may notice that there are 29.97fps and 59.94fps options in OBS. Only use these if you are absolutely sure that your device needs these values. You will likely run into desynchronization issues if you accidentally use these framerates.</p>
<p>Next, when I tested the 1920x1080 capture, I was shocked by how blurry it was. It turns out that this card doesn't actually do true 1080p! Here's a screenshot of Wikipedia, compared to what was captured at 1920x1080.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-2.48.49-AM.png" alt="Screen-Shot-2020-07-09-at-2.48.49-AM"></p>
<p>It looks like the card is capturing the vertical resolution fine, but the horizontal resolution is a soft mess. I tried out 1280x720, and everything looked crisp and fine, leading me to suspect that the card was capturing internally at a resolution of 1280 columns. I ended up using display calibration images from <a href="http://www.lagom.nl/lcd-test/sharpness.php">Lagom LCD</a> to see how the pixels in the capture were behaving. Right click the following image and choose Open/View Image for a better view.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-3.05.56-AM.png" alt="Screen-Shot-2020-07-09-at-3.05.56-AM"></p>
<p>Using the reference on the left, we can see that 1280x720 has correct vertical and horizontal resolution. 1360x768 and 1920x1080 also have correct vertical resolution, but the columns are turning grey. This is because adjacent white and black pixels from the high input resolution are merged into a lower resolution, i.e. from 1920 columns into 1280 columns. If you also noticed that pixel columns are brighter than the rows, I will be talking about that in the next section.</p>
<p>As a quick aside, everything above was for progressive video input. Interestingly, this card also supports an input of 1080i/interlaced video, which I tested with macOS and my Canon 600D camera. Using 1080i was absolutely horrible for desktop recording, since the card uses a brainless deinterlacing algorithm that halves the vertical resolution to 540. Yes, it actually looks that bad. As for my camera, it was decent, but the edges were kind of funny.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.01.51-AM.png" alt="Screen-Shot-2020-07-09-at-5.01.51-AM"></p>
<h3 id="imageaccuracycaveats">Image Accuracy Caveats</h3>
<p>This card needs "Color Range" set to "Full" in the OBS Capture Card Properties. Any devices that are connected to the card input need to have their HDMI "Range" set to "Limited". This is the only correct combination, otherwise highlights and shadows in the video are clipped. The following shows the effects of the device range options.</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.53.19-PM.png" alt="Screen-Shot-2020-07-09-at-5.53.19-PM"></p>
<p>As you might have noticed from the previous section, the 1280x720 capture is brightening the columns. This indicates that the card is performing image sharpening only in the horizontal direction. You can find evidence of this type of sharpening wherever there are sharp edges:</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.21.58-AM.png" alt="Screen-Shot-2020-07-09-at-5.21.58-AM"></p>
<p>This is a bad feature, as all image sharpening should be done after the capture. Fortunately, there is a way to get around this for 1280x720 content. Simply set your device to 1280x720, and then capture at 1920x1080. The image loses some clarity in brightness changes, due to the unnecessary resize, but all the sharpening has disappeared! Furthermore, since we are receiving 1920x1080 data, we now have better colour resolution as well, close to 4:3:3 chroma subsampling.</p>
<p>The 1920x1080 MJPEG capture also has significantly less compression artifacts than the 1280x720 MJPEG capture, which is probably due to different framerate support. From the image below, you can see that the 1080p capture is the winner all around (sharpening was applied post-capture for comparison with 720p).</p>
<p><img src="https://www.naut.ca/blog/content/images/2020/07/Screen-Shot-2020-07-09-at-5.25.44-PM.png" alt="Screen-Shot-2020-07-09-at-5.25.44-PM"></p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>
<p>If you are capturing slower gameplay, i.e. only 30fps, set your device to 1920x1080 and then capture at 1920x1080. This provides the most brightness and colour resolution at 30fps.</p>
</li>
<li>
<p>If you have 1280x720 content, capture at 1920x1080. This will result in the least amount of sharpening and MJPEG artifacts.</p>
</li>
<li>
<p>If you are capturing a desktop screen or anything with thin lines and pixels, then set your device to 1280x720 and then capture at 1280x720.</p>
</li>
<li>
<p>If you need 60fps content, i.e. for gaming, then set your device to 1920x1080 and then capture at 1280x720. This disables sharpening. The sample at the beginning of the article was encoded with "x264" at the "veryfast" setting.</p>
</li>
</ul>
<p>Warning: if you see a listing for a $20 USD capture card that claims to support USB 3.0 and 1080p 60fps, it's a scam. I've already bought two of them from Amazon and eBay, and had to return both because they turned out to be a repackaging of the product I just reviewed!</p>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/07/09/cheap-hdmi-capture-card-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23817119</guid>
            <pubDate>Mon, 13 Jul 2020 04:18:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 in schoolchildren – A comparison between Finland and Sweden [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 93 (<a href="https://news.ycombinator.com/item?id=23816709">thread link</a>) | @mrfusion
<br/>
July 12, 2020 | https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf | <a href="https://web.archive.org/web/*/https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.folkhalsomyndigheten.se/contentassets/c1b78bffbfde4a7899eb0d8ffdb57b09/covid-19-school-aged-children.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816709</guid>
            <pubDate>Mon, 13 Jul 2020 02:50:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Features are a better abstraction than issues]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816682">thread link</a>) | @gauthamshankar
<br/>
July 12, 2020 | https://zepel.io/blog/how-issue-tracking-hurts-development/ | <a href="https://web.archive.org/web/*/https://zepel.io/blog/how-issue-tracking-hurts-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>The short answer is yes. Let me explain.</p><p>I’ve been working with developers and designers my entire life. </p><p>I’ve built a couple of products, worked at a young startup, and I’m now at Zepel helping development teams build better software.</p><p>I’ve spoken to 1000+ development teams while at Zepel alone. <strong>And it's evident that the way we build products is broken.</strong></p><p>There’s so much disconnect between how you and I talk about building products and how our teams actually build them.</p><p>For all the talk of scrum and agile and getting feedback quickly, there’s so much that’s broken in how we act on the feedback and build the feature.</p><p>Teams spend so much time and effort getting a deeper understanding of customers’ needs. And yet distil everything down to a simple two-line ticket and a couple of lines of markdown description.</p><p>This is hurting your developers. And it’s hurting your business.</p><blockquote>Nothing is more frustrating than having to understand what an entire feature should or shouldn’t do from a two-line ticket filled with ten bullet points of acceptance criteria.</blockquote><p><em>*Here are five prioritized tickets for the upcoming sprint. We have to ship them on time!*</em></p><p>On the other hand, you have teams who are able to build top quality software. They’re the ones who can concentrate on the fine implementation details without losing focus on the broader purpose of the feature as a whole.</p><p>Everyone wants to get to that level. But instead, teams do the exact opposite.</p><p><strong>Teams think in issues and tickets, instead of the feature as a system.</strong></p><hr><h2 id="development-teams-are-not-ticket-movers-">Development teams are not ticket movers!</h2><p>Today, everything is about moving a ticket from “Todo” to “Done” as quick as possible. And watching <a href="https://zepel.io/agile/reports/burndown/">burndown charts</a>. And customizing the tool to the extent that the developer only views a single ticket.</p><p><em>*“What’s the velocity of our team?” is simply another way of asking how quickly can my team move an issue from “Todo” to “Done”.*</em></p><p>Pieces of that stuff are important for productivity and shipping on time.</p><p>But seriously, how is your team supposed to ship anything of value if you narrow their focus down to the smallest unit of work without any context of why it’s needed or how it connects to the whole feature?!</p><p>Overall, we’ve lost our way. Product development today has become more about checking items off a list as quickly as possible. </p><p><strong>It isn’t enough to write multiple user stories and share a Figma link if you want to ship quality software.</strong></p><hr><h2 id="how-software-product-teams-really-build-software-together">How software product teams really build software together</h2><p>Development teams build better software together when they have the complete context of what and why something is being built.</p><p>To achieve this, the foundational elements need to change.</p><p>And it starts with getting the right abstractions and naming conventions.</p><p><strong>The names you choose determine the perception and the quality of conversations you have. </strong>It’s why top developers spend time obsessing over names for classes, functions, and variables.</p><p>When you open up a VS Code and see a function called <code>send_signup_email</code>, you have a certain sense of what’s going to be inside and why that’s there.</p><p>The right abstractions can drive the team towards asking the right questions. And this is critical.</p><p><strong>Because when you’re tracking issues and tickets in isolation you have no choice but to measure only outputs.</strong></p><p>And teams today don’t want to measure only the outputs. They want to measure <em>outcomes</em>.</p><hr><h2 id="what-s-the-right-abstraction">What’s the right abstraction?</h2><p>The right abstraction is the one that prioritizes people over processes and tools. It's the one you and I use every day — it's Features.</p><p>When a squad creates a Feature and opens it, they’ll get to look at the entire feature as a unit. A <a href="https://zepel.io/agile/user-stories/">user story</a> inside it might describe a specific functionality. But the difference is, now each developer and designer know how it connects to the larger scheme of things for the entire feature.</p><blockquote>A feature forces inept managers to stop focussing on output-oriented questions like “how can we work faster”. <p>And shifts the focus on outcome-oriented questions like “why should we prioritize this feature” and “how does this feature tie to the OKR”.</p></blockquote><p>Miscellaneous tasks and incoming bugs can be tracked on a separate “List”, so high-priority bugs don't get missed out. And of course, when it comes to tracking them, they can all be tracked on a Sprint or on a Kanban Board.</p><p><strong>Feature as an abstraction is the right middle ground that lets you focus on the output as well as the outcome.</strong> It lets you zoom in and track what's happening today. It also allows you to zoom out and track a feature's progress across multiple disciplines. And it enables you to see how a feature moves from a feature request all the way to prioritization and development.</p><p>Simple issue trackers and project management tools have shoehorned teams into ticket-movers and have made them think in outputs. Metrics get feigned to show productivity. Thinking in outcomes has become ridiculously hard. And it's hurting businesses.</p><p>It's time for tools to reflect the reality of product development. It's time to remove the disconnect between development teams and what your customers really want. </p><p>It's time to stop thinking in isolated tickets and start thinking in features as a system!</p><hr><p>If you liked what you read, I think you’ll love what we have in store for you. Go ahead and <a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=product-development-is-broken">try Zepel for free</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://zepel.io/blog/how-issue-tracking-hurts-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816682</guid>
            <pubDate>Mon, 13 Jul 2020 02:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Website allows you to experience what it is like to live with dyslexia]]>
            </title>
            <description>
<![CDATA[
Score 420 | Comments 175 (<a href="https://news.ycombinator.com/item?id=23816678">thread link</a>) | @colinprince
<br/>
July 12, 2020 | http://geon.github.io/programming/2016/03/03/dsxyliea | <a href="https://web.archive.org/web/*/http://geon.github.io/programming/2016/03/03/dsxyliea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        


<div>
  <div>
    
<p>A friend who has dyslexia described to me how she experiences reading. She <em>can</em> read, but it takes a lot of concentration, and the letters seems to “jump around”.</p>

<p>I remembered reading about <a href="https://en.wikipedia.org/wiki/Typoglycemia">typoglycemia</a>. Wouldn’t it be possible to do it interactively on a website with Javascript? Sure it would.</p>

<p>Feel like making a bookmarklet of this or something? <a href="https://github.com/geon/geon.github.com/blob/master/_posts/2016-03-03-dsxyliea.md">Fork it</a> on github.</p>

<blockquote>
  <p>Dyslexia is characterized by difficulty with learning to read fluently and with accurate comprehension despite normal intelligence. This includes difficulty with phonological awareness, phonological decoding, processing speed, orthographic coding, auditory short-term memory, language skills/verbal comprehension, and/or rapid naming.</p>
</blockquote>

<blockquote>
  <p>Developmental reading disorder (DRD) is the most common learning disability. Dyslexia is the most recognized of reading disorders, however not all reading disorders are linked to dyslexia.</p>
</blockquote>

<blockquote>
  <p>Some see dyslexia as distinct from reading difficulties resulting from other causes, such as a non-neurological deficiency with vision or hearing, or poor or inadequate reading instruction. There are three proposed cognitive subtypes of dyslexia (auditory, visual and attentional), although individual cases of dyslexia are better explained by specific underlying neuropsychological deficits and co-occurring learning disabilities (e.g. attention-deficit/hyperactivity disorder, math disability, etc.). Although it is considered to be a receptive language-based learning disability in the research literature, dyslexia also affects one’s expressive language skills. Researchers at MIT found that people with dyslexia exhibited impaired voice-recognition abilities.</p>
</blockquote>

<p><em>Source: <a href="http://en.wikipedia.org/wiki/Dyslexia">Wikipedia</a></em></p>






    <hr>
    
    <hr>
    


  


<p><a href="http://disqus.com/">blog comments powered by </a>




  </p></div>
  
  
</div>


      </div></div>]]>
            </description>
            <link>http://geon.github.io/programming/2016/03/03/dsxyliea</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816678</guid>
            <pubDate>Mon, 13 Jul 2020 02:40:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning done right can be your biggest investment]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816474">thread link</a>) | @xueyongg
<br/>
July 12, 2020 | https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/ | <a href="https://web.archive.org/web/*/https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><span><p>In the midst of chaotic schedules and piles of work, it is often easy to just take the easy way out of the pile of work: auto pilot. You just switch out the curiosity mode, and just churn out work one after another. “There isn’t time to just sit and ponder. I’ve got 10 other todos to clear out today”. As we continue down this train of thought, we will find ourselves at the brink of a burnout soon and very soon. How then do the smartest people actually learn such complex knowledge? For example, learning calculus in colleague, does one know what does dy/dx actually means?</p>

<p>I came across an article talking about how the smartest people are <a ref="nofollow" target="_blank" href="https://nabeelqu.co/understanding">learning the right way</a>. Now this right does not mean morally right or wrong. But rather learning as a reflection of one’s virtue of honesty and integrity. We will get to this.</p>

<p>Below are four lessons I’ve gotten away from the article:</p>
<br>
<h2>1. More than one solution to the same problem; don’t stop at 1.</h2>

<p>Once a problem was solved, some of the smartest people I’ve known will go back and continue thinking about the problem and try to figure out different solutions to the same problem. Afterwards, he’d come back with 3-4 alternative solutions to the same problem + explanations of why each solutions are somehow connected.</p>
<br>
<blockquote>
<p>It’s also so easy to think that you understand something, when you actually don’t. So even figuring out&nbsp;whether&nbsp;you understand something or not requires you to attack the thing from multiple angles and test your own understanding.</p>
</blockquote>

<p><img src="https://pbs.twimg.com/media/EcvWI2NXYAgD5UT?format=jpg&amp;name=large" alt=""> <em>source from visualizingvalue</em></p>

<p>A problem is often times bigger and more complex beyond our current perspective. The ability to sit and ponder for alternative solutions to the same problem forces you to consider the possibility of not knowing something in this problem at hand. It allows you to force out the cracks in the pottery by placing the knowledge under fire.</p>
<br>
<h2>2. Be honest with yourself; do you really know? Ask yourself.</h2>

<p>To admit that you do not understand a concept is related to honesty or integrity. It is uniquely easy to lie to yourself that you know and move on because there is no external force keeping you honest. You and only you can run that constant loop of asking “do i really understand this?”. Do not just skirt past the problem just to move on to the next task, you’re not a factory that just just churning out work day in day out. You’re an individual that is part of your own journey to learn, grow, and develop.</p>

<p>Also, writing has a part to play. Firstly, it helps you to be honest with yourself; it forces you to articulate your understanding. And if the writing comes out confusing and disjointed, it is a reality check for knowledge gaps.</p>
<br>
<blockquote>
<p>It’s okay to admit that you don’t know</p>
</blockquote>
<br>
<h2>3. Go beyond the abstraction, tell me what you really know. Give examples.</h2>

<p>The tangible experiments of your learning with concrete examples is important to illustrate understanding. You do not just stop at simple verbal “word based” understanding. It can only bring you this far. But visuals creates a context in which your understanding can take place in.</p>
<br>
<blockquote>
<p>Visualizing something, in three dimensions, can help you with a concrete “hook” that your brain can grasp onto and use as a model;</p>
</blockquote>

<p>If you’re not coming up with visuals and your understanding of things remains on the level of abstractions or abstract concepts, you probably do not understand the concept deeply and should dig further. Below is basically the concept of AI conversational classifiers done up with the illustration of a coin filter.</p>

<p><img src="https://pbs.twimg.com/media/Ebxl9eFWoAAJuFT?format=png&amp;name=small" alt=""> <em>source from nwilliams030’s twitter</em></p>
<br>
<ol start="4">
<li>Have the courage to ask; Ask if you don’t know.</li>
</ol>
<p>Have the courage to be unafraid to look stupid. Have the courage to admit and seek for clarity and understanding. Don’t just pretend you understand just to pass the time. This is your journey of learning and getting better than the you yesterday. Do not let other people dictate how you should invest in yourself. Shower yourself with love and respect for your own growth.</p>

<p><img src="https://images.unsplash.com/flagged/photo-1558979217-e7f2c4511e8b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1650&amp;q=80" alt="kid watering flower"></p>
<br>
<hr>
<br>
<h2>TLDR;</h2>

<p>At the end of the day, if you want to understand something, go slow. Explore every step of the way in your adventure to learn and unveil. Read slowly, think slowly, really spend time pondering the thing. A week or a month of continuous pondering about a question will get you surprisingly far. In the space of technology, you will face a ton of technology that are more abstracted and technical beyond human mind (haha kidding, but it feels like so). There’s what you got to be honest with yourself to admit that you don’t know then can the learning begin (:</p>

<p>Before you end off, do watch this video! It is really good. It’s a video talking about the 5 hours rule deliberate learning. Let’s learn together! (:</p>

<p>
<iframe src="https://www.youtube.com/embed/IaODRYKFbrc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></span></p> </div></div>]]>
            </description>
            <link>https://blog.phuaxueyong.com/post/2020-07-13-learning-the-right-way/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816474</guid>
            <pubDate>Mon, 13 Jul 2020 02:02:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Host a Wiki or Knowledge Base for Your Team]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23816462">thread link</a>) | @chsasank
<br/>
July 12, 2020 | http://chsasank.github.io/outline-self-hosted-wiki.html | <a href="https://web.archive.org/web/*/http://chsasank.github.io/outline-self-hosted-wiki.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>How is your startup sharing knowledge with the rest of your team?
We’ve been using slack’s <code>#general</code> or <code>#random</code> channels to make announcements.
We regularly post documents and PPTs slack channels so that they can be used by other people. We have a channel called <code>#setup</code> to post all IT related information like how to login to VPN etc.</p>

<p>But after a few weeks, these docs/notes become super hard to find. As good slack’s search is, you have to precisely know what you’re looking for. What we needed was a centralized knowledge base website - something like <a href="https://www.atlassian.com/software/confluence">Confluence</a></p>

<p>But Confluence is clunky and slow, and not cheap ($5/user). We experimented with <a href="https://tiddlywiki.com/">TiddlyWiki</a>. It calls itself ‘a non-linear personal web notebook’. It’s an opensource software which you can host on your servers or AWS. But its non linear organization makes it super unintuitive and confusing.</p>

<h2 id="why-outline">Why Outline?</h2>

<p>Then, I found <a href="https://www.getoutline.com/">outline</a>! Outline is similar to TiddlyWiki in that it’s opensource and free to self-host. Its UI is a great balance between simplicity of plain text notes and feature creep of Confluence. Login to outline is through your slack - so one less password to remember (or save). You can create private notebooks for a team or just for yourself. You can create a public link of a note so that you can share it with people outside your team - say via email.</p>

<p><span>
    Outline has great UI
</span>
<img src="https://www.getoutline.com/images/screenshot.png"></p>

<p>Best part of all of this is that <em>data doesn’t leave your servers</em> if you self-host it!
We already have a server lying around on AWS to host our own <a href="https://en.wikipedia.org/wiki/Python_Package_Index">python package server, pypi</a>. Since neither hosting pypi nor hosting outline are particularly intensive, we’ve hosted outline on this machine as <code>wiki.qure.ai</code>.</p>

<h2 id="install-outline">Install Outline</h2>

<p>Unfortunately, documentation for self-hosting outline is limited. There’s no robust docker-compose avaialable that you can use to directly create your server. In the rest of this post, I’ll show you how to host in your laptop or server. Before starting, make sure to install <a href="https://docs.docker.com/get-docker/">docker</a> and <a href="https://docs.docker.com/compose/install/">docker-compose</a>.</p>

<div><div><pre><code>git clone https://github.com/chsasank/outline-wiki-docker-compose.git
cd outline-wiki-docker-compose
make install
</code></pre></div></div>
<p><span>
    make install
</span>
<img src="http://chsasank.github.io/assets/images/outline/make_install.png"></p>

<p>Follow the instructions. You’ll have to create a slack app.
<span>
   Slack app
</span>
<img src="http://chsasank.github.io/assets/images/outline/slack_app.png"></p>

<p>If you want to install HTTPS:</p>



<p>Run the server:</p>



  </section></div>]]>
            </description>
            <link>http://chsasank.github.io/outline-self-hosted-wiki.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816462</guid>
            <pubDate>Mon, 13 Jul 2020 02:00:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Biotech]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23816390">thread link</a>) | @apsec112
<br/>
July 12, 2020 | https://www.celinehh.com/how-to-build-a-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/how-to-build-a-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

      

        

        <div data-content-field="main-content">
          <div data-type="page" data-updated-on="1594684464227" id="page-5e0541ebe2b52a3155df2dcb"><div><div><div data-block-type="2" id="block-3ee5a93fdab84f05b621"><p><h3>The Summer of 2019, I gave a series of lectures to Longevity Fund’s Venture Fellows on the basics of building a biotechnology company. This is the write up of those lectures, with some additions by Laura Deming &amp; myself. </h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1577404962916_9483"><div><h2>First Steps</h2><p>You’re intrigued by biotech and want to explore ideas in the area. Where do you start? </p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1577402821118_87823"><div><h2>Raising Money</h2><p>Science is expensive! One way to fund your work is to get venture capital (VC) investment. It’s a very different process from applying for an academic research grant. </p><p>There are a lot of excellent resources out there on raising capital.* Because of this I’ve focused here on “SF style” biotech investing, and the areas where the advice for a bio company differs from that of a tech company. </p><h3><a href="https://www.celinehh.com/vc101">VC for Bio 101</a> </h3><h3><a href="https://www.celinehh.com/investment-memo">Biotech investment memos</a></h3><p><a href="https://pmarchive.com/guide_to_startups_part1.html">*Marc Andreessen’s guide to startups</a>, the <a href="http://paulgraham.com/articles.html">PG essays</a>, and <a href="https://www.amazon.com/Venture-Deals-Smarter-Lawyer-Capitalist/dp/1118443616">Venture Deals</a> are three classics</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1577402821118_96448"><div><h2>Building in Bio</h2><p>A bit of a deeper dive into the predominant types of drugs and the considerations around each of them. The type of drug you select impacts the safety, dosing strategy, potential efficacy, downstream price &amp; profit margin, and competitiveness of your drug. </p></div></div></div></div></div>
        </div>
      
    </div></div>]]>
            </description>
            <link>https://www.celinehh.com/how-to-build-a-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816390</guid>
            <pubDate>Mon, 13 Jul 2020 01:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From English Major to Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816355">thread link</a>) | @shsachdev
<br/>
July 12, 2020 | https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            


<p>
My name is Chris Dang and I work at <a href="https://www.scratch.fi/">Scratch</a> which is a Series A fintech startup that has reimagined loan servicing to help borrowers understand, manage, and pay back their loans. It’s a company filled with determined, smart, and mission driven individuals. 
</p>
<p>
We were recently mentioned in this <a href="https://www.nytimes.com/2020/06/23/business/paycheck-protection-program-cross-river-bank.html">New York Times article</a>.
</p>
<center>
    <img src="https://www.careerfair.io/assets_cdang/final_homepage.png" alt="">
</center>
<p>
I’m a software engineer who primarily focuses on Identity and Access Management. This means I focus on authentication, authorization, and user management problems. I also occasionally work outside my domain in areas such as frontend, security, and infrastructure. This happens a lot at startups which require folks to wear many hats. 
</p>



<p>
I don’t really understand why but I just enjoyed writing essays and discussing texts so I became an English major. It was one of those moments where I felt like I just had to go with my gut and I’m glad I did because becoming an English major made me a more creative person. This creativity allowed me to come up with a few startup ideas that I’ve attempted and have planned for the future. 
</p>
<p>
The reason I taught myself how to code is that I wanted to build my ideas. I’d like to note that I did take a few intro computer science courses before I became an upperclassman, so when I began attempting some of my startup ideas I already knew OOP, runtime analysis, data structures and algorithms. 
</p>
<p>
In my day-to-day, being an English major helps me with communication, which is very key as an engineer, and, this is a little random, but it makes me more relatable to non-engineering folks since a lot of them probably took similar courses to me.
</p>
<center>
  <img src="https://www.careerfair.io/assets_cdang/new_venn_diagram.png" alt="">
</center>



<p>
It was definitely a problem in the beginning since I had no experience and a lot of companies wouldn’t even give me an interview. I wasn’t too worried about this though because I had a passion project I was working on and if I wasn’t able to get a job, I was determined to go all on the project and turn it into a startup. I actually was able to launch it to the app store and had a customer acquisition strategy. Luckily, a few companies, including WeWork, liked the grit I showed in my startup and gave me a chance.
</p>
<p>
The lack of a CS major did leave a gap in my knowledge when it came to interviews and performing the day to day job. I did a few things to mitigate this gap which included going through lecture slides for upper division courses I found interesting (e.g. Operating Systems and Computer Security), spending copious amounts of time reading articles about engineering, and spending time on my passion project which gave me a lot of real world experience. Also, Stack Overflow was my best friend. 
</p>



<p>
My time at WeWork made me realize that I was very interested in the Identity, Infrastructure, and Security domains with Identity being my primary interest. So when I began my job search, I made sure to focus on jobs in those domains but I did apply to some generalist positions. The reason for this is that I’m pretty young and it’s good for me to have breadth in other areas. I also wanted to make sure that my next job had really challenging problems and smart engineers. The things I cared about least were job stability (e.g. whether or not my company would exist in a year), my total compensation, and the company brand. 
</p>
<p>
I optimize for growth over learning by focusing on opportunities that I’m passionate about over opportunities that would make me more money. Money and brand names bring you a limited amount of satisfaction. However, doing something you are passionate about will always be more exciting because as you grow in that area, the horizons expand and more exciting ideas/projects will come to you.
</p>
<center>
    <img src="https://www.careerfair.io/assets_cdang/cash.png" alt="">
</center>



<p>
The nice thing about working at startups is you are guaranteed to have a large role. Everyday I learn something new and I always feel like my work is rewarding. But there is a trade off here.  I do feel like I’m a lot busier since my role is more significant than if I were at a large company. 
</p>
<p>
One thing I wish I realized earlier though was that even at a big company, you can have a really exciting role. It really depends on the team and your manager. If you are hungry for a challenge but would like the comfort of a large company, I would recommend interviewing with some of the newer projects.
</p>



<p>
I actually went to the office before the shelter in place was ordered so I didn’t have any issues with setting up my laptop or developer environment. But even if this wasn’t the case, I don’t see remote onboarding being a problem due to strong video technologies such as Zoom. 
</p>
<p>
My first day of work actually began a few weeks after the quarantine began so I haven’t had more than a few days to see my coworkers in person. It’s a little weird because I spend so much time with these people but our interactions are exclusively through a computer screen. One thing I’ve realized is I’m lukewarm to remote work culture since it’s hard to have spontaneous interactions with coworkers and happy hours aren’t as fun. 
</p>
<p>
That being said, I’m really amazed by how our team has adapted to these conditions. Despite the pandemic, the conditions of working remote, and other obstacles, we’ve managed to persevere and launch our PPP product.
</p>

<center>
  <img src="https://www.careerfair.io/assets_cdang/spontaneous.png" alt="">
</center>




<p>
I’ve worked with teams in business operations and design at least once a week. It’s cool to collaborate with folks from other departments because you can pick their brains and see another perspective to a problem you are working on. A really big aspect of these interactions is your ability to communicate technical topics since a lot of times non-technical individuals will rely on you to explain what’s going on under the hood with the software. 
</p>



<p>
My average day consists of reviewing pull requests and working on my own pull requests. Occasionally, I’ll have meetings to sync on the state of my team or the company or run interviews for candidates.
</p>
<p>
My experience with my side project gave me a pretty good idea of the technical challenges I would face in my day-to-day. I would say one thing that surprised me was how open people were to my questions. This made it easier for me to grow as an engineer since I was surrounded by people who wanted to help me learn. A piece of advice I’d give to new engineers is to try to solve a problem or understand a concept on your own first before asking the questions. 
</p>
          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/software-engineer-interview-at-scratch-finance</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816355</guid>
            <pubDate>Mon, 13 Jul 2020 01:39:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bringing GPU Acceleration to Inkscape, Week 2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816235">thread link</a>) | @shahreel
<br/>
July 12, 2020 | https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/ | <a href="https://web.archive.org/web/*/https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
      
<h2>
  Bringing GPU Acceleration to Inkscape, Week 2
</h2>
<p>Published the <time datetime="2020-06-12T20:02:31+02:00">2020-06-12</time></p>
<p>Hello everyone!</p>
<p>For the past two weeks since the beginning of this <a href="https://summerofcode.withgoogle.com/organizations/6070010742571008/#5859756641615872">GSoC
2020</a>
I have attempted to integrate <a href="https://github.com/servo/pathfinder">Pathfinder</a>
into Inkscape, in order to draw (and refresh!) the canvas much faster by using
your GPU.</p>
<p>After some early attempts, where I created a C++ Inkscape extension opening
Pathfinder’s demo on the current SVG, and another extension which was basically
a copy of <a href="https://github.com/servo/pathfinder/blob/master/examples/c_canvas_glfw_minimal/c_canvas_glfw_minimal.c">Pathfinder’s C canvas
example</a>,
I’ve started to properly integrate it into Inkscape’s widgets.</p>
<p>That’s where the fun began, here is a small tour of the fun bugs I encountered:</p>
<h3 id="using-apitrace-on-wayland-can-be-interesting">Using <code>apitrace</code> On Wayland Can Be Interesting</h3>
<p><a href="https://apitrace.github.io/"><code>apitrace</code></a> is a very handy tool for debugging
OpenGL applications, it avoids having to understand the code’s structure, and
allows me to focus on the actual behaviour from the driver’s point of view.</p>
<pre><code><span>glXGetCurrentContext() not found: /usr/bin/../lib/apitrace/wrappers/egltrace.so: undefined symbol: glXGetCurrentContext
apitrace: warning: caught signal 6
</span></code></pre>
<p>I was a bit sad to see that a bug I found at the intersection of
<a href="https://github.com/apitrace/apitrace/issues/380">apitrace</a> and
<a href="https://github.com/anholt/libepoxy/issues/68">libepoxy</a> back in 2015
reappeared now, this time caused by GDK doing the same.  In the end I rebuilt
both libepoxy and GTK+ with only their Wayland backend so they wouldn’t be
tempted to call GLX symbols.  This breaks Firefox and probably some other
software which link against their X11 symbols, but on my build/testing machine
it’s fine.</p>
<p>Speaking of running a (soon-to-be) OpenGL program on a remote machine,
<a href="https://gitlab.freedesktop.org/mstoeckl/waypipe">waypipe</a> from last year’s
GSoC is extremely useful, it feels almost instantaneous on my 900&nbsp;KiB/s down
80&nbsp;KiB/s up ADSL connection.  For comparison, I also tried X11 forwarding over
ssh which only shows Inkscape’s window after 1:05, and also mounting the build
directory over sshfs where it takes 1:20 to do the same, and 6:40 (!) to
generate a stack trace in case of a panic.  I probably should have figured that
out during the community bonding period, but I didn’t think of it.</p>
<h3 id="pathfinder-doesn-t-like-to-draw-into-gtk-glarea-very-much">Pathfinder Doesn’t Like To Draw Into <code>Gtk::GLArea</code> Very Much</h3>
<p>I spent quite a few days trying to get Pathfinder to draw into a GTK+ widget,
first inside of Inkscape, then in a <a href="https://linkmauve.fr/files/pathfinder-glarea.tar.xz">testcase
application</a>.  The
<code>Gtk::GLArea</code> widget lets an application draw using OpenGL.  I want it to
eventually replace Inkscape’s <code>SPCanvas</code>, once I’m done and <a href="https://wiki.inkscape.org/wiki/index.php?title=Inkscape_Canvas">Tavmjong as
well</a>, but in
the meantime I’ll keep them both side-by-side in order to compare their
rendering more easily.</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/empty-glarea.png" alt=""></p>
<p>Despite the rendering being done, according to <code>apitrace</code>’s step-by-step
debugging, the <code>Gtk::GLArea</code> stayed hopelessly black.  Even though I could
render a simple solid colour using <code>glClearColor()</code> and
<code>glClear(GL_COLOR_BUFFER_BIT)</code>, as soon as I tried to render using Pathfinder
it went back to a solid black.</p>
<p>Experimenting with the OpenGL contexts, I could make Pathfinder render its
iconic tiny house everywhere but where I wanted it:</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/almost-but-not-quite.png" alt=""></p>
<p>Here is a particularly trippy rendering I got, when <code>Gtk::GLArea</code> is reading
from a framebuffer Pathfinder hasn’t written into:</p>

<p>It was only with the help of <a href="https://github.com/s3bk">sebk</a> that I finally
figured out that I wasn’t passing the correct
<a href="https://www.khronos.org/opengl/wiki/Framebuffer_Object">fbo</a> to Pathfinder.  I
was passing <code>0</code> which means the default (display’s) framebuffer instead of the
one created for me by GTK+.  With this fixed, everything rendered fine, even on
resize:</p>

<p>After that it was a simple matter of <a href="https://github.com/servo/pathfinder/pull/357">adding some API to Pathfinder’s C
bindings</a> and I can render the
same SVG as Inkscape!</p>
<p><img src="https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/same-svg.png" alt="">
On the left hand side we can see <a href="https://poez.io/">poezio</a>’s logo rendered by
Inkscape with cairo; on the right hand side the same logo being serialised and
passed to Pathfinder to be rendered on the GPU.</p>
<p>And this concludes my first progress report of this GSoC, a big thanks to
ebassi, halfline and Neville[m] from
<a href="xmpp:%23gtk%irc.freenode.net@irc.jabberfr.org?join">#gtk</a>, and especially sebk
from <a href="xmpp:%23pathfinder%23mozilla.org@matrix.org?join">#pathfinder</a>, who
helped me a lot in that process!</p>


    </div>
  </section></div>]]>
            </description>
            <link>https://linkmauve.fr/blog/2020/06/12/bringing-gpu-acceleration-to-inkscape-week-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816235</guid>
            <pubDate>Mon, 13 Jul 2020 01:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuzz Week 2020 – Come Learn the Basics to Advanced of Fuzzing]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23816110">thread link</a>) | @gamozolabs
<br/>
July 12, 2020 | https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html | <a href="https://web.archive.org/web/*/https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>Welcome to fuzz week 2020! This week (July 13th - July 17th) I’ll be streaming
every day going through some of the very basics of fuzzing all the way to
cutting edge research. I want to use this time to talk about some things
related to fuzzing, particularly when it comes to benchmarking and comparing
fuzzers with each other.</p>



<p>Ha. There’s really no schedule, there is no script, there is no plan, but
here’s a rough outline of what I want to cover.</p>

<p>I will be streaming on my <a href="https://twitch.tv/gamozo">Twitch channel</a> at approximately
<a href="https://www.timeanddate.com/worldclock/fixedtime.html?msg=Fuzz+Week+Approx+Stream+Start&amp;iso=20200713T14&amp;p1=234">14:00 PST</a>. But things aren’t really going to be on a strict schedule.</p>

<p>My <a href="https://twitter.com/gamozolabs">Twitter</a> is probably the best source of information for when
things are about to start.</p>

<p>Everything will be recorded and uploaded to my <a href="https://www.youtube.com/user/gamozolabs">YouTube</a>.</p>

<h4 id="july-13th">July 13th</h4>

<p>The very basics of fuzzing. We’ll write our own fuzzer and tweak it to improve
it. We’ll probably start by writing it in Python, and eventually talk about the
performance ramifications and the basics of scaling fuzzers by using threads or
multiple processes. We’ll also compare our newly written fuzzer against AFL and
see where AFL outperforms it, and also where AFL has some blind spots.</p>

<h4 id="july-14th">July 14th</h4>

<p>Here we’ll cover code coverage. We might get to this sooner, who knows. But
we’re going to write our own tooling to gather code coverage information such
that we can see not only how easy it is to set up, but how flexible coverage
information can be while still proving quite useful!</p>

<h4 id="july-15th-17th">July 15th-17th</h4>

<p>Here we’ll focus mainly on the advanced aspects of fuzzing. While this sounds
complex, fuzzing really hasn’t become that complex yet, so follow along! We’ll
go through some of the more deep performance properties of fuzzing, mainly
focused around snapshot fuzzing.</p>

<p>Once we’ve discussed some basics of performance and snapshot fuzzing, we’ll
start talking about the meaningfulness of comparing fuzzers. Namely, the
difficulties in comparing fuzzers when they may involve different concepts of
what a crash, coverage, or input are. We’ll look at some existing examples of
papers which compare fuzzers, and see how well they actually prove their point.</p>



<p>I think it’s important when doing something like this, to make it clear what my
existing biases are. I’ve got a few.</p>

<ul>
  <li>I think existing fuzzers have some major performance problems and struggle to
scale. I consider this to be a high priority as general performance
improvements to fuzzing harnesses makes both generic fuzzers (eg. AFL,
context-unaware fuzzers) and hand-crafted (targeted) fuzzers better.</li>
  <li>I don’t think outperforming AFL is impressive. AFL is impressive because it’s
got an easy-to-use workflow, which makes it accessible to many different
users, broadening the amount of targets it has been used against.</li>
  <li>I don’t really thinking comparing fuzzers is reasonable.</li>
  <li>I think it is very easy to over-fit a fuzzer to small programs, or add
unrealistic amounts of information extraction from a target under test, in a
way that the concepts are not generally applicable to many targets that
exceed basic parsers. I think this is where a lot of current research falls.</li>
</ul>

<p>But… that’s mainly the point of this week. To either find out my biases are
wildly incorrect, or to maybe demonstrate why I have some of the biases. So,
how will I address some of these (in order of prior bullets)?</p>

<ul>
  <li>I’ll compare some of my fuzzers against AFL. We’ll see if we can outperform
AFL in terms of raw fuzz cases performed, as well as the results (coverage
and crashes).</li>
  <li>I’ll try to demonstrate that a basic fuzzer with 1/100th the amount of code
of AFL is capable of getting much better results, and that it’s really not
that hard to write.</li>
  <li>I’ll propose some techniques that can be used to compare fuzzers, and go
through my own personal process of evaluating fuzzers. I’m not trying to get
papers, or funding, or anything. I don’t really have an interest in making
things look comparatively better. If they perform differently, but have
different use cases, I’d rather understand those cases and apply them
specifically rather than have a one-shoe-fits-all solution.</li>
  <li>I’ll go through some instrumentation that I’ve historically added to my
fuzzers which give them massive result and coverage boosts, but consume so
much information that they cannot meaningfully scale past tiny pieces of
code. I’ll go through when these things may actually be useful, as sometimes
isolating components is viable. I’ll also go through some existing papers and
see what sorts of results are being claimed, and if they actually have
general applicability.</li>
</ul>



<p>It’s important to note, nothing here is scheduled. Things may go much faster,
slower, or just never happen. That’s the beauty of research. I may be very
wrong with some of my biases, and we’ll hopefully correct those. I love being
wrong.</p>

<p>I’ve maybe thought of having some fuzzing figureheads pop on the stream for
random discussions/conversations/interviews. If this is something that sounds
interesting to you, reach out and we can maybe organize it!</p>



<p>See you there :)</p>

<hr>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://gamozolabs.github.io/2020/07/12/fuzz_week_2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23816110</guid>
            <pubDate>Mon, 13 Jul 2020 01:01:46 GMT</pubDate>
        </item>
    </channel>
</rss>
