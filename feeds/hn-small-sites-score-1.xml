<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 1]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 1. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 07 Dec 2020 16:45:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-1.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 07 Dec 2020 16:45:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Thinking About Decentralized Communities]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322532">thread link</a>) | @SubGenius
<br/>
December 6, 2020 | https://gurlic.com/root/thinking-about-decentralized-communities | <a href="https://web.archive.org/web/*/https://gurlic.com/root/thinking-about-decentralized-communities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
          
            <p>Earlier today, I had the misfortune of reading a blog post about the dangers of the decentralized web and how we should not partake in or encourage it's development. Hacker News had a pretty <a href="https://news.ycombinator.com/item?id=25312854" rel="noopener noreferrer nofollow">active discussion</a> about the post.</p><p>Ideological takes on this always turn ugly, and I'm at a point in my life where I avoid that at all costs. I can only talk about my preferences about the world, not about how things ought to be, implying some sort of inherent value or divine moral good.</p><p>Here's what I prefer: a world where ideas, no matter how silly or dangerous, are allowed to be expressed, shared, ignored, attacked and laughed at. I don't imagine a world like this can ever exist easily, but a more decentralized web can help us get halfway there.</p><h3 id="ok-so-what-about-gurlic-then">Ok so what about Gurlic then?</h3><p><a href="https://gurlic.com/" rel="noopener noreferrer nofollow">Gurlic</a> is roughly just over two months old now, and at a point where I am relatively comfortable with the basic features it has. In the coming weeks and months, I want to focus on modifying the backend to either adopt an existing decentralized protocol, or think about how to approach writing a new one. Perhaps it would have been smarter to do this before building it first, but that would have limited how I envisioned Gurlic to be and it would've turned out differently.</p><p>Right now I'm looking into the <a href="https://www.w3.org/TR/activitypub/" rel="noopener noreferrer nofollow">activitypub</a> spec, and the <a href="https://matrix.org/docs/spec/" rel="noopener noreferrer nofollow">matrix</a> spec - here are some initial thoughts I have about how Gurlic should approach decentralization/federation.</p><ul><li><p>Decentralization can be a priority, but must never be promoted as a feature, or made to be a selling point. When decentralization becomes the main selling point of a product or service, the usability and polish tend to suffer. Not always, but nearly always. None of the marketing copy should include the words 'decentralization', 'privacy' etc. <strong>Normal users don't care about any of this</strong>.</p></li><li><p>User experience should be seamless. The user shouldn't have to generate a key, remember an extra password, remember weird URL schemes, or download utilities and clients just to be part of an online community or to write an article. Above all, the user must not be confused, as one usually is when looking at Mastodon instances, which one to sign up to, and so on. My mom should be able to use it without having to call me, just like she does with Facebook. <strong>Normal users do care about this</strong>.</p></li><li><p>The protocol must be flexible enough to allow for all of Gurlic's current features. This means communities, user profiles, publications, articles, galleries, rich media posts, sharing/responding and so on. All seamlessly without any rough edges.</p></li><li><p>Any and all cryptocurrency/blockchain must be avoided.</p></li></ul><p>I'll have more to write about this in the near future.</p>
            </section></div>]]>
            </description>
            <link>https://gurlic.com/root/thinking-about-decentralized-communities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322532</guid>
            <pubDate>Sun, 06 Dec 2020 10:23:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handy tips for staying secure on the go]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322461">thread link</a>) | @henrikwm
<br/>
December 6, 2020 | https://security.christmas/2020/6 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://images.unsplash.com/photo-1517400508447-f8dd518b86db?w=1226&amp;h=400&amp;fit=crop&amp;crop=edges" alt=""><div><section><p>We wrote about <a href="https://security.christmas/2019/21">"Safe travels for the road warrior"</a> last year. This year we offer one more trick, and expand our list for staying safe and secure on the road.</p>
<p>Watch out for shoulder surfers, and protect your equipment if you have to leave it in for example your hotel room.</p>
</section><article><section><p><em>PANDEMIC WARNING: Stay at home if you can. A virus has for the better part of 2020 attacked physical infrastructure (people). We have no patch or hotfix, so while that is being worked out, we advice you to travel as little as possible.</em> </p>
<h2>Shoulder surfers:</h2>
<p>Be aware of your surroundings and reduce the risk of shoulder surfers. A shoulder surfer is someone who is peaking over your shoulder to get information. We can spot people prone to this type of social engineering attack all the time. When people are visiting a cafee, are on public transport, or on air planes they will use their laptop for work stuff. And they don’t notice, or care if someone is looking.</p>
<p>To protect your information, you can, and should invest in a privacy shield for you screen. They cost next to nothing, but reduce/limit the viewing angle of your display.</p>
<p><img src="https://cdn57.androidauthority.net/wp-content/uploads/2019/04/privacy-screen-protector-angle-2.jpg" alt="privacy screen protector"></p>
<p>Reduce the number of apps visible on your computer. On a Mac I recommend that you use <a href="https://www.macbartender.com/">Bartender</a>, but there are Windows and *Nix options as well. The point of this application is that it hides all the running apps from the menu bar, so that it looks like this: </p>
<p><img src="https://i.imgur.com/QsbNjHu.png" alt="a neat menu bar"></p>
<p>rather than this abomination of a menu bar: </p>
<p><img src="https://eshop.macsales.com/blog/wp-content/uploads/2019/05/1password1280.jpg" alt="an untidy and talkative menue bar"></p>
<p>The reason for hiding this information from shoulder surfers is that it reveals many of your attack vector. If someone knows what applications you are running, they know a lot about you. Developer tools, Automator scripts, and a password manager? You presumably work in IT. Bluetooth enabled, an old version of Outlook and a TorrentClient? The bad guys already have tools for these applications.  </p>
<h2>Mikado security</h2>
<p>The other tip is to not leave your computer laying around. This may seem obvious, but there are times when this is impossible. There will be events where you have super secret stuff on your computer, and must step away for a period of time. For instance in a hotel room while you are away for an hour, or go to a resturant.</p>
<p>If an adversary has physical access to your device, they can do all sort of damage. <a href="https://www.theregister.com/2013/12/11/poker_pros_call_shenanigans_over_hotel_malware_infections/">A poker player had this happen to him</a>, where someone broke into his hotel room to install malware on his laptop. This is only one of the cases, but we suspect there are many more based on  the fact that hotel room locks are <a href="https://youtu.be/-Bazy3Ew6D4">ridiculously insecure</a>, and <a href="https://youtu.be/RX-O4XuCW1Y">easy to bypass</a>.<br>
So to combat this problem, we have devised a nice little trick to help you stay safe if you have to leave your device behind.</p>
<p><img src="https://live.staticflickr.com/5475/9350249910_6aeb4b5d85_h.jpg">
<a href="https://flic.kr/p/ffftxm">Mikado</a> by <a href="https://www.flickr.com/photos/kobakpontorg/">Balazs Koren</a>, on Flickr</p>
<p>Mikado (also known as “pick-up sticks game”) is a game where players drop a bundle of sticks as a loose bunch onto a table top. Each player in turn tries to remove a stick from the pile without disturbing any of the others.</p>
<p>MikadoSecurity is where you spread the sticks over the object that you want to protect. You then take a picture of it, and when you return, you can verify that no one has tampered with your device.
In the event that the sticks are not as you left them, you can escalate the problem. Either to do forensics, or discard the computer if you need to.</p>
<p>This trick relies on the same principles as we rely on for computer security. Prime number factoring, traveling salesman problem and SAT are hard to solve if P != NP, but easy to verify.
An example of this is a sudoku board. It is hard for both humans and computers to solve, but if I hand you a board, it is easy for you to verify if I did it correct. </p>
<p><img src="https://i.imgur.com/fibOzob.png" title="Hard to solve / Easy to verify"></p></section></article></div></article><section><ul><li></li><li></li><li></li></ul></section></main></div></div>]]>
            </description>
            <link>https://security.christmas/2020/6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322461</guid>
            <pubDate>Sun, 06 Dec 2020 10:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Perils of File Typing]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25322288">thread link</a>) | @panic
<br/>
December 6, 2020 | https://invisibleup.com/articles/34/ | <a href="https://web.archive.org/web/*/https://invisibleup.com/articles/34/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/34/thumb.gif" alt="The Perils of File Typing thumbnail">
	
	

	
<p>Corrections added to the Creator/Type code section thanks to user "Somebody" on Hacker News</p>

<p>Suppose you double-click on a file on your computer. You're doing this so you can open the file and work with it. But does your operating system know what that means? How does it know <em>what</em> to open the file <em>in</em>? Let's look at some solutions that have been proposed over the years to solving this issue.</p>
<p>(fun fact: this originally started as a touchup of <a href="https://invisibleup.com/articles/2/">one of my oldest articles</a> before just kinda becoming this whole <em>thing</em>, so expect a bit of retreading.)</p>
<h2>Nothing</h2>
<p><img alt="IBM 709 in use" src="https://invisibleup.com/articles/34/IBM709.jpg"></p>
<p><strong>Used in</strong>: Early mainframes such as the <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a>, etc.</p>
<p>(Image credit: <a href="https://www.computer-history.info/Page4.dir/pages/IBM.704.dir/">Lawrence Livermore National Laboratory</a>)</p>
<p>What's a "file", anyways? It's a sequence of bytes on a disk, possibly floppy. Or a tape. (Cassette or paper, your choice.) Or on stacks of cards with holes in them. Or toggled in by hand on a front panel.</p>
<p>File types weren't relevant because <em>files</em> weren't really a thing. In the mainframe era, you typically 
1. loaded a program on to your computer from punch cards or a tape
2. fed input into that program either from a teletype terminal or from a different tape/card deck
3. received output from the teletype, a line printer, or yet another tape/card deck</p>
<p>Computers weren't complicated enough where there was any confusion as to what a file on a certain medium <em>was</em>, simply because there was so little to work with. If you had a stack of punchcards, that was your "file". Hope you labeled the box you put it in!</p>
<p>Tapes are more interesting, because they hold substantially more data. (A whopping 5.76 megabytes, stored on 3/4 of a kilometer of magentic tape. How exciting!) That said, storing more than one file on a tape was a strange task. Operating systems weren't really a <em>thing</em> yet. The best that existed were programming languages such as FORTRAN or COBOL that had statements for hardware tasks such as reading from or writing to a tape or punch card. For example, <a href="http://archive.computerhistory.org/resources/text/Fortran/102649787.05.01.acc.pdf">here's the manual for FORTRAN for the IBM 704.</a> We have several commands such as <code>READ</code> (from the punch card reader), <code>READ TAPE</code>, <code>PUNCH</code> (new cards), <code>PRINT</code> (to the printer), etc.</p>
<p>On the IBM tape units of the time (ex: the <a href="https://en.wikipedia.org/wiki/IBM_727">IBM 727</a>), tapes were separated into <em>files</em> and <em>records</em>. In FORTRAN, records were created on every <code>WRITE TAPE</code> command, and could be read with <code>READ TAPE</code> later. Records could be overwritten by using the <code>BACKSPACE</code> statement and then writing again. Files were collections of records, and could be created with an <code>END FILE</code> command.</p>
<p>As an aside, later programming languages such as C still share their heritage from this era. This is why we draw text to the screen with <a href="http://www.cplusplus.com/reference/cstdio/printf/"><code>printf</code></a> which long ago would have literally printed to a <a href="https://en.wikipedia.org/wiki/Teletype_Model_33">teletype terminal</a>, why we read files using <a href="http://www.cplusplus.com/reference/cstdio/rewind/"><code>rewind</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fseek/"><code>fseek</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fread/"><code>fread</code></a>, and <a href="http://www.cplusplus.com/reference/cstdio/fwrite/"><code>fwrite</code></a> as if we were on a tape drive still. Even <a href="http://www.asciitable.com/">ASCII</a>, the encoding most commonly used for the basic Latin alphabet, has code points for file, group, record, and unit separators. (This may also be related to block terminals, something that will be discussed in a future article.)</p>
<p>As mainframes moved onto more advanced batch processing and later interactive time-share operating systems like UNIX, <a href="https://en.wikipedia.org/wiki/OS/360_and_successors">OS/360</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Terminal_System">Michigan Terminal System</a>, <a href="https://en.wikipedia.org/wiki/Incompatible_Timesharing_System">ITS</a>, etc., they gained more sophisticated methods of dealing with files than raw tape drive access. But then came the microcomputers.</p>
<h2>Type Codes</h2>
<p><img alt="Apple DOS file listing" src="https://invisibleup.com/articles/34/appledos.gif"></p>
<p><strong>Used in</strong>: <a href="https://en.wikipedia.org/wiki/Apple_DOS">Apple DOS for Apple II</a> (1978-1980), <a href="https://www.hpmuseum.org/hp28c.htm">HP-28</a> and <a href="https://www.hpmuseum.org/hp48s.htm">HP-48</a> series, etc.</p>
<p>We have floppy disks now. They can store a lot of files, rename them, delete them, etc. without too much issue. There's this neat computer called the Apple II that just came out. It uses these new-fangled disks, so it needs to figure out how to store files on it.</p>
<p>The way that Apple DOS (the Apple II's disk operating system for most of it's life) stored files is somewhat interesting. Each file has a name (up to 30 characters) and also a <em>type code</em>. 8 of them were defined but only 4 of them mattered:</p>
<ul>
<li>I (Integer BASIC program)</li>
<li>A (Applesoft BASIC program)</li>
<li>B (Binary files; either assembled programs or data)</li>
<li>T (ASCII text files)</li>
</ul>
<p>Apple DOS had some specific commands that interacted with these types. For instance, the <code>RUN</code> command worked on both Interger BASIC and Applesoft BASIC programs, and chose which one to use. <code>BRUN</code>, <em>binary run</em>, only worked on binary files. <code>OPEN</code>, <code>READ</code>, <code>WRITE</code>, and <code>CLOSE</code> all worked only on ASCII text files.</p>
<p><strong>The types more served as a way to help the operating system more so than you.</strong> This is especially evident in the late 80's and early 90's HP calculators such as the HP-28c and the HP-48GX. These calculators didn't have disks, but they did have persistent memory that could store objects into folders much like a computer.</p>
<p>These calculators used Reverse Polish Notation. Essentially, you do math by placing objects on the stack and then executing commands, which take things from the stack and put a new thing on. An <em>object</em> in RPN is something you placed on the stack. The HP-48's Advanced User's Reference Manual lists 32 distinct types, including real numbers, complex numbers, character strings, arrays, lists, variable names, executable programs, graphics objects, directories, etc. A <em>command</em> could be, say, <code>ADD</code> or some fancy plotting calculus stuff. Whatever they were, they needed to know what types they were dealing with so that they could either reject the input or properly work with it.</p>
<p>Like the Apple II, just having an integer for a type is perfectly okay because the types don't serve the user. They're just there so the operating system knows what a given chunk of bytes on the stack <em>is</em>. There are a few reserved spots for custom types, but for the most parts new types aren't expected to ever be added, nor should they be.</p>
<h3>File Extensions</h3>
<p><img alt="CP/M disk listing as seen on an Amstrad CPC" src="https://invisibleup.com/articles/34/cpm.gif"></p>
<p><strong>Used in</strong>: AMSDOS (Amstrad CPC), CP/M, MS-DOS, etc.</p>
<p>Microcomputers really started to gain in popularity with the likes of the ZX Spectrum, the Amstrad CPC and the Commodore 64 among others. These were fairly cheap and simple computers. When first launched, these came with nothing but cassette tape inputs, as disks were too expensive.</p>
<p>On these computers, you'd attach a cassette player using a standard AUX cord (although some, like the CPC, had a cassette player built in), and the computer would instruct you when to start and stop the tape. These cassette players usually came with a little counter that rolled up as the tape progressed, to help you tell where the tape was. When you insert a tape, you reset the counter to zero. When you want to <em>make</em> a file, you'd write down what the counter read, then save the file. To <em>load a specific file</em>, you'd seek the tape until you're at the location you've written down, then start reading.</p>
<p>More advanced computers such as the Amstrad CPC instead saved <a href="http://www.cpcwiki.eu/index.php/AMSDOS_Header">a header</a> with each file containing, among other things, a file name and extension. If asked for a specific file it could just read the tape until it found it. Later these computers gained disk drives, and any ad-hoc tape fiddling was replaced with a proper file system such as <a href="https://en.wikipedia.org/wiki/File_Allocation_Table">FAT</a> or <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a> that stored <em>where</em> a file was on a given disk and <em>what is was called</em>.</p>
<p>File codes are limited. It is nigh-on impossible to add more ones. What you have is what you got. So... what if we just made the codes out of letters? A couple of them? And they could be anything. Then programmers could come up with whatever file extensions they want and that's okay.</p>
<p>Suppose, in MS-DOS, you have a file named <code>REPORT.TXT</code>. <code>REPORT</code> is the file name, <code>TXT</code> is the extension. <strong>File extensions give an easy, consistent indicator of what a file contains.</strong> A <code>TXT</code> file contains text, a <code>BMP</code> file is a bitmap, etc. </p>
<p>Some file extensions, like <code>EXE</code>, <code>BAT</code>, <code>SYS</code> and <code>COM</code> had special meaning much in the same way that the Apple DOS codes had special meanings, but other than that they're just there to help the user. <strong>The user had to manually choose which program to use.</strong> This allowed for the user to choose what view or editor to use depending on what would be the most helpful. Unfortunately, there were no default programs. If the user didn't know which program, say, a <code>VIZ</code> file is for, they're out of luck. Is it a visualization? Some manga thing? The digital manifestation of a cute internet ghost who's staying up way too late geeking out about old computers? <em>The world may never know...</em></p>
<h3>Creator Codes</h3>
<p><strong>Used in:</strong> Classic Mac OS</p>
<p><img alt="File properties dialog on Classic Mac OS" src="https://invisibleup.com/articles/34/macinfo.gif"></p>
<p>Let's hop on over to the Macintosh for a quick second. It was a newfangled thing in 1984, and it had the opportunity to reinvent the wheel and break compatibility with CP/M and mainframe traditions. And so it did.</p>
<p>The original 128K Macintosh used 400K floppy disks, a not-completely-terrible amount of space for the time. It used the <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a>, which didn't support directories but <em>did</em> support files. It was also completely graphically driven. The Finder was supposed to be the primary way of interacting with files, and the <code>File &gt; Open</code> command could launch the program that made the file. How'd it do that?</p>
<p><strong>Instead of file extensions, the Macintosh used type and creator codes</strong>. These were 4-byte identifiers, much like file extensions, but there were two of them each with a different meaning. The type code was mean to represent the format the data was stored in, used to filter files in the Finder's "Open" dialog. The creator code was meant to indicate the application that created the file, and used by the Finder to choose which specific application to launch. Now, these weren't normally visible to the user. They just saw the file name and a icon for that type.</p>
<p>To do that, the system kept a database of codes and their associated icons and programs. When ran for the first time or moved from disk to disk, <strong>the Finder would read the program data and register in a database what creator codes and file types it supported.</strong> The Finder would then save this information on the disk containing the application. Later, <strong>when the user opened a file, the OS would check its type and creator code against its stored list to determine which application to use.</strong> This worked pretty well.</p>
<p><img alt="ResEdit view" src="https://invisibleup.com/articles/34/macresedit.gif"></p>
<p>A similar system was used for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com/articles/34/">https://invisibleup.com/articles/34/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com/articles/34/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322288</guid>
            <pubDate>Sun, 06 Dec 2020 09:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Greta Thunberg Meets Sir David Attenborough]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322245">thread link</a>) | @maxekman
<br/>
December 6, 2020 | https://www.dn.se/kultur/greta-thunberg-meets-sir-david-attenborough/ | <a href="https://web.archive.org/web/*/https://www.dn.se/kultur/greta-thunberg-meets-sir-david-attenborough/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>All is quiet at Greta Thunberg's home on Kungsholmen in Stockholm. On this day one year ago she was at sea, on a catamaran in the middle of the Atlantic Ocean. Now she has just come home from school. Labrador Roxy is asleep on the couch, and Moses, the golden retriever, has crashed out on the floor. A thousand-piece jigsaw puzzle is spread out over the kitchen table on which Greta lays edge pieces while waiting for Sir David to appear on the computer monitor.</p>
        
    
  
    

        
    
  
    

      <p><strong>This fall, she is the main character</strong> in Nathan Grossman's feature film Greta. He has recently released the film and the book A Life on our Planet.</p>
      <p>In the introduction to the film, Sir David says:</p>
      <p>”The natural world is disappearing. The evidence is all around us, it is happened in my lifetime. I have seen it with my own eyes.”</p>
      <p>The story starts in 1937, the year he turned 11.</p>
      <p>Then: Wilderness on 66 percent of the Earth, a carbon dioxide levels in the atmosphere of 280 ppm.</p>
      <p>And now? Wilderness on 35 percent of the Earth, a carbon dioxide levels in the atmosphere of 415 ppm.</p>
      <p>Just like climate change and the <a href="https://www.weforum.org/agenda/2020/11/covid-19-pandemics-nature-scientists/">ongoing pandemic</a>, the loss of biodiversity is part of a major sustainability crisis caused by humans.</p>
      <figure>
        
    

    

    <p><img src="https://cached-images.bonnier.news/swift/bilder/mly/5a950de3-69ed-4700-9307-45b809f13fe0.jpeg?interpolation=lanczos-none&amp;downsize=1010:*&amp;output-quality=80&amp;output-format=auto" srcset="https://cached-images.bonnier.news/swift/bilder/mly/5a950de3-69ed-4700-9307-45b809f13fe0.jpeg?interpolation=lanczos-none&amp;downsize=770:*&amp;output-quality=80&amp;output-format=auto 770w, https://cached-images.bonnier.news/swift/bilder/mly/5a950de3-69ed-4700-9307-45b809f13fe0.jpeg?interpolation=lanczos-none&amp;downsize=1010:*&amp;output-quality=80&amp;output-format=auto 1010w, https://cached-images.bonnier.news/swift/bilder/mly/5a950de3-69ed-4700-9307-45b809f13fe0.jpeg?interpolation=lanczos-none&amp;downsize=1540:*&amp;output-quality=60&amp;output-format=auto 1540w, https://cached-images.bonnier.news/swift/bilder/mly/5a950de3-69ed-4700-9307-45b809f13fe0.jpeg?interpolation=lanczos-none&amp;downsize=2020:*&amp;output-quality=60&amp;output-format=auto 2020w" sizes="(min-width: 1340px) 1010px, 770px" alt="Greta Thunberg got interested in the climat crisis through films and documentaries like the ones David Attenborugh has made.">

    </p>

        <figcaption>
            Greta Thunberg got interested in the climat crisis through films and documentaries like the ones David Attenborugh has made.
            <span>
              Foto: Roger Turesson
            </span>
        </figcaption>
      </figure>
      <p><strong>The computer pings</strong>, and Gretas kitchen is filled with a familiar voice coming from the speakers. A voice usually accompanied by pictures of vast savannas, colorful coral reefs and mighty animals cheerfully says:</p>
      <p>”Hello, Greta!”</p>
        
    
  
    

        
    
  
    

      <p>DN's Head of Culture Björn Wiman leads the conversation by link from home.</p>
      <p><strong>Björn Wiman: ”Sir David, how is life for you during the pandemic?”</strong></p>
      <p><strong>David Attenborough:</strong> ”Well, it is not so bad. I am lucky to have a garden. It is not a big garden, but it is a garden, and it has a pond. I get food delivered once a week. And I have a lot to do: I can write here and I record, doing my voiceovers while watching the programs on a screen. So I have been pretty active... I have not actually left the house in eight and a half months, which is extraordinary. But I cannot complain.”</p>
      <p><strong>”Greta, I know that films and documentaries like the ones Sir David has made were what got you interested in this subject from the start.”</strong></p>
      <p><strong>Greta Thunberg:</strong> ”Yes, that is right. It was by watching documentaries and films that I was introduced to the climate crisis and the environmental crisis. That is how I learned and linked the facts to start with. It was a big eye-opener for me.”</p>
      <figure>
        
    

    

    <p><img src="https://cached-images.bonnier.news/swift/bilder/mly/a6b1880d-a857-46c8-b6ee-2e9c7918df82.jpeg?interpolation=lanczos-none&amp;downsize=1010:*&amp;output-quality=80&amp;output-format=auto" srcset="https://cached-images.bonnier.news/swift/bilder/mly/a6b1880d-a857-46c8-b6ee-2e9c7918df82.jpeg?interpolation=lanczos-none&amp;downsize=770:*&amp;output-quality=80&amp;output-format=auto 770w, https://cached-images.bonnier.news/swift/bilder/mly/a6b1880d-a857-46c8-b6ee-2e9c7918df82.jpeg?interpolation=lanczos-none&amp;downsize=1010:*&amp;output-quality=80&amp;output-format=auto 1010w, https://cached-images.bonnier.news/swift/bilder/mly/a6b1880d-a857-46c8-b6ee-2e9c7918df82.jpeg?interpolation=lanczos-none&amp;downsize=1540:*&amp;output-quality=60&amp;output-format=auto 1540w, https://cached-images.bonnier.news/swift/bilder/mly/a6b1880d-a857-46c8-b6ee-2e9c7918df82.jpeg?interpolation=lanczos-none&amp;downsize=2020:*&amp;output-quality=60&amp;output-format=auto 2020w" sizes="(min-width: 1340px) 1010px, 770px" alt="David Attenborough.">

    </p>

        <figcaption>
            David Attenborough.
            <span>
              Foto: Robert Wilson/Contour by Getty Images
            </span>
        </figcaption>
      </figure>
        
  
  

      <p><strong>”This conversation is about two parts of the same major crisis: Climate change and the mass extinction of other species on Earth. My impression is that the climate crisis sometimes takes up a disproportionate amount of space and that too little attention is focused on the interaction between these two crises. Do you agree?”</strong></p>
      <p><strong>GT:</strong> ”These crises are interconnected. We cannot communicate one crisis without communicating the other. Unfortunately, the media today works in such a way that we want simple and click-friendly headlines. That can make it difficult to explain complex issues, and this is a very complicated issue. We need to connect the information: This is not one crisis, it is not two or three separate crises. This is a symptom of a much bigger issue.”</p>
      <figure>
        
    

    

    <p><img src="https://cached-images.bonnier.news/swift/bilder/mly/34d64774-6b5a-4b0f-a720-ce311aea9c8d.jpeg?interpolation=lanczos-none&amp;downsize=1010:*&amp;output-quality=80&amp;output-format=auto" srcset="https://cached-images.bonnier.news/swift/bilder/mly/34d64774-6b5a-4b0f-a720-ce311aea9c8d.jpeg?interpolation=lanczos-none&amp;downsize=770:*&amp;output-quality=80&amp;output-format=auto 770w, https://cached-images.bonnier.news/swift/bilder/mly/34d64774-6b5a-4b0f-a720-ce311aea9c8d.jpeg?interpolation=lanczos-none&amp;downsize=1010:*&amp;output-quality=80&amp;output-format=auto 1010w, https://cached-images.bonnier.news/swift/bilder/mly/34d64774-6b5a-4b0f-a720-ce311aea9c8d.jpeg?interpolation=lanczos-none&amp;downsize=1540:*&amp;output-quality=60&amp;output-format=auto 1540w, https://cached-images.bonnier.news/swift/bilder/mly/34d64774-6b5a-4b0f-a720-ce311aea9c8d.jpeg?interpolation=lanczos-none&amp;downsize=2020:*&amp;output-quality=60&amp;output-format=auto 2020w" sizes="(min-width: 1340px) 1010px, 770px" alt="Greta Thunberg and Sir David Attenborough in a digital conversation lead by DN's Head of Culture Björn Wiman.">

    </p>

        <figcaption>
            Greta Thunberg and Sir David Attenborough in a digital conversation lead by DN's Head of Culture Björn Wiman.
            <span>
              Foto: Roger Turesson
            </span>
        </figcaption>
      </figure>
        
    
  
    

        
    
  
    

      <p><strong>”Do you think, Greta, that there is too much focus on the ”nature side” of this issue – and too little on the consequences for human civilization and the future of humanity?”</strong></p>
      <p><strong>GT:</strong> ”No, I do not think there is too much focus on nature. I think there is too little focus on nature.”</p>
      <p><strong>DA:</strong> ”Yes, that is right.”</p>
      <p><strong>GT:</strong> ”There is too little focus on all aspects of this crisis.”</p>
        
  
  

      <p><strong>”Does that also apply to the ”solution side” of this problem? You sometimes hear ‘the solution can be found in new technological systems’ or ‘the solution is that we change our way of life’.”</strong></p>
      <p><strong>DA:</strong> ”There is not one single solution. There are a number of different solutions because there are a lot of problems. Fishing has a set of problems, carbon dioxide emissions have different problems, the way we treat agricultural land. The fuel and energy industries have their own challenges. So there is not just one miraculous action that allows us to say, ‘Right, bingo, there we have it! We have resolved the issue.’ It is not like that! There are millions of issues.”</p>
      <p><strong>GT:</strong> ”Exactly. Sometimes it feels like we are wasting the little time we have now by arguing about what solution is best. ‘We shouldn not be doing this because this is better.’ As if we had a choice! As if we can decide for ourselves what we need to do, and as if there is one magical solution that will fix everything. We need to get away from that narrative, we need to leave that idea behind us.”</p>
      <p><strong>DA:</strong> ”Yes, I agree. And at the end of the day, you know, it is a big world. The only thing we can do – what you, Greta, are particularly good at – is to ensure that people around the world see what the problem is. We have to be persistent, and we have to make sure there is a large democratic multitude of voices saying 'do something, do something, do something'. We have to keep that choir alive, or those with power will not react. But even when they do react, it is extremely difficult to reach agreement on how we should treat the oceans or the atmosphere.”</p>
      <p><strong>GT:</strong> ”Yes. For a crisis as complex as this one, which we do not fully understand – for there will always be things we are unaware of – we must bring together all the experts. We have to deal with the crisis as a crisis and work together from there. We cannot expect to have all the answers delivered to us, for someone to say, ‘This is what we need to do. This is going to solve the problem.’ We have to find the answers along the way.”</p>
        
    
  
    

        
    
  
    

      <figure>
        
    

    

    <p><img src="https://cached-images.bonnier.news/swift/bilder/mly/8eacd999-122a-4cb8-9e6f-f1885d9ed266.jpeg?interpolation=lanczos-none&amp;downsize=1010:*&amp;output-quality=80&amp;output-format=auto" srcset="https://cached-images.bonnier.news/swift/bilder/mly/8eacd999-122a-4cb8-9e6f-f1885d9ed266.jpeg?interpolation=lanczos-none&amp;downsize=770:*&amp;output-quality=80&amp;output-format=auto 770w, https://cached-images.bonnier.news/swift/bilder/mly/8eacd999-122a-4cb8-9e6f-f1885d9ed266.jpeg?interpolation=lanczos-none&amp;downsize=1010:*&amp;output-quality=80&amp;output-format=auto 1010w, https://cached-images.bonnier.news/swift/bilder/mly/8eacd999-122a-4cb8-9e6f-f1885d9ed266.jpeg?interpolation=lanczos-none&amp;downsize=1540:*&amp;output-quality=60&amp;output-format=auto 1540w, https://cached-images.bonnier.news/swift/bilder/mly/8eacd999-122a-4cb8-9e6f-f1885d9ed266.jpeg?interpolation=lanczos-none&amp;downsize=2020:*&amp;output-quality=60&amp;output-format=auto 2020w" sizes="(min-width: 1340px) 1010px, 770px" alt="Greta Thunberg and David Attenborough portrayed together by the street artist Bambi in London.">

    </p>

        <figcaption>
            Greta Thunberg and David Attenborough portrayed together by the street artist Bambi in London.
            <span>
              Foto: Marc Boettcher/Alamy
            </span>
        </figcaption>
      </figure>
      <p><strong>”In the communications industry, which you are both part of in some way, the balance between the message of 'apocalyptic' disaster and the constructive tone i often discussed. How do you view that conflict?”</strong></p>
      <p><strong>GT:</strong> ”I think we simply need to tell the truth. We should be adult enough to handle the truth. And the truth can be quite frightening in some ways – but it is also hopeful. There is hope. And we should simply communicate the truth to get the whole picture.”</p>
      <p><strong>DA:</strong> ”Yes. And we cannot expect it to happen overnight, or in a year, or even in a decade. That we are going to solve all the problems. But there have been major changes already... I remember that ten years ago it was considered strange to invest in wind power and solar panels. But it actually happened! And veganism – you are a vegan, Greta – I mean: It has happened! So changes are happening, they are not sufficient, and they are not dramatic enough, but... We all move in our own circles, so it is hard to generalize. But in my circles I meet far more people who understand the problems now, far more people who do what they can in their own lives.”</p>
        <div>
    <div>
        <div>
          <figure>
            <div data-original-src="https://cached-images.bonnier.news/swift/bilder/mly/1ac6f089-98c0-4d83-9796-0d5cb26ac6fd.jpeg?output-quality=80&amp;output-format=auto" data-image-class="picture__img picture__img--center" data-image-parent-class="picture--placeholder-black">
                  
    

    

    

            </div>
            <figcaption>
              
  <strong>Bild <span>1</span> av 2</strong>
    <span>For sixty years David Attenborough has been showing modern man life in the wild – and has long warned us about the damage we are doing to nature. The picture is from his new book A Life on our Planet.</span>


            </figcaption>
          </figure>
        </div>
        
    </div>

    <nav>
      
      
      
    </nav>
  </div>

      <p><strong>”You both have experience of meeting world-leading politicians, those who are poised to lead the world's transformation. What is your impression of their general knowledge of the climate and sustainability crisis?”</strong></p>
      <p><strong>DA:</strong> ”It is hard for me to say, because I am the one talking to them. They are not talking to me. It is a great privilege to speak with President Obama, for example, and those I have met have treated me very politely. But I cannot tell if they are knowledgeable or not. I mean, they say the right things. They say, ‘Yes, we agree’ and ‘We are going to do something’. But they are politicians, they are not going to commit to anything when they are being filmed. At least they have not done so in front of me. Maybe they have said something to Greta?”</p>
      <p><strong>GT:</strong> ”I have the same opinion as you...”</p>
      <p><strong>”Greta, when you spoke in the British Parliament, you used a rhetorical question. You said, ‘Is my microphone working?’. Why did you do that?”</strong></p>
      <p><strong>GT:</strong> ”Because it feels like the message is not getting through. We say the same thing over and over again but it does not seem like anyone is listening. Nobody does anything. So that is why I asked the rhetorical question, is the microphone working, do you really hear us?’ Because it sometimes feels like we speak a completely different language.”</p>
        
    
  
    

        
    
  
    

      <p><strong>DA:</strong> ”Exactly. And in a way, maybe we do. Because the language we use is direct. And democracy is the lesser of the evils when it comes to ways of governing, but it is still pretty bad. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dn.se/kultur/greta-thunberg-meets-sir-david-attenborough/">https://www.dn.se/kultur/greta-thunberg-meets-sir-david-attenborough/</a></em></p>]]>
            </description>
            <link>https://www.dn.se/kultur/greta-thunberg-meets-sir-david-attenborough/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322245</guid>
            <pubDate>Sun, 06 Dec 2020 09:17:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monopoly Technology Platforms Are Colonizing Education]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25322202">thread link</a>) | @partingshots
<br/>
December 6, 2020 | https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/ | <a href="https://web.archive.org/web/*/https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-746">
	<div>
		
		<div>
			<p>Perspectives<em>&nbsp;is an opportunity for Fellows and others to share their ideas in short, accessible essays.&nbsp;IPE/BC Fellows hold a range of views and interests relative to public education.</em></p>
<p><strong>Monopoly Technology Platforms are Colonizing Education</strong></p>
<p><strong>By Larry Kuehn</strong></p>
<p>The exposés of abuse by social media corporations like Google and Facebook have finally brought attention to the dangers of monopolies over our communications. The way these monopolies have been colonizing public education has, however, gone almost unnoticed. This is rampant privatization sneaking in as essential to “21<sup>st</sup> Century learning.”</p>
<p>The top five global capital corporations are technology platforms—Apple, Google, Microsoft, Amazon and Facebook. Platforms are a host for a variety of services and uses. All of the big five platform corporations have become too large in a short period of time to have any significant competition outside of this group. They compete against one another, adding services to secure their monopoly by offering users everything they do online.</p>
<p>If a new service is developed that seems to be gaining users, or that competes with an element of their platform, it is purchased and integrated into the platform—avoiding new competitors. Alternatively, they use their massive resources to develop a comparable app and push the potential competitor aside.</p>
<p>Snicek, in <a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862"><em>Platform Capitalism</em></a>, points out that the development of these monopolies “introduces new tendencies within capitalism that pose significant challenges to a post-capitalist future.” Building public cooperative platforms becomes an impossible dream.</p>
<p>No surprise—these platforms have moved to colonize education. Public education represents a big chunk of potential revenue. Just as importantly, schools are where one can find most of the future potential consumers and users of the platform services.</p>
<p>Colonization is a process where a significant force moves into an area and dominates. It takes over not only the production and resources, but imposes—often by stealth and power—the processes and approaches and even values of the social and cultural environment. And, dominate is what the monopoly platforms are on track to do in public education.</p>
<p><img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-400x200.png" alt="" width="262" height="131" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-400x200.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-768x384.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education.png 800w" sizes="(max-width: 262px) 100vw, 262px">The most successful colonizer has been Google. A recent report indicates that Google’s <em>G-Suite for Education</em> is being used by half the teachers and students in the U.S. Canada is fast approaching the same level of use. It includes a range of free software tools that can be used by students and teachers—word processing, presentations, spread sheets and the like. G-Suite incorporates “Classroom,” an integrated learning management system that keeps track of grades, attendance and more. And, of course, YouTube is linked to student use.</p>
<p>New elements are added frequently. “Google Sites” is promoted for student e-portfolios, because “every student should publish for the world.” Google acquired Workbench, integrated with Google Classroom to give “lessons connected to a variety of ‘maker’ activities focused on STEM.” It is part of Google’s plan to “help schools and educators address their universal needs around education content.”</p>
<p>Google, rather than democratic public institutions, therefore shapes what is on offer. Google’s position as colonizer is strengthened by the hardware increasingly used in schools—the Google Chromebook. <img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-400x222.png" alt="" width="346" height="192" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-400x222.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-768x425.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000.png 1000w" sizes="(max-width: 346px) 100vw, 346px">It is less expensive than other computers because much of what it needs to operate is supplied by Google in the cloud—operating software, applications and memory. No need to build those into the computer.&nbsp; According to market reports, Chromebooks make up the majority of all computers sold to schools in the U.S. and are marketed globally.</p>
<p>However, one must have a gmail account to use these Google tools—so if a parent wants to protect the privacy of their child and refuses a gmail account that kid is left out while the rest of the class works away on their Chromebook and other Google tools. (See <a href="http://s3.documentcloud.org/documents/4497822/GAFE-Information-Letter-and-Consent-Form-page2.pdf">here</a> the kind of consent form parents are asked to sign, giving Google access to acquire and store student information outside of Canada.)</p>
<p><img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-400x70.png" alt="" width="657" height="115" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-400x70.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-768x135.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-1024x180.png 1024w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM.png 1238w" sizes="(max-width: 657px) 100vw, 657px"></p>
<p>Google has even taken up teaching “internet safety,” with a program aimed at reaching 5 million students. Its core is a game for students in Grades three to six to teach them to avoid “schemers, hackers and other bad actors.” However, as critics point out, it doesn’t talk about privacy concerns when users’ personal information and actions are tracked online. Google conveniently ignores its role as a “bad actor.”</p>
<p>A <a href="https://journals.sagepub.com/doi/abs/10.1177/1474904116654917">Swedish study </a>of Google’s strategy concluded that “By making an implicit demarcation between two concepts (your) ‘data’ and (collected) ‘information’ Google can disguise the presence of a business model for online marketing and, at the same time, simulate the practices and ethics of a free public service institution.”</p>
<p>In “<a href="http://2017trends.hackeducation.com/data.html">The Weaponization of Education Data</a>,” Audrey Watters points out “the risk isn’t only hacking.&nbsp; It’s amassing data in the first place. It’s profiling. It’s tracking. It’s surveilling.”</p>
<p>Google isn’t alone in the business of colonizing education and student data—just the most successful so far. One competitor is Microsoft 365 Education, with a promise of “empowering every student on the planet to achieve more” and that it will “unlock limitless learning.”</p>
<p>It’s not an accident that it is “Microsoft 365” that is being pushed. It offers a cloud-based software and cloud storage for your work. It is the new business model for Microsoft: they don’t sell you software, you rent it—and you keep paying for it. And your work isn’t saved on your own computer, so you have to keep up your subscription. Like Google, they are hoping that students will keep using their tools when they finish being students.</p>
<p>Microsoft is imitating much of what Google offers, but by charging for the service rather than trading it for data. It offers apps, educator training and STEM lessons “to enrich science, technology, engineering and math classes.” They offer “budget friendly” Windows 10 devices with licences for Microsoft 365 Education.</p>
<p>The other major tech corporations have programs as well. Apple, for example, was the first into education with the Apple IIe and the “Apple Classroom of Tomorrow” way back in the 1980s. More recently it depended on the ease of use of the iPad, despite its cost, to sell classroom sets along with Pearson curriculum in an <a href="https://www.wired.com/2015/05/los-angeles-edtech/">ill-fated project with Los Angeles schools</a>.</p>
<p>Venture capitalists are hoping to find the magic app that will make a fortune. The potential market is indicated by expenditure of hundreds of millions each year on developing new products. The “winners” are likely to be bought up by one of the major corporations—or find their product idea taken by the monopolies.</p>
<p>Not enough attention is paid by education authorities or researchers to the shaping and distortion of education that is possible—even likely—by this colonization of education by technology monopolies.</p>
<p><em><strong>Larry Kuehn</strong>&nbsp;is an IPE/BC Fellow, IPE/BC director and Director of Research &amp; Technology for the British Columbia Teachers’ Federation.&nbsp;</em></p>


		</div><!-- .entry-content -->

		<!-- .entry-footer -->

		
<!-- .entry-auhtor -->
	</div><!-- .hentry-wrapper -->
</article></div>]]>
            </description>
            <link>https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322202</guid>
            <pubDate>Sun, 06 Dec 2020 09:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VisiData in 60 Seconds]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322091">thread link</a>) | @luu
<br/>
December 6, 2020 | https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/ | <a href="https://web.archive.org/web/*/https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>TL;DR? Here’s a three-step introduction to VisiData.</p><div id="step-1-use-vd-to-open-a-data-file">
<h2>Step 1: Use <code><span>vd</span></code> to open a data file<a href="#step-1-use-vd-to-open-a-data-file" title="Permalink to this headline">¶</a></h2>
<p>Download <a download="" href="https://jsvine.github.io/intro-to-visidata/_downloads/83e70cf67e909f3ac177575439e5f3c5/faa-wildlife-strikes.csv"><code><span>faa-wildlife-strikes.csv</span></code></a>, a dataset of all aircraft-wildlife collisions <a href="https://wildlife.faa.gov/database.aspx">reported to the Federal Aviation Adminsitration</a> between 2010 and mid-2016.</p>
<p>From your terminal, move into the directory where you downloaded the dataset. Then run the following command:</p>
<div><div><pre><span></span>vd faa-wildlife-strikes.csv
</pre></div>
</div>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>|</span><span></span><span> ATYPE        </span><span></span><span>|</span><span></span><span> INCIDENT_DATE     </span><span></span><span>|</span><span></span><span> STATE </span><span></span><span>|</span><span></span><span> AIRPORT            </span><span></span><span>|</span><span></span><span> PHASE_OF_FLT</span><span></span><span>&gt;</span><span> 
</span><span></span><span> BUSINESS           </span><span></span><span></span><span>| PA-28        | 05/22/15 00:00:00 | FL    | VERO BEACH MUNICIP…| APPROACH     ║
</span><span></span><span></span><span> BUSINESS           </span><span></span><span>| BE-1900</span><span>      </span><span>| 06/18/15 00:00:00 | AK    | KENAI MUNICIPAL AR…| APPROACH     ║
</span><span> BUSINESS           </span><span></span><span>| PA-46 MALIBU | 09/20/15 00:00:00 | TX    | DAVID WAYNE HOOKS …|</span><span>              </span><span>║
</span><span> DELTA AIR LINES    </span><span></span><span>| B-717-200    | 11/07/15 00:00:00 | MO    | LAMBERT-ST LOUIS I…| APPROACH     ║
</span><span> BUSINESS           </span><span></span><span>| BE-90 KING   | 12/17/15 00:00:00 | FL    | POMPANO BEACH AIRP…| LANDING ROLL ║
</span><span> DELTA AIR LINES    </span><span></span><span>| B-757</span><span>        </span><span>| 07/17/15 00:00:00 | VI    | HENRY E ROHLSEN AR…|</span><span>              </span><span>║
</span><span> DELTA AIR LINES    </span><span></span><span>| B-717-200    | 08/02/15 00:00:00 | TX    | SAN ANTONIO INTL   | APPROACH     ║
</span><span> BUSINESS           </span><span></span><span>| C-414</span><span>        </span><span>| 08/03/15 00:00:00 | TX    | LONE STAR EXECUTIV…| DEPARTURE    ║
</span><span> ALLEGIANT AIR      </span><span></span><span>| MD-80</span><span>        </span><span>| 09/02/15 00:00:00 | FL    | TAMPA INTL</span><span>         </span><span>| APPROACH     ║
</span><span> TRANS STATES AIRLI…</span><span></span><span>| EMB-145</span><span>      </span><span>| 09/07/15 00:00:00 | MO    | LAMBERT-ST LOUIS I…| APPROACH     ║
</span><span> BUSINESS           </span><span></span><span>| C-172</span><span>        </span><span>| 11/28/15 00:00:00 | FL    | OPA-LOCKA EXECUTIV…| APPROACH     ║
</span><span> GOVERNMENT         </span><span></span><span>| EC120</span><span>        </span><span>| 12/08/15 00:00:00 | CA    | NORMAN Y. MINETA S…|</span><span>              </span><span>║
</span><span> AMERICAN AIRLINES  </span><span></span><span>| A-321</span><span>        </span><span>| 05/06/15 00:00:00 | FL    | FORT LAUDERDALE/HO…| APPROACH     ║
</span><span> EXPRESSJET AIRLINES</span><span></span><span>| CRJ100/200   | 05/06/15 00:00:00 | AR    | FORT SMITH REGIONA…| CLIMB</span><span>        </span><span>║
</span><span> MESA AIRLINES      </span><span></span><span>| CRJ900</span><span>       </span><span>| 05/08/15 00:00:00 | AR    | BILL AND  HILLARY …| LANDING ROLL ║
</span><span> BUSINESS           </span><span></span><span>| HELICOPTER   | 05/06/15 00:00:00 |</span><span>       </span><span>| UNKNOWN</span><span>            </span><span>| En Route     ║
</span><span> DELTA AIR LINES    </span><span></span><span>| A-320</span><span>        </span><span>| 05/07/15 00:00:00 | CA    | METRO OAKLAND INTL |</span><span>              </span><span>║
</span><span> DELTA AIR LINES    </span><span></span><span>| A-320</span><span>        </span><span>| 05/08/15 00:00:00 | UT    | SALT LAKE CITY INTL|</span><span>              </span><span>║
</span><span> LUFTHANSA          </span><span></span><span>| A-380</span><span>        </span><span>| 05/10/15 00:00:00 | TX    | GEORGE BUSH INTERC…| CLIMB</span><span>        </span><span>║
</span><span> BUSINESS           </span><span></span><span>| C-172</span><span>        </span><span>| 05/08/15 00:00:00 | FL    | ORLANDO SANFORD IN…| APPROACH     ║
</span><span> SPIRIT AIRLINES    </span><span></span><span>| A-319</span><span>        </span><span>| 05/10/15 00:00:00 | IL    | CHICAGO O'HARE INT…| CLIMB</span><span>        </span><span>║
</span><span> EXPRESSJET AIRLINES</span><span></span><span>| EMB-145</span><span>      </span><span>| 05/11/15 00:00:00 | AL    | BIRMINGHAM-SHUTTLE…| LANDING ROLL ║
</span><span>1› faa-wildlife-strikes| saul.pw/VisiData v2.0.1 | opening datasets/faa-wildlife        73448 rows </span><span> </span>
</pre>
</div>
</div><div id="step-2-test-drive-a-frequency-table">
<h2>Step 2: Test-drive a frequency table<a href="#step-2-test-drive-a-frequency-table" title="Permalink to this headline">¶</a></h2>
<p>One of VisiData’s strengths is how quickly it lets you summarize your data. Frequency tables are a great example. To create one, press <kbd>Shift+F</kbd>.</p>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>║</span><span></span><span> count♯</span><span></span><span>|</span><span></span><span> percent%</span><span></span><span>|</span><span></span><span> histogram                                         ~</span><span></span><span>║</span><span>        
</span><span></span><span> UNKNOWN            </span><span></span><span></span><span>║ 23076 |   31.42 | ************************************************** ║</span><span>        
</span><span></span><span> SOUTHWEST AIRLINES </span><span></span><span>║  7752 |   10.55 | ****************</span><span>                                   </span><span>║</span><span>        
</span><span></span><span> BUSINESS           </span><span></span><span>║  5868 |    7.99 | ************</span><span>                                       </span><span>║</span><span>        
</span><span></span><span> AMERICAN AIRLINES  </span><span></span><span>║  4337 |    5.90 | *********</span><span>                                          </span><span>║</span><span>        
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>║  2817 |    3.84 | ******</span><span>                                             </span><span>║</span><span>        
</span><span></span><span> FEDEX EXPRESS      </span><span></span><span>║  2709 |    3.69 | *****    </span><span>                                          </span><span>║</span><span>        
</span><span></span><span> UNITED AIRLINES    </span><span></span><span>║  2194 |    2.99 | ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> US AIRWAYS         </span><span></span><span>║  1885 |    2.57 | ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> UPS AIRLINES       </span><span></span><span>║  1773 |    2.41 | ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> SKYWEST AIRLINES   </span><span></span><span>║  1769 |    2.41 | ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> JETBLUE AIRWAYS    </span><span></span><span>║  1740 |    2.37 | ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>║  1347 |    1.83 | **   </span><span>                                              </span><span>║</span><span>        
</span><span></span><span> AMERICAN EAGLE AIR…</span><span></span><span>║  1041 |    1.42 | **</span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> ENVOY AIR          </span><span></span><span>║   883 |    1.20 | *   </span><span>                                               </span><span>║</span><span>        
</span><span></span><span> ALASKA AIRLINES    </span><span></span><span>║   835 |    1.14 | * </span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> REPUBLIC AIRLINES  </span><span></span><span>║   804 |    1.09 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> MESA AIRLINES      </span><span></span><span>║   693 |    0.94 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> AIR WISCONSIN AIRL…</span><span></span><span>║   623 |    0.85 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PSA AIRLINES       </span><span></span><span>║   577 |    0.79 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PRIVATELY OWNED    </span><span></span><span>║   516 |    0.70 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PHI INC            </span><span></span><span>║   491 |    0.67 | *    </span><span>                                              </span><span>║</span><span>        
</span><span></span><span> SHUTTLE AMERICA    </span><span></span><span>║   467 |    0.64 | *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span>2› faa-wildlife-strikes_OPERATOR_freq|</span><span>                         </span><span></span><span>                 F         282 bins </span><span> </span>
</pre>
</div>
</div><div id="step-3-read-visidata-s-manual-page">
<h2>Step 3: Read VisiData’s manual page<a href="#step-3-read-visidata-s-manual-page" title="Permalink to this headline">¶</a></h2>
<p>VisiData’s “<a href="http://visidata.org/man/">quick reference guide</a>” enumerates all of VisiData’s commands and features. You can <a href="http://visidata.org/man/">read it online</a> or access it from anywhere within VisiData by pressing the <kbd>F1</kbd> key or typing <kbd>Control-h</kbd>:</p>
<div>
<pre><span>NAME</span>                     
     <span>VisiData</span> -- a terminal utility for exploring and arranging tabular data                        
<span>SYNOPSIS</span>                 
     <span>vd</span> [<span>options</span>] [<span>input</span> ...]                     
     <span>vd</span> [<span>options</span>] <span>--play</span> <span>cmdlog</span> [<span>-w</span> <span>waitsecs</span>] [<span>--batch</span>] [<span>-o</span> <span>output</span>] [<span>field</span><span></span><span></span><span>=</span><span></span><span></span><span>value</span>]                   
     <span>vd</span> [<span>options</span>] [<span>input</span> ...] <span>+</span><span></span><span></span><span>toplevel</span>:<span>subsheet</span>:<span>col</span>:<span>row</span>                                            
<span>DESCRIPTION</span>              
     <span>VisiData</span> is an easy-to-use multipurpose tool to explore, clean, edit, and restructure          
     data. Rows can be selected, filtered, and grouped; columns can be rearranged, trans-           
     formed, and derived via regex or Python expressions; and workflows can be saved, doc-          
     umented, and replayed.                       
   <span>REPLAY</span> <span>MODE</span>           
     <span>-p</span>, <span>--play</span>=<span>cmdlog</span>       replay a saved <span>cmdlog</span> within the interface                             
     <span>-w</span>, <span>--replay-wait</span>=<span>seconds</span>                    
                             wait <span>seconds</span> between commands                                          
     <span>-b</span>, <span>--batch</span>             replay in batch mode (with no interface)                               
     <span>-o</span>, <span>--output</span>=<span>file</span>       save final visible sheet to <span>file</span> as .tsv                               
:Usage: .No normal_text ... (#659)                
Usage: .No normal_text ... (#1126)                
</pre>
</div>
<div>
<p>Note</p>
<p>If you open the manual from within VisiData it will launch in your terminal’s “pager” program —&nbsp;typically the <a href="https://en.wikipedia.org/wiki/Less_(Unix)">less program</a>. To move around:</p>
<table>
<colgroup>
<col width="55%">
<col width="45%">
</colgroup>
<thead>
<tr><th>Keystroke(s)</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr><td><kbd>Space</kbd> / <kbd>b</kbd></td>
<td>Scroll forward/backward</td>
</tr>
<tr><td><kbd>/</kbd> + <em>search term</em> + <kbd>Enter</kbd></td>
<td>Search for <em>search term</em></td>
</tr>
<tr><td><kbd>n</kbd> / <kbd>N</kbd></td>
<td>Go to next/previous search match</td>
</tr>
<tr><td><kbd>q</kbd></td>
<td>Exit and return to VisiData</td>
</tr>
</tbody>
</table>
<p>You can find additional commands <a href="https://en.wikipedia.org/wiki/Less_(Unix)#Frequently_used_commands">here</a>.</p>
</div>
</div></div>]]>
            </description>
            <link>https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322091</guid>
            <pubDate>Sun, 06 Dec 2020 08:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gemoetry vs. Gerrymandering, a mathematical forensic approach [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25322085">thread link</a>) | @Manheim
<br/>
December 6, 2020 | http://www.cencomfut.com/ScientificAmerican1118-48.pdf | <a href="https://web.archive.org/web/*/http://www.cencomfut.com/ScientificAmerican1118-48.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>,‹/GÁVÂ€ÒÊAÜ›ÉøôÀK&amp;±R¥eO
ÍSÞv›i€|§©‘ò8	9&nbsp;€™¥â4êÕ¤¾UV¦’ –¦Û�"/¼H±ÀE2‚[Ã+5µ1ZÕ4¨`?A\¡’¬ïz ¦˜¨äªMÁ‹ïèlLÀDJf�JÝ|ÌVXÝ9œ"G-Icc§T™“Ÿ¬`#„_¯–â#MVSÃ˜ó­àßqmù×º¬–QòËQëÕ\Î…“Ø HÜêç€ˆ9‘Ê¾_ˆfê&nbsp;¥4¦”¨ê÷T‹êÍ„ò4ÞD&nbsp;³Ÿz¢ƒL ¬E–Ñ{�ûÛ�A&amp;Íp†ÌW§Y_ÃT¨×“…R§½ñ(%<c4(9™æv$øv‹ïƒq�‚Çs‡ Ô×Ä$)¬|ÌÊ.o0iÀÁÀmÂ,Írñ="">¸R…H�æ™‚Nöä9à’ÊáÔ*Œª.P„:šÍÂ²µÉ¢;HÁ¤¬‚µ
&amp;•2š£ÞL”aw?ðdÏ&nbsp;#€AÛ&lt;Ü''S2™jÙÚ”tTLµ<g´ 7�˜:ˆ&4‰Á„n0ŸÙé="" ¯="" sšÀhÎÄz8œ="" {£“ià²¬µ5Ëq="" �ÐîÉ¸$sëœx˜m¼@¶bˆ§ejjm�Œusßˆ„éŸºÑgf�­rh†Ÿnx$™„*™djéj�†d¦˜ó#sÒòmÖÜð"ð‚ÈÑlºgq×æfæ–{x`f–="" vgq�¦i€v¸¿Óa�ÐÞo3é�dx‰Ûa%ÏÔ;k„$ùi<§hè0i„„…b�tÉbn[oÈ="" Àg’="" ›!ÃfevðœÔ«pxøŒn�7ˆØ`$�"x5mtp<="" 5vŸ†iÂÜ�@ì`�]÷8å™w,Š="" g(Æ:Æp&Úõ-˜urÏi3°›€Û—a€“ª="" nn›Õ­mÕô…z“$ažqþÎ<òa#£t×«¯wˆqdü,Âà�ãñÞ0p„j‚z£oÂ¦ˆl˜hÞ�™Á#aš¨="" §ph“ñå"ò;o€‚="" º¹©]teÐmãÌ|¢="ÓþÐ=EðDƒ—…b@" Þy¸"="" ò;`#a7¼Ñ¬Õ]d"¹="" ã¤tŽfó#l”mo:œjš„¡$ª4�“uˆ2`múàjhº#!³ípyu¼ƒ©°'¨¶Ø="" ÌÐf‡zd="" ‚Ó´Ì="" ß·\h%‚�Ðxmº`="" ‚jr€u%€¦Ë×pçéËa5fjª”ÝÌ1%tí§£rŽü°p‚p¡š§]›f’«'r�v•hŽ„ôÀjÏÆ–·ÝªÔÈ*½v’:uv—®iÊÈ%ôòmf¯�ªun6pbì?Î8„ê4x®f¦ti4j–a`="" Øo3éé€Ša0‚6¦f�:Úeêj€Çaªäà~ã ‹939ƒ™vot¨óy@ØÚñªwÀetüòšt¡ÉÊ="" mfy="" Ì^¯€”pxÇ³´+a="" suÑgÃºg7&ðlf="" ¦Ú‚u§”\�ah4®�|8ênØ$¸„Îgs,Ò�r7ï¾qa="" ÎæÓ&ŒÌÁ:ÓsÔÄ(“$ÄuœerÑ*j€="" ”x~‹Üv8d="" š³\Ãu‚uõ¶¯1¿c×$µ±Õt_t="" x(ü•Å° ƒ[‡¦humuhfäjŽ]0‰a&à\="" x0¬áê1¨ìÄ;ÎfÝ9–À”ml="" •g²ôë="E,¥Px;“.2N¢Ÿˆ�4‰w­€”‚LµØÊ�dÂàX°zÆ$">-MêøEcN¥Õ; ›o6 t'+p¤lÍ"Å&lt;&amp;$’“øù“z”g*ŠlÃ$¤×÷@“1Ð� ïqË‚[Ÿ¬Æ™§IÅ:®¬´Ø�AX)‚G0
ãžØÉA¡™‘àDZç·èp! ™ó|Qu2G�2
sa«ryÛoŽ
A($¹¤J
ÔÐ´$¶�ngÌb= zàB"#ßz	]¨Ô* fÔˆ­6…ƒqúà‘Â	BeÐ1
@H
à
ÁõÀAlæbžJ¤Ô�­&nbsp;Øó(/¹zÛc4…f˜e"d;Žñ€”Ir3”&nbsp;²€Ê	h¿RLo'4BÈ$Ê­™Pî,®†�€77¶Üã<g"ùªŽj€°‚u{Âú¬.äp"pw]rïl�2oÃâ0hòa§w¬éq øpÔÙ¤;oñå6Á"”="" Ãª®¤.|õ˜Ûoy—ÒzÏ„†b²Ó¦hz�.Šh±´È0hÊ="" ö~‡9u­saÖªck.À�Ä¾¼ÀÀ”e²‚®jtv¸ðœ’@-ª�aÎ0„w.‹›¦ê5³î·="" ûÑÈÆÜùòÀmŒÐy^r»Ñgz…§p="" ª<Þ‘Ë¯<è("«3="sH°`ê|¤{&nbsp;" Ç#'i¾$xté8Ðv�="" 'oË,½õœ±myòêvì:\zfÆ0]³1Âèæ¥xé+h1æ‚="@8ËPN™*BŠéƒ" @="" �×bµq‘€f±rß„0:õÀd‚eÅ¸.*|*ðÔˆ÷="" ¦="" \‰ã¦il ‰Êð�Âe4¥åevˆ¸="" h1…£¶="" �Øa?t¡âŸ6«à÷íÎ0id="" ¼ß†fÐë%µz="" i¥”‡p¨fó˜“ºƒÓ™ðaznzµ<Ã1s%h="" ÐÓ="" oaÍÿ�˜ÈÖ3hŸ¬="" (a"©›u="" v¤§l�§an’zÆl šø%aíf‡¦åjs`al]t�åh˜Úc$]ûg2st)Ô¨º²†^f="" úú`d–nôoÝÆ[0ôÞ›Ö£›p="" èp…bÌò}Ó�äx4‘š="" 4‡ ¦zq¡bˆÓb-‚kˆao*à‚Ðuwf’$´îks¡.—jhÖxë="" “é×$ã*•³="" t="" ™tù†Ð-¶þ‡˜Àea-ªž5[@[l^y¾3dšÔÍt™îm½®0”vs05–ovl="" ‰‰ØÇ8Û$¨Ôû¢Ën�$µÍ÷o„�ø`!0‚m•¯þ¤êm™[u6bu,�2�;‰¿¦�âavetÒÒÒeŒÈqyç6&:à!+f�ótuÕh'i’ˆa¤�Á3Ó(#€auijÀphürldžx$ffª­j€±"o$€$g¬`b2‚�l*‚l”›6±çòÀÉ.j±§®£+Å="" ¤µä²Úúd)$o¡À”‚|�ixu|½1j-hpzâä‰½°h‚#«@êm,–d‰Ýt�'®="" 9!}á3h*@ˆ3ÎÌßkÛ="" ÐbÕþžªˆ‡b£d^="" ÎpÉ="" <hs ¯Ì¨0.aÛ”mð!6a7ñüßƒ¡u¸pÚdm{ßã¶k�l="" iš�¯�zdéËrÌx¼˜ÔzŠ¬€‚qaŽ="" e¶ž$f¶�¿ªÍ2ùupÌo¨{��ú_ã‚)p’šÈz4i(yÉ´ÀË|™Ñ“-Ã©Ñ­s5%Š‚a’`cy°9`".‚?ˆ«±z’sn€b�77‰õû_tj"˜r¾ø="" Äz£q¬xÓu¹°Ÿ€™õ¶nfdøi“gzµ$="" £}6�sÎÝðÄ="" �«­Þ�f="" îÇmŠÅûi1Üf="" q\Å\¥ô@wnlbdÞâ`ôôÀ@ÙbÐz1t‚—ƒk~·¹í€Šgwvñi¼="" â%�!Óß®4jg‰Ö†e¡¼dÐi¨Ëî•&Ö•“°Àh7a="">ÉCK,³À�G˜)˜¶ããÐôÀJÉš–sÇ­OpXÈ0Á�&gt;QÔF&nbsp;±î#N½&lt;ÆerÏá;QO	Š³P¾‘r¨`/�uA:pü�v¥O1�+W1Ih³¤eË‚,P”
5èŽ XRVô˜�*µî:‘ÏÐGQÊ¶…Òúƒ2�[B…¾üÉž÷Á£„¢;QÖ¦åHù\nOç‚F‚Â8G­Çšµœ°¶’(@#œ;&amp;Á%šÓÎÒÍ4›Î§IÁƒðƒ‚NL&nbsp;‹Z"�Uéæ'}ØÛò#A–cEV&nbsp;ÀÏÊ¯¼`"”jBÓªÀ4’ºF“ÈZ9[AŸá4_7G7SSV¢Ž¨°
»¹ÚÓµúà Eå«'@CÔ“5^úm'c¶ÿ,p‚ƒU©8F#R
,oˆ6úúœH¸¾NˆÉ6V±&gt;�™%ÊÀÔž§ãÏ²„ŽF�¡åYQn/þÐïÈÏL&nbsp;U^…j&nbsp;*�‘2'TA›~ç“Q
‹O1ú`‘Â	¼Ö4ÃÌÂ´‹Ii¼G®ÑƒI”~,µëeËå`ÖO2)0¬Ãeb6ž$øa³ô­Tðë_œêÐÐ	PEŒ¾²1Å5/—éé™,$^Øÿ~˜d‚??š§–F/(ƒö7Á â	ƒ‡ã9=,&nbsp;k:+	Ò,n6#o†
$\ œë°Hv†ÑRÇ&nbsp;çò&lt;dÇr
€LøÕªi±,|g¯yÛ]ÐH3™x¬¯&amp;¢U–d,îÀ–�ùD «?•
åËAVX$n&amp;ÖØ÷À@�J´œÉJPRÚ†Û{±^˜f‚,Âf*1
`¬ÙHïÌör‚S’§à‚ZjbÑs½½-Â	UH¦ÀòÉ˜$�o×à‡Ò¬­Yë3VªÁÎë©Ï”²®Àì	
²	 ¤x‚X«ºy5°�åbÃæAœY&nbsp;ž¸†X©§ù`T
;°ÜQn‘€”Bã
Ä3™ºJŠ+áx•5!ÔÎ“ŽÖ7ôÁ¤:IAfY£O4‡RëPn “ òù`“†è!eÔ—©¼�ffEÇÃ‚M“zt“Ãv’L�1µÎø�½¸¨«¤”25€A6&lt;ð”6k9S7áš—X?‰MàFpIŸÛ$Õ©_Ê)�S&amp;d‹w·|!El½n,ÕiW…¢ÇM0§´Ë½¹`!‚;†+Set€ÄÌßìó9à OTëj_	$8PA ›r“Ï¾T&nbsp;ƒ^¦�àÁm~{ÌséÓ‚]ŸÃQpT	Õrc¡œÈpjÔs_yªìÕ[Ah…ÝCç'Ó›ò‚7Œpz|jƒeª’Â³údøI´rï$e³dMS1¢&nbsp;¨÷`ŸÄ	¼~˜	r‚a§–Ù.ÄµbþŽC­¹l$í8	EYâ5\Àg
˜VÑ=¯¶&nbsp;—år©�FefÑR˜›ù—°åËmÁÀ”`J8mL¡ÿ‚wk²—z’ú��-¶ °´Ÿhx‡ÈÔÿKDn'V“ýÇ-QÕª'œÀb¡ì�0a6âBÊôM*5vŠci/mRŸ\úm{i´=ÍÅÁ¤áÄÀ^„üNŸ�E³
uÔ	`k±s÷¹v½°IÉX¤ëÄ²ë�@®§0d‚z‘€”n‚Äs	÷�YÇ»?Ò#bO—Ðœe7�Y?
)™JU«X�Î×úïÛ)mºÊ…ieÜ×�(®Zäˆƒ&gt;¶Á&nbsp;‚Çóùµ§’55@ÉM@C¸f8æ4Ìž±€’M�J3‚­zz¨»Ó
ÜKÌ©þ«` PAð¼,¡©D˜uƒ7kÚýäà!¢	ú’¥´¦áuÀ�0EÏÇ-�åëRÈ=JuZ�Ž¦°óî’wë;L	ÀHA5e²2R«RµFT&gt;:Z´«#�¤ÔKj€LQ8	  ²Ü‘aZ§òÈ
³È!‚À&amp;EŒÀN
•]€jM2¼ævì"G©ÀE’
ÔjV§›¢ƒþøJ•3¯RIì$G\}È%|O.3@¢°…@7Q¹�Ì	Ž‡,?ý&gt;�Ï5jŠjS�D!VbXGH‰ç4Üb('ÊùFã…:èêQ[T*�Am®±Ëœ`’¢PN\V�Þéx/¨�:å`(AîOÃ|¢‚GÃ&lt;´Q˜bÂTAéyÞÃòÁ¤„&nbsp;ZhP(¾‡
Nàõ‹ÞzÛ”‚oöE+ÒËEbš•	$ì	�Qß¤³$ù®48+TlË¨¤@ðàðtO&gt;{`#.ŒÐM&lt;3Š/S˜'JŠ®´¦X¹=&nbsp;'œ˜	 Ê	Zæš¥v4T•)®Ëçb4‚
ù`ÑÊ	Ã‰¨K
^ B¤,@“–	A%|¿ƒBš"Šå^I-»_x9Ç#€‰ášâ´†a(–Ô™Æâ@*†ýõ€äÆQ7Ac«œJl(&amp;¥je�.G»ªî4–’'sÏ‘('­Èæ\‹ ¹ö@Um·1‚F,PKóü.ŒT.$U0ÀòAÌN2Mõ8E©¦¥4QQ”Í•|Àz©Qóí€ŠY-
ž3«m2@¸3±Õ·#‚K&amp;Å
˜¨.�5i]W0WÍm¿20h�K_0«T
çËa;‚|Ý6ç×&nbsp;°¬ÖF‡
9…oÃðüZ¨ÆIvoxÏáL	M‘+ðÌÓ5ZKDE[ª†¾«r?‡– POm]³µÚ¡Ñ@H–×7ø˜ëß*e
”êf3j§òÕ˜‹‰&amp;&amp;G)‹OL5A&gt;æéø¤)�
µ¸ß|²‚fËQ&amp;®eF¥f‹³JÝbiŽVß¾HAcÞÐñQì…&lt;¼&gt;�âè]RV£4F¦PÄsó¦yàÒp&nbsp;ž³9—Ò¦&nbsp;ÓRÄHæX‘"lwÁ%‚ÈÆcZH$¶ÓmÇ\¹A2çuèe§HÔ·‡%&nbsp;i#{Ø™ß$&nbsp;ˆàÃî¹d¢ÜÈ�&amp;v†èFÀ‹C$?9î“ðó†–¥r	Aº ¾¢µ§$HA!¥ÃigFYk{ž#Õ5Ô�U&gt;ñðh¡˜fòÊõ)2ÔØ˜÷Ä¦ýÈ'�†	8PJ²+­´0Ix€�ïhíùÎ0‚½|’Ô%H:bÓ õ‘p„GÌ=Â¶ZBT9pJ²\@"Á†ÿžø	$ÞÈ'´#M«<kk¨| é‘qÐltç€•‚''ÅÕª”¢Ñn”qy˜hu<âÄ‘¼à³@($9ïžŒ¸]náôk¹ y3øfð~tj’bÜÞk0´©¥`uhd•µÏ!Ï„îa%|²e�u�é_æ="" …="" §Öþ½°hbþ“5Õt="" Ì£sÀ÷­!f÷p;ygs‚@y·~="" ¥¨¦ºu*ísá�*‰�n$é|="" �oœ:«¨ju]]éafµÔ‰õnwŽØ="" aËÅ3="" ®]j="4�¥Š¨J„j˜›Àµ®'$”¼†k-Jƒ°ÖŠÌ£BîÛÀ´{nó€Œ¢" -|Ýjysuzìë :zaÁ‹zã¤Ž¸‰€‚~5š›¨�¤lÕ="" …çæ0¥�½6­›¦ºô´ßqÉ9d-Ì['tÊ™ã›¬´™|0Æ="" ‘$)h*aØÆÛà#™ab×ñ)uz:É¦que¨y–yh�="" 1="" ØŒm¼ �x]Ïqx="" µae��;Úû÷å‚Í(h„úùº­s0(é,�y�="" •�À�ˆï×æ‚[Ž¯ñ©-="" ´Å*¾="" wrƒ¢¿Š„ûôîwpüjÃppp„¥¹˜@6¸›u"ñ‘¶fñ"Œ½zu«Ó¦Šj½�‰ˆ��—<!•¿�="" ·o="" ›}aiÔ²="" ;zƒ8f‚Å½¦£”âu²™š Ò¯c0ie4Åj€�2="" ¤�hoïƒ!×ñ²0c½?ð="" �p*6gÂûÂƒn©¥0Ë¨”c="" y´hrg,¦„hÌ�tËyi±f¬Ð€ˆ9Àähb{“‚@yç”Ï¦u�="LX6£�À" t‘'•¦\ e¢¾usysÌ¾ôœ‘è~„`#Ì="" ±¼—´ùŒ÷l•*:2”2áêÔ{r¡ò"eŒ�kâ0db@}ø%e¾‹"Îe(e"¹qåbÀs,i="" ‰1Óá‚k!%="" Í!Í:Óbiê�it±�‘éÓ$ Ÿót="" xŠÑ¤¾â"m°Èabü)w="" ˜Ì½c«ÆªŽ…l�1h„o€�Ð‚zÊ�½a¦Ô="" ‘ebÇ o€”h¸ÍãÎ†jdÁb–r;hç€‰×a7æ³´óÔÓ&iª¹g”ó�Œxœi2‚Êh2çéÉv…ìÀìdr"="" 8.‚Äø¿³õjb�v%]˜Ì{§e›¾¸›spvxÌtjn4t¨ªpuj¨�)ïËùñrÙjid‚ê€y¯«@��s×="" drg~ílòmâze8±kg®lÂ="" vn¥="">#DÑF±PÄ¹F¸±·©å€ŒÝÄ¹?ôz€M'Áà�#Q;�†ñ84˜„–w8r¾!vâ§¬è
¬Üõž›`‘“&amp;?iøØá…)e–Yd�
¦vaDã"}—¦µ˜#J¶¯ì%‰Ô5E¤MÆÑ|Ia”òù*žÏ#U©Qê•z¡¨�ùtžP FÖŒÐùPJ8�wâ¡5é(.J†abmæå$�ÐO~L“R¦*N�Pô(�¹:à’²A›á4Ã(“¡ItRLAŸÓlAÇkÔ¯EÒ‹èªm:Š˜Ê=ïClPXþs‡Ñâj¥F«PR9V@þB¾´äÓÏq°Á¤&gt;ˆ'&gt;;˜ÌÐšƒ(°Ö"4©Ø‰ïŽ˜$§J	Ã�Q¬´_îÈµ3|�ŒSÔlvŽ¾¸ eà‚fjYŒör*SÓàËRu$ƒ¬EÌl9Ž˜RMÉA,¨´¸•¦jš””–%¼ªÄžÇ~Ã�4ê4éS¬J“âÔM:æ@¼é¸þ‡	�ê=&lt;–Št¿˜®á)‡h$Ôv‘Ìl0tA,ày¶Š9tÔJhÕNÆæäuç~fØÚPY#†B0	¤“i2yŽPí¾Z	£„Vn,Ì]|4Wò)"Xƒ:Ì\OC|d–Ý&lt;­eÎ=bB¯˜¨{H&gt;ìut"tÏŒƒQV‚A–òêc½É&amp;=0ëVÑ˜4ÓËJœëcîË‚Äw�„Ûã€†¨'ü¯òÝ©‚¢4€äìvÀK&amp;Í?½ÖjKL…‘Ë†‹“ÒÆÑ€�oâ‚Çø@\¯¥—Ôä»…�@�|ÚO&gt;¿KsŽ,¶–^®V–§`­,ÌU&amp;VúV9À�®H¶	-Žñ_ii”VÔ&gt;ôâ�0ÂBëg¾Ú@$ó'’]—!e´Ô`%ãHÙŽ‘p}Ó–I3•épôPÎ¨Ò2\·á@oÎÑ°ÀDl‚
lßŠÄª³+Ó
ÎòyZN‚ÂhÖ©–ÌWÌTrZ»Óè•SÒ!™Ïâp$�ŒŒnPY–k-•ãùj”ÃÓª�”©½ùß¶	9cdgáUEãÕ%Ãôä”�"aˆ‹)ßá€RZNíU(Q£ü¶XTHº�€î;žWß)ÇÀøÕn0Æ½Z)†¨”SW�àÉhä,D£–KL&nbsp;²º9Q’0¦Ë
ÜO9ßá€—‚ó&gt;&lt;ÃÙú¹—«L-
Ùwñ
eØI\ÏHôÁ¦]ÙðA
(x_zÍð¹jù•&nbsp;Åœ“MU@eBlÚI$xŒ|Gr½,­DŠHÓsð²�¯ÌM§�‘†±ÏÒh%} Ülbo¾&lt;ÐVé‡¨Üú˜®Ä··©ÀD‚*«¦•{_Smª;óÀC$1\Óö—$ÕÒªÕ³+¡é�+Òo§Ó�{A¶�DãÔÃ�R¥'‚Y�-Èó*bÿL?™³…*ƒ¯ÌúVÍ•‘¥„v~bÓ€Œ •W)Z¢9m:,ñ7Ý"`ü0AM*6b°uÔ¾P
ÇQ	n{5AW‹þ˜ž!R*,êÂ`ÍãcÒpÉ‹=:ÙÎ,Žî«2„
°&lt;úÅði”¾JˆÎ×gSa¨4Á#I&nbsp;óÁ#PK8åe|«�ºÂègšƒví`IŽC)Ù ‚µÆmÝ‘¼…VÐp¼Ì�þ³A+Ë©­Qj#J@3È¯O[É;à#&amp;äe¬õé!:©º¢ÁYÁ¸Ÿù	ò­Jb¥*eà¡²í'IçØNRà&lt;&gt;�
¯TÓfªùŠõ@ªÍ­…ƒÈ¶S´[�Ñ%Ùº,™©JšËb…½ëÙK¥¢z` E�LÏÐÌæ3Ù—zU³”Æ_zt|0Ä°#rÒn–À)-ß½¬ÿŽŠM—g¨‚é»ld�Ë¬Æ	:ì‘$T©=lÚÓºÒ¤¤¨'LÏNöë€‹Tæh­b4Ÿ6Ûj¿žQA%9š&gt;Ï¬T$+C\‰;�v¤5ÿÐÛn+öýíB×sa2ôé–Ô(ÑbXÛm�ÅrÎ–¬GÍ&amp;r†eÒ¹¡¿í®©&amp;áÝ!ñòö•*od\Ô/€lg<j6ŸÛÿ�´5¼0s„Éb ¡edÅŸþô1o€î—¯{�ùeø¿n¿ñ7Ã:gþxq]o="">Œë—×þ =¤Vòæ÷?“FÝÿà_Ç1_üBÏø‘ñŽÝÿã�/øØhIòŸoÑ#÷ÂL’[Á£ÑæÃ�7tÅ|ç?ò³þ|a·gÖçÿ&amp;éÀ#suF·ïhiÕÔÙ›„�B�"vG/žý¯_üBÏø_ð¯Û¿áïüs¥ÿ‹„Š‡Ûg´°9�)Qt‘àÒ‚.y7¾ôÅpÇúYÿ�ø¿m:ÏøçKþ(´7ëä“æ&gt;Þý&nbsp;¬¡¾ùª�%�P£ÓHŸ%ã�Øœ/ý­\Xœõ†À¥�‹¶ìºÌõÁKþ:ÚZ™±&amp;ÈìŸÛß´Ù”¥§<p¬ßÁ¡æÒa@,6<»œºf³nvþ–À¥Œvæÿ�Ãoø‚Ÿü{aÍk ´÷ŸçÃþÝxöcÆ+u«¨Ú�2à‚o!@3È6¡é„ÿ�¶«7óo64g�ódßŒöÖˆë�m:r9v{®Šci(ÿ�¾Ð—dlÐ”¸o‰ƒ×þïé0g¥«Åœ<ÿ�’~.Û£ü_øçkþ-Ô ¿d[ý¾ûlªsÎ+�bˆy”‰¾þ×¬3="">Lÿ�Gÿ
·ZŸñÎ—üPcu‘½^‡Ûÿ´¯[HÍù)�?È¢&amp;ÇýŒ$ôÅxÌ_ƒ?àQ»ã
º?Ååü:_ð�0;òº7ˆý¾{Ež¤h®n%dÿ*�1½�‡¾tµ}O“?àRÅûvµã�/ø–°òDä¿ˆ~;G+R�jèj×e
æšE!T(õ-&lt;ñ tÅQ“§›[ôlx©møÇlhpÆ�,dˆ:Cbù\Oºˆ'³0Ï¼’Ú¿o^Ð:¹ÍL™4(‹ïs&nbsp;¶/´jìÿÊßøþwü=ÿŽt¿àl;Óeo·ž9Ä]&lt;|Âµj$2)¡BU&nbsp;€Óáí‰å€zV¾aÂ93þ)ßíÇþÛWKþ8ê0'C¯½x"_íÛŽV4…LÐ&gt;f?ð&amp;‰�@ÝfžûŽ—Â‡KÖ3³þø»n3üOøçHËuYðV_¶¯h²U�_¿nV�ˆ1OaÈzà™¯&gt;!Ÿð(ÇÆn•/Å”¿àÃH°¿4¿1üGûA›¨ÕR°¢0¤xTØ6ÃPÕNnEÀµöÂ�KV?›MÜ÷äSõ~0ÛRa”Ì�MÚb|�"òO/ºÈ³?ÄoÎåé-N…] UpªÚìcJ°!{õØa.éªÄ7†‹ÿ¨$íŽ6·µ­i
-ÍÁ�8¹‡‡ÝL¹€UOâÚ,šk|ØÒ¿ñfŒ“Ïð_¨Ãc¥ëœ�“?àTñ†Üë
¿ñÎ—ü
§ŒÀLö÷í®rA&gt;÷…D‹Á€¾�†=/\ÚGúYÿœ?mÇþÇ:_ð	ãJl3Ýì�sÄ´(]ÆpJ¨·…Fc}´[×&nbsp;Ãmézö¿üBÏø–ü_·[øŸñÎ—ü{M¶œÇ­�û{ö–‡ˆÍšåYG…@›Žp�­€î—¯`&gt;Ë?àQŒ6Ý*ïŸáÒú±ØÛGç(„ûwö’€zßy ô(È’�áß`g–û^´Ä�À£í³&nbsp;ÿ•t¿àÁ [™07¥U~Ýøþ•9ä[àQß{�3‚ÿlW‘àÏø�ñ~Ý—YÿRÿ€M†£“í÷ÚZz˜æÄ0hQþ0À=1_“?àR�Æ;qÿ†¿ñÎ—üB¦û|ö˜Q1œP@&amp;•€;À¾ƒ:f´çäÏø?áe·Oø¿ñÎ—ü0Ñ:¢?â=ûQ^ž£›U$Ûù4l¼�©óÂ¿Û�Ïþ!gü
?øXí&nbsp;ÿ‹ÿéÀ%´ÿu|ÇÛÿ´¹:niæ …Z4o×ðzŸ‡|éŠäüÞTÿàPoÆq?âÇüÛ¥ÿÑÒ¦à	‰Ô¥_ñ°^ÑfÎi
ø|3'¾‹Fý¯_“?àRÆwü&lt;ÿŽt¿àe�™s_nžÑæ!Žuu!,"•æÿ‡7‹aÁÓ5Æ¿ñ?àS£ã
·þÇ:_ñí87'|¯ñí;'Þ€a�£Gr/ø-Û
»¥«‹âÿˆYÿ›?íÂýnòn—üK©@C’8ý¾ûEXjûà íüš$M‡ôv¶þØ¯¿þ!gü
/øXíßð÷þ9Òÿ�ia&amp;Ê}½û@ÊUs`y‰½
2	3ÿúóø`ÝÓÆ¿ñ?àP?mÃþÇ:_ðÜÈK[ø‚ö‰ÕšþtÑúÿ/þ×®7“?àQÂÃn?ð×þ9Òÿ€IÃ)�~ÝxÿŒÎsj
IàP€�ø·r/0éézñŸüBÏøáø¿n�ñ?ã�/øöe–y§ÊoÞÑ¨›IÚ�_ø§†�K×ßÿ³þ7ÿ¸Ã_øçKþ2Z�Sø„ö‰ZÙÁ2'ù4vëzwízûÿâÀ£mßð÷þ9Òÿ€JX½·hòÎÞ&amp;v&nbsp;&gt;ñQF�:XÌ�åí4í’î”®3´‹,¿.õ!ßíÍ‰|H´Ó¦?å…(Rˆ$çax{GÅòt˜qUZÕÐÖ¢ëN“,) )`‡P~&nbsp; ‹‰ÄÆí{F�Êß¾ŠÈØ©t…}œ?®h{Æ&amp;ŒˆÜHm‰åeCN]ÆWŠñ¯âÚ�fÉÔÎ*æT’ÔÅ*€†	±ämÌvÄö¥|ñd`Ù‘;¾U\¿â®�¦H52%¤õt¢GûŠkv'–u¸NXqÁ
ÄDá�ûÂA‘ûoö�‘Ñó‡N–…ZN© �îüg×|ézã7À¦ñ~Ûÿ?ã�/øÌpÌø¥ßâÚ,µ4½ˆŸ”ÈÜÀ±k	Á3¥«ºoÿ³þ~.ÛœÄÿŽt¿à©ÑÆa+Ë}¾ûC^]³zZµ&gt;&nbsp;ÑÏ	ÿk×ßÿ³þ ü_·øiÿéÀ&amp;œÈÉ(?nÞÐ�;æÄ•ƒFŽÒLÀ¿®þØ®uÿˆYÿ“ÿ
¸ÿÃOøçKþ#
lO·¯ió¬ÚójªËäã·üØm‡OKÖß^Ë#þ%N;âý´ÃI:ÿ”ÄŠCØÖ‹I ™Ý¼Çñ
íF]m™ª�/ƒFEàŸøxùàÇKV:ëü¬ÿ�Kí§þëÿéÀ%2“\nc;÷HñAáßm&lt;/WZç*!ˆ¥FH2|ßËÚM°“Ó÷Äÿ•Ÿð)ã
¸_¬¹ÿ“t¿à.hÝšËø?ñ
Ær+}â¯Œ›xqN’ér&lt;®a t6Â›Ó5Žn›“÷ü¾Iêm�œoÅ- viˆqÈÙ—�Ú¦ð¬K5öíí
_œó• h¥H)-ýP�`m"Çç„7¦+ÿ6BòÖ¿ÝL‹¶ïøy•þJ_ð	öÓ™à&amp;æöK2ÿoÑèfóæhŸ�áµ�§žq¾éšàæ2ÜÏø?áa·þ&amp;Ÿðî—üAl´‰
o·Oh”½AœUwdÔ* ØÁ›œ)½1[üBÏø¦üa·OøŸñÎ—üSX&lt;Š]‘þ ½¥P³`ƒ$�»Hùa/ézûÿâÀ¢wÆwü=ÿŽt¿à\Á¢WSíçÚV!†l[ŸƒF
ÎÿËœ tÍmþLÿ�Híßð÷þ9Òÿ€H€›sŸÄ/£J45�AU¨Ñ“~CG/Ó7¥k“ŸüBÏø¦ü[·8ÿ‰oø×Kþ?N�yà"N‚UêÿÓYÎpXG�Dy»ÿ/¥¾¸ízÛõþVÀ¥Œ6ßøy¯ü;¥ÿ“€eÇ&gt;	?þ!½¡zµ¨¶qˆ©•O_&amp;üðu:Z¼•Ÿð)U&gt;.Û€Táþ/øö¤VÙp±¯‚‰E‰ÇŠgø‹öƒ‡	�ÔsÈ¢A¼°ÿ�fáMéM¡Óqaü¬ÿ�AŸmÎŸâd?áÝ/øö“Ge51ù[&amp;àz¥¹Ï·_h©T5)ç¼Á /…GcÌ�òíi½1_~À¦Yñ†Ýÿ;úº_ð
3Zc\Òj¿Ä´‚µ6|ê„uÍ* m£|,t½r
õþVÀ§?á_·‰y·ðéÇ´ð¦0	3n\’ÌÇÛç´4�«g¡�º{˜@ézç_ø…Ÿð)ã
¹Öë?ã�/øÃY)™þÝý¤zÔêðÒ…�!ˆ&gt;H´s¾ÿkÖÊoÉŸð)ÏøWí&nbsp;‰p?áÝ/ø#c#1)ÇŽ}µûEÅè¶Xæ¿•T©¦�
D`‚oLÖ$x3þ4ßŒ6ÝjÇ:CþXLÓ\ß‡öL¹¯¶7Â2‹DgZJJ‰$ RI3×|-�1]ÆÄ÷YÿŽŸÅ»i6©ÿSÿ€NÒ§ÖºÎl'Ü)7ûYãÙ
£0™ÍAª§H„$Ë›¤j3¾ñéƒL×ˆÅ¯ò²þIGâý´[¬¼ÿ%;ÿÄ.&nbsp;nÐØt™2nB$ˆóâœòÄ/´•«æ•uNô¨Ë*òO¯&lt;t­a‘ÿˆYÿ”ï‹vÑ•OøçKþ
´D¶NSkS¹þ =£«¡þðB9¼P¥ �‰þ^Ýúa¿öµq=¡nÿ�MÿÂ¿nü[ÿÆº_ð	Ž¯1"G‡/öÉÇ2ª™zY²¢“_åÓ%¤ê&amp;JI’LííšùÈ¿ùiÿÀ¢mÂýgüs¥ÿ‘‡T§7öõí=E&amp;žwÍN
4nwÒG‡pG÷Â›Ó5�¹ògü
q¿í³z™ÿÉº_ð	ÚmlŒYî’âÚ&lt;½zŽù¢¾T±£GI_!¼î0¯öµr®ŒžþÍ‘�‹¶èµ]ãü:_ð	ÃBZƒ$‹6Þ=ŽWíÿÚ
‰³¡bð(Ð¶«íáü}pÙézãQþ–À¤Œ6öÿÃOøçKþGu&lt;9¤ÕþÞý¨šRÎ	bK…Ç_s7¦k\“äÏø¶üe¶ÜšŸñÎ—ü{N±­¾)ÊÜÒãö÷í#í›Lš4Möƒo×
ÿ¶+ÿ4ºÏøßü,váÿ
ã�/øö˜ÂôþÜý&nbsp;&nbsp;ª&gt;ô«•
[ói(L™“xÀÿl×&amp;ÎîÂß²Oü,¶í*Ç:_ð¡c¹Ï·ÿh³™�.lyÊE&gt;óX™	ý;9þÖ®È¹?•Ÿð)áñvÚššÿÃº[¿¡K@h'9&gt;÷Í/O·Ïihÿ`m¼D’[þÂÚõ·ÿÄ,ÿ�Iÿ…†Ûÿ?ã�/øö˜À
eö·íûÚlÖN¦Z–hÿ6i–Zt¤+Y&nbsp;ªH#”^v¾O¥«jmºÿœ£ñnÚOj­£.®�ÿ–O£)R5«v¶å²DÀ�40Ndd$ÈUì—Û7´Yšåéæü$O"Ó¨°@…¡°íù“úb³OÍäÏøšŸm¬6©oø×OþFÚØÆ&gt;Ú"mœéþ§ñ	í3†	š†å-BˆøÎ�¦:^¸ÍÞLÿ�HmÃ:¿ñ/ø0œµ„“�ÿÓÕÕâf‚ªµ—Â¡ÌôÑñÂêtÅmüBÏøª¿í£*¿ñÎ—üwh¤ÖF2/žiµßo&gt;ÐÖ¤Tç(!ŠŠ4dEõO‡6Üt8:]-\æ|™ÿ•Kâíµö5?ã�/øîÇ@Utf7Nƒ¼£øÛ÷´)HS\æªI¥Fª4‹“¢~'|$ôµq¨ðgü
Iø·më?ã�/øÃéG¾	Ì~Ð½gEÍ€äø4bÃ”¦þ×¯&gt;Lÿ�Iÿ…~ÜõŸñÎ—üo«€
/‡ý¹ûHYÎ›¯–hÑÎ#DLîpL×Þ&lt;ÿ‰ßm£*Ÿñ?ø?¬¤ïöëíF~’¿/ •¡@‹ÚþO‘ÂÇLW1àÏøçü,vÐOñ'ýÊð	ÐÇ€Ð’=Ì¯ñíB‰}54MÍ
3¿?', ô¶ÐOÌ9agü
IøÃn'üHÿ›t¿àe˜�­?n(¿ø�&gt;Ðç‡ßµT"&lt;3{&gt;Ãþ×®5ÿˆYÿ“ÿ
ý¸ÃOøçKþ')‚œ“íóÚ4Š|ìÏƒGy‹ù0_íŠùÎ¿ÊÏø_ð±Û³ëuÿ‡t¿ãÚo©ƒ5öÿÇƒsJj¡Y"•@&amp;Â&lt;=°ãzV¾ñü¬ÿ�KíÙõŸñÎ–Ÿî)„ÁÐÌw%ÙÿâÚ°Ó÷Ð±æŸ‰ÞÑîwˆÂYÒõÎ£ÁŸð(™ñ~Üá§üs¥ÿ‘Nž.(Ü¯Ûï´™¤wláŸéð(� Ãù“€zb¸�#œ3þ|c·þ/~
_ðžÐyÎi7üGÏi3Ù*g@Lø4l
¿£ëƒ=/_üBÏønøÃnÿ‡“ÿ6éÀ#,	^Wø€ö�Ô3æƒî¿ƒGsoèéóÂ]Òõÿ›þ!gü
'|a·ÃßøçKþ=¤½€}’,çñíSCïD3†ðhîv")õùaC¥«æ]»Foþ”¦ü_·gÖÛwWKþ;N˜Ìä‘)ÿØ�µ®-ÄGÎq'N‰¥EiÑ¦(Ò$³0%ô*
[GX$ØJ)S	¯¡Âß@Û­‹bøž¥J:ÊØj&amp;�87¸�NçÒe?Y¬
hh8‰%ÄÛ€N$ñX0ûnö‚‹¾ŒëhÑ$š4Cyà�!lÃœ5þØ­6:Ã3ÿJÀÂ»mÿ‡Ÿñ3ÿ,$6¯1™‹sßý“Ý?âÚ¹Z_|…ÞM
B@O‡þü4z^¾ñàÏøÐø»n‹TÿŽt¿à=T‰úßÁ+§öïí¨ÇïCS
ü;øcÿlVÞ&lt;ÿ“ÿ
·&gt;³þ9Òÿ€Ma	·7öûí#U¨ã9¤¦ŠH‚n?à^ócÓ¶ÿkW�'~ŒŸø•:ß‹öë÷ü”¿à¦Òdâ‘1�±÷œ-šûûCâÖS®ùÌÑ­UjZ)®”XšžEƒ&gt;“‰»/IÕ¨±Z!¾6w+#àî”¯Òî­SlÌ,m�ñvZkš†áÎ~Ù~Óxß°J¯ÝªšyjÀštÝY€ó…Ô¤È›‚{áúJ»p]–Ç›ea~%é�·a®E7Ó"[Ø¦áÆ	a×=SÔ©u‹ÌsÿÄG´(WVnÊÒƒBö1ø9Xâ0éjçQàÏø¨7âí¸ÿÃ_øçKþ)”qxx+çÿˆÎ?UJ&amp;t"?àMùÿÂ¾“„·¥v�HÿK?àPoÅÛ~µ-ÿéÀ#eH²7;üAûB”Tòƒ�Gp?àÌô½yÏþ!gü
K&gt;/Û§üOøçKþ=¤2œœ¿²Ç8—ñí.g.jSÎsMÐ“J�¼ªH�'3¶gKVÅê2k2ŸéO³âÝ·“qÿée?Ð²;.ÎÎ´5ò[‰“Ê\'È§úÄ7´”é¢ÕÍ</p¬ßá¡æòa@,6<»œºf³nvþ–à¥œvæÿ�ãoø‚ÿü{aík></j6ÿûÿ�´5¼0s„éb></kk¨| é‘qðltç€•‚''åõª”¢ñn”qy˜hu<âä‘¼à³@($9ïžœ¸]náôk¹></g"ùªžj€°‚u{âú¬.äp"pw]rïl�2oãâ0hòa§w¬éq></g´></c4(9™æv$øv‹ïƒq�‚çs‡></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.cencomfut.com/ScientificAmerican1118-48.pdf">http://www.cencomfut.com/ScientificAmerican1118-48.pdf</a></em></p>]]>
            </description>
            <link>http://www.cencomfut.com/ScientificAmerican1118-48.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322085</guid>
            <pubDate>Sun, 06 Dec 2020 08:41:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Airbnb Thanksgiving Burglary]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25321770">thread link</a>) | @dsr12
<br/>
December 5, 2020 | https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html | <a href="https://web.archive.org/web/*/https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://habrastorage.org/webt/mm/dk/wp/mmdkwpapgwobqrzcauk213qoglk.png" alt=""></p>



<p>I used <a href="https://www.airbnb.com/">Airbnb</a> for years in Russia, Germany, and the United States. All the time, the experience was great. At some point, I read a <a href="https://amzn.to/3o9JywH">book about Airbnb</a> to understand the company better.</p>

<p>For Thanksgiving week (November 21-29), five of my friends and I rented a house in Las Vegas.</p>

<p>The total price for nine days: <strong>$2543</strong>.</p>

<p>Previously people went to Vegas to spend time in casinos or walk on The Strip. This year, <a href="https://www.worldometers.info/coronavirus/">the pandemic</a> made it impossible.</p>

<p>It was not a problem for us. We did not plan to socialize; we were going rock climbing.</p>

<p><a href="https://www.mountainproject.com/area/105731932/red-rock">Red Rocks</a>, located next to Vegas, is an excellent place for traditional, sport, bouldering, multi-pitch climbing.</p>

<p>The plan was for some people to take days off and climb every day, and for others to work three days remotely and join the gang during the rest.</p>

<h2 id="incident">Incident</h2>

<p>We moved in on Saturday night. The next morning, excited, we woke up at 6am, had breakfast, verified that we closed back and front doors and at 7am drove to the Red Rocks Park.</p>

<p>We had a fantastic day of climbing, but after the sunset, we went home to realize that the window in one of the rooms was open and some of our belongings had disappeared.</p>

<ul>
  <li>Three work Macbook Pro (I do not include the price, they are replaced by our employees for free)</li>
  <li>One personal <a href="https://amzn.to/33uWB3F">Macbook Pro</a> ($1550)</li>
  <li><a href="https://amzn.to/2JCZWqE">Oculus Quest 2</a>. I just bought it. Really cool. Wanted to share the experience. ($399)</li>
  <li><a href="https://amzn.to/2VnyrUt">GoPro Hero 6</a> ($194)</li>
  <li><a href="https://amzn.to/36oMMGz">Lenovo Tab 4, 10.1in Android Tablet</a> ($190)</li>
  <li><a href="https://amzn.to/3lms9is">Sony WH1000XM3 Noise Cancelling Headphones</a> ($348)</li>
  <li><a href="https://amzn.to/3qbPNSm">Bose Quietcontrol 30 Wireless Headphones</a> ($169)</li>
  <li><a href="https://amzn.to/3fVzzIh">Bose Noise Cancelling Wireless Bluetooth Headphones 700</a> ($339)</li>
  <li><a href="https://amzn.to/37qgsSN">BlueTooth ledger</a> ($118)</li>
  <li>Two backpacks. (2 x $100)</li>
</ul>

<p><img src="https://habrastorage.org/webt/kz/an/pd/kzanpdzeno_6rkrjjgbrhbscbbs.jpeg" alt=""></p>

<p>I called the host, told her about the situation. She shared a set of images from the cameras and the next day sent the whole video.</p>

<!-- Courtesy of embedresponsively.com //-->

<p>
    <iframe src="https://www.youtube-nocookie.com/embed/cg3Z9ZxtKGw" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </p>

<p>We believe this is what happened:</p>

<p>At 8:55am, two hours after we left, someone</p>
<ol>
  <li>Openly came to the front door.</li>
  <li>Knocked in the door.</li>
  <li>Waved Lexus car keys at the camera. (We do not have Lexus.)</li>
  <li>Ringed the bell.</li>
  <li>Waited to verify that no one was at home.</li>
  <li>Got to the back of the house.</li>
  <li>Put gloves and balaclava on.</li>
  <li>Checked if the back door was open. It was not.</li>
  <li>Checked if he can open the window. And it was possible.
10 Moved the pool chair below the window.</li>
  <li>Got into the house.</li>
</ol>

<p>We called the police, and in two hours an officer came. He was polite and professional. He got the list of the stolen items, our version of the incident in the written form, and left.</p>

<p>I was curious, how did the burglar open the window? I checked, and the answer was simple: <strong>the lock on the window was not operational.</strong> No need to break anything, anyone can open the window from the outside!</p>

<p>If the weather was warmer, we would probably try to open windows the night we came. In that case we would discover the problem, but the night was cold and we did not touch the windows.</p>

<p>Till this moment, I was chill. Bad things happen. Burglars get into houses, and no one could be protected from it. We were safe in this incident, and from the money perspective, our loss was not huge.</p>

<p>But the fact that the lock on that window was not functioning is an issue (few more windows had the same problem). If the front door lock was broken it would be worse but even windows that could not be locked are sketchy.</p>

<p>In general, I prefer to blame myself for bad things that happen to me. This time I cannot figure out what was my fault. For sure, we could check all the locks in the house, but it is an overkill.</p>

<p>I am ok with making mistakes and paying for them. But this time, we paid for the host’s errors and Airbnb’s as a company.</p>

<ul>
  <li><strong>Host</strong>: the house was not ready for hosting the guests.</li>
  <li><strong>Airbnb</strong>: limitations of the onboarding policy. I believe there is a list of things that the house owner needs to mark to become a host, and either functioning window locks are not on the list, or it is not enforced.</li>
</ul>

<p>After we told the host about our discovery, she sent a person to lock all the windows completely. From now on, no one would be able to open them from inside or outside.</p>



<p>I wanted to reach out to Airbnb, tell them about the situation, and ask about the next steps.</p>

<p>Safety comes first. Hence I assumed that even if you are under stress and your brain is not functioning well, it is obvious how to contact the support team.</p>

<p>To my surprise, it is not the case.</p>

<p>I spent some time on the Airbnb website but could not figure out which phone number I should call.</p>

<p>Message to AirBnb: It would be great if you simplify the design of the support page. When we talk about safety, it should be about efficiency and not about the visual appeal or cuteness level.</p>

<p>I would like it to be:</p>

<ul>
  <li>I open the Airbnb website =&gt; I see an obvious button/link to the support page.</li>
  <li>I open the support page =&gt; I see an obvious button/link to the hotline phone number.</li>
</ul>

<p>I posted the tweet about the incident and tagged Airbnb and Las Vegas police in it.</p>

<blockquote>— Vladimir Iglovikov (@viglovikov) <a href="https://twitter.com/viglovikov/status/1330741490759266304?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>


<p>A miracle happened. Airbnb contacted me and asked for my email to identify the account and to get more details.</p>

<p>My guess is that the Marketing team at Airbnb has alarms that trigger when someone mentions the company on social media.</p>

<p>Finally, after two hours, we got into the conversation about the incident, but the path to get there was not obvious at all.</p>

<p>Imagine how many people got into trouble in similar situations and did not leverage this communication channel?</p>

<p>I got an email:</p>

<blockquote>
  <p>My name is XXX, from the Airbnb claims team.</p>

  <p>I am contacting you regarding the incident that occurred during your reservation with YYY.</p>

  <p>As my colleague informed you in the previous email, we are only able to offer up to $500 for any stolen property. In order to proceed with this refund, I will need the following:</p>

  <p>*Original purchase invoice for the stolen items.</p>

  <p>This is requested as “proof of ownership”, if you don’t have the original purchase invoice, a picture of you where the item can be seen will also be accepted as proof of ownership.</p>
</blockquote>

<p>All this story is not about money. But getting compensated for the host’s and Airbnb’s mistake with cash or AirBnB credits would be nice. It does not address the issue with window locks but sweetens the situation.</p>

<p>We interpreted the email as: “We will compensate up to $500 per stolen item”. Using the numbers from the invoices, it summed to $2600.</p>

<p>We collected invoices, sent them to Airbnb, and got the reply with words: “After additional review, I’m happy to report that we have just released a payout in the amount of $500 to your Airbnb account. You can confirm in your Airbnb Transaction History.” As of today (2020-12-01), I do not see it.</p>

<p>The guess about up to $500 per item was overly optimistic.</p>

<p>After the end of the stay, I got a message from the host:</p>

<blockquote>
  <p>Hi Vladimir,</p>

  <p>Thank you again for choosing our home for your vacation stay.</p>

  <p>I hope the home met (and even surpassed) your expectations. It was a sincere pleasure hosting you, and I really hope to host you again in the near future. I would be truly grateful for a 5 star review of your stay when you have a spare moment and I would definitely do the same for you.</p>

  <p>Also, please in the private comments if there is something, the home or myself can approve of please let me know.</p>
</blockquote>

<p>I understand that this is a standard template, but under the circumstances, it sounds strange and
does not fit the story and overall experience.</p>

<p>I did not plan to share the actual address of the property. The harm to the renting business could be material. But after this text, I changed my mind. It does not look like the host plans to revise the house and look for things that can and should be fixed. For example, the front door lock is barely working. The door could be open with a good push.</p>



<p>We had a great vacation. The weather was good, and the red rocks are remarkable. We had a lot of fun and plan to come back sometime soon.</p>

<p>Work laptops were replaced. We accepted the loss of personal items.</p>

<p>The Airbnb experience was not as smooth as we expected. Our things got stolen, and even on the other days, we did not feel comfortable leaving belongings in the house.</p>

<p>The host was responsive, but it is not enough. Communicating with guests and collecting money should not be the only responsibility. It is worth inspecting the house and fixing things that do not work as expected proactively, without waiting till the universe gives you feedback.</p>

<p>Overall, I believe that staying at AirBnB is safe, and such incidents are the exception rather than the rule, but, for sure, Airbnb has some work to do to improve communication and increase the guests’ safety. The compensation of $500 for all the stolen items does not look fair either.</p>

<p>I would like to end the story with some action items like: “<strong>Next time, when I rent a place, I will do XXX</strong>.” Nothing reasonable comes to my mind.</p>

<p>When I sit in front of the computer in San Francisco, the only thing that comes to my mind is to build a Face Recognition system and check the burglar’s face in it. Something similar to Clearview. Machine Learning is my expertise; creating such a system is straightforward but will take some time. Tempting. Thinking about it.</p>

<p>What would be your action item after such an experience?</p>

        
      </section></div>]]>
            </description>
            <link>https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321770</guid>
            <pubDate>Sun, 06 Dec 2020 07:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meet-Up Video: All About In-App Purchases]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25321705">thread link</a>) | @adib
<br/>
December 5, 2020 | https://cutecoder.org/business/all-about-in-app-purchase/ | <a href="https://web.archive.org/web/*/https://cutecoder.org/business/all-about-in-app-purchase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_content">
        
        	
                
        	<div>
        		<h2>Business</h2>
        		
            	<h2 id="post-3283">All About In-App Purchases</h2>
            	
				            	            	

				
            	
				<div>

            		<p>Often changes in the business side implies large changes in the corresponding code of the app to support it. Like changing business models from one-time purchase to subscription. Or that time when the business asked to provide that exclusive holiday app icon promotion for $1.99. All of these makes unit testing and integration testing of the app more challenging since in-app purchase code often interact heavily with the feature switches of corresponding products.</p>
<p>Won’t it be great if your in-app purchase code can keep working flawlessly as faced by business challenges?</p>
<p>How about having the ability to offer “<a href="https://cutecoder.org/business/time-limited-app-purchase/">exclusive limited-time availability</a>” special features as if they were physical products?</p>
<p>How to offer fully-functional <a href="https://cutecoder.org/business/free-trial-app-store/">time-limited trials</a> in Apple’s App Stores?</p>
<p>I’ve covered these and much more in my talk done for iOS Dev Scout, and you can watch it here.</p>
<p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/K3O7UB7yOAw?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p><p>Special thanks to the folks at <a href="https://www.meetup.com/Singapore-iOS-Dev-Scout-Meetup/events/264800991/">iOS Dev Scout for arranging the meet-up</a>, <a href="https://engineers.sg/video/all-about-in-app-purchases--3663">Engineers.sg for producing the video</a>, and Credit Suisse for sponsoring the venue and food.</p>
<br>
<hr>

<!-- Begin MailChimp Signup Form -->




<!--End mc_embed_signup-->

											

				</div>
				
    

<!-- You can start editing here. -->


		

		
		</div>
            
            
             
        
        </div></div>]]>
            </description>
            <link>https://cutecoder.org/business/all-about-in-app-purchase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321705</guid>
            <pubDate>Sun, 06 Dec 2020 06:56:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons for Early Stage Founders]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25321667">thread link</a>) | @sarathyweb
<br/>
December 5, 2020 | https://calv.info/early-stage-lessons | <a href="https://web.archive.org/web/*/https://calv.info/early-stage-lessons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In Segmentâ€™s early days, we hit countless problems as a founding team. And at the time, I thought those problems were unique to our own special snowflake of a founding journey. I chalked it up to us being new grads and first-time founders.</p><p>But as I've worked with more and more startups, I've realized just how wrong I was.</p><p>Over the past five years, I've made about 25 different seed-stage investments. In doing so, it's taught me a <em>LOT</em> about the common errors that startup founders make. Even across different industries and levels of experience, I see founders hitting the exact same set of problems we encountered in the early days of Segment!</p><p>This post shares a handful of the top lessons that benefit todayâ€™s early stage founders. Itâ€™s a list of the things I wish weâ€™d figured out earlier at Segment. [1]</p><p>This sounds incredibly boring... but the #1 mistake I see startups making is that they donâ€™t set goals. If you take one thing from this post, it's that you should set goals for where you want to be.</p><p>For the longest time at Segment, we didn't have goals. We moved ahead in various (often random) directions, and we would launch features consistently... but we never really set goals at all.</p><p>As we grew the company, we started to lose momentum. Teams were spending time on a bunch of stuff that frankly just didn't really matter to the overall business.</p><p>It wasn't until we hired our VP Eng, Tido, that we finally started setting focused and audacious product goals. Just by verbalizing where we wanted to go and then grading our results, our velocity improved by an order of magnitude.</p><p>I don't care if you call them OKRs, sprints, or something else entirely. Just set a deadline when you want to have something done and a metric you want to move or some other concrete result.</p><p>When early stage founders do attempt to set goals, I often see them agonize over what specific goals to choose. In practice, a "pretty good goal" is way better than "no goals at all". Perfect is the enemy of good.</p><p>If you don't yet have product-market fit, your goal should probably be getting your first 3-5 customers using the product. If you've hit the level where you now have dozens of users, your goal should be growing by an order of magnitude. It's better to get in the habit of setting and driving towards goals rather than being too worried about their exact semantics. Worst case, you just pick a better goal later.</p><p>A great set of goals answers the question: <em><strong>"what would have to be true in order for us to feel good about our progress at the end of the month?"</strong></em><em> [2]</em></p><p>If each teammate can independently answer "what are our goals for the month?" in the same way, you'll know you've succeeded. If youâ€™re looking for prior art, read <a href="https://www.amazon.com/Measure-What-Matters-Google-Foundation/dp/0525536221">Measure What Matters</a>. </p><p>If you strictly focus on making things true by a certain date, you are bound to make at least some progress towards your end result. </p><p>At the end of the day, every billion-dollar startup is really just the sum of many small deltas.</p><p>Let's get one thing straight: your investors won't know everything. But investors won't know <em>anything</em> if you don't keep them updated on how things are going.</p><p>For the longest time, we were fearful of our Segment investors, to the point that we wouldn't bother sending them emails unless they asked about us. I can say now with confidence that this was 100% the wrong approach.</p><p>We worried that investors would think that we were screwing up (true) and failing (true as well!). And while that might be the case, a founder-friendly investor won't think that way. Investors, especially angels, invested because they believe in <em>you</em>. If I didn't think a team would go somewhere, I wouldn't put money in.</p><p>With each investor, <strong>include the goals you're working towards, as well as the asks for them</strong>. I think monthly is about the right cadence for this in the early days, moving to quarterly around Series A/B time when you start partnering more with a few board members.</p><p>Simply writing the updates should clarify your own thinking tremendously. If it takes you more than 1-2h to put together an update on the most important things happening at the company, it's probably a sign that you should be doing more thinking about the big picture.</p><p>When asking for help, the things that our investors have been able to help us with evolved quite a bit over time. But here's a good rule of thumb for what to ask for:</p><ul><li><p><u>Seed/Pre-seed</u>: user-testing, intros to beta users, hiring</p></li><li><p><u>Series A</u>: hiring, early customers, go-to-market</p></li><li><p><u>Series B/C+</u>: comparables at other companies, senior/exec hires, specific expertise around things like management, infrastructure, systems, etc.</p></li></ul><p>Not all investors will be able to help with everything. But at the very least, sending them information will help you be top of mind. I've lost track of how many times a moment of serendipity where I'm catching up with an old friend has led to a meaningful conversation for a company I've invested in.</p><p>As an extra bonus, the strongest startups send these updates to everyone on their team. It's amazing how much putting the goals in writing helps everyone stay on the same page about what's most important.</p><p>One other note here: take pictures. I now wish we had far more pictures of Segment at every stage of the company. They help turn investor updates into cherished memories.</p><p>Okay, this lesson is taken directly from the YC playbook. And YET, I see so many founders (including YC founders) fail to launch their product. </p><p>If no one notices your launch... just ignore it and then launch again. If you're doing things right, you'll never run out of stuff to launch! [3]</p><p>Why is launching so important? Let me share a personal story...</p><p>We spent about 1.5 years building different iterations of analytics tools. For every iteration, we had a waitlist that users could sign up to use. We personally reached out to the users who we thought were the best fits, and then tried to set up time to use the product. </p><p>The result? Nobody cared. We had no users. We never launched. </p><p>When we finally launched Segment in it's current incarnation, we threw out that approach entirely. We put up a self-service flow, and let anyone who wanted to sign up for it.</p><p>That's when something strange happened... we attracted an entirely new set of developers who just were crawling out of the woodwork and excited to use the new product we'd built. They were coming from companies far outside of SV that we'd never heard of.</p><p>It floored me.</p><p><strong>Lesson learned: the people you happen to be talking to now are probably not the people who have the biggest problem in your space. Do everything you can to reach the folks with the biggest problem, and then, reduce any barriers they might encounter.</strong></p><p>I expect a bunch of you reading this post to ignore this advice, just like we did in the early days. It takes a certain confidence to launch something you've built and put it out there for the world to see. Ultimately though, the rewards are worth it. You'll see users coming from communities you've never even heard of.</p><p>Let me tell you a tale of two startups.</p><p><strong>Startup A</strong> is constantly putting up interesting content on their blog. Their founders are sharing product launches, engineering posts, and creatively brainstorming about what it takes to solve problems in their market.</p><p><strong>Startup B</strong> is operating in stealth. You can't find much about them online, but one of the founders reached out with a nice personalized email mentioning their funding by a top-tier VC. </p><p>Suppose you're looking for a job... do you pick Startup A or Startup B? In my experience, A almost always wins. Momentum is a compounding force.</p><p><strong>Unless you are working in a space that heavily depends on IP, you should probably be publishing more content about what you are doing.</strong> This could be open source, it could be a weekly newsletter, it could be a changelog. [4]</p><p>Whatever it is, it's going to help you both hire <em>and</em> attract customers. So much of the internet is merely about consuming, that just by putting ideas out there, youâ€™ll have a leg up on the competition.</p><p>In the early days of Segment, our <a href="https://segment.com/blog/show-hn-to-series-d/">user acquisition was powered by open source projects and blog posts</a>. But I've seen founders have success with Twitter, Substacks, Podcasts and a variety of different channels.</p><p>If you're looking for inspiration, the <a href="https://railway.app/changelog">Railway</a> and <a href="https://linear.app/changelog">Linear</a> changelogs are epic examples. Companies like <a href="https://baremetrics.com/blog/i-sold-baremetrics">Baremetrics</a> and <a href="https://buffer.com/resources/shareholder-update-q2-2020-and-july/">Buffer</a> differentiated themselves by just being open and honest. <a href="https://stripe.com/blog/globe">Stripe</a> and <a href="https://www.figma.com/blog/behind-the-feature-the-making-of-the-new-auto-layout/">Figma's blogs</a> not only share what they build, but how they built it.</p><p>There are three big inputs that all startups need to continue growing</p><ol><li><p>product capabilities</p></li><li><p>customers and users</p></li><li><p>hiring</p></li></ol><p>I've put them in roughly the order that most teams encounter them. </p><p>Startups begin with a small product that has a modicum of utility. It starts attracting a handful of customers organically. And as more and more customers start using the product, the founders realize that they need extra help to stay on top of all of those requests.</p><p>Remember though, the real goal here is #2. Itâ€™s not the size of your team, itâ€™s the value youâ€™re able to provide to the world. [5]</p><p>I see hiring a big team before you have product-market fit as a red flag. If the company doesn't yet have a set direction, it's going to be harder to pivot with 10 people than it is with 3.</p><p>But, I've worked with startups who have traction and runway... and just seem to be spinning their wheels under load from existing customers.</p><p>I get it. Hiring isn't the most fun, especially for an introvert. It's a lot of interviewing and feeling like there's a lot of rejection. Rejecting people sucks. Losing candidates sucks. For many of our roles at Segment, we've had to talk with 50-100 different people to make an eventual hire.</p><p><strong>If you have 24 months of runway, and a clear list of things youâ€™d do if you had more copies of yourself: you probably aren't spending time to hire the people you need.</strong></p><p>At Segment, my co-founder <a href="https://twitter.com/ivolo">Ilya</a> fulfilled this role. It was back in 2014, we were 12 people at the time, had raised a $10m Series A, and had $1m in revenue.</p><p>Thing…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calv.info/early-stage-lessons">https://calv.info/early-stage-lessons</a></em></p>]]>
            </description>
            <link>https://calv.info/early-stage-lessons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321667</guid>
            <pubDate>Sun, 06 Dec 2020 06:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semantic segmentation algorithms do not generalize to off-road datasets]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25321540">thread link</a>) | @srik901
<br/>
December 5, 2020 | https://unmannedlab.github.io/research/RELLIS-3D | <a href="https://web.archive.org/web/*/https://unmannedlab.github.io/research/RELLIS-3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>
<a href="https://www.tamu.edu/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/tamu_logo.png" alt="Texas A&amp;M University" height="90px" width="450px"></a>    <a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="CCDC Army Research Laboratory" height="90px" width="270px"></a></p>
<p>
Peng Jiang<sup>1</sup>, Philip Osteen<sup>2</sup>, Maggie Wigness<sup>2</sup> and Srikanth Saripalli<sup>1</sup><br>
1. <a href="https://www.tamu.edu/">Texas A&amp;M University; </a> 2. <a href="https://www.arl.army.mil/">CCDC Army Research Laboratory</a><br>
<a href="https://unmannedlab.github.io/research/RELLIS-3D">[Website]</a> <a href="https://arxiv.org/abs/2011.12954">[Paper]</a> <a href="https://github.com/unmannedlab/RELLIS-3D">[Github]</a> 
</p>
<h2 id="overview">Overview</h2>
<p>Semantic scene understanding is crucial for robust and safe autonomous navigation, particularly so in off-road environments. Recent deep learning advances for 3D semantic segmentation rely heavily on large sets of training data; however, existing autonomy datasets represent urban environments or lack multimodal off-road data. We fill this gap with RELLIS-3D, a multimodal dataset collected in an off-road environment containing annotations for <strong>13,556 LiDAR scans</strong> and <strong>6,235 images</strong>. The data was collected on the Rellis Campus of Texas A\&amp;M University and presents challenges to existing algorithms related to class imbalance and environmental topography. Additionally, we evaluate the current state of the art deep learning semantic segmentation models on this dataset. Experimental results show that RELLIS-3D presents challenges for algorithms designed for segmentation in urban environments. Except for the annotated data, the dataset also provides full-stack sensor data in ROS bag format, including <strong>RGB camera images</strong>, <strong>LiDAR point clouds</strong>, <strong>a pair of stereo images</strong>, <strong>high-precision GPS measurement</strong>, and <strong>IMU data</strong>. This novel dataset provides the resources needed by researchers to develop more advanced algorithms and investigate new research directions to enhance autonomous navigation in off-road environments.</p>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/data_example.png">
</p>
<h3 id="recording-platform">Recording Platform</h3>
<ul>
  <li><a href="https://clearpathrobotics.com/warthog-unmanned-ground-vehicle-robot/">Clearpath Robobtics Warthog</a></li>
</ul>

<h3 id="sensor-setup">Sensor Setup</h3>
<ul>
  <li>64 channels Lidar: <a href="https://ouster.com/products/os1-lidar-sensor">Ouster OS1</a></li>
  <li>32 Channels Lidar: <a href="https://velodynelidar.com/vlp-32c.html">Velodyne Ultra Puck</a></li>
  <li>3D Stereo Camera: <a href="https://nerian.com/products/karmin2-3d-stereo-camera/">Nerian Karmin2</a> + <a href="https://nerian.com/products/scenescan-stereo-vision/">Nerian SceneScan</a></li>
  <li>RGB Camera: <a href="https://www.baslerweb.com/en/products/cameras/area-scan-cameras/ace/aca1920-50gc/">Basler acA1920-50gc</a> + <a href="https://www.edmundoptics.com/p/16mm-focal-length-hp-series-fixed-focal-length-lens/28990/">Edmund Optics 16mm/F1.8 86-571</a></li>
  <li>Inertial Navigation System (GPS/IMU): <a href="https://www.vectornav.com/products/vn-300">Vectornav VN-300 Dual Antenna GNSS/INS</a></li>
</ul>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/sensor_setup.png">
</p>
<h2 id="annotated-data">Annotated Data:</h2>
<h3 id="ontology">Ontology:</h3>
<p>With the goal of providing multi-modal data to enhance autonomous off-road navigation, we defined an ontology of object and terrain classes, which largely derives from <a href="http://rugd.vision/">the RUGD dataset</a> but also includes unique terrain and object classes not present in RUGD. Specifically, sequences from this dataset includes classes such as mud, man-made barriers, and rubble piles. Additionally, this dataset provides a finer-grained class structure for water sources, i.e., puddle and deep water, as these two classes present different traversability scenarios for most robotic platforms. Overall, 20 classes (including void class) are present in the data.</p>

<p><strong>Ontology Definition</strong> (<a href="https://drive.google.com/file/d/1K8Zf0ju_xI5lnx3NTDLJpVTs59wmGPI6/view?usp=sharing">Download 18KB</a>)</p>

<h3 id="images-statics">Images Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/img_dist.png">
</p>
<h3 id="image-download">Image Download:</h3>

<p><strong>Image with Annotation Examples</strong> (<a href="https://drive.google.com/file/d/1wIig-LCie571DnK72p2zNAYYWeclEz1D/view?usp=sharing">Download 3MB</a>)</p>

<p><strong>Full Images</strong> (<a href="https://drive.google.com/file/d/1F3Leu0H_m6aPVpZITragfreO_SGtL2yV/view?usp=sharing">Download 11GB</a>)</p>

<p><strong>Full Image Annotations</strong> (<a href="https://drive.google.com/file/d/16URBUQn_VOGvUqfms-0I8HHKMtjPHsu5/view?usp=sharing">Download 94MB</a>)</p>

<p><strong>Image Split File</strong> (<a href="https://drive.google.com/file/d/1zHmnVaItcYJAWat3Yti1W_5Nfux194WQ/view?usp=sharing">44KB</a>)</p>

<h3 id="lidar-scans-statics">LiDAR Scans Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/pt_dist.png">
</p>

<h3 id="lidar-download">LiDAR Download:</h3>

<ul>
  <li>
    <p>LiDAR with Annotation Examples (<a href="https://drive.google.com/file/d/1QikPnpmxneyCuwefr6m50fBOSB2ny4LC/view?usp=sharing">Download 24MB</a>)</p>
  </li>
  <li>
    <p>LiDAR with Color Annotation PLY Format (<a href="https://drive.google.com/file/d/1BZWrPOeLhbVItdN0xhzolfsABr6ymsRr/view?usp=sharing">Download 26GB</a>)</p>
  </li>
  <li>
    <p>LiDAR SemanticKITTI Format (<a href="https://drive.google.com/file/d/1lDSVRf_kZrD0zHHMsKJ0V1GN9QATR4wH/view?usp=sharing">Download 14GB</a>)</p>
  </li>
  <li>
    <p>LiDAR Annotation SemanticKITTI Format (<a href="https://drive.google.com/file/d/1LUmmO2imJ4m5uCtGv1FYusCo-bEPDbBx/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Scan Poses files (<a href="https://drive.google.com/file/d/1cyVqJEnlzO9ANOP7hU8GJk28ckPDUSGv/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Split File (<a href="https://drive.google.com/file/d/1raQJPySyqDaHpc53KPnJVl3Bln6HlcVS/view?usp=sharing">75KB</a>)</p>
  </li>
</ul>

<h3 id="calibration-download">Calibration Download:</h3>
<ul>
  <li>
    <p>Camera Instrinsic (<a href="https://drive.google.com/file/d/1NAigZTJYocRSOTfgFBddZYnDsI_CSpwK/view?usp=sharing">Download 2KB</a>)</p>
  </li>
  <li>
    <p>Camera to LiDAR (<a href="https://drive.google.com/file/d/1Xra1E8Bc4l5VwjjNm7o41nDFO29nmx-u/view?usp=sharing">Download 3KB</a>)</p>
  </li>
</ul>

<h2 id="benchmarks">Benchmarks</h2>

<h3 id="image-semantic-segmenation">Image Semantic Segmenation</h3>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vr3g6lCTKRM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h3 id="lidar-semantic-segmenation">LiDAR Semantic Segmenation</h3>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/wkm8UiVNGao" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2 id="ros-bag-raw-data">ROS Bag Raw Data</h2>

<p>Data included in raw ROS bagfiles:</p>

<table>
  <thead>
    <tr>
      <th>Topic Name</th>
      <th>Message Tpye</th>
      <th>Message Descriptison</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>/img_node/intensity_image</td>
      <td>sensor_msgs/Image</td>
      <td>Intensity image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/noise_image</td>
      <td>sensor_msgs/Image</td>
      <td>Noise image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/range_image</td>
      <td>sensor_msgs/Image</td>
      <td>Range image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/imu/data</td>
      <td>sensor_msgs/Imu</td>
      <td>Filtered imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/data_raw</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/nerian_stereo/left_image</td>
      <td>sensor_msgs/Image</td>
      <td>Left image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/nerian_stereo/right_image</td>
      <td>sensor_msgs/Image</td>
      <td>Right image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/odometry/filtered</td>
      <td>nav_msgs/Odometry</td>
      <td>A filtered local-ization estimate based on wheel odometry (en-coders) and integrated IMU from Warthog</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/imu</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>Point cloud data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/imu_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw imu data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/lidar_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw lidar data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/vectornav/GPS</td>
      <td>sensor_msgs/NavSatFix</td>
      <td>INS data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/IMU</td>
      <td>sensor_msgs/Imu</td>
      <td>Imu data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Odom</td>
      <td>nav_msgs/Odometry</td>
      <td>Odometry from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Pres</td>
      <td>sensor_msgs/FluidPressure</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/vectornav/Temp</td>
      <td>sensor_msgs/Temperature</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/velodyne_points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>PointCloud produced by the Velodyne Lidar</td>
    </tr>
  </tbody>
</table>

<h3 id="ros-bag-download">ROS Bag Download</h3>

<p><strong>ROS Bag Examples</strong> (<a href="https://drive.google.com/file/d/163pEtjMhcM1OJo36ZOi6_zDHpuPSL8us/view?usp=sharing">2GB</a>)</p>

<p><strong>Sequence 00000</strong>: Synced data: (<a href="https://drive.google.com/file/d/10dHPMCschg1dMeb_Y6pcPvC-HZQZ8_ek/view?usp=sharing">12GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1d-t4P1idWkfxDEkodBrsbd4B2nAc8rZ3/view?usp=sharing">23GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1IZ-Tn_kzkp82mNbOL_4sNAniunD7tsYU?usp=sharing">29GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qc7IepWGKr8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00001</strong>: Synced data: (<a href="https://drive.google.com/file/d/1I98lEog0xFFAVVZ_AEBvXzIEcFQ2bGRl/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1LogHRN1ElE2xryILMPU3OtnV6VCnjs52/view?usp=sharing">16GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1hf-vF5zyTKcCLqIiddIGdemzKT742T1t?usp=sharing">22GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nO5JADjDWQ0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00002</strong>: Synced data: (<a href="https://drive.google.com/file/d/1yhohyWOIIf00YLUZ1RT7ouq3B-iaOU91/view?usp=sharing">14GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1F_8yviLHcAVmBpWEyCITFd1nRgPRmkVX/view?usp=sharing">28GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1R8jP5Qo7Z6uKPoG9XUvFCStwJu6rtliu?usp=sharing">37GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aXaOmzjHmNE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00003</strong>:Synced data: (<a href="https://drive.google.com/file/d/1poY5eaKKhmjUQpF1rsoL4mm4wO7T8CJM/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1HDbtqaYhfeyLoq9UsxOhgCJl2urGVKUc/view?usp=sharing">15GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1iP0k6dbmPdAH9kkxs6ugi6-JbrkGhm5o?usp=sharing">19GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Kjo3tGDSbtU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00004</strong>:Synced data: (<a href="https://drive.google.com/file/d/1xLvai6rorpjxRZXraZK7qPsA1vYMkTHJ/view?usp=sharing">7GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1usxAjxHrw89R6rMA0GtmYQRtzIP-QGJF/view?usp=sharing">14GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1WV9pecF2beESyM7N29W-nhi-JaoKvEqc?usp=sharing">17GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/lLLYTI4TCD4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h2 id="full-data-download">Full Data Download:</h2>
<p><a href="https://drive.google.com/drive/folders/1aZ1tJ3YYcWuL3oWKnrTIC5gq46zx1bMc?usp=sharing">Access Link</a></p>

<h2 id="citation">Citation</h2>
<div><div><pre><code>@misc{jiang2020rellis3d,
      title={RELLIS-3D Dataset: Data, Benchmarks and Analysis}, 
      author={Peng Jiang and Philip Osteen and Maggie Wigness and Srikanth Saripalli},
      year={2020},
      eprint={2011.12954},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre></div></div>

<h2 id="collaborator">Collaborator</h2>
<p><a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="The DEVCOM Army Research Laboratory"></a></p>

<h2 id="license">License</h2>
<p>All datasets and code on this page are copyright by us and published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License.</p>



<p><a href="https://unmannedlab.github.io/research/SemanticUSL">SemanticUSL: A Dataset for Semantic Segmentation Domain Adatpation</a></p>

<p><a href="https://unmannedlab.github.io/research/LiDARNet">LiDARNet: A Boundary-Aware Domain Adaptation Model for Lidar Point Cloud Semantic Segmentation</a></p>

  </article></div>]]>
            </description>
            <link>https://unmannedlab.github.io/research/RELLIS-3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321540</guid>
            <pubDate>Sun, 06 Dec 2020 06:15:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All good writing is swimming underwater and holding your breath]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25321207">thread link</a>) | @thecodrr
<br/>
December 5, 2020 | https://blog.streetwriters.co/how-to-write-good-metaphors/ | <a href="https://web.archive.org/web/*/https://blog.streetwriters.co/how-to-write-good-metaphors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Metaphors are everywhere;&nbsp;in literature, visual arts, poetry, and films. Language, in a way, itself&nbsp;is a metaphor. But try to make one on the fly, and you will find out it is not easy. Creating a metaphor requires ingenuity and care. A small mistake can make a metaphor clumsy. So how does one write a good metaphor?&nbsp;Let’s find out.</p><h2>Why Metaphors are Important</h2><p>Metaphors make us understand things better. When feelings are involved or when something happens which has no proper words in our vocabulary, we need something to communicate our experience. Metaphors come in handy in such situations. For example, author F. Scott Fitzgerald wanted to describe good writing. He could simply say that good writing was hard or good writing is very difficult. But he chose to say it like this:</p><p><em>All good writing is swimming underwater and holding your breath.</em></p><p>The metaphor&nbsp;“swimming underwater while holding breath” opens a door for us into the experience of Fitzgerald as a writer. That was a very difficult thing to convey in plain words. A whole paragraph might have not sufficed. But here a metaphor has conveyed the meaning completely in a single sentence. Metaphors help us convey meaning by using similarities in different objects and experiences. They relate things with one another and the result is a new understanding of a certain thing. All good poetry and literature do this to create new meanings. Another example is this beautiful metaphor by Shakespeare:</p><blockquote><p>All the world's a stage,<br>And all the men and women merely players;<br>They have their exits and their entrances;<br>And one man in his time plays many parts.</p><p><em>As You Like It</em>, William Shakespeare</p></blockquote><p>Metaphors help us use all of our senses in reading a sentence. They make the experience of language more immersive. Take this sentence as an example:</p><blockquote><p>Time has not stood still. It has washed over me, washed me away as if I'm nothing more than a woman of sand, left by a careless child too near the water.</p><p><em>The Handmaid's Tale</em>, Margaret Atwood</p></blockquote><p>The writer could simply have said that time has changed me. But the use of sand and water as metaphors has given the whole experience a life of its own. We can hear in our minds the sound of waves when reading the sentence. We can imagine a woman of sand. Therefore, metaphors give a deeper meaning to our words. They can convey meanings for which sometimes whole pages are necessary and sometimes even a book is not enough.</p><blockquote><p>I'm a little pencil in the hand of a writing God.</p><p>Mother Teresa</p></blockquote><p>In this small sentence, Mother Teresa has conveyed the whole of her faith. We can get a glimpse of her intimate relationship with God. We can sense her metaphysical experience. This was not possible without the use of a metaphor.</p><p>Along with that, plain words can be boring for our minds. Our minds hate repetitiveness and mundaneness and loves newness and ingenuity. Metaphors give us this freshness and livens ordinary language. Language becomes more interesting.</p><blockquote><p>She herself is a haunted house. She does not possess herself; her ancestors sometimes come and peer out of the windows of her eyes and that is very frightening.</p><p><em>The Bloody Chamber, </em>Angela Carter</p></blockquote><p>Simply saying that there is an eerie feeling attached to her the writer could have told us about the character but using a metaphor makes it more interesting and memorable. In addition to that, Metaphors add vagueness and abstractedness to our language. This gives readers free rein to make their own interpretations.</p><blockquote><p><em>There's a bluebird in my heart that<br></em><em>wants</em><em> to get out<br></em><em>but</em><em> I'm too tough for him,<br></em><em>I say, stay in there, I'm not going<br></em><em>to</em><em> let anybody see<br></em><em>you</em><em>.</em></p><p><em>Bluebird</em>, Charles Bukowski</p></blockquote><p>Nobody has a clear idea of what the bluebird is in this poem and so people make their interpretations. Metaphors give us the freedom to read works in the context of our own Worldview.</p><h2>How to Write Good Metaphors?</h2><p>First of all, start thinking about the thing or experience you want to express. Concentrate on the idea and think about it deeply. Understand it thoroughly. How do you feel about the whole idea?</p><p>For example, you want to describe the scene of someone waking up for the first time to the sound of the coming train. Lean into the experience of someone peacefully sleeping in a cozy room under blankets in a comfy bed. Now imagine a train passing over with an ear-shattering sound. What will the character feel like? Imagine it. Now can you compare it to something else that is similar in its sudden experience?</p><p>For me, the scene of a car suddenly breaking through the bedroom wall is similar so I would construct my metaphor around that imagery.</p><p><em>He woke up and thought a car had crashed in his bedroom. Everything was moving. His heart was pumping. "Oh! It's the train!" he let out a sigh and shook his head.</em></p><p>Secondly, try using original metaphors in your writing or ones that are rare. Commonly used metaphors are dead in a sense. Some dead metaphors are given here as an example:</p><ul><li>It's raining cats and dogs.</li><li>I'm visiting an old flame.</li><li>He's loose cannon.</li><li>She found herself behind the eight balls.</li><li>He drives me up a wall.</li><li>She saw the light at the end of the tunnel.</li><li>Ticking time bomb</li><li>Tip of the iceberg</li><li>Slippery slope</li><li>Going the extra mile</li><li>Early bird</li><li>Icy personality</li><li>Turning in one's grave</li><li>About to explode (from anger)</li></ul><p>Here are some more complex examples of metaphors. Read them carefully so you can get an idea of how a metaphor works.</p><p><em>1. Books are the mirrors of the soul.</em></p><p>Virginia Woolf describes here the connection between an author and his/her books. Books describe the inner thoughts of the author's mind. That is an experience similar to seeing one's soul. A mirror reflects everything that is in front of it. It does not lie. This small sentence combines these two concepts perfectly to convey a beautiful meaning.</p><p>2. <em>"</em><em>But soft, what light through yonder window breaks? It is the east, and Juliet is the sun!"</em></p><p>Shakespeare is trying to describe the feeling of love that Romeo had for Juliet. The sun is a classic metaphor used in ancient literature to describe a lover.</p><p>3. <em>The parents looked upon Matilda in particular as nothing more than a scab. A scab is </em><em>something you have to put up with until the time comes when you can pick it off and flick </em><em>it away.</em></p><p>The author here depicts the anger Matilda's parents felt for their child using “a scab on skin”. A person puts up with it because it's painful and messy to remove it before time.</p><p>4. <em>"O Lord, You are our Father, We are the clay, and You, our potter; And all of us are the work of Your hand."</em></p><p>In this verse of the Bible, the feeling of helplessness and the might of the All-Mighty God is described. Helplessness is compared with the inertness of the clay. And the potter's hands are the workings of God.</p><p>5. <em>Alas,</em><em> and yet what are you, my written and painted thoughts! It is not long ago that you were still so many-</em><em>coloured</em><em>, young, and malicious, so full of thorns and hidden spices you made me sneeze and laugh and now? You </em><em>have already taken off your novelty and some of you, I fear, are on the point of becoming truths: they already look so immortal, so pathetically righteous, so boring! And has it ever been otherwise? For what things do we write and paint, we mandarins with </em><em>Chinese brushes, we immortalizers of things which let themselves </em><em>be</em><em> written, what alone are we capable of painting? Alas, only that which is about to wither and is beginning to lose its fragrance! Alas, only storms departing exhausted and feelings grown old and yellow! Alas, only birds strayed and grown weary in flight </em><em>who</em><em> now let themselves be caught in the hand in our hand! We immortalize that which cannot live and fly much longer, weary and mellow things alone! And it is only your afternoon, my written and painted thoughts, for which alone I have the </em><em>colours</em><em>, many </em><em>colours</em><em> perhaps, many many-</em><em>coloured</em><em>&nbsp;</em><em>tendernesses</em><em> and fifty yellows and browns and greens and reds: but no one will divine from these how you looked in your morning, you sudden sparks and wonders of my solitude, you my old beloved wicked thoughts!</em></p><p>Here Nietzsche is describing the thoughts in the human mind which are immortal, ever-changing with infinite possibilities, and how impossible it is to define them truly words.</p><h2>Conclusion</h2><p>Good metaphors spice up any piece of art, be it a painting or a poem or a novel. Some writers use whole characters as forms of metaphors, others use symbolism. Learning to write a good metaphor can be a difference between a good piece and a great piece. Here are some other resources you can consult:</p><ol><li><a href="https://prowritingaid.com/Metaphors">Metaphor - The Grammar Guide</a></li><li><a href="https://www.liminalpages.com/write-powerful-metaphors">How to Write Powerful Metaphors</a></li></ol></div></div>]]>
            </description>
            <link>https://blog.streetwriters.co/how-to-write-good-metaphors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321207</guid>
            <pubDate>Sun, 06 Dec 2020 05:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to generate random points on a sphere]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25321067">thread link</a>) | @pabs3
<br/>
December 5, 2020 | https://www.rojtberg.net/1985/how-to-generate-random-points-on-a-sphere/ | <a href="https://web.archive.org/web/*/https://www.rojtberg.net/1985/how-to-generate-random-points-on-a-sphere/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This question often pops up, when you need a random direction vector to place things in 3D or you want to do a particle simulation.</p>



<p>We recall that a 3D unit-sphere (and hence a direction) is parametrized only by two variables; elevation <span data-display="false">\theta \in [0; \pi]</span> and azimuth <span data-display="false">\varphi \in [0; 2\,\pi]</span> which <a href="https://en.wikipedia.org/wiki/Spherical_coordinate_system#Coordinate_system_conversions">can be converted to Cartesian coordinates as</a></p>



<p><span data-display="false">\begin{aligned}  x &amp;= \sin\theta \, \cos\varphi \\  y &amp;= \sin\theta \, \sin\varphi \\  z &amp;= \cos\theta \end{aligned} </span></p><p>If one takes the easy way and uniformly samples this parametrization in numpy like</p>



<pre><code>phi = np.random.rand() * 2 * np.pi
theta = np.random.rand() * np.pi</code></pre>



<p>One (i.e. you as you are reading this) ends with something like this:</p>



<figure><ul><li><figure><a href="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere_uv.png?ssl=1" data-slb-active="1" data-slb-asset="161658899" data-slb-internal="0" data-slb-group="1985"><img loading="lazy" width="621" height="465" src="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere_uv.png?resize=621%2C465&amp;ssl=1" alt="" data-id="2002" data-full-url="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere_uv.png?resize=621%2C465&amp;ssl=1" data-link="https://www.rojtberg.net/?attachment_id=2002" srcset="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere_uv.png?w=621&amp;ssl=1 621w, https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere_uv.png?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 621px) 100vw, 621px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere_uv.png?w=621&amp;ssl=1 621w, https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere_uv.png?resize=300%2C225&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere_uv.png?resize=621%2C465&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>uniform: spherical coordinates</figcaption></figure></li><li><figure><a href="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere.png?ssl=1" data-slb-active="1" data-slb-asset="520479777" data-slb-internal="0" data-slb-group="1985"><img loading="lazy" width="660" height="660" src="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere.png?resize=660%2C660&amp;ssl=1" alt="" data-id="2001" data-full-url="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere.png?resize=660%2C660&amp;ssl=1" data-link="https://www.rojtberg.net/?attachment_id=2001" srcset="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere.png?w=697&amp;ssl=1 697w, https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere.png?resize=300%2C300&amp;ssl=1 300w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere.png?w=697&amp;ssl=1 697w, https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere.png?resize=300%2C300&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/rng_sphere.png?resize=660%2C660&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>biased: 3D projection to Cartesian coordinates</figcaption></figure></li></ul></figure>



<p>While the 2D surface of polar coordinates uniformly sampled (left), we observe a bias of sampling density towards the poles when projecting to the Cartesian coordinates (right).<br>The issue is that the cos mapping of the elevation has an uneven step size in <em>Cartesian</em> space, as you can easily verify: <span data-display="false">cos^{'}(x) = sin(x)</span>.</p>



<p>The solution is to simply sample the elevation in the Cartesian space instead of the spherical space – i.e. sampling <span data-display="false">z \in [-1; 1]</span>. From that we can get back to our elevation as <span data-display="false">\theta = \arccos z</span>:</p>



<pre id="block-6ecb681a-6f13-49b9-8783-cebd81f25d08"><code>z = 1 - np.random.rand() * 2 # convert rand() range 0..1 to -1..1
theta = np.arccos(z)</code></pre>



<p>As desired, this compensates the spherical coordinates such that we end up with uniform sampling in the Cartesian space:</p>



<figure><ul><li><figure><a href="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere_uv.png?ssl=1" data-slb-active="1" data-slb-asset="1631419618" data-slb-internal="0" data-slb-group="1985"><img loading="lazy" width="621" height="465" src="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere_uv.png?resize=621%2C465&amp;ssl=1" alt="" data-id="2000" data-full-url="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere_uv.png?resize=621%2C465&amp;ssl=1" data-link="https://www.rojtberg.net/?attachment_id=2000" srcset="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere_uv.png?w=621&amp;ssl=1 621w, https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere_uv.png?resize=300%2C225&amp;ssl=1 300w" sizes="(max-width: 621px) 100vw, 621px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere_uv.png?w=621&amp;ssl=1 621w, https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere_uv.png?resize=300%2C225&amp;ssl=1 300w" data-lazy-src="https://i0.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere_uv.png?resize=621%2C465&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>compensated spherical coordinates</figcaption></figure></li><li><figure><a href="https://i1.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere.png?ssl=1" data-slb-active="1" data-slb-asset="1494747339" data-slb-internal="0" data-slb-group="1985"><img loading="lazy" width="660" height="660" src="https://i1.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere.png?resize=660%2C660&amp;ssl=1" alt="" data-id="1999" data-full-url="https://i1.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere.png?resize=660%2C660&amp;ssl=1" data-link="https://www.rojtberg.net/?attachment_id=1999" srcset="https://i1.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere.png?w=697&amp;ssl=1 697w, https://i1.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere.png?resize=300%2C300&amp;ssl=1 300w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere.png?w=697&amp;ssl=1 697w, https://i1.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere.png?resize=300%2C300&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/crng_sphere.png?resize=660%2C660&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>uniform: 3D Cartesian coordinates</figcaption></figure></li></ul></figure>



<h2>Custom opening angle</h2>



<p>If you want to further restrict the opening angle instead of sampling the full sphere you can also easily extend the above. Here, you must re-map the cos values from <span data-display="false">[1; -1]</span> to <span data-display="false">[0; 2]</span> as</p>



<pre id="block-f289f7b0-bd4e-4ad9-9ebc-38537536d919"><code>cart_range = -np.cos(angle) + 1 # maximal range in cartesian coords
z = 1 - np.random.rand() * cart_range
theta = np.arccos(z)</code></pre>



<figure><a href="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/Figure_1-1.png?ssl=1" data-slb-active="1" data-slb-asset="353387147" data-slb-internal="0" data-slb-group="1985"><img loading="lazy" width="660" height="330" src="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/Figure_1-1.png?resize=660%2C330&amp;ssl=1" alt="" srcset="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/Figure_1-1.png?w=720&amp;ssl=1 720w, https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/Figure_1-1.png?resize=300%2C150&amp;ssl=1 300w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/Figure_1-1.png?w=720&amp;ssl=1 720w, https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/Figure_1-1.png?resize=300%2C150&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/www.rojtberg.net/wp-content/uploads/2020/12/Figure_1-1.png?resize=660%2C330&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>



<h2>Optimized computation </h2>



<p>If you do not actually need the parameters <span data-display="false">\theta, \varphi</span>, you can spare some trigonometric functions by using <span data-display="false">\sin \theta = \sqrt { 1 - z^2}</span> as</p>



<p><span data-display="false">\begin{aligned} x &amp;= \sqrt { 1 - z^2} \, \cos\varphi \\ y &amp;= \sqrt { 1 - z^2} \, \sin\varphi \end{aligned}</span>
	</p></div></div>]]>
            </description>
            <link>https://www.rojtberg.net/1985/how-to-generate-random-points-on-a-sphere/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321067</guid>
            <pubDate>Sun, 06 Dec 2020 04:35:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenVMS Notes: WASD HTTPd (and the y2k20 dilemma)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25321056">thread link</a>) | @indigodaddy
<br/>
December 5, 2020 | http://neilrieck.net/docs/openvms_notes_wasd.html | <a href="https://web.archive.org/web/*/http://neilrieck.net/docs/openvms_notes_wasd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
        <div>
		<p><img src="http://neilrieck.net/images/digital-shark.gif" alt=""></p>
<p>
Edit: 2020-04-13 (<span>this is a work in progress</span>)
<a id="intro1"></a></p><h2>2k20 - a potential crisis in 2020 </h2>
<p>Modern browsers in 2020 will expect to 
	"connect HTTPS" only using TLSv1.2 and TLSv1.3 (this assumes that support for 
	everything from SSLv3 to TLSv1.1 will be removed)</p>
<ul>
	<li>
	<a href="https://www.zdnet.com/article/chrome-edge-ie-firefox-and-safari-to-disable-tls-1-0-and-tls-1-1-in-2020/">https://www.zdnet.com/article/chrome-edge-ie-firefox-and-safari-to-disable-tls-1-0-and-tls-1-1-in-2020/</a></li>
	<li>
	<a href="https://www.cso.com.au/article/648261/tls-1-0-1-1-will-disabled-edge-ie-chrome-firefox-safari-2020/">https://www.cso.com.au/article/648261/tls-1-0-1-1-will-disabled-edge-ie-chrome-firefox-safari-2020/</a></li>
	<li>
	<a href="https://blog.pcisecuritystandards.org/are-you-ready-for-30-june-2018-sayin-goodbye-to-ssl-early-tls">https://blog.pcisecuritystandards.org/are-you-ready-for-30-june-2018-sayin-goodbye-to-ssl-early-tls</a></li>
	<li>
	<a href="https://www.feistyduck.com/bulletproof-tls-newsletter/issue_46_the_end_of_tls_1_0_and_1_1">
	https://www.feistyduck.com/bulletproof-tls-newsletter/issue_46_the_end_of_tls_1_0_and_1_1</a></li>
	<li>
	<a href="https://www.zdnet.com/article/browsers-to-block-access-to-https-sites-using-tls-1-0-and-1-1-starting-this-month/">
	https://www.zdnet.com/article/browsers-to-block-access-to-https-sites-using-tls-1-0-and-1-1-starting-this-month/</a> 
	(2020-03)</li>
</ul>
<p>While browsers are constantly being updated because of their financial 
	use in everything from on-line purchases to on-line investing and banking, 
many web servers are not. What is worse it this: many organizations, including 
	governments large and small, are slow to update software</p>
<ul>
	<li>
	<a href="https://www.newscientist.com/article/2197453-exclusive-thousands-of-security-flaws-found-on-uk-government-websites/">https://www.newscientist.com/article/2197453-exclusive-thousands-of-security-flaws-found-on-uk-government-websites/</a></li>
	<li><a href="https://www.us-cert.gov/ncas/alerts">https://www.us-cert.gov/ncas/alerts</a></li>
</ul>
<p><span>comment:</span> Firefox has been warning for several months 
(today is 2019-08-25) that one of my servers is preferentially offering 
connections via TLS-1.0 (the lock icon is closed but is orange). Chrome and IE11 
each present a green lock icon.</p>
<h3><a name="openvms"></a>The OpenVMS ecosystem</h3>
<ul>
	<li>Two companies are currently supporting OpenVMS (but this is about to 
	change)<ul>
		<li>In 2014, HP transferred the rights to develop/support OpenVMS to VSI 
		(<a href="https://www.vmssoftware.com/">VMS Software Inc</a>)</li>
		<li>In 2015, HP split into two companies: HP (most desktop products) and 
		HPE (enterprise)</li>
		<li>HPE continued to support OpenVMS software contracts sold to HP customers 
		before 2015 (they also sold/supported VSI products)</li>
		<li>Early in 2019, HPE removed most OpenVMS stuff (documentation as well 
		as software) from their website including CSWS-2.2-1 (<a href="http://neilrieck.net/docs/openvms_notes_apache.html">Compaq Secure Web Services</a>) 
	based upon <span>Apache 2.0.63</span><ul>
			<li>For example, this link:
			<a href="http://h41379.www4.hpe.com/openvms/products/ips/apache/csws.html">http://h41379.www4.hpe.com/openvms/products/ips/apache/csws.html</a> 
		previously provided both software-downloads and product documentation 
		but now diverts you to this common landing page:
			<a href="https://support.hpe.com/hpsc/doc/public/display?docId=a00058693en_us">https://support.hpe.com/hpsc/doc/public/display?docId=a00058693en_us</a> 
		(in fact, all HPE OpenVMS software links now drop you here)</li>
		</ul>
		</li>
		<li>If you have an OpenVMS support contract with HPE, then you will be 
		able to request the latest version of file MOD_SSL (an Apache module for 
		CSWS) which is based upon OpenSSL-1.0L but does not implement TLSv1.3<ul>
			<li>HPE has announced the end of all OpenVMS support by the end of 2020.</li>
		</ul>
		</li>
		<li>Businesses requiring <strong>CSWS/Apache on OpenVMS</strong> should immediately 
	move their support contracts over to VSI where you will have access to a new version of CSWS 
	based upon <span>Apache 2.4.12</span><ul>
			<li><span>caveat:</span> you may be required to update your OS to OpenVMS-8.4-2 so do not wait until the last minute</li>
		</ul>
		</li>
	</ul>
	</li>
	<li>For companies and/or hobbyists financially unable to move to VMS 
	Software Inc., your the only remaining option is to replace CSWS/Apache with WASD HTTPd 
	(the high quality web server from down-under) which is not based upon 
	Apache.<ul>
		<li>WASD already supports TLSv1.2 and TLSv1.3</li>
		<li>"I think" support agreements may be available</li>
	</ul>
	</li>
	<li>This web-page will document my efforts to replace CSWS/Apache with WASD 
	HTTPd on a sacrificial laboratory system (we employ a lot of CGI including one SOAP-based 
	feed)</li>
	<li>Web server products available for VMS/OpenVMS<table>
		<tbody><tr>
			<th>Publisher</th>
			<th>Product Name</th>
			<th>Apache<br>Version</th>
			<th>VAX</th>
			<th>Alpha</th>
			<th>Itanium</th>
			<th>x86-64</th>
			<th>Active</th>
			<th>Notes</th>
		</tr>
		<tr>
			<td>Compaq/HP/HPE</td>
			<td>CSWS (1)</td>
			<td>2.0.xx</td>
			<td>N</td>
			<td>Y</td>
			<td>Y</td>
			<td>N</td>
			<td>?</td>
			<td>HPE will exit the OpenVMS business in 2020<br>Old CSWS 
			(products, patches, plugins) were free up until 2016<br>Since then 
			only patches are available if you have an HPE support agreement</td>
		</tr>
		<tr>
			<td>VSI</td>
			<td>CSWS (2)</td>
			<td>2.4</td>
			<td>N</td>
			<td>Y</td>
			<td>Y</td>
			<td>Y</td>
			<td>Y</td>
			<td>New CSWS (available with new support agreement)</td>
		</tr>
		<tr>
			<td>Ohio State University</td>
			<td><span>OSU DECthreads</span></td>
			<td>n/a</td>
			<td>Y</td>
			<td>Y</td>
			<td>N</td>
			<td>N</td>
			<td>N</td>
			<td>Product hasn't been supported for more than a decade<br>Can be 
			found on the VMS Freeware packages</td>
		</tr>
		<tr>
			<td><span>VSM Software Services</span></td>
			<td><strong>WASD HTTPd</strong></td>
			<td>n/a</td>
			<td>Y</td>
			<td>Y</td>
			<td>Y</td>
			<td>Y</td>
			<td>Y</td>
			<td>Still actively supported</td>
		</tr>
	</tbody></table>
	</li>
</ul>
<h2><a name="intro2"></a>Introduction to WASD HTTPd</h2>
<ul>
	<li><a href="http://wasd.vsm.com.au/">WASD</a> HTTPd - is a very high quality free 
	web 
		server from <a href="http://www.vsm.com.au/">VSM Software 
	Services</a> in Australia<ul>
		<li>it runs on all VMS and OpenVMS platforms: <span>VAX, Alpha, and Itanium</span></li>
		<li>it will run on <span>x86-64</span> when VSI finally 
		publishes a OpenVMS-9 for that CPU architecture</li>
		<li>it is NOT based upon Apache</li>
		<li>it is published with all the source code so if you can program 
			in C then you can improve/extend/tinker</li>
		<li>it can link to its own SSL libraries which already support TLS-1.3, or HP-SSL (based upon 
		OpenSSL-0.9 and lower), or HP-SSL1 (OpenSSL-1.0 and higher)</li>
		<li>excerpt from page-13 of the book <strong>OpenVMS with Apache, OSU, and WASD</strong>
		<p>
				The idea with WASD was to be a really good VMS-only server: Mark Daniel says, "I 
suffered a bit of a VMS cringe when amongst my UNIX colleagues (VMS was perceived 
to be a bit slow and cumbersome), so I have also endeavored to make WASD as fast 
and efficient as I could, avoiding C run-time library and even RMS code layers 
where it was feasible and worth it. I also wanted a similarly tight scripting 
environment and have spent a lot of time honing this aspect"</p>
		</li>
		<li><span>Trivia:</span> <strong>WASD</strong> = "Wide Area 
		Surveillance Division". WASD was previously known as <strong>HFRD</strong> 
		(High Frequency Radar Division) of Australia's Defense, Science and 
		Technology Organization</li>
	</ul>
	</li>
</ul>
<div>
	<p><strong><a id="executive"></a>Executive Summary</strong>:
	</p><ul>
		<li>What an unexpected surprise. WASD HTTPd is the fastest web server I 
		have worked on to date.<br>I am currently supporting web servers on these 
		production platforms...<table>
			<tbody><tr>
				<th>Hardware</th>
				<th>CPU</th>
				<th>Cores</th>
				<th>Memory</th>
				<th>Network</th>
				<th>OS</th>
				<th>Software</th>
			</tr>
			<tr>
				<td>rx2800-i2</td>
				<td>Itanium2</td>
				<td>8</td>
				<td>64G</td>
				<td>IPv4 on 1Gb/s</td>
				<td>OpenVMS-8.4</td>
				<td>CSWS/Apache 2.0.xx</td>
			</tr>
			<tr>
				<td>DL385p-gen8</td>
				<td>AMD x86-64</td>
				<td>24</td>
				<td>132G</td>
				<td>IPv4 on 1Gb/s</td>
				<td>CentOS-7.5</td>
				<td>Apache 2.4.xx</td>
			</tr>
			<tr>
				<td>rx2660</td>
				<td>Itanium2</td>
				<td>8</td>
				<td>16G</td>
				<td>Ipv4 on 1Gb/s</td>
				<td>OpenVMS-8.4</td>
				<td>WASD HTTPd 11</td>
			</tr>
		</tbody></table>...and it appears that 
		WASD on the oldest hardware is able to out-perform Apache on the newest 
		hardware (caveat: I 
		haven't done any full-load stress tests just yet)</li>
		<li>WASD HTTPd is published with all the source code. This means that if 
		Adelaide gets hit with an asteroid you will be able to fix your 
		own code (provided you have access to the DECC "C compiler)</li>
		<li>The source code is mirrored in at least three other locations (see 
		asteroid comment)</li>
	</ul>
</div>
<h2><a id="firststeps"></a>First Steps</h2>
<ul>
	<li>download all the zip files you think you will need from here: <a href="https://wasd.vsm.com.au/wasd/">
	https://wasd.vsm.com.au/wasd/</a> (or the various mirror sites)<ul>
		<li><span>caveat:</span> do not skip any CUP (cumulative 
		update package) files. I wasted a 
		whole day trying to get both Server Admin and SYSUAF to work (I assumed 
		I was doing something wrong). I was only successful after I noticed, 
		then installed, the CUP file (probably need new 
		eyeglasses) </li>
	</ul>
	</li>
	<li>none of these files offer executables so you will need to download a 
	vanilla package (necessary to "compile-link" or just "link") as well as the 
	architecture-specific files</li>
</ul>

<h2><a name="unzip"></a>Unzip then install</h2>
<p>Unzip</p>
<pre>$! DCL script to unzip WASD
$! this is an rx2660 (Itanium2)
$! CSWS/Apache is located on disk dka200 so that's where I'll put WASD
$!
$ define/job yada CSMIS$USER3:[ADMCSM.NEIL._WASD]	! files where downloaded here
$ set default DKA200:[000000]				! move to root of disk dka200
$ unzip yada:WASD1130.zip				! also creates folder [WASD_ROOT}
$ unzip yada:WASD1130-ia64.zip				!
$ set default [WASD_ROOT]				!
$ unzip yada:<span>WASD_CUP_1130b.ZIP</span> 			! do not forget this (or SYSUAF stuff won't work)
$ unzip yada:opensslwasd102r-ia64.zip			! optional</pre>
<p>Install (part 1) you need a DEC-C compiler to do perform step 1 so consider 
starting with step 2</p><br>
<pre>$set default wasd_root:[000000]				!
$@install						!

******************* 
*  BUILD PACKAGE  * 
******************* 

Package executables must be built.

0. skip this step 
1. compiling from source, then linking 
2. linking (separate package) object modules 

Select build method [0]:

[...snip...]</pre>
<p>Install (part 2) really cool because you have a choice</p>
<pre>************************** 
*  SSL TOOLKIT DETECTED  * 
************************** 

A supported Secure Sockets Layer (SSL) toolkit has been detected.
Those with item numbers are available for building, 'x's are not available.

0. do not build an SSL version 
1. OpenSSL (prior to v1.1.0) toolkit
x. OpenSSL (v1.1.0 or later) toolkit 
2. OpenVMS SSL1 product (HP)                    <span>(OpenSSL 1.0 and higher)</span>
x. WASD OpenSSL package                         <span>("x" because download it)</span> 
x. OpenVMS SSL product (HP) no longer supported <span>(OpenSSL 0.9 and lower)</span>

Select item number [2]:</pre>
<h2><a name="config"></a>Config then initial start</h2>
<ul>
	<li>now read
	<a href="https://wasd.vsm.com.au/wasd_root/doc/config/config_0100.html">
	install-and-config</a> as well as
	<a href="https://wasd.vsm.com.au/wasd_root/doc/features/">features</a> (or 
	download the PDFs of those html docs from <a href="https://wasd.vsm.com.au/">
	here</a>)<ul>
		<li>the vanilla http server (port 80) 
		installs itself.</li>
		<li>The secure https server (443) will not work without having
		<a href="https://wasd.vsm.com.au/wasd_root/doc/features/features_0400.html">
		chapter-4 of features</a> open while you edit the config files 
		documented in
	<a href="https://wasd.vsm.com.au/wasd_root/doc/config/config_0100.html">
	install-and-config</a>. IMHO, 
		this is a good thing since we've all worked on systems initially set up 
		by "the brain dead". Security is no laughing matter. I was not able to 
		get HTTPS working without first using the <a href="http://neilrieck.net/docs/openvms_notes_ssl.html">
		OpenSSL CLI</a> from another system</li>
	</ul>
	</li>
	<li>quick steps 1<ul>
		<li>locate your current ssl certificate file (name.crt) and key file 
		(name.key)</li>
		<li>copy both of these files into a third file with an extension of ".pem" 
		(name.pem)</li>
	</ul>
	</li>
	<li>quick steps 2:<ul>
		<li>edit this file: [WASD_ROOT.local]wasd_config_global.conf<br>
		<table>
			<tbody><tr>
				<th>field</th>
				<th>current contents</th>
				<th>new contents</th>
				<th>notes</th>
			</tr>
			<tr>
				<td>[SecureSocket]</td>
				<td>disabled</td>
				<td>enabled</td>
				<td>&nbsp;</td>
			</tr>
			<tr>
				<td>[SSLversion]</td>
				<td>TLSvALL</td>
				<td>TLSvALL,SSLv3</td>
				<td>my system will require SSLv3 for a time</td>
			</tr>
			<tr>
				<td>[SSLcipherList]</td>
				<td>&nbsp;</td>
				<td>MEDIUM:HIGH</td>
				<td>https will not work if this field is BLANK</td>
			</tr>
			<tr>
				<td>[SSLcert]</td>
				<td>&nbsp;</td>
				<td>dka100:[certificates]name.pem</td>
				<td>https will not work if this field is BLANK</td>
			</tr>
			<tr>
				<td>[SSLkey]</td>
				<td>&nbsp;</td>
				<td>&nbsp;</td>
				<td>leave this field BLANK</td>
			</tr>
			<tr>
				<td>[SSLverifyPeerCAFile]</td>
				<td>&nbsp;</td>
				<td>dka100:[certificates]vendor.crt</td>
				<td>this is the vendor's chain file (in PEM format)</td>
			</tr>
			<tr>
				<td>[Welcome]</td>
				<td>INDEX.HTML</td>
				<td>INDEX.HTML<br>DEFAULT.HTML</td>
				<td>this is standard<br>this is the name of our Apache home page</td>
			</tr>
			<tr>
				<td>[Http2Protocol]</td>
				<td>enable</td>
				<td>disable</td>
				<td>disable for use with Firefox and Chrome in 2019</td>
			</tr>
		</tbody></table>
		</li>
	</ul>
	</li>
	<li>quick step 3:<br><pre>$ @dka200:[WASD_ROOT.STARTUP]STARTUP.COM</pre></li>
	<li>https testing<ul>
		<li>testing with browsers can be problematic …</li></ul></li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://neilrieck.net/docs/openvms_notes_wasd.html">http://neilrieck.net/docs/openvms_notes_wasd.html</a></em></p>]]>
            </description>
            <link>http://neilrieck.net/docs/openvms_notes_wasd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321056</guid>
            <pubDate>Sun, 06 Dec 2020 04:33:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emulating a Computer: The CHIP-8 Interpreter]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25321051">thread link</a>) | @riverg
<br/>
December 5, 2020 | https://river.codes/emulating-a-computer-part-1/ | <a href="https://web.archive.org/web/*/https://river.codes/emulating-a-computer-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody">  <p>For several reasons, emulation has always fascinated me. A program that executes other programs sounds like such a cool concept. It really feels like you’re getting your money’s worth out of writing it! Beyond that, it definitely feels like you’re <em>building</em> a computer within software. I really enjoyed learning about computer architecture and writing some basic HDL code, but emulation is a much more straightforward way of achieving a similar feeling of generating a machine. I’ve also always had this goal of knowing exactly how <em>Super Mario World</em> worked, ever since I first saw it as a kid. Because of this, writing a SNES/SFC emulator has been on my mind for a while. I decided recently that it was time to take a <a href="https://github.com/rivergillis/chip-8">step forward</a> towards making this happen.</p> <p>So let’s take a look at writing an emulator. A simple, but complete example would involve CHIP-8.</p> <p><a href="https://en.wikipedia.org/wiki/CHIP-8">CHIP-8</a> is actually a programming language. It’s really simple too, there’s only <a href="http://devernay.free.fr/hacks/chip8/C8TECH10.HTM#3.0">35 opcodes</a>. To write an interpreter for it, we pretty much just need to write a program that can execute all 35 different instructions. The <em>emulation</em> aspect of this comes from the bits you wouldn’t normally find in a programming language interpreter. We need a way to display graphics, process user input, play audio, and we need to simulate the hardware mechanisms of a CHIP-8 machine. Things like registers and memory need to be taken into account during execution, and we also need to be careful about timing.</p> <p>Let’s start! For this project, we’ll be using C++. This should be fairly trivial to translate into other languages. If you want to take a look at the complete source, see the <a href="https://github.com/rivergillis/chip-8">project repository</a>.</p> <p>First, a basic main loop. We’ll ignore emulating timing for now.</p> <div><div><pre><code><span>// main.cpp</span>

<span>void</span> <span>Run</span><span>()</span> <span>{</span>
  <span>CpuChip8</span> <span>cpu</span><span>;</span>
  <span>cpu</span><span>.</span><span>Initialize</span><span>(</span><span>"/path/to/program/file"</span><span>);</span>
  <span>bool</span> <span>quit</span> <span>=</span> <span>false</span><span>;</span>
  <span>while</span> <span>(</span><span>!</span><span>quit</span><span>)</span> <span>{</span>
    <span>cpu</span><span>.</span><span>RunCycle</span><span>();</span>
  <span>}</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>**</span> <span>argv</span><span>)</span> <span>{</span>
  <span>try</span> <span>{</span>
    <span>Run</span><span>();</span>
  <span>}</span> <span>catch</span> <span>(</span><span>const</span> <span>std</span><span>::</span><span>exception</span><span>&amp;</span> <span>e</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>cerr</span> <span>&lt;&lt;</span> <span>"ERROR: "</span> <span>&lt;&lt;</span> <span>e</span><span>.</span><span>what</span><span>();</span>
    <span>return</span> <span>1</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div> <p>Our <code>CpuChip8</code> class will encapsulate the state of our virtual machine and interpreter. Now if we implement <code>RunCycle</code> and <code>Initialize</code> we’ll have ourselves a basic emulator skeleton. We now need to discuss the phsyical system we’re emulating.</p> <p>Our CHIP-8 system will be the <a href="https://en.wikipedia.org/wiki/Telmac_1800">Telmac 1800</a>. We’ve got ourselves a pool of 4K of memory, a 64x32 1-bit display, and the ability to beep. <em>Nice</em>. The CHIP-8 interpreter itself is implemented via a virtual machine. We need to keep track of a stack, sixteen 8-bit registers (named V0 through VF), a 12-bit index register (named I), a program counter, two 8-bit timers, and a 16-frame stack.</p> <p>The canonical memory map looks like this:</p> <div><div><pre><code>0x000 |--------------------|
      | Interpreter memory |
      |                    |
0x050 | Built-in fontset   |
0x200 |--------------------|
      |                    |
      |                    |
      | Program memory     |
      | and dynamic allocs |
      |                    |
      |                    |
0xFFF |--------------------|
</code></pre></div></div> <p>You’ll notice there’s no explicit stack here. The program actually doesn’t have a stack to address, that’s only used by the interpreter to implement jumping to functions and back. With this in mind we can draw up a header.</p> <div><div><pre><code><span>// cpu_chip8.h</span>

<span>class</span> <span>CpuChip8</span> <span>{</span>
 <span>public:</span>
  <span>public</span> <span>Initialize</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>rom</span><span>);</span>
  <span>void</span> <span>RunCycle</span><span>();</span>

 <span>private:</span>
  <span>// Fills out instructions_.</span>
  <span>void</span> <span>BuildInstructionSet</span><span>();</span>

  <span>using</span> <span>Instruction</span> <span>=</span> <span>std</span><span>::</span><span>function</span><span>&lt;</span><span>void</span><span>(</span><span>void</span><span>)</span><span>&gt;</span><span>;</span>
  <span>std</span><span>::</span><span>unordered_map</span><span>&lt;</span><span>uint16_t</span><span>,</span> <span>Instruction</span><span>&gt;&gt;</span> <span>instructions_</span><span>;</span>

  <span>uint16_t</span> <span>current_opcode_</span><span>;</span> 

  <span>uint8_t</span> <span>memory_</span><span>[</span><span>4096</span><span>];</span>  <span>// 4K</span>
  <span>uint8_t</span> <span>v_register_</span><span>[</span><span>16</span><span>];</span>

  <span>uint16_t</span> <span>index_register_</span><span>;</span>
  <span>// Points to the next instruction in memory_ to execute.</span>
  <span>uint16_t</span> <span>program_counter_</span><span>;</span>

  <span>// 60Hz timers.</span>
  <span>uint8_t</span> <span>delay_timer_</span><span>;</span>
  <span>uint8_t</span> <span>sound_timer_</span><span>;</span>

  <span>uint16_t</span> <span>stack_</span><span>[</span><span>16</span><span>];</span>
  <span>// Points to the next empty spot in stack_.</span>
  <span>uint16_t</span> <span>stack_pointer_</span><span>;</span>

  <span>// 0 when not pressed.</span>
  <span>uint8_t</span> <span>keypad_state_</span><span>[</span><span>16</span><span>];</span>
<span>};</span>
</code></pre></div></div> <p>We use excplicit integer types to ensure values are over/underflowed correctly. We need to use 16-bit types for 12-bit values. We also have 16 digital input keys, which we store as either on or off within this class. When we hook up input, we’ll find a way to feed that into the class between cycles. The opcode is made easy by the fact that all CHIP-8 instructions are 2 bytes long.</p> <p>So that gives us 0xFFFF=64k possible instructions (though many are unused). We can actually store every possible instruction in a map so that when we fetch an opcode we are able to immediately execute it by calling the associated <code>Instruction</code> in <code>instructions_</code>. Since we don’t bind much data to the functions, which should be able to fit the entire instruction map in cache!</p> <p>Our <code>Initialize</code> function is where to set up the memory map described above:</p> <div><div><pre><code><span>// cpu_chip8.cpp</span>

<span>CpuChip8</span><span>::</span><span>Initialize</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>rom</span><span>)</span> <span>{</span>
  <span>current_opcode_</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memset</span><span>(</span><span>memory_</span><span>,</span> <span>0</span><span>,</span> <span>4096</span><span>);</span>
  <span>std</span><span>::</span><span>memset</span><span>(</span><span>v_registers_</span><span>,</span> <span>0</span><span>,</span> <span>16</span><span>);</span>
  <span>index_register_</span> <span>=</span> <span>0</span><span>;</span>
  <span>// Program memory begins at 0x200.</span>
  <span>program_counter_</span> <span>=</span> <span>0x200</span><span>;</span> 
  <span>delay_timer_</span> <span>=</span> <span>0</span><span>;</span>
  <span>sound_timer_</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memset</span><span>(</span><span>stack_</span><span>,</span> <span>0</span><span>,</span> <span>16</span><span>);</span>
  <span>stack_pointer_</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memset</span><span>(</span><span>keypad_state_</span><span>,</span> <span>0</span><span>,</span> <span>16</span><span>);</span>
  
  <span>uint8_t</span> <span>chip8_fontset</span><span>[</span><span>80</span><span>]</span> <span>=</span>
  <span>{</span> 
    <span>0xF0</span><span>,</span> <span>0x90</span><span>,</span> <span>0x90</span><span>,</span> <span>0x90</span><span>,</span> <span>0xF0</span><span>,</span> <span>// 0</span>
    <span>0x20</span><span>,</span> <span>0x60</span><span>,</span> <span>0x20</span><span>,</span> <span>0x20</span><span>,</span> <span>0x70</span><span>,</span> <span>// 1</span>
    <span>0xF0</span><span>,</span> <span>0x10</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x80</span><span>,</span> <span>0xF0</span><span>,</span> <span>// 2</span>
    <span>0xF0</span><span>,</span> <span>0x10</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x10</span><span>,</span> <span>0xF0</span><span>,</span> <span>// 3</span>
    <span>0x90</span><span>,</span> <span>0x90</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x10</span><span>,</span> <span>0x10</span><span>,</span> <span>// 4</span>
    <span>0xF0</span><span>,</span> <span>0x80</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x10</span><span>,</span> <span>0xF0</span><span>,</span> <span>// 5</span>
    <span>0xF0</span><span>,</span> <span>0x80</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x90</span><span>,</span> <span>0xF0</span><span>,</span> <span>// 6</span>
    <span>0xF0</span><span>,</span> <span>0x10</span><span>,</span> <span>0x20</span><span>,</span> <span>0x40</span><span>,</span> <span>0x40</span><span>,</span> <span>// 7</span>
    <span>0xF0</span><span>,</span> <span>0x90</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x90</span><span>,</span> <span>0xF0</span><span>,</span> <span>// 8</span>
    <span>0xF0</span><span>,</span> <span>0x90</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x10</span><span>,</span> <span>0xF0</span><span>,</span> <span>// 9</span>
    <span>0xF0</span><span>,</span> <span>0x90</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x90</span><span>,</span> <span>0x90</span><span>,</span> <span>// A</span>
    <span>0xE0</span><span>,</span> <span>0x90</span><span>,</span> <span>0xE0</span><span>,</span> <span>0x90</span><span>,</span> <span>0xE0</span><span>,</span> <span>// B</span>
    <span>0xF0</span><span>,</span> <span>0x80</span><span>,</span> <span>0x80</span><span>,</span> <span>0x80</span><span>,</span> <span>0xF0</span><span>,</span> <span>// C</span>
    <span>0xE0</span><span>,</span> <span>0x90</span><span>,</span> <span>0x90</span><span>,</span> <span>0x90</span><span>,</span> <span>0xE0</span><span>,</span> <span>// D</span>
    <span>0xF0</span><span>,</span> <span>0x80</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x80</span><span>,</span> <span>0xF0</span><span>,</span> <span>// E</span>
    <span>0xF0</span><span>,</span> <span>0x80</span><span>,</span> <span>0xF0</span><span>,</span> <span>0x80</span><span>,</span> <span>0x80</span>  <span>// F</span>
  <span>};</span>
  <span>// Load the built-in fontset into 0x050-0x0A0</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>memory_</span> <span>+</span> <span>0x50</span><span>,</span> <span>chip8_fontset</span><span>,</span> <span>80</span><span>);</span>

  <span>// Load the ROM into program memory.</span>
  <span>std</span><span>::</span><span>ifstream</span> <span>input</span><span>(</span><span>filename</span><span>,</span> <span>std</span><span>::</span><span>ios</span><span>::</span><span>in</span> <span>|</span> <span>std</span><span>::</span><span>ios</span><span>::</span><span>binary</span><span>);</span>
  <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>uint8_t</span><span>&gt;</span> <span>bytes</span><span>(</span>
         <span>(</span><span>std</span><span>::</span><span>istreambuf_iterator</span><span>&lt;</span><span>char</span><span>&gt;</span><span>(</span><span>input</span><span>)),</span>
         <span>(</span><span>std</span><span>::</span><span>istreambuf_iterator</span><span>&lt;</span><span>char</span><span>&gt;</span><span>()));</span>
  <span>if</span> <span>(</span><span>bytes</span><span>.</span><span>size</span><span>()</span> <span>&gt;</span> <span>kMaxROMSize</span><span>)</span> <span>{</span>
    <span>throw</span> <span>std</span><span>::</span><span>runtime_error</span><span>(</span><span>"File size is bigger than max rom size."</span><span>);</span>
  <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>bytes</span><span>.</span><span>size</span><span>()</span> <span>&lt;=</span> <span>0</span><span>)</span> <span>{</span>
    <span>throw</span> <span>std</span><span>::</span><span>runtime_error</span><span>(</span><span>"No file or empty file."</span><span>);</span>
  <span>}</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>memory_</span> <span>+</span> <span>0x200</span><span>,</span> <span>bytes</span><span>.</span><span>data</span><span>(),</span> <span>bytes</span><span>.</span><span>size</span><span>());</span>

  <span>BuildInstructionSet</span><span>();</span>
<span>}</span>
</code></pre></div></div> <p>Don’t worry about trying to read that file loading code, the C++ iostream library is kind of ridiculous. The gist of it here is that we set everything to 0 and load things into memory that need to be loaded. The fontset here is a series of 16 built-in sprites that programs can reference as they want. We’ll go over how that memory forms sprites later on when we worry about graphics. Our goal is that once <code>Initialize</code> complete we’re set up to execute a user program.</p> <p>Let’s build out a basic <code>RunCycle</code> so that we have a better idea of out to write <code>BuildInstructionSet</code>. If you remember any basic computer architecture, a cycle has a few phases. First you fetch the instruction, then you decode it, then you execute it.</p> <div><div><pre><code><span>// cpu_chip8.cpp</span>

<span>void</span> <span>CpuChip8</span><span>::</span><span>RunCycle</span><span>()</span> <span>{</span>
  <span>// Read in the big-endian opcode word.</span>
  <span>current_opcode_</span> <span>=</span> <span>memory_</span><span>[</span><span>program_counter_</span><span>]</span> <span>&lt;&lt;</span> <span>8</span> <span>|</span>
    <span>memory_</span><span>[</span><span>program_counter_</span> <span>+</span> <span>1</span><span>];</span>

  <span>auto</span> <span>instr</span> <span>=</span> <span>instructions_</span><span>.</span><span>find</span><span>(</span><span>current_opcode_</span><span>);</span>
  <span>if</span> <span>(</span><span>instr</span> <span>!=</span> <span>instructions_</span><span>.</span><span>end</span><span>())</span> <span>{</span>
    <span>instr</span><span>-&gt;</span><span>second</span><span>();</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>throw</span> <span>std</span><span>::</span><span>runtime_error</span><span>(</span><span>"Couldn't find instruction for opcode "</span> <span>+</span>
      <span>std</span><span>::</span><span>to_string</span><span>(</span><span>current_opcode_</span><span>));</span>
  <span>}</span>

  <span>// TODO: Update sound and delay timers. </span>
<span>}</span>
</code></pre></div></div> <p>This is pretty much just a map lookup to find the function to execute. The one weird bit here is how we read in the next opcode. CHIP-8 uses a big-endian archicture, which means the most-significant part of the word comes first, followed by the least significant part of the word. This is reversed in modern x86-based systems.</p> <div><div><pre><code>Memory location 0x000: 0xFF 
Memory location 0x001: 0xAB

Big endian interpretation:    0xFFAB
Little endian interpretation: 0xABFF
</code></pre></div></div> <p>Note that we don’t alter the program counter within <code>RunCycle</code>. This is done on a function-by-function base, so we leave that to the implementation of the particular <code>Instruction</code>. Also, since we chose to define <code>Instruction</code> as a function pointer without any arguments, we’re going to have to bind those to the function itself. This requires more work in the initial set-up, but means we completely remove the instruction-decode phase on <code>RunCycle</code>.</p> <p>Let’s dig into the meat of the interpreter, <code>BuildInstructionSet</code>. I wont list the implementations for every function here, but you can find that in the <a href="https://github.com/rivergillis/chip-8">repository for this project</a>. I highly recommend coding this alongside something like <a href="http://devernay.free.fr/hacks/chip8/C8TECH10.HTM#3.1">Cowgod’s technical reference</a>.</p> <div><div><pre><code><span>// cpu_chip8.cpp</span>

<span>#define NEXT program_counter_ += 2
#define SKIP program_counter_ += 4
</span>
<span>void</span> <span>CpuChip8</span><span>::</span><span>BuildInstructionSet</span><span>()</span> <span>{</span>
  <span>instructions_</span><span>.</span><span>clear</span><span>();</span>
  <span>instructions_</span><span>.</span><span>reserve</span><span>(</span><span>0xFFFF</span><span>);</span>

  <span>instructions_</span><span>[</span><span>0x00E0</span><span>]</span> <span>=</span> <span>[</span><span>this</span><span>]()</span> <span>{</span> <span>frame_</span><span>.</span><span>SetAll</span><span>(</span><span>0</span><span>);</span> <span>NEXT</span><span>;</span> <span>};</span> <span>// CLS</span>
  <span>instructions_</span><span>[</span><span>0x00EE</span><span>]</span> <span>=</span> <span>[</span><span>this</span><span>]()</span> <span>{</span>
    <span>program_counter_</span> <span>=</span> <span>stack_</span><span>[</span><span>--</span><span>stack_pointer_</span><span>]</span> <span>+</span> <span>2</span><span>;</span>  <span>// RET</span>
  <span>};</span>

  <span>for</span> <span>(</span><span>int</span> <span>opcode</span> <span>=</span> <span>0x1000</span><span>;</span> <span>opcode</span> <span>&lt;</span> <span>0xFFFF</span><span>;</span> <span>opcode</span><span>++</span><span>)</span> <span>{</span>
    <span>uint16_t</span> <span>nnn</span> <span>=</span>  <span>opcode</span> <span>&amp;</span> <span>0x0FFF</span><span>;</span>
    <span>uint8_t</span> <span>kk</span> <span>=</span>    <span>opcode</span> <span>&amp;</span> <span>0x00FF</span><span>;</span>
    <span>uint8_t</span> <span>x</span> <span>=</span>     <span>(</span><span>opcode</span> <span>&amp;</span> <span>0x0F00</span><span>)</span> <span>&gt;&gt;</span> <span>8</span><span>;</span>
    <span>uint8_t</span> <span>y</span> <span>=</span>     <span>(</span><span>opcode</span> <span>&amp;</span> <span>0x00F0</span><span>)</span> <span>&gt;&gt;</span> <span>4</span><span>;</span>
    <span>uint8_t</span> <span>n</span> <span>=</span>     <span>opcode</span> <span>&amp;</span> <span>0x000F</span><span>;</span>
    <span>if</span> <span>((</span><span>opcode</span> <span>&amp;</span> <span>0xF000</span><span>)</span> <span>==</span> <span>0x1000</span><span>)</span> <span>{</span>
      <span>instructions_</span><span>[</span><span>opcode</span><span>]</span> <span>=</span> <span>GenJP</span><span>(</span><span>nnn</span><span>);</span>
    <span>}</span> <span>else</span> <span>if</span> <span>((</span><span>opcode</span> <span>&amp;</span> <span>0xF000</span><span>)</span> <span>==</span> <span>0x2000</span><span>))</span> <span>{</span>
      <span>instructions_</span><span>[</span><span>opcode</span><span>]</span> <span>=</span> <span>GenCALL</span><span>(</span><span>nnn</span><span>);</span>
    <span>}</span>
    <span>// ...</span>
<span>}</span>
</code></pre></div></div> <p>Each instruction may encode some parameters, which we decode and use when needed. We could use <code>std::bind</code> here to generate the <code>std::function</code>s, in this case I chose to define <code>Gen[INSTRUCTION_NAME]</code> functions which will return the functions as lambdas with all of the data bound. Lets look at some of the more interesting functions:</p> <div><div><pre><code><span>// cpu_chip8.cpp</span>

<span>CpuChip8</span><span>::</span><span>Instruction</span> <span>CpuChip8</span><span>::</span>…</code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://river.codes/emulating-a-computer-part-1/">https://river.codes/emulating-a-computer-part-1/</a></em></p>]]>
            </description>
            <link>https://river.codes/emulating-a-computer-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321051</guid>
            <pubDate>Sun, 06 Dec 2020 04:31:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Hystoria]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25320858">thread link</a>) | @notadog
<br/>
December 5, 2020 | https://100millionbooks.org/blog/news/introducing-hystoria/ | <a href="https://web.archive.org/web/*/https://100millionbooks.org/blog/news/introducing-hystoria/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

    

    <div itemprop="articleBody">
        <p>It’s the year 2020 and we have the immense benefit of thousands of years of history, literature, and technological progress at our fingertips.</p>

<p>Why does this matter? Because with time comes context. Consideration and reconsideration. Deconstruction and reconstruction. Adaptation, further research, new findings, and new examination. Impact. Consequences. Lessons.</p>

<p>Anything old comes with context. Context is gold. Old is gold.</p>

<p>Context helps us evaluate things thoughtfully. It helps us debate things on their merits. In this way we can become better people—and a better people.</p>

<p>Without time, we lose context. Tweets received within seconds have virtually zero context. So what happens? Things are evaluated carelessly because there is no context for thoughtfulness. People attack each other because they don’t have any merits to debate. We become worse people—and a worse people.</p>

<p>Focusing on the immediate tip of the timeline of history—to this extreme—is nonsensical. <em>Now</em> is the least-understood moment in history. If we’re looking to become more informed, is <em>now</em> really the moment we should be examining to the degree we do?</p>

<p><em>Now</em> is a tornado of conjecture with little underlying value and much potential harm: hysteria.</p>

<p>I contend that there is more value in understanding the past in order to understand the present. As an experiment, I’m launching <a href="https://hystoria.100millionbooks.org/" target="_blank">Hystoria</a>, a reddit-like website for rediscovering ideas from the past.</p>

<p>I’ll be posting book snippets and other interesting tidbits I find on it as I work on 100 Million Books, and I hope you do too. You can upvote posts and comment on posts, and the best posts will float to the top.</p>

<p>So what’s different about Hystoria?</p>

<p><strong>Only items produced 5 years ago (or more) will be allowed on the site.</strong></p>

<p>Anything else will be removed. My hope is that this medium will harness the competitive, gamified dynamic of social media to resurface the best ideas of the past. Let’s see if that pans out. I’ll also be pointing people to Hystoria for all new book snippet suggestions.</p>

<p>The site is built with a free and open-source tool called <a href="https://github.com/LemmyNet/lemmy" target="_blank">Lemmy</a>, and I host the website myself—there’s no “big tech” involvement here. Moderation policies and terms of use will be determined if and when needed. Visit the site with an ad blocker and you’ll notice there are no ads or tracking on it either.</p>

<p>There’s another upside of this site: as you can see by the posting history of this blog, I don’t post very often. It’s been years since I last posted at all, in spite of collecting a lot of stuff worth sharing in the mean time. My excuse is that I have many things to post, and creating blog posts worth reading for each item I find would be a unreasonably onerous commitment. Posting on social media like Twitter or Facebook would be more practical but I don’t like the idea of building a following on those sites for their own sakes. I would much rather use them as conduits for sites I actually own. Hystoria enables that.</p>

<p>So I’ll post more on social sites now too. Follow on <a href="https://twitter.com/100millionbooks" target="_blank">Twitter</a>, <a href="https://facebook.com/l00millionbooks" target="_blank">Facebook</a>, and <a href="https://t.me/l00millionbooks" target="_blank">Telegram</a>.</p>

    </div>
    </article><div id="get-email">
        <form>
            <p>We scour thousands of books for lost wisdom &amp; find gems you won't see anywhere else. Some goes <a href="https://100millionbooks.org/#apps">in the apps</a>, and the rest goes in our emails!</p>
            <p>Delivered twice a month, at most.</p>
            
        </form>
        <p>Zero spam, unsubscribe anytime. <a href="https://100millionbooks.org/privacy">See our privacy policy</a>.</p>
    </div></div>]]>
            </description>
            <link>https://100millionbooks.org/blog/news/introducing-hystoria/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320858</guid>
            <pubDate>Sun, 06 Dec 2020 03:51:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doppler Effect and Phase Shift for Doppler Radar]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25320829">thread link</a>) | @keyboardman
<br/>
December 5, 2020 | https://leimao.github.io/blog/Doppler-Effect-Phase-Shift/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Doppler-Effect-Phase-Shift/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Doppler effect has been widely used in radar to measure the relative velocity between source and the target. The radar and lidar that use Doppler effect to measure relative velocities are called Doppler radar. Many autonomous or semi-autonomous machines, such as air-plane, autonomous vehicle, are often equipped with Doppler radar.</p>



<p>In this blog post, I would like to discuss the physics and mathematics of Doppler effect for Doppler radar.</p>

<h3 id="ordinary-radar">Ordinary Radar</h3>

<p>In the ordinary radar configurations, the transmitter of the radar sends out a wave, the wave hits a target object and gets reflected, a small portion of the reflected wave will be received by the receiver of the radar. By measuring the time gap between signal transmission and receipt $\Delta t$, we could determine the distance between the radar and the target object $r$ easily.</p><p>

\[\begin{align}
r &amp;= \frac{c \Delta t}{2} \\
\end{align}\]

</p><p>where $c$ is the wave velocity. Both radar and the target object could be moving. But as long as the wave velocity $c$ is much greater than the relative velocity between the radar and the target object $\Delta v$, the above equation holds.</p>



<p>The ordinary radar is also called time-of-flight radar.</p>

<h3 id="doppler-radar">Doppler Radar</h3>

<p>Different from ordinary radar, Doppler radar could also be used for measuring the the relative velocity between the radar and the target object $\Delta v$.</p>

<h4 id="doppler-effect">Doppler Effect</h4>

<p>Letâ€™s consider the Doppler effect in the simplest 1D scenario. The wave frequency that the receiver measured $f^{\prime}$ is</p><p>

\[\begin{align}
\lambda^{\prime} &amp;= \lambda - \frac{\Delta v}{f}  \\
&amp;= \frac{c}{f} - \frac{\Delta v}{f} \\
&amp;= \frac{c - \Delta v}{f} \\
&amp;= \frac{c}{f^{\prime}} \\
\end{align}\]

</p><p>where $c$ is the wave velocity, $f$ is the source wave frequency, $\Delta v$ is the relative velocity between the source and the target, $\Delta v &gt; 0$ when the source and the target are moving closer, $\Delta v &lt; 0$ when the source and the target are moving farther. Therefore,</p><p>

\[\begin{align}
f^{\prime} &amp;= \frac{c}{c - \Delta v} f \\
\end{align}\]

</p><p>Apparently, when the source and target are moving closer, i.e., $\Delta v &gt; 0$, $f^{\prime} &gt; f$; when the source and target are moving farther, i.e., $\Delta v &lt; 0$, $f^{\prime} &lt; f$.</p>



<p>The Doppler frequency $\Delta f$, which is the difference between the receiver frequency and the transmitter frequency is</p><p>

\[\begin{align}
\Delta f &amp;= f^{\prime} - f \\ 
&amp;= \frac{c}{c - \Delta v} f -f \\
&amp;= \frac{f \Delta v}{c - \Delta v} \\
\end{align}\]

</p>

<p>Assuming $c \gg \Delta v$, we have</p><p>

\[\begin{align}
\Delta f &amp;= \frac{f \Delta v}{c} \\
\end{align}\]

</p><p>The Doppler effect will also happen to a Doppler radar when the radar and the object are relatively moving. Letâ€™s still consider the simplest 1D scenario. The target object will reflect the wave transmitted from the source. In this case, the target object becomes the source of wave, and the radar becomes the target object since the radar has a receiver. The frequency of reflected wave will be the same as the frequency of the wave the target objects receives, which is $f^{\prime}$. Then the frequency of the wave measured from the receiver on the radar $f^{\prime\prime}$ will be</p><p>

\[\begin{align}
f^{\prime\prime} &amp;= \frac{c}{c - \Delta v} f^{\prime} \\
\end{align}\]

</p><p>Assuming $c \gg \Delta v$, the Doppler frequency $\Delta f$, which is the difference between the receiver frequency and the transmitter frequency is</p><p>

\[\begin{align}
\Delta f &amp;= f^{\prime\prime} - f \\ 
&amp;= (f^{\prime\prime} - f^{\prime}) - (f^{\prime} - f) \\
&amp;= \frac{f \Delta v}{c} + \frac{f \Delta v}{c} \\
&amp;= \frac{2 f \Delta v}{c} 
\end{align}\]

</p><p>With this mathematical relationship, by measuring the the Doppler frequency $\Delta f$ on the radar, we could determine the relative velocity between the radar and the target object easily.</p>

<h4 id="phase-shift">Phase Shift</h4>

<p>In practice, instead of measuring the Doppler frequency $\Delta f$, many Doppler radar measure phase shift $\Delta \varphi$.</p>



<p>Assuming $c \gg \Delta v$, the phase difference between the transmitted signal and the received signal, i.e., phase shift $\Delta \varphi$, is</p><p>

\[\begin{align}
\Delta \varphi &amp;= \frac{2r}{\lambda} 2\pi \\
&amp;= \frac{4 \pi r}{\lambda} \\
&amp;= \frac{4 \pi r f}{c} \\
\end{align}\]

</p><p>where $r$ is the distance between the radar and the target object, and $\lambda$ is the wavelength.</p><p>

\[\begin{align}
\frac{d \Delta \varphi}{dt} &amp;= \frac{4 \pi f}{c} \frac{d r}{dt} \\
&amp;= \frac{4 \pi f}{c} \Delta v \\
\end{align}\]

</p><p>Note that $\Delta v = \frac{d r}{dt}$.</p>



<p>This means that if we could measure $\frac{d \Delta \varphi}{dt}$, we could calculate the relative velocity between the radar and the target object. In practice, $\frac{d \Delta \varphi}{dt}$ could be measured easily by transmitting lots of signals in unit time, and measuring the $\frac{\Delta \Delta \varphi}{\Delta t}$.</p>

<h3 id="conclusions">Conclusions</h3>

<p>Doppler radar is not that sophisticated to understand. We determine the relative velocity by measuring the change rate of Doppler effect phase shift.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.radartutorial.eu/11.coherent/co06.en.html">Doppler Effect</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Doppler-Effect-Phase-Shift/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320829</guid>
            <pubDate>Sun, 06 Dec 2020 03:43:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't be afraid to “fail” (2019)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25320786">thread link</a>) | @mooreds
<br/>
December 5, 2020 | https://letterstoanewdeveloper.com/2019/11/07/dont-be-afraid-to-fail/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2019/11/07/dont-be-afraid-to-fail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>This is a guest post from Cierra Nease. Enjoy.</em></p>
<p>Dear new developer,</p>
<p>“Failures” as a new developer are plenty — but you might be asking, why is “failures” in quotes? To fail something is dependent upon one’s perspective. The only true failure is to quit working towards success. Every failure brings a small success in that you learn what the right answer is not. How can you problem solve without a way of marking off solutions that do not work? A failure is simply a solution that didn’t work at that specific time.</p>
<p>We can all talk about how learning and growth come from having failures, but it’s hard to remember that when you feel like you are a failure. Failures do not inherently make the person a failure, and it can be hard to make that distinction in the moment. Sometimes we need someone else to remind us of this.</p>
<p>I’ve had a lot of people in life reiterate this concept to me. The most recent person was a fellow developer named Mike on the Denver light rail. It’s funny what will happen when people participate in communicating and interacting with each other, but that is for another blog post entirely. For now, let’s go back to Mike. Mike overheard me talking to another passenger about being in a bootcamp. When I finished my conversation, he handed me a card and said he’d love to answer any questions I have about becoming a developer. I elaborated on some of my bootcamp experience, which happens to be full of failures.</p>
<p>Mike expressed his number one piece of advice for any developer, telling me: “whatever you do, don’t be afraid to fail.” We started talking about this in depth, and it really resonated with me for the rest of the evening. As a new developer, you really only see senior developers’ successes. Each developer goes through their own learning process which does include failures.</p>
<p>The failures that lead to success don’t stop when you become a “better” developer. If you are looking for a point when you quit failing as a developer, then you are looking for the wrong thing. The more you fail, the more you learn. The more you learn, the more you grow. The more you grow, the better the developer you become.</p>
<p>As a newer developer, I look forward to all of the opportunities to learn, grow, and accept my failures as the wrong solution instead of accepting them as a personal characteristic.</p>
<p>Sincerely,</p>
<p>Cierra</p>
<p><a href="https://www.linkedin.com/in/cierra-nease-denver/"><em>Cierra Nease</em></a><em> is currently studying software development. She blogs at <a href="https://cierracodes101.wordpress.com/">Cierra Codes 101</a>.</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2019-11-07T07:33:10-07:00">November 7, 2019</time><time datetime="2019-11-07T21:25:50-07:00">November 7, 2019</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2019/11/07/dont-be-afraid-to-fail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320786</guid>
            <pubDate>Sun, 06 Dec 2020 03:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Traits of the Financially Independent]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25320594">thread link</a>) | @adrian_monk
<br/>
December 5, 2020 | https://www.thriftythoughts.io/fire-movement/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/fire-movement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h3 id="who-makes-up-the-fi-re-movement">Who makes up the FI/RE Movement?</h3><p>Despite its relatively recent popularity, the FI/RE movement is still in many ways ambiguous. Who are these millionaires next door and what common traits are shared among them? Fortunately based off of data obtained from a survey conducted of nearly 1,400 individuals in the r/financialindependence subreddit, we can get a bit more insight into not only those who are pursuing FI/RE, but also those who have already achieved it. Special thanks to u/melonbalon for conducting the survey in the first place!</p><!--kg-card-begin: html--><!--kg-card-end: html--><figure><img src="https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--7-.png" alt="" srcset="https://www.thriftythoughts.io/content/images/size/w600/2020/12/UNCLAIMED-PROPERTY--7-.png 600w, https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--7-.png 800w" sizes="(min-width: 720px) 720px"></figure><h3 id="insights-obtained">Insights Obtained</h3><p>So much data was obtained as part of this survey and the figures reported in the above visual only scratch the surface of valuable insights that could be drawn. Of note however are a couple items:</p><ol><li><strong>Commute times are very low.</strong> Over 20% of respondents noted that it takes last than 10 minutes to get to work. Additionally, nearly 70% had a commute of less than 30 minutes. It's likely that these smaller commute times result in less transportation costs which could be a motivating factor.</li><li><strong>Individuals who have already FI/RE'd are highly educated.</strong> Not only did nearly 85% of respondents have a college degree, but an additional 7% had multiple graduate degrees. Perhaps these individuals have more time for additional schooling post-retirement. It also could be the case that this additional education helped them FI/RE in the first place. Regardless, more schooling was expected in comparison to the respondent group that had not yet FI/RE'd simply given the older average age. </li><li><strong>Respondents favored urban and suburban environments equally. </strong>Additionally this ratio remained constant in both the pursuing FI/RE and FI/RE'd populations. I would have expected far more suburban living, but perhaps the increased cost of living in an urban environment is offset enough by the reduced transportation costs to be appealing.</li></ol>
                            <section>
                                <h2>Enjoying these posts? Subscribe for more</h2>
                                
                                <br>
                                
                            </section>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.thriftythoughts.io/fire-movement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320594</guid>
            <pubDate>Sun, 06 Dec 2020 02:50:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aavegotchi]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25320585">thread link</a>) | @mudge
<br/>
December 5, 2020 | https://wiki.aavegotchi.com/en/introduction | <a href="https://web.archive.org/web/*/https://wiki.aavegotchi.com/en/introduction">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><hr><p><strong>Aavegotchi</strong> is a DeFi-enabled crypto collectibles game developed by Singapore-based Pixelcraft Studios that allows players to stake NFT avatars with interest-generating <a target="_blank" href="https://wiki.aavegotchi.com/atokens">aTokens</a> and interact with the Aavegotchi <a target="_blank" href="https://wiki.aavegotchi.com/metaverse">metaverse</a>. It is a unique combination of DeFi and NFTs.</p><p>Aavegotchis are pixelated ghosts living on the Ethereum blockchain, backed by the <strong>ERC-721</strong> standard. Their value is determined by rarity level, which is calculated via multiple factors, such as base traits, amount of staked collateral, and equipped <a target="_blank" href="https://wiki.aavegotchi.com/wearables">wearables</a>.</p><p>To level up their Aavegotchis, players can participate in a variety of activities including mini-games, governance, and meetups. Aavegotchis can also increase their rarity level by equipping in-game wearables and leveling up.</p><p>Rare Aavegotchis not only have higher secondary marketplace value, they also enable the Aavegotchi to perform better in <a target="_blank" href="https://wiki.aavegotchi.com/rarity-farming">rarity farming</a>—a minigame that rewards the rarest Aavegotchis with GHST tokens.</p><p>Aavegotchi is governed by <a target="_blank" href="https://wiki.aavegotchi.com/dao">AavegotchiDAO</a> that manages all funds generated through the <a target="_blank" href="https://wiki.aavegotchi.com/ghst">GHST token</a> distribution.</p><h2 id="about-aavegotchis">About Aavegotchis</h2><p>Aavegotchis are rare crypto-collectibles living on the Ethereum blockchain, backed by the ERC-721 standard used in popular blockchain games such as CryptoKitties, Axie Infinity, and Cryptovoxels.
Aavegotchis possess three attributes that determine their overall value and rarity within the Aavegotchi universe: <strong>collateral stake, traits, and wearables.</strong></p><ul><li><p><strong>Collateral stake:</strong>
Each Aavegotchi ERC721 NFT manages an escrow contract address that holds
an Aave-backed ERC20 collateral, or “aToken”. <a target="_blank" href="https://wiki.aavegotchi.com/atokens">aTokens</a> generate yield via
Aave’s LendingPool, which increases the quantity of aTokens held in the
wallet. Thus, the amount of aTokens held in the Aavegotchi’s escrow address grows over time.</p></li><li><p><strong>Traits:</strong>
Aavegotchis possess multiple traits that influence their rarity, their performance in mini-games, and the wearables they can equip. Some are generated randomly upon birth, and others depend on user interactions with the Aavegotchi. <strong>See <a target="_blank" href="https://wiki.aavegotchi.com/traits">Traits</a>.</strong></p><ul><li><p><strong>Random Traits</strong>: Upon birth, every Aavegotchi is assigned several random trait values using the ChainLink VRF random number generator. Trait values are distributed on a bell-curve, and each trait is assigned a value of Common, Uncommon, Rare, Legendary, or Mythical, depending on its rarity.</p></li><li><p><strong>Kinship</strong>: “Kinship” is not randomly assigned, but rather starts at a fixed value upon birth and increases or decreases based on various factors, such as how long the Aavegotchi has been with the same owner, and how often the owner interacts with it.</p></li><li><p><strong>Experience:</strong> Aavegotchis level up as they gain more experience by voting in AavegotchiDAO and participating in mini-games. Every few levels, Aavegotchis receive one Spirit Point that can be allocated towards increasing or decreasing a certain trait.</p></li></ul></li><li><p><strong>Wearables</strong>
In addition to managing the aToken escrow, Aavegotchis also extend the ERC998 Composables standard, which allows them to manage child NFTs, known as wearables in the Aavegotchi ecosystem.
Not every wearable can be equipped by every Aavegotchi. Some wearables may be exclusively equipped by Aavegotchis staked with certain collaterals, those of a certain level, and those with certain traits.
Some wearables can increase or decrease certain traits of an Aavegotchi. For example, equipping a sword may slightly boost an Aavegotchi’s aggressiveness, whereas equipping a Bob Marley shirt may decrease its energy level.</p></li></ul><h2 id="aavegotchi-value">Aavegotchi Value</h2><p>The valuation of an Aavegotchi comes from both from its intrinsic value and from its rarity value.</p><ul><li><p><strong>Intrinsic value</strong>
Intrinsic value is the denominated value of the Aavegotchi’s staked collateral. If the Aavegotchi is staked with 10 aDAI, then the intrinsic value would be 10 aDAI, plus whatever extra aDAI has accrued from the Lending Pool. Initially, only ERC20 tokens listed on the Aave platform (aTokens) will be available as collaterals. However, once AavegotchiDAO launches, the community will be able to vote on which new collaterals to allow.</p></li><li><p><strong>Rarity value</strong>
Rarity value is determined by calculating the rareness of each Aavegotchi’s traits and equipped wearables within the Aavegotchi universe. Unlike other NFT games, rarity is not a fixed value in Aavegotchi. It can change over time as Aavegotchis level up and equip different wearables. Thus, a rare Aavegotchi one week could become common, and vice versa, depending on the overall distribution of traits and wearables within the Aavegotchi universe. This enables a novel concept known as “rarity farming”, which is explained in more detail in the Aavegotchi official whitepaper to be released soon.</p></li></ul><h2 id="the-aavegotchi-universe">The Aavegotchi Universe</h2><p>The Aavegotchi Universe encompasses all the elements that allow Aavegotchis to operate, including Portals, the $GHST Utility Token, AavegotchiDAO, and the Aavegotchi Realm.</p></div></div></div>]]>
            </description>
            <link>https://wiki.aavegotchi.com/en/introduction</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320585</guid>
            <pubDate>Sun, 06 Dec 2020 02:47:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iPhone Is Inferior to Android]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25320572">thread link</a>) | @technojunkie
<br/>
December 5, 2020 | https://www.arencambre.com/iphone-is-inferior-to-android/ | <a href="https://web.archive.org/web/*/https://www.arencambre.com/iphone-is-inferior-to-android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong>UPDATE: While these are valid reasons, <a href="https://www.arencambre.com/iphones-are-inferior-to-android-phones-the-value/">scoring them suggests I should still switch to the iPhone</a>.</strong></p>



<p>I am on day 10 of using an iPhone. I came from the Android world.</p>



<p>The iPhone is deficient. I am leaning towards returning it.</p>




<h2><span id="Context"></span>Context<span></span></h2>



<p>Ten days ago, I switched from a Pixel 4 XL to the iPhone 12 Pro Max. I went with this iPhone model because it’s similarly sized to the Pixel 4 XL, plus I value photography.</p>



<h3><span id="Why_I_switched"></span>Why I switched<span></span></h3>



<p>I made the switch due to intellectual curiosity, to overcome limitations of the Pixel 4 XL, and to get on board with the rest of my family.</p>



<p>I am questioning this decision. While the iPhone helps me escape two Pixel 4 XL limitations, iOS’s regressions from Android feel like a heavy burden.</p>



<p>I am inside Apple’s return window, so I can return the iPhone for a full refund. It is tempting.</p>



<h3><span id="Android_only_has_two_worthwhile_brands"></span>Android only has two worthwhile brands<span></span></h3>



<p>My analysis relies heavily on my experience with the Pixel 4 XL. Much of what I say about Android applies to to top-tier Android manufacturers. Among the requirements of top-tier manufacturers is they deliver highly vanilla Android. This includes <a href="https://store.google.com/us/magazine/compare_pixel">Pixel </a>(Google’s in-house brand), <a href="https://www.oneplus.com/">OnePlus</a>, and more.</p>



<p><strong>Samsung is not a top-tier phone manufacturer.</strong> Its hardware is decent, but it has bad software. Samsung replaces Android’s best features with <a href="https://www.samsung.com/us/support/answer/ANS00078945/">poor, fussy substitutes</a>. It also adds annoying, pointless bloat. In other words, just to differentiate its brand, it <em>devalues its brand </em>by trashing up its core software.</p>



<p>The Bixby assistant is the best example of Samsung’s stupidity. It’s awful. Samsung killing Bixby might signal that it’s ready to take Android seriously. Until then, Samsung is simply not a top-tier manufacturer.</p>



<p>The Samsung example is important because Apple is the same: <strong>great hardware, bad software</strong>.</p>



<h2><span id="A_note_about_definitions"></span>A note about definitions<span></span></h2>



<p>The article’s language is sometimes imprecise. Truly, if you’re comparing Android to something in the Apple ecosystem, it would be iOS. But that is not how people talk about their phones, so I am using loose terminology in places.</p>



<p>If you’re a True Nerd™ and find my word use upsetting, just associate my word with its parent ecosystem.</p>



<p>This is how several terms are correctly used:</p>



<figure><table><tbody><tr><td><strong>Word category</strong></td><td><strong>Android phone ecosystem</strong></td><td><strong>Apple phone ecosystem</strong></td></tr><tr><td>Operating system</td><td>Android</td><td>iOS</td></tr><tr><td>Manufacturers</td><td>Google, OnePlus, and more</td><td>Apple</td></tr><tr><td>Phone brand</td><td>Pixel (Google), OnePlus, and more</td><td>iPhone</td></tr><tr><td>Phone model (current generation)</td><td>For Pixel: Pixel 4A, Pixel 4A 5G, Pixel 5. For OnePlus: OnePlus 8T, OnePlus 8 Pro, OnePlus 8, OnePlus 7T. There are more current model from other manufacturers.</td><td>iPhone 12, iPhone 12 Mini, iPhone 12 Pro, iPhone 12 Pro Max, iPhone SE, and more</td></tr></tbody></table></figure>



<p>Also, some Android features I enjoy are Pixel-specific. While Google freely distributes Android to other manufactures, it reserves some newer features for its own Pixel phones. Sometimes I may mistakenly generalize a Pixel-specific feature as an Android feature. Since Pixel-specific features often eventually end up on other phones, associating Pixel with Android is probably correct in the long run.</p>



<h2><span id="Where_Android_is_better"></span>Where Android is better<span></span></h2>



<p>Android is well thought out. It has a great UX. I really miss its great design.</p>



<h3><span id="Call_screening_Android_wins"></span>Call screening: Android wins<span></span></h3>



<p>Android’s <a href="https://support.google.com/phoneapp/answer/9118387?hl=en">built-in call screener</a> is excellent. It blocks calls it is confident are garbage. If the caller is in a gray area, it will ask the caller first to state the reason for calling, then show that to me on the screen where I can accept the call. And even if does nothing to the call, I can still use a <strong>Screen Call </strong>button to kick the call to a digital assistant, where the caller is invited to state the reason for the call.</p>



<figure><img src="https://www.xda-developers.com/files/2019/11/call_screen_assistant.jpg" alt=""><figcaption>Example call-screen opportunity. (This image shamelessly <a href="https://www.xda-developers.com/automatic-call-screen-google-pixel-phones/">stolen</a> from XDA Developers.)</figcaption></figure>



<p><strong>NOTE:</strong> This may be mostly a Pixel feature right now. Google plans to <a href="https://www.androidpolice.com/2020/09/08/google-phone-will-soon-be-downloadable-from-play-store-verified-calls-feature-rolling-out/">extend</a> this to more Android brands. Because Samsung uses its own, poor quality dialer, it’s unclear how Samsung will get this feature.</p>



<p><strong>Why iPhone sucks:</strong> Apple only has a <a href="https://support.apple.com/en-us/HT207099">crude tool</a>: block callers not in your contacts. You can’t report calls or texts as spam.</p>



<p>If you want to be more selective than Apple’s crude tool, and instead block specific spammers, you must add the spammers to your contacts. That’s dumb; it just clutters your contacts!</p>



<p>You can also subscribe to a third party service. That’s grating, because the phone should manage that itself, given that this is a years-old problem.</p>



<h3><span id="Browser_ad_blocking_Android_wins"></span>Browser ad blocking: Android wins<span></span></h3>



<p>On Android, browser ad-blocking is easy: Switch to the free <a href="https://play.google.com/store/apps/details?id=org.mozilla.firefox&amp;hl=en_US&amp;gl=US">Mozilla Firefox browser</a>. Inside Firefox, add the free <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/">uBlock Origin extension</a>. Then set Firefox as your default browser for happy browsing. Simple! (Android’s Chrome browser does not support extensions.)</p>



<p><strong>Why iPhone sucks:</strong> Install the <a href="https://apps.apple.com/us/app/adguard-adblock-privacy/id1047223162">AdGuard app</a>, jump through several fussy hoops in the <strong>Settings </strong>console’s <strong>Safari </strong>area, and get nagged about going to paid AdGuard. </p>



<p>Maybe I am fussing too much. The hassle is a one-time step, and AdGuard seems to work decently.</p>



<p>Part of the point of ad-blocking is to make YouTube worthwhile. That leads to my next point…</p>



<h3><span id="YouTube_ad_blocking_Android_wins"></span>YouTube ad blocking: Android wins<span></span></h3>



<p>To block YouTube’s ads on Android, just view all YouTube content in Firefox with the uBlock Origin extension. Easy!</p>



<p><strong>Why iPhone sucks:</strong> While Safari + AdGuard = ads blocked on YouTube, it’s still a major regression from Android:</p>



<ul><li>Video quality <a href="https://www.reddit.com/r/apple/comments/aom6ge/why_does_youtube_only_go_up_to_720p_on_mobile/">maxes out at 720p</a>.</li><li>Every YouTube video in Safari starts as low quality (360p). To change it, on <em>every video you watch</em>, you must wade through the settings menu, and it has to be done before you switch to full screen, because of the next bullet’s deficiency.</li><li>When you’re viewing a video in a browser and switch to full screen, Apple cancels the website’s native video player and forces you to use iOS’s default, bad, native video player. Want to double-tap and skip 10 seconds? Want to access the site’s in-video settings? Want any feature not supported by iOS’s dumbed down video control? Forget it! iOS nukes it in full-screen mode.</li></ul>



<p>Firefox Focus is not a solution. It doesn’t fix iOS’s deficiencies.</p>



<h3><span id="Universal_back_button_Android_wins"></span>Universal back button: Android wins<span></span></h3>



<p>For at least a decade, Android has had a back button at the bottom of all windows. This means the valuable concept of “take me back” is baked into the Android paradigm. Need to return where you were, in <em>any</em> app? Just tap the back button, on bottom left of the screen. Or use the back gesture (next section).</p>



<p><strong>Why iPhone sucks:</strong> The back button is a mess.</p>



<p>In Safari, it’s on bottom left.</p>



<p>In most other apps, top left.</p>



<p>To get to the prior app that sent you to the current app, find a tiny button between the app’s top-left back button and the clock. And good luck on that; too much of the time, iOS lists a wrong or irrelevant prior app, especially if you got to your current app from a system notification.</p>



<figure><img loading="lazy" width="1024" height="449" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-1024x449.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-1024x449.png 1024w, https://www.arencambre.com/wp-content/uploads/2020/12/image-300x132.png 300w, https://www.arencambre.com/wp-content/uploads/2020/12/image-768x337.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image.png 1225w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Even though the mini back button says otherwise, I was not sent to GroupMe by NPR One! I was sent there by a notification I tapped while NPR One was active.</figcaption></figure>



<p>Even worse, because the non-Safari back buttons are on the opposite end of the phone from where you hold it, you’re less precise with finger positioning. Therefore, when you intend to use a “back” feature, you’ll instead make the phone think you’re trying to pull down the notification area.</p>



<h3><span id="Gestures_Android_wins"></span>Gestures: Android wins<span></span></h3>



<p>Building on its native strengths, Android’s <a href="https://support.google.com/pixelphone/answer/6073614?hl=en">gestures</a> are excellent. They edge out iOS with the back gesture, which I use a lot. No matter what app you’re in, swipe in from the phone’s right to go back. Simple!</p>



<p><strong>Why iPhone sucks:</strong> Without a “back” gesture, you’re stuck fumbling with iOS’s haphazard back buttons.</p>



<h3><span id="Exiting_apps_Android_wins"></span>Exiting apps: Android wins<span></span></h3>



<p>In Android, you can exit apps with the back gesture or swiping up from the bottom. The back gesture is superior, because it can’t be confused with other gestures.</p>



<p><strong>Why iPhone sucks:</strong> Your only choice is the swipe-up gesture, which sometimes conflicts with normal swipes one does in apps.</p>



<p><strong>NOTE: </strong>I don’t literally mean app-exiting in the computer-science sense. I mean more in a common-parlance sense: you’re out of the app and back to the home screen, or in another app that may have called the current app. One an app is no longer visible, and running in the background, Android and iOS both do fine managing it.</p>



<h3><span id="Ambient_display_Android_wins"></span>Ambient display: Android wins<span></span></h3>



<p>The Pixel has a great feature: even when you’re not using the phone, it shows the current time on the screen, along with some other useful information. This takes minimal power: thanks to the OLED screen, the main power use is when it lights up the specific pixels that show the time.</p>



<figure><img loading="lazy" width="768" height="1024" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-1-768x1024.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-1-768x1024.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-225x300.png 225w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-1152x1536.png 1152w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-1536x2048.png 1536w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Ambient display. This Pixel 4 XL is not active. It’s basically in sleep mode. It uses minimal power to give me useful information on its OLED screen.</figcaption></figure>



<p><strong>Why iPhone sucks:</strong> While the iPhone also has an OLED screen, Apple has no similar feature. You have to tap the phone to see the time, which lights up the whole screen.</p>



<h3><span id="Treating_me_like_an_adult_Android_wins"></span>Treating me like an adult: Android wins<span></span></h3>



<p>Android’s UX language is simply clean. It’s intuitive, simple, and it just works.</p>



<p><strong>Why iPhone sucks:</strong> iOS’s UX feels like a cartoon spoof of a phone OS. Naturally garish colors, toddler-like corner-rounding, goofy font sizes, etc. It’s like iOS’s design semantics were intended to tussle with our innate senses. Barf!</p>



<figure><img loading="lazy" width="473" height="1024" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-2-473x1024.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-2-473x1024.png 473w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-139x300.png 139w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-768x1662.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-710x1536.png 710w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-947x2048.png 947w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2.png 1284w" sizes="(max-width: 473px) 100vw, 473px"><figcaption>When a toddler breaks out crayons and designs a phone, this is what you get.</figcaption></figure>



<h3><span id="Application_organization_Android_wins"></span>Application organization: Android wins<span></span></h3>



<p>All newly installed Android apps go into the app drawer. This is an alphabetized list of apps, accessed by swiping up from a home screen (when you’re not inside an app).</p>



<figure><img loading="lazy" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-4-485x1024.png" alt="" width="485" height="1024" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-4-485x1024.png 485w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-142x300.png 142w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-768x1621.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-728x1536.png 728w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-970x2048.png 970w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4.png 1440w" sizes="(max-width: 485px) 100vw, 485px"><figcaption>Android app drawer. Simple. Organized. Appropriate icon density.</figcaption></figure>



<p>Suppose you have 150 apps. That is 30 rows of five icons each, all in alpha sort. It’s fast to find any application.</p>



<p><strong>Why iPhone sucks:</strong> It wasn’t until <em>this year</em> that Apple delivered its poor ripoff of the app drawer. Before then, people were stuck with jumbled messes of icons on multiple home-screen pages.</p>



<p>Apple’s app-drawer ripoff …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.arencambre.com/iphone-is-inferior-to-android/">https://www.arencambre.com/iphone-is-inferior-to-android/</a></em></p>]]>
            </description>
            <link>https://www.arencambre.com/iphone-is-inferior-to-android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320572</guid>
            <pubDate>Sun, 06 Dec 2020 02:45:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pulling Data from an API, Using AWS Lambda]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25320557">thread link</a>) | @jkm2155
<br/>
December 5, 2020 | https://www.startdataengineering.com/post/pull-data-from-api-using-lambda-s3/ | <a href="https://web.archive.org/web/*/https://www.startdataengineering.com/post/pull-data-from-api-using-lambda-s3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <p><time datetime="2020-11-08T12:05:42-0500">Nov 8, 2020</time> · 13 min read
  </p>

  
<p>If you are looking for a simple, cheap data pipeline to pull small amounts of data from a stable API and store it in a cloud storage, then <code>serverless functions</code> are a good choice. This post aims to answer questions like the ones shown below</p>
<blockquote>
<p>My company does not have the budget to purchase a tool like <code>fivetran</code>, What should I use to pull data from an API ?</p>
</blockquote>
<blockquote>
<p>Do I really need an orchestration tool like Airflow for one simple data pull from an API ?</p>
</blockquote>
<p>In the post we cover what a <code>serverless</code> function can and cannot do, what its pros and cons are and walk through a simple API data pull project.</p>

<p>Chances are that you have heard of the term <code>serverless</code>. The term <code>serverless</code> may be misleading. In fact, there is a server on which your code will be running. <code>Serverless</code> refers to the fact that you do not have to manage any servers, but just the code. We will use <code>AWS Lambda</code> for this simple project. <a href="https://aws.amazon.com/lambda/?c=ser&amp;sec=srv"><code>AWS Lambda</code></a> can be used to run a function without having to provision and maintain a server.</p>
<p>You write a function and deploy it to AWS Lambda. There you can set the function to run based on <a href="https://aws.amazon.com/blogs/architecture/understanding-the-different-ways-to-invoke-lambda-functions/">external triggers</a>. The lambda function will execute the logic and end. Note that you will have a limited time (current max execution time for lambda code execution is 15min) for your code logic to complete. There is also a limit on the memory size(current max is at 3.008GB). In this post we will</p>
<ol>
<li>Start the lambda function.</li>
<li>Download data from a dummy API to local file system.</li>
<li>Copy the downloaded files to AWS S3.</li>
<li>Stop the lambda function.</li>
<li>The lambda function will be scheduled to run every 5 minutes.</li>
</ol>
<p><img src="https://www.startdataengineering.com/images/pull-data-from-API-using-lambda-s3/api_data_pull.png" alt="Simple API Data Pull"></p>

<p>Let’s assume you work for a company that wants to pull some data from an API that you have access to and assess the quality of that data. Your responsibility is to pull this data and make it available via cloud storage for other systems to consume and assess quality. Let’s assume that this is your first and only data pull(for now). There is not enough time/ money to set up/buy a data orchestration tool. This project is to validate the value that this data may provide, based on which your company can choose to either continue paying for this data or not.</p>

<h3 id="prerequisites">Prerequisites</h3>
<ol>
<li><a href="https://aws.amazon.com/">AWS Account</a></li>
<li>AWS CLI <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html">installed</a> and <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html">configured</a></li>
</ol>
<h3 id="api-documentation">API Documentation</h3>
<p>Let us assume that our API has the following documentation.</p>
<ol>
<li>API endpoint: GET <code>http://jsonplaceholder.typicode.com/posts</code> to get user post data.</li>
<li>Query parameters: The data returned from the API is sorted by user_id. Using <code>start_user_id</code> and <code>end_user_id</code> we can query for a range of data based on user ids.</li>
<li>API metadata endpoint: GET <code>http://jsonplaceholder.typicode.com/number_of_users</code>, will return the total number of user posts.</li>
</ol>
<p>The GET endpoint will return a list of JSON with the format</p>
<div><pre><code data-lang="json">{
    <span>"userId"</span>: <span>1</span>,
    <span>"id"</span>: <span>1</span>,
    <span>"title"</span>: <span>"some title here"</span>,
    <span>"body"</span>: <span>"some test here"</span>
}
</code></pre></div><h2 id="paginate">Paginate</h2>
<p>When pulling a “lot” of data from an API, it is general best practice to make multiple requests to pull data in chunks. The definition of a lot of data depends on the amount of data being pulled and the API stability. Based on the <code>API Documentation</code> above, we need to</p>
<ol>
<li>Get the total number of user posts.</li>
<li>Split the number into N number of calls, depending on a predefined <code>CHUNK</code> size. Which is the amount of data you want to pull per API call.</li>
<li>Make the API call, pull the data and write it to a local disk storage. You can also store in memory if the data size is sufficiently small.</li>
<li>Some APIs may fail due to network or other issues, add a retry parameter to account for this. In reality this will depend on the stability of the API and the network.</li>
</ol>
<p><strong>Note:</strong> Depending on the size of data and the allocated lambda memory, it may be more efficient to keep data in memory instead of writing to disk and then uploading to S3.</p>
<p>Lets create a folder called <code>dataPull</code> in your project directory and within it a python script called <code>lambda_function.py</code>, starting with the content below</p>
<div><pre><code data-lang="python">CHUNK_SIZE <span>=</span> <span>10000</span>  <span># determined based on API, memory constraints, experimentation</span>


<span>def</span> <span>get_num_records</span>():
    <span># Dummy function, to replicate GET http://jsonplaceholder.typicode.com/number_of_users call</span>
    <span>return</span> <span>100000</span>


<span>def</span> <span>get_data</span>(
    start_user_id, end_user_id, get_path<span>=</span><span>"http://jsonplaceholder.typicode.com/posts"</span>
):
    http <span>=</span> urllib3<span>.</span>PoolManager()
    data <span>=</span> {<span>"userId"</span>: None, <span>"id"</span>: None, <span>"title"</span>: None, <span>"body"</span>: None}
    <span>try</span>:
        r <span>=</span> http<span>.</span>request(
            <span>"GET"</span>,
            get_path,
            retries<span>=</span>urllib3<span>.</span>util<span>.</span>Retry(<span>3</span>),
            fields<span>=</span>{<span>"start_user_id"</span>: start_user_id, <span>"end_user_id"</span>: end_user_id},
        )
        data <span>=</span> json<span>.</span>loads(r<span>.</span>data<span>.</span>decode(<span>"utf8"</span>)<span>.</span>replace(<span>"'"</span>, <span>'"'</span>))
    <span>except</span> <span>KeyError</span> <span>as</span> e:
        <span>print</span>(f<span>"Wrong format url {get_path}"</span>, e)
    <span>except</span> urllib3<span>.</span>exceptions<span>.</span>MaxRetryError <span>as</span> e:
        <span>print</span>(f<span>"API unavailable at {get_path}"</span>, e)
    <span>return</span> data


<span>def</span> <span>parse_data</span>(json_data):
    <span>return</span> f<span>'{json_data.get("userId")},{json_data["id"]},"{json_data["title"]}"</span><span>\n</span><span>'</span>


<span>def</span> <span>write_to_local</span>(data, part, loc<span>=</span><span>"/tmp"</span>):
    file_name <span>=</span> loc <span>+</span> <span>"/"</span> <span>+</span> str(part)
    <span>with</span> open(file_name, <span>"w"</span>) <span>as</span> file:
        <span>for</span> elt <span>in</span> data:
            file<span>.</span>write(parse_data(elt))
    <span>return</span> file_name


<span>def</span> <span>download_data</span>(N):
    <span>for</span> i <span>in</span> range(<span>0</span>, N, CHUNK_SIZE):
        data <span>=</span> get_data(i, i <span>+</span> CHUNK_SIZE)
        write_to_local(data, i <span>//</span> CHUNK_SIZE)
</code></pre></div><p>In the above code snippet, we have the functions</p>
<ol>
<li><code>get_num_records</code> to simulate the GET call to your API to get the total number of user posts.</li>
<li><code>download_data</code> to make multiple calls to the API and only accessing 10,000 data records per API data pull. This 10,000 is defined as a global variable <code>CHUNK_SIZE</code>. In your project you will need to determine what this size is depending on API stability, memory constraints, network connection and general best practice size for that API.</li>
<li><code>parse_data</code> to convert the json data into a row format string, which gets written to a local file.</li>
<li><code>write_to_local</code> to write the downloaded chunk of data into the local file system. In our case if we have 100,000 records we will generate 10 files name <code>0, 1, 2, 3, 4, 5, 6, 7, 8, 9</code> with the data for user ids <code>0-10000, 10000-20000,...90000-100000</code> correspondingly. Note the local file system location <code>/tmp</code> will only be available for the duration of a single run of your function.</li>
</ol>
<h4 id="concurrency">Concurrency</h4>
<p>In the above snippet, since we are downloading chunks independently we can also make it concurrent using python’s <code>asyncio</code> library. If you are using concurrency be very aware of the number of open connections/ file handlers, etc. You can also manage concurrency at the lambda function level as shown <a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html?icmpid=docs_lambda_console">here</a>.</p>
<p>Note some API may not provide the exact number of records, instead you will have to query until no more data is available (usually using some sort of <code>search_after</code> query parameter). In such cases concurrency will be difficult to achieve since you will need the output from the previous call to make the next API call. An example of this is <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/search-request-search-after.html"><code>ElasticSearch's</code> search_after</a>. There is also the <code>from, size</code> type API endpoints which requires the size of data to pull and an id from which to start pulling data as query parameters to the API call.</p>

<p>Since lambda functions are temporary, so are their local storage. We need to make sure our locally stored data (at <code>/tmp</code>) gets stored in a persistent storage system such as <code>AWS S3</code>. Add the below code to <code>lambda_function.py</code>.</p>
<div><pre><code data-lang="python"><span>import</span> boto3
<span>from</span> datetime <span>import</span> datetime, timezone
<span>import</span> json
<span>from</span> os <span>import</span> listdir
<span>from</span> os.path <span>import</span> isfile, join
<span>import</span> urllib3

s3_client <span>=</span> boto3<span>.</span>client(<span>"s3"</span>)
LOCAL_FILE_SYS <span>=</span> <span>"/tmp"</span>
S3_BUCKET <span>=</span> <span>"your-s3-bucket"</span>  <span># please replace with your bucket name</span>
CHUNK_SIZE <span>=</span> <span>10000</span>  <span># determined based on API, memory constraints, experimentation</span>


<span>def</span> <span>_get_key</span>():
    dt_now <span>=</span> datetime<span>.</span>now(tz<span>=</span>timezone<span>.</span>utc)
    KEY <span>=</span> (
        dt_now<span>.</span>strftime(<span>"%Y-%m-</span><span>%d</span><span>"</span>)
        <span>+</span> <span>"/"</span>
        <span>+</span> dt_now<span>.</span>strftime(<span>"%H"</span>)
        <span>+</span> <span>"/"</span>
        <span>+</span> dt_now<span>.</span>strftime(<span>"%M"</span>)
        <span>+</span> <span>"/"</span>
    )
    <span>return</span> KEY


<span>def</span> <span>get_num_records</span>():
    <span># Dummy function, to replicate GET http://jsonplaceholder.typicode.com/number_of_users call</span>
    <span>return</span> <span>100000</span>


<span>def</span> <span>get_data</span>(
    start_user_id, end_user_id, get_path<span>=</span><span>"http://jsonplaceholder.typicode.com/posts"</span>
):
    http <span>=</span> urllib3<span>.</span>PoolManager()
    data <span>=</span> {<span>"userId"</span>: None, <span>"id"</span>: None, <span>"title"</span>: None, <span>"body"</span>: None}
    <span>try</span>:
        r <span>=</span> http<span>.</span>request(
            <span>"GET"</span>,
            get_path,
            retries<span>=</span>urllib3<span>.</span>util<span>.</span>Retry(<span>3</span>),
            fields<span>=</span>{<span>"start_user_id"</span>: start_user_id, <span>"end_user_id"</span>: end_user_id},
        )
        data <span>=</span> json<span>.</span>loads(r<span>.</span>data<span>.</span>decode(<span>"utf8"</span>)<span>.</span>replace(<span>"'"</span>, <span>'"'</span>))
    <span>except</span> <span>KeyError</span> <span>as</span> e:
        <span>print</span>(f<span>"Wrong format url {get_path}"</span>, e)
    <span>except</span> urllib3<span>.</span>exceptions<span>.</span>MaxRetryError <span>as</span> e:
        <span>print</span>(f<span>"API unavailable at {get_path}"</span>, e)
    <span>return</span> data


<span>def</span> <span>parse_data</span>(json_data):
    <span>return</span> f<span>'{json_data.get("userId")},{json_data["id"]},"{json_data["title"]}"</span><span>\n</span><span>'</span>


<span>def</span> <span>write_to_local</span>(data, part, loc<span>=</span>LOCAL_FILE_SYS):
    file_name <span>=</span> loc <span>+</span> <span>"/"</span> <span>+</span> str(part)
    <span>with</span> open(file_name, <span>"w"</span>) <span>as</span> file:
        <span>for</span> elt <span>in</span> data:
            file<span>.</span>write(parse_data(elt))
    <span>return</span> file_name


<span>def</span> <span>download_data</span>(N):
    <span>for</span> i <span>in</span> range(<span>0</span>, N, CHUNK_SIZE):
        data <span>=</span> get_data(i, i <span>+</span> CHUNK_SIZE)
        write_to_local(data, i <span>//</span> CHUNK_SIZE)


<span>def</span> <span>lambda_handler</span>(event, context):
    N <span>=</span> get_num_records()
    download_data(N)
    key <span>=</span> _get_key()
    files <span>=</span> [f <span>for</span> f <span>in</span> listdir(LOCAL_FILE_SYS) <span>if</span> isfile(join(LOCAL_FILE_SYS, f))]
    <span>for</span> f <span>in</span> files:
        s3_client<span>.</span>upload_file(LOCAL_FILE_SYS <span>+</span> <span>"/"</span> <span>+</span> f, S3_BUCKET, key <span>+</span> f)

</code></pre></div><p>In the above code snippet, we have added some global variables and function</p>
<ol>
<li><code>s3_client</code>: This is a boto3 s3 client used to programmatically access S3.</li>
<li><code>dt_now</code>: The current date time in UTC.</li>
<li><code>S3_BUCKET</code>: The name of your S3 bucket, please replace this with your bucket name. You will create this bucket in the next section.</li>
<li><code>_get_key()</code>: This represents the path within your <code>S3_BUCKET</code> where the data you pulled will be stored. We use <code>YYYY-mm-dd/HH/MM</code> format, eg the time 2020-11-10 9:14PM would translate to a folder structure of <code>2020-11-10…</code></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.startdataengineering.com/post/pull-data-from-api-using-lambda-s3/">https://www.startdataengineering.com/post/pull-data-from-api-using-lambda-s3/</a></em></p>]]>
            </description>
            <link>https://www.startdataengineering.com/post/pull-data-from-api-using-lambda-s3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320557</guid>
            <pubDate>Sun, 06 Dec 2020 02:41:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Localizer, a Kubernetes reverse tunnel/tunnel manager]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25320488">thread link</a>) | @jaredallard2
<br/>
December 5, 2020 | https://blog.jaredallard.me/localizer-an-adventure-in-creating-a-reverse-tunnel-and-tunnel-manager-for-kubernetes/ | <a href="https://web.archive.org/web/*/https://blog.jaredallard.me/localizer-an-adventure-in-creating-a-reverse-tunnel-and-tunnel-manager-for-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Not interested in the back story? </strong>Jump ahead to <a href="#introducing-localizer">Introducing Localizer</a><strong>.</strong></p><p>Before we get into the details of what localizer is and how it came to be, it's crucial that we look at what developer environments were and the motivations behind the ones I create.</p><p>Ever since I wrote my first ever <a href="https://github.com/staymarta/dev">developer environment</a> for the now-defunct <a href="https://github.com/staymarta">StayMarta</a>, I've always focused on one thing: ease of use. For a docker-compose based development environment, this was a relatively simple task. Create Docker containers, write a compose file, declare ports, and they'd be available on my local machine. It was as simple as <code>docker-compose up</code>. While this approach didn't necessarily match what production looked like, it was really the best option available for containers at the time. Options that exist now, such as Kubernetes, weren't available, which rendered <a href="https://www.docker.com/blog/announcing-docker-machine-swarm-and-compose-for-orchestrating-distributed-apps/">equality between production and development a work-in-progress dream</a>.</p><p>Fast forward to 2017, at my first larger-scale startup, <a href="https://azuqua.com/">Azuqua</a>, I had a chance to reimagine what a developer environment looked like under a whole new set of constraints. While Docker Compose works for small teams, it falls apart when you map it to production systems. At the time, our production system was based on Chef. Docker Compose doesn't map to Ruby-based Chef configuration files. When I joined Azuqua, the pain around having separate tooling for infrastructure had become incredibly clear. It wasn't sustainable to have an entire team; write the configuration for our services, communicate with developers why infrastructure can't infinitely scale without good software design, and do it all without blame or single points of failure. Fundamentally this is why I take issue with DevOps teams and prefer promoting the <a href="https://sre.google/">Google SRE Model</a> instead. While at Azuqua, we started a transition to an SRE model and used Kubernetes as a way to help facilitate that.</p><figure><img src="https://blog.jaredallard.me/content/images/2020/12/kind-1.png" alt="KinD Logo"></figure><p>While at Azuqua, I identified the need to run Kubernetes to ease cloud resources' scalability and improve the developer experience. At the same time, this <strong>drastically decreased the developer experience</strong>. While this may seem contradictory at first, it's essential to consider the multiple ways that developer experience presents itself. While at first, it may seem like it's just tooling to test/write code, it's a combination of testing code, writing code, and deploying that code. With the Docker Compose environment at StayMarta, we made the test/build cycle incredibly simple but shifted the deploy aspects onto a bespoke team, the DevOps model. That approach works for small teams, but as you grow, this quickly doesn't scale. If you can't deploy code efficiently, the developer experience is frustrating and promptly turns to an unhealthy relationship with the team responsible for that cycle.</p><p>Going back to how Kubernetes <em>improved the developer experience</em>, which I assure you it does. The benefit to Kubernetes was that it brought a control plane into the mix and focused on being just a container orchestrator. The DSL it does have is highly specific to orchestrating containers and making them work. The control-plane allows self-healing and building tooling to enable all different types of use-cases consistently. While it lacks abstractions, it brings something to developers they've never had before, the ability to deploy code reproducibly. With the introduction of <a href="https://minikube.sigs.k8s.io/docs/">minikube</a>, <a href="https://kind.sigs.k8s.io/docs/">KinD</a>, and others, you could now run the same stack you run in production, but locally.</p><p>The ability to reproducibly deploy helps both deployment confidence and the amount of time needed to get from nothing to running in production. However, it's not without its faults. Whenever you start moving deployment tooling onto developers, you've decreased the developer experience. It's unavoidable because you're introducing net new materials, DSLs, and more for the developers to learn. While <a href="https://kind.sigs.k8s.io/docs/">KinD</a> and <a href="https://minikube.sigs.k8s.io/docs/">minikube</a> are great projects, they all suffer from needing developers to understand how to work with Kubernetes. You need to be able to build a Docker image, push the docker image into the cluster, delete the application pod, verify if it's even using the correct tag, wait for Kubernetes to recreate the container, and make sure you've configured an ingress route to access it outside of your cluster or use <code>kubectl port-forward</code> to access it. The second that breaks, you're now required to dig into why service connectivity isn't working, why your Docker image isn't in the <code>containerd</code> cache, or other not so easily solved areas. While to someone who's worked with Kubernetes for years now, this isn't very difficult, this is hardly achieving the "ease of use" goal I have.</p><p>Solving these problems is not easy. Debugging Kubernetes is difficult and requires knowledge that can only be solved with education, more tooling, or a combination of both. Unfortunately, these are not cheap. Education is hard to do correctly and tends to result in lots of time writing quickly out of date material that is hard to maintain. While at Azuqua, we encountered this same problem. Very few engineers wanted to learn Kubernetes or invest time in the technology around it. We decided to go back to the basics and focus on a tooling based approach. How do we get the same developer experience level, at a minimum, of Docker Compose with Kubernetes? Our answer ended up being a tool called <a href="https://telepresence.io/">Telepresence</a>. Telepresence describes itself as:</p><blockquote>[...] an open source tool that lets you run a single service locally, while connecting that service to a remote Kubernetes cluster.<p><a href="https://www.telepresence.io/discussion/overview">https://www.telepresence.io/discussion/overview</a></p></blockquote><p>It seemed perfect, a tool that enabled your local machine to act as if it were running in Kubernetes and allow your services to be targeted from inside of Kubernetes. We rolled it out at Azuqua after initial tests showed it worked well, and we went with it. Unfortunately, it didn't last.</p><p>While Telepresence solved the problem of communicating with our local Kubernetes cluster, it spectacularly failed at letting services inside the cluster talk to our local services. When it worked, it worked amazingly, but nine times out of ten, it'd fail in a magnitude of ways. Whether that's failing to clean up after random crashing or slowly taking down the computer's internet connection, it generally wouldn't work. Luckily for us at Azuqua, we had a pretty well-defined system for service discovery and few services that needed to talk to one another directly. The few that needed that could just run outside of the cluster. That allowed us to accept those pains and be successful with Telepresence. To be clear, this is not a hit on Telepresence. It worked very well for us at Azuqua, but it's not a complete solution.</p><p>When I started developing a new development environment for <a href="https://outreach.io/">Outreach</a>, I again tried to use Telepresence as the solution to bridge the gap between our local cluster and our local machine. Unfortunately, it didn't work. We did not have a well-defined service discovery mechanism to work around the bugs, we had a much larger engineering team, and almost all services needed to talk to each other. We found more and more edge cases with Telepresence, and our developer experience was suffering. Our NPS score for our developer environment was at a low of -26, just because of Telepresence!</p><figure><img src="https://blog.jaredallard.me/content/images/2020/12/image-1.png" alt="Chart showing the NPS spread"><figcaption>For comparison, a good NPS is generally +30...&nbsp;</figcaption></figure><p>It was pretty clear that Telepresence was not going to solve our use-cases. It was time to look into alternatives.</p><p>Telepresence was interesting since it used a VPN to give you access to your resources. However, it also required a hack DNS injector component, which tended to be the primary source of network problems. There weren't many projects out there that seemed to solve this, but one interesting one was <a href="https://github.com/txn2/kubefwd">kubefwd</a>. If you're not aware of Kubernetes port-forwarding, there is a command that allows you to bring down a set of ports for a given service and have them be available on your local machine via <code>kubectl port-forward</code>. Think of the <code>-p</code> argument to <code>docker run</code>, but for Kubernetes. Unfortunately, this didn't support FQDNs (<code>.svc.cluster.local</code>), statefulsets, or all namespaces automatically. It also didn't support reverse tunneling. I wanted to keep the spirit of Telepresence by continuing to be a one-stop tool. Aside from <code>kubefwd</code>, there were seemingly no tools that could do this. Reverse tunneling into Kubernetes alone seemed to be an unsolved problem. To fill that gap, I decided to write <code>localizer</code>.</p><p><a href="https://github.com/jaredallard/localizer">Localizer</a> is a rewrite of Telepresence in Golang, but without the complex surface area. Its goal is to be a simple, no-frills development tool for application developers using Kubernetes. It does this by being easy to use, self-explanatory, and easy to debug. Localizer only supports what Kubernetes networking does, and acts as a daemon. This is most useful when trying to expose multiple services, developers generally had to have many terminal windows to run Telepresence or other reverse tunnel solutions. Localizer moves away from that by having all commands send a gRPC message to the daemon. More on that later. At the core of Localizer is three commands.</p><h2 id="default-creating-tunnels">Default: Creating Tunnels</h2><figure><img src="https://blog.jaredallard.me/content/images/2020/12/Screen-Shot-2020-12-04-at-1.28.31-PM-1.png" alt="Output from running the localizer daemon"><figcaption>Running <code>localizer</code> on my home Kubernetes Cluster (it's not limited to just local developer environments)</figcaption></figure><p>When you run <code>localizer</code> without any arguments, it automatically creates port-forwards for all Kubernetes Services (this is important), a loopback-interface powered IP address, and adds them to <code>/etc/hosts</code>. Out of the box, this allows code to communicate with Kubernetes services despite being outside of the cluster.</p><h2 id="expose-creating-a-reverse-tunnel">Expose: Creating a Reverse Tunnel</h2><p>The <code>expose</code> command takes <code>namespace/service</code> as an argument that allows you to point a Kubernetes service down to your machine's service instance. When run, it automatically scales down any endpoints that already exist for the service. Localizer then creates an OpenSSH pod with the Kubernetes service's selector, which makes Kubernetes route traffic to the created pod. Localizer creates an SSH reverse proxy over a Kubernetes port-forward (which …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jaredallard.me/localizer-an-adventure-in-creating-a-reverse-tunnel-and-tunnel-manager-for-kubernetes/">https://blog.jaredallard.me/localizer-an-adventure-in-creating-a-reverse-tunnel-and-tunnel-manager-for-kubernetes/</a></em></p>]]>
            </description>
            <link>https://blog.jaredallard.me/localizer-an-adventure-in-creating-a-reverse-tunnel-and-tunnel-manager-for-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320488</guid>
            <pubDate>Sun, 06 Dec 2020 02:28:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Urgent appeal to Paul Graham, etc.: Please help kickstart Common Lisp revolution]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25320063">thread link</a>) | @Hexstream
<br/>
December 5, 2020 | https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham | <a href="https://web.archive.org/web/*/https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      

      <nav>
        <ul>
          <li><a href="#context">Context</a></li>
        </ul>
        <ul>
          <li><a href="#lispworks-and-franz">LispWorks and Franz</a></li>
          <li><a href="#common-lisp-foundation">Common Lisp Foundation</a></li>
          <li><a href="#paul-graham">Paul Graham</a></li>
          <li><a href="#planck-ez">Planck EZ (Ergodox, ZSA)</a></li>
          <li><a href="#everyone-else">Everyone else</a></li>
        </ul>
      </nav>

      

      <section id="context">

        

        <p><a href="https://github.com/sponsors/Hexstream" target="_blank">I am trying to kickstart the Common Lisp revolution from 28 november to <strong>10 december 2020</strong></a>, and as of 5 december 2020, it did look like we were going to run out of time, so this is my last-ditch attempt at rectifying the situation before it's too late. <strong><em><a href="https://github.com/sponsors/Hexstream" target="_blank">Please support the Common Lisp Revival 2020 Fundraiser!!!</a></em></strong></p>

        <p>
          Since we are on such a tight deadline, I am soliciting donations of <strong>1000$ or more</strong> from the following organizations and people. This is the only way we can realistically make it in time.
          <br>
          I can confirm that they are all eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>.
        </p>

        <p>
          Please make sure to <a href="https://github.com/sponsors/Hexstream" target="_blank">sponsor me</a> from an account able to give out doublers, you should see a banner confirming this at the top (when logged in).
          <br>
          Also <strong>beware of prorating</strong>, which might significantly cut down your contribution if you are not careful. Any prorating will be announced on the checkout page, and you may need to sponsor at a higher tier to arrive at the amount that you intended to contribute.
        </p>

        <p>I wrote this page's core content in one day, so please excuse any sloppy writing.</p>

      </section>

      <section id="lispworks-and-franz">

        

        <p>Dear LispWorks, Dear Usha, Dear Franz, Dear Jans,</p>

        <p>
          One of the biggest divisions within the Common Lisp community remains largely unacknowledged. That is <strong>the division between <em>Open Source and Proprietary</em></strong>.
          <br>
          There is tremendous untapped, latent energy to unlock to help make Common Lisp successful, and we just need a slight paradigm shift to do so.
        </p>

        <p>
          <a href="https://twitter.com/HexstreamSoft/status/1213964177657794577" target="_blank" rel="noreferrer">We can make Common Lisp a top 5 programming language by 2040</a>, and this will be much easier to achieve if we unify our forces.
          <br>
          <strong><a href="https://cv.hexstream.expert/" target="_blank">Through my work</a>, I am working to dramatically expand the Common Lisp community, which is guaranteed to greatly benefit your business</strong>.</p>

        <p>
          <strong>You could boost my productivity almost beyond imagination just by providing me a tiny fraction of a normal salary!</strong>
          <br>
          For instance, 1000$/month would be basically infinite money in my current situation. How about you each contribute 500$/month for 6 months as a trial?
          <br>
          Of course, please consider starting with a large donation to the <a href="https://github.com/sponsors/Hexstream" target="_blank">Common Lisp Revival 2020 Fundraiser</a> before <strong>10 december 2020</strong>, as GitHub will double your contribution!
        </p>

        <p>
          I also urge you to open source more of your technology, not even necessarily out of pure generosity, but simply because it makes so much business sense!
          <br>
          For instance, you could send SHOCKWAVES throughout the world simply by open sourcing <a href="http://www.lispworks.com/products/capi.html" target="_blank">CAPI</a> and <a href="https://allegrograph.com/products/allegrograph/" target="_blank">AllegroGraph</a>!
          <br>
          Inherently, the more you open source, the more you stand to benefit from the great Open Source Marketing Machine!
        </p>

        <p>In fact, I almost wonder if you should also open source LispWorks and Allegro Common Lisp and transform yourself into a services company like Red Hat? It's really hard to compete with world-class open source implementations like <a href="http://sbcl.org/" target="_blank">SBCL</a> these days. But obviously, this would be a more long-term project, and I don't presume to understand your business better than you do or tell you what to do. I'm just suggesting ideas. We stand to greatly benefit from a healthy exchange of ideas.</p>

        <p>
          Please check out the details about <a href="https://sponsors.hexstreamsoft.com/about/" target="_blank">HexstreamSoft Sponsors</a>. I think you may find them very compelling.
          <br>
          You are obviously eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>. These grant you great visibility on <a href="" target="_blank">HexstreamSoft</a>, <a href="https://cv.hexstream.expert/#hexstreamsoft-alexa-stats" target="_blank">the #1 Common Lisp site</a>!
        </p>

      </section>

      <section id="common-lisp-foundation">

        

        <p>Dear Common Lisp Foundation, Dear Dave,</p>

        <p>Thank you for giving birth to <a href="https://twitter.com/HexstreamSoft/status/1041671580957466624" target="_blank" rel="noreferrer">one of the most important conversations in the Common Lisp community</a>!</p>

        <p>I have reason to believe that your understanding and appreciation for <a href="https://cv.hexstream.expert/" target="_blank">my crucial work within the Common Lisp community</a> has only been growing since this historic event.</p>

        <p>I believe you have the necessary knowledge and resources to be a key ally in <a href="https://github.com/sponsors/Hexstream" target="_blank">leading Common Lisp to unprecedented success</a>.</p>

        <p>You are already managing <a href="https://www.common-lisp.net/" target="_blank">common-lisp.net</a> and <a href="https://www.cliki.net/" target="_blank">cliki.net</a>, both crucial resources. It is time to unify our efforts. I <a href="https://twitter.com/HexstreamSoft/status/1250142510267224065" target="_blank" rel="noreferrer">again</a> urge you to move to GitHub, the best open source platform, and the <a href="https://github.com/sponsors/Hexstream" target="_blank">Common Lisp Revival 2020 Fundraiser</a> is a great occasion to demonstrate to the world what already ought to be quite obvious: <a href="https://github.com/" target="_blank">GitHub</a> is the best code hosting platform, and <a href="https://github.com/sponsors" target="_blank">GitHub Sponsors</a> is the best open source funding platform! Let's leave <q>avoid success at all costs</q> to Haskell!</p>

        <p>
          I am not sure if your corporate processes in any way allow for such a quick turnaround time, or if you can sanely make an exception, but if in any way possible,
          <br>
          <strong>please make a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> if you wish to help kickstart the Common Lisp revolution right now! Thank you.</strong>
        </p>

      </section>

      <section id="paul-graham">

        

        <p>Dear Paul Graham, Dear Y Combinator,</p>

        <p><a href="https://cv.hexstream.expert/" target="_blank">I have been almost entirely dedicating my life to Common Lisp since mid-2006</a> when I discovered Common Lisp, largely thanks to <a href="http://www.paulgraham.com/" target="_blank">your essays</a>, especially <a href="http://www.paulgraham.com/avg.html" target="_blank">Beating the Averages</a>. After spending 2 weeks reading your essays and researching Common Lisp, I went all-in on Common Lisp and completely abandoned Java. <strong>To this day, this has been the best and most determinant event in my life and I am deeply thanking you for it!</strong></p>

        <p>Basically, I've been running <a href="https://www.hexstreamsoft.com/" target="_blank">an unregistered Common Lisp startup</a> for 14 years. I am planning to register in 2022 at the latest. I have finally started experiencing <a href="https://cv.hexstream.expert/#hexstreamsoft-alexa-stats" target="_blank">some visible success</a> this year, as I am finally reaching the interesting point in the exponential curve. <strong>I am requesting your help to further accelerate and embolden this process.</strong></p>

        <p>
          Unfortunately, I believe the traditional Y Combinator process would not be a good fit for me, due to various reasons.
          <br>
          I am requesting a fairly insignificant amount of funding compared to your usual investments, but this would completely change my life.
        </p>

        <p><a href="https://github.com/sponsors/Hexstream" target="_blank">I am the chief architect of the looming Common Lisp revolution.</a> The revolution would still happen even if you just decided to watch it unfold from afar, but I thought I would highlight your opportunity to lend it a bit of your vast resources and influence, thereby greatly empowering it. Everyone has much to gain from this happening. This is a traditional win-win-win scenario.</p>

        <p>I trust that your world-class expertise in startups will easily detect the amazing intrinsic value and potential of me and my startup.</p>

        <p><strong>Please make a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> if you wish to help kickstart the Common Lisp revolution right now! Thank you.</strong></p>

      </section>

      <section id="planck-ez">

        

        <p>Dear Ergodox/ZSA, Dear Erez, Dear Tisha, Dear Florian,</p>

        <p>The <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is truly revolutionary and life-changing! I predict that it (or its close descendants) will remain the best keyboard on the planet for decades to come!</p>

        <p>Thank you for implementing custom labels in <a href="https://configure.ergodox-ez.com/planck-ez/layouts/ABWNG/latest/0" target="_blank">Oryx</a>, <a href="https://twitter.com/HexstreamSoft/status/1237462417577295873" target="_blank" rel="noreferrer">as I requested</a>. Your email support is truly amazing, and I was surprised to find that indeed, we have already exchanged <strong>more than 100 emails in 9 months!</strong> I greatly value our great relationship, and here is a perfect occasion to go to the next level!</p>

        <p>
          The <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is so damn great that I couldn't resist making <a href="https://status-quo.hexstream.expert/hardware/planck-ez/#my-config" target="_blank">an advanced presentation for my custom keyboard layout</a>.
          <br>
          You were so impressed with it that you quickly offered to <a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/" target="_blank">interview me</a>, and I then proceeded to really pour my soul into that article, with quite impressive results I might say!</p>

        <p>
          The kicker? <strong>I did this while I was already late to launch <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a>! <em>Oh noes!!</em></strong> 🤣
          <br>
          But seriously, I just <em>couldn't wait</em> to share my passion for the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> with the world! That's how goddamn amazing it is!!
        </p>

        <p>I had already been using the TypeMatrix 2030 (a somewhat similar keyboard) for more than a decade, and the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is at least 20x better! It's easy to infer that I'm probably going to stick to the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> or a close descendant for the next decade at least... As <a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/#alternative-to-qmk" target="_blank">previously stated</a>, I am planning to build much more powerful alternatives to <a href="https://qmk.fm/" target="_blank">QMK</a>, <a href="https://ergodox-ez.com/pages/wally" target="_blank">Wally</a> and <a href="https://configure.ergodox-ez.com/" target="_blank">Oryx</a>, all written in Common Lisp, of course. Admittedly, it would take at least a few years before I can start working on this, due to <a href="https://roadmap.hexstreamsoft.com/" target="_blank">more pressing priorities</a>. My <a href="https://status-quo.hexstream.expert/hardware/planck-ez/#my-config" target="_blank">awesome Planck EZ layout presentation</a> is already a good first step towards an Oryx alternative, although it is not yet written in Common Lisp. (I would probably only support the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a>, since that's the only keyboard I find interesting...) <strong><a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/#stenography" target="_blank">I believe the Planck EZ will be the key to unlocking 100x productivity!</a></strong></p>

        <p>
          I think there is already an inherent and fundamental link between Common Lisp and the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a>:
          <br>
          <em>It's only fair to expect that the best programmers would gravitate not only towards the best programming language, but also the <a href="https://ergodox-ez.com/pages/planck" target="_blank">best keyboard</a>!</em>
          <br>
          Thankfully, we have a tremendous opportunity to make that connection even more concrete today!
        </p>

        <p><strong>As such, I would be extremely honored if you made a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> to help kickstart the Common Lisp revolution right now! Thank you.</strong></p>

        <p>I can confirm ZSA is eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>. You can advertise your amazing products on the front page of the #1 Common Lisp site thanks to <a href="https://sponsors.hexstreamsoft.com/about/#monthly-perks" target="_blank">Monthly Perks</a>.</p>

      </section>

      <section id="everyone-else">

        

        <p>Dear everyone interested in Common Lisp and/or Open Source or …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham">https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham</a></em></p>]]>
            </description>
            <link>https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320063</guid>
            <pubDate>Sun, 06 Dec 2020 01:21:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Team That Ships]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25320053">thread link</a>) | @shsachdev
<br/>
December 5, 2020 | https://www.careerfair.io/reviews/angellist-shipping-culture | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/angellist-shipping-culture">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
Naval Ravikant, founder of AngelList, describes his companyâ€™s shipping culture in one of his <a href="https://nav.al/build-a-team-that-ships">blog posts</a>. 
</p>
<p>
They like to keep projects to one person. And every person is responsible for shipping something every single week. 
</p>
<p>
Itâ€™s quite a polarizing culture. So much so that Naval makes explicit that their environment is wrong for most people. Theyâ€™re looking for independent people who can ship code and if you donâ€™t fit that type, you should go look elsewhere:
</p>


<blockquote>
    If they canâ€™t ship, release them. Our environment is wrong for them. They should go find someplace where they can thrive. Thereâ€™s someplace for everyone.
    <span>Naval Ravikant</span>
</blockquote>

<p>
I wish more companies would do this. When youâ€™re able to clearly outline your values, you tend to attract individuals that stick. 
</p>
<p>
And sometimes, itâ€™s just as important to list all the reasons why someone <em>wouldnâ€™t enjoy</em> working at a company as it is to list everything good about the company. 
</p>
<p>
Hereâ€™s an example from <a href="https://www.notion.so/Join-Levels-Remote-Head-of-Marketing-Growth-6e64dba240404eaea9160a48f1c5f24f">Levels Healthâ€™s</a> recent job description:
</p>

<center>
    <img src="https://www.careerfair.io/assets_angellist/job_description.png" alt="">
</center>

<p>
Information like this is gold dust. Think about the countless <em>years</em> people waste working at companies that theyâ€™re not suited for. 
</p>
<p>
For instance, the role above would be a bad fit for me. Iâ€™m at a stage of my career where mentorship would be helpful and Iâ€™d like to execute on projects that are clearly defined in scope. 
</p>
<p>
If a company is not able to explain to me what would make someone a bad candidate for the role, then that would worry me. If youâ€™re not able to eliminate <em>anyone</em> for a role, then the job position itself has likely not been set up for success. 
</p>
<h2>Build a team that ships</h2>


<p>
I want to talk a bit more about AngelListâ€™s prolific shipping culture.
</p>
<p>
It reminds me of a ceramics experiment that was done (can be traced back to this <a href="https://www.amazon.com/dp/0961454733/?tag=codihorr-20">book</a>) in which the teacher divided the class into two groups. 
</p>
<p>
One group would be graded solely on the quantity of work they produced, whilst the other solely on its quality.
</p>
<p>
The grading procedure was simple:
</p>
<p>
<em>â€œOn the final day of class, the instructor would bring in his bathroom scales and weigh the work of the "quantity" group: fifty pound of pots rated an "A", forty pounds a "B", and so on. Those being graded on "quality", however, needed to produce only one pot - albeit a perfect one - to get an "A".â€�</em>
</p>
<p>
Fast forward to grading time. Can you guess what happened? 
</p>
<p>
It turns out that the works of highest quality were all produced by the group being graded for quantity:
</p>
<p>
<em>â€œIt seems that while the "quantity" group was busily churning out piles of work - and learning from their mistakes - the "quality" group had sat theorizing about perfection, and in the end had little more to show for their efforts than grandiose theories and a pile of dead clay.â€�</em>
</p>
<p>
Naval acknowledges that shipping at the velocity they do is not ideal. They make mistakes and many of the features they release are half-baked. 
</p>
<p>
But it is also precisely <em>because</em> they ship so much that theyâ€™re able to get it right. Just like the â€œquantityâ€� group, the engineers at AngelList are constantly iterating and testing out their assumptions. 
</p>
<p>
Rather than always being in paralysis mode, they just build the damn thing. And if it doesnâ€™t work, they try again until it does. 
</p>

<h2>
Plug
</h2>

<p>
Thanks for reading. I send out a weekly email newsletter containing my best content every Monday - I'd love for you to join. 
</p>

          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/angellist-shipping-culture</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320053</guid>
            <pubDate>Sun, 06 Dec 2020 01:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Brown University know where you are?]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25319392">thread link</a>) | @jswrenn
<br/>
December 5, 2020 | https://jack.wrenn.fyi/blog/brown-location-surveillance | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/brown-location-surveillance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In September 2020, Brown University <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">accused students</a> of lying about their location; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/notice.png" height="auto" width="100%" alt="The University has learned that between September 14, 2020 and September 21, 2020 you were allegedly in the Providence area during which time your location of study was listed as remote. This alleged behavior is a violation of the Student Code of Conduct and the COVID-19 Campus Safety Policy. A copy of the Student Commitment to COVID-19 Community Health and Safety Requirements is attached for your review, along with this link to the COVID-19 Campus Safety Policy. failure to abide by these requirements is a violation of the Code of Student Conduct. 
Based on the details of the incident and your student conduct history, the Office of Student Conduct &amp; Community Standards has decided to allow you the opportunity to accept responsibility for the following prohibited conduct without having a COVID-19 Dean's Review Meeting:
• D.8 Failure to Comply
• D.13 Misrepresentation
"></p>
<p><strong>What was Brown's basis for these accusations?</strong></p>
<p>In an <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">interview with The Brown Daily Herald</a>, University Spokesperson Brian Clark said the University evaluated a variety of indicators, including:</p>
<ol>
<li>indications of building access,</li>
<li>indications of accessing private electronic services,</li>
<li>indications of accessing secure networks, and</li>
<li>reports from community members.</li>
</ol>
<p>The mechanics of that last indicator are pretty self-explanatory, but what about the others? <a href="https://it.brown.edu/services/type/canvas-learning-management-system">Canvas</a> <em>doesn't</em> <a href="https://knowyourmeme.com/memes/google-wants-to-know-your-location">Want To Know Your Location</a>. <strong>In this post, I'm going to break down the technical mechanisms behind each of these indicators.</strong></p>
<p>For the most part, I do not have insider knowledge on how Brown reached its decisions. Rather, I'm going to consider each of the indicators Brian Clark named, and describe the technical mechanisms to which Brown <em>could</em> have availed itself to generating location data.</p>
<h2 id="indications-of-building-access">Indications of Building Access</h2>
<p>This is an easy one. Brown's buildings are located on Brown's campus. Brown's campus is in Providence. If you are in Brown's buildings, you are on Brown's campus, in Providence. QED.</p>
<p>At Brown, building access is primarily regulated with electronic control systems (namely Software House's <a href="https://www.swhouse.com/products/software_CCURE9000.aspx"><strong>C•CURE 9000</strong></a> system), not mechanical keys.</p>
<p>Encoded on <a href="https://en.wikipedia.org/wiki/Magnetic_stripe_card#Track_2">track 2</a> of the magnetic stripe on every University ID card is a sixteen digit number that uniquely identifies the card:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-back.jpg" height="auto" width="100%" alt="Image of back of Brown ID card. A tall magnetic stripe runs across the entire width of the card."></p>
<p>Well, that's underwhelming — of <em>course</em> you can't <em>see</em> it! However, up until 2017 or 2018, this number was also <em>printed</em> on the front of ID cards, just above the card-holder's name:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-front.jpg" height="auto" width="100%" alt="Image fo the front of a Brown ID card, displaying the building access code: 6009553660926201"></p>
<p>This pseudo-random identifier (well, its last ten digits) are what uniquely identify you whenever you swipe your Brown ID card <em>anywhere</em>. And, if you lose your Brown ID card, this is the <em>only</em> thing that's changed when you're issued a replacement. Convenient! In contrast, when you lose your dorm room's mechanical key, Brown must replace (or rather, <a href="https://en.wikipedia.org/wiki/Rekeying">rekey</a>) the locks.</p>
<p>But, <em>also</em> unlike a mechanical key, <em>every</em> swipe of a Brown ID card is logged in a central database. <strong>The C•CURE 9000 lets administrators view the complete historical building access history of a person.</strong> Last Spring, Brown used this mechanism to identify and prod students who were slow to evacuate Providence.</p>
<h2 id="indicators-from-electronic-services">Indicators from Electronic Services</h2>
<p>University web services like Canvas <em>don't</em> directly ask you for your location. Nonetheless, accessing these services leaves a location finger print: your IP address.</p>
<p>Your <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> is a number that identifies your device (computer, phone, etc.) for the purposes of network routing. In principle, nobody but you and your internet provider know the <em>exact</em> mapping of your IP address to your physical address.</p>
<p>In practice, IP addresses can be used to <em>roughly</em> geolocate a device. Batches of IP addresses are associated <em>loosely</em> with geographic areas. Since every web service access leaves an IP address as a trace, there are tremendous incentives for advertisers to be able accurately identify what city or town an IP address is probably associated with.</p>
<p>Brown probably <em>isn't</em> analyzing the access logs of its <em>individual</em> web services (like Canvas). Rather, they need only to audit the access logs of its three identity access management (IAM) systems:</p>
<ul>
<li>The <a href="https://workspace.google.com/">Google Workplace</a> IAM system is used to control access to your @brown.edu email, and to the various Google Drive services. <a href="https://support.google.com/a/answer/4580120?hl=en"><strong>Google Workplace</strong> provides administrators with login audit logs that include users' IP addresses.</a></li>
<li>The <a href="https://www.shibboleth.net/">Shibboleth</a> IAM system controls access to all <em>other</em> Brown web services, such as Canvas. It's what you think of as your "Brown account". Shibboleth is <em>very</em> flexible, and can be <a href="https://wiki.shibboleth.net/confluence/display/IDP30/AuditLoggingConfiguration#AuditLoggingConfiguration-GenericFields">configured to log IP addresses</a>.</li>
<li><a href="https://duo.com/">DUO</a> is used to provide two-factor authentication for Shibboleth logins. <a href="https://help.duo.com/s/article/1023?language=en_US#docs-internal-guid-0aa3b4ce-c686-7559-8814-1377592fce4a:%7E:text=Access%20Device">It too provides administrators with detailed access logs</a>.</li>
</ul>
<p>You can partly view your Google Workplace login history for yourself by opening your Brown email and clicking "Details" in the bottom right-hand corner of the page; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/gmail-account-activity.png" height="auto" width="100%"></p>
<p>With <em>either</em> of these access logs in hand, Brown could then turn to any number of geolocation services (<a href="https://tools.keycdn.com/geo">like this one</a>) to guess your physical location.</p>
<h2 id="indicators-from-secure-networks">Indicators from Secure Networks</h2>
<p>This is another easy one. Brown's WiFI network <a href="https://jack.wrenn.fyi/blog/blog/brown-location-surveillance/Campus_Wireless_Coverage_Map_24x36_1.pdf">blankets Brown's campus</a>. Brown's campus is in Providence. If you are on Brown's WiFi network, you are on Brown's campus. QED.</p>
<p>What might surprise you is the sheer depth of surveillance that's capable with WiFi alone. This section will <em>barely</em> scratch the surface.</p>
<h3 id="identification">Identification</h3>
<p>Brown's WiFi routers each broadcast three <a href="https://en.wikipedia.org/wiki/Service_set_(802.11_network)">service sets</a>:</p>
<ol>
<li><a href="https://it.brown.edu/services/type/wireless-network-brown">Brown</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-network-eduroam">eduroam</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-access-brown-guest">Brown Guest</a></li>
</ol>
<p>The Brown and eduroam networks require that you authenticate with your Brown account credentials. Brown University is thus able to identify the owner of any device connected to these networks.</p>
<p>While Brown Guest does <em>not</em> require authentication, it still provides mechanisms of identification. Your network devices broadcast a unique identifier called a <a href="https://en.wikipedia.org/wiki/MAC_address"><strong>MAC address</strong></a>.</p>
<p><a href="https://drawings.jvns.ca/mac-address/"><img type="image/svg+xml" src="https://drawings.jvns.ca/drawings/mac-address.svg" height="auto" width="100%" alt="Comic by Julia Evans. Text: Every computer on the internet has a network card. When you make HTTP requests with Ethernet/WiFi, every packet gets sent to a MAC address. (&quot;Wait, how do I know someone else on the same network isn't reading all my packets?&quot; &quot;You don't! That's one reason we use HTTPS &amp; secure WiFi networks.&quot;) Your router has a table that maps IP addresses to MAC addresses.  (Read about ARP for more.)
"></a></p>
<p>Brown <a href="https://it.brown.edu/computing-policies/network-connection-policy#32:%7E:text=CIS%20maintains%20a%20database%20of%20unique,a%20computer%20when%20it%20is%20necessary.">maintains databases of the MAC addresses of all connected devices</a>.</p>
<p>If you have ever connected to an authenticated network, Brown will be able to de-anonymize your connections to Brown Guest — <em>unless</em> your device implements <a href="https://en.wikipedia.org/wiki/MAC_address#Randomization">MAC address randomization</a>, which (as the name suggests) randomizes your device's MAC address on a per-network basis.</p>
<h3 id="localization">Localization</h3>
<p>Brown's access points log the MAC addresses of the devices that have connected to them. As of 2015, Brown retained these logs for at least several years — possibly indefinitely. Since there are so many access points on campus, which access point you are connected to can narrow your location down to a particular room. <strong>Combined, these logs paint a <em>very</em> accurate picture of your location on campus at any time.</strong></p>
<p>You do not need to be <em>actively</em> browsing the internet for Brown to know where you are via this mechanism. As you walk through campus, your phone likely <em>automatically</em> reconnects to the nearest available access point. If you are within a literal stone's throw of campus, you should assume that Brown can (roughly) identify your location.</p>
<p>Furthermore, if you are in range of three or more of Brown's ARUBA access points, Brown can precisely triangulate your location. This functionality is <a href="https://www.arubanetworks.com/pdf/technology/whitepapers/wp_Hybrid_WIDS.pdf">common</a> in enterprise-grade WiFi infrastructure. (If you've ever tried to run a "rogue" WiFi router in your dorm room and receive an angry knock on your door — this is the mechanism by which you were located.) </p>
<h2 id="bonus-surveillance-cameras">Bonus: Surveillance Cameras</h2>
<p>As of February 2020, <a href="https://www.browndailyherald.com/2020/02/21/cameras-installed-hegeman-hall/#post-2838338:%7E:text=The%20University%20uses%20approximately%20800%20cameras,with%20high%20crime%20activity%2C%20Porter%20said."><em>eight hundred</em> surveillance cameras monitor campus 24/7</a>. Brown has as about as many surveillance cameras as it has full-time faculty! This map documents a <em>mere seven percent</em> of Brown University's total camera surveillance capacity:</p>

<p><small>This map displays data from <a href="https://www.openstreetmap.org/about">OpenStreetMap</a>. <a href="https://pietervdvn.github.io/Staging/surveillance.html?z=17&amp;lat=41.82681&amp;lon=-71.4016">Help improve its accuracy!</a></small></p><p>Brown University has a longstanding policy governing the appropriate uses of its surveillance cameras. <strong>Unfortunately, <a href="https://www.browndailyherald.com/2008/01/10/surveillance-cameras-on-campus-triple/#post-1679525:%7E:text=DPS%20would%20not%20release%20the%20University%E2%80%99s%20full%20policy%20on%20the%20surveillance%20camera%20system">this policy is secret</a>.</strong></p>
<p>While Brown probably does not <em>currently</em> have the capacity to both broadly and deeply inspect the firehose of data produced by these cameras, expect this to change in the near future. Axis Communications, Brown's primary supplier of surveillance cameras, <a href="https://www.axis.com/customer-story/3767">now touts cameras that can perform <em>on-board</em> facial recognition</a>. And Software House, the provider of the C•CURE 9000 access control system, has begun marketing the integration of facial recognition with its access control systems:</p>
<p><iframe src="https://www.youtube.com/embed/bk395D0tPRA" frameborder="0" allowfullscreen=""></iframe></p>
<h2 id="how-do-i-find-out-more">How do I find out more?</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act"><em>Family Educational Rights and Privacy Act</em></a> empowers students to request their education records from their University.</p>
<p><iframe src="https://www.youtube.com/embed/jWzBrC8dVnw" frameborder="0" allowfullscreen=""></iframe></p>
<p>If you are a current Brown student and would like to go beyond my blog post and learn <em>exactly</em> how Brown University knows your location, <a href="https://www.brown.edu/about/administration/registrar/student-information-rightsferpa">file a FERPA request</a>. Brown University is obligated to respond within 45 days. You'll need to be specific with your request. I suggest requesting:</p>
<ul>
<li>the timestamps, MAC addresses and BSSIDs associated with your devices' connections to Brown University's wireless access points</li>
<li>the timestamps and locations associated with all building accesses conducted with your ID card</li>
<li>the login audit data associated with all Google Workplace, Shibboleth, and DUO authentications conducted by your accounts</li>
</ul>
<p>Additionally, the <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation"><em>General Data Protection Regulation</em></a> gives EU citizens and residents expansive control over how their personally identifiable information (PII) is used, and the right to request a copy of or the destruction of collected data. I believe these requests should be directed to <a href="https://compliance.brown.edu/">Brown's compliance office</a>. You might be able to do this even if you're a Brown alumni.</p>
<p><strong>If you attempt either of these steps, <a href="mailto:jack@wrenn.fyi">please get in touch</a>!</strong> I'm very curious as to what Brown is <em>actually</em> doing.</p>

  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/brown-location-surveillance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319392</guid>
            <pubDate>Sat, 05 Dec 2020 23:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top PostgreSQL Tools]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25319372">thread link</a>) | @blopeur
<br/>
December 5, 2020 | https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/ | <a href="https://web.archive.org/web/*/https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<figure><img loading="lazy" src="https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-1024x749.png" alt="#PostgreSQLtools" width="512" height="375" srcset="https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-1024x749.png 1024w, https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-300x219.png 300w, https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-768x562.png 768w, https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-1536x1124.png 1536w, https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-2048x1498.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></figure>



<p>PostgreSQL, or Postgres for short, comes with many out-of-the-box features that make it very popular among developers and data engineers. Among the numerous benefits of implementing Postgres are that there are many approaches to take to scale your database horizontally or vertically—but that is a discussion for a whole different article. Postgres comes with plenty of add-ons and a strong community of developers behind it too for open-source support.&nbsp;</p>



<p>Aside from plugins that you can quickly add a variety of tools and resources to your Postgres suite to expand the many functionalities of your Postgres database system to help you take your use of Postgres to the next level. This article shares the top 62 tools, plugins, and add-ons in that suite for you to improve your Postgres operations and productivity quickly and efficiently.</p>



<h2><strong>Graphical User Interface</strong></h2>



<p>Postgres doesn’t come with a native GUI, but that doesn’t mean you cannot manage your Postgres databases using a simple user interface. Web-based GUIs and tools for this specific purpose are easy to find.</p>



<figure><img loading="lazy" src="https://lh6.googleusercontent.com/plt54JgoE56tK9XTfy0n77S5kbUU3yOsxHuFncLuPYsC32QWHl9NQUTVulFjqJupJRB5i-Uvwy3u9NF0liPb4C2BCrEjvxNcZfSaUe2kJtPap4fiC3INTgPJubPtRHRhwi3zFGTl" alt="#DataGrip" width="254" height="113"></figure>



<ol><li><a href="https://www.jetbrains.com/datagrip/" target="_blank" rel="noreferrer noopener">Datagrip</a></li></ol>



<p>DataGrip is a tool that helps simplify managing multiple databases. It is compatible with multiple database systems, including PostgreSQL. You get a graphical interface for managing databases, running queries, and completing routine maintenance tasks. This tool is very popular at Cherre.</p>



<figure><img loading="lazy" src="https://lh3.googleusercontent.com/D0s1cOPz_g7XyuUoASoiIubUy5ZC5w3F5dSNp9KGUWF1alKUJCH-DzzBdO0yK_fgvUmG9_L1K59jYcq3OWfgrICkU6ov5uV9ukGNZQycHZvllxvtMZLYI_QfQEj1rroavXbnLVeb" alt="#DBeaver" width="216" height="108"></figure>



<ol start="2"><li><a href="https://dbeaver.io/" target="_blank" rel="noreferrer noopener">DBeaver&nbsp;</a></li></ol>



<p>The latest version of DBeaver, 7.1.4, includes data editing features that are designed to be intuitive. DBeaver, however, offers more than data editing. It supports PostgreSQL and many other database systems.</p>



<figure><img loading="lazy" src="https://lh3.googleusercontent.com/EIl8uFSl3bnrnLWOE5xbNYy_PLs0Gb1g5xC3CuhqGN_6Snr8DmyO0NI7BDxhRuKqqreLGm4hPwMTfA970hSC--k1D3UKg_xsNYk6qgnX5bTM9HFDX5IlPQhLTXC98UN3eEzLWuJu" alt="#Navicat" width="267" height="108"></figure>



<ol start="3"><li><a href="https://www.navicat.com/en/" target="_blank" rel="noreferrer noopener">Navicat for PostgreSQL</a></li></ol>



<p>Navicat is not a new name in the database landscape. Its product for Postgres is designed to offer you all the tools you need to manage complex databases. There are also data visualization tools available within.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/FQ2Tdygv9EVAvWLrJo8Ab9jA-L1cBtv3ek41rVaaVmCKLfYyHpJewvoy6dlmIiuNaLFODhsDHFdMfeotCx9cmcoBzxLFbpAN_efDh5s13Qzn2xFSXFfQkAmqlucDgfMf4wPhxzT6" alt="#Pgadmin" width="113" height="117"></figure>



<ol start="4"><li><a href="https://www.pgadmin.org/" target="_blank" rel="noreferrer noopener">Pgadmin</a></li></ol>



<p>When it comes to keeping Postgres maintenance and management simple, Postgres has pgADmin. The web-based option now supports external configuration files and runs completely in the cloud. You can use it as a way to manage database clusters. However, it feels a little limited compared to a full gui.</p>



<ol start="5"><li><a href="https://www.valentina-db.com/en/studio-for-postgresql" target="_blank" rel="noreferrer noopener">Valentina Studio for PostgreSQL</a></li></ol>



<p>Valentina Studio comes in different flavors, but even the free version is capable enough for managing multiple Postgres databases. It supports forms, can be integrated with CI/CD pipelines, and simplifies data transfer between databases.</p>



<ol start="6"><li><a href="http://phppgadmin.sourceforge.net/doku.php" target="_blank" rel="noreferrer noopener">phpPgAdmin</a></li></ol>



<p>MySQL has phpMyAdmin, and PostgreSQL has phpPgAdmin. If you are familiar with phpMyAdmin, then you will have no trouble using the Postgres version. The features and tools are relatively the same with a few adjustments.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/FHiWWzHKdvKOGEwdNi_FFJ4cmSFLW208aREpKrHw-fdNhR0AnIx7N5Rpe5_wVhnVpbGYfrF3dZJFVSjdse4ye7fXvVna-WxaW8oP94ZPEwl6VH5mOYfTCfoo12EQOp5mq8FgAc8A" alt="#Metabase" width="195" height="146"></figure>



<ol start="7"><li><a href="https://www.metabase.com/" target="_blank" rel="noreferrer noopener">Metabase</a></li></ol>



<p>Metabase is more of a data processing tool with advanced UIs. Rather than complex queries, it allows you to answer questions by visualizing insights collected from the PostgreSQL databases that you maintain.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/Z1m1CLoiqrVOz1S1LHm1SJDB5RkgizMFx8mqRC-GWyMs7gfrhAMoCHwOe9yGqKGJpWYPxJM62NgdJVAKJy6NwbYcszplUaCl0o1SOs68VgNsjFIc_sljbRRimFGeJPIodS_Zqn3_" alt="#Slemma" width="240" height="80"></figure>



<ol start="8"><li><a href="https://slemma.com/connectors/database-reporting/" target="_blank" rel="noreferrer noopener">Slemma</a></li></ol>



<p>Slemma is far from just another GUI for Postgres. It takes data visualization to another level by introducing automation. Reports from a series of entries can be generated automatically based on parameters and the kind of insights you want to get in return.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/vDAmrWbVqi9izoCkHpRiHKd7KC8sbos8p_L7tgBOLz-2EuI12hFg1BuhY9vgDfdyUGd__ChCmc37rpimb4LMqXPYnzLP7RHDqnU6_5PWA_B4UK5SZu6lEHxfZAwqSKcNxrGZF7CP" alt="#windwardstudios" width="331" height="76"></figure>



<ol start="9"><li><a href="https://www.windwardstudios.com/datasource/postgresql" target="_blank" rel="noreferrer noopener">Windward Studios</a></li></ol>



<p>Windward is the last GUI tool on our list with a special trick up its sleeve: it can be integrated with Microsoft Office natively. You can use Office apps to design templates for reports or to visualize your report using data stored in Postgres.</p>



<h2><strong>Utilities</strong></h2>



<p>Utilities for Postgres are usually designed to do specific things. While PostgreSQL doesn’t require special maintenance, it is still a good idea to integrate good utilities into your database management workflow. The best utilities tools will certainly make your life as a database engineer easier.</p>



<ol><li><a href="https://github.com/EnterpriseDB/pg_catcheck" target="_blank" rel="noreferrer noopener">Pg_catcheck</a></li></ol>



<p>System catalog corruption can be a huge problem that can bring an entire Postgres database down when it happens. Depending on the severity of the corruption, you may also lose entries and valuable information. Use pg_catheck to monitor for system catalog corruption.</p>



<ol start="2"><li><a href="http://www.pgbouncer.org/" target="_blank" rel="noreferrer noopener">pgBouncer</a></li></ol>



<p>As the name suggests, pgBouncer acts as the bouncer that prevents unauthorized access. The common use case for this tool is to manage connections, similar to a load balancer. While Postgres is relatively secure as long as you follow the best practices, having encrypted SCRAM secrets used for storing passwords is a good idea.</p>



<ol start="3"><li><a href="https://hypopg.readthedocs.io/en/latest/" target="_blank" rel="noreferrer noopener">HypoPG</a></li></ol>



<p>Hypotheticals are not always possible—and are certainly difficult to keep track of—and HypoPG is here to solve those challenges. It is basically a virtual index that doesn’t really consume cloud resources. It can also handle hypothetical partitioning.</p>



<ol start="4"><li><a href="https://www.postgis.net/" target="_blank" rel="noreferrer noopener">PostGIS</a></li></ol>



<p>PostGIS fills one specific hole, lack of native support for spatial information. Postgres users can now use PostGIS to use location information in queries. If your app relies on location data, this utility certainly helps.</p>



<ol start="5"><li><a href="https://www.postgresql.org/docs/11/postgres-fdw.htm" target="_blank" rel="noreferrer noopener">Postgres_fdw</a></li></ol>



<p>Foreign-data wrapper makes accessing external Postgres databases possible. Postgres_fdw takes that idea one step further and makes the whole process easier.&nbsp; In short you can use objects from other databases, without having to sync the two together, Postgres_fdw inexpensively makes it look like it’s in both. After installing the utility, you can create a foreign server object and work with user mapping accordingly.</p>



<ol start="6"><li><a href="https://www.yohz.com/dbdoc_details.htm" target="_blank" rel="noreferrer noopener">DB Doc for PostgreSQL</a></li></ol>



<p>While launching a new app or distributing it to a client is a fairly straightforward process, making sure that the app is used properly—and is developed with care—is still difficult. DB Doc for PostgreSQL takes care of creating documentation for your projects.</p>



<h2><strong>Platform as a Service (PaaS)</strong></h2>



<p>Being able to utilize Postgres without having to manage the entire cloud infrastructure supporting it is something that many development teams want these days. Organizations turn to managed database services so that they can utilize the features of Postgres without the usual complications. Fortunately, there are several solutions being offered as Platform as a Service or PaaS.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/gxEUzL5xD9FYbEf-O1dSweSDqCeuqH29GAw6U5GyrdwRC_SO5VV4V9XPG3JysT_7F9kcsa-iE0r265pi6RwU5uzXM-tpSnsRHqLHsKTX7VlyNJC4Vx1grypmnH3oFvmQwyzQo2nW" alt="#AmazonRDSforPostgreSQL" width="118" height="132"></figure>



<ol><li><a href="https://aws.amazon.com/rds/postgresql/" target="_blank" rel="noreferrer noopener">&nbsp;Amazon RDS for PostgreSQL</a></li></ol>



<p>Amazon’s RDS is perhaps the most popular option of them all, offering cloud relational databases as managed services. It has Amazon RDS for PostgreSQL, which allows you to forget about storage, deployment cycles, availability, and backup while taking full advantage of what Postgres has to offer.</p>



<figure><img loading="lazy" src="https://lh6.googleusercontent.com/nS9uoXzAn68iKWqAXzTgHzMuvjQHn1hmVqNshUIYCWstM0cHCt6EbVAdiormaASkc-li1fJ1JWz71885r6tTmODgpyRt6J_gYBjbT1W3jaQwoOjMMg7HPYBOBYhqb5UfvyS8QJro" alt="#aiven" width="173" height="91"></figure>



<ol start="2"><li><a href="https://aiven.io/postgresql" target="_blank" rel="noreferrer noopener">Aiven for PostgreSQL</a></li></ol>



<p>Aiven for PostgreSQL is another option when it comes to fully managed SQL databases. You can give the platform a try for free before switching to one of the paid plans that suit your needs best. Even better, Aiven runs on AWS, GCP, Azure, and other cloud ecosystems for better availability.</p>



<figure><img loading="lazy" src="https://lh4.googleusercontent.com/iIeJzX5JFZAPYm24YDmJo3HzHIUgSfrhyGhrm15jrIPLNWot_qIWi3UDmEf7_2l2fn4Pxa2TsGECybWOVjqhOPiuRlNSyXiURZjhJT_Z9TAMg8bPSNEwyCrey_1jpPUCby_w8bAE" alt="#CloudSQLforPostgreSQL" width="137" height="128"></figure>



<ol start="3"><li><a href="https://cloud.google.com/sql/docs/postgres" target="_blank" rel="noreferrer noopener">Cloud SQL for PostgreSQL</a></li></ol>



<p>Cloud SQL for PostgreSQL is Google’s version of managed relational databases in the cloud. As part of Google Cloud, Cloud SQL for PostgreSQL integrates well with other GCP services, plus it can be used to support apps running in a multi-cloud environment thanks to its comprehensive API.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/7ZleaQxKb5wx4XkzKSr7GNtUS2UEch28DRlFutxf3iS4Ai5-0qsFIv-M8oImaGQwLIKoWDxychrTKrgQebP-30aEA_AMuHy_prL3botCzH5qX5F9IrCTu0F2dvxaqY6olaoRk3Ww" alt="#AzureDatabaseforPostgrSQL" width="143" height="143"></figure>



<ol start="4"><li><a href="https://azure.microsoft.com/en-us/services/postgresql/" target="_blank" rel="noreferrer noopener">Azure Database for PostgreSQL</a></li></ol>



<p>Amazon has one. Google has one. So it is not surprising to see Microsoft offering the Azure Database for PostgreSQL. Azure doesn’t just offer another PaaS for Postgres users, though. It leans heavily on scalability and offers intelligent performance recommendations—powered by machine learning—as one of its features.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/oEUtjqnAJ03bOJYbQwkiRuvcTTNe2Rd0hXx90YTR4ksZy60WEsiOeoAqZh6soY89yz2ifXnSwyryIuNfQSc_Ytrbo-7JeXi4Qs1wjdM3m20Ir-MtgmsHbU8baiND5WBHxTDHQ95s" alt="#DigitalOcean" width="132" height="132"></figure>



<ol start="5"><li><a href="https://www.digitalocean.com/products/managed-databases/" target="_blank" rel="noreferrer noopener">DigitalOcean Managed Databases</a></li></ol>



<p>For a more affordable option, DigitalOcean Managed Databases is the service you want to look into. It starts at only $15/month, but It offers easy setup, seamless maintenance, daily backups, and multiple redundancies to support your apps and microservices.</p>



<figure><img loading="lazy" src="https://lh6.googleusercontent.com/E59LDZy3uUEiBAnPPFauhfT3q6tyvzWyWtrC0xKGyp_pbVurrhrCDo4ZQW2eTvVX03fdD8MsegQvb0VlaobAgX5R_pY60qItNr8b9ZweovwCHE-2wZNeKnvohMiXKmDLZ9yitemq" alt="#Heroku" width="198" height="110"></figure>



<ol start="6"><li><a href="https://elements.heroku.com/addons/heroku-postgresql" target="_blank" rel="noreferrer noopener">Heroku PostgreSQL</a></li></ol>



<p>Heroku PostgreSQL offers all the Postgres features you will ever need, but without making the entire platform cluttered or too complicated. Available in the United States and Europe, Heroku PostgreSQL is also affordable thanks to its nano and micro plans.</p>



<h2><strong>Applications</strong></h2>



<p>There are a lot of tools designed to make designing Postgres databases, creating relationships, managing tables, and organizing the entire PostgreSQL platform easier, but most of them are designed to offer specific features. In this part, we are going to take a look at the two Postgres applications that you can use for end-to-end database design and management.</p>



<figure><img loading="lazy" src="https://lh6.googleusercontent.com/BNG9GB5GDj0UgmVKyLRJ2PFYbJBXPHemZTxuUfYYy3_WrsOTDydLH4eORC3gQwSQ6Bu38EGkcxzKd6N6yJ4emc88wRIhz9rQIZ-U6FrdXtxxRF21JdT2Toj9_vOWosaLeyTDG-ZA" alt="#agileBase" width="129" height="115"></figure>



<ol><li><a href="http://www.agilebase.co.uk/" target="_blank" rel="noreferrer noopener">agileBase</a></li></ol>



<p>AgileBase is famous for its low-code or no-code approach. You don’t have to be a database specialist—or any specialist for that matter—to build your own platform and support the application you want to deliver. AgileBase’s PostgreSQL features are designed as blocks and can be customized to your liking.</p>



<figure><img loading="lazy" src="https://lh4.googleusercontent.com/4COODpGprHglQA440b4to0ipwxVG3SIqAZJNOyqHQ_aERyOUZENL9c6nFzn5ue05rXnVomRuQRV9pkeF_m9T6l8cX9vZ2ojPzYanMVYL2HJgjWgDa3ZfrRrFk2AXoCqmXb28SKF-" alt="#Dataedo" width="255" height="78"></figure>



<ol start="2"><li><a href="https://dataedo.com/" target="_blank" rel="noreferrer noopener">Dataedo</a></li></ol>



<p>Dataedo is all about simplicity. You can manage even the most complex Postgres database through the app’s simple user interface. Even relationships are displayed visually and can be edited as such. This is a great app to use if you don’t want complex database management to be a bottleneck in your pipeline.</p>



<h2><strong>High-Availability</strong></h2>



<p>A database always sits at the core of the application that uses it. Database failures and unreliable database systems are unacceptable because they tend to bring the entire application down with them. That is why PostgreSQL is best implemented in a highly available environment, and these tools are the ones to use if you want to monitor high availability.</p>



<ol><li><a href="https://daamien.github.io/PostgreSQL-Dashboard/">B</a><a href="https://daamien.github.io/PostgreSQL-Dashboard/" target="_blank" rel="noreferrer noopener">G</a><a href="https://daamien.github.io/PostgreSQL-Dashboard/">R</a></li></ol>



<p>The PostgreSQL Dashboard offers access to key metrics that make ensuring high availability easier. There is no need to go through logs manually. Insights are displayed visually and you can go straight to refining your cloud infrastructure to boost the reliability of your database system.</p>



<figure><img loading="lazy" src="https://lh4.googleusercontent.com/THt0_k5TJV7ZBN8Evk-T8SDq_RMjV9WLgxMAHzjkfxFDer19sBClE-GQDwPNUtSqg3lclTrPQC48D46J2e6f72b4xArlJOO-SSusLTmXdNZ6FznQcBq24UGq3RDxKsHuKoroWXPy" alt="#Stolon" width="210" height="105"></figure>



<ol start="2"><li><a href="https://github.com/sorintlab/stolon" target="_blank" rel="noreferrer noopener">Stolon</a></li></ol>



<p>Stolon is another native PostgreSQL management tool designed to make high availability more accessible. It adds features such as native support for Kubernetes and automatic service discovery, allowing multiple database instances to run …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/">https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/</a></em></p>]]>
            </description>
            <link>https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319372</guid>
            <pubDate>Sat, 05 Dec 2020 23:14:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No dog food today: the Linux Foundation annual report]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25319086">thread link</a>) | @ingve
<br/>
December 5, 2020 | https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><a href="https://daniel-lange.com/categories/17-Strategy"><img title="Strategy: Airplanes are interesting toys but of no military value. (Marechal Ferdinand Foch, Professor of Strategy, Ecole Superieure de Guerre)" alt="Strategy" src="https://daniel-lange.com/uploads/strategy.serendipityThumb.jpg"></a></p><p>The Linux Foundation has published its <a href="https://www.linuxfoundation.org/wp-content/uploads/2020/11/2020-Linux-Foundation-Annual-Report_113020.pdf">annual report</a> today. LWN <a href="https://lwn.net/Articles/838871">calls it glossy</a> and yeah, boy, it is shiny.</p>

<p>So shiny that people that work in the publishing industry immediately see this has been produced with the Adobe toolchain which - unfortunately - is one of the big suites of software not yet available for Linux.</p>

<p>Checking the PDF file metadata reveals the keywords "open source, open standards, open hardware, open data". That is what the Linux Foundation is about. Good stuff.</p>

<p><!-- s9ymdb:667 --><img width="552" height="676" src="https://daniel-lange.com/uploads/entries/Linux-Foundation-Annual-Report-2020-cover.jpg" title="Mouseovers are for xkcd!" alt="Linux Foundation annual report 2020 cover"></p>

<p>The PDF producer meta data for the annual report PDF has been set to "Linux kernel 0.12.1 for Workgroups" and the PDF creator meta data element to "Sharp Zaurus XR-5000 (Maemo5) Edition". Somebody thought to better hide the real data and had some tongue-in-cheek ideas. Kudos.</p>

<p>But nicer would have been to use Open Source software to produce the report, not?</p>

<p>Running <code>strings 2020-Linux-Foundation-Annual-Report_113020.pdf | grep Adobe | wc -l</code> gives us 1229 lines and confirms the suspicion of the toolchain.</p>

<p>A stale <code>/Title (Annual Report 2020) /Producer (macOS Version 10.15.7 \(Build 19H15\) Quartz PDFContext)</code> has been forgotten in the document to tell us about the platform.</p>

<p>So, ladies and gentlemen, the Linux Foundation 2020 annual report has been produced on a Mac.</p>

<p>Running Adobe Creative Cloud on MacOS Catalina 10.15.7.</p>

<p>Which is proprietary software. Its kernel (and some userland pieces) are based on BSD. Not Linux.</p>

<hr>

<p>The image on the front page also struck me as a bit odd ... using a ballpoint pen on the laptop screen?</p>

<p>Unbranded laptop.
Unbranded cup in the foreground.</p>

<p>Kid in the background <em>not</em> paying attention to his tablet.</p>

<p>All of that cries stock image so loud it hurts.</p>

<p>Google currently finds ~560 uses of the picture and any <a href="https://www.shutterstock.com/support/article/Do-I-need-to-credit-Shutterstock-the-artist-when-I-use-Images-or-Footage">editorial use</a> nicely tells us that it is © <a href="https://www.shutterstock.com/de/g/draganagordic">Dragana Gordic / Shutterstock</a>.</p>

<p>The image is "Smiling mom working at home with her child on the sofa while writing an email. Young woman working from home, while in quarantine isolation during the Covid-19 health crisis".</p>

<p>See the <a href="https://www.dailymail.co.uk/news/article-8683629/Staff-working-home-nearly-extra-hour-day-research-shows-send-emails.html">Daily Mail</a> for a wonderful example of the working mum in context. I hope, if her laptop had been powered on, it would have run Linux. I mean, what else would still run on an old white MacBook with an Intel "Core 2 Duo" processor from 2008?</p>

<p><!-- s9ymdb:668 --><img width="504" height="742" src="https://daniel-lange.com/uploads/entries/DailyMail-screenshot-stock-image.png" title="O.k., here you go: Shiny, too!" alt="Daily Mail screenshot of the same stock image used"></p>

                </div><div id="extended">
        <p>Bonus round:</p>

<p>The Ethernet port, the USB ports and the headset connector are on the left side of the MacBook. The Daily Mail got it right.</p>

<p>Mirroring images is usually not a good idea. To Linux Foundation's defense ... similar pictures are available <a href="https://www.shutterstock.com/de/image-photo/busy-young-woman-son-home-shot-1680921679">already mirrored on Shutterstuck</a> next to the <a href="https://www.shutterstock.com/de/image-photo/smiling-mom-working-home-her-child-1680923362">correctly oriented picture</a>.</p>

        </div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319086</guid>
            <pubDate>Sat, 05 Dec 2020 22:36:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust makes cross compilation child's play]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25319018">thread link</a>) | @MarcoIeni
<br/>
December 5, 2020 | https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/ | <a href="https://web.archive.org/web/*/https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<h2 id="why-do-i-care-about-this">Why do I care about this</h2>

<p>Recently I solved <a href="https://github.com/dandavison/delta/issues/396">this</a> delta issue,
where the maintainer asked to switch from Travis CI to GitHub actions.</p>

<p>These are all the pull requests I’ve done if you want to have a look at this journey:
<a href="https://github.com/dandavison/delta/pull/399">#399</a>, <a href="https://github.com/dandavison/delta/pull/400">#400</a>,
<a href="https://github.com/dandavison/delta/pull/409">#409</a>, <a href="https://github.com/dandavison/delta/pull/411">#411</a>,
<a href="https://github.com/dandavison/delta/pull/413">#413</a>, <a href="https://github.com/dandavison/delta/pull/417">#417</a>
and finally <a href="https://github.com/dandavison/delta/pull/418">#418</a>.</p>

<p>And yes..As you can see I like small incremental work and early feedback instead of giant pull requests. 😁</p>

<p>Anyway, the delta project has a lot of compilation targets and the binaries are automatically released in the
GitHub releases <a href="https://github.com/dandavison/delta/releases">page</a> every time the project is tagged. Sweet. 😌</p>

<p><img src="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/delta.png" alt="delta releases" title="Releases"></p>

<p>From an x86_64 architecture (TLDR: common 64 bit Intel or AMD processors) it is really straightforward to
compile for a different operating system with <code>cargo</code> if you are targeting the same architecture.
For example if you want to compile for macOS you just need to run:</p>

<pre><code>rustup target add x86_64-apple-darwin
cargo build --target x86_64-apple-darwin
</code></pre>

<p>The problems start to arise when you want to compile for a different architecture, such as i686 (32 bit) or ARM processors.
In this case, you have to install some dependencies and set some environment variables, which may be painful.
For example, in the old continuous integrations scripts of delta,
<a href="https://github.com/dandavison/delta/blob/15d06cbf7584570ec3b5beaba99cb8898f9ec3dc/etc/ci/before_install.sh">this</a>
was the way dependencies were installed. Ugly, I know. As rust developers we are used to great tools,
so there must be a better way right?</p>

<h2 id="meet-cross">Meet Cross</h2>

<blockquote>
<p>“Zero setup” cross compilation and “cross testing” of Rust crates.</p>
</blockquote>

<p>This is the description of the <a href="https://github.com/rust-embedded/cross">Cross</a> tool.</p>

<p>The TLDR is that it let you compile and test rust projects for architectures other than i686 and x86_64.</p>

<p>Instead of doing <code>cargo build --target &lt;YOUR_TARGET&gt;</code> you simply do <code>cross build --target &lt;YOUR_TARGET&gt;</code>.
Based on the target, in fact, cross will run a docker image that has all the right dependencies already
installed and configured by the rust-embedded team itself. 😉
And that’s it..just run <code>cargo install cross</code> and you are ready to cross-compile for all
<a href="https://github.com/rust-embedded/cross#supported-targets">these</a> targets in rust, no other dependency
is required, except docker of course!</p>

<p>Obviously this was not an exhaustive overview about cross and I encourage you to have a look at the GitHub page
if you are interested.</p>

<h2 id="cross-in-github-actions">Cross in GitHub actions</h2>

<p>Of course, after a whole morning getting mad trying to setup weird ubuntu dependencies for the delta issue,
when I found out about cross I felt very stupid for not knowing it in advance and I tried to integrate it in the
Continuous Deployment delta pipeline.</p>

<p>It turns out that this is like the easiest thing in the world! The <a href="https://github.com/actions-rs/cargo">action-rs/cargo</a> action
I was already using had built-in <a href="https://github.com/actions-rs/cargo#cross-compilation">support</a> for cross.
Now I even felt more stupid, but anyway..you just need to set the <code>use-cross</code> variable to <code>true</code> and you are done!</p>

<p><a href="https://github.com/dandavison/delta/blob/e198c0d841d9fb660e59e0329235a8601b407c69/.github/workflows/cd.yml#L32-L37">This</a>
is the step that builds the whole delta project for all its different targets..easy, right? 😀</p>

<h2 id="cross-in-rust-github-template">Cross in Rust GitHub template</h2>

<p>You may or (probably) may not be aware of <a href="https://rust-github.github.io/">Rust GitHub Template</a>.</p>

<blockquote>
<p>Rust GitHub Template is a template for cargo generate that aims to be a starting point suitable for the vast majority of rust projects that will be hosted on GitHub.</p>
</blockquote>

<p>Beyond all its nice goodies, this template will setup Continuous Deployment for you, therefore whenever
you tag your project, it will be published on <code>crates.io</code> and the binaries will be released in the GitHub Releases page,
just like in delta. 😁</p>

<p>Until today, Rust GitHub template only supported x86_64 windows, linux and mac, but after I found out Cross I couldn’t resist
and I added support for i686 and aarch64 linux architectures, which are both two <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">tier 1</a> rust targets.
In practice, this means your “old thinkpad” and “raspberry pi” users will thank you a lot. 😛</p>

<p><img src="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/rust-gh.png" alt="gh template releases" title="Releases"></p>

<p><a href="https://github.com/rust-github/rust-gh-example/blob/01e0aae91f83e1e932f4498a0eddb2905c8fffc3/.github/workflows/cd.yml#L57-L63">This</a>
is an example of the resulting Continuous Deployment step.</p>

<p>And that was it, after I spent a lot of <em>very useful</em> time trying to setup compilation dependencies basically I just wanted to share my love for the <code>cross</code>
tool with the rest of the world in order to avoid this pain to as many people as possible. 😅</p>

<p>Thanks for reading this far! You can find me on <a href="https://twitter.com/MarcoIeni">twitter</a> or <a href="https://www.youtube.com/MarcoIeni">YouTube</a>, bye! 👋</p>

  </div></div>]]>
            </description>
            <link>https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319018</guid>
            <pubDate>Sat, 05 Dec 2020 22:27:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The California Privacy Rights Act of 2020]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318891">thread link</a>) | @bencmbrook
<br/>
December 5, 2020 | https://transcend.io/laws/cpra/ | <a href="https://web.archive.org/web/*/https://transcend.io/laws/cpra/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><main><section><div><div><div width="100"><p><span><p>The California Privacy Rights Act of 2020 (CPRA) amends the California Consumer Privacy Act of 2018 (CCPA). Transcend makes privacy laws easy for engineers and lawyers alike. In that spirit, we've transcribed this law into something easily referenceable.</p></span></p></div></div></div></section><section><div><div><div><div name="Section1"><h2>SEC. 1. Title.</h2><p>This measure shall be known and may be cited as "The California Privacy Rights Act of 2020."</p></div><div name="Section2"><h2>SEC. 2. Findings and Declarations.<!-- --> </h2><p>The People of the State of California hereby find and declare all of the following:</p><p>A. In 1972, California voters amended the California Constitution to include the right of privacy among the "Inalienable" rights of all people. Voters acted in response to the accelerating encroachment on personal freedom and security caused by increased data collection and usage in contemporary society. The amendment established a legal and enforceable constitutional right of privacy for every Californian. Fundamental to this right of privacy is the ability of individuals to control the use, including the sale, of their personal information.</p><p>B. Since California voters approved the constitutional right of privacy, the California Legislature has adopted specific mechanisms to safeguard Californians' privacy, including the Online Privacy Protection Act, the Privacy Rights for California Minors in the Digital World Act, and Shine the Light, but consumers had no right to learn what personal information a business had collected about them and how they used it or to direct businesses not to sell the consumer's personal information.</p><p>C. That changed in 2018, when more than 629,000 California voters signed petitions to qualify the California Consumer Privacy Act of 2018 for the ballot. In response to the measure's qualification, the Legislature enacted the California Consumer Privacy Act of 2018 (CCPA) into law. The CCPA gives California consumers the right to learn what information a business has collected about them, to delete their personal information, to stop businesses from selling their personal information, including using it to target them with ads that follow them as they browse the internet from one website to another, and to hold businesses accountable if they do not take reasonable steps to safeguard their personal information.</p><p>D. Even before the CCPA had gone into effect, the Legislature considered many bills in 2019 to amend the law, some of which would have significantly weakened it. Unless California voters take action, the hard-fought rights consumers have won could be undermined by future legislation.</p><p>E. Rather than diluting privacy rights, California should strengthen them over time. Many businesses collect and use consumers' personal information, sometimes without consumers' knowledge regarding the business's use and retention of their personal information. In practice, consumers are often entering into a form of contractual arrangement in which while they do not pay money for a good or service, they exchange access to that good or service in return for access to their attention, or access to their personal information. Because the value of the personal information they are exchanging for the good or service is often opaque, depending on the practices of the business, consumers often have no good way to value the transaction. In addition, the terms of agreement or policies in which the arrangements are spelled out, are often complex, unclear, and as a result most consumers never have the time to read or understand them.</p><p>F. This asymmetry of information makes it difficult for consumers to understand what they are exchanging and therefore to negotiate effectively with businesses. Unlike in other areas of the economy where consumers can comparison shop, or can understand at a glance if a good or service is expensive or affordable, it is hard for the consumer to know how much his or her information is worth to any given business, when data use practices vary so widely between businesses.</p><p>G. The State therefore has an interest in mandating laws that will allow consumers to understand more fully how their information is being used, and for what purposes. In the same way that ingredient labels on foods help consumers shop more effectively, disclosure around data management practices will help consumers become more informed counterparties in the data economy, and promote competition, Additionally, if a consumer can tell a business not to sell his or her data, then that consumer will not have to scour a privacy policy to see whether the business is, In fact, selling that data, and the resulting savings in time is worth, in the aggregate, a tremendous amount of money.</p><p>H. Consumers need stronger laws to place them on a more equal footing when negotiating with businesses in order to protect their rights, Consumers should be entitled to a clear explanation of the uses of their personal information, including how it is used for advertising, and to control, correct, or delete it, Including by allowing consumers to limit businesses' use of their sensitive personal information to help guard against identity theft, to opt-out of the sale and sharing of their personal information, and to request that businesses correct inaccurate information about them.</p><p>I. California is the world leader in many new technologies that have reshaped our society. The world today is unimaginable without the internet, one of the most momentous inventions in human history, and the new services and businesses that arose on top of it -- many of which were invented here in California. One of the most successful business models for the internet has been services that rely on advertising to make money as opposed to charging consumers a fee. Advertising-supported services have existed for generations, and can be a great model for consumers and businesses alike. However, some advertising businesses today use technologies and tools that are opaque to consumers to collect and trade vast amounts of personal information, to track them across the internet, and to create detailed profiles of their individual interests. Some companies that do not charge consumers a fee, subsidize these services by monetizing consumers' personal information. Consumers should have the information and tools necessary to limit the use of their information to non-invasive, pro-privacy advertising, where their personal information is not sold to or shared with hundreds of businesses they've never heard of, If they choose to do so. Absent these tools, it will be virtually impossible for consumers to fully understand these contracts they are essentially entering into when they interact with various businesses.</p><p>J. Children are particularly vulnerable from a negotiating perspective with respect to their privacy rights. Parents should be able to control what information is collected and sold or shared about their young children and should be given the right to demand that companies erase information collected about their children.</p><p>K. Business should also be held directly accountable to consumers for data security breaches and notify consumers when their most sensitive information has been compromised.</p><p>L. An independent watchdog whose mission is to protect consumer privacy should ensure that businesses and consumers are well-informed about their rights and obligations and should vigorously enforce the law against businesses that violate consumers' privacy rights.</p></div><div name="Section3"><h2>SEC. 3. Purpose and Intent.</h2><p>In enacting this Act, It is the purpose and intent of the people of the State of California to further protect consumers' rights, including the constitutional right of privacy. The implementation of this Act shall be guided by the following principles:</p><h3>A. Consumer Rights</h3><p>1. Consumers should know who is collecting their personal information and that of their children, how it is being used, and to whom it is disclosed, so that they have the information necessary to exercise meaningful control over businesses' use of their personal information and that of their children,</p><p>2. Consumers should be able to control the use of their personal information, Including limiting the use of their sensitive personal information, the unauthorized use or disclosure of which creates a heightened risk of harm to the consumer, and they should have meaningful options over how it is collected, used, and disclosed.</p><p>3. Consumers should have access to their personal information and should be able to correct it, delete it, and take it with them from one business to another.</p><p>4. Consumers or their authorized agents should be able to exercise these options through easily accessible self-serve tools.</p><p>5. Consumers should be able to exercise these rights without being penalized for doing so.</p><p>6. Consumers should be able to hold businesses accountable for falling to take reasonable precautions to protect their most sensitive personal information from hackers and security breaches.</p><p>7. Consumers should benefit from businesses' use of their personal information.</p><p>8. The privacy interests of employees and independent contractors should also be protected, taking into account the differences in the relationship between employees or independent contractors and businesses, as compared to the relationship between consumers and businesses. In addition, this law is not intended to interfere with the right to organize and collective bargaining under the National Labor Relations Act. It is the purpose and intent of the Act to extend the exemptions in this title for employee and business to business communications until January 1, 2023.</p><h3>B. The Responsibilities of Businesses</h3><p>1. Businesses should specifically and clearly inform consumers about how they collect and use personal information and how they can exercise their rights and choice.</p><p>2. Businesses should only collect consumers' personal information for specific, explicit, and legitimate disclosed purposes, and should not further collect, use, or disclose consumers' personal information for reasons incompatible with those purposes.</p><p>3. Businesses …</p></div></div></div></div></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://transcend.io/laws/cpra/">https://transcend.io/laws/cpra/</a></em></p>]]>
            </description>
            <link>https://transcend.io/laws/cpra/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318891</guid>
            <pubDate>Sat, 05 Dec 2020 22:09:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Feature Store]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318723">thread link</a>) | @nlathia
<br/>
December 5, 2020 | https://nlathia.github.io/2020/12/Building-a-feature-store.html | <a href="https://web.archive.org/web/*/https://nlathia.github.io/2020/12/Building-a-feature-store.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The corner of the internet that I read is awash with posts about feature stores: systems that aim to be <a href="https://blog.feast.dev/post/what-is-a-feature-store">“the interface between models and data.”</a></p>

<p>This idea has been around for quite a while, but there are now an increasing number of companies that are building feature store platforms or products–the concept is becoming established in the machine learning system <em>operations</em> arena.</p>

<p>A few months ago, I built a feature store at <a href="https://monzo.com/">Monzo</a>; in light of that, I thought I’d share some of the thinking that motivated my team to need to build one and how I designed it.</p>

<p>As a broad summary: the feature store that I built does not solve for the many different use cases that you may hear about feature store products–our feature store focuses on regularly and safely transferring data between our analytics and production stacks.</p>

<p>Let’s begin!</p>

<h2 id="-isnt-a-feature-store-just-a-database">🤔 Isn’t a feature store just a database?</h2>

<p>Well, yes. But also no.</p>

<p>When I first started talking about the idea of a feature store internally, some feedback that I received was ‘we already do this–we just haven’t been calling them feature stores.’ Indeed, the emphasis of the name “feature store” has often been on the “<strong>store</strong>” aspect, which does make the whole thing sound like it is just a database. The word “<strong>feature</strong>” is often used to mean “some type of data” (e.g., a column in a table).</p>

<p>At Monzo, you can’t look at any corner of our <a href="https://qconlondon.com/london2020/presentation/modern-banking-1500-microservices">production infrastructure</a> without running into the key-value store we use, Cassandra. In our systems, it’s common for each microservice to have its own keyspace, and for individual services to collect, aggregate, and store the different types of data that they need.</p>

<p>We already had two patterns across several systems which looked like “feature stores:”</p>

<ol>
  <li>Services that receive a request, fan out a bunch of calls to other services, and then munge and store the resulting features. For example, we have a system that filters help articles, and caches features about users, who will be actively navigating the content.</li>
  <li>Services that consume events from streams to construct features about different entities. For example, we have a system that consumes events that occur when chat messages are sent and received, and can then serve requests for features about conversations (e.g., the number of turns).</li>
</ol>

<p>What this means is that data across our keyspaces is typically organised around the systems that they serve: we design a system first (e.g., a system for user accounts), and the features it holds follows from that design (data about user accounts).</p>

<h2 id="-whats-different-about-feature-stores">🧐 What’s different about “feature stores?”</h2>

<p>The idea of a feature store is different because it is a system that is meant to prospectively hold a <em>wide diversity</em> of data–nearly anything that could be valuable input to machine learning models. The “features” could even be the output of <em>other</em> machine learning models (predictions or embeddings).</p>

<p>I think this is an important point because this inverts how data is organised in a production system. With a feature store, you can build a separation of concerns between the systems that generate data and the aggregations of that data that are input into ML models. If you want stats about user accounts, you no longer need to know about user account system– you <em>just</em> query the feature store.</p>

<p>The main reason that is often stated for having a centralised place for features is that they are <em>meant to be reused</em> to solve different problems. For example, let’s say that I’m building a feature, like “average number of transactions in the last 7 days.” This feature could potentially be very useful to a whole host of <em>different</em> machine learning models. If we were going to store this data inside of the system that uses it, we may end up:</p>
<ol>
  <li>Having to rebuild the same feature in more than one place, and</li>
  <li>Making it very difficult to discover what features are available for reuse across problems.</li>
</ol>

<h3 id="-pause-do-these-two-problems-actually-matter">⏸ Pause: do these two problems actually matter?</h3>

<p>Before I carry on to describe our feature store, I’ll pause to reiterate a word of warning that I mentioned in <a href="http://nlathia.github.io/2020/11/Why-ML-code.html">my last blog post</a>. Building something <em>twice</em> may, at first glance, sound like a waste of time. Folks pitching feature stores often tend to drive home that point. However, in some critical use cases, building something twice can help to validate the system’s correctness.</p>

<p>As <a href="https://twitter.com/danielchatfield">one of our Staff Engineers</a> told me, “the types of mistakes that you can make when writing SQL <em>are very different</em> from the types of mistakes you can make when writing Go.” Reimplementing a feature from SQL to Go provides us with two outputs which we can use for reconciliation: if both spit back the same number, we can be more confident the implementations are correct.</p>

<p>In short: the “only code things once” pitch doesn’t actually work for all use cases.</p>

<p>The second point, regarding discovering features for reuse across problems, is also contentious. You could imagine putting all of your features into a set of wide relational tables. At some point, centralising all of the data would come hand-in-hand with a loss of context about what that data means, and how it should be used. Once you have 1000s of features, a central list of them becomes difficult to navigate.</p>

<p>For example, if you had a feature that describes a user as <code>is_inactive</code>, what does that <em>actually</em> mean, and does that definition fit with the new use case?  How do you ensure that the feature store’s documentation for this remain lined up with the upstream system that is generating the raw data? How do you avoid ending up with multiple implementations of the same <em>concept</em>, expressed as variants of the same code, ad nauseam?</p>

<p>So the “discover all your features” is also a slightly trickier problem that “just put them all in one place.”</p>

<h2 id="-narrowing-down-the-problem-space">🔍 Narrowing down the problem space</h2>

<p>If you open up the website of your favourite company that is offering a feature store, it’s more than likely that they’ll have a list of five to ten (sometimes more!) problems that their feature store solves: integrations, data sources, consistency, monitoring, versioning, meta-data and documentation, training dataset creation, production serving, and so on.</p>

<p><em>It’s mind boggling.</em></p>

<p>Up front, I decided that I had no desire to migrate any of our existing systems to sit behind any kind of centralised “feature store” API. I didn’t want the feature store to become a replacement for things that already existed, or a behemoth that is owned by my (small) team. Instead, I learned about what we needed by looking for patterns in the machine learning models that we were shipping.</p>

<p>Specifically, we didn’t need a feature store until this year, when we ramped up how often we were designing and shipping machine learning models that were trained on tabular data (systems we built prior were very NLP-heavy).</p>

<p>When shipping tabular-based models, we kept finding that many of the features we would input into a model while training it were <em>not</em> readily available in our production infrastructure. A large part of this is because our <a href="https://cloud.google.com/customers/monzo">analytics stack</a>, where all of our Data Scientists and Analysts contribute, sits separately from our <a href="https://aws.amazon.com/solutions/case-studies/monzo/">production stack</a>.</p>

<p>Here’s a toy example: a customer’s account balance, accurate to this specific moment, is already available in production–so doesn’t need to be in a feature store. <em>But</em> aggregations on a customer’s balance (e.g., a customer’s 7-day average balance) were not, even though these numbers were already available in our <em>analytics</em>, based on SQL queries that Data Scientists had previously written.</p>

<p>We found that we already had an abundance of features in our analytics tables that, if used in production, would specifically be characterised by:</p>

<ol>
  <li>Having values that change “slowly.” These are different types of aggregations, like averages and counts, that we wanted to use, but specifically did not need them to be accurate up to the latest microsecond.</li>
  <li>Being easy to implement in BigQuery SQL, on our historical data, but would be harder (or, more simply, a lot of work) to rebuild and backfill in our production environment.</li>
</ol>

<blockquote>
  <p>Our problem, therefore, narrowed down to “we need a subset of the numbers, that only exist in our analytics, in production.”</p>
</blockquote>

<p>The first couple of times that anyone in my team ran into this, we queried BigQuery directly from our services, and cached the results. Job done. Over time, the pattern started becoming clearer: we were bound to regularly need this <em>bridge</em> between BigQuery and Cassandra, and didn’t want to rebuild it every single time.</p>

<blockquote>
  <p>This narrowed down the purpose and value-add for a building a feature store in our system: <em>enabling</em> the safe reuse of slow-changing features from our analytics, in production.</p>
</blockquote>

<h2 id="-our-analytics-feature-store">🏪 Our analytics feature store</h2>

<p>What we have today is a system that automates the journey of shipping features between our analytics (BigQuery) and production (Cassandra) databases.</p>

<p>The process starts with a Data Scientist writing some SQL, as they usually do. They tag it as a query that builds a feature table. These tables are automaticaly scheduled and generated alongside all of our other analytics tables, at varying frequencies (daily, hourly, etc.), using Airflow. We use <a href="https://www.getdbt.com/">dbt</a>, and so each query will be written with <a href="https://docs.getdbt.com/docs/building-a-dbt-project/tests/">tests</a>.</p>

<p>By design, feature tables must specificy a <code>subject_type</code> column. This defines the entity that the feature described, such as a “user” feature or a “sort code” feature. The table must also have a corresponding <code>subject_id</code>, which is the actual ID of the user for that row. The schema of this table is replicated in the feature store Go service, because we do not want it to “blindly” ingest data.</p>

<p>The creation of feature tables is monitored: a cron jobs regularly checks whether those tables should be sync’ed into Cassandra. A table should be sync’ed if:</p>
<ul>
  <li>It has been recreated (compared to the last time it was sync’ed), and;</li>
  <li>It passes data validation tests (i.e., it doesn’t accidentally have garbage in it);</li>
</ul>

<p>When a table needs to be sync’ed, it gets partitioned into batches and then exported as line-delimited JSON into …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nlathia.github.io/2020/12/Building-a-feature-store.html">https://nlathia.github.io/2020/12/Building-a-feature-store.html</a></em></p>]]>
            </description>
            <link>https://nlathia.github.io/2020/12/Building-a-feature-store.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318723</guid>
            <pubDate>Sat, 05 Dec 2020 21:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking About Decentralized Communities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318709">thread link</a>) | @SubGenius
<br/>
December 5, 2020 | https://gurlic.com/root/thinking-about-decentralized-communities | <a href="https://web.archive.org/web/*/https://gurlic.com/root/thinking-about-decentralized-communities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
          
            <p>Earlier today, I had the misfortune of reading a blog post about the dangers of the decentralized web and how we should not partake in or encourage it's development. Hacker News had a pretty <a href="https://news.ycombinator.com/item?id=25312854" rel="noopener noreferrer nofollow">active discussion</a> about the post.</p><p>Ideological takes on this always turn ugly, and I'm at a point in my life where I avoid that at all costs. I can only talk about my preferences about the world, not about how things ought to be, implying some sort of inherent value or divine moral good.</p><p>Here's what I prefer: a world where ideas, no matter how silly or dangerous, are allowed to be expressed, shared, ignored, attacked and laughed at. I don't imagine a world like this can ever exist easily, but a more decentralized web can help us get halfway there.</p><h3 id="ok-so-what-about-gurlic-then">Ok so what about Gurlic then?</h3><p><a href="https://gurlic.com/" rel="noopener noreferrer nofollow">Gurlic</a> is roughly just over two months old now, and at a point where I am relatively comfortable with the basic features it has. In the coming weeks and months, I want to focus on modifying the backend to either adopt an existing decentralized protocol, or think about how to approach writing a new one. Perhaps it would have been smarter to do this before building it first, but that would have limited how I envisioned Gurlic to be and it would've turned out differently.</p><p>Right now I'm looking into the <a href="https://www.w3.org/TR/activitypub/" rel="noopener noreferrer nofollow">activitypub</a> spec, and the <a href="https://matrix.org/docs/spec/" rel="noopener noreferrer nofollow">matrix</a> spec - here are some initial thoughts I have about how Gurlic should approach decentralization/federation.</p><ul><li><p>Decentralization can be a priority, but must never be promoted as a feature, or made to be a selling point. When decentralization becomes the main selling point of a product or service, the usability and polish tend to suffer. Not always, but nearly always. None of the marketing copy should include the words 'decentralization', 'privacy' etc. <strong>Normal users don't care about any of this</strong>.</p></li><li><p>User experience should be seamless. The user shouldn't have to generate a key, remember an extra password, remember weird URL schemes, or download utilities and clients just to be part of an online community or to write an article. Above all, the user must not be confused, as one usually is when looking at Mastodon instances, which one to sign up to, and so on. My mom should be able to use it without having to call me, just like she does with Facebook. <strong>Normal users do care about this</strong>.</p></li><li><p>The protocol must be flexible enough to allow for all of Gurlic's current features. This means communities, user profiles, publications, articles, galleries, rich media posts, sharing/responding and so on. All seamlessly without any rough edges.</p></li><li><p>Any and all cryptocurrency/blockchain must be avoided.</p></li></ul><p>I'll have more to write about this in the near future.</p>
            </section></div>]]>
            </description>
            <link>https://gurlic.com/root/thinking-about-decentralized-communities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318709</guid>
            <pubDate>Sat, 05 Dec 2020 21:45:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The cardinal rule of mental health]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318675">thread link</a>) | @euthymiclabs
<br/>
December 5, 2020 | https://feelbetterlater.com/the-cardinal-rule-of-mental-health/ | <a href="https://web.archive.org/web/*/https://feelbetterlater.com/the-cardinal-rule-of-mental-health/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>How many psychiatrists does it take to change a lightbulb?</p>



<p>It’s a dumb joke, and I’ll let you suffer through it. But first, let’s talk about relationships.</p>



<p>Every relationship is more than just two people. There is an unspoken middle ground called the <em>relationship system</em>, a constantly evolving construct defined by the interactions between two people. In other words: how I act influences you, and how you behave affects me. Relationship systems have a memory, and past events color how we see each other. A good relationship system can produce trust, shared experience, and so much more. And when people have problems with each other, it’s usually best to start looking at flaws in the relationship system before trying to find fault in either party.</p>



<p>How do you improve a relationship? You have some control over your own behaviors, a little control over the relationship system, and absolutely no control over the other person.</p>



<p>To strengthen relationships, it helps to understand what I call <em>the cardinal rule of mental health</em>: your only real option to improve any situation is to change your behavior. That doesn’t mean that everything is your fault. It’s an acknowledgment that you wait for something unexpected to happen, change your approach, or leave. But you’ll never, ever, be able to force real change in someone else. You can ask them for change, support them, antagonize them, or even cut them off. No one strategy works in every situation. And yet all reasonable options start and end with you.</p>



<p>I’m not trying to minimize the capacity for change in others. I am fundamentally optimistic about our capacity to improve, despite the very real forces of <a href="https://feelbetterlater.com/why-is-it-so-hard-to-change/">ambivalence and habit</a>. There are reasons why we do what we do, and reasons we want to do better. A good therapist digs deep to uncover motivation, but they can’t build on something that isn’t there. It’s rare outside of therapy to have the permission, skill, and safety to probe others this way. Instead, you get to decide if you can tolerate what’s happening right now.</p>



<p>That is the textbook definition of a boundary: “you can’t do this to me and expect our relationship to continue as it is.” How do you enforce a boundary? By changing your part in the relationship. You don’t have the power to do anything else.</p>



<p>How many psychiatrists does it take to change a lightbulb? How many people does it take to have a positive influence? One. But some small part of the lightbulb has to want to change itself. You don’t have to spend the rest of your life clinging to lightbulbs that refuse to budge. </p>
					</div></div>]]>
            </description>
            <link>https://feelbetterlater.com/the-cardinal-rule-of-mental-health/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318675</guid>
            <pubDate>Sat, 05 Dec 2020 21:41:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Blub Studies]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318635">thread link</a>) | @edavis
<br/>
December 5, 2020 | https://www.benkuhn.net/blub/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/blub/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Sometimes people ask me what they should learn to become a better programmer. I feel like the default recommendation here is usually an obscure programming language or a textbook on some high-powered machinery like ML. So I always feel a little bit embarrassed and boring when I instead suggest going really deep on what you already know: your main programming language, web framework, object-relational mapper, UI library, version control system, database, Unix tools, etc. It’s not shiny or esoteric, but for me, building a detailed mental model of those (and how they compare to alternatives) might be the learning that’s contributed most to my effectiveness as an engineer.</p><p>A coworker coined the phrase “blub studies” to refer to this sort of mundane, ultra-specific-seeming knowledge. “Blub” comes from a Paul Graham essay, <a href="http://www.paulgraham.com/avg.html" target="_blank">Beating the Averages</a>, in which Blub is a hypothetical middlebrow language whose programmers get defensive when Graham asserts that Lisp is superior. Blub studies is the study of what goes on in the guts of these boring, everyday systems—not the kind you get tenure for inventing, but the kind people actually use.</p><p>Blub studies is a never-ending treadmill of engineering know-how. It’s the fiddly technical details of how Git stores data, or how Postgres locking semantics <a href="https://gocardless.com/blog/zero-downtime-postgres-migrations-the-hard-parts/" target="_blank">caused your migration to bring down prod</a>, or why <code>pip install</code> failed <em>this</em> time. It’s what goes on inside the boiler rooms of your computer. There’s a seemingly infinite amount of it, full of bespoke details for you to stumble over, and that makes it, often, unbelievably frustrating. Experts in shiny fields like machine learning write shiny-sounding articles like <em><a href="https://blog.acolyer.org/2018/01/31/a-theory-of-the-learnable/" target="_blank">A theory of the learnable</a></em>; experts in blub studies emit screeds like <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">The Law of Leaky Abstractions</a> and <a href="https://www.stilldrinking.org/programming-sucks" target="_blank">Programming Sucks</a>.</p><p>In short, if you’re in search of generalizable knowledge that <a href="https://fs.blog/2019/02/compounding-knowledge/" target="_blank">compounds exponentially over time</a>, then blub studies looks like the crap you have to wade through to get to the good stuff. So it’s easy to see why people give up on understanding all the blub they’re surrounded by, except what they need to get the job done.</p><p>But for me, the opposite attitude has been more productive. <a href="https://blog.nelhage.com/post/computers-can-be-understood/" target="_blank">Computers can be understood</a>—even if it’s hard and takes a while. Blub studies is more generalizable than it seems, and has its own way of compounding over time, too. That makes it a lot more useful than you’d expect.<sup><label for="sn0">✻</label><span><span><sup>✻</sup>
Of course, there are useless parts of blub studies: if this essay gets you excited to memorize a bunch of command-line flags, consider <a href="https://slatestarcodex.com/2014/03/24/should-you-reverse-any-advice-you-hear/" target="_blank">reversing this advice</a>. But in my experience, it’s more common to neglect the useful parts of blubs, than to over-index on trivia.</span></span></sup></p><hr><p>The most straightforward benefit of blub expertise is that it saves you time. <a href="https://twitter.com/geoffreylitt/status/1305214228991750144" target="_blank">“You can’t apply those brilliant insights you learned from SICP if you don’t have the knowledge base and emotional fortitude to fight through <code>pip install</code> first."</a> If you know how Git’s internal model works, you can get your repository out of its borked state without spending hours on Stack Overflow.</p><p>This effect is larger than it might seem. If you’re working with a system you don’t understand, you’re limited to debugging via guess-and-check, which can be arbitrarily slow. A more efficient method would be to <a href="https://twitter.com/b0rk/status/1265360282513281025?lang=en" target="_blank">get as much information as possible about your program’s execution</a> and then use that information to exclude most of the hypothesis space. But this requires a good understanding of both the system, and the tools available for inspecting it. If you’re tracking down, say, a networking problem, staring at some <code>tcpdump</code> output will often get you most of the way there, but only if you know how to interpret it and what to look for.</p><p>If you spend half your programming time debugging, and being a blub expert lets you debug twice as fast, then just the speed gain from blub expertise will let you increase your output by a third.<sup><label for="sn1">†</label><span><span><sup>†</sup>
If you think “half of programming time debugging” sounds high, imagine how much faster you’d be if all your code worked the first time.<p>Doubling debugging speed is probably a conservative estimate—you can save pretty much unlimited time via things like <a href="http://rachelbythebay.com/w/2020/10/14/lag/" target="_blank">“hmm, 40 milliseconds sounds like the timeout for Nagle’s algorithm, try setting <code>TCP_NODELAY</code>”</a>. I somewhat frequently debug tricky things 5x+ faster than coworkers, just because I’ve been working with our stack for a long time, so I know where to look for problems and how to quickly test hypotheses.</p></span></span></sup> That justifies a lot of time staring at <code>tcpdump</code> output! But there are also more subtle reasons I’ve gotten so much from blub studies. It’s both more general, lasts longer, and has more of a compounding effect, than I expected.</p><hr><p>Blub studies are surprisingly broadly applicable because, even if you’re learning about the details of some specific blubby system, that system’s design will contain a juicy non-blubby core of extractible general principles. Unlike many “general principles” people try to teach you, the ones you learn via blub studies are guaranteed to be important to at least one real-world system (the one you’re learning about). And you’ll see them realized in all their messy detail, which academic presentations often leave out.</p><p>Suppose your blub of choice is React. You might worry that learning the gory details will be useless if you ever move to a different part of the stack, or even a different web framework. And, yes, some of them will. But the core idea of React—writing pure render functions, using <a href="https://reactjs.org/docs/reconciliation.html" target="_blank">reconciliation</a> to make updates fast—is extremely powerful and general. In fact, it’s now been copied by the next generation of UI frameworks on both iOS (<a href="https://developer.apple.com/xcode/swiftui/https://developer.apple.com/xcode/swiftui/" target="_blank">SwiftUI</a>) and Android (<a href="https://developer.android.com/jetpack/compose" target="_blank">Jetpack Compose</a>). Learning the principles behind React makes it easier to learn those other frameworks. In fact, it can even be a useful source of ideas to “import” from one to the other. At Wave, for instance, we’ve gotten a lot of mileage out of importing ideas from <a href="https://relay.dev/" target="_blank">Relay</a> into our mobile apps.</p><p>This is a good example of an idea that, as far as I know, you can <em>only</em> learn about through blub studies. Academia didn’t give much attention to React-style UI programming. In fact, it doesn’t seem to view user-interface programming paradigms as a particularly interesting object of study at all. People do sometimes publish on it but, for instance, I couldn’t find any courses on it in MIT’s extensive course catalog.<sup><label for="sn2">‡</label><span><span><sup>‡</sup>
You could argue that this is because UI programming is “too applied” and one shouldn’t expect it to be covered in an academic curriculum. But computer science covers many other equally-“applied” areas, like networking, databases, operating systems, and graphics.</span></span></sup></p><hr><p>Blub studies also compound more than you’d naively expect, in two ways. First, knowing about one blub makes it easier to learn about alternative blubs that serve the same purpose—like the React/SwiftUI example above. Second, knowing more about one blub helps you learn blubs in <em>adjacent</em> parts of the stack more quickly.</p><p>Once, while pair programming with a more junior coworker, we were writing a complicated SQLAlchemy query. My coworker used <code>user.name</code> (the <code>name</code> field of an object stored in the <code>user</code> variable) instead of <code>User.name</code> (the <code>name</code> field of the <em>class</em> <code>User</code>) and was wondering why her query gave the wrong results. I tried to explain the “magic” by which <code>User.name</code> was an instance of <code>Column</code> while <code>user.name</code> was a simple <code>str</code>. I went around in circles for a little while until I eventually explained Python’s <a href="https://docs.python.org/3/howto/descriptor.html" target="_blank">descriptor protocol</a> to her (the language feature SQLAlchemy uses to enable the “declarative” ORM syntax). At that point, everything clicked—and I realized that Python’s <code>__dunder__</code> methods are the key to decoding quite a lot of “magical” seeming code. If you learn the Python language features well, lots of complicated libraries will become a lot easier to understand.</p><p>I had a similar experience myself with Kubernetes. The first time I tried to learn it, it was a bewildering morass of jargon—all those namespaces and containers and Pods and Deployments and Services and Ingresses just to get a simple HTTP server running! Then I read <a href="http://intronetworks.cs.luc.edu/" target="_blank">a networking textbook</a> and everything made much more sense. The (arguably) most complicated parts of Kubernetes exist to solve networking-related problems—allowing hundreds of containers to talk to each other independently while hosted on a much smaller set of computers—so the networking textbook gave me a schema onto which I could hang all my Kubernetes factoids. Once I knew how Linux’s IP routing, iptables, and network namespaces worked, it was much easier for me to understand what exactly something like “kube-proxy” was doing.</p><p>If you know enough different blubs, you can end up at the point where you don’t even need to look things up to figure out how they’re (probably) implemented. An experienced Python programmer can guess immediately how SQLAlchemy’s “declarative” ORM works under the hood. That’s the point when your blub expertise will really start compounding—almost as soon as you start working with something new, you’ll start figuring out how it works and extracting the kernel of generally-interesting ideas.</p><hr><p>Because of this compounding effect, the most important step toward becoming a blub master is to kickstart your “blub flywheel”—the virtuous cycle of blub accumulation—however you can. That means starting with whichever blubs are the easiest or most motivating to learn, and branching out from there. For me, the easiest place to start has been with blubs I’m already using at my day job. I have a couple strategies for getting the most out of those.</p><p>First, I’ll try to <em>go deeper than necessary</em>. If I really want to ship something, it’s easy to give into temptation to, say, Google an error message, copy-paste a fix from Stack Overflow, and move on with my day. But it often doesn’t take that much longer to actually read the error message, understand what it means, and try to figure out <em>why</em> that Stack Overflow answer fixed my problem. Similarly, if I’m stuck in a tricky yak shave, I’ll bias against “guess-and-check” style …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.benkuhn.net/blub/">https://www.benkuhn.net/blub/</a></em></p>]]>
            </description>
            <link>https://www.benkuhn.net/blub/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318635</guid>
            <pubDate>Sat, 05 Dec 2020 21:37:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to List Comprehensions in Python]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318448">thread link</a>) | @janprincek
<br/>
December 5, 2020 | https://www.pythonstacks.com/blog/list-comprehensions-python/ | <a href="https://web.archive.org/web/*/https://www.pythonstacks.com/blog/list-comprehensions-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>List comprehensions are a more meaningful and efficient way to generate lists in python. A list comprehension provides a concise way to create a list using a for loop.</p>

<p>Mostly problems that are tackled with list comprehensions can also be implemented using a normal for loop, but with a list comprehension, code quantity is less and efficient.<br>
&nbsp;</p>

<h2>Generating a list with for loop</h2>

<pre><code>fruit = "apples"
newlist = []

for char in fruit:
    newlist.append(char)
    
print(newlist)             #['a', 'p', 'p', 'l', 'e', 's']</code></pre>

<p>This for loop iterates over the characters in "apples" and them to a list, newlist. But this is too much code for such a simple task, we can achieve this easily and concisely with list comprehensions.<br>
&nbsp;</p>

<h2>Generating a List with list comprehensions</h2>

<pre><code>fruit = "apples"
newlist = [char for char in fruit]
           
print(newlist)    #['a', 'p', 'p', 'l', 'e', 's']</code></pre>

<p>You can see that a list comprehension creates a list more easily and concisely than using only a for loop.<br>
&nbsp;</p>

<p><strong>Example 2</strong></p>

<p>Suppose you have a list of fruits, and you want to create a new list containing only the fruits which have an 'e' in it:</p>

<p><strong>with a for loop only, </strong></p>

<pre><code>fruits = ["apple", "banana","date", "orange", "cherry", "kiwi", "mango"]
newlist = []

for fruit in fruits:
    if "e" in fruit:
        newlist.append(fruit)
        
print(newlist)        # ['apple', 'date', 'orange', 'cherry']</code></pre>

<p>This can also be achieved in List comprehensions with the use of <strong>filters</strong>.</p>



<h2>Filtering list comprehensions</h2>

<p>Filters in list comprehensions are just conditions(if else elif) in a list comprehension.</p>

<p>The above process of creating a new list with fruits having the letter 'e' can be simplified as</p>

<pre><code>fruits = ["apple", "banana","date", "orange", "cherry", "kiwi", "mango"]

newlist = [fruit for fruit in fruits if "e" in fruit]
        
print(newlist)        # ['apple', 'date', 'orange', 'cherry']</code></pre>



<p>If you want a list of fruits that have more than 5 letters:</p>

<pre><code>newlist = [fruit for fruit in fruits if len(fruit) &gt; 5]
print(newlist)        # ['banana', 'orange', 'cherry']</code></pre>



<p>If you want a new list containing the fruits in uppercase:</p>

<pre><code>newlist = [f.upper() for f in fruits]
print(newlist)        # ['APPLE', 'BANANA', 'DATE', 'ORANGE', 'CHERRY', 'KIWI', 'MANGO']</code></pre>



<p><strong>More Examples:</strong></p>

<p>To create a new list containing the squares of numbers in another list:</p>

<pre><code>nums = [2, 3, 1, 5, 6, 4, 12, 3]

squares = [i*i for i in nums]
print(squares)                # [4, 9, 1, 25, 36, 16, 144, 9]</code></pre>

<p><strong>&nbsp;</strong><br>
To generate a list containing the squares of even numbers in another list:</p>

<pre><code>nums = [2, 3, 1, 5, 6, 4, 12, 3]

squares = [i*i for i in nums if i%2==0]
print(squares)                # [4, 36, 16, 144]</code></pre>



<h2>Functions and List comprehensions</h2>

<p>With list comprehensions,<span> you can generate a list from the values returned from a function</span>. Let's take a look at a function that takes in a person's name and returns it in uppercase with a greeting:</p>

<pre><code>def greet(name):
    greeting = "Hello " + name.upper()
    return greeting

people = ["John", "Doe", "Prince", "Abdul", "Isaac"]

greet_everyone = [greet(p) for p in people]

print(greet_everyone)</code></pre>

<p><strong>output</strong></p>

<pre><code>['Hello JOHN', 'Hello DOE', 'Hello PRINCE', 'Hello ABDUL', 'Hello ISAAC']</code></pre>




        </div></div>]]>
            </description>
            <link>https://www.pythonstacks.com/blog/list-comprehensions-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318448</guid>
            <pubDate>Sat, 05 Dec 2020 21:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Time I Built a Crack for Nearly All Shareware]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318373">thread link</a>) | @codazoda
<br/>
December 5, 2020 | https://joeldare.com/that-time-i-built-a-crack-for-nearly-all-shareware | <a href="https://web.archive.org/web/*/https://joeldare.com/that-time-i-built-a-crack-for-nearly-all-shareware">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p>It was in the ’90s and shareware was still cool. I had written a couple of small shareware programs and I was worried about bugs related to dates and times.</p>

<p>So I wrote a new program called DateDesist.</p>

<p>DateDesist allowed me to test how my program would behave on specific dates. It was a fairly simple command line program. What it did was change the date on the machine, execute the program to be tested, wait a few seconds, then restore the date and exit.</p>

<p>It worked incredibly well for testing date-based shareware and making sure that programs expired when they were intended to.</p>

<p>I found it useful for my own testing and wanted to release it for other developers. So I package it up and released it on a bunch of shareware sites such as Tucows, SoftSeek and Freeware Home.</p>

<p>Sometime later I went looking for a <em>crack</em> for a piece of software that I was having trouble getting. I pulled up HotBot (my preferred search engine at the time) and quickly found what I was looking for. I downloaded the archive and took a look at the files inside.</p>

<p>There, I found the typical readme file with a short description of the program it was intended to crack and some ASCII art with the name of the cracking crew. Also included was a copy of my original DateDesist executable and a batch file to launch the target program on a specific date.</p>

<p>Now curious, I searched the web again for other cracks made by the same crew. To my surprise DateDesist had been used in dozens, maybe hundreds, of different cracks that were released by this group. I checked other cracks from other groups on the same sites and found DateDesist used in a significant number of them.</p>

<p><em>Written by Joel Dare on December 5th, 2020</em></p>


      
    </div></div>]]>
            </description>
            <link>https://joeldare.com/that-time-i-built-a-crack-for-nearly-all-shareware</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318373</guid>
            <pubDate>Sat, 05 Dec 2020 21:08:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study on IQs of video gamers finds women outscore men, Android outscores iOS]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25318247">thread link</a>) | @Bologo
<br/>
December 5, 2020 | https://www.psychnewsdaily.com/study-on-iq-scores-of-video-gamers-finds-women-outscore-men-android-beats-iphone/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/study-on-iq-scores-of-video-gamers-finds-women-outscore-men-android-beats-iphone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5423" role="main"><div><div><div><p>A new (and non peer-reviewed) <a href="https://www.royalpanda.com/ca/most-intelligent-gamers/" target="_blank" rel="noreferrer noopener">study conducted by online gambling company Royal Panda</a> compared the IQ scores of video gamers on number of categories.<span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The company had a team of psychologists administer an online IQ test to a sample of 1,001 gamers. The results will doubtless infuriate some, and assuage others.</p><h2>IQ scores by gaming system: PC vs. PlayStation vs. Xbox vs. Nintendo vs. “mobile”</h2><p>Their study revealed that PC gamers had the highest IQ scores among the gaming platforms tested, with an average IQ of 112.3. Next came users of the <a href="https://amzn.to/33P8Msn" target="_blank" rel="noreferrer noopener sponsored nofollow">PlayStation</a>, whose average IQ was 110.7. Xbox users took third place with an average IQ of 103.8, followed by Nintendo Switch users with 101.3. In fifth and last place was the vague category of “mobile gamers,” who averaged 99.4 on the IQ test.</p><p>The test was broken down into four categories: verbal intelligence, mathematical ability, logical reasoning, and visual reasoning. PC gamers took the top spots in verbal intelligence and mathematical ability, while PlayStation users won in logical reasoning and visual reasoning. <a href="https://amzn.to/3ghd9BK" target="_blank" rel="noreferrer noopener sponsored nofollow">Xbox users</a> took third place in all four categories, and pulling up the rear, again, were the Nintendo Switch users and “mobile gamers.”</p><h2>IQ scores by choice of game: Rainbow Six Siege takes first place</h2><p>The survey also ranked 15 popular games by their users’ IQ scores. The winning game was T<em>om Clancy’s Rainbow Six Siege</em> — its players had an average IQ score of 120.3. They were followed close behind by players of <em>Among Us </em>(IQ of 118.9) and <em>Minecraft </em>(116.3). In last pace were <em>Sage Candy Crush</em> (IQ of 96.4) and <em>Angry Birds</em> (95.8).<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>In between, in descending order, were: <em>Call of Duty: Modern Warfare </em>(average IQ of 111.2), <em>EA Sports FIFA </em>(106.5), <em>Fall Guys: Ultimate Knockout </em>(105.8), <em>Animal Crossing </em>(104.8), <em>Fortnite </em>(103.6), <em>Mariokart </em>(99.9), <em>Grand Theft Auto </em>(99.6), <em>Assassin’s Creed </em>(99.6), and <em>Rocket League </em>(99.3).</p><h2>Ranking IQ by operating system</h2><p>The study also found that Android gamers have higher IQs than iOS (iPhone and iPad) gamers. The average IQ score among study participants whose main mobile device runs on Android was 110.3, and the IQ score for iOS users was a mere 102.1.</p><p>On the other hand, the study also found that gamers who use Apple Mac computers had slightly higher IQ scores than Windows users (108.2 vs 106.7). One explanation for this finding is that there are many more Windows users than Mac users. In fact, the survey included six times more Windows users than Mac users.&nbsp; And that larger sample of Windows users might just be more accurately reflecting the great variety in IQ scores in general.</p><h2>Female gamers smarter than male gamers</h2><p>In addition, the study also revealed that female gamers had substantially higher IQ scores than male gamers. The average IQ of the female gamers was 108.4, versus the male average of 102.3. The female participants also got higher average scores on each of the four sub-scales: verbal intelligence, mathematical ability, logical reasoning, and visual reasoning.<span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>The study does not indicate the ratio of male to female participants who took part in the research. Likewise, it omits lots of other key demographic information that you would expect such a study to include. For example, the study says nothing about the location, age, or education levels of its participants.</p><p>Nonetheless, despite its rather non-scientific nature (no peer review, no mention of the study’s authors or affiliations, no demographic information on the participants), this study is still an interesting look at some of the putative differences in intelligence between various groups of gamers.</p><p>In fact, <a href="https://scholar.google.com/scholar?hl=nl&amp;as_sdt=0%2C5&amp;q=video+games+and+intelligence&amp;btnG=" target="_blank" rel="noreferrer noopener">the links between video games and intelligence</a> have become a topic of increasing popularity in academic research over the past few years. Perhaps other researchers will use this Royal Panda study as an impetus to conduct more serious research into this subject.</p><p>Click <a href="https://www.psychnewsdaily.com/category/iq/" target="_blank" rel="noreferrer noopener">here to read more about the latest news on IQ research</a>.</p><hr><p><strong>Photo credit:</strong> <a href="https://www.lyncconf.com/" target="_blank" rel="noreferrer noopener">Lyncconf.com</a>, via <a href="https://www.flickr.com/photos/nodstrum/29447967578/in/album-72157669048309687/" target="_blank" rel="noreferrer noopener">Flickr</a>; license: <a href="https://creativecommons.org/licenses/by/2.0/legalcode" target="_blank" rel="noreferrer noopener">CC BY 2.0</a></p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/study-on-iq-scores-of-video-gamers-finds-women-outscore-men-android-beats-iphone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318247</guid>
            <pubDate>Sat, 05 Dec 2020 20:54:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Azure Functions vs. Firebase Functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317734">thread link</a>) | @Osinachi
<br/>
December 5, 2020 | https://osi.codes/azure-functions-vs-firebase-functions | <a href="https://web.archive.org/web/*/https://osi.codes/azure-functions-vs-firebase-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1607198016695/_hCQg6ISd.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>This article is part of <a target="_blank" href="https://aka.ms/ServerlessSeptember2020">#ServerlessSeptember</a>. You'll find other helpful articles, detailed tutorials, and videos in this all-things-Serverless content collection. New articles from community members and cloud advocates are published every week from Monday to Thursday through September. </p>
<p>Find out more about how Microsoft Azure enables your Serverless functions at <a target="_blank" href="https://docs.microsoft.com/azure/azure-functions/?WT.mc_id=servsept20-devto-cxaall">https://docs.microsoft.com/azure/azure-functions/</a></p>
<h2 id="introduction">Introduction</h2>
<p>Serverless functions are microservices which run on preconfigured servers that scale according to demand. Serverless functions are used to perform tasks such as running chatbots and database sanitization.</p>
<p>Azure and Firebase both offer serverless functions as part of their cloud offering. Firebase functions can be seen as part of Google Cloud Platform (GCP). I tested the code on this article directly on GCP. You should obtain the same results if you go through Firebase. We would compare the speed, ease of development and ease of deployment of serverless functions than run on Azure and Google Cloud.</p>
<h2 id="computation-speed">Computation Speed</h2>
<p>When comparing the execution speed, we must note that one machine running the function may be closer to us than the other. We must also note that different machines are used to execute the function. Therefore, we would run the function several times, then calculate the percentage range of their results.</p>
<p>We would use this long-running task function in both scripts</p>
<pre><code><span><span>function</span> <span>longRunningTask</span>(<span></span>) </span>{
  <span>return</span> <span>new</span> <span>Promise</span>(<span>(<span>resolve, reject</span>) =&gt;</span> {
    <span>const</span> start = <span>new</span> <span>Date</span>();

    <span>let</span> a = <span>0</span>;
    <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; <span>90000000</span>; i++) {
      a += i;
    }

    <span>const</span> end = <span>new</span> <span>Date</span>() - start;
    resolve(end / <span>1000</span>);
  });
}
</code></pre>
<h3 id="serverless-function-on-google-cloud">Serverless function on Google Cloud</h3>
<p>Here's the function that will execute on gcloud.</p>
<pre><code>{Add longRunningTask <span><span>function</span> <span>here</span>}

<span>exports</span>.<span>longRunningFunction</span> = <span>async</span> (<span>req, res</span>) =&gt; </span>{

  <span>return</span> <span>new</span> <span>Promise</span>(<span>(<span>resolve</span>) =&gt;</span> {
    <span>const</span> loopCount = req.query.loopCount || <span>10</span>
    <span>const</span> runTimes = [];

    <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; loopCount; i++) {
      longRunningTask()
        .then(<span>(<span>data</span>) =&gt;</span> {
          runTimes.push(data);
        })
        .catch(<span>(<span>error</span>) =&gt;</span> {
          <span>console</span>.error(error);
        });
    }

    resolve(runTimes)
  }).then(<span>(<span>data</span>) =&gt;</span> {
    res.status(<span>200</span>).send(data);
  })
};
</code></pre>
<p>Ensure you set your entry point as <code>longRunningFunction</code></p>
<h3 id="serverless-function-on-azure">Serverless function on Azure</h3>
<p>Below is the function that will execute on Azure</p>
<pre><code>{Add longRunningTask <span><span>function</span> <span>here</span>}

<span>module</span>.<span>exports</span> = <span>async</span> <span>function</span> (<span>context, req</span>) </span>{
  <span>const</span> runTimes = [];

  <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; <span>10</span>; i++) {
    longRunningTask()
      .then(<span>(<span>data</span>) =&gt;</span> {
        runTimes.push(data);
      })
      .catch(<span>(<span>error</span>) =&gt;</span> {
        <span>console</span>.error(error);
      });
  }

  context.res = {
    <span>body</span>: runTimes,
  };
};
</code></pre>
<h3 id="results">Results</h3>
<p>Running these functions and testing their results on <a target="_blank" href="https://repl.it/@Vicradon/relative-range#index.js">this repl</a> gives this result</p>
<pre><code><span>Azure</span>
<span>Min:</span> <span>0.278</span>
<span>Max:</span> <span>0.672</span>
<span>Percentage Range:</span> <span>108</span><span>%</span>
<span>GCloud</span>
<span>Min:</span> <span>0.619</span>
<span>Max:</span> <span>0.705</span>
<span>Percentage Range:</span> <span>12</span><span>%</span>
</code></pre><p>From the result, we can conclude that azure runs the function faster than google cloud.</p>
<p>Status
Azure: 1
GCloud: 0</p>
<h2 id="ease-of-development">Ease of development</h2>
<p>In this section, we compare how easy it is to write, test and debug functions on the two platforms. Azure offers an intuitive interface for editing and testing functions.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/w0unsgnvqtvpzq5of6vz.png" alt="Azure function development interace"></p>
<p>GCloud's interface doesn't allow for immediate testing. You must redeploy a function after edits are made.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/x4xwpgq3wzmpnorg8b6n.png" alt="Google cloud functions edit interface"></p>
<p>Status:
Azure: 2,
GCloud: 0</p>
<h2 id="ease-of-deployment">Ease of deployment</h2>
<p>Deploying functions on these platforms depends on your deployment pipeline. If we solely compare deployment using the dashboard, we can conclude that they are both intuitive. So we have a tie.</p>
<p>Status:
Azure: 3,
GCloud: 1</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this article, we made an attempt to compare the speed, development and deployment of serverless functions on Google Cloud and Azure. Using the metrics above, we can conclude that working with serverless functions on Azure gives you a better experience than Google Cloud. This isn't the absolute conclusion. We didn't consider a whole lot of metrics. But this can be a start. Thank you for reading. ✌🏽🧡</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://osi.codes/azure-functions-vs-firebase-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317734</guid>
            <pubDate>Sat, 05 Dec 2020 19:56:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prevent reverse tabnabbing phishing attack with noopener, noreferrer attributes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317619">thread link</a>) | @bhanuteja_p
<br/>
December 5, 2020 | https://blog.bhanuteja.dev/noopener-noreferrer-and-nofollow-when-to-use-them-how-can-these-prevent-phishing-attacks | <a href="https://web.archive.org/web/*/https://blog.bhanuteja.dev/noopener-noreferrer-and-nofollow-when-to-use-them-how-can-these-prevent-phishing-attacks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Now and then, when you click on a link on a website, the link will be opened in a new tab, but the old tab will also be redirected to some other phishing website where it asks you to login or starts downloading some malware to your device. In this blog post, I will explain how something like this is achieved, and how to easily prevent this from happening in your own websites. </p>
<p>We see values like <code>noopener</code>, <code>noreferrer</code> and <code>nofollow</code> attached to <code>rel</code> attribute of <code>anchor</code>(<code>&lt;a&gt;</code>) tags. We usually see these values along with <code>target=_blank</code>. Many of us do not know what each of the value means, and what happens when we set or do not set any of the values. In this blog post, I will explain what these values mean, and also explain what set of values to use for anchor tags in your website.</p>
<p>Before diving into the post, let's see what security implications will be there when you set <code>target="_blank"</code> on an anchor tag in your website.</p>
<pre><code><span>&lt;<span>a</span> <span>href</span>=<span>"https://google.com"</span> <span>target</span>=<span>"_blank"</span>&gt;</span>Google<span>&lt;/<span>a</span>&gt;</span>
</code></pre>
<p>When you create a hyperlink in the above way on your website with no <code>rel</code> attribute, clicking on it will open <a href="http://google.com/" target="_blank">google.com</a> in a new tab. But there are some security risks in doing so. There is a property called <code>window.opener</code> which is set to the window of the opening tab, in this case, your website. </p>
<p>Let's see more of what I mean here in detail below.</p>
<p>For example, let's say you have a link in <a href="https://hashnode.com/@hashnode">Hashnode</a> with the target set to <code>_blank</code>, but no <code>rel</code> attribute, then <code>window.opener</code> property in the opened tab(new tab) is automatically set to the window of the opening tab(<code>Hashnode</code> tab). </p>
<p>Phishing attacks are often carried out in this way. Since the new tab has now access to the window of the previous tab, the new tab can set the location of the old tab using <code>window.opener.location.href = 'link-of-some-fake-site-that-looks-almost-same-as-original-site'</code>, and a login page can be shown in that fake site saying "<strong>You have been logged out, please reenter your login credentials to login</strong>". Then if the user doesn't check that the domain name has changed and enters the login credentials, the attacker will now have access to the user's login details to <strong>Hashnode</strong> site. The fake site may also make you download malware on to your device. <strong>See the code in below section if you do not yet understand properly of what I mean.</strong></p>
<p>This popular attack which a lot of websites are a victim to is called <code>Reverse Tabnabbing</code>.</p>
<p>So, what is the solution to this? The solution is very simple. You just have to set the <code>rel</code> attribute of your <code>anchor</code> tag to <code>noopener</code> whenever there is <code>target="_blank"</code> set. What this means is simple, when you click on the link, it opens the page in a new tab, and also <code>window.opener</code> value in the new tab is set to <code>null</code>. Now, the new link has no access to the tab that this new link is opened from.</p>
<p>Let's see in detail what each of the values mean and also see what values you should use in your website.</p>
<h3 id="noopener">noopener</h3>
<p>When you set this value along with <code>target=_blank</code>, you are instructing the browser to open the link in a new tab, but do not give access to the page that opened it(<code>window.opener = null</code> in new tab).</p>
<p>I don't see any use-case where you would ever want to give access to the <code>window</code> of your website to some other external website. So it is always best to have <code>noopener</code> value in the <code>rel</code> attribute of your anchor tag, whenever you set the <code>target</code> to <code>_blank</code>.</p>
<pre><code>
<span>&lt;<span>a</span> <span>href</span>=<span>"some-external-link"</span> <span>target</span>=<span>"_blank"</span>&gt;</span>Some External Website<span>&lt;/<span>a</span>&gt;</span>
</code></pre>
<pre><code>
<span>&lt;<span>script</span>&gt;</span><span>

<span>window</span>.opener.location.href = <span>'link-to-some-phising-website-that-looks-almost-same-as-your-own-website'</span>
</span><span>&lt;/<span>script</span>&gt;</span>
</code></pre>
<p>To prevent the above attack, you just have to add <code>rel=noopener</code> to your link.</p>
<pre><code><span>&lt;<span>a</span> <span>href</span>=<span>"some-external-link"</span> <span>rel</span>=<span>"noopener"</span> <span>target</span>=<span>"_blank"</span>&gt;</span>Some External Website<span>&lt;/<span>a</span>&gt;</span>
</code></pre>
<pre><code>
<span>&lt;<span>script</span>&gt;</span><span>

<span>window</span>.opener.location.href = <span>'link-to-some-phising-website-that-looks-almost-same-as-your-own-website'</span>

</span><span>&lt;/<span>script</span>&gt;</span>
</code></pre>
<h3 id="noreferrer">noreferrer</h3>
<p><code>noreferrer</code> is very much similar to its function as <code>nopener</code>. This also prevents the newly opened site to manipulate the window of the opening tab.(<code>window.opener</code> will be set to <code>null</code>). The extra thing that <code>noreferrer</code> will have in addition to <code>noopener</code> is that it will hide the referrer information when the link is clicked. For example, if you have a link to your website with <code>noreferrer</code> and <code>target="_blank"</code>, then when the user clicks on that link, they will be taken to your website, but your website will not have access to where the users coming from. Your analytics software like <code>Google Analytics</code> will consider these users as direct traffic and not as a referral. </p>
<p>Based on this explanation, I hope you have a clear idea of what <code>noreferrer</code> means and when to use it and when not to use it. If you don't want to pass on any referrer information to the external links, then consider using <code>noreferrer</code> value, otherwise do not use it. </p>
<p>You will often see the anchor tags with both <code>noopener noreferrer</code>. Since <code>noreferrer</code> also does what <code>noopener</code> is doing, why to have <code>noopener</code> along with <code>noreferrer</code>. This is mainly to support old browsers. Some of the old browsers do not support <code>noopener</code> value, so whenever you want to use <code>noopener</code>, you also see people using <code>noreferrer</code> value along with it.</p>
<pre><code>
<span>&lt;<span>a</span> <span>href</span>=<span>"some-external-link"</span> <span>rel</span>=<span>"noopener noreferrer"</span> <span>target</span>=<span>"_blank"</span>&gt;</span>Some External Website<span>&lt;/<span>a</span>&gt;</span>
</code></pre>
<h3 id="nofollow">nofollow</h3>
<p>To have good SEO on your website, it is crucial to have backlinks to your website. All links are not equal in value. Some will be valued more than others. Search engines use something called <code>Page Ranking</code> algorithm to determine the value of a link or website. When you link another website from your website, you are endorsing that other page, so the value of other page will be increased in proportion to what value your website has. Similarly, the value of your website is determined by the backlinks that are pointed to your website, and again all the values of all the backlinks are not the same. I will talk more about Google's Page Ranking algorithm, and in detail in some other blog post. Let's just get back to what setting <code>rel=nofollow</code> value to your link means.</p>
<p>When you set <code>nofollow</code> to a link in your website, you are telling Google that you are not endorsing the link and also telling it not to pass the page rank value of your website to it. </p>
<p>You will typically use <code>nofollow</code> when linking to internal pages or when you are linking to a less valuable site from your more valuable site.</p>
<p>Google recently introduced some other values like <code>rel=sponsored</code>, <code>rel=ugc</code> etc, which are out of scope for this blog post. </p>
<pre><code>
<span>&lt;<span>a</span> <span>href</span>=<span>"some-external-link"</span> <span>rel</span>=<span>"nofollow"</span> <span>target</span>=<span>"_blank"</span>&gt;</span>Some External Website<span>&lt;/<span>a</span>&gt;</span>
</code></pre>
<p><strong>Note:</strong></p>
<blockquote>
<p>You can even set the three values to <code>rel</code> attribute.</p>
<pre><code><span>&lt;<span>a</span> <span>href</span>=<span>"some-external-link"</span> <span>rel</span>=<span>"noopener noreferrer nofollow"</span> <span>target</span>=<span>"_blank"</span>&gt;</span>Some External
</code></pre>
</blockquote>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>You can(and probably should) use rel="noopener" on all links that have <code>target="_blank"</code>.</li>
<li>rel="noreferrer" does the same thing as <code>noopener</code> especially in older browsers which do not support <code>noopener</code>. In addition to it, setting rel="noreferrer" will affect analytics of the external website.</li>
<li>You should use rel="nofollow" when you don't want to endorse links on your websites. This affects the SEO of the external website.</li>
</ul>
<blockquote>
<p>If you have any feedback or suggestions to improve this blog post, please leave them in the comments. I will try to improve the post accordingly. </p>
<p>If this blog post was helpful to you, please consider liking it and sharing it so that it reaches more people. </p>
<p>If you want to get notified via email as soon as I write a new blog post, you can click on <strong>Subscribe</strong> button at the top of this page. You can also follow me here at <a href="https://hashnode.com/@pbteja1998">Bhanu Teja P</a> or on twitter at <a target="_blank" href="https://twitter.com/pbteja1998">@pbteja1998</a> to get updated.</p>
</blockquote>
<p><strong>Links and References:</strong></p>
<ul>
<li><a target="_blank" href="https://owasp.org/www-community/attacks/Reverse_Tabnabbing">Reverse Tabnabbing Attack</a></li>
<li><a target="_blank" href="https://html.spec.whatwg.org/multipage/links.html#link-type-nofollow">HTML Spec</a></li>
<li><a target="_blank" href="https://pointjupiter.com/what-noopener-noreferrer-nofollow-explained/">Explained: noopener, noreferrer, and nofollow Values</a></li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.bhanuteja.dev/noopener-noreferrer-and-nofollow-when-to-use-them-how-can-these-prevent-phishing-attacks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317619</guid>
            <pubDate>Sat, 05 Dec 2020 19:40:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Erlang Releases Without EPMD on OTP 23.1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317576">thread link</a>) | @todsacerdoti
<br/>
December 5, 2020 | https://blog.erlware.org/epmdlessless/ | <a href="https://web.archive.org/web/*/https://blog.erlware.org/epmdlessless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
        <p>Erlang/OTP deployments that want to provide shell access or cluster nodes relied
on something called the Erlang Port Mapper Daemon (EPMD), a separate process
that handled all distribution mechanisms. Previous attempts at working around
this requirement used third party dependencies such as
<a href="https://github.com/tsloughter/epmdless">epmdless</a> and required specific
configuration arguments to the VM to setup. This was not ideal and was easy to
get wrong.</p>
<p>With <a href="https://www.erlang.org/news/141">Erlang/OTP 23.1</a> and <a href="https://github.com/erlware/relx/releases/tag/v4.2.0">relx 4.2</a> (included in <a href="https://blog.erlware.org/epmdlessless/">Rebar3 3.14.3</a>) it is now possible
to conveniently run Erlang releases without relying on EPMD for opening a
remote shell or clustering nodes. This is particularly going to make Erlang releases
simpler to configure in locked down environments, and easier to use with containers.</p>
<p>EPMD is a separate process that is started, if
not already running, when an Erlang node boots with distribution enabled –
meaning <code>-sname</code> or <code>-name</code> is passed to the boot command. The new node <a href="http://erlang.org/doc/apps/erts/erl_dist_protocol.html#epmd-protocol">talks to
the EPMD process</a> to register its name with a port that the node will also bind
to. When a node wants to connect to another one it must look up the port the other
node is listening on through EPMD. This is required both for
clustering nodes together and connecting a remote shell on the command line –
which is essentially the same as clustering because a new node is started before
attaching to the remote node to bring up a shell on that node.</p>
<p>Bypassing EPMD has been made possible through a couple new options added to <code>erl</code>:</p>
<ul>
<li><a href="https://github.com/erlang/otp/commit/c21bbb6136a1f4d343c3cf53476107e78221a68f"><code>-erl_epmd_port P</code></a>: Configures the port this node will listen on and use when
connecting to remote nodes.</li>
<li><a href="https://github.com/erlang/otp/commit/7a7c90be0e87cb3b4920de5aaf215c4b9cebcb30"><code>-dist_listen false</code></a>:
Setting this keeps the node from binding to the port, preventing it from
acting as a server, and instead uses the port only for connecting to remote
nodes. The use case for this is when opening a remote shell <code>-remsh &lt;node&gt;</code>
(<code>remote_console</code> in the release script) to a local node.</li>
<li><a href="https://github.com/erlang/otp/commit/61b1ad3c57f4e92fb9b55f97b9ffd9dee80067e2"><code>-[s]name undefined</code></a>:
Passing <code>undefined</code> for the short or long name of a node generates a unique node
name and sets additional flags, <code>-dist_listen false -hidden -dist_auto_connect never</code>.</li>
</ul>
<p>An extra option has also been added to <a href="http://erlang.org/doc/man/erl_call.html"><code>erl_call</code></a> :</p>
<ul>
<li><a href="https://github.com/erlang/otp/commit/ce4fcf0640d81a268c15af339a888406b757ced5"><code>-address P</code></a>:
Sets the address and/or port to connect to the running Erlang node. This
removes the need to look up the remote node or to even specify its name when
running <code>erl_call</code>.</li>
<li><a href="https://github.com/erlang/otp/commit/3a57ed212befae5d0e03569408849e8a72122911"><code>-R</code></a>: Tells <code>erl_call</code> to use a dynamic random name for the hidden node it starts.</li>
</ul>
<p>As of OTP 23.1+ the <code>relx</code> generated release script uses <code>erl_call</code> instead of
the custom <code>escript</code> <code>nodetool</code> when the commands <code>rpc</code> and <code>eval</code> are used to
run code on a running node.</p>
<p>These options are used automatically by the release shell script when starting a
node, opening a remote shell or interacting with the running node through <code>rpc</code>
and <code>eval</code>. The only change you as a user must make to run your release without
<code>epmd</code> is to set the OS environment variable <code>ERL_DIST_PORT</code>.</p>
<p>When <code>ERL_DIST_PORT</code> is set in the environment the option to not start EPMD
(<code>-start_epmd false</code>) is added to the <code>erl</code> arguments automatically, along with
<code>-erl_epmd_port ${ERL_DIST_PORT}</code>. The <code>ERL_DIST_PORT</code> is also used by
<code>erl_call</code> with <code>-address ${ERL_DIST_PORT}</code>.</p>
<p><a href="https://github.com/tsloughter/epmdlessless">epmdlessless</a> is an example project
that comes with a
<a href="https://github.com/tsloughter/epmdlessless/blob/main/docker-compose.yml">docker-compose.yml</a>
setup that makes it simple to play with these new features. Note that no changes are
required to <code>vm.args.src</code> to disable EPMD or set a port to use, the only
configuration done is through the environment variable <code>ERL_DIST_PORT</code> in
<code>docker-compose.yml</code>:</p>
<pre><code>    ...
    environment:
      - ERL_DIST_PORT=8001
    ...
</code></pre><p>Note that each node must listen on the same port because setting
<code>-erl_epmd_port P</code> tells Erlang both what port to listen on and what port to use
when connecting to other nodes.</p>
<p>After cloning the repo, build the Docker image and start 3 nodes (<code>node_a</code>, <code>node_b</code>, <code>node_c</code>):</p>
<pre><code>$ docker-compose up
</code></pre><p>Then, use <code>docker exec</code> to open a remote shell on <code>node_a</code> and connect to
<code>node_b</code> (be sure to disconnect from the remote shell with <code>Ctrl-g</code> followed by
<code>q</code>, if you use <code>q().</code> it will shutdown the remote node):</p>
<pre><code>$ docker exec -ti node_a bin/epmdlessless remote_console
Erlang/OTP 23 [erts-11.1.3] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]

Eshell V11.1.3  (abort with ^G)
(<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="d9bca9b4bdb5bcaaaab5bcaaaa99b7b6bdbc">[email&nbsp;protected]</a>_a)1&gt; net_kernel:connect_node(<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="afcadfc2cbc3cadcdcc3cadcdcefc1c0cbca">[email&nbsp;protected]</a>_b).
true
(<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="91f4e1fcf5fdf4e2e2fdf4e2e2d1fffef5f4">[email&nbsp;protected]</a>_a)2&gt; erlang:nodes().
[<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="e88d98858c848d9b9b848d9b9ba886878c8d">[email&nbsp;protected]</a>_b]
(<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="92f7e2fff6fef7e1e1fef7e1e1d2fcfdf6f7">[email&nbsp;protected]</a>_a)3&gt; 
User switch command
 --&gt; q
</code></pre><p>Do the same on <code>node_c</code> and also connect to <code>node_b</code> and you’ll see the full
mesh is created with <code>node_a</code>:</p>
<pre><code>$ docker exec -ti node_c bin/epmdlessless remote_console
Erlang/OTP 23 [erts-11.1.3] [source] [64-bit] [smp:8:8] [ds:8:8:10] [async-threads:1] [hipe]

Eshell V11.1.3  (abort with ^G)
(<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="4124312c252d2432322d243232012f2e2524">[email&nbsp;protected]</a>_c)1&gt; net_kernel:connect_node(<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="bdd8cdd0d9d1d8ceced1d8cecefdd3d2d9d8">[email&nbsp;protected]</a>_b).
true
(<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="1c796c717870796f6f70796f6f5c72737879">[email&nbsp;protected]</a>_c)2&gt; erlang:nodes().
[<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="7114011c151d1402021d140202311f1e1514">[email&nbsp;protected]</a>_b,<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="cca9bca1a8a0a9bfbfa0a9bfbf8ca2a3a8a9">[email&nbsp;protected]</a>_a]
(<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="f4918499909891878798918787b49a9b9091">[email&nbsp;protected]</a>_c)3&gt; 
User switch command
 --&gt; q
</code></pre><p>Test the <code>rpc</code> command by running <code>erlang:nodes()</code> on <code>node_b</code>:</p>
<pre><code>$ docker exec -ti node_b bin/epmdlessless rpc erlang nodes
[<a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="0c697c616860697f7f60697f7f4c62636869">[email&nbsp;protected]</a>_a, <a href="https://blog.erlware.org/cdn-cgi/l/email-protection" data-cfemail="7d180d101911180e0e11180e0e3d13121918">[email&nbsp;protected]</a>_c]
</code></pre><p>Lastly, you can verify that none of the commands caused EPMD to be run:</p>
<pre><code>$ docker exec -ti node_b erts-11.1.3/bin/epmd -names
epmd: Cannot connect to local epmd
</code></pre><h2 id="separate-ports-where-epmdless-is-still-needed">Separate Ports: Where epmdless is Still Needed</h2>
<p>It is important to note that this requires every node to listen on the same
port, which requires every node to have its own IP. If this isn’t an option, or
for whatever reason you need to use separate ports for nodes, then <a href="https://github.com/tsloughter/epmdless">epmdless</a>
is an option to replace EPMD and track the node to port mapping. But if you are
running with containers in an environment like Kubernetes you can now keep EPMD
from running in each container by simply upgrading Erlang and Rebar3, and
setting the <code>ERL_DIST_PORT</code> environment variable.</p>
    
        </div>
    </section></div>]]>
            </description>
            <link>https://blog.erlware.org/epmdlessless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317576</guid>
            <pubDate>Sat, 05 Dec 2020 19:34:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Descartes' God has failed and Thompson's Satan rules our computers]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317557">thread link</a>) | @jrepinc
<br/>
December 5, 2020 | https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1658">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
tpms, crypto wars, monopolism, computer science, trickbot, uefi, trickboot, trusted computing, palladium, ken thompson, rene descartes, infosec, malware, apts, seth david schoen, peter biddle, ngscb

Summary:
Descartes' God has failed and Thompson's Satan rules our computers

URL:
https://pluralistic.net/2020/12/05/trusting-trust/

Title:
Pluralistic: 05 Dec 2020 trusting-trust

Bullet:
👒

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://www.nakedcapitalism.com/).

--><br>
<a href="https://pluralistic.net/2020/12/05/trusting-trust/"><img src="https://i2.wp.com/craphound.com/images/05Dec2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/05Dec2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">Descartes' God has failed and Thompson's Satan rules our computers</a>: Computers, trust, and the knowability of the universe.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#retro">This day in history</a>: 2005, 2010, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="thompsons-devil"></a><br>
<img src="https://i1.wp.com/craphound.com/images/NGSCBWHEC03.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/NGSCBWHEC03.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Security researchers are alarmed: the already-notorious Trickbot malware has been spotted probing infected computers to find out which version of UEFI they're running. This is read as evidence that Trickbot has figured out how to pull off a really scary feat.</p>
<p>To understand why, you have to understand UEFI: a fascinating, deep, philosophical change to our view of computers, trust, and the knowability of the universe. It's a tale of hard choices, paternalism, and the race to secure the digital realm as it merges with the physical.</p>
<p>Computers were once standalone: a central processing unit that might be augmented by some co-processors for specialized processes, like a graphics card or even a math co-processor.</p>
<p>These co-pros were subordinate to the CPU though. You'd turn on the computer and it would read a very small set of hardcoded instructions telling it how to access a floppy disk or other storage medium for the rest of the boot sequence, the stuff needed to boot the system.</p>
<p>The hardwired instructions were in a ROM that had one job: wake up and feed some instructions to the "computer" telling it what to do, then go back to sleep. But there's a philosophical conundrum here.</p>
<p>Because the world of computing is adversarial and networked computing is doubly so: there are people who want your computer to do things that are antithetical to your interests, like steal your data or spy on you or encrypt all your files and demand ransom.</p>
<p>To stop this, you need to be able to examine the programs running on your computer and terminate the malicious ones. And therein lies the rub: when you instruct your computer to examine its own workings, how do you know if you can trust it?</p>
<p>In 1983, Ken Thompson (co-creator of C, Unix, etc) was awarded a Turing Award ("computer science's Nobel Prize"). He gave a fucking bombshell of an acceptance speech, called "Reflections on Trusting Trust."</p>
<p><a href="https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf">https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf</a></p>
<p>Thompson revealed that he had created a backdoor for himself that didn't just live in Unix, but in the C compiler that people made to create new Unix systems.</p>
<p>Here's what that means: when you write a program, you produce "high-level code" with instructions like "printf("Hello, World!");". Once your program is done, you turn it into machine code, a series of much shorter instructions that your CPU understands ("mov  dx, msg" etc).</p>
<p>Most programmers can't read this machine code, and even for those who can, it's a hard slog. In general, we write our code, compile it and run it, but we don't examine it. With nontrivial programs, looking at the machine code is very, very hard.</p>
<p>Compilers are treated as intrinsically trustworthy. Give 'em some source, they spit out a binary, you run the binary. Sometimes there are compiler bugs, sure, and compiler improvements can be a big deal. But compilers are infrastructure: inscrutable and forgotten.</p>
<p>Here's what Thompson did: he hid a program in his compiler that would check to see whether you were compiling an operating system or a compiler. If you were compiling an OS, it hid a secret login for him inside of it.</p>
<p>If you were compiling a compiler, it hid the program that looked for compilers or operating systems inside of it.</p>
<p>Think about what this means: every OS you compiled had an intentional security defect that the OS itself couldn't detect.</p>
<p>If you suspected that your compiler was up to no good and wrote your own compiler, it would be compromised as soon as you compiled it. What Thompson did was ask us to contemplate what we meant when we "trusted" something.</p>
<p>It was a move straight out of Rene Descartes, the reasoning that leads up to "I think therefore I am." Descartes' "Discourse on the Method" asks how we can know things about the universe.</p>
<p>He points out that sometimes he thinks he senses something but is wrong – he dreams, he hallucinates, he misapprehends.</p>
<p>If all our reasoning depends on the impressions we get from our senses, and if our senses are sometimes faulty, how can we reason at all?</p>
<p>Descartes wants a point of certainty, one thing he <em>knows</em> to be absolutely true. He makes the case that if you can be certain of one thing, you can anchor everything else to this point and build up a massive edifice of trustable knowledge that all hangs off of this anchor.</p>
<p>Thompson is basically saying, "You thought you had descartesed your way into a trustable computing universe because of the axiom that I would never poison your lowest-level, most fundamental tools.</p>
<p>"<em>Wrong</em>.</p>
<p>"Bwahahahaha."</p>
<p>(But, you know, in a nice way: an object lesson to serve as a wake-up call before computers fully merged with the physical world to form a global, species-wide digital nervous system whose untrustworthy low-level parts were foolishly, implicitly trusted).</p>
<p>But processors were expensive and computers were exploding. PCs running consumer operating systems like Windows and Mac OS (and more exotic ones like GNU/Linux and various Unices) proliferated, and they all shared this flawed security model.</p>
<p>They all relied on the operating system to be a faithful reporter of the computer's internals, and operated on the assumption that they could use programs supervised by the OS to detect and terminate malicious programs.</p>
<p>But starting in 1999, Ken Thompson's revenge was visited upon the computing world. Greg Hoglund released Ntrootkit, a proof-of-concept malware that attacked Windows itself, so that the operating system would lie to antivirus programs about what it was doing and seeing.</p>
<p>In Decartesspeak, your computer could no longer trust its senses, so it could no longer reason. The nub of trust, the piton driven into the mountainface, was made insecure and the whole thing collapsed. Security researchers at big companies like Microsoft took this to heart.</p>
<p>In 2002, Peter Biddle and his team from Microsoft came to EFF to show us a new model for computing: "Trusted Computing" (codenamed "Palladium").</p>
<p><a href="https://web.archive.org/web/20020805211111/https://www.microsoft.com/presspass/features/2002/jul02/0724palladiumwp.asp">https://web.archive.org/web/20020805211111/https://www.microsoft.com/presspass/features/2002/jul02/0724palladiumwp.asp</a></p>
<p>Palladium proposed to give computers back their nub of Descartesian certainty. It would use a co-processor, but unlike a graphics card or a math co-pro, it would run before the CPU woke up and did its thing.</p>
<p>And unlike a ROM, it wouldn't just load up the boot sequence and go back to sleep.</p>
<p>This chip – today called a "Secure Enclave" or a "Trusted Platform Module" (etc) – would have real computing power, and it would remain available to the CPU at all times.</p>
<p>Inside the chip was a bunch of cool cryptographic stuff that provided the nub of certainty. At the start of the boot, the TPM would pull the first stages of the boot-code off of the drive, along with a cryptographic signature.</p>
<p>A quick crypto aside:</p>
<p>Crypto is code that mixes a key (a secret known to the user) with text to produce a scrambled text (a "ciphertext") that can only be descrambled by the key.</p>
<p>Dual-key crypto has two keys. What one scrambles, the other descrambles (and vice-versa).</p>
<p>With dual-key crypto, you keep one key secret (the "private key") and you publish the other one (the "public key"). If you scramble something with a private key, then anyone can descramble it with your public key and know it came from you.</p>
<p>If you scramble it <em>twice</em>, first with your private key and then with your friend's public key, then they can tell it came from you (because only your private key's ciphertexts can be descrambled with your public key).</p>
<p>And <em>you</em> can be certain that only they can read it (because only their private key can descramble messages that were scrambled with their public key).</p>
<p>Code-signing uses dual-key crypto to validate who published some code.</p>
<p>Microsoft can make a shorter version of its code (like a fingerprint) and then you scramble it with its private key. The OS that came with your computer has a copy of MSFT's public key. When you get an OS update, you can descramble the fingerprint with that built-in key.</p>
<p>If it matches the update, then you know that Microsoft signed it and it hasn't been tampered with on its way to you. If you trust Microsoft, you can run the update.</p>
<p>But…What if a virus replaces Microsoft's public keys with its own?</p>
<p>That's where Palladium's TPM comes in. It's got the keys hardcoded into it. Programs running on the CPU can only ask the TPM to do very limited things like ask it to sign some text, or to check the signature on some text.</p>
<p>It's a kind of god-chip, running below the most privileged level of user-accessible operations. By design, you – the owner of the computer – can demand things of it that it is technically capable of doing, and it can refuse you, and you can't override it.</p>
<p>That way, programs running even in the most privileged mode can't compromise it.</p>
<p>Back to our boot sequence: the TPM fetches some startup code from the disk along with a signature, and checks to see whether the OS has been signed by its manufacturer.</p>
<p>If not, it halts and shows you a scary error message. Game over, Ken Thompson!</p>
<p>It is a very cool idea, but it's also very scary, because the chip doesn't take orders from Descartes' omnibenevolent God.</p>
<p>It takes orders from Microsoft, a rapacious monopolist with a history of complicity with human rights abuses. Right from that very first meeting the brilliant EFF technologist Seth Schoen spotted this (and made the Descartes comparison):</p>
<p><a href="https://web.archive.org/web/20021004125515/http://vitanuova.loyalty.org/2002-07-05.html">https://web.archive.org/web/20021004125515/http://vitanuova.loyalty.org/2002-07-05.html</a></p>
<p>Seth identified a way of having your cake and eating it too: he proposed a hypothetical thing called an "owner override" – a physical switch that, when depressed, could be used to change which public keys lived in the chip.</p>
<p>This would allow owners …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317557</guid>
            <pubDate>Sat, 05 Dec 2020 19:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TeX: A Tale of Two Worlds]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317503">thread link</a>) | @figomore
<br/>
December 5, 2020 | https://bitbashing.io/tex.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/tex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!-- for XeTeX -->


<p>Best viewed in <del>Internet Explorer 6</del>
<a href="https://assets.bitbashing.io/papers/tex-tale-of-two-worlds.pdf">PDF</a>
because… well… read the damn thing.</p>

<!--
It all started when a college friend told me about a cool program for typesetting
papers. Now typography books litter my apartment and I can't read a menu
without noticing bad kerning. Thanks, Max. This is all your fault.
-->

<hr>

<p>Most serious programmers have heard of Donald Knuth,
the man who coined the term <em>analysis of algorithms</em> in 1968
and pioneered many of the computer science fundamentals we use today.
Knuth is perhaps most famous for his ongoing magnum opus,
<em>The Art of Computer Programming</em>.</p>

<p>When the first volume of TAOCP was released that same year,
it was printed the way most books had been since the turn of the century:
with <em>hot metal</em> type.
Each individual letter was cast from molten lead,
then arranged into its line.</p>

<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/7/72/Matrixcase-bembo-16pts.jpg" alt="Monotype matrix case" height="400">
<figcaption>
A case of letter molds—or <em>matrices</em>—used by the Monotype caster,
the most commonly-used machine for printing books in the days of hot metal type.
Its main contemporary, the Linotype, molded entire lines at a time,
and was often used for printing newspapers.
</figcaption>
</figure>

<p>These lines were clamped together to form pages of the book,
which were finally inked and pressed against paper.
By March of 1977, Knuth was ready for a second run of TAOCP, Volume&nbsp;2,
but he was horrified when he received the proofs.
Hot metal typesetting was an expensive, complicated, and time-consuming process,
so publishers had replaced it with phototypesetting,
which works by projecting characters onto film.
The new technology, while much cheaper and faster,
didn’t provide the same level of quality he had come to expect.</p>

<p>The average author would have resigned themselves to the change and moved on,
but Knuth took great pride in print quality,
especially for the mathematics in his books.
Around this time, he discovered an exciting new technology:
digital typesetting.
Instead of working with metal or film,
letters and shapes were built from tiny dots,
often packed together at over 1,000 per inch.
Inspired by this burgeoning tech and frustrated with the current state of affairs,
Knuth set off on one of the greatest yak shaves of all time.
For years, he paused all work on his books to create his own
digital typesetting system.
When the dust settled in 1978, Knuth had the first version of
<span>T<sub>e</sub>X</span>
.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>It’s hard to understand how much of a revolution <span>T<sub>e</sub>X</span>
 was,
especially looking back from a time where anybody with a copy
of Word can be their own desktop publisher.
Adobe’s PDF wouldn’t exist for another decade, so Knuth
invented a device-independent format, DVI.
Scalable fonts were uncommon at the time, so Knuth created a system,
<span>METAFONT</span>
, to rasterize his characters into dots on the
page.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Perhaps most importantly, Knuth and his graduate students designed algorithms
to automatically hyphenate and justify lines of text into
beautifully-typeset paragraphs.</p>

<p>Here is where the timelines diverge.
In one, <span>T<sub>e</sub>X</span>
 was just the beginning.
Computer typography evolves rapidly as the decades go by,
building on Knuth’s prior work and
taking advantage of the million-fold increases we’ve seen in computing power.
Browsers, e-readers, and word processors deliver beautiful type
to every person who looks at a screen, with almost no effort from authors.</p>

<p>In the darker timeline… none of this happens.
<span>T<sub>e</sub>X</span>
 is still some of the best we’ve got for computer typesetting.
It’s seen some impressive improvements,<sup id="fnref:3"><a href="#fn:3">3</a></sup>
but its core hasn’t changed much in decades.
To this day,
it doesn’t lay out more than one page at a time because 1980s computers didn’t
have enough RAM to do any better.<sup id="fnref:4"><a href="#fn:4">4</a></sup>
Almost no other software—except for a handful of professional layout
programs like Adobe InDesign—leverages any of the advances
<span>T<sub>e</sub>X</span>
 made in line breaking and hyphenation.
Layout in Word, browsers, and even e-readers is a sad joke.</p>

<figure>
<img src="https://assets.bitbashing.io/images/exa.png" alt="Mobile browser layout example" height="400">
<figcaption>
State of the art text layout in today's browsers. Mind the gaps.
</figcaption>
</figure>

<p>I’m not sure what to make of this.
Maybe most people, outside a small cadre of designers and
enthusiasts, just don’t care about typography very much.
After all, the human brain is incredibly good glossing over minor details and
im<span>p</span>erfections when reading.
But even the design world seems largely unaware or indifferent to Knuth’s work.
Despite collaborations with famous type designers like Hermann Zapf,
you’ll find no mention of him in renowned books and documentaries on
the subject.<sup id="fnref:5"><a href="#fn:5">5</a></sup>
And parametric font families—just like the ones <span>METAFONT</span>
 offered in 1983—are
heralded in 2017 as “a new era of type design”.<sup id="fnref:6"><a href="#fn:6">6</a></sup>
It’s bizarre.</p>

<p>Good typography can make almost anything more enjoyable to read,
and it feels like such a shame that better layout isn’t
available to the masses
when so much of the groundwork was laid almost forty years ago.
In an age when the average American reads from a screen they keep in their pocket
dozens of times a day,
and where each one of those devices holds more processing power than you could
fit in several rooms back when Donald Knuth
wrote <span>T<sub>e</sub>X</span>
, surely we can—and <em>should</em>—do better.</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/tex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317503</guid>
            <pubDate>Sat, 05 Dec 2020 19:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to call a function on URL change in JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317274">thread link</a>) | @championshuttle
<br/>
December 5, 2020 | https://championshuttler.in/how-to-call-a-function-on-url-change-in-javascript | <a href="https://web.archive.org/web/*/https://championshuttler.in/how-to-call-a-function-on-url-change-in-javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Modern JS frameworks tend not to reload the page but manipulate DOM and change URL path for internal navigation, for performance and smooth UX. But since there is no page reload, <code>window.onload</code> event does not get triggered for subsequent navigation. We run into a situation where we need to call a function whenever URL path changes (not the hash).</p>
<h3 id="problem">Problem</h3>
<p>The <a target="_blank" href="https://itsopensource.com/"><code>itsopensource.com</code></a> blog is built using <a target="_blank" href="https://www.gatsbyjs.org/">gatsby</a>, we wanted to add google analytics to this, but instead of using google tag manager, we tried to restrict what <a target="_blank" href="https://github.com/tsl143/itsopensource/blob/master/src/html.js#L32">data</a> is sent to google and in this process, we need to send XHR request on every page load. We created a function <code>sendTelemetry</code> and called it on <code>window.onload</code>. This works as expected (partially), whenever the page is loaded the XHR is sent, but gatsby do not reload the page while changing the URL when any blog link is clicked, so XHR is sent only once per session and not on subsequent page loads.<br>Javascript does not provide any native listener to path change (not hashchange).</p>
<h3 id="solution">Solution</h3>
<p>The <code>history</code> API maintains complete the navigation state. Whenever a new page is navigated <code>history.pushState</code> is called and page is added to the state. That means this event is called whenever the URL changes. We hooked our function on this, and done :)</p>
<pre><code>(<span><span>function</span>(<span>history</span>)</span>{
    <span>var</span> pushState = history.pushState;
    history.pushState = <span><span>function</span>(<span>state</span>) </span>{
      
      <span>console</span>.log(<span>'I am called from pushStateHook'</span>);
      <span>return</span> pushState.apply(history, <span>arguments</span>);
    };
})(<span>window</span>.history);
</code></pre>
<h3 id="demo">Demo</h3>
<p>A quick demo can be the following:</p>
<ol>
<li>Open the browser console on this very page.</li>
<li>Paste the above-written code snippet.</li>
<li>Keep console open and navigate various pages on this blog</li>
<li>You should see a message in console on every navigation.</li>
</ol>

<p><em>The first choice for the title was <code>how to hook a function on history.pushState</code>.</em>  </p>
<p>Reference: <a target="_blank" href="https://stackoverflow.com/questions/4570093/how-to-get-notified-about-changes-of-the-history-via-history-pushstate">stackoverflow</a>  😉</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://championshuttler.in/how-to-call-a-function-on-url-change-in-javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317274</guid>
            <pubDate>Sat, 05 Dec 2020 19:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HDR: High Dynamic Range and Wide Gamut Color on the Web]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317262">thread link</a>) | @tosh
<br/>
December 5, 2020 | https://w3c.github.io/ColorWeb-CG/ | <a href="https://web.archive.org/web/*/https://w3c.github.io/ColorWeb-CG/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <section id="abstract">
      <p>
        The Note is a gap analysis document.
        It identifieds the next steps
        for enabling
        Wide Color Gamut (WCG)
        and
        High Dynamic Range (HDR)
        on the Open Web Platform.
      </p>
    </section>
    
    <section>
      <h2>Introduction</h2>

      <p>The initial commercial application of Color Science
        (principally colorimetry, rather than color appearance modelling)
        to the reproduction of color
        was concerned with surface colors
        such as painted or printed objects,
        lit by a single illuminant.
        The achievable luminance range was thus constrained
        to the luminance of a perfect diffuse reflector
        (practically, an unprinted sheet of good paper)
        at the high end,
        and the densest printed or painted black
        that could be achieved without the paper tearing or deforming,
        at the darkest end. This produced luminance ranges
        from as low as 20:1
        to as high as 90:1 (Fairchild, p.399 [[Fairchild-CAM]]).
        The achievable Chroma range was also limited
        by the vibrancy of mass-produced paints and inks,
        and the prohibitive cost of using additional spot colors
        to extend the gamut.
        <!-- add UCS diagram of coated and uncoated FOGRA21 and 39 -->
        Self-luminous displays, in that commercial environment,
        were primarily used at low luminances
        for soft proofing of an eventual printed product,
        and were intended to replicate the appearance of a viewing booth.
      </p>

      <p>Over time, self-luminous displays were seen
        as a worthy color management target in their own right:
        for computer displays,
        for the display of digital photography,
        for digital cinema,
        and for the consumption of media such as television and movies in the home.
        The luminance range increased:
        media consumed in near-dark environments such as the cinema
        could have much deeper blacks,
        while media consumed in dim to normal viewing environments
        enjoyed an increased peak white luminance of 200 to 300 cd/m².
        The darkest blacks in such environments were constrained by viewing flare,
        which is why the sRGB standard mandated a viewing flare of 5%,
        typical for glossy glass CRT displays of the time;
        coupled with a peak luminance of only 80cd/m²
        the luminance range was still relatively modest.
        The introduction of matt LCD and OLED screens,
        and the commercial success of HDTV, increased the dynamic range somewhat,
        but it was still comfortable encoded in 8 bits per gamma-corrected component.
        This is referred to as <b>Standard Dynamic Range (SDR)</b>.
        The achievable Chroma range for sRGB and Rec.709 HDTV, although extending beyond that of printed material at the primaries, was also relatively modest.
        Wider gamut displays were available professionally,
        covering most of the Adobe 1998 RGB™ colorspace,
        but wre typically not found in a home or office environment.
        <!-- sRGB gamut on UCS diagram -->
      </p>

      Commercial availability of displays covering the Display P3 gamut
      (a derivative of DCI P3 used for digital cinema,
      but altered to account for a non-dark viewing environment,
      with an sRGB transfer curve ,and D65 white point)
      meant that <b>Wide Color Gamut (WCG)</b> displays became commonplace
      on laptops, external monitors, mobile phones, and even watches.
      WCG requires a modest increase in the
      number of bits per gamma-corrected component,
      from 8 to 10 or 12 (for the widest gamut
      in common use for content delivery,
      Rec.2020).

      <p>The deployment of 4k and then 8k television,
      accompanied by digital content delivery,
      brought not only a similarly increased color gamut
      to the media space, but also a greatly increased dynamic range
      of 4000:1 or more.
      Increased phosphor efficiency and purity,
      together with bright and modulatable backlights,
      brought <b>High Dynamic Range (HDR)</b> into widespread use.
      Computers, however, remained limited to SDR for the most part.</p>

      <p>
        The human visual system can,
        with appropriate adaptation,
        function over an enormous luminance range —
        from starlight or moonlight at 0.01 cd/m² and  0.1 cd/m²,
        through the dim lighting at dawn and dusk (10 cd/m²),
        office lighting (100 cd/m²),
        modern displays (800 cd/m²),
        overcast daylight (1,000 cd/m²),
        bright daylight (10,000 cd/m²)
        and full direct sunlight (100,000 cd/m²).
        However, the full range cannot be simultaneously percieved
        in the same scene
        at the same time.
      </p>
      <p>
        There are two main
        systems defined for HDR video:
        Hyprid Log Gamma (HLG), developed by BBC and NHK, and
        Dolby Perceptual Quantizer (PQ).
        While improvement in video quality has driven the innovation of HDR,
        support for content on the web more generally, e.g., for static images,
        the <code>&lt;canvas&gt;</code> element, and in CSS in general, is still
        needed.
      </p>
      <p>
        Add a brief description of PQ and HLG approaches, including: use of
        metadata, absolute vs relative brightness, proprietary vs open standard,
        etc.
      </p>
      <p>
        The BBC has published a frequently-asked questions document
        [[hdr-hlg-faq]] that gives a high level introduction to HDR, and the
        PQ and HLG solutions.
      </p>
      <p>
        Fredrik Hubinette from Google has written a useful document
        [[hdr-chrome]] that discusses the issues with presenting, and in
        particular compositing, SDR and HDR content. This was presented at
        TPAC 2017. It considers both PQ and HLG. (<a href="https://www.w3.org/2017/11/07-colorweb-minutes.html">minutes
          of the TPAC 2017 meeting</a>)
      </p>

      <p>
        On the web, SDR, and HDR content using both HLG and PQ is expected to
        coexist, potentially within the same page, as authors can include
        arbitrary content in their web pages. An example is a page that contains
        multiple embedded videos, or their poster images. This raises the
        question of how to composite content with different color spaces and
        dynamic range encodings.
      </p>
    </section>
    <section>
      <h2>Goals</h2>
      <p>
        Support for HDR and WCG on the web is important to allow color and
        luminance matching between HDR video content and surrounding or
        overlaid graphic and textual content in web pages.
      </p>
      <p>
        Some specific goals include:
      </p>
      <ul>
        <li>
          Ensure support for HDR encoded video as a first class citizen on the
          web, including both HLG and PQ, with appropriate rules defined for
          composition of content.
        </li>
        <li>
          Enable support for HDR static images, texual content, and graphics
          rendered via Canvas or SVG.
        </li>
        <li>
          Promote understanding of HDR graphics issues among the web developer
          community.
        </li>
      </ul>
      <p>
        There are a number of specifications potentially impacted by HDR.
        One of the purposes of this document is to identify all documents that
        are possibly affected, so that we can review them and determine any
        changes needed.
      </p>
      <ul>
        <li>Media Capabilities API [[media-capabilities]], [[media-capabilities-explainer]]</li>
        <li>CSSOM View Module [[cssom-view]]</li>
        <li>CSS Color Module Level 4 [[css-color-4]]</li>
        <li>HTML canvas Element [[canvas-colorspace]]</li>
        <li>HTML input type="color" [[html-color-input]]</li>
        <li>Media Queries 5 [[mediaqueries-5]]</li>
        <li>Scalable Vector Graphics (SVG2) [[svg2]]</li>
        <li>TTML2 [[ttml2]], IMSC1.1 [[ttml-imsc1.1]]</li>
        <li>Using the ITU BT.2100 PQ EOTF with the PNG Format [[png-hdr-pq]]</li>
      </ul>

    </section>
    <section>
      <h2>Specifying Colors in Web Pages</h2>
      <section>
        <h3>CSS Color Module</h3>
        <p>
          CSS defines several ways of specifying the colors to use in web
          pages, in the CSS Color Module specifications. The current Recommendation is
          Level 3 [[css-color-3]], and its successor, Level 4, is becoming stable
          and starting to be implemented [[css-color-4]].
          The various methods in Level 4 cover WCG but not HDR, and are:
        </p>
        <ul>
          <li>sRGB (Red, Green, Blue), using the <code>rgb()</code> and <code>rgba()</code> functions</li>
          <li>Named colors, from early HTML and X11, e.g., 'aqua', 'black', 'blue', 'fuchsia', etc</li>
          <li>HSL (Hue, Saturation, Lightness), using the <code>hsl()</code> and <code>hsla()</code> functions</li>
          <li>(*) HWB (Hue, Whiteness, Blackness), using the <code>hwb()</code> function</li>
          <li>(*) Lab and LCH (Lightness, Chroma, Hue), using the <code>lab()</code> and <code>lch()</code> functions</li>
          <li>(*) Profiled, device-dependent colors:
            <ul>
              <li>predefined colorspaces: <code>display-p3</code>, <code>a98-rgb</code> (compatible with Adobe® RGB (1998)), <code>prophoto-rgb</code>, <code>rec-2020</code> </li>
              <li>calibrated colorspaces, using <code>@profile</code> to link to an ICC profile.
              This is not limited to RGB: <a href="https://drafts.csswg.org/css-color-4/#cal-cmyk">CMYK and wide-gamut print spaces</a> are also covered.</li>
            </ul>
          </li>
        </ul>
        <p>Items marked (*) are new in Level 4. <code>rgb()</code>,
          <code>named colors</code>, <code>HSL</code> and <code>HWB</code>
          all resolve to sRGB. The others are WCG.
          To date, all of these are SDR colorspaces.</p>
        <p>
          Section 12 in [[css-color-4]] is titled "Working Color Space", and
          currently empty. It is intended to cover compositing multiple colorspaces.
          There is as yet no consensus on whether this should be per-document or a per-element property;
          nor on whether a single value is appropriate for all operations.
          We need to define how should compositing work, if
          there is HLG, PQ, and SDR content present. The [[hdr-chrome]]
          discussion document provides useful input. This will require defining
          where black, media/paper white, and peak whites (full-screen and small-area hilights)
          map in the various spaces.
        </p>
        <p>
          The draft CSS Color Module Level 4 [[css-color-4]],
          adds WCG support. Rec. 2020 is covered, but only for SDR.
          The range of CIE Lightness (in Lab and LCH)
          is not constrained to 100,
          and a figure of 400 …</p></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://w3c.github.io/ColorWeb-CG/">https://w3c.github.io/ColorWeb-CG/</a></em></p>]]>
            </description>
            <link>https://w3c.github.io/ColorWeb-CG/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317262</guid>
            <pubDate>Sat, 05 Dec 2020 19:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No-Cloning Theorem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317260">thread link</a>) | @keyboardman
<br/>
December 5, 2020 | https://leimao.github.io/blog/No-Cloning-Theorem/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/No-Cloning-Theorem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>In the classical world, it is quite common that we could make an exactly the same copy of something. However, in the quantum world, the laws of physics impose a severe restriction on copying: It is impossible to make a perfect copy of an unknown state.</p>



<p>In this blog post, I would like to discuss the No-Cloning Theorem in quantum theory.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="kronecker-product-inverse-transpose-property">Kronecker Product Inverse-Transpose Property</h4>

<p>Conjugate transposition are distributive over the Kronecker product:</p><p>

\[(A \otimes B)^{\dagger} =  A^{\dagger} \otimes B^{\dagger}\]

\[\begin{align}
(A \otimes B)^{\dagger} &amp;= 
\begin{bmatrix} 
    A_{0,0}B &amp; A_{0,1}B &amp; \cdots &amp; A_{0,n-1}B \\
    A_{1,0}B &amp; A_{1,1}B &amp; \cdots &amp; A_{1,n-1}B \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    A_{m-1,0}B &amp; A_{m-1,1}B &amp; \cdots &amp; A_{m-1,n-1}B \\
\end{bmatrix}^{\dagger} 
\nonumber\\
&amp;= 
\begin{bmatrix} 
    (A_{0,0}B)^{\dagger} &amp; (A_{1,0}B)^{\dagger} &amp; \cdots &amp; (A_{m-1,0}B)^{\dagger} \\
    (A_{0,1}B)^{\dagger} &amp; (A_{1,1}B)^{\dagger} &amp; \cdots &amp; (A_{m-1,1}B)^{\dagger} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    (A_{0,n-1}B)^{\dagger} &amp; (A_{1,n-1}B)^{\dagger} &amp; \cdots &amp; (A_{m-1,n-1}B)^{\dagger} \\
\end{bmatrix}
\nonumber\\
&amp;= 
\begin{bmatrix} 
    \overline{A_{0,0}}B^{\dagger} &amp; \overline{A_{1,0}}B^{\dagger} &amp; \cdots &amp; \overline{A_{m-1,0}}B^{\dagger} \\
    \overline{A_{0,1}}B^{\dagger} &amp; \overline{A_{1,1}}B^{\dagger} &amp; \cdots &amp; \overline{A_{m-1,1}}B^{\dagger} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    \overline{A_{0,n-1}}B^{\dagger} &amp; \overline{A_{1,n-1}}B^{\dagger} &amp; \cdots &amp; \overline{A_{m-1,n-1}}B^{\dagger} \\
\end{bmatrix}
\nonumber\\
&amp;= 
\begin{bmatrix} 
    A_{0,0}^{\dagger}B^{\dagger} &amp; A_{0,1}^{\dagger}B^{\dagger} &amp; \cdots &amp; A_{0, m-1}^{\dagger}B^{\dagger} \\
    A_{1,0}^{\dagger}B^{\dagger} &amp; A_{1,1}^{\dagger}B^{\dagger} &amp; \cdots &amp; A_{1, m-1}^{\dagger}B^{\dagger} \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    A_{n-1,0}^{\dagger}B^{\dagger} &amp; A_{n-1,1}^{\dagger}B^{\dagger} &amp; \cdots &amp; A_{n-1,m-1}^{\dagger}B^{\dagger} \\
\end{bmatrix}
\nonumber\\
&amp;=
A^{\dagger} \otimes B^{\dagger} \\
\end{align}\]

</p><p>This concludes the proof.</p>

<h4 id="kronecker-product-mixed-product-property">Kronecker Product Mixed-Product Property</h4>

<p>Let $A \in \mathbb{C}^{m \times n}$, $B \in \mathbb{C}^{r \times s}$, $C \in \mathbb{C}^{n \times p}$, and $D \in \mathbb{C}^{s \times t}$, then</p><p>

\[(A \otimes B)(C \otimes D) = (AC) \otimes (BD)\]

</p><p>This has been proved in <a href="https://leimao.github.io/blog/Kronecker-Product-In-Circuits/">Kronecker Product In Circuits</a>.</p>

<h4 id="inner-product-expansion-property">Inner Product Expansion Property</h4>

<p>Suppose $|x\rangle$ is any unit vector whose $|x|^2 = \langle x | x \rangle = 1$. We have $\langle \phi | \psi \rangle = (\langle \phi | \otimes \langle x |) (| x \rangle \otimes | \psi \rangle)$</p><p>

\[\begin{align}
(\langle \phi | \otimes \langle x |) (| \psi \rangle \otimes | x \rangle) &amp;= (| \psi \rangle \otimes | x \rangle)^{\dagger} (|\phi\rangle \otimes |x\rangle) \\
&amp;= (| \psi \rangle^{\dagger} \otimes | x \rangle^{\dagger}) (|\phi\rangle \otimes |x\rangle) \\
&amp;= (| \psi \rangle^{\dagger}|\phi\rangle) \otimes (| x \rangle^{\dagger}|x\rangle) \\
&amp;= \langle \phi | \psi \rangle \otimes \langle x | x \rangle\\
&amp;= \langle \phi | \psi \rangle \otimes 1\\
&amp;= \langle \phi | \psi \rangle\\
\end{align}\]

</p><p>This concludes the proof.</p>

<h4 id="unitary-matrix-preserves-inner-product">Unitary Matrix Preserves Inner Product</h4>

<p>Given two complex vectors $x$ and $y$, multiplication by unitary matrix $U$ preserves their inner product.</p><p>

\[\begin{align}
\langle Ux, Uy \rangle &amp;= \langle x, y \rangle
\end{align}\]

</p><p>Using the definition of inner product,</p><p>

\[\begin{align}
\langle Ux, Uy \rangle &amp;= (Uy)^{\dagger} (Ux) \\
&amp;= y^{\dagger}U^{\dagger} U x \\
&amp;= y^{\dagger}(U^{\dagger} U) x \\
&amp;= y^{\dagger} I x \\
&amp;= y^{\dagger} x \\
&amp;= \langle x, y \rangle \\
\end{align}\]

</p><p>This concludes the proof.</p>

<h3 id="no-cloning-theorem">No-Cloning Theorem</h3>

<p>In quantum mechanics, copy, as it is the same to other quantum operators except measurement operators, is an reversible and linear operator.</p>



<p>Given any unknown normalized quantum state $| \phi \rangle$, and the copy operator $U$, we are supposed to have the following mathematical expression if we are going to copy the quantum state $| \phi \rangle$ to another system whose quantum state is $|x \rangle$ before copy.</p><p>

\[| \phi \rangle \otimes |x\rangle \xrightarrow[]{U} | \phi \rangle \otimes |\phi\rangle\]

</p><p>We would like to write this transformation into equation.</p><p>

\[U (| \phi \rangle \otimes |x\rangle) = | \phi \rangle \otimes |\phi\rangle\]

</p><p>Without loss of generality, we could have another state $| \psi \rangle$ that is applied to the copy operator.</p><p>

\[U (| \psi \rangle \otimes |x\rangle) = | \psi \rangle \otimes |\psi\rangle\]

</p><p>Note that for $| \psi \rangle$ we also used $|x\rangle$ which $| \phi \rangle$ is using, meaning that before copy, the â€œvacantâ€� system is always the same. This is something we could guarantee.</p>



<p>We examine the inner product of $| \phi \rangle$ and $| \psi \rangle$ using the copy property and all the properties in the prerequisite section.</p><p>

\[\begin{align}
\langle \phi | \psi \rangle &amp;= (\langle \phi | \otimes \langle x |) (| \psi \rangle \otimes | x \rangle) \\
&amp;= \big(U (\langle \phi | \otimes \langle x |)\big) \big(U (| \psi \rangle \otimes | x \rangle)\big) \\
&amp;= (\langle \phi | \otimes \langle \phi |) (| \psi \rangle \otimes | \psi \rangle) \\
&amp;= (| \psi \rangle \otimes | \psi \rangle)^{\dagger} (| \phi \rangle \otimes | \phi \rangle) \\
&amp;= (| \psi \rangle^{\dagger} \otimes | \psi \rangle^{\dagger}) (| \phi \rangle \otimes | \phi \rangle) \\
&amp;= (| \psi \rangle^{\dagger} | \phi \rangle ) \otimes (| \psi \rangle^{\dagger} | \phi \rangle ) \\
&amp;= \langle \phi | \psi \rangle \otimes \langle \phi | \psi \rangle \\
\end{align}\]

</p><p>Because $\langle \phi | \psi \rangle$ is scalar, we further have</p><p>

\[\begin{align}
\langle \phi | \psi \rangle &amp;= \langle \phi | \psi \rangle \otimes \langle \phi | \psi \rangle \\
&amp;= \langle \phi | \psi \rangle ^2 \\
\end{align}\]

</p><p>Solving the above equation, we have $\langle \phi | \psi \rangle = 0$ or $1$.</p>



<p>Because $| \phi \rangle$ and $| \psi \rangle$ could be any arbitrary unknown states, $\langle \phi | \psi \rangle = 0$ or $1$ could never be satisfied.</p>



<p>Therefore, there is no general quantum copy operator that makes copy of any unknown state.</p>

<h3 id="more-restrict-no-cloning-theorem">More Restrict No-Cloning Theorem</h3>

<p>In quantum theory, $| \phi \rangle$ and $c | \phi \rangle$, where $c$ is a non-zero complex number, represent the same physical state. If $|c \phi|^2 = 1$, then $| \phi \rangle$ and $c | \phi \rangle$ only have phase difference.</p>



<p>For example, $| \phi \rangle$ and $| \psi \rangle$ have exactly the same probability of collapsing to $| 0 \rangle$ and $| 1 \rangle$. However, $| \phi \rangle$ has phase $\varphi_1$ while $| \psi \rangle$ has phase $\varphi_2$.</p><p>

\[\begin{align}
| \phi \rangle &amp;= \cos \frac{\theta}{2} | 0 \rangle + e^{i\varphi_1} \sin \frac{\theta}{2} | 1 \rangle \\
| \psi \rangle &amp;= \cos \frac{\theta}{2} | 0 \rangle + e^{i\varphi_2} \sin \frac{\theta}{2} | 1 \rangle \\
\end{align}\]

</p><p>More restrict No-Cloning Theorem states that â€œcopyingâ€� any unknown state while abandoning the phase is not possible either.</p>



<p>Suppose we have such â€œcopyâ€� operator, the mathematical expression for â€œcopyâ€� will be as follows.</p><p>

\[U (| \phi \rangle \otimes |x\rangle) = e^{\varphi} | \phi \rangle \otimes |\phi\rangle\\
U (| \psi \rangle \otimes |x\rangle) = e^{\varphi^{\prime}} | \psi \rangle \otimes |\psi\rangle\]

</p><p>Similarly, we have</p><p>

\[\begin{align}
\langle \phi | \psi \rangle &amp;= e^{\varphi} e^{\varphi^{\prime}}\langle \phi | \psi \rangle ^2 \\
&amp;= e^{\varphi + \varphi^{\prime}} \langle \phi | \psi \rangle ^2 \\
\end{align}\]

</p><p>The norm of the two sides should be equivalent.</p><p>

\[\begin{align}
|\langle \phi | \psi \rangle| &amp;= |e^{\varphi + \varphi^{\prime}} \langle \phi | \psi \rangle ^2| \\
&amp;= |e^{\varphi + \varphi^{\prime}}| |\langle \phi | \psi \rangle ^2| \\
&amp;= 1 |\langle \phi | \psi \rangle ^2| \\
&amp;= |\langle \phi | \psi \rangle ^2| \\
&amp;= |\langle \phi | \psi \rangle |^2 \\
\end{align}\]

</p><p>Solving the above equation, we have $|\langle \phi | \psi \rangle | = 0$ or $1$.</p>



<p>Because $| \phi \rangle$ and $| \psi \rangle$ could be any arbitrary unknown states, $|\langle \phi | \psi \rangle | = 0$ or $1$ could never be satisfied.</p>



<p>Therefore, there is no general quantum â€œcopyâ€� operator that makes â€œcopyâ€� of any unknown state that has lost the phase information.</p>

<h3 id="transportation">Transportation</h3>

<p>Since it is not possible to do copy in quantum world, how about transportation?</p>



<p>Concretely, given any unknown normalized quantum state $| \phi \rangle$, and the transportation operator $U$, we are supposed to have the following mathematical expression if we are going to transport the quantum state $| \phi \rangle$ to another system whose quantum state is $|x \rangle$ before transportation.</p><p>

\[U(| \phi \rangle \otimes |x\rangle) = | x \rangle \otimes |\phi\rangle\]

</p><p>Note that although it is called transportation, it is more like a switch, where the two system states, one unknown and one known, got switched.</p>



<p>Without loss of generality, we could have another state $| \psi \rangle$ that is applied to the transportation operator.</p><p>

\[U(| \psi \rangle \otimes |x\rangle) = | x \rangle \otimes |\psi\rangle\]

</p><p>Similarly, we compute the inner product of $| \phi \rangle$ and $| \psi \rangle$.</p><p>

\[\begin{align}
\langle \phi | \psi \rangle &amp;= (\langle \phi | \otimes \langle x |) (| \psi \rangle \otimes | x \rangle) \\
&amp;= \big(U (\langle \phi | \otimes \langle x |)\big) \big(U (| \psi \rangle \otimes | x \rangle)\big) \\
&amp;= (\langle x | \otimes \langle \phi |) (| x \rangle \otimes | \psi \rangle) \\
&amp;= (| x \rangle \otimes | \psi \rangle)^{\dagger} (| x \rangle \otimes | \phi \rangle) \\
&amp;= (| x \rangle^{\dagger} \otimes | \psi \rangle^{\dagger}) (| x \rangle \otimes | \phi \rangle) \\
&amp;= (| x \rangle^{\dagger} | x \rangle ) \otimes (| \psi \rangle^{\dagger} | \phi \rangle ) \\
&amp;= \langle x | x \rangle \otimes \langle \phi | \psi \rangle \\
&amp;= 1 \otimes \langle \phi | \psi \rangle \\
&amp;= \langle \phi | \psi \rangle \\
\end{align}\]

</p><p>Unlike copy, we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/No-Cloning-Theorem/">https://leimao.github.io/blog/No-Cloning-Theorem/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/No-Cloning-Theorem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317260</guid>
            <pubDate>Sat, 05 Dec 2020 19:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Special Kind of Hell: intmax_t in C and C++]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25316933">thread link</a>) | @ingve
<br/>
December 5, 2020 | https://thephd.github.io/intmax_t-hell-c++-c | <a href="https://web.archive.org/web/*/https://thephd.github.io/intmax_t-hell-c++-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>C and C++ as languages have a few things separating them from each other, mostly in their minute details and, occasionally, larger feature sets like designated initializers. But there is a disturbingly high amount of C++ that can simply do C’s job far better than C<!--more-->, including when it comes to solving some of the biggest problems facing the evolution of C and C++.</p>

<p>Let’s take a contemporary problem plaguing both C and C++, affecting everyone from standard library maintainers to project developers, that has been going on for the last 20 or so years: <code>intmax_t</code>.</p>



<p>The concept behind <code>intmax_t</code> is simple enough: it is the largest integer type that your implementation and its standard library support in conjunction. Here is a few things <code>intmax_t</code> controls inside the implementation:</p>

<ul>
  <li>numeric literals are preprocessed according to what <code>intmax_t</code> can handle (C and C++);</li>
  <li>it is the maximum number of bits that can be printed portably, e.g. with <code>printf("%j", (intmax_t)value)</code> (C and C++);</li>
  <li><code>intmax_t</code> is the largest type for which <code>std::numeric_limits</code> applies, including most types up to and including that type (C++ only);</li>
  <li><code>intmax_t</code> underpins <code>std::chrono</code>’s casts and similar (e.g. no information is lost during conversions out of and into the system) (C++ only);</li>
  <li>and, there are a set of integer operations provided by the standard library (like absolute value and quotient / remainder operations) that can be done with the maximum bit precision available to the implementation (C and C++).</li>
</ul>

<p>These properties forge the basis of <code>intmax_t</code>’s purpose. Lossless storage, pass-through operations, and more can all be achieved by relying on this implicit contract of the type. Since it is a type definition, the “real” integer type underneath it can be swapped out and people relying on it can be upgraded seamlessly!</p>



<p>We cannot upgrade seamlessly.</p>

<p>C has a much higher commitment to not breaking old code and keeping “developers close to the machine”. What this actually translates to for most Application Binary Interfaces is very simplistic “name mangling” schemes (i.e., none), <a href="https://twitter.com/__phantomderp/status/1329960075096694790">weak linkers</a>, and other shenanigans. The end result is that we expose C developers to platform details that become invisible dependencies for their code that must be preserved at all costs. For example, let’s take a C Standard function that uses <code>intmax_t</code>, <code>imaxabs</code>:</p>

<div><div><pre><code><span>intmax_t</span> <span>imaxabs</span><span>(</span><span>intmax_t</span> <span>j</span><span>);</span>
</code></pre></div></div>

<p>and, let’s try to figure out how we can upgrade someone off of this usage without breaking their code too badly. We will try fixing this in both C and C++.</p>



<p>Taking <code>intmax_t</code>, let’s do a no-brainer usage case: calling a function with <code>intmax_t</code> input and return types. The syntax and usage ends up looking like this:</p>

<div><div><pre><code><span>#include &lt;inttypes.h&gt;
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>original</span> <span>=</span> <span>(</span><span>intmax_t</span><span>)</span><span>-</span><span>2</span><span>;</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>imaxabs</span><span>(</span><span>original</span><span>);</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>val</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Easy enough! But, there’s also a hidden dependency here, based on how the code is compiled. While many people compile their C standard library as a static library and only generate final binary code for what they use as to have a “self-contained” binary, the vast majority of the shared ecosystem depends on shared libraries/dynamically linked libraries for the standard. This means that when a program is milled through an operating system at program startup, the “loader” runs off to find the symbol <code>imaxabs</code> inside some system library (e.g., <code>/lib/x86_64-linux-gnu/libc-2.27.so</code> for an “amd64” system). Harmless enough, right? Well, it turns out to be a bit of a problem in practice, because the name <code>imaxabs</code> is all that’s used in C to figure out what subroutine to talk with in some shared library,</p>

<p>and that name is completely inadequate.</p>

<p>Consider the following scenario:</p>

<ol>
  <li>The glibc maintainers decide they’re going to change from <code>long long</code> as their <code>intmax_t</code> and move to <code>__int256_t</code> for most platforms, because most platforms support it and they have a lot of customers asking for it.</li>
  <li>They upgrade the <code>libc</code> to its next version for various Linux distribution, and everyone links against it when they look for the default <code>libc</code>.</li>
  <li>You have an application. Your code was not changed or updated, so it was not recompiled. It calls <code>imaxabs</code>. The argument it passes is a <code>long long</code>, because that was the type at the time you last compiled and shipped your software.</li>
  <li>The <code>imaxabs</code> used to lookup the function to call finds the version that takes a <code>__int256_t</code> in the new <code>libc</code>.</li>
  <li>Different registers are used to pass and return the function value than expected by the <code>imaxabs</code> function call in the <code>libc</code> binary, because your application is in <code>long long</code> mode but glibc expects a <code>__int256_t</code>.</li>
  <li>All hell breaks loose.</li>
</ol>

<p>This is one of the manifestations of what is called an “Application Binary Interface (ABI) Break”. ABI Breaks are generally undetectable, silent breaks that occur within the runtime of a program that completely destroy any dependency your program has on that functionality for correctness. It typically happens when a subtle detail – the registers used to negotiate a large integral value between a shared library and its application, the amount of padding a structure might have on a certain build, the ordering and layout of class members, the interpretation of bits even if the layout or passing convention of a type never changes, and even more – changes.</p>

<h2 id="but-c-is-abi-stable">“But C Is ABI-Stable?!”</h2>

<p>Not necessarily. C is a simple language, and it both sells itself on and prides itself as such. So much so, that it’s even part of the <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2021.htm">language’s rolling charter</a>. There’s barely any name mangling because there’s no overloading. If you want “virtual functions” you need to hand-craft your virtual table structure and initialize it yourself. There’s barely any lookup or entity negotiation: what you write – <a href="https://twitter.com/thingskatedid/status/1328918322507706368">however scary or cursed</a> – is what you get, in a general sense. (No, it’s not “portable assembly”. Compilers tear C code apart and make it far more efficient than the code people stuff into it. It’s not even a direct model of the machine anymore: just an abstract one.)</p>

<p>Still, sometimes even C can’t get away from it. The function <code>imaxabs</code> relates to exactly one entity that, for historical reasons, was pinned to a function taking and returning a <code>long long</code>. Upgrading it means dealing with this schism between what the user expects (<code>intmax_t</code> that got upgraded and can print <code>__int128_t</code>/<code>__int256_t</code>) with old, non-recompiled code that maintains the old invariant (<code>long long</code>, a 64-bit number).</p>



<p>Okay, so symbols can be repurposed between library versions that lead to ABI breaks. What are the ways to defend against such a world, in C?</p>

<h2 id="macros">Macros?</h2>

<p>Macros! Object-like macros are fun. You could do something like this…</p>

<div><div><pre><code><span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<p>… as a way to provide the <code>imaxabs</code> function. It is a bit like artisanal, hand-crafted, free-range, and organic ABI versioning (or, as I have affectionately come to call it: personal masochism to make up for language failures). This mostly works, until… it doesn’t!</p>

<h3 id="714">§7.1.4</h3>

<p>This is the “ABI Breaks Guaranteed” section in the C Standard. It’s real name is “§7.1.4 Use of library functions”. Reproduced below is the relevant piece that condemns us, emphasis mine:</p>

<blockquote>
  <p>Any function declared in a header may be additionally implemented as a function-like macro defined in the header, so if a library function is declared explicitly when its header is included, one of the techniques shown below can be used to ensure the declaration is not affected by such a macro. <strong>Any macro definition of a function can be suppressed locally by enclosing the name of the function in parentheses</strong>, because the name is then not followed by the left parenthesis that indicates expansion of a macro function name. For the same syntactic reason, it is permitted to take the address of a library function even if it is also defined as a macro. <strong>The use of <code>#undef</code> to remove any macro definition will also ensure that an actual function is referred to</strong>.</p>
</blockquote>

<p>Not only can a user suppress a function-like macro invocation by using the same trick used on <code>&lt;windows.h&gt;</code> like <code>(max)(value0, value1)</code>, but the C Standard Library permits them to also undefine function names:</p>

<div><div><pre><code><span>// implementer code: inttypes.h</span>
<span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<div><div><pre><code><span>// user code: main.c</span>
<span>#include &lt;inttypes.h&gt;
</span>
<span>#undef imaxabs // awh geez
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
	<span>intmax_t</span> <span>absval</span> <span>=</span> <span>imaxabs</span><span>(</span><span>val</span><span>);</span> <span>// awH GEEZ</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>absval</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Mmm……</p>

<h3 id="implementation-specific-strategies">Implementation-specific strategies</h3>

<p>Alright, the C Standard basically loads a double barrel and brings our only standardized mitigation strategy out back behind the barn. What’s left? Well, implementation-specific insanity, that’s what:</p>

<div><div><pre><code><span>extern</span>
<span>intmax_t</span>
<span>__glibc228_imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>

<span>__attribute</span><span>((</span><span>symbol</span><span>(</span><span>__MANGLE</span><span>(</span><span>__glibc228_imaxabs</span><span>))))</span>
<span>extern</span>
<span>intmax_t</span>
<span>imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>
</code></pre></div></div>

<p>This is pseudo-code. But, wouldn’t you believe it, some implementations actually do things very similar to this to get around these problems! The things they do are far more involved, like actually dropping down to the level of the linker and creating symbol maps and other exceedingly painful workarounds. The sed scripts and the awk scripts and the bash starts coming out, people are doing lots of text processing to get symbol names and match them to versioned symbol names…</p>

<p>It’s a mess.</p>

<p>Still, given the mess, it does save us from the problem. In C code you get to use “the real name” <code>imaxabs</code> as Our Lord and Savior intended, the binary gets linked to <code>___glibc228_imaxabs</code>, and everyone’s happy. There’s only one problem with this kind of fix…</p>

<p>It’s Quality of Implementation (QoI).</p>

<p>QoI is great for the pure, theoretical standard. We get to write sexy narratives in the C standard and call them “Recommended Practice”, with little footnotes furtively implying a more wonderful world while waggling our eyebrows seductively at hot, young developers in our area. Just come along, it’s going to be so great, we’re going have soooooo much fun, just go with that lovely little implementation right over there, you’re making such fine progress, enjoy yourself and come back soon my …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/intmax_t-hell-c++-c">https://thephd.github.io/intmax_t-hell-c++-c</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/intmax_t-hell-c++-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316933</guid>
            <pubDate>Sat, 05 Dec 2020 18:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Navel Gazing on Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25316908">thread link</a>) | @guycombinator
<br/>
December 5, 2020 | https://guycombinator.com/posts/navel-gazing-on-hacker-news | <a href="https://web.archive.org/web/*/https://guycombinator.com/posts/navel-gazing-on-hacker-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Being the internet-dabbling dilettante that I am, I often gaze longingly at the front page of Hacker News, wondering when my own content will reach it and <del>waste</del> merit the time of others. But alas, my time is precious, and I can't spend all day refreshing the browser to see when I've achieved my goal. Let's set something up to do that for me.</p>
<p><strong><em>Mission:</em></strong> Write a script that scans the front page of HN for the presence of this blog post. If we detect it, update this blog post, including the time from when it reached the front page. Run the script(s) periodically for a day before accepting inevitable defeat.</p>

<h2><a href="#how-is-this-going-to-work">How is this going to work?</a></h2>
<p>Nothing fancy here - let's approach each of these steps individually before gluing them together:</p>
<ol>
<li>Create a <code>go</code> script that scrapes the front page of HN for our post.</li>
<li>Create a <code>bash</code> script that calls the <code>go</code> script (and can tell whether it found our post or failed).</li>
<li>Create a periodically running job that runs the <code>bash</code> script.</li>
<li>
<p>Add conditional behaviors to the <code>bash</code> script:</p>
<ul>
<li>If the <code>go</code> script succeeds in finding our post: modify our post markdown (succeeded!), create a <code>git</code> commit, and push to <code>github</code> to trigger a deploy. Clear the job!</li>
<li>If the <code>go</code> script fails (and we're out of time): modify our post (failed), create a <code>git</code> commit, and push to <code>github</code> to trigger a deploy. Clear the job!</li>
<li>If the <code>go</code> script fails (and we have time left): log some information.</li>
</ul>
</li>
<li>Deploy the blog post, submit it to HN, and start the script!</li>
<li>Keep my computer awake and return in 24 hours.</li>
</ol>
<p>We can test the little pieces by handing the <code>go</code> script existing or fictional targets to search for on the front page of HN.</p>
<p>Sweet! Nothing to it but to do it. A few things to keep in mind before we start:</p>
<h4>High Level Caveats</h4>
<ol>
<li>I'm going to use <code>launchd</code> as my job scheduler because I'm working on a Mac. If you're on Linux, <span id="aside-os-scheduler" aside-content="Swapping in your own OS-specific scheduler is an exercise left to the reader! systemd is probably a reasonable place to start. 😇">you're going to need to use something else.<sup><a href="#aside-os-scheduler-note">1</a></sup></span></li>
<li>We will consider the "front page" to be anything in the top 30, since that's what loads on desktop before paginating. I may end up keeping track of "peak height reached", to salve my bruised ego - TBD.</li>
<li>We're going to run the script every 10 minutes for a day and then give up. Judging from the front page of HN <em>at this moment</em>, it looks like nothing is up there that's more than 24 hours old. If we don't reach the front page by then, we're fine with that.</li>
<li>We're going to write the results from running the script to a log file we can check later.</li>
</ol>
<p>Although there are practical applications of periodically scraping websites and doing things with the data, this is obviously not one of them. Let's get to it.</p>

<h2><a href="#scraping-hacker-news">Scraping Hacker News</a></h2>
<p>Here's what I'm envisioning running the <code>go</code> script will look like:</p>
<div data-language="shell-session"><pre><code><span><span>$</span> <span>go run gaze.go</span></span>
<span>- Scanning the front page of HN for our post...
Time: 14:13 EST (2020-11-30T14:13:23-05:00)
- Checking top 30 posts...
Did not find our post!

...

</span><span><span>$</span> <span>go run gaze.go</span></span>
<span>- Scanning the front page of HN for our post...
Time: 14:13 EST (2020-11-30T14:13:23-05:00)
- Checking top 30 posts...
We were 27/30 (front page!)</span></code></pre></div>
<p>So let's get started by using someone's <code>go</code> client for HN. <a href="https://github.com/peterhellberg/hn">This one</a> seems good enough. We can install it...</p>
<div data-language="shell-session"><pre><code><span><span>$</span> <span>go get -u github.com/peterhellberg/hn</span></span>
<span><span>$</span> <span>atom gaze.go</span></span></code></pre></div>
<p>...and mostly use the code we need straight from the repo's example usage (with a <span>few tweaks</span>):</p>
<div data-language="go"><pre><code><span>package</span> main


<span>import</span> <span>(</span>
  <span>"fmt"</span>
<span>  <span>"os"</span></span>  <span>"time"</span>
  <span>"github.com/peterhellberg/hn"</span>
<span>)</span>

<span>func</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  hn <span>:=</span> hn<span>.</span>DefaultClient
  fmt<span>.</span><span>Println</span><span>(</span><span>"- Scanning the front page of HN for our post..."</span><span>)</span>
  now <span>:=</span> time<span>.</span><span>Now</span><span>(</span><span>)</span>
  fmt<span>.</span><span>Printf</span><span>(</span><span>"Time: %s (%s)\n"</span><span>,</span> now<span>.</span><span>Format</span><span>(</span><span>"15:04 EST"</span><span>)</span><span>,</span>
    now<span>.</span><span>Format</span><span>(</span>time<span>.</span>RFC3339<span>)</span><span>)</span>

  ids<span>,</span> err <span>:=</span> hn<span>.</span><span>TopStories</span><span>(</span><span>)</span>
  <span>if</span> err <span>!=</span> <span>nil</span> <span>{</span>
    <span>panic</span><span>(</span>err<span>)</span>
  <span>}</span>

  fmt<span>.</span><span>Println</span><span>(</span><span>"- Checking top 30 posts..."</span><span>)</span>
  <span>for</span> i<span>,</span> id <span>:=</span> <span>range</span> ids<span>[</span><span>:</span><span>30</span><span>]</span> <span>{</span>
    item<span>,</span> err <span>:=</span> hn<span>.</span><span>Item</span><span>(</span>id<span>)</span>
    <span>if</span> err <span>!=</span> <span>nil</span> <span>{</span>
      <span>panic</span><span>(</span>err<span>)</span>
    <span>}</span>

    <span>if</span> <span>(</span>item<span>.</span>Title <span>==</span> <span>"Navel Gazing on Hacker News"</span><span>)</span> <span>{</span>
      fmt<span>.</span><span>Println</span><span>(</span><span>"We were"</span><span>,</span> i<span>,</span> <span>"(front page!)"</span><span>)</span>
      fmt<span>.</span><span>Println</span><span>(</span>i<span>,</span> <span>"–"</span><span>,</span> item<span>.</span>Title<span>,</span> <span>"\n   "</span><span>,</span> item<span>.</span>URL<span>)</span>
<span>      os<span>.</span><span>Exit</span><span>(</span><span>0</span><span>)</span></span>    <span>}</span>
  <span>}</span>

  fmt<span>.</span><span>Println</span><span>(</span><span>"Did not find our post!"</span><span>)</span>
<span>  os<span>.</span><span>Exit</span><span>(</span><span>1</span><span>)</span></span><span>}</span></code></pre></div>
<p>I'm using <code>os.Exit</code> to hand back a status code. We're going to use a <span id="aside-exit-status" aside-content="We're being slightly dishonest here, since this outcome is expected and nothing actually 'went wrong' per se, but it's a convenient mechanism for conditionalizing behavior from the calling context of this script.">non-zero status<sup><a href="#aside-exit-status-note">2</a></sup></span> to indicate that a process errored. Let's run it and see what happens. I haven't posted yet, so we should just fail to find our post.</p>
<div data-language="shell-session"><pre><code><span><span>$</span> <span>go run gaze.go</span></span>
<span>- Scanning the front page of HN for our post...
Time: 14:21 EST (2020-11-30T14:21:17-05:00)
- Checking top 30 posts...
Did not find our post!
exit status 1</span></code></pre></div>
<p>The call to <code>os.Exit()</code> <em>does</em> output some information, but we're fine with that. Looks good though - onwards and upwards.</p>

<h2><a href="#creating-a-bash-script">Creating a bash script</a></h2>
<p>We need to make a <code>bash</code> script that calls the <code>go</code> script. Keeping it as simple as possible:</p>
<div data-language="shell"><pre><code><span>#!/bin/bash</span>


<span>echo</span> <span>"Running navel.sh"</span>
<span>ret</span><span>=</span><span><span>$(</span>go run gaze.go<span>)</span></span>
<span>echo</span> <span>"<span>$ret</span>"</span></code></pre></div>
<p>Let's set it as executable and run it:</p>
<div data-language="shell-session"><pre><code><span><span>$</span> <span><span>chmod</span> <span>755</span> navel.sh</span></span>
<span><span>$</span> <span>./navel.sh</span></span>
<span>Running navel.sh
exit status 1
- Scanning the front page of HN for our post...
Time: 15:05 EST (2020-11-30T15:05:32-05:00)
- Checking top 30 posts...
Did not find our post!</span></code></pre></div>
<p>The exit status is echoed a little out of the order I'd expect, but that's fine for now.</p>

<h2><a href="#spinning-up-a-periodic-job">Spinning up a periodic job</a></h2>
<p>Half the fun of this is getting my computer to check regularly for me instead of pounding <code>cmd + r</code>. I initially looked into using <code>cron</code> and <code>crontab</code>, and saw the following when I ran <code>man crontab</code>:</p>
<div><p>...(Darwin note: Although cron(8) and crontab(5) are officially supported under Darwin, their functionality has been absorbed into launchd(8), which provides a more flexible way of automatically executing commands.  See launchctl(1) for more information.)</p></div>
<p>I figure that this is a quiet way of saying "might be deprecated soon" so I'm going to use the more contemporary set of tools (<code>launchd</code>) for our script.</p>
<p>How can we create a <code>launchd</code> job? I feel like I've done this in a past life, but I followed <a href="https://medium.com/@chetcorcos/a-simple-launchd-tutorial-9fecfcf2dbb3">this useful walkthrough</a> by <a href="https://medium.com/@chetcorcos">Chet Corcos</a> to refresh my memory. For <a href="https://www.launchd.info/">reference</a>:</p>
<div><p>(launchd is) a unified, open-source service management framework for starting, stopping and managing daemons, applications, processes, and scripts.</p></div>
<p>...and <code>launchctl</code> is the command line tool we can use to start and stop those processes. We're basically going to create an <code>XML</code> file describing when to run our job and how frequently, and add it to the set of jobs that my computer is already running periodically using <code>launchctl load ~/Library/LaunchAgents/foo</code>. Unsurprisingly, we can unload the script with <code>launchctl unload ...</code>, referencing the same filepath.</p>
<p>Here's what my basic job looks like (<code>~/Library/LaunchAgents/com.gc.navel.plist</code>):</p>
<div data-language="xml"><pre><code><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span>&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;</span>
<span><span><span>&lt;</span>plist</span> <span>version</span><span><span>=</span><span>"</span>1.0<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>dict</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>key</span><span>&gt;</span></span>Label<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>string</span><span>&gt;</span></span>com.gc.navel.plist<span><span><span>&lt;/</span>string</span><span>&gt;</span></span>

    <span><span><span>&lt;</span>key</span><span>&gt;</span></span>RunAtLoad<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>true</span><span>/&gt;</span></span>

    <span><span><span>&lt;</span>key</span><span>&gt;</span></span>StartInterval<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>integer</span><span>&gt;</span></span>600<span><span><span>&lt;/</span>integer</span><span>&gt;</span></span>

    <span><span><span>&lt;</span>key</span><span>&gt;</span></span>StandardErrorPath<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>string</span><span>&gt;</span></span>/Users/scott/home/navel/err.log<span><span><span>&lt;/</span>string</span><span>&gt;</span></span>

    <span><span><span>&lt;</span>key</span><span>&gt;</span></span>StandardOutPath<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>string</span><span>&gt;</span></span>/Users/scott/home/navel/out.log<span><span><span>&lt;/</span>string</span><span>&gt;</span></span>

    <span><span><span>&lt;</span>key</span><span>&gt;</span></span>EnvironmentVariables<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>dict</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>key</span><span>&gt;</span></span>PATH<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
      <span><span><span>&lt;</span>string</span><span>&gt;</span></span><span>&lt;![CDATA[/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin]]&gt;</span><span><span><span>&lt;/</span>string</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>dict</span><span>&gt;</span></span>

<span>    <span><span><span>&lt;</span>key</span><span>&gt;</span></span>WorkingDirectory<span><span><span>&lt;/</span>key</span><span>&gt;</span></span></span><span>    <span><span><span>&lt;</span>string</span><span>&gt;</span></span>/Users/scott/home/guycombinator/<span><span><span>&lt;/</span>string</span><span>&gt;</span></span></span>
<span>    <span><span><span>&lt;</span>key</span><span>&gt;</span></span>ProgramArguments<span><span><span>&lt;/</span>key</span><span>&gt;</span></span></span><span>    <span><span><span>&lt;</span>array</span><span>&gt;</span></span></span><span>      <span><span><span>&lt;</span>string</span><span>&gt;</span></span>/Users/scott/home/navel/navel.sh<span><span><span>&lt;/</span>string</span><span>&gt;</span></span></span>    <span><span><span>&lt;/</span>array</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>dict</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>plist</span><span>&gt;</span></span></code></pre></div>
<p>Simple enough - the <code>XML</code> file is a set of key value pairs that define a script to run (<code>ProgramArguments</code>), a frequency to run at (<code>StartInterval</code>, measured in seconds), and some output paths and environment information (<code>WorkingDirectory</code>, <code>EnvironmentVariables</code>, etc.). Note that right now we've configured the job to run every 10 minutes, which we may want to tweak for debugging later. Also notice that the <span id="aside-directory-structure" aside-content="Obviously your directory structure might look completely different, so do what makes sense if you're following along at home.">working directory doesn't match<sup><a href="#aside-directory-structure-note">3</a></sup></span> the output paths I've referenced, and that I've moved the script to a separate directory too. I don't really want this code living in the repo for my blog, even though that's where we want to run the script (to possibly modify the markdown post and push with <code>git</code>).</p>
<div data-language="shell-session"><pre><code><span><span>$</span> <span><span>cd</span> ~/home</span></span>
<span><span>$</span> <span><span>mkdir</span> navel</span></span>
<span><span>$</span> <span>tree -L <span>1</span> <span>|</span> <span>grep</span> -E <span>"(navel|guycom)"</span></span></span>
<span>├── guycombinator
├── navel
</span><span><span>$</span> <span><span>mv</span> guycombinator/navel.sh navel/</span></span></code></pre></div>
<p>Nice. We've enabled <code>RunAtLoad</code>, so the script will run immediately. Let's see that everything still "works" by loading the job and checking <code>out.log</code> and <code>err.log</code>:</p>
<div data-language="shell-session"><pre><code><span><span>$</span> <span>launchctl load ~/Library/LaunchAgents/com.gc.navel.plist</span></span>
<span><span>$</span> <span><span>cd</span> ~/home/navel</span></span>
<span><span>$</span> <span><span>cat</span> out.log</span></span>
<span>Running navel.sh

</span><span><span>$</span> <span><span>cat</span> err.log</span></span>
<span>/Users/scott/home/navel/navel.sh: line 6: go: command not found
/Users/scott/home/navel/navel.sh: line 6: go: command not found</span></code></pre></div>
<p>Aha - it doesn't look like the job knows how to run <code>go</code> commands. We need to make sure that the <code>&lt;EnvironmentVariables/&gt;</code> <code>ENV</code> value includes our <code>go</code> binary. Easy enough to fix:</p>
<div data-language="shell-session"><pre><code><span><span>$</span> <span><span>which</span> go</span></span>
<span>/Users/local/go/bin/go</span></code></pre></div>
<p>So lets add <em>the directory where</em> <code>go</code> <em>is located</em> (<code>/Users/local/go/bin</code>) to the end of our set of directories to look for executables (<code>PATH</code>) in the <code>plist</code> file:</p>
<div data-language="xml"><pre><code>...
<span><span><span>&lt;</span>key</span><span>&gt;</span></span>EnvironmentVariables<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
<span><span><span>&lt;</span>dict</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>key</span><span>&gt;</span></span>PATH<span><span><span>&lt;/</span>key</span><span>&gt;</span></span>
<span>  <span><span><span>&lt;</span>string</span><span>&gt;</span></span><span>&lt;![CDATA[/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/go/bin]]&gt;</span><span><span><span>&lt;/</span>string</span><span>&gt;</span></span></span><span><span><span>&lt;/</span>dict</span><span>&gt;</span></span></code></pre></div>
<p>Once more, with feeling:</p>
<div data-language="shell-session"><pre><code><span><span>$</span> <span>launchctl unload ~/Library/LaunchAgents/com.gc.navel.plist</span></span>
<span><span>$</span> <span><span>rm</span> err.log out.log</span></span>
<span><span>$</span> <span>launchctl load ~/Library/LaunchAgents/com.gc.navel.plist</span></span>
<span><span>$</span> <span><span>sleep</span> <span>30</span><span>;</span> <span>cat</span> out.log</span></span>
<span>Running navel.sh
- Scanning the front page of HN for our post...
Time: 12:27 EST (2020-12-01T12:27:04-05:00)
- Checking top 30 posts...
Did not find our post!
exit status 1</span></code></pre></div>
<p>It takes a few seconds on my machine to fetch the results, we're waiting a bit with <code>sleep</code> before we check for results. But it worked! So let's add some slightly more complex behaviors based on the result of the script running.</p>

<h2><a href="#conditionalizing-the-bash-script">Conditionalizing the bash script</a></h2>
<p>Let's make sure it can do different things based on the execution of our script. To get the exit code back from a bash script, we can use the special variable <code>$?</code>.</p>
<div data-language="shell"><pre><code><span>#!/bin/bash</span>


<span>echo</span> <span>"Running navel.sh"</span>

<span>ret</span><span>=</span><span><span>$(</span>go run gaze.go<span>)</span></span>

<span>EXIT_CODE</span><span>=</span><span>$?</span>

<span>if</span> <span>[</span> <span>${EXI…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://guycombinator.com/posts/navel-gazing-on-hacker-news">https://guycombinator.com/posts/navel-gazing-on-hacker-news</a></em></p>]]>
            </description>
            <link>https://guycombinator.com/posts/navel-gazing-on-hacker-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316908</guid>
            <pubDate>Sat, 05 Dec 2020 18:28:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Founder ISA as Investment Model]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25316896">thread link</a>) | @dustingetz
<br/>
December 5, 2020 | https://investinme.vc/how-it-works | <a href="https://web.archive.org/web/*/https://investinme.vc/how-it-works">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      
      
      <div data-type="page-section" id="page-section-5f74c273cbe3615032055af1"><div><div><div data-block-type="2" id="block-3b03fb3478c96914c440"><div><h2>How does investinme work?? 🧐&nbsp;</h2><p>Invest In Me allows your network to invest in you to work on your project full-time. You will then pay back your investors over time via an income share agreement.</p><h3>About <strong>Income Share Agreements</strong></h3><p>An Income Share Agreement (ISA) allows for individuals to seek funding without requiring their investors to take a massive risk.&nbsp;</p><p>‍<br>We found that many Friends and Family funding rounds and Pre-Seed funding rounds by startup founders happen when the business is still incredibly risky. With an incredibly high chance of failure, it is almost always a bad investment to make. At these early stages of a venture, the investors are usually investing based on their confidence in the founder more than any other factor. With that in mind, we believe it makes sense to provide founders with an investment vehicle that matches investors’ thought processes. That is where Income Share Agreements (ISAs) come into play. An ISA allows for investors to invest in a founder, with the potential to profit from the founder’s success. This means that an investor could profit if the founder is successful with their second or even third venture, instead of the investor’s money completely riding on the founder’s first venture.&nbsp;<br>‍<br>While this investment vehicle is not wiped out when an entity goes out of business, it also does not put a founder into long-term debt. There is no guarantee that a founder will pay back the entire amount of the initial investment, making the investment potentially more risky than a standard loan. But, since the investment does not go away with an entity, the investment is potentially less risky than an equity investment.<br>‍<br>We believe that ISAs are most useful when a startup founder needs capital to build their Minimum Viable Product, which is typically where a Friends and Family round happens.&nbsp;<br>‍<br>We also believe that ISAs are great alternatives to loans and are versatile to fit many different applications. From our research and customer development initiatives, we have found people who want to utilize ISAs for startup funding, working capital as a freelancer, student financing, debt refinancing or consolidation, and many other applications.&nbsp;</p><h2>ISA Examples</h2><p><strong>Basic Terms of an ISA</strong></p><ul data-rte-list="default"><li><p>Dollar amount of investment</p></li><li><p>Percentage of income each year</p></li><li><p>Max duration of income sharing</p></li><li><p>Capped pay-back amount</p></li></ul><p><strong>Example of an ISA and two scenarios</strong></p><ul data-rte-list="default"><li><p>You borrow $100k</p></li><li><p>Terms are 10% of income for 10 years, 3x pay-back cap</p></li></ul><p><em>Scenario 1</em></p><ul data-rte-list="default"><li><p>You start making money from your business 2 years after getting funded through Invest In Me’s ISA.</p></li><li><p>You make $100k/yr for the next 5 years and then sell your business, making $10m from the sale.</p></li><li><p>You have paid back $50k from your annual income and $250k from the sale of your business, hitting the 3x cap on the ISA.&nbsp;</p></li></ul><p><em>Scenario 2</em></p><ul data-rte-list="default"><li><p>You work on your business for 3 years, making no money. Your business fails and you decide to move on and get a job.&nbsp;</p></li><li><p>You make $60k/yr for the next 10 years. (Duration of the ISA is deferred while you were starting out and not earning anything.)</p></li><li><p>You have paid back $60k from your annual income and the ISA ends, leaving you debt-free.</p></li></ul><p>‍</p><p><strong>Other terms an ISA could contain</strong></p><ul data-rte-list="default"><li><p>Delay start of “duration” until first annual income over $40k happens</p></li><li><p>Years of under $40k income are exempt and deferred, extending the “duration”</p></li><li><p>Protections against stashing income in an S-corp to avoid paying on an ISA</p></li><li><p>Protections against taking a minimal income in order to “ride out” the term of the ISA before taking dividends from your business or selling it for a profit</p></li><li><p>No prepayment penalty, but also no prepayment discount on the capped pay-back.&nbsp;</p></li><li><p>Audit rights of personal tax returns, pay stubs, and bank statements.</p></li></ul><h2>Why are we doing this?? 🤯</h2><div><p>Invest In Me is currently providing a way for startup founders to raise capital through an easier means. Our future will add to this and continue on our mission to increase people's access to capital.</p><p>Our intentions are to build a crowd-lending platform to allow for anyone to raise capital from the crowd via income share agreements. That's about as much as we can tell you right now. If you are interested in staying up-to-date on our progress, follow us on&nbsp;<a href="https://twitter.com/InvestInMeVC" target="_blank">Twitter</a>.</p></div><h2>‍</h2></div></div></div></div></div>
    </div>
  </div></div>]]>
            </description>
            <link>https://investinme.vc/how-it-works</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316896</guid>
            <pubDate>Sat, 05 Dec 2020 18:26:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 'At My Last Place ' Problem]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25316818">thread link</a>) | @techcodes
<br/>
December 5, 2020 | https://www.shayon.dev/post/2020/330/the-at-my-last-place...-problem/ | <a href="https://web.archive.org/web/*/https://www.shayon.dev/post/2020/330/the-at-my-last-place...-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody" id="content"><p>The “At my last place…” problem, or also commonly discussed as</p><p><em>‘xooglers always be like “at google we…”’</em> — <a href="https://twitter.com/devonbl/status/1329905383175929858">twitter</a></p><p>If you have been working at a place for a while and switch to a new gig, you may find yourself making a comparison or drawing from your past experiences about a project, tool, tech, or process you are working on. In fairness, I feel like Xooglers get a bad rap. Since in my limited experience, I have noticed this to be just as true for folks from any other tech company - AirBnb, Uber, Stripe, or similar.</p><p>It’s not uncommon for humans to draw comparisons or use past learning to inform a future decision. It’s something I faced too after my time at Intercom. Then every time, I began a sentence with “At my place…” I mentally put a dollar in a jar while feeling a rush of cringe through my body. On the one hand, I felt horrible for not bringing a rational, unbiased mind to a conversation. On the other hand, I considered the comparison a useful thought experiment to tease out the details.</p><p>Drawing from a past experience, naming a company, technology, or referencing a white paper are also some ways of bringing credibility to the table while sharing an honest opinion. In fairness, I looked back to all kinds of experiences, especially the ones with lessons learnt.</p><p>The problem to avoid here is not to get into a rut of doing something just because that’s how X company or team operated in the past. Or because it makes the decision process more comfortable, so you patch the problem at hand and move on to the next things.</p><p>You may notice that often what is also being proposed is a solution that more or less addresses the problem. Still, folks get too involved in solutionizing, so they miss the sight of the original problem. Going back to first principles is a nice way to reset the ground. Asking questions like “Does this address the problem, we are facing here today?” or “What problem is it trying to solve?” can be helpful.</p><p>One thing to remember is not giving yourself a hard time. Its also why companies hire people with past experiences so you can bring that knowledge and expertise to help solve current problems.</p><p>A smart person once said, “The important thing is not to stop questioning”. And I think that’s what matters at the end of the day is to be able to innovate while being fair.</p></article></div>]]>
            </description>
            <link>https://www.shayon.dev/post/2020/330/the-at-my-last-place...-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316818</guid>
            <pubDate>Sat, 05 Dec 2020 18:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Distributed Systems Fail]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25316475">thread link</a>) | @parsecs
<br/>
December 5, 2020 | https://robertovitillo.com/how-distributed-systems-fail/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/how-distributed-systems-fail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>December 05, 2020</p></header><p>At scale, any failure that can happen will eventually happen. Hardware failures, software crashes, memory leaks - you name it. The more components you have, the more failures you will experience.</p><p>This nasty behavior is caused by <em>cruel math</em> - given an operation that has a certain probability of failing, as the total number of operations performed increases, so does the total number of failures. In other words, as you scale out your application to handle more load, the more failures it will experience.</p><p>To protect your application against failures, you first need to know what can go wrong. Assuming you are using a cloud provider and not maintaning your own datacenter, the most common failures you will encounter are caused by single points of failure, the network being unreliable, slow processes, and unexpected load.</p><h2 id="single-point-of-failure"><a href="#single-point-of-failure" aria-label="single point of failure permalink"></a>Single Point of Failure</h2><p>A single point of failure is the most glaring cause of failure in a distributed system - it’s that one component that when it fails brings down the entire system with it. In practice, distributed systems can have multiple single points of failure.</p><p>A service that to start up needs to read its configuration from a non-replicated database is an example of a single point of failure - if the database isn’t reachable, the service won’t be able to start. </p><p>A more subtle example is a service that exposes a HTTP API on top of TLS and uses a certificate that needs to be manually renewed. If the certificate isn’t renewed by the time it expires, then most clients trying to connect to it wouldn’t be able to open a connection with the service. </p><p>Single points of failure should be identified when the system is architected before they can cause any harm. The best way to detect them is to examine every component of the system and ask what would happen if that component were to fail. Some single points of failure can be architected away, e.g., by introducing redundancy, while others can’t. In that case, the only option left is to minimize the blast radius.</p><h2 id="unreliable-network"><a href="#unreliable-network" aria-label="unreliable network permalink"></a>Unreliable Network</h2><p>When a client make a remote network call, it sends a request to a server and expects to receive a response from it a while later. In the best case, the client receives a response shortly after sending the request. But what if the client waits and waits and still doesn’t get a response? </p><p>In that case, the client doesn’t know whether a response will eventually arrive or not. At that point it has only two options, it can either continue to wait, or fail the request with an exception or an error.</p><p>Slow network calls are the <a href="https://robertovitillo.com/default-timeouts/">silent killers</a> of distributed systems. Because the client doesn’t know whether the response is on its way or not, it can spend a long time waiting before giving up, if it gives up at all. The wait can in turn cause degradations that are extremely hard to debug. </p><h2 id="slow-processes"><a href="#slow-processes" aria-label="slow processes permalink"></a>Slow Processes</h2><p>From an observer’s point of view, a very slow process is not very different from one that isn’t running at all - neither can perform useful work. Resource leaks are one of the most common causes of slow processes.</p><p>Memory leaks are arguably the most well-known source of leaks. A memory leak manifests itself with a steady increase in memory consumption over time. Run-times with garbage collection don’t help much either - if a reference to an object that isn’t longer needed is kept somewhere, the object won’t be deleted by the garbage collector. </p><p>A memory leak keeps consuming memory until there is no more of it, at which point the operating system starts swapping memory pages to the disk constantly, all the while the garbage collector kicks in more frequently trying its best to release any shred of memory. The constant paging and the garbage collector eating up CPU cycles make the process slower. Eventually, when there is no more physical memory, and there is no more space in the swap file, the process won’t be able to allocate more memory, and most operations will fail.</p><p>Memory is just one of the many resources that can leak. For example, if you are using a thread pool, you can lose a thread when it blocks on a synchronous call that never returns. If a thread makes a synchronous, and blocking, HTTP call <a href="https://robertovitillo.com/default-timeouts/">without setting a timeout</a>, and the call never returns, the thread won’t be returned to the pool. Since the pool has a fixed size and keeps losing threads, the pool will eventually run out of threads. </p><p>You might think that making <em>asynchronous</em> calls, rather than a synchronous ones, would mitigate the problem in the previous case. But, modern HTTP clients use socket pools to avoid recreating TCP connections and pay a <a href="https://robertovitillo.com/what-every-developer-should-know-about-tcp/">hefty performance fee</a>. If a request is made without a timeout, the connection is never returned to the pool. As the pool has a limited size, eventually there won’t be any connections left to communicate with the host.</p><p>On top of all that, the code you write isn’t the only one accessing memory, threads and sockets. The libraries your application depends on access the same resources, and they can do all kinds of shady things. Without digging into their implementation, assuming it’s open in the first place, you can’t be sure whether they can wreak havoc or not.</p><h2 id="unexpected-load"><a href="#unexpected-load" aria-label="unexpected load permalink"></a>Unexpected Load</h2><p>Every system has a limit to how much load it can withstand without scaling. Depending on how the load increases, you are bound to hit that brick wall sooner or later. But one thing is an organic increase in load, which gives you the time to scale your service out accordingly, and another is a sudden and unexpected spike.</p><p>For example, consider the number of requests received by a service in a period of time. The rate and the type of incoming requests can change over time, and sometimes suddenly, for a variety of reasons:</p><ul><li>The requests might have a seasonality - depending on the hour of the day the service is going to get hit by users in different countries.</li><li>Some requests are much more expensive than others and abuse the system in ways you didn’t really anticipate for, like scrapers slurping in data from your site at super human speed.</li><li>Some requests are malicious - think of DDoS attacks which try to saturate your service’s bandwidth, denying access to the service to legitimate users.</li></ul><h2 id="cascading-failures"><a href="#cascading-failures" aria-label="cascading failures permalink"></a>Cascading Failures</h2><p>You would think that if your system has hundreds of processes, it shouldn’t make much of a difference if a small percentage are slow or unreachable. The thing about faults is that they tend to spread like cancer, propagating from one process to the other until the whole system crumbles to its knees. This effect is also referred to as a <em>cascading failure</em>, which occurs when a portion of an overall system fails, increasing the probability that other portions fail.</p><p>For example, suppose there are multiple clients querying two database replicas A and B, which are behind a load balancer. Each replica is handling about 50 transactions per second.</p><p>{width: 75%}
<span>
      <a href="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/67fe0/cascading_failure_1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cascading failure 1" title="cascading failure 1" src="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/fcda8/cascading_failure_1.png" srcset="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/12f09/cascading_failure_1.png 148w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/e4a3f/cascading_failure_1.png 295w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/fcda8/cascading_failure_1.png 590w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/efc66/cascading_failure_1.png 885w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/67fe0/cascading_failure_1.png 1101w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>Suddenly, replica B becomes unavailable because of a network fault. The load balancer detects that B is unavailable and removes it from its pool. Because of that, replica A has to pick up the slack for replica B, doubling the load it was previously under. </p><p>{width: 75%}
<span>
      <a href="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/561da/cascading_failure_2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cascading failure 2" title="cascading failure 2" src="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/fcda8/cascading_failure_2.png" srcset="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/12f09/cascading_failure_2.png 148w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/e4a3f/cascading_failure_2.png 295w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/fcda8/cascading_failure_2.png 590w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/efc66/cascading_failure_2.png 885w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/561da/cascading_failure_2.png 969w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>As replica A starts to struggle to keep up with the incoming requests, the clients experience more failures and timeouts. In turn, they retry the same failing requests several times, adding insult to injury. </p><p>Eventually, replica A is under so much load that it can no longer serve requests promptly, and becomes for all intent and purposes unavailable, causing replica A to be removed from the load balancer’s pool. In the meantime, replica B becomes available again and the load balancer puts it back in the pool, at which point it’s flooded with requests that kill the replica instantaneously. This feedback loop of doom can repeat several time.</p><p>Cascading failures are very hard to get under control once they have started. The best way to mitigate one is to not have it in the first place by stopping the cracks in your services to propagate to others.</p><h2 id="defense-mechanisms"><a href="#defense-mechanisms" aria-label="defense mechanisms permalink"></a>Defense Mechanisms</h2><p>There is a variety of best practices you can use to mitigate failures, like circuit breakers, load shedding, rate-limiting and bulkheads. I plan to blog about those in the future, but in the meantime Google is your friend. Also, I have an entire chapter dedicated to resiliency patterns in my <a href="https://distributedsystemsmanual.com/">book about distributed systems</a>. </p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/how-distributed-systems-fail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316475</guid>
            <pubDate>Sat, 05 Dec 2020 17:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of Walking]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25316328">thread link</a>) | @KlimYadrintsev
<br/>
December 5, 2020 | https://klimy.co/blog/benefits-of-walking | <a href="https://web.archive.org/web/*/https://klimy.co/blog/benefits-of-walking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>How long does it take to walk 1 mile?</h2>
<p>As both research and actual scientific measurements, an average adult will walk 1 mile in 15 to 18 minutes at moderate to a brisk pace. Or in other words, 3 to 4 miles per hour.</p>
<p>This is a general measure for a healthy adult between 20 and 50 years old, at dry weather, on relatively flat terrain, with no destruction from cars and other environments.</p>
<p>If you are either less healthy or subjected to any of the environmental distractions, your speed, of course, will be lower.</p>
<h2>Average walking speed by age group and gender</h2>
<p>There is little difference between male and female, with males walking on average 2% faster.</p>
<p>The table below shows the speed of walking based on age and gender:</p>
<pre><code>| Age      | Sex    | Meters per second | Miles per hour |
|----------|--------|-------------------|----------------|
| 20 to 29 | Male   | 1.36              | 3.04           |
|          | Female | 1.34              | 3.0            |
| 30 to 39 | Male   | 1.43              | 3.2            |
|          | Female | 1.34              | 3.0            |
| 40 to 49 | Male   | 1.43              | 3.2            |
|          | Female | 1.39              | 3.11           |
| 50 to 59 | Male   | 1.43              | 3.2            |
|          | Female | 1.31              | 2.93           |
| 60 to 69 | Male   | 1.34              | 3.0            |
|          | Female | 1.24              | 2.77           |
| 70 to 79 | Male   | 1.26              | 2.82           |
|          | Female | 1.13              | 2.53           |
| 80 to 89 | Male   | 0.97              | 2.17           |
|          | Female | 0.94              | 2.10           |
</code></pre>
<h2>Benefits of walking</h2>
<p>There has been a great deal of research that showed that walking brings a huge advantage to humans. To both <a href="https://journals.sagepub.com/doi/abs/10.1177/0013916518800798">physical, and mental well being.</a> The benefits are as follows:</p>
<p>Physical:</p>
<ul>
<li>Burning calories. A direct way to reduce and to control your weight.</li>
<li>Lower glucose level and blood sugar levels. <a href="https://care.diabetesjournals.org/content/early/2013/06/03/dc13-0084">Research</a> has focused on short walks, where it helped reduce glucose intolerance.</li>
<li><a href="https://bjsm.bmj.com/content/45/12/987?sid=fe62a8c5-430b-4506-b854-20b62e8a5e9e">Help deal with infection and possibly Covid.</a></li>
<li>Help boost immune function.</li>
<li>Give additional energy to do other tasks due to increased efficiency of nutrients absorption and conversion.</li>
<li>Prolonging life. There is a <a href="https://bjsm.bmj.com/content/52/12/761">research that showed</a> evidence of having a relationship between physical activity and overall life expectancy. </li>
<li>Strengthen the heart. Even 20 minutes of daily walking has shown to reduce the risk of stroke by at least 20%.</li>
</ul>
<p>Mental:</p>
<ul>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving self esteem</a> by 45%.</li>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving mood</a> by 54%.</li>
<li>Additional time on focusing on self-education with educational podcasts and books. <a href="https://digitalcommons.georgiasouthern.edu/nyar_savannah/2020/2020/90/">Research</a> has shown that it leads to better learning of the material, longer retention, better engagement in post-walk discussions, better behaviour and mood, AND improved health literacy.</li>
<li>Improving <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">goal setting</a> in other areas by targeting non-specific goals which in consequence lead to better results.</li>
<li>Walking helps you get your thoughts in order. Whenever you are alone with yourself, and you are unable to really look at the phone, you are finally able to understand what is happening with yourself with no distractions.</li>
<li>Improve the creative part of the brain. While walking, <a href="https://psycnet.apa.org/record/2014-14435-001">research showed</a>, that it is easier to come up with great ideas.</li>
<li>Save money on medications. With the amount of food, we consume and with costly medicine, walking and doing exercises can help you save money and nerves.</li>
</ul>
<h2>Covid and sitting time</h2>
<p>In the world of pandemics and covid, it has been evident that humans are sitting more and more and do less and less exercises. There is a <a href="https://www.sciencedirect.com/science/article/pii/S221133552030214X">great research</a> that shows that 2020 has caused a sharp increase in average sitting time. The data is staggering.</p>
<p><code>Overall, 42.6% of participants reported sitting for &gt; 8 h/day (95% CI: 41.2%–44.0%) and 72.5% (71.2%–73.7%) reported being either sufficiently (150–300 MVPA minutes) or highly active (&gt;300 min).</code></p>
<p>If you want to boost your health and still to be able to keep up with a busy schedule walking or running can be the best idea for spending your free time. In the world where only entertainment inside your house is minimal. If being glued to the screen is no longer an option, than being outside can boost your health and your mental capabilities immensely.</p>
<p><img alt="walking in the park grass and women leg" src="https://i.gyazo.com/ecae9926d17ad69ded99b1a445482e9a.jpg"></p>
<h2>Tips on how to start walking</h2>
<h3>How to make walking a habit?</h3>
<p>The walk starts with the first step. It would be best if you did not put huge goals onto yourself. Start somewhere small, then later you can always adjust based on how you feel.</p>
<p>Start by putting on clothes(plus a mask) and go outside. Going back to your apartment would feel bad at that point.</p>
<p>Next, you should walk around your building or up and down the street.</p>
<p>Next, you walk around the block and later you can finally go for huge walks that can be a couple of hours long.</p>
<p>Don’t try to start at the last step that would only make you quit before you get the full benefit of the habit.</p>
<p>Peg your walking habit to something else. If you go for a coffee every morning, go to a coffee house that is further away. If you are usually riding a tube to work, start the journey at the stop further away from you</p>
<h3>Identify as a walker</h3>
<p>If you would like to start walking you need to think of <strong>how do you become a walker.</strong></p>
<p>You need to make sure you identify as someone who goes on walks, then keeping up with the habit will be much easier.</p>
<p>Next time someone asks you, whatever you do any exercises or what you love doing with your free time, you need to want to say that you love walking. At that point, you will be able to keep on walking and improving your health immensely.</p>
<h2>How much walking per week is enough?</h2>
<p>I think that it is tough to give a simple number for everyone, but if you are in the age range of 18-50, then:</p>
<ul>
<li>150 to 300 minutes per week is an ideal level if you are walking with moderate speed</li>
<li>75 to 150 minutes per week if you are walking with a brisk pace.</li>
</ul>
<p>Don’t think that doing extra physical exercise will be useless. In contrast, anything above that time limit will give even higher benefits to your health, so take the timing above as a general guideline. Do as much as you want.</p>
<h2>Personal tips on walking more</h2>
<h3>Wake up earlier</h3>
<p>Right now it is very easy to blame everything on covid and health, but not many people <a href="https://klimy.co/blog/how-to-wake-up-early">wake up very early in the morning</a>, that gives people that live in the city an ability to walk as much as they want, even in usually crowded spaces.</p>
<p>Also, your excuse of not having enough time can not be reinforced if you have an extra hour in the morning.</p>
<h3>Get a pet (dog)</h3>
<p>Even though it can seem like a lousy idea, multiple research papers show a relationship between owning a dog and the number of steps you do daily. If you are struggling to make time, your favourite pet will make you find time for walks.</p>
<p><img alt="man and dog walking in forest autumn" src="https://i.gyazo.com/5e16de8c0474f84f4285df88fab28c14.jpg"></p>
<h3>Podcasts and Audiobooks</h3>
<p>I love learning and listening to books. I do it all the time even when I am at home at my desk, so a change of pace for me is always going for an extended walk where I can do the same thing.</p>
<p>What I discovered is that I understand and remember information much better when I have consumed it while walking. That makes me spend twice as little time and getting twice the result. </p>
<p>Podcasts have been my go-to method of getting new relevant news and information in my field of expertise. Since I have started a habit of walking, I have been on top of my field and able to implement solutions that I would have never thought of otherwise.</p>
<h3>Music</h3>
<p>I also love discovering new music. Sometimes when I really need to get my head around something I go for a brisk walk with my favourite songs. This helps me to unwind and later really understand the problem.</p>
<p>Most of the time while on the walk, I solve the problem that I had, and in my experience would off taken me much more time to solve.</p>
<h3>Walking groups</h3>
<p><img alt="walking groups picture" src="https://i.gyazo.com/26609ccb0d7ae90e9f746389479a32b0.jpg"></p>
<p>Sometimes socialising can be hard and especially when all of your friends are on the lockdown and all of the socialising places, such as restaurants, are closed. </p>
<p>That is where walking groups can come into play! You can find someone who is staying healthy and being diligent with their health and walk together! That will allow you to catch up and have social interaction, that we humans require.</p>
<h5>So what this means?</h5>
<p>Now you have a social responsibility in your habit, and the whole activity can let you be more motivated to do it.</p>
<p>Also, walking groups normally allow you to meet new people and to bond better with existing relationships.</p>
<p>Also, walking groups is a great way to speed up your walking pace and improve your health.</p>
<h2>How do I get better at walking?</h2>
<p>If you would like to improve the speed at which you walk, there are multiple ways to do so:</p>
<ul>
<li>As mentioned above, walking groups are amazing for giving you a speedup of pace, just make sure to not overdo it.</li>
<li>Walking poles (tracking poles) are an easy way to speed up the pace. They are especially useful for those with back or leg injury, that immensely help reduce the stress on joints and back as well as speed up the pace. There is a lot of research behind use cases and benefits of using them.</li>
<li>Treadmills. If you are unable to properly walk in the wild or in the park, get yourself a treadmill. Although they can be expensive, some are very cheap and immensely powerful alternatives provide the same result. You don’t need something overly expensive. Treadmills are great for controlling your pace as well as letting you support yourself with the rails that are at either side of the treadmill.</li>
<li>Have an open goal. Whenever you are walking, the <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">research has shown</a> that having an open goal to where you want to walk or for how long will extend the amount of walking that you will eventually do.</li>
<li>Keep track of your metrics. Understanding what your heart rate and your pace are, is vital for your well being and motivation. Seeing that you have improved over a period of time is the greatest motivator there is.</li>
<li>Strive towards a 13 minutes per mile goal. The 13 minutes per mile has been shown to be the meeting point between fast walkers and the joggers. As …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klimy.co/blog/benefits-of-walking">https://klimy.co/blog/benefits-of-walking</a></em></p>]]>
            </description>
            <link>https://klimy.co/blog/benefits-of-walking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316328</guid>
            <pubDate>Sat, 05 Dec 2020 17:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Orthogonal Persistence and WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25316232">thread link</a>) | @nynx
<br/>
December 5, 2020 | https://charted.space/orthogonal-persistence.html | <a href="https://web.archive.org/web/*/https://charted.space/orthogonal-persistence.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        
        <p><time>Friday, December 4th, 2020</time></p>
    </header>
    <hr>
    <p>I was reading about 
        <a href="https://en.wikipedia.org/wiki/Urbit" data-popup-title="Urbit" data-popup-title-html="Urbit" data-popup-author="Eng­lish Wikipedia" data-popup-date="2020-12-04" data-popup-abstract="<p><img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Urbit_Logo.svg/1920px-Urbit_Logo.svg.png&quot; style=&quot;width:30%; float:left; margin-right:15px;&quot;>Urbit is a decentralized personal server platform. The platform seeks to deconstruct the client-server model in favour of a federated network of personal servers in a peer-to-peer network with a consistent digital identity.<p>">Urbit</a> the other day. I recommend giving the wiki article a quick read if you're not familar with it, 
        but the core (and this is very watered-down) is that Urbit is how one might imagine computing
        <a href="https://en.wikipedia.org/wiki/Technological_singularity" data-popup-title="Technological singularity" data-popup-title-html="Technological singularity" data-popup-author="Eng­lish Wikipedia" data-popup-date="2020-12-04" data-popup-abstract="The technological singularity—also, simply, the singularity—is a hypothetical point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization. According to the most popular version of the singularity hypothesis, called intelligence explosion, an upgradable intelligent agent will eventually enter a &quot;runaway reaction&quot; of self-improvement cycles, each new and more intelligent generation appearing more and more rapidly, causing an &quot;explosion&quot; in intelligence and resulting in a powerful superintelligence that qualitatively far surpasses all human intelligence.">post-singularity</a>. Computing power and bandwidth are infinite, so inefficiencies are irrelevant and one needn't bother with worrying about them.
    </p>
    <p>
        Urbit takes many strange paths, but when viewed through this 
        lens, I find it <span>slightly</span> more understandable.
    </p>
    <p>
        Urbit is many things, but a core part is the concept of an <span>Operating Function</span>, a take on the term, <span>Operating System</span>.
        The Operating Function fulfills the role of an operating system (e.g. orchestrating applications, talking to the outside world, etc), but in a pure, functional manner:
    </p>
    <code>
        (event, old state) ⟶ (effect, new state)
    </code>
    <p>
        All the incoming events are automatically saved by the Urbit runtime.
        Occasionally, the list of events is squashed down and the most recent state is saved instead.
    </p>
    <p>
        The applications running inside of Urbit don't have to explicitly save their data,
        they just modify their state over time, receiving events and producing effects.
        But, when the computer is shut down, the urbit system can resume exactly in the same state.
    </p>
    <p>This is called <a href="https://en.wikipedia.org/wiki/Persistence_(computer_science)#Orthogonal_or_transparent_persistence" data-popup-title="Orthogonal or transparent persistence" data-popup-title-html="Orthogonal or transparent persistence" data-popup-author="Eng­lish Wikipedia" data-popup-date="2020-12-04" data-popup-abstract="<p>Persistence is said to be &quot;orthogonal&quot; or &quot;transparent&quot; when it is implemented as an intrinsic property of the execution environment of a program. An orthogonal persistence environment does not require any specific actions by programs running in it to retrieve or save their state.</p><p>Non-orthogonal persistence requires data to be written and read to and from storage using specific instructions in a program, resulting in the use of persist as a transitive verb: On completion, the program persists the data.</p><p>The advantage of orthogonal persistence environments is simpler and less error-prone programs.</p>"><span>Orthogonal Persistence</span></a>.</p>
    <hr>
    <p><span>Orthogonal persistence</span> refers to persistence of data without explicitly saving it.</p>
    <img src="https://charted.space/static/images/non-orthogonal-vs-orthogonal.jpeg">
    <p>
        There's no need to use the filesystem or a database.
        Just store data the way you would in a running application. e.g. in lists, tables, or anything else.
    </p>
    <hr>
    <p>
        <span>So</span>, I like the idea of orthogonal persistence. The "business" logic of the application is probably significantly clearer and simpler
        when saving and loading data isn't part of it.
        <!-- <span class="italics">But</span>, Urbit is too weird of a hump to get over <span class="italics">and</span>, despite the collective
        insistence of futurists, the singularity isn't right around the corner, so concepts like performance do, in fact, matter. -->
    </p>
    <!-- <p>Urbit is admittedly elegant despite (or perhaps because of) the obscurist veneer, but if we have</p> -->
    <p>Is it possible to have this without the obscurist veneer of Urbit? Yes, it is.</p>
    <p>
        Webassembly provides a (mostly) deterministic execution environment and I have a hunch that it'll be just flexible
        enough for the cursed things we'll have to do to it. As a plus, wasm can run quite fast!
    </p>
    <hr>
    <h2>Webassembly</h2>
    <p>What's in a wasm module anyhow?</p>
    <img src="https://charted.space/static/images/wasm-module.jpeg">
    <p>
        Doesn't look like much, does it? (I'm not referring to my drawing skills.) The code section is self-explanatory, and there's nothing there
        we need to work with for this project. Globals, tables, and memory are the important parts here. However, because this
        is a proof-of-concept, we're not going to worry about tables, which hold things like function references.
    </p>
    <ul>
        <li>
            <p>
                The globals section contains data that's, well, global. The shadow stack pointer, and other miscellaneous pointers tend
                to hang out here when the module has been generated by llvm.
            </p>
        </li>
        <li>
            <p>
                The memory is where most data gets stored. It's generally represented by a big slab of contiguous bytes.
            </p>
        </li>
    </ul>
    <p>With those in mind, there are two things we need to do to persist the state then:</p>
    <ol>
        <li>Save the wasm memory</li>
        <li>Save the mutable globals (e.g. that the program can change at runtime)</li>
    </ol>
    <p>
        However, we run into a hiccup here. Oftentimes, the module keeps many of its globals private and inaccessible from outside.
        Even native wasm runtimes, like <a href="https://github.com/bytecodealliance/wasmtime">wasmtime</a>, don't let you get at them.
        The solution to this is to actually modify the wasm module itself to make the right items accessible.
        The <a href="https://crates.io/crates/walrus">walrus</a> crate works well for this.
    </p>
    <p>
        Let's get started with what we want the wasm module to be. I'll write it in Rust, though other languages would work fine.
    </p>
    <code>
        <pre><span>static</span> <span>mut</span> N: <span>usize</span> = <span>0</span>;

<span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span><span>fn</span> <span>set</span></span>(x: <span>usize</span>) {
    <span>unsafe</span> { N = x }
}

<span>#[no_mangle]</span>
<span>pub</span> <span>extern</span> <span>"C"</span> <span><span>fn</span> <span>get</span></span>() -&gt; <span>usize</span> {
    <span>unsafe</span> { N }
}</pre>
    </code>
    <p>
        Rust really doesn't like mutable global variables, like <code>N</code>, so we have to use <code>unsafe</code> to access it.
    </p>
    <p>Let's compile that to webassembly:</p>
    <code>
        <pre>❯ rustc --target=wasm32-unknown-unknown --crate-type=cdylib -O test.rs</pre>
    </code>
    <p>
        Now for actually loading and unloading the wasm module, I threw together a rust crate that makes it pretty easy.
        This uses <a href="https://github.com/bytecodealliance/wasmtime">wasmtime</a> internally to load and execute the webassembly.
    </p>
    <p>Here's how you instantiate a module and then save the state to the filesystem!</p>
    <code>
        <pre><span>let</span> store = Store::default();
<span>let</span> (_, instance) = PersistentInstance::new_from_file(
    &amp;store,
    <span>"test.wasm"</span>
)?;

<span>let</span> set = instance
    .get_func(<span>"set"</span>)
    .ok_or(anyhow::format_err!(<span>"failed to find `set` function export"</span>))?
    .get1::&lt;<span>u32</span>, ()&gt;()?;

<span>println!</span>(<span>"Calling exported wasm function: `set(42)`"</span>);
set(<span>42</span>)?;
instance.save(<span>"globals.json"</span>, <span>"memory.bin"</span>)?;</pre>
    </code>
    <p>Here's the contents of the <code>globals.json</code> file we just generated:</p>
    <code>
        <pre>{<span>"__heap_base"</span>:{<span>"I32"</span>:<span>1049664</span>},<span>"$probed_global:0"</span>:{<span>"I32"</span>:<span>1048576</span>},<span>"__data_end"</span>:{<span>"I32"</span>:<span>1049664</span>}}</pre>
    </code>
    <p><code>memory.bin</code> ends up being a 1.1Mb file of mostly zeros. This could be very easily compressed to save space.</p>
    <p>And here's how to reload it!</p>
    <code>
        <pre><span>let</span> store = Store::default();
<span>let</span> (_, instance) = PersistentInstance::load_from_file(
    &amp;store,
    <span>"test.wasm"</span>,
    <span>"globals.json"</span>,
    <span>"memory.bin"</span>
)?;

<span>let</span> get = instance
    .get_func(<span>"get"</span>)
    .ok_or(anyhow::format_err!(<span>"failed to find `get` function export"</span>))?
    .get0::&lt;<span>u32</span>&gt;()?;

<span>let</span> x = get()?;
<span>println!</span>(<span>"calling exported wasm function: `get()` =&gt; {}"</span>, x);
<span>assert_eq!</span>(x, <span>42</span>);</pre>
    </code>
    <hr>
    <h2>Okay, so how is this Orthogonal Persistence?</h2>
    <p>
        Well, what I have here isn't orthogonal persistence exactly, but it represents a necessary building block
        for building a system that enables webassembly modules to orthogonally persist their data.
    </p>
    <p>
        I think there are some interesting possibilities.
    </p>
    <p>
        For applications with an event loop, which is almost every application if you squint your eyes a little,
        that event loop could be moved outside the module into the runtime itself. When the program is not on the call-stack,
        the runtime can simply persist it to disk (possibly through a memory mapped file, more research is necessary).
    </p>
    <p>
        When <a href="https://github.com/WebAssembly/interface-types/blob/master/proposals/interface-types/Explainer.md">webassembly interface types</a> eventually land, I think a whole system, operating system even, could consist
        of these orthogonally persistent programs all talking to each other through strongly-typed interfaces. It's a beautiful, elegant vision in my eyes.
    </p>
</article></div>]]>
            </description>
            <link>https://charted.space/orthogonal-persistence.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316232</guid>
            <pubDate>Sat, 05 Dec 2020 17:18:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top-Down Code Reviews]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25316040">thread link</a>) | @azhenley
<br/>
December 5, 2020 | https://surfingcomplexity.blog/2020/12/04/top-down-code-reviews/ | <a href="https://web.archive.org/web/*/https://surfingcomplexity.blog/2020/12/04/top-down-code-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1582">
			<!-- .entry-header -->		<div>
			<p>
							<span>
					<a href="https://surfingcomplexity.blog/category/software/" rel="category tag">software</a>				</span></p><!-- .cat-links -->
			
			
			<p><span>
				<time datetime="2020-12-04T21:10:27-08:00">December 4, 2020</time><time datetime="2020-12-04T21:11:29-08:00">December 4, 2020</time>			</span>

			<span>1 Minute</span>		</p></div><!-- .entry-meta -->
	
	<div>
		
<p>I’ve long been frustrated by the task of code reviews. Often, the pull request (PR) I’m reviewing involves a part of the codebase I’m not intimately familiar with. I read it, not quite understanding it, looking to see if I can offer some sort of useful feedback, and typically that feedback would be on the micro level (e.g., “you can simplify this function by calling this other library function instead”).</p>



<p>I recently started experimenting with a new review approach that I’m going to call <em>top down code</em> <em>review.</em> Here’s how it works: <strong>I start by understanding the code well enough so that I can write my own version of the pull request message, describing the PR in my own words.</strong> After I’ve done this, then I provide feedback.</p>



<p>I call this approach “top down” because the review that I end up generating starts with a “top down” description of the PR: the problem it’s trying to solve, and the solution approach, before diving into describing notable implementation details. Here are the reviews I’ve done in this style so far:</p>



<ul><li><a href="https://github.com/spinnaker/keel/pull/1681#pullrequestreview-543335454" rel="nofollow">https://github.com/spinnaker/keel/pull/1681#pullrequestreview-543335454</a> </li><li><a href="https://github.com/spinnaker/keel/pull/1674#pullrequestreview-537791392" rel="nofollow">https://github.com/spinnaker/keel/pull/1674#pullrequestreview-537791392</a></li><li><a href="https://github.com/spinnaker/keel/pull/1673#pullrequestreview-536820748" rel="nofollow">https://github.com/spinnaker/keel/pull/1673#pullrequestreview-536820748</a></li><li><a href="https://github.com/spinnaker/keel/pull/1657#pullrequestreview-534881241" rel="nofollow">https://github.com/spinnaker/keel/pull/1657#pullrequestreview-534881241</a></li></ul>



<p>I’ve been finding this approach useful because it forces me to come to terms with how well I really understand the PR. If I can’t explain the PR in my own words, then I don’t really understand it. It also helps me figure out what questions to ask the original author to help clarify things for me.</p>



<p>I also get more of a sense of closure after doing the review. Even if I had no feedback to give, I understand the changes in a way that I didn’t before.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-12-04T21:10:27-08:00">December 4, 2020</time><time datetime="2020-12-04T21:11:29-08:00">December 4, 2020</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://surfingcomplexity.blog/2020/12/04/top-down-code-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316040</guid>
            <pubDate>Sat, 05 Dec 2020 16:58:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improbable Inspiration: Bayesian Networks (1996)]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25315982">thread link</a>) | @1e
<br/>
December 5, 2020 | https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html | <a href="https://web.archive.org/web/*/https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td>

      <span face="Arial,Helvetica" color="#003366">

      <b>Improbable Inspiration</b><p>
      The future of software may lie in the obscure theories of an
      18th century cleric named Thomas Bayes.

      </p><p>

      By LESLIE HELM, Times Staff Writer

      </p><hr>
      <p>

      When Microsoft Senior Vice President Steve
      Ballmer first heard his company was planning to make a huge
      investment in an Internet service offering movie reviews and
      local entertainment information in major cities across the
      nation, he went to Chairman Bill Gates with his concerns.

      </p><p>

      &nbsp;&nbsp;&nbsp; After all, Ballmer has billions of dollars of
      his own money in Microsoft stock, and entertainment isn't
      exactly the company's strong point.

      </p><p>

      &nbsp;&nbsp;&nbsp; But Gates dismissed such
      reservations. Microsoft's competitive advantage, he responded,
      was its expertise in "Bayesian networks."

      </p><p>

      &nbsp;&nbsp;&nbsp; Asked recently when computers would finally
      begin to understand human speech, Gates began discussing the
      critical role of "Bayesian" systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Ask any other software executive about
      anything "Bayesian" and you're liable to get a blank
      stare.

      </p><p> 

      &nbsp;&nbsp;&nbsp; Is Gates onto something? Is this
      alien-sounding technology Microsoft's new secret weapon?

      </p><p>

      &nbsp;&nbsp;&nbsp; Quite possibly.
      
      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks are complex diagrams that
      organize the body of knowledge in any given area by mapping out
      cause-and-effect relationships among key variables and encoding
      them with numbers that represent the extent to which one
      variable is likely to affect another.

      </p><p>

      &nbsp;&nbsp;&nbsp; Programmed into computers, these systems can
      automatically generate optimal predictions or decisions even
      when key pieces of information are missing.

      </p><p>

      &nbsp;&nbsp;&nbsp; When Microsoft in 1993 hired Eric Horvitz,
      David Heckerman and Jack Breese, pioneers in the development of
      Bayesian systems, colleagues in the field were surprised. The
      field was still an obscure, largely academic enterprise.

      </p><p>
 
      &nbsp;&nbsp;&nbsp; Today the field is still obscure. But scratch
      the surface of a range of new Microsoft products and you're
      likely to find Bayesian networks embedded in the software. And
      Bayesian nets are being built into models that are used to
      predict oil and stock prices, control the space shuttle and
      diagnose disease.

      </p><p>

      &nbsp;&nbsp;&nbsp; Artificial intelligence (AI) experts, who saw
      their field discredited in the early 1980s after promising a
      wave of "thinking" computers that they ultimately
      couldn't produce, believe widening acceptance of the Bayesian
      approach could herald a renaissance in the field.

      </p><p>
      
      &nbsp;&nbsp;&nbsp; Bayesian networks provide "an
      overarching graphical framework" that brings together
      diverse elements of AI and increases the range of its likely
      application to the real world, says Michael Jordon, professor of
      brain and cognitive science at the Massachusetts Institute of
      Technology.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is unquestionably the most
      aggressive in exploiting the new approach. The company offers a
      free Web service that helps customers diagnose printing problems
      with their computers and recommends the quickest way to resolve
      them. Another Web service helps parents diagnose their
      children's health problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; The latest version of Microsoft Office
      software uses the technology to offer a user help based on past
      experience, how the mouse is being moved and what task is being
      done.

      </p><p>

      &nbsp;&nbsp;&nbsp; "If his actions show he is distracted,
      he is likely to need help," Horvitz says. "If he's
      been working on a chart, chances are he needs help formatting
      the chart."

      </p><p>

      &nbsp;&nbsp;&nbsp; "Gates likes to talk about how computers
      are now deaf, dumb, blind and clueless. The Bayesian stuff helps
      deal with the clueless part," says Daniel T.  Ling,
      director of Microsoft's research division and a former IBM
      scientist.

      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks get their name from the
      Rev. Thomas Bayes, who wrote an essay, posthumously published in
      1763, that offered a mathematical formula for calculating
      probabilities among several variables that are causally related
      but for which--unlike calculating the probability of a coin
      landing on heads or tails--the relationships can't easily be
      derived by experimentation.

      </p><p>

      &nbsp;&nbsp;&nbsp; Early students of probability applied the
      ideas to discussions about the existence of God or efforts to
      improve their odds in gambling. Much later, social scientists
      used it to help clarify the key factors influencing a particular
      event.

      </p><p>

      &nbsp;&nbsp;&nbsp; But it was the rapid progress in computer
      power and the development of key mathematical equations that
      made it possible for the first time, in the late 1980s, to
      compute Bayesian networks with enough variables that they were
      useful in practical applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; The Bayesian approach filled a void in the
      decades-long effort to add intelligence to computers.

      </p><p>

      &nbsp;&nbsp;&nbsp; In the late 1970s and '80s, reacting to the
      "brute force" approach to problem solving by early
      users of computers, proponents of the emerging field of
      artificial intelligence began developing software programs using
      rule-based, if-then propositions. But the systems took time to
      put together and didn't work well if, as was frequently the
      case, you couldn't answer all the computer's questions clearly.

      </p><p>

      &nbsp;&nbsp;&nbsp; Later companies began using a technique
      called "neural nets" in which a computer would be
      presented with huge amounts of data on a particular problem and
      programmed to pull out patterns. A computer fed with a big stack
      of X-rays and told whether or not cancer was present in each
      case would pick out patterns that would then be used to
      interpret X-rays.

      </p><p>

      &nbsp;&nbsp;&nbsp; But the neural nets won't help predict the
      unforeseen. You can't train a neural net to identify an incoming
      missile or plane because you could never get sufficient data to
      train the system.

      </p><p>

      &nbsp;&nbsp;&nbsp; In part because of these limitations, a slew
      of companies that popped up in the early 1980s to sell
      artificial intelligence systems virtually all went bankrupt.

      </p><p>

      &nbsp;&nbsp;&nbsp; Many AI techniques continued to be
      used. Credit card companies, for example, began routinely using
      neural networks to pick out transactions that don't look right
      based on a consumer's past behavior. But increasingly, AI was
      regarded as a tool with limited use.

      </p><p>

      &nbsp;&nbsp;&nbsp; Then, in the late 1980s--spurred by the early
      work of Judea Pearl, a professor of computer science at UCLA,
      and breakthrough mathematical equations by <a href="http://www.hugin.dk/">Danish researchers</a>--AI
      researchers discovered that Bayesian networks offered an
      efficient way to deal with the lack or ambiguity of information
      that has hampered previous systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz and his two Microsoft colleagues, who
      were then classmates at Stanford University, began building
      Bayesian networks to help diagnose the condition of patients
      without turning to surgery.

      </p><p>

      &nbsp;&nbsp;&nbsp; The approach was efficient, says Horvitz,
      because you could combine historical data, which had been
      meticulously gathered, with the less precise but more intuitive
      knowledge of experts on how things work to get the optimal
      answer given the information available at a given time.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz, who with two colleagues founded
      Knowledge Industries to develop tools for developing Bayesian
      networks, says he and the others left the company to join
      Microsoft in part because they wanted to see their theoretical
      work more broadly applied.

      </p><p>

      &nbsp;&nbsp;&nbsp; Although the company did important work for
      the National Aeronautics and Space Administration and on medical
      diagnostics, Horvitz says, "It's not like your grandmother
      will use it."

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft's activities in the field are now
      helping to build a groundswell of support for Bayesian ideas.

      </p><p>

      &nbsp;&nbsp;&nbsp; "People look up to Microsoft," says
      Pearl, who wrote one of the key early texts on Bayesian networks
      in 1988 and has become an unofficial spokesman for the
      field. "They've given a boost to the whole area."
                     
      </p><p>

      &nbsp;&nbsp;&nbsp; A researcher at German conglomerate Siemens
      says Microsoft's work has drawn the attention of his superiors,
      who are now looking seriously at applying Bayesian concepts to a
      range of industrial applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; Scott Musman, a computer consultant in
      Arlington, Va., recently designed a Bayesian network for the
      Navy that can identify enemy missiles, aircraft or vessels and
      recommend which weapons could be used most advantageously
      against incoming targets.

      </p><p>

      &nbsp;&nbsp;&nbsp; Musman says previous attempts using
      traditional mathematical approaches on state-of-the-art
      computers would get the right answer but would take two to three
      minutes.

      </p><p>

      &nbsp;&nbsp;&nbsp; "But you only have 30 seconds before the
      missile has hit you," says Musman.

      </p><p>

      &nbsp;&nbsp;&nbsp; General Electric is using Bayesian techniques
      to develop a system that will take information from sensors
      attached to an engine and, based on expert opinion built into
      the system as well as vast amounts of data on past engine
      performance, pinpoint emerging problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is working on techniques that will
      enable the Bayesian networks to "learn" or update
      themselves …</p></span></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</a></em></p>]]>
            </description>
            <link>https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315982</guid>
            <pubDate>Sat, 05 Dec 2020 16:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Techversary: Most popular in tech from the year you were born and beyond]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25315967">thread link</a>) | @naeemnur
<br/>
December 5, 2020 | https://techrewind.co/techversary/ | <a href="https://web.archive.org/web/*/https://techrewind.co/techversary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>⏪ TechRewind &gt; Version: 20.20 | Made by <a rel="author" href="https://techrewind.co/naeem/">Naeem</a> in 🇧🇭 | Trademarks, logos and copyrights are the property of their respective owners
</p>
</div></div>]]>
            </description>
            <link>https://techrewind.co/techversary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315967</guid>
            <pubDate>Sat, 05 Dec 2020 16:52:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An accessible introduction to type theory and implementing a type-checker]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25315819">thread link</a>) | @mrathi12
<br/>
December 5, 2020 | https://mukulrathi.co.uk/create-your-own-programming-language/intro-to-type-checking/ | <a href="https://web.archive.org/web/*/https://mukulrathi.co.uk/create-your-own-programming-language/intro-to-type-checking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3>Creating the Bolt Compiler: Part 4</h3><p><h3>June 15, 2020</h3><h3>10 min read</h3></p><nav><h2>Series: Creating the Bolt Compiler</h2><ul><li></li><li></li><li></li><li><strong>Part 4: An accessible introduction to type theory and implementing a type-checker</strong></li><li></li><li></li><li></li><li><em>Part 8: LLVM for the Uninitiated*</em></li><li><em>Part 9: Adding Concurrency to Bolt*</em></li><li><em>Part 10: Inheritance and method overriding in Bolt*</em></li><li><em>Part 11: Generics - adding polymorphism to Bolt*</em></li><p>*coming soon! </p></ul></nav><hr><h2 id="what-are-types"><a href="#what-are-types" aria-label="what are types permalink"></a>What are types?</h2><p>We’d discussed this briefly in the first part of the compiler series, however it’s worth revisiting this:</p><p>We implicitly classify words in a sentence as parts-of-speech (adjectives, nouns, verbs). Types work the <strong>same way</strong>, we classify program values based on the behaviour we’d like them to have. E.g. <code>int</code> for numbers that can be multiplied together, <code>string</code> for streams of characters that can be concatenated together.</p><p>The role of the type-checker is to prevent undesirable behaviour from happening - like concatenating <code>int</code>s or multiplying <code>string</code>s together - these operations make no sense so shouldn’t be allowed.</p><p>Most practical languages use types in one form or another. Some languages like Haskell are <em>statically</em> typed, meaning that the compiler checks the types at <em>compile-time</em>. You might argue, what about languages like JavaScript? There’s no compile-time type-checking there. These languages are <em>dynamically</em> typed, that is values are tagged with types and we check types at <em>runtime</em>, and throw a runtime error if types are mismatched. The runtime error acts as a very late safety check, stopping you just before you try to access a field of something that is <code>undefined</code>. So even JavaScript has types under the hood.</p><p>This all means that at some point, your fancy new language will likely implement some form of type-checking. With Bolt, I’ve chosen to implement <em>static</em> type-checking, i.e. the type-checking is another stage of our compiler.</p><p>Right now this all feels a little hand-wavey. What we need to do is take our high-level goal of “preventing undesirable behaviour” and formalise this. We want a list of rules to check a program against, and then if it passes those, we know our program is safe.</p><p>Enter <em>type systems</em>.</p><h2 id="type-systems"><a href="#type-systems" aria-label="type systems permalink"></a>Type Systems</h2><p>A type system consists of a set of rules, or <em>typing judgements</em>, that assigns a type <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span> to an expression <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi></mrow><annotation encoding="application/x-tex">e</annotation></semantics></math></span></span>. We start with seemingly obvious facts, and build up from there.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊢</mo><mrow><mi mathvariant="bold">t</mi><mi mathvariant="bold">r</mi><mi mathvariant="bold">u</mi><mi mathvariant="bold">e</mi></mrow><mo>:</mo><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">\vdash \mathbf{true} : bool</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊢</mo><mrow><mi mathvariant="bold">f</mi><mi mathvariant="bold">a</mi><mi mathvariant="bold">l</mi><mi mathvariant="bold">s</mi><mi mathvariant="bold">e</mi></mrow><mo>:</mo><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">\vdash \mathbf{false} : bool</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊢</mo><mi>n</mi><mo>:</mo><mi>i</mi><mi>n</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\vdash n : int</annotation></semantics></math></span></span> for any natural number <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span>.</p><p>The symbol <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊢</mo></mrow><annotation encoding="application/x-tex">\vdash</annotation></semantics></math></span></span> is just maths notion for “it follows that”.</p><h3 id="typing-environments"><a href="#typing-environments" aria-label="typing environments permalink"></a>Typing environments</h3><p>Thing is, looking at an expression on its own isn’t always enough for us to type-check an expression.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊢</mo><mi>x</mi><mo>:</mo><mtext>&nbsp;</mtext><mo stretchy="false">?</mo></mrow><annotation encoding="application/x-tex">\vdash x :\ ?</annotation></semantics></math></span></span></p><p>What type does the variable <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> have? Well it depends on what type it had when it was defined. Right, so these rules need to be updated to take that into account. To do this we’ll introduce a <em>typing environment</em>, that we’ll represent with a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span>. This typing environment <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> is a function that maps our variables to our types.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>t</mi></mrow><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><mi>x</mi><mo>:</mo><mtext>&nbsp;</mtext><mi>t</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\cfrac{\Gamma(x) = t} {\Gamma \vdash x :\ t}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">\Gamma(x) = t</annotation></semantics></math></span></span> just says that we look up variable <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> in <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span>, and we find it has type <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span>.</p><p>How do we construct this typing environment <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span>? Hold your horses for just a second, there’s something we skimmed over in that last rule.</p><h3 id="inference-rules"><a href="#inference-rules" aria-label="inference rules permalink"></a>Inference rules</h3><p>We stacked rules in what looks like some kind of fraction. What’s that all about?</p><p>This odd “fraction” is a way of representing deductive reasoning (like Sherlock Holmes but for programming languages). If everything on the top holds, then the bottom also holds.</p><p>Here’s another rule. This says that if we know <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">e_2</annotation></semantics></math></span></span> are <code>int</code>s, then if we add them together the result is also an <code>int</code>. This “stack” is just a formal way of saying that - we call it an <em>inference</em> rule.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><msub><mi>e</mi><mn>1</mn></msub><mo>:</mo><mi>i</mi><mi>n</mi><mi>t</mi><mtext>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</mtext><mi mathvariant="normal">Γ</mi><mo>⊢</mo><msub><mi>e</mi><mn>2</mn></msub><mo>:</mo><mi>i</mi><mi>n</mi><mi>t</mi></mrow><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><msub><mi>e</mi><mn>1</mn></msub><mo>+</mo><msub><mi>e</mi><mn>2</mn></msub><mo>:</mo><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mi>t</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\cfrac{\Gamma \vdash e_1 : int\ \ \ \ \ \ \Gamma \vdash e_2 : int } {\Gamma \vdash e_1 + e_2 :\ int}</annotation></semantics></math></span></span></p><p>Using these <em>inference</em> rules, we can stack together our pieces of evidence about different parts of the program, and then be able to reason about the whole program. This is how we build up our type system - we <em>stack</em> our rules.</p><p>Let’s combine what we’ve learnt so far in a little expression: <code>x + 1</code> where <code>x</code> is an integer.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow></mrow><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>i</mi><mi>n</mi><mi>t</mi></mrow></mfrac></mstyle><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><mi>x</mi><mo>:</mo><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mi>t</mi></mrow></mfrac></mstyle><mtext>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</mtext><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow></mrow><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><mn>1</mn><mo>:</mo><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mi>t</mi></mrow></mfrac></mstyle></mrow><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><mi>x</mi><mo>+</mo><mn>1</mn><mo>:</mo><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mi>t</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\cfrac{ \cfrac{\cfrac{}{\Gamma(x) = int}} {\Gamma \vdash x :\ int} \ \ \ \ \ \ \cfrac{} {\Gamma \vdash 1 :\ int} } {\Gamma \vdash x + 1 :\ int}</annotation></semantics></math></span></span></p><p>It’s convention here to represent the base cases (<em>axioms</em>) with a line above them.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow></mrow><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><mn>1</mn><mo>:</mo><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mi>t</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\cfrac{} {\Gamma \vdash 1 :\ int}</annotation></semantics></math></span></span></p><p>Since they have nothing on the top, technically everything on the top is true. So the bottom <strong>always</strong> holds.</p><p>If you look back to our example and flip it upside down, it kind of looks like a tree. It also lays out our reasoning, so acts as a <em>proof</em> - you can just follow the steps. Why is <code>x+1</code> an int? Well <code>x</code> and <code>1</code> are <code>int</code>s? Why is <code>x</code> an int? Because… You get the idea. So what we’ve constructed here is called a <em>proof tree</em>.</p><p>Okay, let’s look at another rule. What about an <code>if-else</code> block?</p><div><div><pre><p><span>if</span><span> </span><span>(</span><span>something</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  do_one_thing</span></p><p><span></span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>  do_something_else</span></p><p><span></span><span>}</span></p></pre></div></div><p>Well, the <code>something</code> has to be a boolean expression, and regardless of which branch we execute we ought to return the same type. This is because we’re <em>statically</em> checking our types - we haven’t actually run our program so in general we don’t know which branch we’ll execute. JavaScript and Python would allow different types, since they’re doing their type-checking at runtime, so they know which branch was chosen.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><msub><mi>e</mi><mn>1</mn></msub><mo>:</mo><mi>b</mi><mi>o</mi><mi>o</mi><mi>l</mi><mtext>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</mtext><mi mathvariant="normal">Γ</mi><mo>⊢</mo><msub><mi>e</mi><mn>2</mn></msub><mo>:</mo><mi>t</mi><mtext>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</mtext><mi mathvariant="normal">Γ</mi><mo>⊢</mo><msub><mi>e</mi><mn>3</mn></msub><mo>:</mo><mi>t</mi></mrow><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><mrow><mi mathvariant="bold">i</mi><mi mathvariant="bold">f</mi></mrow><mtext>&nbsp;</mtext><msub><mi>e</mi><mn>1</mn></msub><mtext>&nbsp;</mtext><mo stretchy="false">{</mo><msub><mi>e</mi><mn>2</mn></msub><mo stretchy="false">}</mo><mtext>&nbsp;</mtext><mrow><mi mathvariant="bold">e</mi><mi mathvariant="bold">l</mi><mi mathvariant="bold">s</mi><mi mathvariant="bold">e</mi></mrow><mtext>&nbsp;</mtext><mo stretchy="false">{</mo><msub><mi>e</mi><mn>3</mn></msub><mo stretchy="false">}</mo><mo>:</mo><mtext>&nbsp;</mtext><mi>t</mi></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\cfrac{\Gamma \vdash e_1 : bool\ \ \ \ \ \ \Gamma \vdash e_2 : t \ \ \ \ \ \ \Gamma \vdash e_3 : t } {\Gamma \vdash \mathbf{if}\ e_1\ \{ e_2 \}\ \mathbf{else}\ \{ e_3 \} :\ t}</annotation></semantics></math></span></span></p><h3 id="typing-the-overall-program"><a href="#typing-the-overall-program" aria-label="typing the overall program permalink"></a>Typing the Overall Program</h3><p>This post would end up being too long if I were to list all the rules, but you can work through each of the cases (they match the <em>grammar</em> we defined in the previous post). So let’s talk about how we’d type the overall program.</p><p>Initially <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo>=</mo><mo stretchy="false">{</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\Gamma = \{ \}</annotation></semantics></math></span></span> - It’s empty as we haven’t defined any variables. We care if the program is <em>well-typed</em> (you can assign it a type) but we don’t care which type <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span></span> it evaluates to. So we essentially want a proof tree that shows:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mo stretchy="false">}</mo><mtext>&nbsp;</mtext><mo>⊢</mo><mi>p</mi><mi>r</mi><mi>o</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mo>:</mo><mtext>&nbsp;</mtext><mi>t</mi></mrow><annotation encoding="application/x-tex">\{\}\ \vdash program :\ t</annotation></semantics></math></span></span></p><p>How do we add variables to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span>? Through <code>let</code> declarations, i.e. <code>let x = e</code></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><msub><mi>e</mi><mn>1</mn></msub><mo>:</mo><msub><mi>t</mi><mn>1</mn></msub><mtext>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</mtext><mi mathvariant="normal">Γ</mi><mo separator="true">,</mo><mi>x</mi><mo>:</mo><msub><mi>t</mi><mn>1</mn></msub><mo>⊢</mo><msub><mi>e</mi><mn>2</mn></msub><mo>:</mo><msub><mi>t</mi><mn>2</mn></msub></mrow><mrow><mi mathvariant="normal">Γ</mi><mo>⊢</mo><mrow><mi mathvariant="bold">l</mi><mi mathvariant="bold">e</mi><mi mathvariant="bold">t</mi></mrow><mtext>&nbsp;</mtext><mi>x</mi><mo>=</mo><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">;</mo><mtext>&nbsp;</mtext><msub><mi>e</mi><mn>2</mn></msub><mo>:</mo><msub><mi>t</mi><mn>2</mn></msub></mrow></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\cfrac{\Gamma \vdash e_1 : t_1 \ \ \ \ \ \Gamma, x: t_1 \vdash e_2 : t_2} {\Gamma \vdash \mathbf{let}\ x = e_1 ;\ e_2 : t_2 }</annotation></semantics></math></span></span></p><p>Breaking this down, we get the type of the expression <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">e_1</annotation></semantics></math></span></span> being assigned to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span>. We then extend the environment with the mapping from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">t_1</annotation></semantics></math></span></span> (which we write as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo separator="true">,</mo><mi>x</mi><mo>:</mo><msub><mi>t</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\Gamma, x: t_1</annotation></semantics></math></span></span>) and we can now use this extended environment to type the next expression <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">e_2</annotation></semantics></math></span></span>.</p><h3 id="type-checking-vs-type-inference"><a href="#type-checking-vs-type-inference" aria-label="type checking vs type inference permalink"></a>Type Checking vs Type Inference</h3><p>One finer point: here we wrote <code>let x = e</code>. We could have equally written this as <code>let x : t = e</code> - where the programmer <em>annotates</em> <code>x</code> with type <code>t</code>. e.g. <code>let x : int = 1 + 2</code>.</p><p>These lead to different typing algorithms - in the first case the compiler <em>infers</em> that <code>1+2</code> has type <code>int</code>, and in the second case, the compiler has to <em>check</em> that <code>1+2</code> has type <code>int</code> (since we specified the type <code>int</code> of <code>x</code>).</p><p>As you might imagine, type inference means that the programmer has to write fewer type annotations, but it is much more complex for the compiler - it’s like filling a Sudoku from scratch versus checking a Sudoku solution is valid. OCaml and Haskell are examples of languages with type inference baked in.</p><p>In practice, most statically-typed languages do require some type annotations, but can infer some types (e.g. the <code>auto</code> keyword in C++). This is like completing a partially solved Sudoku puzzle and is much easier.</p><p>For Bolt, we’re going to infer types <em>within</em> a function or method definition, but require programmers to annotate the parameter and return types. This is a nice middle ground.</p><div><p><span>example_function.bolt</span></p><div><pre><p><span>function</span><span> int </span><span>something</span><span>(</span><span>int x</span><span>,</span><span> bool y</span><span>)</span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> z </span><span>=</span><span> </span><span>...</span><span> </span><span></span></p><p><span>  </span><span>...</span><span></span></p><p><span></span><span>}</span></p></pre></div></div><p>Okay, enough theory, let’s get to implementing this type-checker!</p><h2 id="implementing-a-type-checker"><a href="#implementing-a-type-checker" aria-label="implementing a type checker permalink"></a>Implementing a Type-checker</h2><h3 id="just-give-me-the-code"><a href="#just-give-me-the-code" aria-label="just give me the code permalink"></a>Just give me the code!</h3><p>You’ll need to clone the Bolt repository:</p><div><div><pre><p><span>git</span><span> clone https://github.com/mukul-rathi/bolt</span></p></pre></div></div><p>The <a href="https://github.com/mukul-rathi/bolt">Bolt repository</a> <code>master</code> branch contains a more complex type-checker, with support for inheritance, function/method overloading and generics. Each of these topics will get its own special post later in the series.</p><p>So instead, you’ll want to look at the <code>simple-compiler-tutorial</code> release. You can do this as follows:</p><div><div><pre><p><span>git checkout simple-compiler-tutorial</span></p></pre></div></div><p>This contains a stripped-back version of Bolt from earlier in the development processs. <a href="https://github.com/mukul-rathi/bolt/tree/simple-compiler-tutorial">(View this online)</a></p><p>The folder we care about is <code>src/frontend/typing</code>.</p><h3 id="types-in-bolt"><a href="#types-in-bolt" aria-label="types in bolt permalink"></a>Types in Bolt</h3><p>Bolt has four main types: <code>int</code>, <code>bool</code>, <code>void</code> and user-defined classes. We represent these four options using a variant type <code>type_expr</code> in OCaml:</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/simple-compiler-tutorial/src/frontend/ast/ast_types.mli"> <!-- -->ast_types.mli</a></span></p><div><pre><p><span>type</span><span> type</span><span>_</span><span>expr </span><span>=</span><span> </span><span>TEInt</span><span> </span><span>|</span><span> </span><span>TEClass</span><span> </span><span>of</span><span> </span><span>Class_name</span><span>.</span><span>t </span><span>|</span><span> </span><span>TEVoid</span><span> </span><span>|</span><span> </span><span>TEBool</span></p></pre></div></div><h3 id="annotating-our-ast-with-types"><a href="#annotating-our-ast-with-types" aria-label="annotating our ast with types permalink"></a>Annotating our AST with types</h3><p>Let’s recap our Abstract Syntax Tree from the last part of the series:</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/simple-compiler-tutorial/src/frontend/parsing/parsed_ast.mli"> <!-- -->parsed_ast.mli</a></span></p><div><pre><p><span>type</span><span> identifier </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Variable</span><span> </span><span>of</span><span> </span><span>Var_name</span><span>.</span><span>t</span></p><p><span>  </span><span>|</span><span> </span><span>ObjField</span><span> </span><span>of</span><span> </span><span>Var_name</span><span>.</span><span>t </span><span>*</span><span> </span><span>Field_name</span><span>.</span><span>t</span></p><p><span></span><span>type</span><span> expr </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Integer</span><span>     </span><span>of</span><span> loc </span><span>*</span><span> int</span></p><p><span>  </span><span>|</span><span> </span><span>Boolean</span><span>     </span><span>of</span><span> loc </span><span>*</span><span> bool</span></p><p><span>  </span><span>|</span><span> </span><span>Identifier</span><span>  </span><span>of</span><span> loc </span><span>*</span><span> identifier</span></p><p><span>  </span><span>|</span><span> </span><span>Constructor</span><span> </span><span>of</span><span> loc </span><span>*</span><span> </span><span>Class_name</span><span>.</span><span>t </span><span>*</span><span> constructor</span><span>_</span><span>arg list</span></p><p><span>  </span><span>|</span><span> </span><span>Let</span><span>         </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr option </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t </span><span>*</span><span> expr</span></p><p><span>  </span><span>|</span><span> </span><span>Assign</span><span>      </span><span>of</span><span> loc </span><span>*</span><span> identifier </span><span>*</span><span> expr</span></p><p><span>  </span><span>|</span><span> </span><span>If</span><span>          </span><span>of</span><span> loc </span><span>*</span><span> expr </span><span>*</span><span> block</span><span>_</span><span>expr </span><span>*</span><span> block</span><span>_</span><span>expr</span></p><p><span>  </span><span>.</span><span>.</span><span>.</span><span></span></p><p><span></span><span>and</span><span> block</span><span>_</span><span>expr </span><span>=</span><span> </span><span>Block</span><span> </span><span>of</span><span> loc </span><span>*</span><span> expr list</span></p></pre></div></div><p>This AST annotates each expression with <code>loc</code> - the line and position of the expression. In our type-checking phase, we’ll be checking the types of each of the possible expressions. We’ll want to store our results by <em>directly annotating</em> the AST, so the next compiler stage can view the types just by looking at the AST.</p><p>This AST gets the imaginative name <code>typed_ast</code>:</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/simple-compiler-tutorial/src/frontend/typing/typed_ast.mli"> <!-- -->typed_ast.mli</a></span></p><div><pre><p><span>type</span><span> identifier </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Variable</span><span> </span><span>of</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t</span></p><p><span>  </span><span>|</span><span> </span><span>ObjField</span><span> </span><span>of</span><span> </span><span>Class_name</span><span>.</span><span>t </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Field_name</span><span>.</span><span>t</span></p><p><span></span><span>type</span><span> expr </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Integer</span><span>     </span><span>of</span><span> loc </span><span>*</span><span> int  </span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Boolean</span><span>     </span><span>of</span><span> loc </span><span>*</span><span> bool  </span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Identifier</span><span>  </span><span>of</span><span> loc </span><span>*</span><span> identifier  </span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Constructor</span><span> </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Class_name</span><span>.</span><span>t </span><span>*</span><span> constructor</span><span>_</span><span>arg list</span></p><p><span>  </span><span>|</span><span> </span><span>Let</span><span>         </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t </span><span>*</span><span> expr</span></p><p><span>  </span><span>|</span><span> </span><span>Assign</span><span>      </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> identifier </span><span>*</span><span> expr</span></p><p><span>  </span><span>|</span><span> </span><span>If</span><span>          </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> expr </span><span>*</span><span> block</span><span>_</span><span>expr </span><span>*</span><span> block</span><span>_</span><span>expr</span></p><p><span>  </span><span>.</span><span>.</span><span>.</span><span></span></p><p><span></span><span>and</span><span> block</span><span>_</span><span>expr </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Block</span><span> </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> expr list  </span></p></pre></div></div><p>We don’t annotate obvious types, like for <code>Integer</code> and <code>Boolean</code>, but we annotate the type of the overall expression for other expressions e.g. the type returned by an <code>if-else</code> statement.</p><p>A good rule of thumb when annotating the AST is, what would the next stage need to be told about the program that it can’t guess from it being well-typed? For an <code>if-else</code> statement, if it is well-typed then the if-condition expression is clearly of type <code>bool</code>, but we’d need to be told the type of the branches.</p><h3 id="a-note-on-ocaml-syntax"><a href="#a-note-on-ocaml-syntax" aria-label="a note on ocaml syntax permalink"></a>A note on OCaml syntax</h3><p>In this tutorial we’ll be using OCaml syntax. If you’re unfamiliar with this, the main gist is that we’ll:</p><p><strong>a)</strong> Pattern match each of the cases. Here we have a variable <code>x</code> and we do different things based on each of its cases <code>A</code>, <code>B</code></p><div><div><pre><p><span>match</span><span> x </span><span>with</span><span></span></p><p><span>  </span><span>|</span><span> …</span></p></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mukulrathi.co.uk/create-your-own-programming-language/intro-to-type-checking/">https://mukulrathi.co.uk/create-your-own-programming-language/intro-to-type-checking/</a></em></p>]]>
            </description>
            <link>https://mukulrathi.co.uk/create-your-own-programming-language/intro-to-type-checking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315819</guid>
            <pubDate>Sat, 05 Dec 2020 16:40:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Flaws of Human Thinking]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25315667">thread link</a>) | @dandanua
<br/>
December 5, 2020 | https://dandanua.github.io/posts/major-flaws-of-human-thinking/ | <a href="https://web.archive.org/web/*/https://dandanua.github.io/posts/major-flaws-of-human-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As in the lovely child’s quote found on the internet —</p><blockquote><p>I know everything. Except anything I don’t.</p></blockquote><p>— we think that we see everything around us. But we don’t. There are so many things that greatly affect our lives, yet we don’t aware of them. One type of such things is deep inside us — the flaws of our own thinking. Here is my top list of those flaws.</p><h2 id="1-wishful-thinking-conservatism-and-conformism"><strong>1. Wishful thinking, conservatism and conformism</strong></h2><p>By <em>wishful thinking</em> I don’t mean optimism, which is rather speculation about the future. Wishful thinking is when we put more weight on the present knowledge that is pleasant to us, and at the same time ignore the knowledge that is not so nice. For example, people like to ignore the knowledge that puts them in a bad light. This is clearly seen in toxic relationships, where an abuser justifies his actions by “the care” of its victim. A dictator probably thinks that he is doing the best for its nation, while completely ignoring his incapabilities and bad doings. The same is true for groups of people or even nations. An invasion is commonly portrayed as liberation.</p><p>On the other hand, anyone who had experienced an addiction probably knows how it can alter decision-making. “Vodka is an antiseptic, didn’t you know? Let’s drink those bottles so we’ll be healthier!” Gambler thinks that he is going to make money, so his family will be happy. An ordinary gamer thinks that other real affairs are not that important, so it’s ok to spend more time on the game.</p><p>This is just few examples, but such thinking is so common that I don’t think a single book will be enough to collect all different “use cases”.</p><hr><p>Another flaw of our thinking is <em>conservatism</em> — an insufficient ability to change our common views and beliefs with the new data, new evidence. This is understandable — changing basis views leads to a reconsideration of all related knowledge. An enormous amount of rebuilding is required. Our biological brains just can’t do that in a short time, also it’s much harder with age. Because of this, we give much more weight to old knowledge rather than new evidence, thus making a conservatism bias.</p><p>In our rapidly changing world, this problem will have even more impact.</p><hr><p><em>Conformism</em> is when we weigh our knowledge in accordance with our community. The effect of this is highly underrated. An ordinary human thinks that “her thoughts are her own”, without realizing to what extent they are shaped by a community. I think that we’re all conformists to some degree. And it’s hard to imagine what’s that means not to be. This is proved by numerous experiments with a group of actors and one unsuspicious testee, where actors trick the testee to make some ridiculous statements or to do some crazy actions, like the one described <a href="https://www.youtube.com/watch?v=vjP22DpYYh8">here</a>. We are social creatures.</p><p>An extreme version of conformist thinking is the one imposed by religion. I’m not against religions in general, they can be useful, but a blind belief, an unquestioning subordination to “sacred” authorities — that’s just a disaster for a clear mind. A clear mind should have the ability to stress any dogmas.</p><h2 id="2-binary-black-and-white-thinking-overgeneralization"><strong>2. Binary (black-and-white) thinking, overgeneralization</strong></h2><p>Good-evil, smart-stupid, beautiful-ugly, tall-short, fast-slow, and so on and on. We think in binary terms. Our language reflects that. And some people are stuck very hard in such thinking. The worst case of it is <em>all-or-nothing</em> thinking, when any result other than the best is considered as a failure. It causes stress and depression in people. They don’t realize anymore why the world is so mean to them. They stop seeing how many gradients are there, and also how colorful our world is.</p><p>A similar flaw is <em>overgeneralization</em>. We put into the same category very broad types of information. Prejudice, labeling, stereotypes are all related to overgeneralization.</p><h2 id="3-self-projecting-thinking"><strong>3. Self-projecting thinking</strong></h2><p>Mind reading is an ability that everyone would like to have. It would be so easier to communicate. Also, it’s an advantage if we could read the thoughts of our rivals. While we can’t do it in reality, we’re still trying to predict other people’s thoughts, both in collaboration and confrontation.</p><p>To make such predictions we use two main assumptions:</p><ol><li>Other people see the same things as we do.</li><li>Other people are like us, thus their way of thinking is similar to ours.</li></ol><p>Based on these assumptions we use our way of thinking to deduce the thoughts of others. And this is very natural since we have to model another person’s thinking somehow. But the only model that we have is ours. It’s the only model that we can use. So, we essentially project our mind into another person’s head.</p><p>This has a fatal flaw. Because both main assumptions are only half true. While we see the same bits of the world, perception is a way more complex process. From bits we see high-order patterns, but they can be very personal. People could see different patterns and focus on different things. Also, the same bits (e.g. colors) can cause different emotions. Associations are also personal. The way we do conclusions is also very different in people because every person has its own experience, principles, beliefs, preferences, etc. We do not understand how unique the mind of every human.</p><p>And this causes a lot of trouble. People are fighting because of misunderstandings. In most situations they don’t realize, that they are fighting against their own reflection (from a distorting mirror).</p><h2 id="4-human-centric-thinking"><strong>4. Human-centric thinking</strong></h2><p>Humans are extremely focused on their own businesses. Yes, we are successful as a whole, in comparison to other creatures. But we are still part of nature. We follow its laws. Despite this, we neglect nature and the life of other species at scale.</p><p>Moreover, we value leaders, rulers and heroes amongst us much more than others. Even in fiction secondary characters usually die (who cares), while all hail goes to the main performers. We think that leaders are responsible for like 99% of the job done. Thus, we are trying to analyze them, rather than abstract patterns, situations and laws of nature. For example, from the popular culture it may look like Hitler was solely responsible for WWII and the Holocaust. Yeah, sure. How about WWI? Or any other war, genocide, mass conflict in human history? It’s silly to think that all these things were mainly because of leaders. This is just how humans work. In every moment in history there is a mix of wishes, intentions, beliefs, possibilities, thoughts of a total population. It could be that nature just picks a random guy as a leader that represents the mass.</p><p>On the other hand, we think that human is a singular, indivisible unit. That’s also not true. We are a composition of attributes, that are selected by evolution. Any child has some attributes from its mother and some attributes from its father. Human is a composable organism, the same is true for its mind. I’m sure that everyone experienced competing thoughts in his head. There is a natural selection of thoughts ongoing in the mind of every human.</p><h2 id="5-false-associations-confusion-of-causation-and-correlation"><strong>5. False associations, confusion of causation and correlation</strong></h2><p>Our thinking is associative, and we can make connections very fast based on very small data. A typical example is superstition, which is clearly seen in <a href="https://www.psychologistworld.com/superstition">pigeon experiments</a>.</p><p>Survival bias and filtering are accompanying flaws that lead to false associations. In probability theory, this is related to the fact that independent events are not necessary conditionally independent.</p><p>Even when our associations are quite objective we can make false conclusions about the causes. In fact, in probability theory and statistics the notion of a <em>cause</em> is not even defined. Events can be either correlated or independent in this theory. To deduce <em>what causes what</em> we use other tools, like common sense, physics, etc. Typically, to deduce a causation from two correlated events, we check two main things:</p><ol><li>One event is earlier in time than another one.</li><li>There is no common cause that could explain the correlation.</li></ol><p>This is hard stuff even for scientists. Because you have to exclude any possible common cause. Earlier we could use physical locality of events to exclude a lot of possible common causes. But with the advance of quantum mechanics, even locality is not a reliable factor anymore.</p><h2 id="final-words"><strong>Final words</strong></h2><p>There are a lot of other flaws, if you want to learn more you can start <a href="https://en.wikipedia.org/wiki/Cognitive_bias">here</a> and <a href="https://en.wikipedia.org/wiki/Cognitive_distortion">here</a>. But those described above I find the most impactful. I feel them myself and meet them all the time.</p></div></div>]]>
            </description>
            <link>https://dandanua.github.io/posts/major-flaws-of-human-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315667</guid>
            <pubDate>Sat, 05 Dec 2020 16:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing HashiCorp Vault on DigitalOcean with hashi-up]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25315450">thread link</a>) | @jsiebens
<br/>
December 5, 2020 | https://johansiebens.dev/posts/2020/12/installing-hashicorp-vault-on-digitalocean-with-hashi-up/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/12/installing-hashicorp-vault-on-digitalocean-with-hashi-up/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-02/jason-pofahl-zLtXrNXJpKM-unsplash-banner.png" alt="photo by Jason Pofahl on Unsplash"> <figcaption>
            <p>photo by <a href="https://unsplash.com/@jasonpofahlphotography?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Jason Pofahl</a> on <a href="https://unsplash.com/" target="_blank">Unsplash</a></p>
        </figcaption>
</figure>


<h2 id="introduction">Introduction</h2>

<figure><a href="https://www.vaultproject.io/">
    <img src="https://johansiebens.dev/uploads/2020-12-02/Vault_VerticalLogo_FullColor_RGB_small.png" width="150"> </a>
</figure>


<p>While every IT environment is not the same, secret management is one of the things that remains constant.<br>
Whether it is an application, automation script, CI/CD pipeline, they all rely on some form of credentials to access other services or data.</p>

<p><strong>HashiCorp Vault</strong> is a prominent tool in this particular area. It is used for securely storing tokens, passwords, certificates, and encryption keys, while it tightly controls access to that data by authenticating against trusted sources of identity.</p>

<p>In this tutorial, you will learn how to install Vault with <a href="https://github.com/jsiebens/hashi-up" target="_blank"><strong>hashi-up</strong></a>, a small tool I’m working on from time to time, to install the HashiCorp tools on any remote host via SSH.<br>
At the start of the project, only Consul and Nomad was supported, but with the latest release, Vault can be installed as well.</p>

<h2 id="set-up-a-single-vault-server-on-digitalocean">Set up a single Vault server on DigitalOcean</h2>

<p>There are several ways to provision the resources we need for the tutorial, like using the DigitalOcean dashboard or CLI, or tools like <a href="https://terraform.io/" target="_blank">HashiCorp Terraform</a>.</p>

<p>Because we only need a few resources, I’ll continue using the CLI (<code>doctl</code>).</p>

<p>Add your SSH key to your DigitalOcean dashboard, then find out the ID of the SSH key. We will need it later when we are using SSH to install Vault.</p>
<div><pre><code data-lang="bash">$ doctl compute ssh-key list
ID          Name          FingerPrint
<span>28960471</span>    operator      3b:6e:09:b7:d8:ac:84:e1:cf:15:89:e3:3d:13:9e:39</code></pre></div>
<p>And make it available for the next commands:</p>
<div><pre><code data-lang="bash">export SSH_KEY<span>=</span><span>'28960471'</span></code></pre></div>
<p>Provision a new VM with a compatible operating system such as Ubuntu or something else and make sure you a register your SSH key to this new host.</p>
<div><pre><code data-lang="bash">$ doctl compute droplet create --image ubuntu-18-04-x64 --size s-1vcpu-2gb --region lon1 vault --tag-names vault --wait --ssh-keys $SSH_KEY
ID           Name     Public IPv4       Private IPv4    Public IPv6    Memory    VCPUs    Disk    Region    Image                     VPC UUID                                Status    Tags     Features              Volumes
<span>219527892</span>    vault    <span>165</span>.232.109.36    <span>10</span>.106.0.3                     <span>2048</span>      <span>1</span>        <span>50</span>      lon1      Ubuntu <span>18</span>.04 <span>(</span>LTS<span>)</span> x64    9bdab0c6-776e-413c-95fa-3587ff2daf45    active    vault    private_networking</code></pre></div>
<p>Next, use hashi-up to bootstrap a Vault server over SSH:</p>
<div><pre><code data-lang="bash">$ hashi-up vault install --ssh-target-addr <span>165</span>.232.109.36 --version <span>1</span>.6.0
Uploading Vault configuration and certificates...
Installing Vault...
<span>[</span>INFO<span>]</span>  Creating user named vault
<span>[</span>INFO<span>]</span>  Downloading and unpacking vault_1.6.0_linux_amd64.zip
<span>[</span>INFO<span>]</span>  Creating service file /etc/systemd/system/vault.service
<span>[</span>INFO<span>]</span>  Enabling vault unit
Created symlink /etc/systemd/system/multi-user.target.wants/vault.service → /etc/systemd/system/vault.service.
<span>[</span>INFO<span>]</span>  Starting vault</code></pre></div>
<blockquote>
<p><strong>How does hashi-up install Vault?</strong></p>

<ul>
<li>it starts an SSH session to your target host<br></li>
<li>it generates a Vault configuration file, based on the commandline flags, and uploads the result via SCP<br></li>
<li>on the remote host, it downloads the Vault distribution and places the binary in the correct directory<br></li>
<li>it creates a vault user and some directories, like <code>/etc/vault.d</code> and <code>/opt/vault</code><br></li>
<li>it generates a systemd service file for Vault<br></li>
<li>it enables and starts this new systemd service<br></li>
</ul>
</blockquote>

<p>Open a browser and go to http://&lt;public ip&gt;:8200 and, eureka! Time to unseal this freshly installed Vault and start managing those secrets.</p>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-02/Screenshot_2020-12-02_17-34-40.png" width="500px"> 
</figure>


<p>But wait a minute… a secret management tool running with plain HTTP and no HTTPS? That doesn’t sound like a good idea, right?</p>

<p>Grab yourself a certificate or generate a self-signed one with hashi-up:</p>
<div><pre><code data-lang="bash">$ hashi-up cert create --host <span>165</span>.232.109.36 --host vault.example.com
<span>2020</span>/12/02 <span>17</span>:39:06 wrote server.pem
<span>2020</span>/12/02 <span>17</span>:39:06 wrote server-key.pem</code></pre></div>
<p>And rerun the previous install command with some extra flags to upload the key and certificate. No worries, it will just update the Vault configuration and restart the service:</p>
<div><pre><code data-lang="bash">$ hashi-up vault install --ssh-target-addr <span>165</span>.232.109.36 --version <span>1</span>.6.0 --key-file<span>=</span>server-key.pem --cert-file<span>=</span>server.pem
Uploading Vault configuration and certificates...
Installing Vault...
<span>[</span>INFO<span>]</span>  User vault already exists. Will not create again.
<span>[</span>INFO<span>]</span>  Vault binary already installed in /usr/local/bin, skipping downloading and installing binary
<span>[</span>INFO<span>]</span>  Creating service file /etc/systemd/system/vault.service
<span>[</span>INFO<span>]</span>  Enabling vault unit
<span>[</span>INFO<span>]</span>  Starting vault</code></pre></div>
<p>Now that’s more like, HTTPS enabled!</p>

<h3 id="set-up-an-ha-vault-cluster-on-digitalocean">Set up an HA Vault cluster on DigitalOcean</h3>

<p>A single Vault server is already nice to get started, but if our VM crashes for some reason, our secret management service will suffer a total failure. Vault supports a multi-server mode for high availability. This will protect you against outages and is automatically enabled when using a storage that supports it.</p>

<p>By default, hashi-up will install Vault configured with a Filesystem Backend which lacks support for high availability. But with hashi-up, you have the possibility to select the Consul Storage Backend.</p>

<p>The architecture we aim for is a Vault HA setup consisting of the following:</p>

<ul>
<li>Cluster of 3 Consul servers<br></li>
<li>2 Vault servers: 1 active and 1 standby</li>
</ul>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-02/vault-ha-consul.png" alt="Vault HA with Consul Storage Backend" width="600px"> <figcaption>
            <p>Vault HA with Consul Storage Backend</p>
        </figcaption>
</figure>


<p>For this Vault cluster, we will use a dedicated VPC:</p>
<div><pre><code data-lang="bash">$ doctl vpcs create --name vault-ha --region ams3
ID                                      URN                                            Name        Description    IP Range         Region    Created At                                 Default
c0c00111-58ec-46b8-af0c-faaf663c3e7e    <span>do</span>:vpc:c0c00111-58ec-46b8-af0c-faaf663c3e7e    vault-ha                   <span>10</span>.110.0.0/20    ams3      <span>2020</span>-12-05 <span>15</span>:20:27.252353591 +0000 UTC    false</code></pre></div><div><pre><code data-lang="bash">export VPC_ID<span>=</span><span>'c0c00111-58ec-46b8-af0c-faaf663c3e7e'</span></code></pre></div>
<p>Create 3 nodes for the Consul servers:</p>
<div><pre><code data-lang="bash">doctl compute droplet create --image ubuntu-18-04-x64 --size s-1vcpu-2gb --region ams3 consul-01 --tag-names consul-server --vpc-uuid $VPC_ID --ssh-keys $SSH_KEY
doctl compute droplet create --image ubuntu-18-04-x64 --size s-1vcpu-2gb --region ams3 consul-02 --tag-names consul-server --vpc-uuid $VPC_ID --ssh-keys $SSH_KEY
doctl compute droplet create --image ubuntu-18-04-x64 --size s-1vcpu-2gb --region ams3 consul-03 --tag-names consul-server --vpc-uuid $VPC_ID --ssh-keys $SSH_KEY</code></pre></div>
<p>Consul will use the tags attached for automatically joining other nodes using cloud metadata. This feature is called Consul Auto-join.</p>

<p>Create 2 nodes for the Vault servers:</p>
<div><pre><code data-lang="bash">doctl compute droplet create --image ubuntu-18-04-x64 --size s-1vcpu-2gb --region ams3 vault-01 --tag-names vault --vpc-uuid $VPC_ID --ssh-keys $SSH_KEY
doctl compute droplet create --image ubuntu-18-04-x64 --size s-1vcpu-2gb --region ams3 vault-02 --tag-names vault --vpc-uuid $VPC_ID --ssh-keys $SSH_KEY</code></pre></div>
<p>Now first bootstrap the Consul cluster:</p>
<div><pre><code data-lang="bash">export DO_API_TOKEN<span>=</span>&lt;your token&gt;

export SERVER1<span>=</span><span>$(</span>doctl compute droplet list | grep consul-01 | tr -s <span>' '</span> | cut -d <span>' '</span> -f <span>3</span><span>)</span>
export SERVER2<span>=</span><span>$(</span>doctl compute droplet list | grep consul-02 | tr -s <span>' '</span> | cut -d <span>' '</span> -f <span>3</span><span>)</span>
export SERVER3<span>=</span><span>$(</span>doctl compute droplet list | grep consul-03 | tr -s <span>' '</span> | cut -d <span>' '</span> -f <span>3</span><span>)</span>

hashi-up consul install --ssh-target-addr $SERVER1 <span>\
</span><span></span>  --server <span>\
</span><span></span>  --advertise <span>"{{ GetInterfaceIP \"eth1\" }}"</span> <span>\
</span><span></span>  --bootstrap-expect <span>3</span> <span>\
</span><span></span>  --retry-join <span>"provider=digitalocean region=ams3 tag_name=consul-server api_token=</span>$DO_API_TOKEN<span>"</span> <span>\
</span><span></span>  --client <span>0</span>.0.0.0

hashi-up consul install --ssh-target-addr $SERVER2 <span>\
</span><span></span>  --server <span>\
</span><span></span>  --advertise <span>"{{ GetInterfaceIP \"eth1\" }}"</span> <span>\
</span><span></span>  --bootstrap-expect <span>3</span> <span>\
</span><span></span>  --retry-join <span>"provider=digitalocean region=ams3 tag_name=consul-server api_token=</span>$DO_API_TOKEN<span>"</span>

hashi-up consul install --ssh-target-addr $SERVER3 <span>\
</span><span></span>  --server <span>\
</span><span></span>  --advertise <span>"{{ GetInterfaceIP \"eth1\" }}"</span> <span>\
</span><span></span>  --bootstrap-expect <span>3</span> <span>\
</span><span></span>  --retry-join <span>"provider=digitalocean region=ams3 tag_name=consul-server api_token=</span>$DO_API_TOKEN<span>"</span></code></pre></div>
<p>At this moment, you should have a Consul cluster running.</p>

<p>For the Vault cluster, besides a Vault service, also a Consul client needs to be installed:</p>
<div><pre><code data-lang="bash">export SERVER1<span>=</span><span>$(</span>doctl compute droplet list | grep vault-01 | tr -s <span>' '</span> | cut -d <span>' '</span> -f <span>3</span><span>)</span>
export SERVER2<span>=</span><span>$(</span>doctl compute droplet list | grep vault-02 | tr -s <span>' '</span> | cut -d <span>' '</span> -f <span>3</span><span>)</span>

export PRIVATE_IP1<span>=</span><span>$(</span>doctl compute droplet list | grep vault-01 | tr -s <span>' '</span> | cut -d <span>' '</span> -f <span>4</span><span>)</span>
export PRIVATE_IP2<span>=</span><span>$(</span>doctl compute droplet list | grep vault-01 | tr -s <span>' '</span> | cut -d <span>' '</span> -f <span>4</span><span>)</span>

hashi-up consul install --ssh-target-addr $SERVER1 <span>\
</span><span></span>  --advertise <span>"{{ GetInterfaceIP \"eth1\" }}"</span> <span>\
</span><span></span>  --retry-join <span>"provider=digitalocean region=ams3 tag_name=consul-server api_token=</span>$DO_API_TOKEN<span>"</span>

hashi-up consul install --ssh-target-addr $SERVER2 <span>\
</span><span></span>  --advertise <span>"{{ GetInterfaceIP \"eth1\" }}"</span> <span>\
</span><span></span>  --retry-join <span>"provider=digitalocean region=ams3 tag_name=consul-server api_token=</span>$DO_API_TOKEN<span>"</span>

hashi-up vault install --ssh-target-addr $SERVER1 --version <span>1</span>.6.0 --api-addr http://$SERVER1:8200 --cluster-addr http://$PRIVATE_IP1:8201 --storage consul
hashi-up vault install --ssh-target-addr $SERVER2 --version <span>1</span>.6.0 --api-addr http://$SERVER2:8200 --cluster-addr http://$PRIVATE_IP2:8201 --storage consul</code></pre></div>
<p>Now, you can initialize Vault and unseal each server.</p>
<div><pre><code data-lang="bash">$ vault operator init
$ vault operator unseal &lt;unseal_key_x&gt;</code></pre></div>
<p>This prepares the storage in Consul, which is then addressed by the active Vault server. It also generates a master key and disassemble that master key in several key shares. Each Vault server in the cluster can use these unseal keys, and each Vault server must be unsealed before it can be used.</p>

<p>Unseal both servers and finally verify the HA status.</p>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-12-02/consul-vault.png" alt="Vault services registered to Consul, both the active as the standby node"> <figcaption>
            <p>Vault services registered to Consul, both the active as the standby node</p>
        </figcaption>
</figure>


<p>Server 1:</p>
<div><pre><code data-lang="bash">$ vault status
Key             Value
---             -----
Seal Type       shamir
Initialized     true
Sealed          false
Total Shares    <span>1</span>
Threshold       <span>1</span>
Version         <span>1</span>.6.0
Storage Type    consul
Cluster Name    vault-cluster-d698e865
Cluster ID      b955f670-59ad-4fc2-ad30-fac83746c9fa
HA Enabled      true
HA Cluster      …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johansiebens.dev/posts/2020/12/installing-hashicorp-vault-on-digitalocean-with-hashi-up/">https://johansiebens.dev/posts/2020/12/installing-hashicorp-vault-on-digitalocean-with-hashi-up/</a></em></p>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/12/installing-hashicorp-vault-on-digitalocean-with-hashi-up/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315450</guid>
            <pubDate>Sat, 05 Dec 2020 15:58:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An accessible introduction to type theory and implementing a type-checker]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25315243">thread link</a>) | @mrathi12
<br/>
December 5, 2020 | https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/ | <a href="https://web.archive.org/web/*/https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3>Demystifying Deep Learning: Part 11</h3><p><h3>September 17, 2018</h3><h3>5 min read</h3></p><nav><h2>Series: Demystifying Deep Learning</h2><ul><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li><strong>Part 11: Backpropagation through, well, anything!</strong></li></ul></nav><hr><h2 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h2><p>So far in this series, we have looked at the general principle of <a href="https://mukulrathi.co.uk/demystifying-deep-learning/learning-gradient-descent">gradient descent</a>, and how we computed <a href="https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-maths-intuition-derivation-neural-network/">backpropagation</a> for each layer in a feedforward neural network, then generalising to look at <a href="https://mukulrathi.co.uk/demystifying-deep-learning/conv-net-backpropagation-maths-intuition-derivation/">backprop in different types of layers in a CNN</a>.</p><p>Now we will take a step back and look at backpropagation in a more general sense - <em>through a computation graph</em>. Through this we’ll get a general intuition for how the frameworks compute their</p><p>We’ll use the LSTM cell as our motivating example - to continue the task of sentiment analysis on the IMDB review dataset - you can find the code in the accompanying <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">Jupyter notebook</a></p><h2 id="general-backpropagation-principles"><a href="#general-backpropagation-principles" aria-label="general backpropagation principles permalink"></a>General Backpropagation Principles</h2><p>Let’s look back at the principles we’ve used in this series:</p><ul><li><p><em>Partial Derivative Intuition</em>: Think of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{y}}{\partial{x}}</annotation></semantics></math></span></span> loosely as quantifying how much <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span></span> would change if you gave the value of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> a little “nudge” at that point.</p></li><li><p><em>Breaking down computations</em> - we can use the <strong>chain rule</strong> to aid us in our computation - rather than trying to compute the derivative in one fell swoop, we break up the computation into smaller <strong>intermediate</strong> steps.</p></li><li><p><em>Computing the chain rule</em> - when thinking about which intermediate values to include in our chain rule expression, think about the immediate outputs of equations involving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> - which other values get directly affected when we slightly nudge <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span>?</p></li><li><p><em>One element at a time</em> - rather than worrying about the entire matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>, we’ll instead look at an element <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}</annotation></semantics></math></span></span>. One equation we will refer to time and time again is:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mi>A</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>B</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi>C</mi><mo>=</mo><mi>A</mi><mi mathvariant="normal">.</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">C_{ij} = \sum_k A_{ik}B_{kj} \iff  C=A.B</annotation></semantics></math></span></span></p><p>A useful tip when trying to go from one element to a matrix is to look for summations over repeated indices (here it was k) - this suggests a matrix multiplication.</p><p>Another useful equation is the element-wise product of two matrices:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>B</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi>C</mi><mo>=</mo><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C_{ij} = A_{ij}B_{ij} \iff  C=A*B</annotation></semantics></math></span></span></p></li><li><p><em>Sanity check the dimensions</em> - check the dimensions of the matrices all match (the derivative matrix should have same dimensions as the original matrix, and all matrices being multiplied together should have dimensions that align.</p></li></ul><p>A <strong>computation graph</strong> allows us to clearly break down the computations, as well as see the immediate outputs when computing our chain rule.</p><p>We will use the computation graph representation <em>(shown above</em>) of the LSTM to compute the gradients using backpropagation through time.</p><h2 id="the-lstm-computation-graph"><a href="#the-lstm-computation-graph" aria-label="the lstm computation graph permalink"></a>The LSTM Computation Graph</h2><h3 id="forward-propagation-equations"><a href="#forward-propagation-equations" aria-label="forward propagation equations permalink"></a>Forward Propagation equations</h3><p>From the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">previous post</a>, the forward propagation equations for one timestep in the LSTM are:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>i</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_i = \sigma(W_i.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_i)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>f</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>f</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_f = \sigma(W_f.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_f)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>o</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>o</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_o = \sigma(W_o.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_o)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>W</mi><mi>c</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>c</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;} =\tanh (W_c.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_c)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>+</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">{c}^{&lt; t&gt;} = \Gamma_i*\tilde{c}^{&lt; t&gt;} + \Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>∗</mo><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;} = \Gamma_o*\tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p><strong>Notation used</strong>:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span> denotes a <strong>concatenation of the two matrices</strong> to form a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a+n_x)</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> matrix. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">A.B</annotation></semantics></math></span></span> denotes matrix multiplication of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span>, whereas <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A*B</annotation></semantics></math></span></span> denotes elementwise multiplication. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> refers to the gate - see the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">previous post</a> defining the LSTM for a full breakdown of the notation used.</p><p>To backpropagate through the cell, given the gradient with respect to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t&gt;}</annotation></semantics></math></span></span> from the backprop from the next step, we need to compute the gradients for each of the weights <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>f</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>o</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">W_i, W_f, W_o, W_c</annotation></semantics></math></span></span> and biases <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>f</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>o</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">b_i, b_f, b_o, b_c</annotation></semantics></math></span></span>, and finally we will need to backpropagate to the previous timestep and compute the gradient with respect to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t-1&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t-1&gt;}</annotation></semantics></math></span></span>.</p><p>These are a <em>lot</em> of partial derivatives to compute - indeed as our neural networks get more complicated there will be more partial derivatives to calculate.</p><h3 id="how-can-we-use-our-computation-graph-to-break-this-down"><a href="#how-can-we-use-our-computation-graph-to-break-this-down" aria-label="how can we use our computation graph to break this down permalink"></a>How can we use our computation graph to break this down?</h3><p>Firstly, since the gate equations are identical, we can combine them so instead we have a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> containing the 3 gates’ outputs, and we can refer to the first third of the matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_i</annotation></semantics></math></span></span> and the other two thirds <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_f</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_o</annotation></semantics></math></span></span> respectively. Then we have one <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a + n_x)</annotation></semantics></math></span></span> matrix of weights for the gates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">W_g</annotation></semantics></math></span></span> and one <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> bias vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">b_g</annotation></semantics></math></span></span>.</p><p>Next, we want to document all intermediate stages in calculation (every node in the graph).</p><p>So, walking through the computation graph node-by-node in the forward step:</p><ul><li><p>We concatenate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t-1&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x^{&lt; t&gt;}</annotation></semantics></math></span></span> to form the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a + n_x)</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> concatenated input matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span>.</p></li><li><p>We calculate the weighted input matrix for the gates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> using the weights <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">W_g</annotation></semantics></math></span></span> and bias <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">b_g</annotation></semantics></math></span></span>.</p></li><li><p>Likewise we calculate the weighted input <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span> for the candidate memory <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> using the weight matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">W_c</annotation></semantics></math></span></span> and bias <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">b_c</annotation></semantics></math></span></span>.</p></li></ul><p>(<em>NB:</em> the diagram uses one weight matrix W, but it helps to think about these weights separately because of the different activation functions used)</p><ul><li><p>We apply the sigmoid activation function to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> to get the Gate matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> (denoted by <strong>f</strong>, <strong>i</strong>, <strong>o</strong> in diagram), and the tanh activation function to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span> to get <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> (denoted by <strong>g</strong> in the diagram).</p></li><li><p>Since elementwise multiplication and addition are straightforward operations, for brevity we won’t give the intermediate outputs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\Gamma_i*\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span> their own symbols.</p></li><li><p>Let us denote the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> intermediate output as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span>.</p></li></ul><p>Now we have broken down the computation graph into steps, and added our intermediate variables we have the equations:</p><ol><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub><mo>=</mo><msub><mi>W</mi><mi>g</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g = W_g.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_g</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub><mo>=</mo><msub><mi>W</mi><mi>c</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c = W_c.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_c</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>Z</mi><mi>g</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma = \sigma(Z_g)</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;} =\tanh Z_c</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>+</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">{c}^{&lt; t&gt;} = \Gamma_i*\tilde{c}^{&lt; t&gt;} + \Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{a}^{&lt; t&gt;} = \tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;} = \Gamma_o*\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span></p></li></ol><p>These equations correspond to the nodes in the graph - the left-hand-side variable is the ouput edge of the node, and the right-hand-side variables are the input edges to the node.</p><h2 id="backpropagation-in-a-computation-graph"><a href="#backpropagation-in-a-computation-graph" aria-label="backpropagation in a computation graph permalink"></a>Backpropagation in a Computation Graph:</h2><p>These equations allow us to clearly see the immediate outputs with respect to a variable when computing the chain rule - <em>e.g. for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span> the immediate outputs are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span></em>.</p><p>If we look at the equations / computation graph, we can more generally look at the type of operations, and then use the same identities:</p><ul><li><p><strong>Addition</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><mo>+</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C = A + B</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = 1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{B}} = 1</annotation></semantics></math></span></span></p></li><li><p><strong>Elementwise multiplication</strong>:
If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C = A * B</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = B</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>=</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{B}} = A</annotation></semantics></math></span></span></p></li><li><p><strong>tanh</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">C = \tanh A</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mn>1</mn><mo>−</mo><msup><mo><mi>tanh</mi><mo>⁡</mo></mo><mn>2</mn></msup><mi>A</mi><mo>=</mo><mn>1</mn><mo>−</mo><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = 1 - \tanh^2 A = 1 - C^2</annotation></semantics></math></span></span></p></li><li><p><strong>sigmoid</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C = \sigma(A)</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>−</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = \sigma (A)- \sigma^2 (A) = C*(1-C)</annotation></semantics></math></span></span></p></li><li><p><strong>Weighted Input</strong>: this is the same equation as the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/feed-forward-neural-network/">feedforward neural network</a>. If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>W</mi><mi mathvariant="normal">.</mi><mi>X</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Z =  W.X + b</annotation></semantics></math></span></span> then:</p></li></ul><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>W</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac><mi mathvariant="normal">.</mi><msup><mi>X</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W}}=  \frac{1}{m} \frac{\partial{J}}{\partial{Z}}.X^{T}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>b</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b}} = \frac{1}{m} \sum_{i=1}^{m}\frac{\partial{J}}{\partial{Z}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>X</mi></mrow></mfrac><mo>=</mo><msup><mi>W</mi><mi>T</mi></msup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{X}} = W^{T}.\frac{\partial{J}}{\partial{Z}}</annotation></semantics></math></span></span></p><p>Armed with these general computation graph principles, we can apply <strong>chain rule</strong>. We elementwise multiply (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span>) the partial derivatives, i.e.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span></p><p>Also note we sum partial derivatives coming from each of the immediate outputs:</p><p>So if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B = f(A)</annotation></semantics></math></span></span>
and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C = g(A)</annotation></semantics></math></span></span>, i.e. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> are immediate outputs of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> in the computation graph, then we sum the partial derivatives:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}} + \frac{\partial{J}}{\partial{C}}*\frac{\partial{C}}{\partial{A}}</annotation></semantics></math></span></span></p><p>In a <strong>deep learning framework</strong> like <em>TensorFlow</em> or <em>Keras</em>, there will be identities like this for each of the differentiable operations.</p><h2 id="backpropagation-through-time-in-an-lstm-cell"><a href="#backpropagation-through-time-in-an-lstm-cell" aria-label="backpropagation through time in an lstm cell permalink"></a>Backpropagation Through Time in an LSTM Cell</h2><p>When trying to compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}}</annotation></semantics></math></span></span>, we’ll use the general equation:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span></p><p>For brevity, we’ll substitute the value of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span> using the operations’ identities above.</p><p>The equations are thus as follows:</p><p>From equation 7:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\tilde{a}^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{a^{&lt; t&gt;}}}* \Gamma_o</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_o}}= \frac{\partial{J}}{\partial{a^{&lt; t&gt;}}}*\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p>Using equation 6, and writing equation 5 as an equation for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t+1&gt;}</annotation></semantics></math></span></span> instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t&gt;}</annotation></semantics></math></span></span> (i.e. adding 1 to the timestep):</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo><mn>2</mn></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{c^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{c^{&lt; t+1&gt;}}}*\Gamma_f + \frac{\partial{J}}{\partial{\tilde{a}^{&lt; t&gt;}}} *(1-\tilde{a}^{&lt; t&gt;2})</annotation></semantics></math></span></span></p><p>Also using equation 5:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\tilde{c}^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*\Gamma_i</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_i}}= \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_f}}= \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*c^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p><p>From equations 3 and 4 respectively:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="normal">Γ</mi></mrow></mfrac><mo>∗</mo><mi mathvariant="normal">Γ</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi mathvariant="normal">Γ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{Z_g}} = \frac{\partial{J}}{\partial{\Gamma}}*\Gamma*(1-\Gamma)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><msup><mo>&gt;</mo><mn>2</mn></msup></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{Z_c}} = \frac{\partial{J}}{\partial{\tilde{c}^{&lt; t&gt;}}}*(1-\tilde{c}^{&lt; t&gt;^2})</annotation></semantics></math></span></span></p><p>Equations 1 and 2 are identical, and so are the partial derivatives, differing only in subscript.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>W</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W_g}} = \frac{1}{m} \frac{\partial{J}}{\partial{Z_g}}.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]^T</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>b</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msubsup><mi>Z</mi><mi>g</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b_g}} = \frac{1}{m}\sum_{i=1}^{m} \frac{\partial{J}}{\partial{Z_g^{(i)}}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>W</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W_c}} = \frac{1}{m} \frac{\partial{J}}{\partial{Z_c}}.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]^T</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>b</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msubsup><mi>Z</mi><mi>c</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b_c}} = \frac{1}{m}\sum_{i=1}^{m} \frac{\partial{J}}{\partial{Z_c^{(i)}}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow></mrow></mfrac><mo>=</mo><msubsup><mi>W</mi><mi>g</mi><mi>T</mi></msubsup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mo>+</mo><msubsup><mi>W</mi><mi>c</mi><mi>T</mi></msubsup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]}} =  W_g^T.\frac{\partial{J}}{\partial{Z_g}}+     W_c^T.\frac{\partial{J}}{\partial{Z_c}}</annotation></semantics></math></span></span></p><p>So by breaking the computation graph into many steps, we can break down the calculation into smaller simpler steps that just use the operations’ derivative identities mentioned above.</p><h3 id="code"><a href="#code" aria-label="code permalink"></a>Code:</h3><p>The motivating example we’ve looked at uses an <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">LSTM network</a> for sentiment analysis on a dataset of IMDB reviews</p><div><div><pre><p><span>def</span><span> </span><span>backward_step</span><span>(</span><span>dA_next</span><span>,</span><span> dC_next</span><span>,</span><span>cache</span><span>,</span><span>parameters</span><span>)</span><span>:</span><span></span></p><p><span>    </span><span>(</span><span>a_next</span><span>,</span><span> c_next</span><span>,</span><span> input_concat</span><span>,</span><span> c_prev</span><span>,</span><span> c_candidate</span><span>,</span><span>IFO_gates</span><span>)</span><span> </span><span>=</span><span> cache</span></p><p><span>    n_a</span><span>,</span><span> m </span><span>=</span><span> a_next</span><span>.</span><span>shape</span></p><p><span>    dC_next </span><span>+=</span><span> dA_next</span><span>*</span><span> </span><span>(</span><span>IFO_gates</span><span>[</span><span>2</span><span>*</span><span>n_a</span><span>:</span><span>]</span><span>*</span><span>(</span><span>1</span><span>-</span><span>np</span><span>.</span><span>tanh</span><span>(</span><span>c_next</span><span>)</span><span>**</span><span>2</span><span>)</span><span>)</span><span></span></p><p><span>    dC_prev </span><span>=</span><span> dC_next </span><span>*</span><span> IFO_gates</span><span>[</span><span>n_a</span><span>:</span><span>2</span><span>*</span><span>n_a</span><span>]</span><span></span></p><p><span>    dC_candidate </span><span>=</span><span>  dC_next </span><span>*</span><span> IFO_gates</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dIFO_gates </span><span>=</span><span> np</span><span>.</span><span>zeros_like</span><span>(</span><span>IFO_gates</span><span>)</span><span></span></p><p><span>    dIFO_gates</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span> </span><span>=</span><span> dC_next </span><span>*</span><span> c_candidate</span></p><p><span>    dIFO_gates</span><span>[</span><span>n_a</span><span>:</span><span>2</span><span>*</span><span>n_a</span><span>]</span><span>=</span><span> dC_next </span><span>*</span><span> c_prev</span></p><p><span>    dIFO_gates</span><span>[</span><span>2</span><span>*</span><span>n_a</span><span>:</span><span>]</span><span> </span><span>=</span><span> dA_next </span><span>*</span><span> np</span><span>.</span><span>tanh</span><span>(</span><span>c_next</span><span>)</span><span></span></p><p><span>    dZ_gate </span><span>=</span><span>  dIFO_gates</span><span>*</span><span> </span><span>(</span><span>IFO_gates</span><span>*</span><span>(</span><span>1</span><span>-</span><span>IFO_gates</span><span>)</span><span>)</span><span></span></p><p><span>    dA_prev </span><span>=</span><span>  </span><span>(</span><span>parameters</span><span>[</span><span>"Wg"</span><span>]</span><span>.</span><span>T</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>dZ_gate</span><span>)</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dWg </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>dZ_gate</span><span>.</span><span>dot</span><span>(</span><span>input_concat</span><span>.</span><span>T</span><span>)</span><span></span></p><p><span>    dbg </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>np</span><span>.</span><span>sum</span><span>(</span><span>dZ_gate</span><span>,</span><span>axis</span><span>=</span><span>1</span><span>,</span><span> keepdims</span><span>=</span><span>True</span><span>)</span><span></span></p><p><span>    dZ_c </span><span>=</span><span> dC_candidate </span><span>*</span><span> </span><span>(</span><span>1</span><span>-</span><span>c_candidate</span><span>**</span><span>2</span><span>)</span><span></span></p><p><span>    dA_prev </span><span>+=</span><span>  </span><span>(</span><span>parameters</span><span>[</span><span>"Wc"</span><span>]</span><span>.</span><span>T</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>dZ_c</span><span>)</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dWc </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>dZ_c</span><span>.</span><span>dot</span><span>(</span><span>input_concat</span><span>.</span><span>T</span><span>)</span><span></span></p><p><span>    dbc </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>np</span><span>.</span><span>sum</span><span>(</span><span>dZ_c</span><span>,</span><span>axis</span><span>=</span><span>1</span><span>,</span><span> keepdims</span><span>=</span><span>True</span><span>)</span><span></span></p><p><span>    </span><span>return</span><span> dA_prev</span><span>,</span><span> dC_prev</span><span>,</span><span> dWg</span><span>,</span><span> dbg</span><span>,</span><span> dWc</span><span>,</span><span> dbc</span></p></pre></div></div><div><h3>Join me on this learning journey!</h3><p>This summer I’m using my blog to teach the topics I’ve learnt this year. It’s a win-win - you get computer science tutorials and I get to share it with you!</p></div><h3 id="practical-considerations"><a href="#practical-considerations" aria-label="practical considerations permalink"></a>Practical Considerations:</h3><p>When checking the equations for the backprop, it helps to have a numerical checker - I’ve written one in the accompanying <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">Jupyter notebook</a>.</p><h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2><p>This seems like a good juncture to recap the series so far.</p><p>We started the series looking at the most commonly used termninology, followed by looking at simple machine learning algorithms in <a href="https://mukulrathi.co.uk/demystifying-deep-learning/linear-logistic-regression/">linear and logistic regression</a>, building up the intuition behind the maths behind <a href="https://mukulrathi.co.uk/demystifying-deep-learning/learning-gradient-descent/">gradient descent</a> as we built up to a <a href="https://mukulrathi.co.uk/demystifying-deep-learning/feed-forward-neural-network/">feedforward neural network</a>.</p><p>Next we looked at the learning process itself, and how we could <a href="https://mukulrathi.co.uk/demystifying-deep-learning/optimising-gradient-descent/">improve gradient descent</a> itself, as well as <a href="https://mukulrathi.co.uk/demystifying-deep-learning/debug-neural-network-learning/">debug our model</a> to see whether it was learning or not.</p><p>Finally, we moved onto more specialised neural networks - <a href="https://mukulrathi.co.uk/demystifying-deep-learning/convolutional-neural-network-from-scratch/">CNNs</a> and <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">recurrent neural nets</a>, not only looking at their theory but the motivation behind them. We also looked at the maths behind them, deriving the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/conv-net-backpropagation-maths-intuition-derivation/"> CNN backprop</a> equations from scratch.</p><p>Now that we’re at the point that we’re able to understand backprop in a general computation graph, we can use the abstractions of the deep learning frameworks in subsequent posts.</p></article></div>]]>
            </description>
            <link>https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315243</guid>
            <pubDate>Sat, 05 Dec 2020 15:31:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Books I read before I launched my startup]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25315136">thread link</a>) | @karlhughes
<br/>
December 5, 2020 | https://www.karllhughes.com/posts/startup-books | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/startup-books">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/startup-books.png" alt="The Best Startup Books for Founders">
</p> 

<p>
2020, Dec 04&nbsp;&nbsp;&nbsp;—&nbsp;
13 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>As a startup founder, you get pulled in a million different directions from the moment you start your company. It can be overwhelming to have to learn so many new skills at once: raising funds, hiring a team, managing people.</p>
<p>Before I started <a href="https://draft.dev/">Draft.dev</a> earlier this year, I spent almost a decade working with startups, reading, and preparing myself to run a business. I worked with some great people, met fantastic mentors, and read some outstanding books that gave me the confidence to go out on my own. In this post, I’ll give you my list of the best startup books available today.</p>
<h2 id="early-stage-startups">Early-Stage Startups</h2>
<p>This category includes books for people who are just starting out. If you are building your first product or raising the first round of funding, these books will provide you with a good starting point.</p>
<h3 id="founders-at-work-stories-of-startups-early-days"><a href="https://amzn.to/390FASS">Founders at Work: Stories of Startups’ Early Days</a></h3>
<p>What I love about this book is that it shows you how several popular technology companies started out. The book is a collection of interviews with founders of Paypal, Hotmail, Apple, and other giants of our era. It’s interesting to see where they got the ideas that eventually made them household names and how they recovered from various difficulties along the way.</p>
<p>“If you’re thinking about entrepreneurship you should read this book to get familiar with the possibilities, both the positives and the challenges. From the success arrived by a detour to the success of following a dedicated plan. There’s much to absorb and it’s just plain interesting.”</p>
<h3 id="the-innovators-dilemma"><a href="https://amzn.to/3nxL9fs">The Innovator’s Dilemma</a></h3>
<p>Written by the Harward professor and businessman Clayton Christensen, The Innovator’s Dilemma is one of the most important business books on the market. It explains how mammoth, successful companies can lose market leadership in a blink of an eye as new competitors rise and become dominant in emerging segments of their market.</p>
<p>“Christensen shows that successful innovation is not unpredictable. This comes with the recognition, however, that “data only exist about the past” and hence what is working in the present for leading firms need not apply to disruptive firms of the future. This paradigm necessarily applies to all companies and is not exclusive to technological ones.”</p>
<h3 id="the-lean-startup"><a href="https://amzn.to/2KhETKk">The Lean Startup</a></h3>
<p>We live in an age where technology changes rapidly and quickly changes the market around it. This means that sometimes, you have to move fast to avoid getting swallowed up by innovation. In The Lean Startup, Ries talks about his own business failure and how he spent too much time on the initial product launch instead of focusing on validating the market.</p>
<p>“This book focuses on giving an overview of Lean methods and convincing you why you should use them. It uses a lot of examples, mainly from startups. Some of the best examples come from the author’s own experience, and his company continues to do well.”</p>
<h3 id="zero-to-one-notes-on-startups-or-how-to-build-the-future"><a href="https://amzn.to/3fg4EWN">Zero to One: Notes on Startups, or How to Build the Future</a></h3>
<p><a href="https://amzn.to/3fg4EWN"><img src="https://i.imgur.com/eN4XABh.jpg" alt="Zero to One book cover"></a></p>
<p>I don’t love Peter Thiel’s politics, but I do like how he pushes readers to think for themselves. He explains that you don’t necessarily have to fight the competition to be the leader in the market. Instead, by thinking out of the box and creating a brand new market, you can become a leader with no competition at all. With a unique idea, you can escape the rivals and focus completely on your unique value proposition.</p>
<p>“Let me assure you that Zero to One is worth reading, even if you’re not engaged in the world of startups and venture capital. It’s worth reading in the same way a triple espresso is worth drinking: it makes you feel superhuman, at least for the moment. You can almost hear the caffeine coursing through your veins as you absorb the ideas.”</p>
<h3 id="the-art-of-the-start"><a href="https://amzn.to/38YBhXT">The Art of the Start</a></h3>
<p>Although named “The Art of the Start,” this book covers various business areas, including the art of launching, positioning, socializing, and marketing your startup. In 13 easy-to-read chapters, Guy Kawasaki talks about crucial topics for startup founders like finding a business idea, finding the right co-founder, writing a vision statement, and defining your business model.</p>
<p>“Never assume you’re done. Recruiting doesn’t stop when a candidate accepts your offer, nor when he resigns from his current employer, nor on his last day at his current employer—not even after he starts at your organization. In actuality, recruiting never stops. Every day is a new contract between a startup and an employee.”</p>
<h3 id="the-startup-owners-manual"><a href="https://amzn.to/3nxLiQ2">The Startup Owner’s Manual</a></h3>
<p>With over a hundred charts, graphs, and valuable checklists, this book helps startup founders in many ways. For example, it teaches you how to avoid “deadly sins” that lead your business to failure and how to drive your company to repeatable and scalable profits. The methods in this book were created by Steve Blank, a famous Silicon Valley startup, and were tested by him for more than a decade.</p>
<p>“Best entrepreneur book period. If you liked Lean Startup (another great read/education) you’ll love this one by Steve Blank. He taught those guys. I love how the author really reset your approach and lays out a clear plan on how to test and scale.”</p>
<h2 id="growth-stage-startups">Growth Stage Startups</h2>
<p>Books in this category will teach you how to grow your business from the first few customers to wider adoption. These will also help you sell high-dollar products and scale your sales to the next level.</p>
<h3 id="crossing-the-chasm-marketing-and-selling-high-tech-products-to-mainstream-customers"><a href="https://amzn.to/2UL4oWm">Crossing the Chasm: Marketing and Selling High-Tech Products to Mainstream Customers</a></h3>
<p>I first read this classic over a decade ago. It explains the way products move to progressively more mainstream markets and how you can cross the “chasm” from early adopters to these lucrative mass markets. Although technology changes rapidly, the principles in Crossing the Chasm can still be applied in the software industry today.</p>
<p>“The author’s emphasis is on distinguishing between the selling and marketing tactics for the early innovators versus mainstream customers. There is a chasm between the innovators and mainstream market and the author dedicates the book outlining the various steps a high tech company should perform to successfully navigate through the chasm.”</p>
<h3 id="hacking-growth-how-todays-fastest-growing-companies-drive-breakout-success"><a href="https://amzn.to/35Mrz99">Hacking Growth: How Today’s Fastest-Growing Companies Drive Breakout Success</a></h3>
<p>Ever wonder why Facebook unseated early entrants like MySpace to become the number one social network? Or how Uber succeeded despite seeming to have no chance against New York’s Yellow Cabs? With the proper methodology - known as “growth hacking” - they became the giants of our era. Sean and Morgan’s stories inspired me, and I recommend this book to any founder who will handle marketing.</p>
<p>“The authors walk the reader through each stage of building a growth machine, give examples from real companies, and, the best part, they apply this process to a hypothetical scenario/product so you can see what it would look like from beginning to end.”</p>
<h3 id="the-hard-thing-about-hard-things"><a href="https://amzn.to/3fjCUAS">The Hard Thing About Hard Things</a></h3>
<p>This book is a collection of stories from the career of Ben Horowitz, one of the most respected entrepreneurs of Silicon Valley. It reveals problems that he faced during his journey from being a founder to becoming an investor. It analyzes difficulties that confront leaders every day, related to management, selling, investment, and staying balanced.</p>
<p>“If you’re planning to start a company, whether it’s a high-tech company or the kinds of companies that I started and ran, read this book. If you’re going to be someone in charge of anything in any kind of a company, read this book.”</p>
<h3 id="great-at-work-how-top-performers-do-less-work-better-and-achieve-more"><a href="https://amzn.to/2IXvYNp">Great at Work: How Top Performers Do Less, Work Better, and Achieve More</a></h3>
<p>Early in my career, I worked too much on too many projects. It took me nearly a decade to figure out that putting hours into <em>the right</em> things was the key. This book debunks the myth of multitasking, talks about coordinating between priorities, and reveals how to make your work time more productive.</p>
<p>“With the massive amount of business books published every year, it’s tough to find a book with some original ideas. This book is one of those. What’s great about it is that there isn’t a lot of fluff and the book gets to the points of what can help one become a great performer. I would recommend this book to any leader out there who wants to help his or her team grow and become more, with less of the wrong kind of work.”</p>
<h2 id="hiring-and-management">Hiring and Management</h2>
<p>At some point in running a business, you will have to build a team of professionals around you. You will likely move into management, which requires an entirely new set of skills. These books helped me out, and I’m sure you will find them useful, too.</p>
<h3 id="recruit-rockstars-the-10-step-playbook-to-find-the-winners-and-ignite-your-business"><a href="https://amzn.to/3fjDuP4">Recruit Rockstars: The 10 Step Playbook to Find the Winners and Ignite Your Business</a></h3>
<p>I learned the hard way that <a href="https://www.karllhughes.com/posts/hiring-process">many business-related problems have their roots in poor hiring practices</a>. Instead of hiring consistent A-players, many startup founders rush to assemble half-hearted teams that are bound to fail. Hyman shows his ten practical steps to recruiting top talent in this book. My favorite part was about choosing employees based on data instead of gut feeling, and I used this to create <a href="https://draft.dev/learn/posts/hiring-rubric">my first hiring rubric at Draft.dev</a>.</p>
<p>“This is the recruitment guide that every startup needs to read. It’s especially valuable for people who might not have a background in recruiting but find themselves in a position where they need to hire the best. Recruit Rockstars is a clear and concise guide that won’t waste your time and gives you the recruitment background you need. I can’t recommend this book enough!”</p>
<h3 id="high-output-management"><a href="https://amzn.to/393d7eX">High Output Management</a></h3>
<p>Written by the former chairman of Intel, this book shows startup founders how to build highly productive teams that lead the company to peak performance. Management isn’t about posturing or power-struggles. It’s about getting results.</p>
<p><img src="https://i.imgur.com/urnxGMb.jpg" alt="High Output Management book"></p>
<p>“The author emphasizes the importance of judging managers based on the output that they achieve, which is an accumulation of the outputs of the people that work for them. He also focuses on the importance of continuing to improve yourself and strive to be better. He rightly points out that nobody owes you …</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/startup-books">https://www.karllhughes.com/posts/startup-books</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/startup-books</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315136</guid>
            <pubDate>Sat, 05 Dec 2020 15:18:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uncertainty and Change]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25314774">thread link</a>) | @RikNieu
<br/>
December 5, 2020 | https://www.riknieu.com/uncertainty/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/uncertainty/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@mikael_k?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Mikael Kristenson</a> on <a href="https://unsplash.com/s/photos/uncertainty?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><h2 id="a-year-of-changes">A year of changes</h2><p>This year has been one of major change. The sheer amount of outlandish things that left the kitchen of providence ruined a lot of appetites, but made for some excellent servings of memes.</p><p>And some, me included, wonder if the year is done with its menu of &nbsp;surprises.</p><p>Here's a small sample of some of the crazy shit that happened;</p><ul><li><a href="https://www.abc.net.au/news/2020-01-07/world-war-3-qassem-soleimani-trump-us-and-iran/11841254">Threats of WW3 </a></li><li><a href="https://www.bbc.com/news/world-australia-50951043">Crazy wild fires in Auz</a></li><li><a href="https://abc7news.com/bay-area-skies-smoke-in-the-air-today-orange-apocalyptic/6416218/">Crazy wild fires in California</a></li><li><a href="https://www.reuters.com/article/health-coronavirus-timeline-idUSL1N2GN04J">A world-wide pandemic</a> with <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic_lockdowns">world-wide, months-long lockdowns</a></li><li><a href="https://www.defense.gov/Newsroom/Releases/Release/Article/2165713/statement-by-the-department-of-defense-on-the-release-of-historical-navy-videos/">The pentagon officially releasing UFO videos</a></li><li><a href="https://www.theatlantic.com/science/archive/2020/07/disappearing-star-supernova-galaxy/613699/">A huge, old star just poofed out of existence</a></li><li><a href="https://www.pbs.org/newshour/world/harry-meghan-to-quit-royal-jobs-give-up-highness-titles#:~:text=Prince%20Harry%20and%20his%20wife,announced%20Saturday%20by%20Buckingham%20Palace.&amp;text=They%20will%20be%20known%20as,and%20Meghan%2C%20Duchess%20of%20Sussex.">Prince Harry quit the royal family</a></li><li><a href="https://www.wired.com/story/inside-twitter-hack-election-plan/">A random teenager hacked the twitter accounts of Joe Biden, Joe Rogan, Bill Gates, Elon Musk and Kanye West</a></li></ul><figure><img src="https://www.riknieu.com/content/images/2020/11/jokes-about-2020-5edf2d2423557__700.jpg" alt="2020: Very bad, would not recommend."><figcaption>2020: 1 star. Very bad, would not recommend</figcaption></figure><p>This year proved that uncertainty is always around, ready to pounce. With this post, I want to explore uncertainty and how it affects our experience of life. </p><p>Why are we always surprised by uncertainty and change? Why do we hope for some things to change and expect others to never change at all. Why do we inflict pain on ourselves and others by identifying with things and assuming them to be permanent truths when they are, in fact, neither?</p><h3 id="covid">COVID </h3><p>An obvious place to start would be an exploration of this little pandemic we're all experiencing. COVID19 has rolled out quite a lot of turbulence over our global society. </p><p>Mask-wearing is no longer something that only a select few Asian countries do. Last year this time, in most places in the world, you would have been regarded with suspicion if you entered public spaces with half your face deliberately hidden.</p><p>Security would have surely tailed you in the malls, and young mothers with infants would have scampered out of your way in the dairy isle. But now, practically everywhere, it's legally <em>mandated</em> that you peer at strangers over a piece of cloth in public, like a bandit or dentist.</p><p>Working remotely has also become commonplace, where it had previously been something only the weird and vagabond do. I myself now perform my duties this way for a company that previously did not even consider it a remote possibility. </p><p>The lockdown came and taught us a lot of things. Some of it good, like that remote work is possible, realistic, and even, perhaps, more productive. <a href="https://www.insider.com/photos-videos-earth-planet-thriving-coronavirus-2020-4">That nature can recover quite quickly</a>, if we but gave her a chance.</p><p>But we also learned that governments could and would force everyone to stay at home, stop working, and stop interacting with friends and family. They could and would force conditions that threatened to kill entire industries and a scary amount of companies and jobs. And we learned that populations, as a whole, will simply comply and go along with these directions.</p><p>And COVID is likely not done yet, and I'm not even referring to a second wave. Quite a lot of people I've spoken with reckon that most of the economic and societal fallout due from even the first one is still yet to come. Like electricity in the air, everyone can feel a storm is brewing.</p><p>COVID has was pretty effective in its disruption of whole societies and cultures in an instant. But there are other more mundane ways uncertainty and change expresses itself if our lives, whether we like it or not.</p><h3 id="moving-can-be-quite-disruptive">Moving can be quite disruptive</h3><p>For instance, I moved to a new residence recently. It was sudden and unexpected, and revealed exactly how much I personally rely on routine and the familiar to feel relaxed and in control of my life.</p><p>Having to change where you call home and mentally adjust who you consider your community can be quite disruptive. It's like it dislodges little pieces of your identity that you didn't consider before.</p><p>What you like, dislike or get used to about your everyday life are like pieces of Lego blocks, and these little conceptualisations eventually assemble themselves into what you consider yourself. They click together into a tapestry of assumed identity and you take them to be statements of who <em>you</em> are. "I am someone who gets up and exercises at 5am", "I am Californian", "I like this brand of coffee", "I listen to that podcast on my commute", "I am happy when it rains in the afternoon".</p><p>These are little behavioural heuristics we adopt to help smooth out and automate decision-making in our daily lives, creating concealed yet interlinked chains of dependencies that we experience as a sense of control and consistency. They are webs of reassurance. They make us feel that things are as they should be, we can relax. </p><p>This is how they catch and trap us. </p><p>Out of ignorance we weave together an assumed reality and take it for a dependable Truth.</p><p>When you move, a portion of that goes out of the window. You'd be surprised how many of those little circumstantial components you unconsciously adopted as part of your identity gets shaken loose when you just move your domicile. It's can be a little bit like going to a foreign country and experiencing severe culture shock. Your very identity is now suddenly on shaky ground and full of holes.</p><p>You need to actually think about things again that, just a day before, were so certain and True that they were not even worth a second of reflection. </p><p>I now need to deal with mosquitos all hours of the day where this wasn't an issue I needed to contend with last week. Then I was a peace loving being, in harmony with nature. Now I can be an annoyed, angry person that wants to deal out death with slaps of spite. That's extra mental energy and patience I'm having to expend, and it forms into internal conflict.</p><p>Cumulatively these form daily drips of discomfort. And discomfort can eventually build up into pain and suffering.</p><p>But let's get back to larger scale changes again. What if the stability of our entire society and community crumbles?</p><h3 id="worlds-that-were-eternal-but-now-aren-t">Worlds that were eternal but now aren't</h3><p>Think about the world. Who are the major powers, what conclusions can you draw about how things will likely play out in the future, and what is your own community's place is in this world?</p><p>These are assumptions that you use to make long-term decisions to try and ensure the safety and happiness of your self, your family, and community.</p><p>Now take those assumptions, crumble then up and throw the lot in the trash, because as I shall explain, nothing in the world is for sure, not even the world order as you know it.</p><p>History is rife with examples of the seemingly invulnerable superpowers and empires crumbling into dust in mere decades, if not faster. Recent examples include Yugoslavia and the USSR. I have friend who personally lived through the disintegration and disappearance of the former. In the 60s and 70s, the complete collapse of the latter in <em>a mere 30 years</em> would have seemed very, <em>very</em> unlikely.</p><p>What happened to the British Empire? The Austria-Hungary Empire, the Ottoman Empire? All of these were major, world-shaking powers only a lifetime or so ago.</p><p>But let's go back a bit further and look at societies that must have felt to be even more eternal to their citizens. </p><p>Would it have been conceivable to the Aztec's Montezuma, that the strange-looking European Hernán Cortés and his odd band of men would in 8 months be able to lay utter waste to an almost 180 year old empire? That their entire culture, religion and history would be swept away in what must have felt like an instant torrent of blood, tears and immeasurable misery. </p><p>And it wasn't just them, the Spanish invasion of the New World would eventually destroy the entire way of life and culture of many people that had first ventured into the Americas 20K+ years ago.</p><p>In the old world, more examples; Assyria lasted 756 years as one of the most powerful superpowers in its region. That is a long-ass time. How could it end? What did it feel like for citizens when Assyria fell?</p><p>The Roman empire, if you include Byzantium, lasted just under 1500 years! Can you even comprehend that? Can you imagine living in that society and someone suggested that, one day, the Roman Empire would be no more. No Roman citizen would have believed such nonsense. It would have been inconceivable.</p><p>Even more so Sumer, which existed for 2000 years before it was in ruins. Egypt was a de facto world power of the 'known' world for 30 centuries. Where are they now? </p><p>And take my word for it, the current batch of powerful and "invincible" countries will all be gone one day too. Current incarnations of the US, China, Germany, Russia - all of them will one day be no more, and replaced with other, different societies.</p><p>Consider your own country. If you strongly identify with your nation and your culture, and feel <em>particularly</em> nationalistic, think about what it could mean if one day your country would be no more too. </p><p>And consider that your decedents who would be around then would also be very proud to belong to whatever community would have come into existence then. They would be proud to be <em>something </em>completely different to<em> </em>that that which you now hold so dear. They will be part of another nation, another people. They would be like foreigners, your children's children's children.</p><p>You might feel particularly proud and protective of your culture and religion, but consider that your ancestors would possibly be aghast that you, their kin, their very bloodline, now cling to and defend a religion and culture that awful, merciless enemies came and forced unto them, when they came and conquered their lands and destroyed their communities. This happened countless times throughout history and almost certainly happened to your own family if you go back far enough.</p><p>I'm writing this in Roman characters, living in a society who's laws were built on Roman law, and who's very fabric is structured around things invented by the Romans. But my ancestors were mostly from the barbarians up in northern Europe, who got conquered, decimated, and sold into slavery by the Romans. </p><p>What would they think of me now, this bastardised Roman-Germanic decedent of theirs, living in a far-off land, with a culture, language, values and word view so foreign to …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.riknieu.com/uncertainty/">https://www.riknieu.com/uncertainty/</a></em></p>]]>
            </description>
            <link>https://www.riknieu.com/uncertainty/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314774</guid>
            <pubDate>Sat, 05 Dec 2020 14:30:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 in Sweden]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25314732">thread link</a>) | @ComputingMonk
<br/>
December 5, 2020 | https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/ | <a href="https://web.archive.org/web/*/https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <h2 id="i">I</h2><p>When Sweden announced their laissez-faire approach to COVID-19, experts, and politicians around the world, were in disbelief. Without a lockdown and mandatory masks, this could only end in a disaster. The famous model used to justify the lockdown in the <a href="https://www.businessinsider.com/neil-ferguson-transformed-uk-covid-response-oxford-challenge-imperial-model-2020-4?r=DE&amp;IR=T">UK and many other countries</a>, predicted 100.000 deaths by June if Sweden did not follow all the other countries and institute strict measures. It is now November, and at the time of writing, 6,972 people have died in Sweden from COVID-19. So what happened?</p><h2 id="ii">II</h2><p>Let’s take a step back and look at the famous model, which was the basis for many of the government measures back in March as well as for the 100.000 death prediction: The Imperial Model. It was developed by Neil Fergusson and his team at the Imperial College London.</p><p>The involvement of Neils Fergusson should already have raised doubts about the validity of the model because his track record, and there is no other way to say this, is terrible. If you think it cannot be that bad, you are in for a surprise.</p><p>We will do what <a href="https://www.businessinsider.com/neil-ferguson-transformed-uk-covid-response-oxford-challenge-imperial-model-2020-4?r=DE&amp;IR=T">Business Insider</a> promised back in April:</p><blockquote>Here's what we know about “Professor Lockdown” and the gold standard in science that is Imperial College.</blockquote><p>Of course, they did not mention his past predictions, and the “gold standard” turned out to be fake gold, but let's not get ahead of ourselves. His past predictions:</p><ul><li><a href="https://www.nationalreview.com/wp-content/uploads/2020/05/Ferguson-Estimating-the-human-health-risk-from-possible-BSE-infection-of-the-British-sheep-flock.pdf">In 2002</a>, Ferguson predicted that up to 150,000 people could die from exposure to BSE (mad cow disease) in the U.K. There were only 177 deaths.</li><li><a href="https://www.nationalreview.com/corner/professor-lockdown-modeler-resigns-in-disgrace/">In 2009</a>, Ferguson predicted that the bird flu could kill 150 million people. 282 people died worldwide.</li><li><a href="https://www.spectator.co.uk/article/six-questions-that-neil-ferguson-should-be-asked">In 2009</a>, Ferguson predicted as a “reasonable worst-case scenario” that the swine flu would kill 65,000 people in Britain. It killed 457.</li></ul><p>I think that is enough about our “Professor Lockdown.” We want to focus more on the model and “the gold standard in science that is Imperial College.”</p><h2 id="iii">III</h2><p>One reason why nobody doubted the model was that it was secret—always a smart move. When on March 16, 2020, Neil and his team published their paper, they did not publish their code. Yes, you read that correctly. Their paper made several policy recommendations based on predictions of a model <em>they did not publish</em>. So there was no way of knowing if their claims were true or false. They were simply baseless claims without any evidence.</p><p>To me, this destroys any trustworthiness Neil Ferguson might have had left. One hallmark of science is independent verifiability. Without others being able to verify the claims and run the model themselves, it is not science; it is pseudo-science with a strong appeal to authority.</p><p>On April 27, over one month after the paper in question was published, they finally released their code on <a href="https://github.com/mrc-ide/covid-sim">GitHub</a>. However, it turns out that they did not release the original code used to generate the predictions in their paper. The released version was edited by software engineers of GitHub to make it acceptable:</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Before the GitHub team started working on the code it was a single 15k line C file that had been worked on for a decade, and some of the functions looked like they were machine translated from Fortran. There are some tropes about academic code that have grains of truth, but \</p>— John Carmack (@ID_AA_Carmack) <a href="https://twitter.com/ID_AA_Carmack/status/1254872369556074496?ref_src=twsrc%5Etfw">April 27, 2020</a></blockquote>

</figure><p>As you can read in this Tweet, the original code was “a single 15k line C file that had been worked on for a decade.” Everyone with a little bit of knowledge about software engineering should be shocked. A single 15000 line C file is beyond bad practice.</p><p>But even GitHubs’s engineers could not salvage the code. The released version is still riddled with bugs and random equations that literally nobody can explain. Moreover, even if the released code were exactly the code used in the paper, no one could have replicated the results because the input parameters used in the paper were not published. As the <a href="https://github.com/mrc-ide/covid-sim/tree/master/data">GitHub page</a> reads:</p><blockquote>IMPORTANT: The parameter files are provided as a sample only and do not necessarily reflect runs used in published papers.</blockquote><p>At this point, we are long past science, with a small s, and far into the world of Science, with a capital S. The latter is the world where the term “Believe the Science” makes sense. While science (small s) is the process of doubting everything, disregarding authority, and searching for the truth, Science (capital S) is where the truth is determined by fiat, and your job is to believe, not question it. But I digress.</p><h2 id="iv">IV</h2><p>After several issues around the non-deterministic behavior of the model were brought up on GitHub, the team responded with an <a href="https://github.com/mrc-ide/covid-sim/issues/116#issuecomment-617304550">interesting answer</a>:</p><blockquote>We are aware of some small non-determinisms when using multiple threads to set up the network of people and places. (Look for the omp critical pragmas in the code). This has historically been considered acceptable because of the general stochastic nature of the model.</blockquote><p>Non-deterministic means that given the same input, you do not always get the same output (non-deterministic behavior is not necessarily bad; only in cases like this where it is not explainable). Their answer to this problem was that it does not matter because the model is “stochastic,” which is just a fancy word for saying that they run the model multiple times and average over all the outcomes.</p><p>Every time a new issue around non-determinism came up or a different bug was discovered, the team’s answer was the <a href="https://github.com/mrc-ide/covid-sim/issues/30">same</a>:</p><blockquote>This isn’t a problem running the model in full as it is stochastic anyway.</blockquote><p>But is this really true? You do not have to worry about bugs because “it is stochastic anyway”? The answer is, obviously, no.</p><p>To understand this stochastic magic better, let’s take a look at an example: baking a cake. If we weigh flour, we might weigh it several times and then average over all these measurements—only if we are nerds and want to follow the recipe particularly closely, of course. But why does this give us a more accurate result? The answer is that if, for example, we make an error when reading from the scale (imagine an old analog scale), then an error in one direction (more) is as likely as an error in the other direction (less). In other words, if the flour weighs 100 grams, you are just as likely to mistake it for 102 g the first time, and 98 g the next. Only if we make mistakes sometimes in one direction and sometimes in another, averaging out works. Otherwise, <em>it does not</em>. If your scale is broken, and always shows five grams more, averaging does not help you.</p><p>The same is true for bugs. If, and only if, we could be sure that the bugs distort the output sometimes upwards and sometimes downwards (preferably with equal probability and magnitude), we could solve the problem by running the model “stochastically.” However, this is not the case because, by definition, we do not know how bugs affect the code; otherwise we would understand them and probably be able to fix them. The point is that nobody, including the “scientists” who produced this model, can know how those bugs affect the code.</p><p>Do not get me wrong, stochastic models are not necessarily like this. Most of the time, if the model is not too complicated (we will get to this point later), small changes in the input create small changes in the output, and the randomness in the output stems from intentionally included pseudo-randomness. However, this model is not non-deterministic in the predictable (explainable) mathematical sense. It is non-deterministic in the angry-toddler-in-a-toy-store sense: nobody knows what is going to happen, and there is no way to replicate it. <a href="https://medium.com/@allenfarrington/simple-truths-and-complex-nonsense-2e1c28ae6f29">Put differently</a>:</p><blockquote>It has nondeterministic outputs that do not follow from seeded pseudorandomness but are rather an inexplicable part of the process. I am not using “inexplicable” rhetorically here: nobody can explain this. This is one of the great issues in Complexity Science. Clearly there is a stark mathematical difference between deterministic and non-deterministic. But there is also a fuzzy, and arguably more important, difference between non-deterministic and really, really, really NON-DETERMINISTIC.</blockquote><p>Unfortunately, the Imperial Model falls into the latter category.</p><h2 id="v">V</h2><p>Alright, a summary of what we have learned so far: the code was not released with the paper; the released code is not the code used in the paper; the original code was a single 15 thousand line C file; the model is non-deterministic bordering on chaotic; the parameters released are not the parameters used in the paper; the code is riddled with bugs. An impressive list for a “scientific” model that informed government decisions on life and death.</p><h2 id="vi">VI</h2><p>But what about the model without the code? Sure, the code that implements the model is awful, but maybe they have figured out a great way to model pandemics and just need better software engineering to make it work. Sadly, this is not the case.</p><p>Do you remember the parameters that were <em>not</em> provided so nobody could replicate the results of the paper? It turns out that the model has 450 input parameters. Let me say it again: the model depends on <em>450 (!!!)</em> parameters. Nobody can understand a model with this many parameters. And it gets even worse because as it turns out, complex systems like pandemics have many interdependencies, which complicates everything. As described by Allen <a href="https://medium.com/@allenfarrington/simple-truths-and-complex-nonsense-2e1c28ae6f29">here</a>:</p><blockquote>Now I should be clear that, maybe, the virus is that complicated. But it doesn’t matter. Because we can’t possibly understand this. And actually I lowballed it by a factor of 450 (Oh, God …). Because if this system is linear, which it surely is not, what this really means is that a single set of parameters can be represented as a 450-dimensional column vector acting on a 450x450 matrix with 450² = 202k independent numbers. Because, remember, the parameters can be anything. Katya suspects they are totally made up. So it’s not just the dimensions we need to account for. The surface of the earth has 2 dimensions but more than 2 locations. Assuming every entry in this matrix has only two possible states, which it surely does not, this model maps a system with at least …</blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/">https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/</a></em></p>]]>
            </description>
            <link>https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314732</guid>
            <pubDate>Sat, 05 Dec 2020 14:21:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Neobanks Should Monetize Status Signaling]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25314600">thread link</a>) | @imartin2k
<br/>
December 5, 2020 | https://julian.digital/2020/12/03/banking-on-status/ | <a href="https://web.archive.org/web/*/https://julian.digital/2020/12/03/banking-on-status/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 		
<h3>How Neobanks Should Monetize Status Signaling</h3>



<p><span>01</span> Intro</p>



<p>If you’ve been following this blog for a while, you probably know by now that one of my favorite topics to think and write about is “status signaling”.</p>



<p>Signaling explains most of our everyday actions: what clothes we wear, which universities we pick and which religion we subscribe to. Everything has a hidden signaling component with which we communicate our desired tribal affiliation.</p>



<p>In <a href="http://julian.digital/2020/03/28/signaling-as-a-service/">Signaling-as-a-Service</a>, I described the implications signaling has on the monetization of software businesses. For many traditional industries, monetizing the display of status is not a new concept. A Rolex watch, for example, is not better at telling the time than a cheap Casio watch. But a Rolex reveals something about its owners’ wealth and, thus, their status in society. It’s that status message that explains the difference in price.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/equaltime.png"></p><p>Similarly, driving a Prius says something about your views on climate change. A <em>Make America Great Again</em> cap reveals something about your political affiliations. And Nike athletic wear signals a healthy, pro-active lifestyle.</p>



<p>Software is at a crucial disadvantage compared to these physical products because of its intangibility. A fitness app also signals a healthy, pro-active lifestyle, but no one can see it because it only lives on your phone. Everyone can see your Nike gear whenever you wear it in public. Software can’t offer the same benefit. It doesn’t have a signaling distribution channel.</p>



<p>This is why there is no software equivalent of a Rolex watch or a Louis Vuitton handbag. People aren’t willing to spend money on things other people can’t see they spent money on.</p>



<p>But it doesn’t have to be that way. As software is eating the world, the lines between physical and digital products are becoming increasingly blurry. As I have pointed out in my original essay, one way for software companies to solve the signaling distribution problem is to add a physical element to their software product.</p>



<p>In this post I want to explore this idea a little bit further. Specifically, we’ll look at neobanks – and their opportunity to monetize credit card signaling.</p>



<p><span>02</span> Neobanks</p>



<p>In the last couple of years we have witnessed the birth and rise of a new startup vertical: neobanks.</p>



<p>Neobanks differ from traditional banks in two ways:</p>



<p>1) Rather than relying on a physical branch network, the entire banking experience is managed via an app</p>



<p>2) Instead of the <a href="https://www.youtube.com/watch?v=C-q4bEULG64">“how do you do, fellow kids”</a>-cringiness that ad campaigns of traditional banks usually invoke when they try to appeal to a younger audience, neobanks are actually perceived as cool. In fact, many of them feel more like lifestyle brands than banks or tech companies.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/12/1_26qGBSGmB3yaPD7nZJrFIg.gif">



<img src="https://julian.digital/wp-content/uploads/2020/12/lifestylebrand-1.png"></p><p>Interestingly though, neobanks still use one very traditional banking element: physical cards.</p>



<p>At first glance, this might seem counterintuitive. If you are building a mobile-first bank, why not offer virtual cards and let users pay with their phone? Why go through the hassle of producing and shipping physical cards?</p>



<p>The answer is – you guessed it – signaling.</p>



<p>Think about it: Paying for things (offline) is a social activity. It’s an interaction between at least you and a cashier or waiter. But ideally, in a dinner scenario for example, you are surrounded by other people you want to impress: a date, a group of friends, or work colleagues.</p>



<p>This makes the moment you take out your card to pay the bill a great opportunity to make a statement and build social capital.</p>



<p>If you look at neobanks out there today, it’s pretty obvious that signaling is in fact one of the main benefits they offer – and almost the only thing they monetize <span>(apart from interchange, of course)</span>:</p>



<ul><li>The premium subscriptions neobanks offer usually don’t win on features but solely on nicer looking cards. The <a href="https://n26.com/metal">N26</a> or <a href="https://revolut.com/metal">Revolut</a> Metal plans, for example, don’t offer any additional features that <em>really</em> justify the ~€15 / month price tag. They do include a nice looking metal card though – that’s what people pay for.</li><li>Relatedly, it seems like most of the innovation in the industry is happening in card design. The actual banking products are more or less interchangeable, what differs is whether the card comes in <a href="https://www.apple.com/apple-card/">titanium</a>, <a href="https://www.treecard.org/">wood</a>, or <a href="https://twitter.com/cashapp/status/1290694734529400832">glow-in-the-dark yellow</a>.</li><li>You may have noticed that the credit card number has moved from the front to the back of the card. This makes it easier for users to share photos of their cards on social media as an additional signaling distribution channel.</li></ul>



<p><img src="https://julian.digital/wp-content/uploads/2020/11/nocardnumber-1.png"></p><p>Neobanks are popping up like mushrooms after the rain at the moment and it’s unlikely that this trend will end any time soon. Thanks to banking-as-a-service providers, we’ll likely see a lot of non-banking-companies add banking functionalities and cards to their product offering.</p>



<p>There’s an old Twitter joke that every app evolves until it eventually becomes a chat app. The 2020 version of that joke is that every app evolves until it eventually becomes a bank.</p>



<p>When <a href="https://twitter.com/lehrjulian/status/1295024066869567488">I did some research on credit card designs</a> recently, I was surprised by the sheer amount of different neobanks already in existance. And yet, even though almost all of them offer well-designed cards, it’s shocking how similar they all are. It seems like all of them are focusing on the same target audience instead of differentiating their signaling messages.</p>



<p>Let me explain.</p>



<p><span>03</span> In-Groups, Out-Groups and Artificial Scarcity</p>



<p>In every signaling scenario there are two possible target audiences: An in-group and an out-group.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/groups.png"></p><p>The in-group is the tribe you want to join and signal your affiliation to. The out-group is everyone else – people you want to distance yourself from.</p>



<p><a href="https://www.fastcompany.com/90391587/why-we-dont-want-you-and-your-android-green-bubbles-in-our-imessage-chat">iMessage is a great illustration of this</a>: the chat bubble colors clearly indicate who belongs to the in-group (blue = iOS) and who is part of the out-group (green = Android). </p>



<p>It’s important to note that signaling in iMessage is limited to the in-group since these color codes are only visible for iOS users – Android users can’t see who in the group is using which operating system. </p>



<p>Signaling, however, grows stronger the larger the out-group is – as long as the out-group knows about the in-group. This is why luxury car manufacturers deliberately extend their advertising campaigns to people who will never be able to afford their cars: they are increasing the size of the out-group by educating people about the in-group.</p>



<p>At the same time, brands need to control the size of the in-group. The more exclusive the in-group, the higher the signaling strength and, thus, the monetization potential of a customer. </p>



<p>The easiest control mechanism for the size of the in-group is price. If you set the price high enough, few people will be able to afford the product. Ironically, this, in turn, justifies the high price.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/priceloop.png"></p><p>Alternatively, companies create artificial scarcity by setting a hard number on supply. Limited supply creates FOMO and hype which increases the size of the out-group and results in higher social status for members of the in-group. Artificial scarcity explains the price of Bitcoin, Pokémon trading cards and why people spend hours queuing in front of Supreme shops.</p>



<p>The problem with keeping the in-group small is that it also limits the number of potential customers and, thus, overall revenue potential. Companies need to walk a fine line between maximizing the number of customers while simultaneously maximizing the number of people they can (afford to) exclude.</p>



<p><span>04</span> What Neobanks Should Build</p>



<p>The problem with neobanks today is that they all focus on the same in-group. Here are the premium cards of some of the largest European challenger banks – notice any difference?</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/metalcards.png"></p><p>It seems like everyone is trying to become the Apple of Banking – including <a href="https://www.apple.com/apple-card/">Apple itself</a>. The signaling messages are all about displaying economic power.</p>



<p>But we are slowly seeing new banking apps that are focusing on different audiences. For example, there are now a <a href="https://www.tomorrow.one/">handful of</a> <a href="https://blog.gohenry.com/uk/gohenry-news/meet-our-new-biodegradable-eco-card/">“green”</a> <a href="https://www.treecard.org/">neobanks</a> that help users signal environmental altruism. </p>



<p>Or how about <a href="https://www.razer.com/razer-card">this Razer Card</a> targeted at the gamer community?</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/12/environment.png"></p><p>The question for these companies and their investors is whether the in-group is big enough to justify building an entire bank around it. Making the unit economics of a bank work requires a certain amount of users, but as we discussed earlier, the signaling strength decreases as the size of in-group increases.</p>



<p>So how do you solve this problem?<br>By introducing multiple in-groups.</p>



<p>See, the current model looks like this:</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/neogroup01.png"></p><p>(In fact, given how undifferentiated most of the offerings and cards are, there are actually multiple neobanks within the same small in-group bubble.)</p>



<p>But what if one bank would target multiple, different in-groups?</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/neogroup02.png"></p><p>For example, what if N26 had dedicated cards for soccer fans, hip-hop enthusiasts and gamers? Instead of focusing on just one signaling audience, their total addressable market would massively increase. </p>



<p>The way they would target these audiences is via brand collaborations. N26 does not have the necessary reputation in any of the above-mentioned areas to build credible signaling messages. It would not be able to build attractive in-groups on its own – but other brands could lend N26 their social capital. </p>



<p>Apple has long worked with <a href="https://www.apple.com/lae/product-red/">RED</a>, IKEA recently <a href="https://www.highsnobiety.com/p/virgil-abloh-ikea-collaboration-best-look/">teamed up with Virgil Abloh</a>, and <a href="https://www.headspace.com/partners/nike-partnerships">Nike partners with Headspace</a>. Why wouldn’t this concept work for neobanks?</p>



<p>What would <strong>N26 x Manchester United</strong> look like? <br>Or <strong>Chime x Supreme</strong>? <br>Or <strong>Revolut x 100 Thieves</strong>?</p>



<p>Because of a bigger target audience overall, individual in-groups could be kept smaller. Cards could be <a href="https://thegeneralist.substack.com/p/scarcity-as-an-api">released as limited edition drops</a> transforming them into collectibles, which would justify a higher price tag per card.</p>



<p>It’s worth noting that different signaling audiences are not mutually exclusive. We don’t just subscribe to a single in-group – our <a href="http://julian.digital/2020/09/25/is-this-real-life/">identities are prismatic</a>. This means that some users might …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://julian.digital/2020/12/03/banking-on-status/">https://julian.digital/2020/12/03/banking-on-status/</a></em></p>]]>
            </description>
            <link>https://julian.digital/2020/12/03/banking-on-status/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314600</guid>
            <pubDate>Sat, 05 Dec 2020 14:00:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NASA Puts the Kibosh on VSVN]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25314551">thread link</a>) | @jawns
<br/>
December 5, 2020 | https://shaungallagher.pressbin.com/blog/nasa-vsvn.html | <a href="https://web.archive.org/web/*/https://shaungallagher.pressbin.com/blog/nasa-vsvn.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="portfolio">
        <div>
            <div>
                <div>


<div>





<p>A couple of weeks ago, I noticed something really cool about NASA's classic "Worm" logo:</p>

<p><img src="https://shaungallagher.pressbin.com/blog/img/nasa.svg"></p>

<p>If you flip it upside down, it produces a new acronym: VSVN.  I'm not sure what those letters might stand for, 
   but this little discovery was Very Surprising and Very Neat.</p>

<p>It occurred to me that it might be fun to come up with some sort of design that incorporates the letters VSVN,
   and my first thought was to put a cheeky twist on the
   <a href="https://www.etsy.com/market/nasa_worm_logo">multitude of apparel items</a>
   that feature the NASA "Worm" logo.</p>
   
<p>I created a mock-up of a VSVN design and uploaded it to <a href="https://teespring.com/">Teespring</a>,
   which allows designers to sell apparel online:</p>
   
<p><img src="https://shaungallagher.pressbin.com/blog/img/vsvn-shirt.jpg"></p>

<p>But a few minutes after publishing the design, I received an email from Teespring notifying me that my listing had been removed:</p>

<blockquote>
    Your campaign has been terminated early due to content concerns.
    It appears your campaign may be using content owned by a third party.
</blockquote>
   
   
<p>That was strange.  Were they talking about the NASA "Worm" logo?</p>

<p>Normally, under the U.S. Copyright Act, any creative works produced by the U.S. government automatically become part of the public domain.</p>

<p>So, for instance, <a href="https://en.wikipedia.org/wiki/Category:NASA_images">these NASA images</a> of the moon, the Earth, and the stars
   can be freely used, even commercially, without having to get permission from the agency.</p>
   
<p>But after doing some research, I learned there are <a href="https://www.usa.gov/government-works">a few specific exceptions</a> to that general rule.
   And one of them pertains to agency logos:</p>
   
<blockquote>
    You cannot use government trademarks or government agencies' logos without permission.
</blockquote>
      

<p>If federal agencies' logos are not in the public domain, what explains the proliferation of T-shirts,
   sweatshirts, and other apparel that prominently feature the NASA logo?</p>
   
<p>It turns out that NASA does routinely grant permission for its logo to be used on apparel, subject to
   some <a href="https://www.nasa.gov/audience/formedia/features/Merchandising_Guidelines.html">rather restrictive regulations</a>.
   When permission is granted, there are no licensing fees involved,
   which can make NASA-themed apparel a lucrative line of business.</p>

<p>But does this VSVN design actually infringe on NASA's logo?</p>

<p>On the one hand, it is certainly true that if you flip VSVN upside down, you get the NASA logo, which is the agency's trademark.</p>

<p>But within copyright and trademark law, there is a concept known as <a href="https://www.copyright.gov/fair-use/more-info.html">fair use</a>.
   Fair use is a defense against a claim of infringement; when a work is covered under the fair-use defense,
   it can be used without a license from the copyright or trademark holder.</p>

<p>There are multiple factors that go into determining whether an unlicensed use of a work
   is covered under the fair-use defense, and in general fair use is broader for copyright than trademarks,
   but one key factor is whether the work is 
   <a href="https://www.justia.com/intellectual-property/copyright/fair-use/transformative-use/">transformative</a>,
   meaning that the new work has fundamentally changed the meaning, interpretation, or nature of the original work.</p>

<p>While in many cases merely flipping a logo 180 degrees is not sufficiently transformative to survive
   a claim of infringement, there are some rare cases where an upside-down representation of a logo is indeed transformative,
   such as when the new work is clearly perceived as something that stands on its own, and is not merely perceived as
   the original work flipped upside-down.</p>
   
<p>In the case of VSVN, I'm going to wager that the average person does not immediately recognize the design as an
   upside-down version of the NASA logo.  Instead, what they are likely to immediately perceive are the letters VSVN.</p>
   
<p>Indeed, the entire novelty of the design is predicated on the fact that VSVN stands on its own — unlike, say,
   an upside-down version of the agency's iconic "Meatball" logo:</p>
   
<p><img src="https://shaungallagher.pressbin.com/blog/img/nasa-logo.svg"></p>
   
<p>Are there other cases where flipping something is transformative?</p>

<p>Well, what if I were to begin selling T-shirts with this design?</p>
   
<p><img src="https://shaungallagher.pressbin.com/blog/img/shell-oil.png"></p>   

<p>That's arguably an infringement of Shell Oil's intellectual property.</p>

<p>But what about this?</p>

<p><img src="https://shaungallagher.pressbin.com/blog/img/shell-oil.png"></p>   

<p>That's the same image upside-down, but it "transforms" the previous design into the numbers 710 77345.  Do those numbers
   violate any copyright or trademark held by Royal Dutch Shell?  I think it would be quite a stretch to say they do.</p>
   
<p>Several artists have also produced transformative works by re-orienting physical objects.
   For instance, Marcel Duchamp, who specialized in conceptual art, created a work called
   <a href="https://en.wikipedia.org/wiki/Fountain_(Duchamp)">Fountain</a> by taking an ordinary porcelain urinal
   and turning it 90 degrees:</p>
   
<p><img src="https://shaungallagher.pressbin.com/blog/img/fountain.jpg"></p>   
   
<p>Given the fact that VSVN stands on its own and is arguably covered under fair use,
   I decided to reach out to NASA about the Teespring design.</p>

<p>I had hoped that they would agree with me that the design is transformative enough that no permission was needed from the agency.</p>

<p>But a representative from NASA's communications department, which handles such requests, responded to my inquiry and said
   the design <i>did</i> require NASA's authorization, but the design as presented would not be approved,
   because the agency does not permit the logo to be presented upside-down.</p>
   
<blockquote>
    It is patently obvious that your intent is to render the NASA Logotype upside down, else the clever premise is non-sensical.
    Our Merchandising Guidelines clearly state that the NASA Logotype cannot be altered, and you have rendered it upside down.
    Accordingly, it does not conform to the Guidelines so cannot be approved.  
    Alternatively, if you insist that VSVN is arbitrary, or an acronym for another entity/item,
    and that the premise is not related to the Agency, then we request you execute the premise using a different acronym and font
    since this use is obviously confusingly similar to NASA’s Logotype.
</blockquote>
  

<p>Unfortunately, although I think there is a case to be made for my design being considered non-infringing,
   I will not be pursing this any further.  I created the design just for giggles, and I have no interest
   in investing the time or money to successfully defend the design against a claim of copyright infringement
   from a federal agency.</p>

<p>I hope, though, that my experience has helped illuminate some of the intricacies of copyright law,
   and maybe even led you to think more deeply about what it means for a creative work to be transformative.</p>
   
<hr>

<p><i>
    Note: This essay presents both the NASA "Worm" logo and the NASA "Meatball" logo, in various orientations.
    This falls very firmly under fair use, because the essay is non-commercial in nature, involves commentary
    pertaining to the original works and how they relate to the VSVN work, and the logos are presented at
    relatively small size, just big enough to get the point across.  There are a variety of news articles
    (e.g. <a href="https://www.cnn.com/style/article/nasa-worm-logo-scn/index.html">1</a>,
          <a href="https://www.nytimes.com/2020/04/08/science/nasa-logo-worm-spacex.html">2</a>, and
          <a href="https://www.fastcompany.com/90536737/nasas-worm-logo-lay-dormant-for-28-years-so-why-are-people-so-obsessed-with-it">3</a>)
    that similarly reproduce the logos for the purpose of commentary about them, and my use is very similar.
</i></p>



 
</div>

                </div>
            </div>
        </div>
    </section></div>]]>
            </description>
            <link>https://shaungallagher.pressbin.com/blog/nasa-vsvn.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314551</guid>
            <pubDate>Sat, 05 Dec 2020 13:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Elixir]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25314446">thread link</a>) | @ingve
<br/>
December 5, 2020 | https://functional.christmas/2020/4 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today I want to give you an introduction to the programming language Elixir, some of its features and why you might want to check it out!</p>
</section><article><section><h2>The basics</h2>
<p>First things first: Elixir is a concurrent functional language that runs on the Erlang VM. It is inspired by many different languages where Ruby and Erlang are most obvious ones based on the syntax.</p>
<p>Elixir is a <a href="https://thinkingelixir.com/elixir-in-the-type-system-quadrant/">strong, dynamically typed language</a>. This puts it in the same category as Ruby and Python and it has optional functionality for compile time type checking as well.Elixirs data structures are immutable, but variables can be reassigned/rebound. <sup><sup id="fnref-2"><a href="#fn-2">2</a></sup></sup> This was a bit strange for me in that I got started with FP through Elm where there are no variables, just constants.</p>
<p>Elixir inherits a lot its data structures and related syntax from Erlang which in many ways is its biggest influence. <a href="https://elixir-lang.org/blog/2013/08/08/elixir-design-goals/">Elixir Design Goals</a> describes the relation to Erlang like this:</p>
<blockquote>
<p>Elixir is meant to be compatible with the Erlang VM and the existing ecosystem. When we talk about Erlang, we can break it into three parts:</p>
<ul>
<li>A functional programming language, called Erlang</li>
<li>A set of design principles, called OTP (Open Telecom Plaform)</li>
<li>The Erlang Virtual Machine, referred to as EVM or BEAM</li>
</ul>
<p>Elixir runs in the same virtual machine and is compatible with OTP. Not only that, all the tools and libraries available in the Erlang ecosystem are also available in Elixir, simply because there is no conversion cost from calling Erlang from Elixir and vice-versa.</p>
</blockquote>
<p>This is a great feature of Elixir that we will talk more about later.</p>
<p>As for other inspirations Elixir has docstrings from Python, polymorphism and protocols from Clojure, macros and meta-programming from different Lisps, just to name a few. <sup><sup id="fnref-1"><a href="#fn-1">1</a></sup></sup></p>
<h3>Hello World!</h3>
<p>As I said, Elixir is a concurrent functional programming language. For the functional part it means that Elixir mainly uses functions and modules for code structure and has other features that are associated with functional languages. We'll talk about the concurrent part later. </p>
<p>A hello world example in Elixir might look something like this:</p>
<div data-language="elixir"><pre><code><span>defmodule</span> HelloWorld
  <span>def</span> hello_world <span>do</span>
    IO<span>.</span>puts<span>(</span><span>"Hello, World!"</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>Here we define a module with a function that simply writes "Hello, World!" to the console.</p>
<h2>Killer applications</h2>
<p>Many programming languages has <a href="https://en.wikipedia.org/wiki/Killer_application">"killer apps"</a>; libraries, frameworks and use cases, that in themself are enough to justify the transition to the language or try it out. For Ruby it was the web framework Ruby on Rails and in many ways Elixir has its own Rails: Phoenix.</p>
<h3>Phoenix web framework</h3>
<p><a href="https://www.phoenixframework.org/">Phoenix</a> is inspired by Rails (the team originally behind Elixir was previously a Ruby shop) and was an early addition to the Elixir community. The creators of Phoenix has learned from years of Rails development and made their own opinions in addition to the natural changes needed when going from an object oriented language to a functional language.
Compared to Rails Phoenix has with the help of the Erlang VM great performance. Some of you might have heard about Phoenix' amazing <a href="https://www.phoenixframework.org/blog/the-road-to-2-million-websocket-connections">2 million simultaneous web sockets</a> benchmark!</p>
<h3>The Nerves Project</h3>
<p>Another interesting project in the Elixir ecosystem is the embedded/IoT project <a href="https://www.nerves-project.org/">Nerves</a>. Nerves makes it possible to use Elixir code to create embedded system where previously you would have had to use a low level language like C. This does not stop you from bringing your own code (like C, C++, Python, Rust, and more) while using Nerves as a platform for your IoT project.
The project web site says:</p>
<blockquote>
<p>Nerves is a complete IoT platform and infrastructure for you to build and deploy maintainable embedded systems.</p>
</blockquote>
<h2>The BEAM and OTP</h2>
<p>When talking about the advantages of Elixir it is hard to not talk about the advantages of Erlang and its virtual machine, the BEAM (Bogdan's Erlang Abstract Machine). It is in many ways the biggest selling point for Elixir. We are now talking about the concurrent part of Elixir. Erlang and the BEAM has shown its resiliency over many years, exemplified in giving Ericsson 9 nines (99.9999999%) availability in their AXD301 switch.<sup><sup id="fnref-3"><a href="#fn-3">3</a></sup></sup> It is known for its "let it break" philosophy and self-healing properties and by being compatible with Erlang, Elixir inherits a lot of these traits.</p>
<p>Elixirs creator, Jose Valim, attributes one of the motivational factors for the creation of Elixir to the rise of multi-core CPUs and the need to utilize these. Ruby and other languages with a global interperter lock (GIL) limits this, but the Erlang VM and the tools and design prinsiples of OTP have proven to be a great choice for creating concurrent, performant and resilient applications.</p>
<h3>Everything is a process</h3>
<p>Everything in the BEAM is a process. These are not OS processes, but lightweight processes which can be cheaply spawned and killed. In his PhD thesis the co-inventor of Erlang, Joe Armstrong, summarized Erlangs principles regarding processes:</p>
<blockquote>
<ul>
<li>Everything is a process.</li>
<li>Processes are strongly isolated.</li>
<li>Process creation and destruction is a lightweight operation.</li>
<li>Message passing is the only way for processes to interact.</li>
<li>Processes have unique names.</li>
<li>If you know the name of a process you can send it a message.</li>
<li>Processes share no resources.</li>
<li>Error handling is non-local.</li>
<li>Processes do what they are supposed to do or fail.</li>
</ul>
</blockquote>
<p>Sidenote: For some this may sound vaguely familiar. Some object oriented languages has had similar principles, but instead of processes they are applied to objects. Smalltalk is reported to be one of the inspirations to Erlang and it is fun to think about Erlang being a functional language but still be more object oriented than some object oriented languages. This is of course not the case as the definition of OOP has changed over time and Erlang is a functional language, but it is fun to ponder the similarities. 😄 Back to the main story! 😅</p>
<p>These unique principles for processes where they communicate through messages lays a great foundation for creating concurrent application, but there is one more piece to the puzzle: OTP.</p>
<h3>OTP - The Open Telecom Platform</h3>
<p>As with so many other parts of this article OTP is a big topic and could be a separate article, but I'll try make it short! Today the name is a bit strange but it was created by Ericsson for their telephone switches in the 80s and 90s so in that context in makes more sense.</p>
<p>OTP is an integral part of many Erlang applications. In essence OTP is a set of design principles and standards including tools and libraries to make it easier to create applications that adheres to them.<sup><sup id="fnref-4"><a href="#fn-4">4</a></sup></sup> </p>
<p>Since Elixir is compatible with OTP we can leverage these principles and technologies that has been battle tested in high-pressure and critical applications for decades!</p>
<h2>The take-away</h2>
<p>Luckily you don't need to understand or know much about Erlang, BEAM and OTP.
Without deep knowledge of these topics you can still reap the benefits of highly performing web applications and resilient IoT applications. It would certainly help but it is not a prerequisite. This is the great thing about Elixir: it is an approachable language with battle tested underpinnings! 💪</p>
<p>It might not be your idea of a perfect language. It is not mine either, but that does not stop me from using the great tools at my disposal. If you are all into Haskell or the likes it might not be something you would use and that is OK. Whatever your preferences are you might now know a little more about Elixir and Erlang and some more knowledge is always a good thing. 😄</p>
<p>If you would like to check Elixir out I recommend checking out <a href="https://elixir-lang.org/getting-started/introduction.html">the official Getting started guide</a> or the interactive guide <a href="https://try-elixir.herokuapp.com/">Try Elixir</a> and then trying out a project with Phoenix or Nerves. Hands-on experience is always better than something you read on the internet! 🤓</p>
<p>Psst! By the way: there are other languages that run on the BEAM. <a href="https://lfe.io/">Lisp variants</a> and lately some work on <a href="https://gleam.run/">strong statically compiled ML-like languges</a> if you are into that!</p>
</section></article></div>]]>
            </description>
            <link>https://functional.christmas/2020/4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314446</guid>
            <pubDate>Sat, 05 Dec 2020 13:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Wrote a Book on Data Analysis with Rust Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25314170">thread link</a>) | @DataCrayon
<br/>
December 5, 2020 | https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
    <div id="et-boc">
			
		<!-- #end wrapper --><div>
			<div>
		<div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				
				
				<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they’re implemented in practice.</p>
			</div>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				
				
				<div>
					<div data-columns="4">
	<figure>
		<p><a href="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg"><img width="480" height="679" src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" alt="" loading="lazy" title="cover_darn" data-caption="" data-src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image_width="480" data-large_image_height="679" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg 480w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-212x300.jpg 212w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-300x424.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></a></p>	</figure>
</div>

				</div>
			</div>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				<div>
					 <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_row_inner --><div>
				<div>
				
				
				<div>
				
				
				<ul>
					<li><a href="#">Description</a></li>
				</ul>
				<div>
					<div>
					<div>
						<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.</p>
<ul>
<li><strong>Discounted</strong>&nbsp;<strong>Price</strong> that will grow as the book does,</li>
<li>All code examples in <strong>Rust</strong>,</li>
<li><strong>Rust (Jupyter) Notebooks</strong> for each Section,</li>
<li>Supplementary <strong>Video Tutorials</strong>,</li>
<li>Format: <strong>PDF download</strong>,</li>
<li><strong>Unlimited</strong> downloads and access to updates.</li>
</ul>
<p>Get it now to enhance your work in Rust, NDArray, Data Science, Data Analysis, and Machine Learning.</p>

					</div><!-- .et_pb_tab_content" -->
				</div>
				</div> <!-- .et_pb_all_tabs -->
			</div> <!-- .et_pb_tabs -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row_inner -->
			</div> <!-- .et_pb_column -->
				</div> <!-- .et_pb_row -->
				
			</div> <!-- .et_pb_section --> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				 <!-- .et_pb_text --><p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/shahin_square.jpg" alt="" title="shahin_square" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square.jpg 288w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-150x150.jpg 150w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-100x100.jpg 100w" sizes="(max-width: 288px) 100vw, 288px"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<div><p>Dr. Shahin Rostami is a <a href="http://staffprofiles.bournemouth.ac.uk/display/srostami" target="_blank" rel="noopener noreferrer">Senior Academic (Associate Professor)</a> and <a href="https://www.linkedin.com/in/shahinrostami/" target="_blank" rel="noopener noreferrer">Consultant</a> in Data Science and Artificial Intelligence, with applications in the areas of Healthcare and Defence.</p>
<p>As a <a href="https://www.heacademy.ac.uk/system/files/downloads/UK%20Professional%20Standards%20Framework%20%28PSF%29_1.pdf">Senior Fellow</a> of the Higher Education Academy and <a href="https://shahinrostami.com/">Programme Leader</a> for many postgraduate programmes, he aims to contribute openly available learning resources through this website and his <a href="https://www.youtube.com/shahinrostami" target="_blank" rel="noopener noreferrer">YouTube channel</a>.</p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>Dr. Rostami writes and maintains the works published and offered through this website. You can expect ongoing updates and support through the communication channels listed below.</p>
			</div> <!-- .et_pb_text --> <!-- .et_pb_text --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/author-icon-03-2.png" alt="" title=""></span>
			</p><div>
				
				
				<div><p>The aim is to generate everything in this book through code! This means you’ll see the code for all the figures and tables, including things like flowcharts.</p>
<p>Every section is intended to be independent and <span jsslot=""><span data-dobid="hdw">reproducible</span></span>, so you’ll find some repetition as you progress from one section to another.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><h2>10% discount on books.</h2>
<p>Join the newsletter to receive book and software updates, as well as discounts and occasional freebies! Your email will only used for this newsletter.</p></div>
			</div> <!-- .et_pb_text --> <!-- .et_pb_code --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column --> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->		</div><!-- .et_builder_inner_content -->
	</div><!-- .et-l -->
	
			
		</div><!-- #et-boc -->
		    </div></div>]]>
            </description>
            <link>https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314170</guid>
            <pubDate>Sat, 05 Dec 2020 12:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Std::visit is everything wrong with modern C++ (2017)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 206 (<a href="https://news.ycombinator.com/item?id=25314126">thread link</a>) | @xucheng
<br/>
December 5, 2020 | https://bitbashing.io/std-visit.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/std-visit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!--
Sorry once again for the infrequent posts.
I've been busy.
Originally, because I was supposed to get married this summer.
Then because my fiancée cheated on me while I was watching my grandfather die
and moved in with the other guy the following week.
So that's been fun, but I'm trying to get back into some more productive habits.
Hopefully that includes blogging regularly.
-->

<h2 id="sum-types-and-you">Sum Types and You</h2>

<p>Let’s talk about a simple, yet powerful concept in programming: <em>sum types</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>A sum type, also called a <em>discriminated union</em>,
can hold one (and only one) of several types of things.
For example, consider some settings in an
<a href="https://en.wikipedia.org/wiki/INI_file">INI</a>-like configuration file.
Let’s say that each setting must be a string, an integer, or a Boolean value.
If we wanted to roll our own solution in C++, we might write something resembling:</p>

<div><pre><code><span>struct</span> <span>Setting</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>string</span> <span>str</span><span>;</span>
        <span>int</span> <span>num</span><span>;</span>
        <span>bool</span> <span>b</span><span>;</span>
    <span>};</span>
    <span>enum</span> <span>Type</span> <span>{</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Bool</span> <span>};</span>
    <span>Type</span> <span>tag</span><span>;</span>
<span>};</span>

<span>// Map settings to their names.
</span><span>using</span> <span>Settings</span> <span>=</span> <span>unordered_map</span><span>&lt;</span><span>string</span><span>,</span> <span>Setting</span><span>&gt;</span><span>;</span>
</code></pre>
</div>

<p>Here be dragons, though, since we must always remember to:</p>

<ul>
  <li>
    <p>Update <code>tag</code> whenever assigning a new value.</p>
  </li>
  <li>
    <p>Only retrieve the correct type from the union (according to <code>tag</code>).</p>
  </li>
  <li>
    <p>Call constructors and destructors at appropriate times for all non-trivial types.
(<code>string</code> is the only one here, but you could imagine similar
scenarios with others.)</p>
  </li>
</ul>

<p>If a step is ever forgotten, the object falls into an
inconsistent state and there shall be wailing and gnashing of teeth.
You could encapsulate all this trickery and interact with the type
through a series of methods—e.g., <code>getType()</code>, <code>asBool()</code>,
<code>asString()</code>, and so on—but this is quite verbose.
It also just shifts the problem onto whoever implements these methods; they
still need to carefully maintain the invariants with no help from the language.</p>

<p>It would be much nicer if a general-purpose sum type was provided by the standard
library.
In C++17, we finally get one!
It’s called <a href="http://en.cppreference.com/w/cpp/utility/variant"><code>std::variant</code></a>.
Let’s take a look.</p>

<h2 id="using-stdvariant">Using <code>std::variant</code></h2>

<p><code>variant</code> is a class template that takes, as template parameters, the types
it could hold.
For the example above,
we could define a setting as a <code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span></code>.
Assigning a value to a <code>variant</code> works just like you might expect:</p>
<div><pre><code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span> <span>mySetting</span> <span>=</span> <span>string</span><span>(</span><span>"Hello!"</span><span>);</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>42</span><span>;</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>false</span><span>;</span>
</code></pre>
</div>

<p>Once we put a value into a <code>variant</code>, we’ll eventually want to look at what that
value is, and just as importantly, what the type of the value is.
This is where the fun begins.
Some languages offer dedicated <em>pattern matching</em> syntax for the task,
such as:</p>
<div><pre><code><span>match</span> <span>(</span><span>theSetting</span><span>)</span> <span>{</span>
    <span>Setting</span><span>::</span><span>Str</span><span>(</span><span>s</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A string: {}"</span><span>,</span> <span>s</span><span>),</span>
    <span>Setting</span><span>::</span><span>Int</span><span>(</span><span>n</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"An integer: {}"</span><span>,</span> <span>n</span><span>),</span>
    <span>Setting</span><span>::</span><span>Bool</span><span>(</span><span>b</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A boolean: {}"</span><span>,</span> <span>b</span><span>),</span>
<span>};</span>
</code></pre>
</div>
<p>but this didn’t make the cut for C++17.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Instead we’re given a companion function called <code>std::visit</code>.
It takes the <code>variant</code> you want to examine, along with
some <em>visitor</em> that is callable for each type in the variant.</p>

<p>How do we define such a visitor?
One way is to create an object that overloads the call operator
for relevant types:</p>
<div><pre><code><span>struct</span> <span>SettingVisitor</span> <span>{</span>
    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>int</span> <span>n</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"An integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>n</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A boolean: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre>
</div>

<p>This seems terribly verbose, and it gets even worse
if we want our visitor to capture or modify some other state.
Hmm—<a href="https://stackoverflow.com/a/7627218">lambdas</a> are perfect
for capturing state.
What if we could build a visitor from those?</p>
<div><pre><code><span>make_visitor</span><span>(</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>d</span><span>);</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>)</span>
</code></pre>
</div>
<p>That’s a bit better, but the standard library doesn’t provide any sort of
<code>make_visitor</code> to combine the lambdas into a callable object for us.
We’ll need to define it ourselves.</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>;</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>,</span> <span>class</span><span>...</span> <span>Frest</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>,</span> <span>Frest</span><span>...</span><span>&gt;</span> <span>:</span> <span>F0</span><span>,</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>,</span> <span>Frest</span><span>...</span> <span>rest</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>),</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span><span>(</span><span>rest</span><span>...)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
    <span>using</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>&gt;</span> <span>:</span> <span>F0</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>auto</span> <span>make_visitor</span><span>(</span><span>Fs</span><span>...</span> <span>fs</span><span>)</span>
<span>{</span>
    <span>return</span> <span>overload</span><span>&lt;</span><span>Fs</span><span>...</span><span>&gt;</span><span>(</span><span>fs</span><span>...);</span>
<span>}</span>
</code></pre>
</div>

<p>Here we use C++11’s <a href="http://en.cppreference.com/w/cpp/language/parameter_pack">variadic templates</a>.
They must be defined recursively, so we create some base case <code>F0</code>,
then use that to define a cascading set of constructors for <code>overload</code>,
each of which peels off a lambda argument and adds it to the type
as a call operator.</p>

<p>If this seems troublesome, fear not! C++17 will offer a new syntax
that reduces all of the above to:</p>
<div><pre><code><span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>struct</span> <span>overloaded</span> <span>:</span> <span>Ts</span><span>...</span> <span>{</span> <span>using</span> <span>Ts</span><span>::</span><span>operator</span><span>()...;</span> <span>};</span>
<span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>overloaded</span><span>(</span><span>Ts</span><span>...)</span> <span>-&gt;</span> <span>overloaded</span><span>&lt;</span><span>Ts</span><span>...</span><span>&gt;</span><span>;</span>
</code></pre>
</div>
<p>Easy, right? But if don’t like any of these options, you could
use C++17’s compile-time conditionals instead:</p>
<div><pre><code><span>[](</span><span>auto</span><span>&amp;</span> <span>arg</span><span>)</span> <span>{</span>
    <span>using</span> <span>T</span> <span>=</span> <span>std</span><span>::</span><span>decay_t</span><span>&lt;</span><span>decltype</span><span>(</span><span>arg</span><span>)</span><span>&gt;</span><span>;</span>

    <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>string</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>int</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>bool</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>}</span>
</code></pre>
</div>

<p>Much better, no?</p>

<h2 id="no">No.</h2>

<p>The rigmarole needed for <code>std::visit</code> is entirely insane.
We started with a simple goal: look at the contents of a sum type.
To accomplish this meager mission, we had to:</p>

<ol>
  <li>
    <p>Define a function object, which requires a lot of
boilerplate, <em>or</em></p>
  </li>
  <li>Define our behavior with lambdas, which required:
    <ul>
      <li>An understanding of variadic templates, in all their recursively-defined fun, <em>or</em></li>
      <li>A familiarity with variadic <code>using</code> declarations, fresh on the scene from C++17.</li>
    </ul>

    <p><em>or</em></p>
  </li>
  <li>Use compile-time conditionals, which require you to know
about—and grok—the new <code><span>constexpr</span> <span>if</span></code> syntax, along with
<code>type_traits</code> fun like
<code>std::decay</code>.</li>
</ol>

<p>None of these concepts are too enigmatic if you’re an experienced C++ developer,
but several are certainly “advanced” features of the language.
Things have really gone sideways if we need to know so much
to do something so simple.</p>

<h2 id="how-did-we-get-here">How did we get here?</h2>

<p>My goal isn’t to disparage the folks on the ISO C++ committee
who picked this approach.
I’ve had beers with some of them,
and they’re smart, kind, hardworking people.
I’m sure that I’m missing important context since I’ve never sat in on a
standards meeting or read all of the relevant
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">committee papers</a>.
But from an outsider’s perspective, the disparity in complexity between the
problem being solved (“What’s in here?”)
and the solutions is just nuts.
How do you teach this without overwhelming a beginner with all this other…
stuff?
Is it expected to be common knowledge for your everyday programmer?
(And if the goal of adding <code>variant</code> to the standard library <em>isn’t</em> to
make it a tool for the masses, shouldn’t it be?)
The very least C++17 could do—if the committee didn’t have the time or resources
to get pattern matching into the language—is provide something akin to <code>make_visitor</code>.
But that too is left as an exercise for the user.</p>

<p>If I had to guess how we ended up this way,
I’d assume it comes down to confirmation bias.
Maybe when a bunch of really smart people who know how
<a href="http://en.cppreference.com/w/cpp/language/sfinae">SFINAE</a> works offhand
and don’t flinch when they see the likes of</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>F</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if</span><span>&lt;!</span><span>std</span><span>::</span><span>is_reference</span><span>&lt;</span><span>F</span><span>&gt;::</span><span>value</span><span>,</span> <span>int</span><span>&gt;::</span><span>type</span>
<span>foo</span><span>(</span><span>F</span> <span>f</span><span>)</span>
<span>{</span>
    <span>// ...
</span><span>}</span>
</code></pre>
</div>

<p>get together, the result is something like <code>std::visit</code>.
Nobody proclaims that the emperor has no clothes, or that it’s completely
bonkers to expect the average user to build an overloaded callable
object with recursive templates just to see if the thing they’re looking at
holds an <code><span>int</span></code> or a <code><span>string</span></code>.</p>

<p>I’m also not here to claim that C++ is too complicated for its own good,
but it’s certainly more complicated than it has to be.
Scott Meyers, the guy who wrote <em>Effective&nbsp;C++</em> and <em>Effective Modern&nbsp;C++</em>,
has made similar noises in <a href="http://www.ustream.tv/recorded/47947981">recent</a>
<a href="https://youtu.be/RT46MpK39rQ?t=29m51s">talks</a>.
To paraphrase Meyers, I’m sure each member of the committee cares very much
about avoiding needless complexity and making the language easier to use.
But if you look at the results of their work, it’s hard to tell.
The accidental complexity just keeps stacking up.</p>

<h2 id="where-are-we-headed">Where are we headed?</h2>

<p>There’s a reason C++ is so widely used, especially in systems programming.<sup id="fnref:3"><a href="#fn:3">3</a></sup>
It can be incredibly expressive, yet gives you nearly full control of your hardware.
The tooling around it is some of the most mature of any programming language
out there, bar C.
It supports a ridiculous number of platforms.</p>

<p>But even if you set aside all the historical baggage, it has some serious shortcomings.
Spend any amount of time messing with D and you’ll quickly realize that
metaprogramming needn’t require self-flagellation and insane syntax.
Play with Rust and <!-- Hi, PCJ --> you’ll feel like <code>unique_ptr</code>
and <code>shared_ptr</code>—which themselves have been a breath of fresh air—are
a bad joke.
The fact that we still handle dependencies in 2017
by literally copy-pasting files into each other with <code><span>#include</span></code>
macros is <em>obscene</em>.</p>

<p>You get the impression, based on what ends up in the ISO standards and what
you hear in conference talks,
that those driving C++ are trying to eliminate some of these shortcomings by
glomming nice bits from other languages onto it.
That’s a great idea on its face,
but these features often seem to arrive half-baked.
While C++ isn’t going away any time soon,
it feels like the language is constantly playing a clumsy game of catchup.</p>

<hr>

<p>In spite of all of this,
I’ll be busy encouraging my coworkers to use <code>variant</code> if anybody needs me.
Sum types are such a useful concept that they’re worth the pain,
and <a href="https://www.youtube.com/watch?v=wvtFGa6XJDU">to quote Jon Kalb</a>,
“If you can’t program in a language with ugly warts, maybe C++ isn’t the language
you should be programming in.”</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/std-visit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314126</guid>
            <pubDate>Sat, 05 Dec 2020 12:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Down Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25314066">thread link</a>) | @lelf
<br/>
December 5, 2020 | https://greydanus.github.io/2020/12/01/scaling-down/ | <a href="https://web.archive.org/web/*/https://greydanus.github.io/2020/12/01/scaling-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
      <div>

  

  <article>
  

<div>
    <div>
    <video id="demoDisplay">
    	<source src="https://greydanus.github.io/assets/scaling-down/construction.mp4" type="video/mp4">
    </video>
    <p>Constructing the MNIST-1D dataset. As with the original MNIST dataset, the task is to learn to classify the digits 0-9. Unlike the MNIST dataset, which consists of 28x28 images, each of these examples is a one-dimensional sequence of points. To generate an example, we begin with 10 digit templates and then randomly pad, translate, add noise, and transform them as shown above.</p>
  	</div>
</div>





<p>By any scientific standard, the Human Genome Project <a href="https://deepblue.lib.umich.edu/handle/2027.42/62798">was enormous</a>: it involved billions of dollars of funding, dozens of institutions, and over a decade of accelerated research. But that was only the tip of the iceberg. Long before the project began, scientists were hard at work assembling the intricate science of human genetics. And most of the time, they were not studying humans. The foundational discoveries in genetics centered on far simpler organisms such as peas, molds, fruit flies, and mice. To this day, biologists use these simpler organisms as genetic “minimal working examples” in order to save time, energy, and money. A well-designed experiment with Drosophilia, such as <a href="https://pubmed.ncbi.nlm.nih.gov/10746727/">Feany and Bender (2000)</a>, can teach us an astonishing amount about humans.</p>

<p>The deep learning analogue of Drosophilia is the MNIST dataset. A large number of deep learning innovations including <a href="https://jmlr.org/papers/v15/srivastava14a.html">dropout</a>, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf">convolutional networks</a>, <a href="https://arxiv.org/abs/1406.2661">generative adversarial networks</a>, and <a href="https://arxiv.org/abs/1312.6114">variational autoencoders</a> began life as MNIST experiments. Once these innovations proved themselves on small-scale experiments, scientists found ways to scale them to larger and more impactful applications.</p>

<p>They key advantage of Drosophilia and MNIST is that they dramatically accelerate the iteration cycle of exploratory research. In the case of Drosophilia, the fly’s life cycle is just a few days long and its nutritional needs are negligible. This makes it much easier to work with than mammals, especially humans. In the case of MNIST, training a strong classifier takes a few dozen lines of code, less than a minute of walltime, and negligible amounts of electricity. This is a stark contrast to state-of-the-art vision, text, and game-playing models which can take months and <a href="https://arxiv.org/abs/2004.08900">hundreds of thousands of dollars</a> of electricity to train.</p>

<p>Yet in spite of its historical significance, MNIST has three notable shortcomings. First, it does a poor job of differentiating between linear, nonlinear, and translation-invariant models. For example, logistic, MLP, and CNN benchmarks obtain 94, 99+, and 99+% accuracy on it. This makes it hard to measure the contribution of a CNN’s spatial priors or to judge the relative effectiveness of different regularization schemes. Second, it is somewhat large for a toy dataset. Each input example is a 784-dimensional vector and thus it takes a non-trivial amount of computation to perform hyperparameter searches or debug a metalearning loop. Third, MNIST is hard to hack. The ideal toy dataset should be procedurally generated so that researchers can smoothly vary parameters such as background noise, translation, and resolution.</p>

<p>In order to address these shortcomings, we propose the MNIST-1D dataset. It is a minimalist, low-memory, and low-compute alternative to MNIST, designed for exploratory deep learning research where rapid iteration is a priority. Training examples are 20 times smaller but they are still better at measuring the difference between 1) linear and nonlinear classifiers and 2) models with and without spatial inductive biases (eg. translation invariance). The dataset is procedurally generated but still permits analogies to real-world digit classification.</p>

<div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_a.png"></p><p>Constructing the MNIST-1D dataset. Like MNIST, the classifier's objective is to determine which digit is present in the input. Unlike MNIST, each example is a one-dimensional sequence of points. To generate an example, we begin with a digit template and then randomly pad, translate, and transform it.</p>
  </div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_b.png"></p><p>Visualizing the performance of common models on the MNIST-1D dataset. This dataset separates them cleanly according to whether they use nonlinear features (logistic regression vs. MLP) or whether they have spatial inductive biases (MLP vs. CNN). Humans do best of all. Best viewed with zoom.</p>
  </div>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/tsne.png">
  </p>
  <p>Visualizing the MNIST and MNIST-1D datasets with tSNE. The well-defined clusters in the MNIST plot indicate that the majority of the examples are separable via a kNN classifier in pixel space. The MNIST-1D plot, meanwhile, reveals a lack of well-defined clusters which suggests that learning a nonlinear representation of the data is much more important to achieve successful classification. Thanks to <a href="https://twitter.com/hippopedoid">Dmitry Kobak</a> for making this plot.</p>
</div>

<h2 id="example-use-cases">Example Use Cases</h2>

<p>In this section we will explore several examples of how MNIST-1D can be used to study core “science of deep learning” phenomena.</p>

<p><strong>Finding lottery tickets.</strong> It is not unusual for deep learning models to have ten or even a hundred times more parameters than necessary. This overparameterization helps training but increases computational overhead. One solution is to progressively prune weights from a model during training so that the final network is just a fraction of its original size. Although this approach works, conventional wisdom holds that sparse networks do not train well from scratch. Recent work by <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a> challenges this conventional wisdom. The authors report finding sparse subnetworks inside of larger networks that train to equivalent or even higher accuracies. These “lottery ticket” subnetworks can be found through a simple iterative procedure: train a network, prune the smallest weights, and then rewind the remaining weights to their original initializations and retrain.</p>

<p>Since the original paper was published, a multitude of works have sought to explain this phenomenon and then harness it on larger datasets and models. However, very few works have attempted to isolate a “minimal working example” of this effect so as to investigate it more carefully. The figure below shows that the MNIST-1D dataset not only makes this possible, but also enables us to elucidate, via carefully-controlled experiments, some of the reasons for a lottery ticket’s success. Unlike many follow-up experiments on the lottery ticket, this one took just two days of researcher time to produce. The curious reader can also <a href="https://bit.ly/3nCEIaL">reproduce these results</a> in their browser in a few minutes.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a2.png">
  </p>
  <p>Finding and analyzing lottery tickets. In <b>a-b)</b>, we isolate a "minimum viable example" of the effect. Recent work by <a href="https://arxiv.org/abs/1906.02773">Morcos et al (2019)</a> shows that lottery tickets can transfer between datasets. We wanted to determine whether spatial inductive biases played a role. So we performed a series of experiments: in <b>c)</b> we plot the asymptotic performance of a 92% sparse ticket. In <b>d)</b> we reverse all the 1D signals in the dataset, effectively preserving spatial structure but changing the location of individual datapoints. This is analogous to flipping an image upside down. Under this ablation, the lottery ticket continues to win.</p>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b2.png">
  </p>
    <p>Next, in <b>e)</b> we permute the indices of the 1D signal, effectively removing spatial structure from the dataset. This ablation hurts lottery ticket performance significantly more, suggesting that part of the lottery ticket's performance can be attributed to a spatial inductive bias. Finally, in <b>f)</b> we keep the lottery ticket sparsity structure but initialize its weights with a different random seed. Contrary to results reported in <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a>, we see that our lottery ticket continues to outperform a dense baseline, aligning well with our hypothesis that the lottery ticket mask has a spatial inductive bias. In <b>g)</b>, we verify our hypothesis by measuring how often unmasked weights are adjacent to one another in the first layer of our model. The lottery ticket has many more adjacent weights than chance would predict, implying a local connectivity structure which helps gives rise to spatial biases.</p>
</div>

<p>You can also visualize the actual masks selected via random and lottery pruning:
<br></p>





<p><strong>Observing deep double descent.</strong> Another intriguing property of neural networks is the “double descent” phenomenon. This phrase refers to a training regime where more data, model parameters, or gradient steps can actually <em>reduce</em> a model’s test accuracy<sup id="fnref:fn1" role="doc-noteref"><a href="#fn:fn1">1</a></sup> <sup id="fnref:fn2" role="doc-noteref"><a href="#fn:fn2">2</a></sup> <sup id="fnref:fn3" role="doc-noteref"><a href="#fn:fn3">3</a></sup> <sup id="fnref:fn4" role="doc-noteref"><a href="#fn:fn4">4</a></sup>. The intuition is that during supervised learning there is an interpolation threshold where the learning procedure, consisting of a model and an optimization algorithm, is just barely able to fit the entire training set. At this threshold there is effectively just one model that can fit the data and this model is very sensitive to label noise and model mis-specification.</p>

<p>Several properties of this effect, such as what factors affect its width and location, are not well understood in the context of deep models. We see the MNIST-1D dataset as a good tool for exploring these properties. In fact, we were able to reproduce the double descent pattern after a few hours of researcher effort. The figure below shows our results for a fully-connected network and a convolutional model. We also observed a nuance that we had not seen mentioned in previous works: when using a mean square error loss, the interpolation threshold lies at \(n * K\) model parameters where \(n\) is the number of training examples and \(K\) is the number of model outputs. But when using a negative log likelihood loss, the interpolation threshold lies at \(n\) model parameters – it does not depend on the number of model outputs. This is an interesting empirical observation that may explain some of the advantage in using a log likelihood loss over a MSE loss on this type of task. You can reproduce these results <a href="https://bit.ly/2UBWWNu">here</a>.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_a.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_b.png">
  </p>
  <p>Observing deep double descent. MNIST-1D is a good environment for determining how to locate the interpolation threshold of deep models. This threshold is fairly easy to predict in fully-connected models but less easy to …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greydanus.github.io/2020/12/01/scaling-down/">https://greydanus.github.io/2020/12/01/scaling-down/</a></em></p>]]>
            </description>
            <link>https://greydanus.github.io/2020/12/01/scaling-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314066</guid>
            <pubDate>Sat, 05 Dec 2020 12:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[V4 UUID generation Postgres benchmarks]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313857">thread link</a>) | @shusson
<br/>
December 5, 2020 | https://shusson.info/post/benchmark-v4-uuid-generation-in-postgres | <a href="https://web.archive.org/web/*/https://shusson.info/post/benchmark-v4-uuid-generation-in-postgres">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  

<p><strong>05/12/2020</strong></p>

<p>TLDR: use <code>gen_random_uuid</code> to generate v4 uuids.</p>

<p>There are two main functions to generate v4 uuids in postgres, <code>uuid_generate_v4</code> and <code>gen_random_uuid</code>. In postgres 13, <code>gen_random_uuid</code> is a built in function. Otherwise you will need to install the <code>pgcrypto</code> extension. <code>uuid_generate_v4</code> requires the <code>uuid-ossp</code> extension. Depending how postgres is configured, postgres may actually use different libraries for the <code>uuid-ossp</code> extension (ossp-uuid, libc, libuuid) see <a href="https://www.postgresql.org/docs/13/uuid-ossp.html">postgres doc</a> for more info.</p>

<h2 id="tests">Tests</h2>

<pre><code>CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";
</code></pre>

<pre><code>EXPLAIN ANALYZE SELECT uuid_generate_v4() FROM generate_series(1, 10000);
EXPLAIN ANALYZE SELECT gen_random_uuid() FROM generate_series(1, 10000);
</code></pre>

<h2 id="notes">Notes</h2>

<ul>
  <li>All benchmarks used postgres 12.x.</li>
  <li>On windows, postgres was installed using https://www.enterprisedb.com.</li>
  <li>On linux, postgres was installed using respective package managers.</li>
  <li>All tests were done on google cloud VMs.
    <ul>
      <li>e2-medium: (2 vCPUs, 4 GB, HDD)</li>
      <li>e2-standard-4: (4 vCPUs, 16 GB, HDD)</li>
    </ul>
  </li>
</ul>

<h2 id="results">Results</h2>

<table>
  <thead>
    <tr>
      <th>hardware</th>
      <th>platform</th>
      <th>uuid_generate_v4</th>
      <th>gen_random_uuid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>e2-medium</td>
      <td>ubuntu-16.04</td>
      <td>95ms</td>
      <td>10ms</td>
    </tr>
    <tr>
      <td>e2-standard-4</td>
      <td>centos-8</td>
      <td>80ms</td>
      <td>30ms</td>
    </tr>
    <tr>
      <td>e2-medium</td>
      <td>windows-server-2012</td>
      <td>1800ms</td>
      <td>5ms</td>
    </tr>
    <tr>
      <td>e2-medium</td>
      <td>windows-server-2016</td>
      <td>3600ms</td>
      <td>5ms</td>
    </tr>
    <tr>
      <td>e2-standard-4</td>
      <td>windows-server-2019</td>
      <td>4400ms</td>
      <td>5ms</td>
    </tr>
  </tbody>
</table>

<p>More investigation is required to determine why <code>uuid_generate_v4()</code> is so slow on windows server. It’s unclear what underlying lib the enterprisedb postgres is using for <code>uuid-ossp</code>. Regardless of why it’s slow on windows server, the best option for now is to use <code>gen_random_uuid</code> which is significantly faster on all platforms tested and comes built in on postgres 13.</p>

<p><strong>update</strong></p>

<p>To be sure the windows issue was not limited to the edb postgres 12.4 version, I did one quick benchmark on the latest edb postgres 13 and found similar execution times for uuid_generate_v4.</p>

      

  <span><time datetime="2020-12-05T00:00:00+01:00"></time></span>


  
  <!--<span class="meta"><time datetime="2020-12-05T00:00:00+01:00">December 5, 2020</time> &middot; </span>
  -->
</section></div>]]>
            </description>
            <link>https://shusson.info/post/benchmark-v4-uuid-generation-in-postgres</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313857</guid>
            <pubDate>Sat, 05 Dec 2020 11:50:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Smart TV is probably ignoring your PiHole]]>
            </title>
            <description>
<![CDATA[
Score 400 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25313776">thread link</a>) | @giuliomagnifico
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313776</guid>
            <pubDate>Sat, 05 Dec 2020 11:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vouching for Docker Images]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313669">thread link</a>) | @oedmarap
<br/>
December 5, 2020 | https://shopify.engineering/voucher-docker-images | <a href="https://web.archive.org/web/*/https://shopify.engineering/voucher-docker-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>If you were using computers in the ‘90s and the early 2000s, you probably had the experience of installing a piece of software you downloaded from the internet, only to discover that someone put some nasty into it, and now you’re dragging your computer to IT to beg them to save your data. To remedy this, software developers started “signing” their software in a way that proved both who they were and that nobody tampered with the software after they released it. Every major operating system now supports code or application signature verification, and it’s a backbone of every app store.But what about Kubernetes? How do we know that our Docker images aren’t secret bitcoin miners, stealing traffic away from customers to make somebody rich? That’s where Binary Authorization comes in. It’s a way to apply the code signing and verification that modern systems now rely on to the cloud. Coupled with Voucher, an open source project started by my team at Shopify, we’ve created a way to prevent malicious software from being installed without making developers miserable or forcing them to learn cryptography.</p>
<h2>Why Block Untrusted Applications?</h2>
<p>Your personal or work computer getting compromised is a huge deal! Your personal data being stolen or your computer becoming unusable due to popup ads or background processes doing tasks you don’t know about is incredibly upsetting.</p>
<p>But imagine if you used a compromised service. Imagine if your email host ran in Docker containers in a cluster with a malicious service that wanted to access contents of the email databases? This isn’t just your data, but the data of everyone around you.</p>
<p>This is something we care about deeply at Shopify, since trust is a core component of our relationship with our merchants and our merchants’ relationships with their customers. This is why Binary Authorization has been a priority for Shopify since our move to Kubernetes.</p>
<h2>What is Code Signing?</h2>
<p>Code signing starts by taking a hash of your application. Hashes are made with hashing algorithms that take the contents of something (such as the binary code that makes up an application) and make a short, reproducible value that represents that version. A part of the appeal of hashing algorithms is that it takes an almost insurmountable amount of work (provided you’re using newer algorithms) to find two pieces of data that produce the same hash value.</p>
<p>For example, if you have a file that has the text:</p>
<p><code>Hello World</code></p>
<p>The hash representation of that (using the “sha256” hashing algorithm) is:</p>
<p><code>d2a84f4b8b650937ec8f73cd8be2c74add5a911ba64df27458ed8229da804a26</code></p>
<p>Adding an exclamation mark to the end of our file:</p>
<p><code>Hello World!</code></p>
<p>Results in a completely different hash:</p>
<p><code>03ba204e50d126e4674c005e04d82e84c21366780af1f43bd54a37816b6ab340</code></p>
<p>Once you have a hash of an application, you can run the same hashing algorithm on it to ensure that it hasn’t changed. While this is an important part of the code signing, most signing applications will automatically create a hash of what you are signing, rather than requiring you to hash and then sign the hash separately. It makes the hash creation and verification transparent to the developers and their users.</p>
<p>Once the initial release is ready, the developer that’s signing the application creates a public and private key for signing it, and shares the public key with their future users. The developer then uses the private part of their signing key and the hash of the application to create a value that can be verified with the public part of the key.</p>
<p>For example, with Minisign, a tool for creating signatures quickly, first we create our signing key:</p>

<p>The public half of the key is now:</p>
<p><code>RWSs3jHbeTsmYhWlyqpDEufCe5QSGHsb1fFnglZItPwDfJ3wEZzSGyBJ</code></p>
<p>And the private half remains private, living in&nbsp;<code>/Users/caj/.minisign/minisign.key</code>.</p>
<p>Now, if our application was named “hello” we can create a signature with that private key:</p>

<p>And then your users could verify that “hello” hasn’t been tampered with by running:</p>

<p>Unless you’re a software developer or power user, you likely have never consciously verified a signature, but that’s what’s happening behind the scenes if you’re using a modern operating system.&nbsp;</p>
<h2>Where is Code Signing Used?</h2>
<p>Two of the biggest users of code signing are Apple and Google. They use code signing to ensure that you don’t accidentally install software updates that have been tampered with or malicious apps from the internet. Signatures are usually verified in the background, and you only get notified if something is wrong. In Android, you can turn this off by <a href="https://developer.android.com/distribute/marketing-tools/alternative-distribution.html" target="_blank" title="Alternative distribution options - Android Developer" rel="nofollow noopener noreferrer">allowing unknown apps in the phone's settings</a>, whereas iOS requires the device be jailbroken to allow unsigned applications to be installed.</p>
<p><img alt="A macOS dialog window showing that Firefox is damaged and can't be opened. It gives users the option of moving it to the Trash." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/FirefoxMessage.jpg?v=1606786217" src="https://cdn.shopify.com/s/files/1/0779/4361/files/FirefoxMessage.jpg?v=1606786217"></p>
<p><br><em>A macOS dialog window showing that Firefox is damaged and can't be opened. It gives users the option of moving it to the Trash.</em></p>
<p>In macOS, applications that are missing their developer signatures or don’t have valid signatures are blocked by the operating system and advise users to move them to the Trash.</p>
<p>Most Linux package managers, (such as Apt/DPKG in Debian and Ubuntu, Pacman in ArchLinux) use code signing to ensure that you’re installing packages from the distribution maintainer, and verify those packages at install time.</p>
<p><img alt="Docker Hub showing a docker image created by the author." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/DockerImage.jpg?v=1606786314" src="https://cdn.shopify.com/s/files/1/0779/4361/files/DockerImage.jpg?v=1606786314"><br><em>Docker Hub showing a docker image created by the author.</em></p>
<p>Unfortunately, Kubernetes doesn’t have this by default. There are features that allow you to leverage code signing, but chances are you haven’t used them.</p>
<p>And at the end of the day, do you really trust some rando on the internet to actually give you a container that does what it says it does? Do you want to trust that for your organization? Your customers?</p>
<h2>What is Binary Authorization?</h2>
<p>Binary Authorization is a series of components that work together:&nbsp;</p>
<ul>
<li>A metadata service: a service that stores signatures and other image metadata</li>
<li>A Binary Authorization Enforcer: a service that blocks images that it can’t find valid signatures for</li>
<li>A signing service: a system that signs new images and stores those signatures in the metadata service.</li>
</ul>
<p>Google provides the first two services for their Kubernetes servers, which Shopify uses, based on two open source projects:</p>
<ul>
<li>Grafeas, a metadata service</li>
<li>Kritis, a Binary Authorization Enforcer</li>
</ul>
<p>When using Kritis and Grafeas or the Binary Authorization feature in Google Kubernetes Engine (GKE), infrastructure developers will configure policies for their clusters, listing the keys (also referred to as attestors) that must have signed the container images before they can run.</p>
<p>When new resources are started in a Kubernetes cluster, the images they reference are sent to the Binary Authorization Enforcer. The Enforcer connects to the metadata service to verify the existence of valid signatures for the image in question and then compares those signatures to the policy for the cluster it runs in. If the image doesn’t have the required signatures, it’s blocked, and any containers that would use it won’t start.You can see how these two systems work together to provide the same security that one gets in one’s operating system! However, there’s one piece that wasn’t provided by Google until recently: the signing service.</p>
<h2>Voucher: The Missing Piece</h2>
<p>Voucher serves as the last piece for Binary Authorization, the signing service. Voucher allows Shopify to run security checks against our Docker images and sign them depending on how secure they are, without requiring that non-security teams manage their signing keys.</p>
<p><img alt="Using Voucher's client software to check an image with the 'is_shopify' check, which verifies if the image was from a Shopify owned repository." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/ImageApproved.jpg?v=1606786428" src="https://cdn.shopify.com/s/files/1/0779/4361/files/ImageApproved.jpg?v=1606786428"><br><em>Using Voucher's client software to check an image with the 'is_shopify' check, which verifies if the image was from a Shopify owned repository.</em></p>
<p>The way it works is simple:</p>
<ol>
<li>Voucher runs in Google Cloud Run or Kubernetes and is accessible as a REST endpoint</li>
<li>Every build pipeline automatically calls to Voucher with the path to the image it built</li>
<li>Voucher reviews the image, signs it, and pushes that signature to the metadata service</li>
</ol>
<p>On top of the basic code signing workflow discussed previously, Voucher also supports validating more complicated requirements, using separate security checks and associated signing keys to mix and match required signatures on a per cluster basis to create distinct policies based on a cluster’s requirement.</p>
<p>For example, do you want to block images that weren’t built internally? Voucher has a distinct check for verifying that an image is associated with a Git commit in a Github repo you own, and signing those images with a separate key.</p>
<p>Alternatively, do you need to be able to prove that every change was approved by multiple people? Voucher can support that, creating signatures based on the existence of approvals in Github (with support for other code hosting services coming soon). This would allow you to use Binary Authorization to block images that would violate that requirement.</p>
<p>Voucher also has support for verifying the identity of the container builder, blocking images with a high number of vulnerabilities, and so on. And Voucher was designed to be extensible, allowing for the creation of new checks as need be.By combining Voucher’s checks and Binary Authorization policies, infrastructure teams can create a layered approach to securing their organization’s Kubernetes clusters. Compliance clusters can be configured to require approvals and block images with vulnerabilities, while clusters for experiments and staging can use less strict policies to allow developers to move faster, all with minimum work from non-security focused developers.</p>
<h2>Voucher Joins Grafeas</h2>
<p>As mentioned earlier, Voucher serves a need that hasn’t been provided by Google <i>until recently</i>. This is because <a href="https://cloud.google.com/blog/products/devops-sre/introducing-voucher-service-help-secure-container-supply-chain" target="_blank" title="Introducing Voucher, a service to help secure the container supply chain" rel="nofollow noopener noreferrer">Voucher has moved into the Grafeas organization</a> and now is a service provided by Google to Google Kubernetes Engine users going forwards.&nbsp;</p>
<p>Since our move to Kubernetes, Shopify’s security team has been working with Google’s Binary Authorization team to plan out how we’ll roll out Binary Authorization and design Voucher. We also released Voucher as an open source project in December 2018. This move to the Grafeas …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/voucher-docker-images">https://shopify.engineering/voucher-docker-images</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/voucher-docker-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313669</guid>
            <pubDate>Sat, 05 Dec 2020 11:20:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being honest about code coverage]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313630">thread link</a>) | @brainlessdev
<br/>
December 5, 2020 | https://fnune.com/2020/12/04/being-honest-about-code-coverage/ | <a href="https://web.archive.org/web/*/https://fnune.com/2020/12/04/being-honest-about-code-coverage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  <header>
    
    <time datetime="2020-12-04T18:21:50+00:00">Friday, December 4, 2020</time>
    <span>|</span>
    <a href="https://fnune.com/atom.xml">RSS</a>
    <span>|</span>
    <a href="https://github.com/fnune/fnune.github.io/blob/master/_posts/2020-12-04-being-honest-about-code-coverage.md">Edit on GitHub</a>
    <span>|</span>
    <a href="https://fnune.com/">Read more of my posts</a>
  </header>
  <p>In my experience, discussing code coverage has always been done with an expectation of a binary conclusion; it’s either a good metric to shoot for or it isn’t. It seems to me like there’s more to be gained if the question is framed differently: how does one achieve high code coverage <em>beneficially</em>?</p>

<p>Asking it this way leads to more fruitful argumentation because the following points are no longer part of the question:</p>

<ul>
  <li>Code coverage is a bad metric because it encourages writing sweeping tests that don’t test anything.</li>
  <li>Code coverage sometimes forces developers to test library code.</li>
  <li>Code coverage ultimately makes a code base more difficult to maintain because of all the extra meaningless tests.</li>
</ul>

<p>To those arguments, my answer is: the problem is not code coverage, but code that’s hard to test, a dogmatic approach to unit testing leading to their misuse, or the very fact that one often tries to increase code coverage by writing more tests.</p>

<p>So, as an exercise, let’s agree on this for the next couple of paragraphs: code coverage is a good metric as long as you’re honest about how to increase it.</p>

<p>What does it mean to be honest about increasing coverage?</p>

<ul>
  <li>Don’t start by trying to test the uncovered lines. Start by questioning the implementation instead, and look for ways to reduce complexity.</li>
  <li>If you’re testing library code or glue code, perhaps the implementation deals with mixed-up concerns that you can distinguish and test differently.</li>
  <li>A code base full of meaningless tests is indicative of a deeper problem with the implementation. Try to find that problem instead of writing more meaningless tests.</li>
</ul>

<p>Code coverage can bear a lot of meaning or very little. If you decide to track it, you and your peers will face having to decide whether to be diligent about it or not, and I’d say that’s a good thing.</p>

  <hr>
</article>


    </div></div>]]>
            </description>
            <link>https://fnune.com/2020/12/04/being-honest-about-code-coverage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313630</guid>
            <pubDate>Sat, 05 Dec 2020 11:14:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Did Microsoft Crushed Slack?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25313597">thread link</a>) | @leoneldicamillo
<br/>
December 5, 2020 | https://www.platformer.news/p/how-microsoft-crushed-slack | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/how-microsoft-crushed-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.platformer.news/p/how-microsoft-crushed-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313597</guid>
            <pubDate>Sat, 05 Dec 2020 11:07:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Fun Calc)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25313516">thread link</a>) | @martyalain
<br/>
December 5, 2020 | http://lambdaway.free.fr/lambdawalks/?view=meta6 | <a href="https://web.archive.org/web/*/http://lambdaway.free.fr/lambdawalks/?view=meta6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambdaway.free.fr/lambdawalks/?view=meta6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313516</guid>
            <pubDate>Sat, 05 Dec 2020 10:53:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No One Ever Got Fired for Choosing React]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313506">thread link</a>) | @soonnow
<br/>
December 5, 2020 | https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a web app without a framework. There are a bunch of potential advantages (no bloat! bespoke to your project!) and being able to say you built something with minimal dependencies gets you Engineer Points.</p>
<p>That is, if you can pull it off.</p>
<p>I started a new side project recently. It’s a web-based graphics editor, so it needs to be a single page app. My time spent profiling <a href="https://songrender.com/">SongRender</a> for performance issues has made me a little wary of React for building interfaces that update at 60 frames per second, so I decided to avoid it. I’d go (mostly) vanilla and see how far that took me.</p>
<p>I installed <a href="https://lit-html.polymer-project.org/">lit-html</a> and got to work. “Components” were simply functions that returned lit-html template results. A big singleton at the top of the tree held onto all the application state, stored as a global variable within that module.</p>
<p>The first hurdle came when a component needed local state. I could have lifted it to the singleton, but that would have broken the component’s encapsulation. I noticed that lit-html directives can keep state, so I decided to use them to build a tiny component library — ignoring a warning from the lit-html developers that this wasn’t a supported use case.</p>
<p>My home-brewed library worked great… until I needed to run some code when a component appeared on the screen. I started digging through lit-html documentation and issues looking for a way to detect a directive’s lifecycle, but it became clear to me that going down that path would be painful.</p>
<p>At that point, I recalled <a href="https://tomdale.net/2015/11/javascript-frameworks-and-mobile-performance/">this quote by Tom Dale</a>:</p>
<blockquote>
<p>I have heard from many developers who have told me that they accepted the argument that vanilla JavaScript or microlibraries would let them write leaner, meaner, faster apps. After a year or two, however, what they found themselves with was a slower, bigger, less documented and unmaintained in-house framework with no community. As apps grow, you tend to need the abstractions that a framework offers. Either you or the community write the code.</p>
</blockquote>
<p>Fair enough. Let’s avoid that trap. What about a small framework? I’d heard a lot of good things about Svelte, and although I was slightly worried about the size of the Svelte community I figured it would be fine.</p>
<p>My migration attempt quickly ground to a halt when I wanted a parent component to apply some styles to a child component. In React, I’d pass a class name in from the parent as a <code>className</code> prop. In Svelte, that’s considered a workaround, and the actual feature is the subject of an <a href="https://github.com/sveltejs/rfcs/blob/master/text/0000-style-properties.md">RFC</a>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Maybe this is an example of <a href="https://prog21.dadgum.com/160.html">dangling by a trivial feature</a>. But it’s so basic a capability that I’m surprised Svelte is on version three without an officially blessed way to do it. I ran into this limitation when I created my <strong>second component</strong>. Way before I got to try out any of the cool reactivity that earns Svelte all that buzz.</p>
<p>So I changed my mind and went with React. After an hour or so, I’d finished moving everything over — and my anxiety had vanished. I stopped worrying about having most efficient component system, and picked up work on the thing I wanted to build in the first place.</p>
<p>No, React isn’t perfect. It’s optimized for apps that make network requests and then display lists of things (i.e. most apps) which isn’t really what I’m doing here<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The performance is fine now, although I expect I’ll have to optimize as my project gets more complex.</p>
<p>But React lets me stop thinking about the framework. React gets out of my way. React is <a href="https://mcfunley.com/choose-boring-technology">boring</a>. React is actively developed. React has a giant ecosystem and a giant community. React is battle-tested on some of the most visited websites in the world.</p>
<p>I’m sure there are technically better ways to build a highly interactive interface on the web, but life is too short for me to spend hours trying to figure them out. There are things I want to create, and the only way I can actually create them is to stop spending so much time on tooling.</p>
<p>For now, I’m choosing React.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The solution they seem to have landed on — letting the child expose CSS custom properties as props — is actually pretty cool, though I don’t like that Svelte will silently wrap your component with an extra <code>div</code>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Although Dan, if you read this, the <a href="https://twitter.com/dan_abramov/status/1133341485133438982">“animation pass” mode</a> you’ve mentioned offhandedly sounds very relevant! <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313506</guid>
            <pubDate>Sat, 05 Dec 2020 10:51:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[72% of smart TVs and 46% of game consoles hardcode DNS settings]]>
            </title>
            <description>
<![CDATA[
Score 459 | Comments 596 (<a href="https://news.ycombinator.com/item?id=25313480">thread link</a>) | @boramalper
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313480</guid>
            <pubDate>Sat, 05 Dec 2020 10:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make slides with text, markdown, YAML, JSON or JavaScript, your call]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25313347">thread link</a>) | @abusedmedia
<br/>
December 5, 2020 | https://play.presenta.cc/v2 | <a href="https://web.archive.org/web/*/https://play.presenta.cc/v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://play.presenta.cc/v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313347</guid>
            <pubDate>Sat, 05 Dec 2020 10:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Between two Lisps]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25313311">thread link</a>) | @galfarragem
<br/>
December 5, 2020 | https://ane.github.io/2020/10/05/between-two-lisps.html | <a href="https://web.archive.org/web/*/https://ane.github.io/2020/10/05/between-two-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Out of all Lisps the ones I’ve come to appreciate the most are <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a> and <a href="https://common-lisp.net/">Common
Lisp</a>. <!--break-->These two languages are fundamentally very different: Scheme
is a minimalist language built on the foundations of <a href="https://en.wikipedia.org/wiki/Lambda_calculus">lambda calculus</a>, while
Common Lisp is a multi-paradigm synthesis of many Lisps before it. Common Lisp
is a large standard with many implementations, Scheme is a collection of an
evolving but minimalistic standard with many implementations. The core of Scheme
is quite small compared to Common Lisp. The latest standard <a href="http://www.r6rs.org/final/r6rs-lib.pdf">R6RS</a> is about 65
pages, while the ANSI Common Lisp standard from 1994 is about 1100 pages. The
<a href="https://srfi.schemers.org/">Scheme Requests for Implementation</a> process aims to standardize additional
features (like <a href="https://srfi.schemers.org/srfi-64/srfi-64.html">test suites</a>) that implementations may implement.</p>

<p>Common Lisp has some wonderful features, <a href="http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html">conditions and restarts</a>, the <a href="https://lispcookbook.github.io/cl-cookbook/clos.html">Common
Lisp Object System (CLOS)</a>, <a href="http://www.paulgraham.com/onlisp.html">the macro system</a>, among many other things. The <a href="http://joaotavora.github.io/sly/">SLY
IDE for Emacs</a> is <em>amazing</em>, and the <a href="http://www.sbcl.org/">Steel Bank Common Lisp</a> compiler is really
great. It has <a href="https://www.quicklisp.org/index.html">Quicklisp</a> and <a href="https://common-lisp.net/project/asdf/">ASDF</a> for package and build management,
respectively. I find the developer experience of Common Lisp to be superior to
almost anything imaginable, and this is not an empty statement: having used all
sorts of IDEs and editors for over 25 years, I have seen <em>many</em>.</p>

<h3 id="tastes-differ">Tastes differ</h3>

<p>That said, Common Lisp is <em>weird</em>. What I find particularly jarring is that
functions and variables live in different namespaces: if you put a function into
a variable, you can’t just use it like a function, you have to <code>funcall</code> it.
Having programmed in lots of languages of the ML family this is just, well, odd;
but this is due to historical reasons and there are <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">sound technical reasons for
it</a>.  There are other
oddities, some strange things like <code>(cdr '())</code> is not an error (in Scheme it
is), <code>()</code> and <code>nil</code> are equal (in Scheme <code>#f</code> and <code>()</code> are separate things), and
so on.</p>

<p>This isn’t really a fault in Common Lisp: other languages have impacted my taste
and preferences to bias me in the direction of Scheme, but that is not to say I
cannot work with Common Lisp’s idiosyncracies. Actually, I don’t mind them, I
just <em>notice</em> them.</p>

<p>I like the naming styles of Scheme more, as well. It has <code>string?</code> vs <code>string-p</code>
for predicate functions, <code>set!</code>  for state modifying functions, <code>foo-&gt;bar</code> for
conversions, these make code quite easier to read. Scheme has hygienic macros,
Guile has the traditional <code>defmacro</code> as well.</p>

<p>Many nice Scheme features are available in Common Lisp libraries. Pattern match
is available in the <a href="https://github.com/guicho271828/trivia">trivia</a> library. Named lets are easy to implement with a macro.</p>

<p>Common Lisp aficionados are quick to point out things Scheme <em>doesn’t</em> have:
keyword arguments, docstrings, rest arguments, but my Scheme implementation of
choice Guile has these built into the language.</p>

<h3 id="productivity-matters">Productivity matters</h3>

<p>Guile is in a strange niche is that its primary <em>raison d’être</em> is to be an
extension language for the GNU project. Like Emacs Lisp is for extending Emacs,
Guile is the <em>de facto</em> language for GNU programs for extension and scripting.</p>

<p>Guile doesn’t have Quicklisp and its package manager and build system is
basically nonexistent for the first and <a href="https://www.gnu.org/software/autoconf/">Autoconf</a> for the second. There is
<a href="https://lists.gnu.org/archive/html/guile-user/2017-03/msg00168.html">sentiment</a> in the Guile community to have <a href="https://guix.gnu.org/">Guix</a> as the package manager for
Guile. This might sound a bit onerous, since Guix is also a complete package
management for many other things than Guile, but consider this: as Andy Wingo
points out in his message that Guile libraries often come with C extensions,
Guile packages need some sort of managed build system for building the C
extensions. Since it doesn’t have one, to solve the problem of building a
package manager you’d also have to build a build system that can manage C code
and packages needed by the C code bits. To do this elegantly is a gargantuan
task, for instance, <a href="https://wiki.call-cc.org/man/5/Extensions#installing-eggs-that-use-libraries">chicken-install just asks you to put compiler/linker flags
on the command line before calling it</a>, so it obviously is a hard problem.</p>

<p>Now, Guix solves all that, and more, in a manner that is quite elegant and
interesting. But it’s not as lightweight as something like Quicklisp or
<a href="https://wiki.call-cc.org/man/5/Extensions"><code>chicken-install</code></a> from <a href="http://call-cc.org/">CHICKEN Scheme</a>. What is more, Guix works only on GNU/Linux
systems really, so macOS and Windows users won’t be able to do use your library
if you plan on distributing it via Guix. Duh, it’s the GNU project, but
portability is always nice.</p>

<p>But in Common Lisp I can write <code>(ql:quickload :alexandria)</code> and voilà, it will
automatically install the <a href="http://quickdocs.org/alexandria/">Alexandria</a> library that I can use. Then again, in
Common Lisp it’s somewhat rarer to have C extensions, so I don’t know how ASDF
handles that.</p>

<p>It is unfair to compare <a href="http://joaotavora.github.io/sly/">SLY</a> to <a href="https://www.nongnu.org/geiser/">Geiser</a>, the best Emacs Scheme integration
package.  SLY is based on <a href="https://common-lisp.net/project/slime/">SLIME</a> which has <em>decades</em> of man-years of work behind
it. Geiser is able to support multiple Scheme implementations and it is quite
impressive in this regard. But SLY obviously has much more (e.g. an interactive
debugger). That said, Geiser has nice Guile support, and Guile is in general the
most Common Lisp-y of all Schemes, in fact, it has</p>

<ul>
  <li>an imitation of CLOS in the form of <a href="https://www.gnu.org/software/goops/">GOOPS</a></li>
  <li>docstrings and keyword, rest, and optional arguments for function
definitions</li>
  <li>an interactive REPL and a mutable top-level (unlike many Schemes)</li>
  <li>a nice module system</li>
  <li><a href="https://www.gnu.org/software/guile/manual/html_node/Defmacros.html"><code>defmacro</code></a> and exceptions somewhat <a href="https://www.gnu.org/software/guile/manual/html_node/Raising-and-Handling-Exceptions.html">similar to Common Lisp restarts </a></li>
</ul>

<p>and some nice things Common Lisp doesn’t have like first-class
continuations. But then again I would use those rarely.</p>

<h3 id="when-would-i-pick-one-over-the-other">When would I pick one over the other?</h3>

<p>If I were to write an extensible C/C++/Rust program that I <em>know</em> will need to use
a low-level language, I might do the low level bits using a low level language
and then write the rest in Guile. Guile makes it very easy to spin up a REPL
socket to do something like <code>myprogram --repl=12345</code> that you can connect to, and
the interop between C and Guile is fantastic, it has to be, as it’s primarily an
extension language.</p>

<p>On the other hand, if were to build a wholly standalone application, the choice is
not as obvious. I could do the whole thing in either language. Common Lisp can
build native executables, although their size will be large (who cares?) since
the binary will include the whole Lisp implementation. Guile cannot compile to
native code so you’ll have to write a script executable, but that doesn’t really
matter.</p>

<p>Scenarios where I would pick Guile:</p>

<ul>
  <li>when I’m making an extensible program that has to have some C/C++ bits but I
want to make it scriptable by users</li>
  <li>when I want to write a native binary but not write too much C/C++ code</li>
  <li>I just want to write Scheme, because Scheme is a bit more elegant</li>
  <li>the project has something to do with the <a href="https://www.gnu.org/software/autoconf/">GNU project</a></li>
</ul>

<p>On the other hand, Common Lisp makes the most sense if I just want to enjoy a
seriously rapid development experience, a large standard library and language,
and I don’t mind having 50MB binaries (again, who cares?) if I were to write
standalone programs. Guile can’t do that, but it’s easy to either write Guile
scripts or a C program that essentially bootstraps a binary to load a Scheme
runtime. This is how <a href="http://lilypond.org/">LilyPond</a> is written, for example.</p>

<p>So the answer to which one is decidedly <strong>both</strong>! Both languages are really fun to
write. At the moment I don’t do Lisp at my day job so it’s all for fun
anyway. If this were for professional purposes, I don’t know. Very often a
strict requirement for professional work is to be able to be productive. In that
regard I think Common Lisp has a significant edge, not only due to its superior
development experience, but its history as a real production language. There are
actual companies doing stuff in Common Lisp. I have not heard of any
professional (in the industrial sense) uses of Guile, notwithstanding that many
projects powered by Guile (Guix, etc.)  are <em>extremely</em> professional in the way
they are written and maintained. But Common Lisp has <em>more</em> libraries and
companies behind it.</p>

<h3 id="what-about-clojure">What about Clojure?</h3>

<p>I’ve actually had the pleasure to use Clojure for personal fun, and a little bit
of professional use. I wrote a couple of libraries (<a href="https://github.com/ane/vigil">vigil</a> and <a href="https://github.com/ane/task">task</a>) and my
experience with has always been positive and its development experience is
excellent. Clojure isn’t a true Lisp, or well, it is part of the <em>Lisp
family</em>. Its ability to interface with the JVM makes it easy to leverage the
thousands of JVM libraries out there.</p>

<p>I’d gladly do it again, though I feel that Common Lisp with CLOS and its module
system makes it somewhat easier to practice <a href="https://en.wikipedia.org/wiki/Programming_in_the_large_and_programming_in_the_small"><em>programming in the large</em></a>. Clojure
explores interesting territories with <a href="https://clojure.org/guides/spec">spec</a>, so it is interesting to see what
direction the language will take in the future.</p>

<h3 id="final-words-emacs-lisp">Final words: Emacs Lisp</h3>

<p>There’s also a parenthetical elephant in the room here: Emacs Lisp! An old
descendant of <a href="https://en.wikipedia.org/wiki/Maclisp">MacLisp</a>, it’s actually quite fun to write, and the fact that Emacs
itself is the interpreter, you have superb introspectability for any Elisp
code. Most of the Lisp I write these days is probably Emacs Lisp. It’s very
close to Common Lisp. <a href="https://www.gnu.org/software/emacs/manual/html_mono/cl.html#Overview">cl-lib</a> adds a sufficient amount of convenience from
Common Lisp to make Elisp writing quite enjoyable. <a href="https://www.gnu.org/software/emacs/manual/html_mono/eieio.html#Top">EIEIO</a> adds a subset of CLOS
that can be used seamlessly with cl-lib. The condition system is missing.</p>

<p>I’ve also done a fair bit of <a href="https://fennel-lang.org/">Fennel</a>, a Lisp that compiles to Lua. I used it to
write a <a href="https://github.com/ane/mudrally">small game</a> and it was fun to write since you could develop the game in a
REPL.</p>

<p>All in all, Lisp in all its variants is the most fun I’ve ever had while
programming a computer. Guile and Common Lisp are definitely the most fun I’ve
had programming in <em>Lisp</em>.</p>

  </div></div>]]>
            </description>
            <link>https://ane.github.io/2020/10/05/between-two-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313311</guid>
            <pubDate>Sat, 05 Dec 2020 10:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Input Events in Qt 6]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313204">thread link</a>) | @todsacerdoti
<br/>
December 5, 2020 | https://www.qt.io/blog/input-events-in-qt-6 | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/input-events-in-qt-6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Friday December 04, 2020 by <a href="">Shawn Rutledge</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>The delivery of mouse and touch events in Qt Quick is complex, and it became clear a few years ago that we needed to refactor the event inheritance hierarchy, to have some common API for various event types, so that more of the delivery code could be shared. In Qt 5.8 we added QQuickPointerEvent and associated types, as a way of prototyping what that could look like. They are QObjects; and since then, QQuickWindow has been delivering these wrapper events that carry the original events inside. Now finally in Qt 6 we have been able to complete the QEvent refactoring, so that QQuickWindow no longer needs the wrappers. Along with that, we were able to add a few features and fix a few bugs. Many of the remaining bugs that seemed intractable in Qt 5 should at least be possible to fix later on.</p>
<!--more--><h2>Say hello to QPointerEvent and QEventPoint</h2>
<p>The inheritance hierarchy now looks like this:</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/event-hierarchy-qt6.png?width=1280&amp;name=event-hierarchy-qt6.png" alt="event-hierarchy-qt6" width="1280" srcset="https://www.qt.io/hs-fs/hubfs/event-hierarchy-qt6.png?width=640&amp;name=event-hierarchy-qt6.png 640w, https://www.qt.io/hs-fs/hubfs/event-hierarchy-qt6.png?width=1280&amp;name=event-hierarchy-qt6.png 1280w, https://www.qt.io/hs-fs/hubfs/event-hierarchy-qt6.png?width=1920&amp;name=event-hierarchy-qt6.png 1920w, https://www.qt.io/hs-fs/hubfs/event-hierarchy-qt6.png?width=2560&amp;name=event-hierarchy-qt6.png 2560w, https://www.qt.io/hs-fs/hubfs/event-hierarchy-qt6.png?width=3200&amp;name=event-hierarchy-qt6.png 3200w, https://www.qt.io/hs-fs/hubfs/event-hierarchy-qt6.png?width=3840&amp;name=event-hierarchy-qt6.png 3840w" sizes="(max-width: 1280px) 100vw, 1280px"><br>QPointerEvent is the new abstract type for all events that come from pointing devices (mouse, touchscreen, tablet stylus). It has the common API to be able to handle all these in a device-agnostic way. Since QTouchEvent can carry multiple touchpoints in one event, we standardized this concept: every QPointerEvent represents potentially a cluster of QEventPoint instances (even though most events only carry one point), and therefore has appropriate API: points(), point(i) and pointCount(). <br>Every QInputEvent (including QPointerEvent) carries a pointer to the QInputDevice that it came from. This allows event-handling code to respond in device-specific ways, even when handling synthetic mouse events. </p>
<p>Every QEventPoint has velocity. The Kalman filter that Qt Quick was using in Qt 5 has been moved to QtGui, so that the average velocity from the last few movements is available wherever the event is delivered. This enables velocity-sensitive behavior (such as distinguishing a slow drag from a quick flick, or responding to a particular direction of movement) regardless which device it comes from. Instantaneous velocity is generally too volatile for such purposes, but if you need it you can calculate it as <code>(globalPosition() - globalLastPosition()) / (timestamp() - lastTimestamp())</code>. </p>
<p>QSinglePointEvent is another abstract type that standardizes the position accessors that used to be separately and inconsistently implemented in QMouseEvent, QTabletEvent, QHoverEvent, QWheelEvent and a few more. They are all floating-point now. position() replaces pos() and posF(), scenePosition() replaces windowPos(), and globalPosition() replaces screenPos(). The old accessors are still there for now, but deprecated: a Qt 5 application will not encounter an SC break just because of handling QMouseEvent, for example. QEventPoint replaces QTouchEvent::TouchPoint, but there is a "using" declaration for the sake of source compatibililty. </p>
<p>I have <a href="https://github.com/ec1oud/clazy" rel="noopener" target="_blank">forked clazy</a> and added a new qevent-accessors check, which might save you some trouble: it can automatically apply "fixits" to get rid of the deprecation warnings stemming from the event accessor renaming. (Yes we should upstream that change.)</p>
<h2>Device-agnostic event handling in C++</h2>
<p>In various places in Qt we can now respond to mouse, touch and tablet events (such as detecting a click or a drag), either by iterating the QEventPoints, or just responding to the first point. Here's a contrived example of how a QQuickItem subclass could do that: </p>
<pre>bool MyItem::event(QEvent *ev) override {<br>  if (ev-&gt;isPointerEvent()) {<br>    QPointerEvent *pev = static_cast&lt;QPointerEvent *&gt;(ev);<br>    for (QEventPoint &amp;point : pev-&gt;points()) {<br>      switch (point.state()) {<br>      case QEventPoint::State::Pressed:<br>        if (reactToPress(point.position()))<br>          pev-&gt;setExclusiveGrabber(point, this);<br>        break;<br>      case QEventPoint::State::Updated:<br>        ...<br>      }<br>    }<br>    return true;<br>  }<br>  return QQuickItem::event(ev);<br>}</pre>
<p>QQuickFlickable::childMouseEventFilter() works this way, for example. And that has an interesting result: </p>
<h2>Flickable handles touch now! </h2>
<p>There were many open bugs related to the fact that Qt 5's Flickable could only handle actual mouse events and synthetic mouse events. Qt only supports one mouse, one mouse position, one cursor (so far, but we're working on that...) and therefore you could not flick two Flickables with two fingers. If you touch some component inside the Flickable that is able to handle touch events, but then you drag your finger across the Flickable in the allowed direction, it uses childMouseEventFilter() to steal the grab from that component; but that involved switching from the actual touch event to a synthetic mouse event, and also remembering to deliver the following updates as synth-mouse events to Flickable. Various things went wrong. Well... those days are over, because Flickable::childMouseEventFilter() no longer cares which device the QPointerEvents come from. If you set pressDelay, it's able to withhold the actual touch press and then replay it to the items inside when the timer expires. Yes, you can now drag multiple Flickables with multiple fingers too.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/parallel-flickables.gif?width=1280&amp;name=parallel-flickables.gif" alt="parallel-flickables" width="1280" srcset="https://www.qt.io/hs-fs/hubfs/parallel-flickables.gif?width=640&amp;name=parallel-flickables.gif 640w, https://www.qt.io/hs-fs/hubfs/parallel-flickables.gif?width=1280&amp;name=parallel-flickables.gif 1280w, https://www.qt.io/hs-fs/hubfs/parallel-flickables.gif?width=1920&amp;name=parallel-flickables.gif 1920w, https://www.qt.io/hs-fs/hubfs/parallel-flickables.gif?width=2560&amp;name=parallel-flickables.gif 2560w, https://www.qt.io/hs-fs/hubfs/parallel-flickables.gif?width=3200&amp;name=parallel-flickables.gif 3200w, https://www.qt.io/hs-fs/hubfs/parallel-flickables.gif?width=3840&amp;name=parallel-flickables.gif 3840w" sizes="(max-width: 1280px) 100vw, 1280px"><br>Multi-touch still doesn't work with the remaining mouse-only items like MouseArea though, because those still rely on synth-mouse events. But it can be avoided. In general: try to use Event Handlers rather than MouseArea, because (as its name indicates) it's not really intended to support anything more than mouse interaction. </p>
<p>QTabletEvents (from your Wacom stylus, Samsung S-pen, Apple Pencil etc.) are also just pointer events that carry a few more properties, and can be handled by any device-agnostic code that handles mouse and touch events. But we will keep working on improving the experience with those. We didn't add any new virtual functions in QQuickItem for them, but they will get delivered to QQuickItem::event() soon. </p>
<p>Another thing we're still working on is making Flickable behave better with laptop touchpads. A fix is coming soon. </p>
<h2>Left to your own devices</h2>
<p>Platform plugins now have responsibility to discover and register input devices, in order to fulfill the promise that every QInputEvent tells you exactly where it came from. Some of this work is already done on some of the platforms. (On others it's proving to be problematic.) You can get a list of all registered devices from QInputDevice::devices(). The qtdiag utility also shows you this list. </p>
<p>QInputDevice is a QObject, and its parent() can be another device in case there is a natural hierarchy: for example, X11 has master and slave devices, and a tablet stylus "belongs to" a particular tablet device. In other cases, the parent is simply an object within the platform plugin that owns the device for memory management purposes. </p>
<p>On the platforms where the device discovery work is not done, QInputEvent::device() is never null, but may be a generic instance taken from QInputDevice::primaryKeyboard() or QPointingDevice::primaryMouse(). Touchscreen devices are unique though; we already did it that way in Qt 5. </p>
<p>QInputDevice::seatName() correponds to the Wayland notion of a "seat": a set of devices that one user is using. There is little multi-seat support so far, but it will be improved over time. If you configure a <a href="https://wiki.archlinux.org/index.php/Multi-pointer_X" rel="noopener" target="_blank">multi-pointer X server</a>, you can see different seat names on different devices, but those names are automatically generated from xinput IDs in the xcb plugin. On Wayland compositors such as <a href="https://manpages.debian.org/experimental/sway/sway-input.5.en.html#SEAT_CONFIGURATION" rel="noopener" target="_blank">Sway</a>, it's possible to give the seats arbitrary names; and we plan that Qt will eventually work with that. </p>
<pre>$ xinput list<br>Virtual core pointer id=2 [master pointer (3)]<br>  Virtual core XTEST pointer id=4 [slave pointer (2)]<br>  ZSA Technology Labs ErgoDox EZ Mouse id=11 [slave pointer (2)]<br>  ZSA Technology Labs ErgoDox EZ Consumer Control id=13 [slave pointer (2)]<br>  Logitech MX Master 2S id=15 [slave pointer (2)]<br>Virtual core keyboard id=3 [master keyboard (2)]<br>  Virtual core XTEST keyboard id=5 [slave keyboard (3)]<br>  Power Button id=6 [slave keyboard (3)]<br>  Power Button id=7 [slave keyboard (3)]<br>  Sleep Button id=8 [slave keyboard (3)]<br>  UVC Camera (046d:0992) id=9 [slave keyboard (3)]<br>  ZSA Technology Labs ErgoDox EZ id=10 [slave keyboard (3)]<br>  ZSA Technology Labs ErgoDox EZ System Control id=12 [slave keyboard (3)]<br>  ZSA Technology Labs ErgoDox EZ Keyboard id=14 [slave keyboard (3)]<br>  ZSA Technology Labs ErgoDox EZ Consumer Control id=16 [slave keyboard (3)]<br>  Logitech MX Master 2S id=17 [slave keyboard (3)]<br>aux pointer id=22 [master pointer (23)]<br>  Microsoft Microsoft Optical Mouse by Starck id=19 [slave pointer (22)]<br>  aux XTEST pointer id=24 [slave pointer (22)]<br>aux keyboard id=23 [master keyboard (22)]<br>  Apple, Inc Apple Keyboard id=20 [slave keyboard (23)]<br>  Apple, Inc Apple Keyboard id=21 [slave keyboard (23)]<br>  aux XTEST keyboard id=25 [slave keyboard (23)]<p>$ qtdiag<br>Qt 6.0.0 (x86_64-little_endian-lp64 shared (dynamic) debug build; by GCC 10.2.0) on "xcb" <br>OS: Arch Linux [linux version 5.9.11-arch2-1]<br>...<br>Input devices: 23<br>QInputDevice::DeviceType::Mouse "Virtual core pointer", seat: "30002" capabilities: Position Scroll Hover<br>QInputDevice::DeviceType::Keyboard "Virtual core keyboard", seat: "30002" capabilities:<br>QInputDevice::DeviceType::Mouse "aux pointer", seat: "170016" capabilities: Position Scroll Hover<br>QInputDevice::DeviceType::Keyboard "aux keyboard", seat: "170016" capabilities:<br>QInputDevice::DeviceType::Mouse "Virtual core XTEST pointer", seat: "30002" capabilities: Position Scroll Hover<br>QInputDevice::DeviceType::Keyboard "Virtual core XTEST keyboard", seat: "30002" capabilities:<br>QInputDevice::DeviceType::Keyboard "Power Button", seat: "30002" capabilities:<br>QInputDevice::DeviceType::Keyboard "Power Button", seat: "30002" capabilities:<br>QInputDevice::DeviceType::Keyboard "Sleep Button", seat: "30002" capabilities:<br>QInputDevice::DeviceType::Keyboard "UVC Camera (046d:0992)", seat: "30002" …</p></pre></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.qt.io/blog/input-events-in-qt-6">https://www.qt.io/blog/input-events-in-qt-6</a></em></p>]]>
            </description>
            <link>https://www.qt.io/blog/input-events-in-qt-6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313204</guid>
            <pubDate>Sat, 05 Dec 2020 09:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of Template Haskell and cross compilation]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313146">thread link</a>) | @fanf2
<br/>
December 5, 2020 | https://www.tweag.io/blog/2020-11-25-asterius-th/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-11-25-asterius-th/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Template Haskell (TH) is a widely used yet controversial language extension. You have
probably used it in your own code; with a single line of splice code, you can
achieve tasks like deriving instances and embedding files easily. And you might
also have heard the reasons why people may dislike it: it slows down
compilation, breaks encapsulation, arbitrary IO at compile time is risky, etc.</p>
<p>But it is less well known that Template Haskell also makes cross compilation
with GHC harder. In this post, we’ll show why this is a challenge, some existing
solutions developed by the community, and in particular, how this problem is
addressed by <a href="https://github.com/tweag/Asterius">Asterius</a>.</p>
<h2>Just run some code at compile time, what can go wrong?</h2>
<p>Conceptually, Template Haskell is a principled way of generating Haskell AST at
compile time, like in the simplified example below:</p>
<div data-language="haskell"><pre><code>

<span><span>import</span> Data.Char</span>
<span><span>import</span> Language.Haskell.TH.Syntax</span>
<span><span>import</span> System.Process</span>

<span>gitRev</span> <span>::</span> <span>String</span>
<span>gitRev</span> <span>=</span>
  <span>$</span><span>(</span> <span>do</span>
       <span>rev</span> <span>&lt;-</span>
         <span>runIO</span> <span>$</span>
           <span>filter</span> <span>isHexDigit</span> <span>&lt;$&gt;</span> <span>readProcess</span> <span>"git"</span> <span>[</span><span>"rev-parse"</span><span>,</span> <span>"HEAD"</span><span>]</span> <span>""</span>
       <span>liftString</span> <span>rev</span>
   <span>)</span></code></pre></div>
<p>Suppose we’d like to define a <code>gitRev</code> string that represents the current <code>git</code>
revision in the project repository. This can be done using an expression splice:
it is written using the <code>$(...)</code> syntax, and the content within <code>$()</code> is an
expression of type <code>Q Exp</code>, representing a compile-time computation that returns
an <code>Exp</code> value, which is, in this case, the current <code>git</code> revision as a string
literal.</p>
<p>Splice code lives in the <code>Q</code> monad, which manages the context for Template
Haskell and provides a rich set of interfaces. Inside <code>Q</code> we can query info
about datatypes or functions, allocate fresh identifiers, etc. Arbitrary <code>IO</code>
actions may also be run inside <code>Q</code>. Here, we run <code>git rev-parse HEAD</code> to obtain
the <code>git</code> revision and then return it. When GHC compiles this module, the splice
is replaced with a string literal, and compilation moves on.</p>
<p>So at first glance, Template Haskell is just about running user code at compile
time, what can go wrong? All is right for most developers, who compile to the
same platform they run GHC on, but there’s trouble ahead when you try to do
cross compilation…</p>
<h2>The what and why of cross compilation</h2>
<p>Suppose we’d like to write a Haskell app for an Android phone or a Raspberry
Pi. It’s possible to bootstrap a native GHC release on them and use it to
compile stuff, but given the limited hardware resources of these machines, it’s
wiser to run GHC on a proper x64 build server and emit code for these ARM
devices. When we do so, we’re performing <em>cross compilation</em>. Some terminology:</p>
<ul>
<li>The <em>host</em> platform is where we run GHC to compile stuff.</li>
<li>The <em>build</em> platform is where we compile GHC. For simplicity, we assume
build=host and only use the host term from now on.</li>
<li>The <em>target</em> platform is where we run the compiled Haskell app. When
host=target, the GHC is a <em>native</em> GHC, otherwise it’s a <em>cross</em> GHC.</li>
</ul>
<p>For a native GHC, Template Haskell isn’t a problem, since GHC can link and run its
emitted code just like native dynamic libraries. But this doesn’t work
out-of-the-box for a cross GHC.</p>
<p>Over the years, people have come up with different approaches to address the
cross compilation issue of Template Haskell, each coming with its own rough
edges; more details follow in later sections.</p>
<h2>Only run TH on the host platform</h2>
<p>If we can’t run emitted code, then how about we don’t run it at all and stay
with a cross GHC without TH support? We’ll preprocess the cross GHC input code,
strip usages of the Template Haskell extension, and replace all TH splices with
the expanded code. And the way to expand the splices would be… using a native
GHC to compile it!</p>
<p>There’s a GHC flag <code>-ddump-splices</code> which dumps the expanded splices code.
Unfortunately, the dump output has extra text decorations and isn’t proper Haskell
source code, so it takes more work to use the dumps. Here’s a list of known
implementations of the splice dump approach:</p>
<ul>
<li><a href="http://source.git-annex.branchable.com/?p=source.git;a=blob;f=Build/EvilSplicer.hs;h=e07034c5b05f47c316a1e68e6a85d54335c8e253;hb=aaa841e60a55524c3efb5e9783b8e6074d2413cc"><code>EvilSplicer</code></a> uses a <code>parsec</code>-based parser to process the dumps
for later consumption of cross GHC. It was used in the
<a href="https://git-annex.branchable.com/"><code>git-annex</code></a> project until late 2018.</li>
<li><a href="https://hackage.haskell.org/package/zeroth"><code>ZeroTH</code></a> is a tool which does something similar, and includes a CLI
and <code>Cabal</code>-related helper functions.</li>
<li><a href="https://github.com/reflex-frp/reflex-platform"><code>reflex-platform</code></a> uses a patched native GHC which dumps the
expanded splices as proper Haskell source code, and feeds into <a href="https://github.com/ghcjs/ghcjs">GHCJS</a>.</li>
</ul>
<p>However, making native/cross GHC work together is not trivial:</p>
<ul>
<li>Unlike <code>gcc</code> or <code>clang</code> which can emit code for other platforms by simply
adding relevant CLI flags, a GHC installation can only emit code for a single
target platform configured at its build time. So two different GHC
installations must be managed in isolated places.</li>
<li>Native/cross GHC must have the same version and process the same build plan to
minimize the chance of emitting wrong code. Say package <code>foo</code> includes a TH
splice that uses package <code>bar</code>, if native/cross GHC sees different versions
(or even same version but different build plan) of <code>bar</code>, the splice behavior
could potentially differ, expanding into wrong code that may be silently
consumed by cross GHC.</li>
</ul>
<p>Given the complexity of the required hacks and GHC/Cabal’s lack of cross
compilation support, it’s common to use an external build system (e.g.
<a href="https://nixos.org/">Nix</a>) to encapsulate this mechanism.</p>
<p>Other than saving dumps of expanded splices, there is another solution to only
run TH splice code on the host platform: the same GHC always compile everything
to both host/target code in one invocation! When running TH, we can just load
host code just like native GHC. This requires quite some customization of GHC
behavior and is only possible for 3rd-party compilers based on GHC API. In
fact, GHCJS used this approach in its earliest days.</p>
<h3>Pros and cons of running TH on the host platform</h3>
<p>Running TH on the host platform works for pure splices, which can only do
things like reifying info and generating ASTs. It should also work pretty well
for side-effecting splices which reads files, spawns processes or fires
missiles, since the splice behavior should be just the same as when we use a
native GHC to compile stuff.</p>
<p>But is this the end of story? Not yet. Here’s one immediate problem: the
native/cross GHC may not consume the same Haskell sources despite our best
efforts.</p>
<ul>
<li>Haskell modules may use the <code>CPP</code> extension with target-specific macros, so
when you compile for different targets, you see different top-level
definitions.</li>
<li>Cabal files may also check implementation/platform/etc, and end up with
different flags or even different modules to be consumed by GHC.</li>
</ul>
<p>The problems above will likely trigger compile-time errors. And there’s an even
stealthier problem that may lead to generating incorrect code instead of a
crash: the architecture difference of host/target, e.g. word size or endianness.
For instance, a TH splice may make use of <code>sizeOf (undefined :: Int)</code>, which is
4 on 32-bit target platforms, and if the host platform is 64-bit, then the TH
splice will see 8, which sneaks into the emitted code without a single warning.</p>
<h2>Run TH code on the target platform</h2>
<p>As explained in earlier sections, vanilla GHC can only link and run host code.
Would it be possible to teach GHC to link and run target code? The answer is
yes. The key to supporting running non-native code is RPC (Remote Procedure
Calls). GHC needs to call into target code to obtain the splice expansion
result; the target code needs to call GHC to do reification. These calls are
achieved via exchanging serialized messages between GHC and the loaded splices.
Since there is a fixed set of operations allowed in the <code>Q</code> monad (as methods of
the <code>Quasi</code> class), the operations and the results can be encoded as a
serializable <code>Message</code> datatype.</p>
<p>This RPC approach to run TH code is standardized in the <a href="https://gitlab.haskell.org/ghc/ghc/-/wikis/commentary/compiler/external-interpreter">external
interpreter</a> feature. When running TH, GHC starts an
external process calls <code>iserv</code>, pipes messages to <code>iserv</code> and tells it to load
archives, objects, etc and link code. After a splice starts running in <code>iserv</code>,
<code>iserv</code> may send queries back to GHC and get results. Finally, the splice
expansion result is sent back to GHC.</p>
<p>The external interpreter opens up the possibility of using various emulators
(e.g. <code>wine</code> for windows, <code>node</code> for js/wasm or even <code>qemu</code> for exotic
platforms) to run target code for TH. GHC itself doesn’t need to care about how
the code is actually linked and run in <code>iserv</code>, and TH should work as long as
our target-specific <code>iserv</code> can properly process the messages.</p>
<p>This approach was pioneered by GHCJS, and later made it into upstream GHC by
7.10. Other than GHCJS, known users include:</p>
<ul>
<li>GHC itself, even in native GHC! But why bother? Well, suppose we’re compiling
a profiled library with TH usage. Since profiled code follows different
runtime conventions and links with profiled runtime, in the early days, a
profiled GHC executable was needed. Now, we can simply use a profiled <code>iserv</code>
executable, and avoid the extra profiling overhead in GHC.</li>
<li><a href="https://github.com/input-output-hk/haskell.nix">haskell.nix</a>, which includes support for cross-compiling to
Windows via <code>wine</code> emulation of TH code.</li>
<li><a href="https://medium.com/@zw3rk">Mobile Haskell</a>, which are ARM-targetting GHC distributions.
They use Android/iOS emulators to set up the splice runtime environment. GHC
talks to an <code>iserv-proxy</code> process via pipes, and <code>iserv-proxy</code> merely relays
the messages to the real <code>iserv</code> program in the emulator via a socket.</li>
<li>The <a href="https://github.com/typelead/eta">Eta</a> Haskell-to-JVM compiler.</li>
<li><a href="https://github.com/tweag/Asterius">Asterius</a>, which uses <code>node</code> for running the WebAssembly &amp;
JavaScript code.</li>
</ul>
<h3>Pros and cons of running TH on the target platform</h3>
<p>Compared to running TH on the host platform, there are a few benefits to
running it on the target platform:</p>
<ul>
<li>No host/target incoherence issues, as explained in earlier sections.</li>
<li>Less hacky and more standardized. Although upstream GHC won’t likely contain
<code>iserv</code> implementations for all interesting target platforms out there,
developers can just roll their own if needed.</li>
<li>Simpler, since there isn’t a bunch of hacks to be packaged via nix anymore,
and it works with vanilla <code>cabal</code>/<code>stack</code>.</li>
</ul>
<p>It would be tempting to announce TH for cross compilation is now a solved
problem! Turns out it’s not. Recall how TH enables running …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2020-11-25-asterius-th/">https://www.tweag.io/blog/2020-11-25-asterius-th/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-11-25-asterius-th/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313146</guid>
            <pubDate>Sat, 05 Dec 2020 09:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up CI/CD with GitHub Actions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313102">thread link</a>) | @nickyvanurk
<br/>
December 5, 2020 | https://codingwizardry.com/2020/12/02/how-to-set-up-ci-cd-with-github-actions-for-rails/ | <a href="https://web.archive.org/web/*/https://codingwizardry.com/2020/12/02/how-to-set-up-ci-cd-with-github-actions-for-rails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="penci-post-entry-inner">
			
<p>In this guide I am going to show you how to setup <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/CI/CD" target="_blank">CI/CD</a> with GitHub Actions for Rails. I assume you are running Linux and have Rails 6 installed together with PostgreSQL and Git. If you need help, I wrote a guide on <a rel="noreferrer noopener" href="https://codingwizardry.com/2020/11/10/how-to-install-ruby-on-rails-on-ubuntu-20-04/" target="_blank">how to install Rails with PostgreSQL on Ubuntu 20.04</a>. In this tutorial we will create a basic Rails application. We will upload the application to GitHub, integrate GitHub Actions, and setup a CI/CD workflow that deploys to Heroku. Let’s begin!</p>



<h2>Setting Up PostgreSQL</h2>



<p>Create a PostgreSQL user for the Rails app we’ll create in the next step. To do this, switch into the <code>postgres</code> user and fire up <code>psql</code>:</p>



<pre><code>$ sudo -u postgres -i
$ psql</code></pre>



<p>Then create a new user (or “role”, as PostgreSQL calls it):</p>



<pre><code>$ create role social_network with createdb login password 'password1';</code></pre>



<p>To go back you type <code>\q </code>to exit psql and <code>exit</code> to return to your main terminal.</p>



<h2>Creating a New Rails App</h2>



<p>Navigate to a directory on your computer where you want to store the project (I like to use <code>~/dev</code>) and execute the following commands:</p>



<pre><code>$ rails new social_network -d postgresql
$ cd social_network</code></pre>



<p>Open up the <code>config/database.yml</code> file in a text editor and under <code>default</code> find the line that says <code>pool: &lt;%= ENV.fetch("RAILS_MAX_THREADS") { 5 } %&gt;</code> and add the following lines: </p>



<pre><code>host: localhost
username: social_network
password: &lt;%= ENV['SOCIAL_NETWORK_DATABASE_PASSWORD'] %&gt;</code></pre>



<p>We are going to need an environment variable to store the database password. The password should match the password used in the previous step. Execute the following commands:</p>



<pre><code>$ echo 'export SOCIAL_NETWORK_DATABASE_PASSWORD="password1"' &gt;&gt; ~/.bashrc
$ source ~/.bashrc</code></pre>



<p>Finally, we’ll create our database and launch our application.</p>



<pre><code>$ rails db:create
$ rails server</code></pre>



<p>You can now visit <a rel="noreferrer noopener" href="http://localhost:3000/" target="_blank">http://localhost:3000</a> and if everything has gone right you will be greeted by the following website:</p>



<figure><img loading="lazy" width="1024" height="679" src="https://codingwizardry.com/wp-content/uploads/2020/11/image-1-1024x679.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/image-1-1024x679.png 1024w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-300x199.png 300w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-768x509.png 768w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-1170x776.png 1170w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-780x516.png 780w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-585x388.png 585w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-263x175.png 263w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Add Project to GitHub</h2>



<p>Next up, let’s create a new repository on GitHub. You can create a new repository <a rel="noreferrer noopener" href="https://github.com/new" target="_blank">here</a> once you’re logged into GitHub.</p>



<figure><img loading="lazy" width="724" height="716" src="https://codingwizardry.com/wp-content/uploads/2020/11/image-2-e1605980210642.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/image-2-e1605980210642.png 724w, https://codingwizardry.com/wp-content/uploads/2020/11/image-2-e1605980210642-300x297.png 300w, https://codingwizardry.com/wp-content/uploads/2020/11/image-2-e1605980210642-585x579.png 585w" sizes="(max-width: 724px) 100vw, 724px"></figure>



<p>Then we want to link the GitHub repository to our local project. In the <code>social_network</code> folder execute the following command:</p>



<pre><code>$ git remote add origin git@github.com:your_username/social-network.git</code></pre>



<p>Or if you prefer to use HTTPS instead of SSH, run the following command:</p>



<pre><code>$ git remote add origin https://github.com/your_username/social-network.git</code></pre>



<p>Verify that we’ve set the remote origin correctly:</p>



<pre><code>$ git remote -v
origin  git@github.com:your_username/social-network.git (fetch)
origin  git@github.com:your_username/social-network.git (push)</code></pre>



<p>Because we’ve let GitHub create a README.md and .gitignore file for us, let’s remove the the ones generated by Rails, and pull the new files (including a LICENCE file) from GitHub into our local project folder:</p>



<pre><code>$ rm .gitignore README.md
$ git pull origin main
From github.com:your_username/social-network
 * branch            main       -&gt; FETCH_HEAD</code></pre>



<p>Now to push all our local files onto GitHub, execute the following commands. Note here that we have to rename our master branch to main, <a href="https://www.zdnet.com/article/github-to-replace-master-with-alternative-term-to-avoid-slavery-references/" target="_blank" rel="noreferrer noopener nofollow">GitHub no longer uses the name master</a> in order to rid itself from references to slavery.</p>



<pre><code>$ git add -A
$ git commit -m "Initial commit"
$ git branch -m master main
$ git push --set-upstream origin main</code></pre>



<p>If everything went well, we’ve successfully uploaded our newly created Rails application to GitHub.</p>



<h2>Continuous Integration with GitHub Actions</h2>



<p>To set up GitHub Actions for our project we’ll need a workflow file. A workflow is an automated procedure that you can add to a repository. Workflows are made up of one or more jobs and can be scheduled or triggered by an event. The workflow can be used to build, test, package, release, or deploy a project on GitHub. You can read more about GitHub Actions <a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions" target="_blank" rel="noreferrer noopener">here</a>. In this tutorial we’re going to use a workflow to test the project and, if all tests pass, deploy the project to <a href="https://heroku.com/" target="_blank" rel="noreferrer noopener">Heroku</a>.</p>



<p>Let’s start by creating a functional workflow file. This file will be able to automatically run the, currently non-existent, tests. In your project folder create a new directory <code>.github/workflows/</code>. Within the newly created workflows directory create a new workflow file <code>social-network.yml</code>:</p>



<pre><code>name: Social Network
on: [push]
jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres
        ports: ['5432:5432']
        env:
          POSTGRES_USER: social_network
          POSTGRES_PASSWORD: postgres
        options: &gt;-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Check out repository code
        uses: actions/checkout@v2
      - name: Set up Node.js
        uses: actions/setup-node@v1
        with:
          node-version: '14.x'
      - name: Set up Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: 2.7
          bundler-cache: true
      - name: Install dependencies
        run: |
          bundle install --jobs 4 --retry 3
          yarn
      - name: Set up database
        run: bundle exec rails db:prepare
        env:
           SOCIAL_NETWORK_DATABASE_PASSWORD: postgres
      - name: Run tests
        run: bundle exec rails test
        env:
           RAILS_ENV: test
           SOCIAL_NETWORK_DATABASE_PASSWORD: postgres       </code></pre>



<p>To understand the workflow file I recommend you take a moment to read the “Understanding the workflow file” section in the GitHub Actions documentation <a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions#understanding-the-workflow-file" target="_blank" rel="noreferrer noopener">here</a>. Now, commit and push the file to GitHub:</p>



<pre><code>$ git add -A
$ git commit -m "Add automated tests workflow"
$ git push</code></pre>



<p>Head over to GitHub and select the <strong>Actions</strong> tab in the social-network repository and click on “Add automated tests workflow”, you will see the following output:</p>



<figure><img loading="lazy" width="1015" height="654" src="https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684.png 1015w, https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684-300x193.png 300w, https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684-768x495.png 768w, https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684-585x377.png 585w" sizes="(max-width: 1015px) 100vw, 1015px"></figure>



<p>We’ve successfully set up continuous integration! In the next section we will focus on automatic deployment to Heroku.</p>



<h2>Continuous Deployment with GitHub Actions</h2>



<p>Create a new Heroku account if you haven’t already got on <a href="https://signup.heroku.com/" target="_blank" rel="noreferrer noopener">here</a>. Then, create a new app within Heroku <a href="https://dashboard.heroku.com/new-app" target="_blank" rel="noreferrer noopener">here</a>. Choose an app name and select your region, I like to prefix the app name with my last name:</p>



<figure><img loading="lazy" width="655" height="327" src="https://codingwizardry.com/wp-content/uploads/2020/12/image-1.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/12/image-1.png 655w, https://codingwizardry.com/wp-content/uploads/2020/12/image-1-300x150.png 300w, https://codingwizardry.com/wp-content/uploads/2020/12/image-1-585x292.png 585w" sizes="(max-width: 655px) 100vw, 655px"></figure>



<p>In order to deploy to Heroku we will need to setup a GitHub Secret with the Heroku API key. The API key can be found <a href="https://dashboard.heroku.com/account" target="_blank" rel="noreferrer noopener">here</a>. Create a new GitHub secret:</p>



<ol><li>On GitHub, navigate to the main page of the repository.</li><li>Under the repository name, click <strong>Settings</strong>.</li><li>In the left sidebar, click <strong>Secrets</strong>.</li><li>Click <strong>New repository secret</strong>.</li><li>Type <code>HEROKU_API_KEY</code> in the <strong>Name</strong> input box.</li><li>Paste the Heroku API key in the <strong>Value</strong> input box.</li></ol>



<p>We can now use this secret in the workflow file. Update the workflow file to deploy to Heroku once all tests pass:</p>



<pre id="block-a8c659b2-f50c-4043-8a74-f7fc3eb6a65f"><code>name: Social Network
on: [push]
jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres
        ports: ['5432:5432']
        env:
          POSTGRES_USER: social_network
          POSTGRES_PASSWORD: postgres
        options: &gt;-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Check out repository code
        uses: actions/checkout@v2
      - name: Set up Node.js
        uses: actions/setup-node@v1
        with:
          node-version: '14.x'
      - name: Set up Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: 2.7
          bundler-cache: true
      - name: Install dependencies
        run: |
          bundle install --jobs 4 --retry 3
          yarn
      - name: Set up database
        run: bundle exec rails db:prepare
        env:
           SOCIAL_NETWORK_DATABASE_PASSWORD: postgres
      - name: Run tests
        run: bundle exec rails test
        env:
           RAILS_ENV: test
           SOCIAL_NETWORK_DATABASE_PASSWORD: postgres
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
     - uses: actions/checkout@v2
     - uses: akhileshns/heroku-deploy@v3.6.8
       with:
         heroku_api_key: ${{secrets.HEROKU_API_KEY}}
         heroku_app_name: 'Your Heroku app name'
         heroku_email: 'Your email'</code></pre>



<p>In order to execute commands on Heroku once the project is deployed, we need a <code>Procfile</code>. We will need to execute commands that set up the database and start the application. Go ahead and create the file in the project root directory with the following contents:</p>



<pre><code>release: bundle exec rails db:prepare
web: bundle exec puma -C config/puma.rb</code></pre>



<p>Commit the changes:</p>



<pre><code>$ git add -A
$ git commit -m "Add automated deployment to workflow"</code></pre>



<p>We are almost ready to push to GitHub. But first, add a root route so that the project knows what to display whenever a users surfs to the website. Add a function named <code>index</code> to <code>app/controllers/application_controller.rb</code>:</p>



<pre><code>class ApplicationController &lt; ActionController::Base
  def index
    render html: 'Hello, world!'
  end
end</code></pre>



<p>Then, add a root route to <code>config/routes.rb</code>:</p>



<pre><code>Rails.application.routes.draw do
  root 'application#index'
end</code></pre>



<p>Commit the changes once more and push to GitHub:</p>



<pre><code>$ git add -A
$ git commit -m "Add root route"
$ git push</code></pre>



<p>Head over to GitHub Actions and confirm that all tests pass:</p>



<figure><img loading="lazy" width="1015" height="408" src="https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105.png 1015w, https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105-300x121.png 300w, https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105-768x309.png 768w, https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105-585x235.png 585w" sizes="(max-width: 1015px) 100vw, 1015px"></figure>



<p>And that’s it! The project is now successfully deployed to Heroku.</p>



<figure><img loading="lazy" width="631" height="81" src="https://codingwizardry.com/wp-content/uploads/2020/12/image-5.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/12/image-5.png 631w, https://codingwizardry.com/wp-content/uploads/2020/12/image-5-300x39.png 300w, https://codingwizardry.com/wp-content/uploads/2020/12/image-5-585x75.png 585w" sizes="(max-width: 631px) 100vw, 631px"></figure>




			
			
			
												
									</div>
	</div></div>]]>
            </description>
            <link>https://codingwizardry.com/2020/12/02/how-to-set-up-ci-cd-with-github-actions-for-rails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313102</guid>
            <pubDate>Sat, 05 Dec 2020 09:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Apple Teaches Us About Web and Product Design]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313100">thread link</a>) | @Alvinthj
<br/>
December 5, 2020 | https://blog.snappymob.com/what-apple-teaches-us-about-web-and-product-design | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/what-apple-teaches-us-about-web-and-product-design">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Standing in line with other high-end brands, <em>“Less is better”</em> has always been the one principle that we can all observe in Apple’s branding and design. From their physical store layouts to their website and products including hardware and software, Apple has always emanated a sense of luxury in their aesthetic. And that’s what makes them stand out.</p>
<!--more--><p>What standards has Apple set for the world of design? Let’s take a close look at how they do it.</p>
<h2><strong>How Apple Does Web Design</strong></h2>
<p>Do you remember the first time you went on Apple’s website to check out their new iPhone? You were probably really quickly convinced by the clean typography, smooth animation flows, and high definition product images that immersed you by filling your screen… that you wanted one.&nbsp;</p>
<p>Apple’s web design doesn’t just function, it wows.<img src="https://blog.snappymob.com/hs-fs/hubfs/clean%20white%20space%20and%20font-min.png?width=1383&amp;name=clean%20white%20space%20and%20font-min.png" alt="Apple iPad product images and descriptions clean white space and font" width="1383" srcset="https://blog.snappymob.com/hs-fs/hubfs/clean%20white%20space%20and%20font-min.png?width=692&amp;name=clean%20white%20space%20and%20font-min.png 692w, https://blog.snappymob.com/hs-fs/hubfs/clean%20white%20space%20and%20font-min.png?width=1383&amp;name=clean%20white%20space%20and%20font-min.png 1383w, https://blog.snappymob.com/hs-fs/hubfs/clean%20white%20space%20and%20font-min.png?width=2075&amp;name=clean%20white%20space%20and%20font-min.png 2075w, https://blog.snappymob.com/hs-fs/hubfs/clean%20white%20space%20and%20font-min.png?width=2766&amp;name=clean%20white%20space%20and%20font-min.png 2766w, https://blog.snappymob.com/hs-fs/hubfs/clean%20white%20space%20and%20font-min.png?width=3458&amp;name=clean%20white%20space%20and%20font-min.png 3458w, https://blog.snappymob.com/hs-fs/hubfs/clean%20white%20space%20and%20font-min.png?width=4149&amp;name=clean%20white%20space%20and%20font-min.png 4149w" sizes="(max-width: 1383px) 100vw, 1383px">(Image Source: Apple)</p>
<p>If we look at how Apple’s website has transformed over the years, we can see that minimalistic web design is one of its most consistent catches.&nbsp;</p>
<p>Their website focuses on clutterless single content areas that highlight one piece of content at a time with plenty of white space and wide margins. Not only is this design aesthetically pleasing, it is easy on the eyes and makes content easy to take in.</p>
<p>To make reading even lighter, Apple also uses simple headlines that show you the main idea of the paragraph without requiring you to read the paragraph.&nbsp;</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/Apple%20homepage.png?width=1488&amp;name=Apple%20homepage.png" alt="Apple homepage iPhone 12 Pro product image" width="1488" srcset="https://blog.snappymob.com/hs-fs/hubfs/Apple%20homepage.png?width=744&amp;name=Apple%20homepage.png 744w, https://blog.snappymob.com/hs-fs/hubfs/Apple%20homepage.png?width=1488&amp;name=Apple%20homepage.png 1488w, https://blog.snappymob.com/hs-fs/hubfs/Apple%20homepage.png?width=2232&amp;name=Apple%20homepage.png 2232w, https://blog.snappymob.com/hs-fs/hubfs/Apple%20homepage.png?width=2976&amp;name=Apple%20homepage.png 2976w, https://blog.snappymob.com/hs-fs/hubfs/Apple%20homepage.png?width=3720&amp;name=Apple%20homepage.png 3720w, https://blog.snappymob.com/hs-fs/hubfs/Apple%20homepage.png?width=4464&amp;name=Apple%20homepage.png 4464w" sizes="(max-width: 1488px) 100vw, 1488px">(Image Source: Apple)</p>
<p>On their homepage, it’s difficult to ignore the huge product image that appears as soon as you enter, filling your entire screen from edge to edge, immersing you in it. The reason behind this design choice is to prevent decision fatigue and give visitors room to breathe. Instead of pushing their products onto you all at once, they let you focus on one single product, one headline, and one catchy subheadline.</p>
<p>Unlike most other websites that use multiple, smaller product photos, Apple uses techniques that obey the principles of visual hierarchy. They use large images, high contrast and bold typefaces for emphasis, and maximize space around it to draw even more attention to the subject. That is why when you glance at the image above, ‘iPhone 12 Pro’ takes center stage before anything else.</p>
<h2><strong>How Apple Does Product Design</strong></h2>
<p><span>It’s no unpopular opinion that Apple products look AND feel luxurious, whether it’s the iPhone, Mac, iPad or Apple Watch. One of the most groundbreaking moments for Apple was when they launched the original Macbook Air in 2008. Their iconic </span><a href="https://www.youtube.com/watch?v=3Ywa_EynjC8"><span>Envelope Ad</span></a><span> went viral because at the time, the Macbook Air was the thinnest laptop ever in the market.&nbsp;</span><span></span></p>
<p><span>When we look at their unrivaled history of success, we can’t help but wonder: What’s been keeping Apple products ahead of the rest all these years?</span></p>
<p><span><img src="https://blog.snappymob.com/hs-fs/hubfs/an%20image%20of%20iphone.jpg?width=724&amp;height=483&amp;name=an%20image%20of%20iphone.jpg" alt="an image of iphone" width="724" height="483" srcset="https://blog.snappymob.com/hs-fs/hubfs/an%20image%20of%20iphone.jpg?width=362&amp;height=242&amp;name=an%20image%20of%20iphone.jpg 362w, https://blog.snappymob.com/hs-fs/hubfs/an%20image%20of%20iphone.jpg?width=724&amp;height=483&amp;name=an%20image%20of%20iphone.jpg 724w, https://blog.snappymob.com/hs-fs/hubfs/an%20image%20of%20iphone.jpg?width=1086&amp;height=725&amp;name=an%20image%20of%20iphone.jpg 1086w, https://blog.snappymob.com/hs-fs/hubfs/an%20image%20of%20iphone.jpg?width=1448&amp;height=966&amp;name=an%20image%20of%20iphone.jpg 1448w, https://blog.snappymob.com/hs-fs/hubfs/an%20image%20of%20iphone.jpg?width=1810&amp;height=1208&amp;name=an%20image%20of%20iphone.jpg 1810w, https://blog.snappymob.com/hs-fs/hubfs/an%20image%20of%20iphone.jpg?width=2172&amp;height=1449&amp;name=an%20image%20of%20iphone.jpg 2172w" sizes="(max-width: 724px) 100vw, 724px"></span></p>
<p><span>Yes, Apple definitely has a strong focus on user experience, premium quality, practical design, and even tasking users’ feedback into consideration. But ask anyone what they think stands out about Apple products, and they’ll mention one thing </span><span>—</span> <em><span>simplicity</span></em><span>.</span></p>
<p><span>The book </span><em><span>Steve Jobs Biography</span></em><span> written by Walter Isaacson highlights Apple’s emphasis on simplicity:</span></p>
<p><span><em>Jobs’ belief in the power of simplicity as a design precept reached its pinnacle with the three consumer device triumphs he produced beginning in 2001: the iPod, iPhone and iPad. He immersed himself daily in the design of the original iPod and its interface.</em></span></p>
<p><span><em>His main demand was <strong>“Simplify!”</strong></em></span></p>
<p><span><em>He would go over each screen and apply a rigid test: If he wanted a song or a function, he should be able to get there in three clicks. And the click should be intuitive. If he couldn’t figure out how to navigate to something, or if it took more than three clicks, he would be brutal.</em></span></p>
<p><span><em>“There would be times when we’d wrack our brains on a user interface problem, and think we’d considered every option, and he would go, ‘Did you think of this?’” said Tony Fadell, the team leader.</em></span></p>
<p><span><em>“He’d redefine the problem or approach, and our little problem would go away.”</em></span></p>
<p><span>This is what makes Apple’s design unique. With Jobs’ hard focus on clean, simple, and sleek, iOS had started a big design wave </span><span>that, to this day, has Android operating systems scrambling to ride it.</span></p>
<p><span>When Apple launched the iPad 2 in Silicon Valley in 2011, Jobs said:</span></p>
<p><span><em>“It is in Apple’s DNA that technology alone is not enough - it’s technology married with liberal arts, married with the humanities, that yields us the results that make our heart sing.”&nbsp;</em></span></p>
<p><span>Today, it’s clear that Apple designers are continuing his legacy in keeping Apple at the intersection of technology and liberal arts. This is the reason why Apple’s design is great. Their products don't just look good, they’re designed in a way that thinks about the people they’re designed for.&nbsp;</span></p>
<h2><strong><span>Next Step for You</span></strong></h2>
<p><span>User experience makes Apple the winner that it is today. At Snappymob, we believe in the same thing.&nbsp;</span></p>
<p><span>We design products that function with feelings and connect with humans. If you’re in search of a product design and development agency, we are here to help.&nbsp;</span></p>
<p><span>Talk to us! Your consultation is on us.</span></p>
<p><strong><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-f33b2069-3350-40ff-bb1f-8570d0f9691e"><span id="hs-cta-f33b2069-3350-40ff-bb1f-8570d0f9691e"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/6960697/f33b2069-3350-40ff-bb1f-8570d0f9691e"><img id="hs-cta-img-f33b2069-3350-40ff-bb1f-8570d0f9691e" src="https://no-cache.hubspot.com/cta/default/6960697/f33b2069-3350-40ff-bb1f-8570d0f9691e.png" alt="Contact Us"></a></span></span><!-- end HubSpot Call-to-Action Code --></strong></p>
</span></p><p><label>app design</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/what-apple-teaches-us-about-web-and-product-design</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313100</guid>
            <pubDate>Sat, 05 Dec 2020 09:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CNCF Accepts Kyverno as the Latest Sandbox Project]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313041">thread link</a>) | @AnnieNma
<br/>
December 5, 2020 | https://thechief.io/c/news/cncf-accepts-kyverno-latest-sandbox-project/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/news/cncf-accepts-kyverno-latest-sandbox-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p>Nirmata announced the news of the acceptance of Kyverno by CNCF in its official <a href="https://nirmata.com/2020/11/18/nirmatas-kubernetes-native-policy-engine-kyverno-joins-the-cncf-as-a-sandbox-project/">blog</a> post. The post said that the decision to donate Kyverno was taken to promote the adoption of Kubernetes policies. Policy engines are crucial for enterprise Kubernetes management, but their complexity and learning curve hinder many from adopting it.</p><p><a href="https://github.com/kyverno/kyverno/">Kyverno</a> comes with a host of features, including:</p><ul><li><b>Admission controls</b>: To provide configuration security and block invalid and non-compliant configurations.</li><li><b>Background scanning</b>: Regularly scans all resources and creates a policy report for each namespace and cluster-wide resources.</li><li><b>Automated rules for pod controllers</b>: Uses pod policies to automatically generate rules for pod controllers, making Kubernetes policy management easier.</li><li><b>Dynamic generation of new configurations</b>: It helps enable several use cases by supporting flexible triggers for automatic dynamic regeneration of new configuration resources.</li><li><b>Synchronize configuration across namespaces</b>: Kyverno allows automatic propagation of changes from a common source by automatically synchronizing configuration changes across namespaces.</li></ul><p>Security seems one of the main concerns of enterprises that have already adopted this Kubernetes. Several companies are building tools to resolve critical security issues in Kubernetes. Just like Kyverno helps in securing Kubernetes, there are several other tools like <a href="https://thechief.io/c/cloudplex/top-10-kubernetes-security-tools/">Kube-bench, Kube-hunter, and Project Calico</a> that help in securing networking issues in Kubernetes. </p></div></section></div>]]>
            </description>
            <link>https://thechief.io/c/news/cncf-accepts-kyverno-latest-sandbox-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313041</guid>
            <pubDate>Sat, 05 Dec 2020 09:19:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Road to PWA – Part I]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312992">thread link</a>) | @s1hfmnn
<br/>
December 5, 2020 | https://blog.s1h.org/the-road-to-pwa-1/ | <a href="https://web.archive.org/web/*/https://blog.s1h.org/the-road-to-pwa-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p>PWAs are (hopefully) here to stay.</p><p>As I mentioned in my <a href="https://blog.s1h.org/wedding-pwa/">previous post</a>,</p><p>the problem with native apps is that they are supposed to be distributed via a dedicated app store.</p><p>To be able to distribute apps via these stores requires you to sign up for a developer account,</p><p>which requires a one time or regular payment.</p><p>(I do know about open-source app stores like <a href="https://f-droid.org/">F-Droid</a> for Android,</p><p>but I do assume that the largest portion of smartphone users does not.)</p><p>That's exactly where PWA's come into play!</p><h2 id="ok-sounds-cool-but-what-exactly-is-a-pwa">Ok, sounds cool, but what exactly <strong>IS</strong> a PWA?</h2><p>The most important thing about PWAs is that it's possible to enhance any existing web application with progressive features.</p><p>PWA features integrate seamlessly into existing applications, when added carefully they will be available in supporting browsers, but also not cause any differences or errors on browsers which do not (yet) support them.</p><p>In my opinion, the three core building blocks which make up a PWA are the following:</p><ol><li>Responsive, engaging Design</li><li>Modern JavaScript APIs</li><li>Service Workers</li><li>HTTPS</li></ol><p>The thing I want to talk about in this post is regarding the design of PWAs, but more posts will follow.</p><p>(Except for HTTPS. Here you only have to know that full-featured PWAs require HTTPS. You'll see why in the post on service workers. If you do not yet have a valid TLS certificate, I can only recommend <a href="https://letsencrypt.org/getting-started/">Let's Encrypt - Free SSL/TLS Certificates</a>. As an alternative, <a href="https://pages.github.com/">GitHub Pages</a> are also served via HTTPS and allow for custom domains.)</p><h2 id="responsive-design">Responsive Design</h2><p>Over the course of years certain UI / UX patterns established in smartphone apps.</p><p>The two most notable styles are certainly the <a href="https://developer.apple.com/ios/human-interface-guidelines/overview/themes/">iOS interface guidelines</a> and Google's <a href="https://material.io/guidelines/material-design/introduction.html">Material Design</a>.</p><p>These two style guides contain detailed information on how to design user interfaces for the respective platform,</p><p>as well as guidelines on how to handle user interaction.</p><p>Taking these guidelines into account gives new users an easier onboarding to your app,</p><p>since the overall look and feel already seems "familiar".</p><p>These guidelines are also of interest for progressive web apps.</p><p>Since a PWA could be used as a light-weight alternative to the full web page (<a href="https://mobile.twitter.com/">Twitter lite</a> for example),</p><p>or even serve as a full replacement to native apps,</p><p>users of your PWA should still feel at home,</p><p>no matter whether they are using a native app or visiting the web app.</p><h3 id="mobile-first">Mobile First</h3><p>The old-school approach when designing a webpage was to make it look good on desktop browsers and later on make it look ok on mobile browsers.</p><p>The mobile first approach takes the other way round by designing webpages with mobile devices in mind.</p><p>Design for smartphones but also apply techniques to make the webpage look good when accessed via desktop browser.</p><p>To make this possible one could rely on a CSS framework like Twitter's <a href="https://getbootstrap.com/">Bootstrap</a> or <a href="https://getmdl.io/">Material Design Lite</a>,</p><p>but it certainly does no harm to read up on CSS Media Queries <a href="https://blog.s1h.org/p/70dac731-261c-4e22-bbc0-efd51aa8a53c/">1</a>, <a href="https://blog.s1h.org/p/70dac731-261c-4e22-bbc0-efd51aa8a53c/">2</a>.</p><p>With mobile first UIs in place, another major point which distinguishes web apps from native apps is the fact, that web apps are still running in a browser.</p><p>One of the cool things about PWAs is that they can be "installed" to a device (well, currently it's an Android device, to be precise) like a native app.</p><p>The requirement for this is a so-called "<strong>app manifest</strong>".</p><h2 id="web-app-manifest">Web App Manifest</h2><p>The web app manifest contains metadata about a web application.</p><p>It's actually a simple JSON file, but it's also common to name the file</p><pre><code>manifest.webmanifest
</code></pre><p>The manifest file allows configuring things like application name, icons, display style, color schemes and much more.</p><p>The following listing shows the content of wddng's manifest:</p><pre><code>{
  "name": "wddng",
  "short_name": "wddng",
  "start_url": "./index.html",
  "scope": ".",
  "display": "standalone",
  "background_color": "#fff",
  "theme_color": "#fff",
  "description": "Keine Hochzeit ohne Technik!",
  "dir": "ltr",
  "lang": "en-US",
  "orientation": "any",
  "icons": [
    {
      "src": "./src/images/icons/app-icon-48x48.png",
      "type": "image/png",
      "sizes": "48x48"
    },
    {
      "src": "./src/images/icons/app-icon-96x96.png",
      "type": "image/png",
      "sizes": "96x96"
    },
    {
      "src": "./src/images/icons/app-icon-144x144.png",
      "type": "image/png",
      "sizes": "144x144"
    },
    {
      "src": "./src/images/icons/app-icon-192x192.png",
      "type": "image/png",
      "sizes": "192x192"
    },
    {
      "src": "./src/images/icons/app-icon-256x256.png",
      "type": "image/png",
      "sizes": "256x256"
    },
    {
      "src": "./src/images/icons/app-icon-384x384.png",
      "type": "image/png",
      "sizes": "384x384"
    },
    {
      "src": "./src/images/icons/app-icon-512x512.png",
      "type": "image/png",
      "sizes": "512x512"
    }
  ]
}
</code></pre><p><code>name</code> and <code>short_name</code> should be pretty self-explanatory.</p><p><code>name</code> contains the full application name and will be shown on e.g. the startup splash-screen.</p><p><code>short_name</code> will be used on application icons.</p><p>The <code>start_url</code> configures which URL is loaded on application start, via an optional application <code>scope</code> one could configure for which scopes the PWA manifest should apply. When navigating outside the scope, the web app would be served as a regular webpage.</p><p>Setting <code>"display": "standalone"</code> will display the web app like a native app including a launcher icon, hidden URL bar, hidden navigation elements etc.</p><p>There are many available options and the application manifest spec is still in active development.</p><p>According to the latest draft it will also be possible to install service workers via manifest option.</p><p>I won't go in on details on all available values, for an explanatory overview you can check the resources provided at the end of the post.</p><h3 id="including-a-manifest">Including a manifest</h3><p>A manifest file is included using a <code>&lt;link ...&gt;</code> tag with relationship set to <code>"manifest"</code>.</p><pre><code>&lt;link rel="manifest" href="/manifest.webmanifest"&gt;
</code></pre><h4 id="side-note-packaging-using-parcel-js">Side note: Packaging using <a href="https://parceljs.org/">parcel.js</a></h4><p>At the time of writing, <a href="https://parceljs.org/">parcel.js</a> would only package manifest files with <code>*.webmanifest</code> ending correctly.</p><h2 id="useful-resources">Useful resources</h2><ul><li><a href="https://w3c.github.io/manifest/">Web App Manifest Spec</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/Manifest">MDN webdoc on Web App Manifest</a></li><li><a href="https://caniuse.com/#feat=web-app-manifest">Browser support for app manifests</a></li></ul><h2 id="summary">Summary</h2><p>Using responsive design combined with an application manifest makes your web app mobile device friendly and installable.</p><p>It's also possible to partially customize the app theme via manifest file.</p><p>Adding a manifest to a web application is our first step to a full-featured progressive web app.</p><p>Stay tuned for more!</p><p>So long</p><p>Simon</p>
                                </div></div>]]>
            </description>
            <link>https://blog.s1h.org/the-road-to-pwa-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312992</guid>
            <pubDate>Sat, 05 Dec 2020 09:10:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Horizons]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312940">thread link</a>) | @simonebrunozzi
<br/>
December 5, 2020 | https://www.yakcollective.org/projects/future-frontiers/#projects-future-frontiers-01-philosophy-01-on-horizons-01 | <a href="https://web.archive.org/web/*/https://www.yakcollective.org/projects/future-frontiers/#projects-future-frontiers-01-philosophy-01-on-horizons-01">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="projects-future-frontiers"><div><div><div><div id="projects-future-frontiers-01-philosophy-01-on-horizons-01"><div><div><h3><a href="#projects-future-frontiers-01-philosophy-01-on-horizons-01">On Horizons</a></h3><p><time>December 1st, 2020</time></p><p>#philosophy</p><p><em>Because horizon is the end of vision, and because every move we make gives the field an aspect we couldn’t have noticed before, what lies beyond the horizon cannot be known. […] There are experiences and new information that will show the familiar as strange, the comforting as dangerous, the adjacent as distant. […] Moreover, not every shift of the viewer will reveal something significant. It can be just more of the same, or nothing worth reflecting on. And yet without that shift, we begin to lose our vision altogether: what is seen over and over again ceases to be seen.</em><br>— James P. Carse, <a href="https://archive.org/details/religiouscaseaga00cars"><em>The Religious Case Against Belief</em></a>, pages 80–81</p><p>Frontiers are essential food for the psyche, for a species with the temporal imagination to see past the limits of individual mortality. Frontiers are spaces where moving towards horizons results reliably, if not predictably, in encounters with novelty. And it is the endless supply of novelty flowing across the frontier horizons of humanity that makes it possible to play what philosopher James Carse called the infinite game, where the goal is not to win, but to continue the play.</p></div></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-02-trends-01-democratized-underwater-exploration-01"><div><div><h3><a href="#projects-future-frontiers-02-trends-01-democratized-underwater-exploration-01">Democratized Underwater Exploration</a></h3><p><time>December 1st, 2020</time></p><p><a href="https://www.yakcollective.org/members/rao-venkatesh/">Venkatesh&nbsp;Rao</a></p><p>#trends</p><p>Consumer-priced ocean exploration products are just beginning to emerge, creating unprecedented opportunities for democratized participation in oceanic exploration. Companies like Sofar (created via merger of OpenROV and Spoondrift) now offer consumer-priced oceanic exploration gear capable of serious research and exploration activities. The development is similar to the impact of low cost, high power amateur telescopes (such as large aperture Dobsonian telescopes) in amateur astronomy. But the stack required for true democratization remains incomplete.</p></div></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-02-trends-01-democratized-underwater-exploration-02"><div><p><strong>Consumer-scale products</strong> have limited range, endurance, depth limit, modest sensor payload, low autonomy capabilities, and a limited stack. <strong>Bespoke research equipment</strong> like the MBARI <em>Tethys</em> above are capable of long range endurance missions and are supported by a deeper stack of support technologies.</p></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-02-trends-01-democratized-underwater-exploration-03"><div><div><ul><li><strong>Political:</strong> How do amateurs enter the playground of militaries and commercial shipping?</li><li><strong>Economic:</strong> How do amateurs meet the high costs of staging deep ocean exploration?</li><li><strong>Socio-cultural:</strong> The oceans are a wilderness, how do you build a cultural foundation?</li><li><strong>Technological:</strong> How to build the capabilities, which are much deeper than other amateur fields?</li><li><strong>Legal:</strong> Can amateurs handle lawless international waters and regulation choked territorial waters?</li><li><strong>Ecological:</strong> Will amateurs help protect threatened marine ecosystems or become part of the threat?</li></ul></div></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-02-trends-01-democratized-underwater-exploration-04"><div><div><p>What might a solid stack for democratized underwater exploration look like?</p><ul><li><strong>Grand challenges and missions:</strong> Suited to democratized exploration</li><li><strong>Strong explorer community:</strong> Comparable to open source, maker movement, astronomy</li><li><strong>Open-source software tools:</strong> To process data from community oceanic infrastructure</li><li><strong>Infrastructure relations:</strong> With research institutions, commercial shipping, military</li><li><strong>Piggyback capabilities:</strong> For opportunistic staging, deployment, communications, and telemetry</li><li><strong>Hardware foundation:</strong> High-quality, low-cost, high-variety hardware with greater range, endurance, and sensor payloads</li></ul></div></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-02-trends-02-the-promise-of-nanosatellites-for-developing-nations-01"><div><div><h3><a href="#projects-future-frontiers-02-trends-02-the-promise-of-nanosatellites-for-developing-nations-01">The Promise of Nanosatellites for Developing Nations</a></h3><p><time>December 1st, 2020</time></p><p><a href="https://www.yakcollective.org/members/ramsamy-kannen/">Kannen&nbsp;Ramsamy</a></p><p>#trends</p><p>The modern-age space industry has long been dominated by major global superpowers. Today nanosatellites offer significant promise for <strong>developing nations to engage with the space industry on their own terms, in a way that directly benefits <em>their</em> populations</strong>. Domestic universities, public sector bodies and businesses can begin to come to grips with space tech without necessarily turning to wealthier nations to ‘import’ relevant technological insight and expertise. Younger generations pursuing interests in space will also have increased opportunities to realise these interests at home, rather than abroad.</p></div></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-02-trends-02-the-promise-of-nanosatellites-for-developing-nations-02"><div><div><p>In 2017 the Federal University of Technology in <strong>Nigeria</strong> launched the <strong>Nigeria-Edusat-1</strong>. The objectives for Nigeria were to increase their scope for space education, capture low/high res photographs of the country and improve measurements of atmospheric density.</p><p>In 2018 the Cape Peninsula University of Technology in <strong>South Africa</strong> launched the <strong>ZACube-2</strong>. The objectives for South Africa were to monitor their natural resources and enhance communication services.</p><p>The nanosatellite launch rate is expected to continue growing, signalling a move away from the elitist and unrestrainedly expensive routes that have been the mainstay of the industry. Developing nations will be able to capture a small percentage of this continued growth, gaining access to space in the way that Nigeria and South Africa have successfully been able to do.</p></div></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-02-trends-02-the-promise-of-nanosatellites-for-developing-nations-03"><div><div><p>Nanosatellites shift the power dynamics of space exploration by transforming it into a truly multi-actor field. Developing nations can partake in a variety of political alliances that start to form exclusively across the space industry in a similar way to existing economic/trade alliances.</p><p>Those which rely heavily on natural resources will benefit from nanosatellite data e.g. understanding how rapid growth in human populations could impact certain agricultural/geological spaces. Improved signal monitoring will also help navigate the impact of natural disasters and support effective relief mobilisation. Developing nations will also eventually start to leverage their data/expertise/manufacturing capacity emerging from nanosatellite usage.</p></div></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-03-exploitation-01-starship-gold-rush-01"><div><div><h3><a href="#projects-future-frontiers-03-exploitation-01-starship-gold-rush-01">Starship Gold Rush</a></h3><p><time>December 1st, 2020</time></p><p><a href="https://www.yakcollective.org/members/bilsland-charlie/">Charlie&nbsp;Bilsland</a></p><p>#exploitation</p><p>Getting into orbit has always been the biggest challenge of space. A functioning Starship would reduce cost to orbit by a factor of ten, with wide-reaching implications. Politically, US dominance of the space environment could grow, with grave implications for multilateral space law, and the danger of space debris could grow exponentially. New advances in space technology could surge forward, especially in the fields of resource utilisation and in-space manufacturing, as well as significant growth in space tourism.</p></div></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-03-exploitation-01-starship-gold-rush-02"><div><p>One future vision, enabled by Starship, could be the US gaining strategic control of the orbital environment, as well as tactical control of Shackleton Crater on the South Pole of the moon by 2030. Shackleton Crater, with both the largest amount of water ice on the moon, and peaks of eternal light, enables the US to crack water ice into rocket fuel, further consolidating their dominance over the cislunar sphere. China predictably responds in kind, expanding their lunar base, and our orbital environment is becoming increasingly militarised. Europe and Russia are working together to restrain the expansion of these superpowers, with little success so far.</p></div></div></div></div></div><div><div><div><div id="projects-future-frontiers-99-epilogue-01-contribute-to-future-frontiers"><div><div><h3><a href="#projects-future-frontiers-99-epilogue-01-contribute-to-future-frontiers">Contribute to Future Frontiers</a></h3><p>Future Frontiers is set up as an indefinitely evolving project, to which new modules can be added at any time. Any member of the Yak Collective is welcome to contribute a module (subject to editorial approval) on any frontiers-related topic at any time. If you would like to contribute a module, check out <a href="https://roamresearch.com/#/app/ArtOfGig/page/O12GM-bXp">the project page</a> for details.</p><p>We’ve made a special effort to make this project newbie-contribution friendly. It is one of the easiest and fastest ways for you to learn what the Yak Collective is about, and how to get active within it.</p><p>When you contribute to <em>Future Frontiers</em>, you will make new friends, learn how our projects work, earn a member page on this website, and level up your role from <em>yak</em> to <em>made yak</em> on our Discord server. All you need is an interesting take on the nature of frontiers that can be captured in a few slides and short notes. If you can’t think of a topic, there is a list of prompts and suggestions available for you on the project page.</p></div></div></div></div></div></div></article></div>]]>
            </description>
            <link>https://www.yakcollective.org/projects/future-frontiers/#projects-future-frontiers-01-philosophy-01-on-horizons-01</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312940</guid>
            <pubDate>Sat, 05 Dec 2020 08:57:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Immutable C#]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312935">thread link</a>) | @Sankra
<br/>
December 5, 2020 | https://functional.christmas/2020/5 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><section><p>I really love C#. It's by far <a href="https://hjerpbakk.com/tag/csharp/">my favorite programming language</a>. And who wouldn't agree? I mean with a piffy, roll of the tounge <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)">Wikipedia description</a> like this, what is not to love?</p>
<blockquote>
<p>C# is a general-purpose, multi-paradigm programming language encompassing static typing, strong typing, lexically scoped, imperative, declarative, functional, generic, object-oriented (class-based), and component-oriented programming disciplines.</p>
</blockquote>
<p>"Yeah, yeah", I hear you say dear reader. "I know C# is great to use if you want to write better Java apps, even so, this is the Bekk Functional advent calendar. What are you rambling about?"</p>
<p>I know you love your pure, scalable functions in <a href="https://wiki.haskell.org/Functional_programming#Purity">Haskell</a> and your fancy web pages written in <a href="https://www.elm.christmas/2020">Elm</a>, but did you spot the magic word in the description above? It said:</p>
<blockquote>
<p>... <strong>functional</strong> ...</p>
</blockquote>
<p>Yes! As the late Sean Connery <a href="https://youtu.be/hKJZ9pzDMCk">said so excitedly</a>:</p>
<p><img src="https://hjerpbakk.com/img/christmas/the-day-is-mine.jpeg" alt="The day is mine!"></p>
<p>C# is not only useful on the <a href="https://docs.microsoft.com/en-us/aspnet/core/introduction-to-aspnet-core?view=aspnetcore-5.0">backend</a>, while writing <a href="https://docs.microsoft.com/en-us/xamarin/">iOS and Android apps</a>, <a href="https://docs.microsoft.com/en-us/aspnet/core/blazor/?view=aspnetcore-5.0">replacing JS in the browser</a> or as a <a href="https://github.com/filipw/dotnet-script">scripting language</a>, it also becomes more and more functional-friendly with every new language version!</p>
<p>However, what does it mean to be a <em>functional-friendly</em> programming language?</p>
<h2>Functional advantages</h2>
<p>Enrico Buonanno argues in his book <a href="https://www.amazon.com/Functional-Programming-write-better-code/dp/1617293954/">Functional Programming in C#: How to write better C# code</a> that we should care about functional programming because it gives us the following:</p>
<ul>
<li><strong>Power:</strong> We can get more done with less code. Functional programming raises the level of abstraction, allowing us to write high-level code while freeing us from low-level technicalities that add complexity but no value.</li>
<li><strong>Safety:</strong> A program written in the imperative style may work well in a single-threaded implementation but due to the mutable state that is in its nature, cause all sorts of bugs when concurrency comes in. Code in the functional style might offer better guarantees in concurrent scenarios.</li>
<li><strong>Clarity:</strong> We spend more time maintaining and consuming existing code than writing new code, so it’s important that our code be clear and intention-revealing. As we learn to think functionally, achieving this clarity will become more natural.</li>
</ul>
<p>C# supports a lot of <a href="https://functionalprogrammingcsharp.com/functional-features-of-c-sharp">functional building blocks</a>, such as <em>function delegates</em>, <em>higher order functions</em>, <em>expressions instead of statements</em>, <em>method chaining</em>, <em>extension methods</em>, <em>yield</em>, <em>LINQ</em>, <em>tuples</em> and <em>local functions</em>. Despite all that, the core functional tenet of <em>immutability of data</em> has always been a C# pain point. Until now.</p>
<h2>Immutability in C#</h2>
<p>C# second greatest error<sup><sup id="fnref-1"><a href="#fn-1">1</a></sup></sup> was to one-up Java and introduce the concept of properties as a first class language feature with the poorest defaults of all time: the default property syntax made it all too easy to create classes with mutable properties. The deed is as simple as:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>Person</span>
<span>{</span>
    <span>public</span> <span><span>uint</span></span> Age <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>
<span>}</span></code></pre></div>
<p><img src="https://hjerpbakk.com/img/christmas/the-wolf.png" alt="Listen to the wolf"></p>
<p>Alas, premature aging can take its toll and we should've listened to the dog, hound, wolf or whatever, and make the <code>age</code> property immutable. It came with a cost however, amounting to a lot more work and boilerplate code. I mean, I got bored by just writing out this small example from the past:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>Person</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span><span>uint</span></span> age<span>;</span>

    <span>public</span> <span>Person</span><span>(</span><span><span>uint</span></span> age<span>)</span>
    <span>{</span>
        <span>this</span><span>.</span>age <span>=</span> age<span>;</span>
    <span>}</span>

    <span>public</span> <span><span>uint</span></span> Age <span>{</span> <span>return</span> age<span>;</span> <span>}</span>
<span>}</span></code></pre></div>
<p><a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/properties#expression-body-definitions">C# 6</a> made the pit of success a bit deeper by introducing read-only properties using only a <code>get</code> accessor:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>Person</span>
<span>{</span>
    <span>public</span> <span>Person</span><span>(</span><span><span>uint</span></span> age<span>)</span>
    <span>{</span>
        Age <span>=</span> age<span>;</span>
    <span>}</span>

    <span>public</span> <span><span>uint</span></span> Age <span>{</span> <span>get</span><span>;</span> <span>}</span>
<span>}</span></code></pre></div>
<p><a href="https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/builtin-types/struct#readonly-struct">C# 7.2</a> made declaring our intent more explicit by allowing a <code>struct</code> to be marked as <code>readonly</code>:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>readonly</span> <span>struct</span> <span>Person</span>
<span>{</span>
    <span>public</span> <span>Person</span><span>(</span><span><span>uint</span></span> age<span>)</span>
    <span>{</span>
        Age <span>=</span> age<span>;</span>
    <span>}</span>

    <span>public</span> <span><span>uint</span></span> Age <span>{</span> <span>get</span><span>;</span> <span>}</span>
<span>}</span></code></pre></div>
<p>This is all well and good, yet consider when our class or struct has multiple readonly properties and we need to construct a new copy with an updated value in one or more of them. My head hurts just by thinking about it. The boilerplate has tested my Christmas spirit, why must we endure this error prone, manual waste? A better way must exist!</p>
<h2>Records in C# 9</h2>
<p>And finally this year, at the end of the <a href="https://www.youtube.com/watch?v=zu3k2PJumfI">worst year ever</a>, it does! Microsoft bestowed <a href="https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-9">.Net 5 and C# 9</a> upon us, giving us my most requested feature: <em>language support for immutable data types</em>, <a href="https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-9#record-types">Record types</a>!</p>
<div data-language="csharp"><pre><code><span>public</span> <span>record</span> <span>Person</span><span>(</span><span><span>uint</span></span> Age<span>)</span><span>;</span>
</code></pre></div>
<p>A <code>record</code> is immutable in that none of the properties can be modified once it's been created. When we define a record type, the compiler provides several useful methods for us:</p>
<ul>
<li>Methods for value-based equality comparisons</li>
<li>Override for <code>GetHashCode()</code></li>
<li>Copy and Clone members</li>
<li><code>PrintMembers</code> and <code>ToString()</code></li>
</ul>
<p>Seems like we're finally winning the war against boilerplate, and if we need to create a copy with an updated value, we can now easily use the <code>with</code> keyword:</p>
<div data-language="csharp"><pre><code><span><span>var</span></span> me <span>=</span> <span>new</span> <span>Person</span><span>(</span><span>37</span><span>)</span><span>;</span>
<span>Person</span> meAYearOlder <span>=</span> <span>me</span> with <span>{</span> Age <span>=</span> <span>38</span> <span>}</span><span>;</span></code></pre></div>
<p>With such quality functional features in C# like <em>immutable records</em>, not even time's inevitable flowing towards my 40th birthday and usage of 24(!) year old memes can break this aging developer's Christmas spirit!</p>
</section></article></div></div>]]>
            </description>
            <link>https://functional.christmas/2020/5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312935</guid>
            <pubDate>Sat, 05 Dec 2020 08:55:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maybe we shouldn't want a fully decentralized web]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 415 (<a href="https://news.ycombinator.com/item?id=25312854">thread link</a>) | @talhah
<br/>
December 5, 2020 | https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spent a large part of 2019 working with the distributed and decentralized web, especially IPFS, also known as the “Inter-Planetary File System”. I’ve written a few articles on the topic, on how you can host a web app on IPFS, one of which even ended up on the front page of HackerNews.</p><p>For about a year, I hosted my blog and other apps through an IPFS cluster. I wrote a utility for making pinning files easier on Pinata, a third-party cloud service for IPFS. I made some small contributions to the IPFS core projects. I built some projects with it, including one that I never released–nor fully completed–that used both IPFS and Ethereum. And I even gave a talk about hosting static web apps on IPFS at Node+JS Interactive last December in Montreal.</p><p>That all changed in the Spring of 2020. I called myself out of the distributed web.</p><p>My blog and other apps I built aren’t hosted on IPFS anymore. I don’t participate in those online communities anymore. I’ve stopped writing about the distributed and researching about it. I’ve shelved all my projects that were using those technologies.</p><p>I also updated my blog posts about IPFS adding a note that my blog isn’t hosted that way anymore. More than a few people asked me why, and I always gave the same answer: a mix of technical issues and mostly personal reasons. So, I think it’s time I explain the personal reasons.</p><p>First, I need to explain why I got involved with IPFS in the first place.</p><p>When I first read about IPFS, my mind immediately saw it as an exciting new platform I could build my apps for. The premise of a fully-decentralized platform included unlimited scalability, ultra-high availability and resiliency, no single points of failure, and resistance against attacks like DDoS.</p><p>Coming from a background in which I am always thinking about SLAs, number of nines of uptime, disaster recovery, etc, IPFS sounded like a dream platform that would magically solve all my concerns. And, aside from some performance issues at times, it did. Plus, the small engineer inside me was really excited about being able to play with a new, shiny toy, that had lots of hype around it!</p><p>What happened next for me was a reckoning with the reality of what many people behind the IPFS core project and the community around it saw: the dream of a radically open, unfiltered, and by-design un-censorable platform.</p><p>I have recently opened up about my experience, over a decade ago, with building an app with good intentions but that was then misused (<a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html"><em>That time I accidentally built a spying app</em></a>). I learned early on in my life and (pre-)professional career about the importance of ethics in software development, and I am now a proponent of the idea that just because something <em>can</em> be built, it doesn’t mean it <em>should</em> be built.</p><p>And that brings me back to why, after spending some time in the world of the decentralized web, I have called myself out, and why I think that should things like IPFS actually become mainstream, they might cause more harm than good in the world.</p><p><strong>I have seen, and I am seeing every day, the dangers of completely unrestricted speech, and I don’t want to be the one enabling that.</strong></p><p>I know that last sentence is a strong ideological statement; some might call it a <em>political</em> statement, but for me it’s more than just political, which is often used to describe extemporary beliefs.</p><p>Many of you reading this will not agree with me, and that’s fine. I’m not going to try and change your beliefs with this blog post. Rather, I’m looking to explain why, while I respect that others might have differing opinions, I stopped doing anything that would actively advance a technology whose ethics I question. To put it in other terms: your freedom of speech isn’t my obligation to enable you and give you a platform.</p><p>In short, I think that while the Internet has helped the world in countless of ways, it has also brought out the worst in people.</p><p>I do believe we need some filters on the Internet. It’s not just about stopping criminal activities, terrorism and child pornography: while I am obviously unsupportive of all them, I also think they’re not the biggest dangers coming from the Internet (yet they’re a very convenient pretext for politicians).</p><p>Instead, I think that regular people’s writings on the Internet is hurting the world on a bigger scale. And the collective sentiment is often manipulated by some “agitators” that are exploiting anonymous online speech for their own agendas: that includes online militias–for example sponsored by foreign governments–whose goal is to destabilize a society.</p><p>In the last few years, completely unregulated online speech has given rise to fake news and conspiracy theories that have actually killed people. It’s offered a megaphone to those promoting dangerous ideas like white supremacy, Islamophobia, anti-Semitism, homophobia and other anti-LGBTQ positions, and sometimes outright Nazism. It has tilted many democracies towards right-wing populism and fascism.</p><p>All these extreme ideas have divided societies and increased social tensions. And they’re responsible for a number of acts of terrorism which caused the death of too many people.</p><p>Given our experiences so far, there’s no sign that indicates that a fully decentralized and unrestrained web would be anything but a dangerous wild west.</p><p>In fact, despite being tightly centralized and controlled, social media companies are facing significant challenges regulating what people write on their platforms, and in fact they are usually at the center of every scandal of these years. Decentralization and less control won’t be the solution to this issue, but rather the opposite.</p><p>If you believe that I’m overthinking this, and that it’s not going to be bad <em>this time</em>, I urge you to think twice.</p><p>First, there’s no indication that a new Web would be better than the previous one just on virtue of being decentralized. The same actors that are using today’s Internet to wreak havoc around the world would not disappear in the new Internet, and actually, they could be even more unrestrained.</p><p>Second, while almost everyone in the communities supporting a distributed web are good people, with good intentions, seeing some names in there is concerning to me. Regarding IPFS, advocates (at least for a while) included people like Nick Lim of BitMitigate and VanwaNet, companies responsible for rescuing, among others, <a href="https://www.geekwire.com/2017/seattles-bitmitigate-now-protecting-pro-nazi-site-daily-stormer-web-attacks/">pro-nazi website</a> The Daily Stormer <a href="https://arstechnica.com/information-technology/2019/11/breaking-the-law-how-8chan-or-8kun-got-briefly-back-online/">and the platform</a> 8chan, a cesspool full of Nazi propaganda, child pornography, and other hate speech. Gatherings on 8chan have been <a href="https://en.wikipedia.org/wiki/8chan#2019_shootings">blamed</a> for at least three mass shootings in 2019 alone, including the one in the <a href="https://time.com/5648479/8chan-ban-new-zealand/">mosque in Christchurch</a>, all of them motivated by racial hatred.</p><p>The first real examples of the distributed web aren’t particularly encouraging either. Among some of the most popular apps (“popular” in relative terms, of course) for the distributed web is DTube, a sort of YouTube that is built on top of IPFS. As you can expect, the website is full of questionable content, including conspiracy theories, cryptocurrency scams, weapons, RT&nbsp;International’s <a href="https://www.theguardian.com/commentisfree/2019/jul/26/russia-disinformation-rt-nuanced-online-ofcom-fine">Russian propaganda</a>… and of course, porn.</p><p>In essence, if it’s true that <em>a good beginning makes a good ending</em>… with such a mixed beginning, the outlook isn’t too rosy.</p><p>I understand that my opinion is somehow a minority one, and people will continue to build IPFS and other technologies part of the distributed web. There’s also a chance they might become successful and potentially get mainstream adoption–although at this stage the barrier to entry is too high for the average user.</p><p>However, I feel that it’s my responsibility to not be helping to advance this technology and the beliefs of at least some advocates in the world of the distributed web hold. If the advancement occurs, it won’t be because of my help.</p><hr><p><em>PS: The idea that freedom of speech is an absolute right that should have (almost) no limitations is not a universal one. While that right is granted to people living in all democratic countries, outside of North America it’s accepted that such right comes <a href="https://www.nytimes.com/2019/08/06/world/europe/el-paso-shooting-freedom-of-speech.html">with limitations</a>, and usually that has roots in the history of those places.</em></p><p><em>For example, in Italy where I grew up, the same constitution that grants freedom of expression (speech, press, etc) also criminalizes “apology of fascism”, or propagating the ideas of fascism; it also sets other limits on speech that is hateful or discriminatory. Other European countries have similar laws, such as the outlawing of Nazi rhetoric and symbology in Germany.</em></p></article></div>]]>
            </description>
            <link>https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312854</guid>
            <pubDate>Sat, 05 Dec 2020 08:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Coils to Curves – A Primer on Elliptic Curve Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312733">thread link</a>) | @roberla
<br/>
December 4, 2020 | https://security.christmas/2020/5 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>It is well known that prime numbers are important for cryptography, although it has not always been true. The advent of primes came with several groundbreaking papers almost 50 years ago. Pioneers in introducing asymmetric cryptography, Whit Diffie, Martin Hellman, Ron Rivest, Adi Shamir and Leonard Adleman, used results from number theory to build key agreement, encryption, and signatures. Prime numbers hold a very special position in number theory, and this carried over to cryptography.</p>
<h2>From Primes to Crypto</h2>
<p>Cryptographic protocols are typically working <em>modulo</em> some prime <em>p</em>. This can be likened to turning the number line into a coil, such that 0, <em>p</em>, 2<em>p</em>, etc. all join at the same place. From then on, whenever we add or multiply the number such that we go beyond <em>p</em>, we can simply remove as many multiples of <em>p</em> as necessary until we come between 0 and <em>p</em> again.</p>
<p>Now, imagine that we used a composite number instead, for example 12. Then 0 and 12 are "the same" in this situation, but that also means that 3 multiplied by 4 is ... 0! One of the intuitions when working with normal numbers is that if <em>ab</em> = 0, then either <em>a</em> or <em>b</em> would have to be 0. Hence, when using composite numbers, there is simply stuff that no longer works the way we’re used to. Fortunately, this is not the case when using the primes — for instance 7 — as our so-called modulus.</p>
<p><img src="https://security.christmas/assets/curves.png"></p>
<p>Let’s make a rule, and let’s call it <em>m</em>. We take the coil we just made from the number line, and since we can always reduce numbers to below <em>p</em>, we label our points on this circle from 0 to <em>p</em>-1. Given two points <em>a</em> and <em>b</em> on the circle, we decided that the output of the rule <em>m</em>(<em>a</em>, <em>b</em>) should be the point which is represented by the product <em>ab</em>, possibly after reducing modulo <em>p</em>. It may look like a very natural rule, but it is nonetheless a rule we just agreed on. If you play around with this rule a bit, you will notice some properties:</p>
<ul>
<li>If <em>a</em> = 1, then <em>m</em>(<em>a</em>, <em>b</em>) = <em>b</em> (and the other way around).</li>
<li>For any <em>a</em>, <em>b</em> not equal to 0, <em>m</em>(<em>a</em>, <em>b</em>) is never zero. So, if we removed 0 from the circle entirely, no harm would happen — the rule would still be well-defined.</li>
<li>For any nonzero <em>a</em>, there is always some <em>b</em> such that <em>m</em>(<em>a</em>, <em>b</em>) = 1.</li>
</ul>
<p>These nice properties — together with a property called associativity — are the properties we need to be able to do cryptographic computations.</p>
<p>Now focus on a particular number on the circle, and let’s call it <em>g</em>. If we take <em>m</em>(<em>g</em>, <em>g</em>), or — to return to the more usual notation — <em>g²</em>, we will reach a new point on the circle. We can continue this process and compute <em>g</em>³, <em>g</em>⁴, etc. At some point, we will reach 1. All the points we have visited in this process are members of the set of numbers <em>generated</em> by <em>g</em>, and if the number of points on the coil is a large prime, then we have a very good candidate for doing cryptography, for example Diffie-Hellman key exchange. Let <em>h</em> be some number in this set generated by <em>g</em>. That means that <em>h</em> = <em>g</em>ᵉ for some exponent <em>e</em>. If it is easy to find this <em>e</em> from <em>g</em> and <em>h</em>, we would have trouble. Fortunately, it turns out that if we use <em>large enough</em> primes, then this <em>e</em> appears to be very difficult to find.</p>
<h2>From Coils to Curves</h2>
<p>Coiling up the number line is not the only way of finding suitable primitives for cryptography. Let’s make a new rule. Instead of using a circle like we did in the previous section, we consider the following equation:</p>
<p><em>y</em>² = <em>x</em>³ + <em>ax</em> + <em>b</em>, where <em>a</em> and <em>b</em> are fixed constants.</p>
<p>If we graph this in our usual coordinate system, it may look like this curve:</p>
<p><img src="https://security.christmas/assets/curves2.png"></p>
<p>We will now make a rule on how to combine two distinct points <em>P</em> and <em>Q</em> on this curve. The agreed upon notation is to call this rule addition, but we will have to define what we mean by that. Programming languages often include this mental concept as operation overloading. Draw the straight line between <em>P</em> and <em>Q</em>. It will intersect at a third point, say, <em>R</em>. This could have been a nice candidate for <em>P</em> + <em>Q</em>, but since we are making the rules, let’s make this a bit more interesting. Draw a vertical line through <em>R</em>. It will intersect the curve on the opposite side of the <em>x</em>-axis, and we define this point as <em>P</em> + <em>Q</em>. Just as before, this is a rule we’re deciding here and now. However, this also turns out to be a very useful rule, with the same properties as before:</p>
<ul>
<li>Instead of having the point 1 on the circle, we imagine a point infinitely far up. (Remember what you see when looking at railway tracks: parallel lines actually meet beyond the horizon, at infinity.) So, now the line intersecting <em>R</em> and <em>P</em> + <em>Q</em> is indeed also intersecting a third point: the point at infinity. This can be made precise, but requires maths from algebraic geometry, which is far beyond the scope of this blog post. This point at infinity has all the same properties as 1 had above.</li>
<li>For any point <em>S</em> on the curve, there is always a point <em>T</em> such that we get a line intersecting <em>S</em>, <em>T</em> and the point at infinity. This means that for any point <em>S</em>, we can find a point we can call -<em>S</em>.</li>
</ul>
<p>You can test this rule interactively in a simple <a href="https://www.geogebra.org/m/ukhajwzs">GeoGebra demonstration</a>.</p>
<p><img src="https://security.christmas/assets/ec_group_law.gif"></p>
<p>We just assumed that <em>P</em> and <em>Q</em> were distinct. If <em>P</em> = <em>Q</em>, then we simply use the tangent to the curve at point <em>P</em> instead, and proceed as before.</p>
<p>In particular, take a point <em>G</em>, and compute 2<em>G</em> = <em>G</em> + <em>G</em>, 3<em>G</em>, 4<em>G</em>, etc. Eventually, we reach the point at infinity, and then back to <em>G</em>. We have now spent about 1000 words of this blog post getting here, just to do the same as we did above, and what was the point? Above, we said that computing exponents are secure if the primes were large enough. It turns out that "large enough" is currently about 3072 bits, or a number with approximately 925 digits. That is somewhat strenuous even for a computer, but the elliptic curve version only requires us to work on numbers of size 256 bits, or 77 digits, which is far more efficient.</p>
<h2>Elliptic Curve Diffie-Hellman Key-Exchange</h2>
<p>The Diffie-Hellman key-exchange protocol is widely used today, and its instantiation using elliptic curves is ranked as the best choice in modern cryptographic protocols like TLS and SSH. The protocol is fairly simple. The public information is an elliptic curve <em>E</em> and a generator <em>G</em> for the points on this curve. One party, Alice, samples a random integer <em>a</em> and computes a point <em>A</em> = <em>a</em> <em>G</em>. Another party, Bob, samples a random integer <em>b</em> and computes <em>B</em> = <em>b</em> <em>G</em>. Then they exchange the values <em>A</em> and <em>B</em>, and compute the shared key <em>K</em> = <em>b</em> <em>A</em> = <em>a</em> <em>B</em> = <em>a</em> <em>b</em> <em>G</em>. As long as both <em>a</em> and <em>b</em> stay secret, even when an attacker knows <em>G</em>, <em>A</em> and <em>B</em>, then the key is secure.</p>
<p><img src="https://security.christmas/assets/dh.png"></p>
<p><em>Reference: <a href="https://asecuritysite.com/encryption/go_x3dh">https://asecuritysite.com/encryption/go_x3dh</a>. Used with permission.</em></p>
<p>To achieve long-term security, to protect previous messages in the case where someone’s secret keys are leaked after the fact, Alice and Bob can do an ephemeral key-exchange every time they communicate. If <em>a</em> and <em>A</em> is Alice’s long term key pair where <em>A</em> is public to everyone, and similar for Bob, they can run the following protocol to agree upon a one-time session-key. Alice samples a random integer <em>c</em> and computes <em>C</em> = <em>c</em> <em>G</em>, and Bob samples a random integer <em>d</em> and computes <em>D</em> = <em>d</em> <em>G</em>. Then they exchange <em>C</em> and <em>D</em>, and compute the shared key as (<em>a</em> <em>b</em> + <em>c</em> <em>d</em> )<em>G</em>.</p>
<p>The interested reader can check out this <a href="https://play.golang.org/p/qJBI0_2lsGP">simple example written in Go</a>. Are you able to extend the basic protocol to the ephemeral key-exchange on behalf of Alice and Bob?</p>
<p>We finally point out that this protocol is vulnerable to a man-in-the-middle attack, and we need to also send signatures computed on the messages to ensure that the communication is authentic. Are you able to attack the protocol as described above, when signatures are not used? If you found these problems interesting, we encourage you to check out similar challenges at <a href="https://cryptohack.org/challenges/ecc/">cryptohack.org</a>.</p>
<h2>Common Curves</h2>
<p>Not all elliptic curves are suitable for cryptography. There could also be power in choosing a curve and the distinguished base point(s). Hence, implementations tend to choose among a small number of well-known curves. The US National Institute of Standards and Technology <a href="https://csrc.nist.gov/publications/detail/fips/186/4/final">maintains a list</a> of recommended curves; P-256 is perhaps the most popular among these.&nbsp;</p>
<p>Among others, there is also the <a href="https://safecurves.cr.yp.to/">SafeCurves</a> collection proposed by Dan Bernstein and Tanja Lange. In particular, their Curve25519 has proven to be a popular choice.</p>
<p>Elliptic curve libraries will typically have tailored support for certain curves.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312733</guid>
            <pubDate>Sat, 05 Dec 2020 07:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Tire-pressure monitoring system Sensors: Let's try a DoS attack]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25312714">thread link</a>) | @pabs3
<br/>
December 4, 2020 | http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack | <a href="https://web.archive.org/web/*/http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <td>&nbsp; &nbsp;</td>

  <!-- left column -->
  <td>

<!--
   <p>
   <br />
   <b>About</b> <br />
   Dieter Spaar's blog, Dieter Spaar's personal Blosxom blog.<br /><br />
   Dieter Spaar<br />
   <a href="mailto:spaar@mirider.com">spaar@mirider.com</a> <br />
   </p>
-->

   <p>
   <a href="http://www.mirider.com/weblog/index.rss">RSS</a>
   </p>

   <p>
     <b>Dieter's Web</b> <br>
     <a href="http://www.mirider.com/">mirider.com</a><br>
   </p>

   <p>
   <b>Projects I am participating</b> <br>
    <a href="http://bb.osmocom.org/" target="_blank">OsmocomBB</a><br>
    <a href="http://openbsc.osmocom.org/" target="_blank">OpenBSC</a><br>
    
   </p>

   <p>
   <b>Categories</b> <br>
   </p>
   <ul>
<li><a href="http://www.mirider.com/weblog/index.html">Root</a> (24)
<ul>
<li><a href="http://www.mirider.com/weblog/automotive/index.html">automotive</a> (3)
</li>
<li><a href="http://www.mirider.com/weblog/gsm/index.html">gsm</a> (17)
</li>
<li><a href="http://www.mirider.com/weblog/misc/index.html">misc</a> (1)
</li>
<li><a href="http://www.mirider.com/weblog/sdr/index.html">sdr</a> (2)
</li>
</ul>
</li>
</ul>


   <p>
   <b>Archives</b> <br>
   </p>
   <ul>
	<li><a href="http://www.mirider.com/weblog/2020/">2020</a> (1)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2020/12/index.html">December</a> (1)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2018/">2018</a> (5)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2018/09/index.html">September</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/05/index.html">May</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/03/index.html">March</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/01/index.html">January</a> (2)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2013/">2013</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2012/">2012</a> (4)
	</li>
	<li><a href="http://www.mirider.com/weblog/2011/">2011</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2010/">2010</a> (8)
	</li>
</ul>


<!--
   <p>
   <b>Flavours</b> <br />
   There's more than one way to view this weblog; try these flavours on
   for size.
    <li><a href="http://www.mirider.com/weblog/index.index">index</a></li>
    <li><a href="http://www.mirider.com/weblog/index.1993">circa 1993</a></li>
    <li><a href="http://www.mirider.com/weblog/index.rss">RSS</a></li>
   </p>
-->
   <p>
   <b>Other Bloggers</b> <br>
    <a href="http://laforge.gnumonks.org/weblog/" target="_blank">Harald Welte</a><br>
    <a href="http://openbts.blogspot.com/" target="_blank">David Burgess</a><br>
   </p>

<!--
   <p>
   
   </p>
-->

   <p>
    <br>
    <a href="http://www.blosxom.com/"><img src="http://mirider.com/weblog/pb_blosxom.gif" alt="blosxom"></a>
   </p>

   <p>
    <br>
    <a href="http://www.mirider.com/#Site%20Contact">Contact/Impressum</a>
   </p>

  </td>

  <td>&nbsp; &nbsp;</td>

  <td>&nbsp; &nbsp;</td> 

  <!-- main blog entry column -->
  <td> 

   <br>

<span>Fri, 04 Dec 2020</span>
<div>
<p><a name="20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack"><b>Modern TPMS Sensors: Let's try a DoS attack</b></a></p><p>
TPMS (Tire-pressure monitoring system) sensors have been researched extensively
many years ago, they periodically transmit the tire pressure, temperature
and a unique ID which can be misused for tracking a vehicle. But there is
another aspect: modern TMPS sensors also have a receiver which is typically
used to trigger the data transmission when a new TPMS sensor is presented to
the vehicle ("learning procedure").
</p>

<p>
Here in Europe TPMS sensors usually transmit on the 433 MHz ISM band. The
receiver operates on 125 kHz, very similar to LF RFID. A simple way to make
use of the receiver is just to look for the presence of the 125 kHz carrier
and then trigger data transmission. Current sensors are usually more evolved
and use a modulated carrier which contains command packets and only if the
correct command is received data transmission is triggered.
</p>

<p>
If you already have a receiver you can do of course more than just trigger
data transmission: For example there might be support for different
commands, some sensors even allow firmware updates this way.
</p>

<p>
One such command which is typically supported is switching the sensor into
"Shipping" mode. Why would you need that? When the sensor is operating
normally it waits for motion (there is an acceleration/shock sensor inside)
and only starts periodic data transmission when the wheel is rotating. This
is used to safe battery life. When the TPMS sensor is not yet mounted in the
tire it should not react on motion, that’s why there is this "Shipping" mode.
In this mode the sensor only wakes up every few seconds and looks if there
is a 125 kHz signal, if yes it checks for a valid command, for example the
command to trigger data transmission which usually also leaves "Shipping"
mode and switches the sensor into normal operation.
</p>

<p>
This "Shipping" mode can be misused: If you can switch a TPMS sensor of a
vehicle’s wheel into "Shipping" mode the sensor will no longer transmit data
and the vehicle's tire pressure control light will go on after a while.
Just to make it clear: This warning light is annoying to the driver, it
does not affect safety of the car because the deactivated TMPS sensor has
not affected the actual tire pressure.
</p>

<p>
I have looked at a few TPMS sensors for different cars if this really works,
I choose sensors for BMW and Ford cars. Please note that most certainly
other car manufactures are affected too, mainly because there are only a
few manufactures of TPMS sensors which deliver their sensors to various
car manufactures. My choice for BMW and Ford came from the fact that I
found lots of cheap, used sensor for those cars.
</p>

<p>
Also I only looked at "OEM" sensors for BMW and Ford, which means that those
sensors are mounted by the car manufacturer. There are also so called
"Universal" sensors which are typically mounted by tire dealers, there
are some notes about them at the end of this text.
</p>

<p>
It is quite easy to build a tool for transmitting data on 125 kHz: There
is this cheap EL-50448 TMPS sensor activation tool which only transmits a
carrier without modulation. However the hardware can easily be modified
to modulate the carrier: Most of the time OOK (On-Off Keying) is used
for communication, which means that the carrier is just turned on and off.
The EL-50448 uses a power driver with an unused "enable" pin to generate
the carrier, you can use this "enable" pin to modulate the carrier. The
data rate is slow, a frequently used rate is 3900 baud.  Most of the time
Manchester encoding of the data bits is used, which means that the carrier
changes twice as much (7800 changes per second). This is nothing special
and can be done with probably any microcontroller you prefer to use. The
hardware costs for such a setup are below EUR 20, the transmission range
is about 20 centimeters.
</p>

<p>
How can you find the command to switch to Shipping" mode? Brute force by
trying all possible commands is only an option if the command is short.
The reason is that the sensor only looks for the LF 125 kHz signal every
few seconds. If the command is not longer than two bytes brute force is
possible (it takes a few days), for longer commands it is impractical.
Please note that you also have to find a way to detect if the command you
send causes a reaction of the TPMS sensor, e.g. by monitoring the power
consumption of the sensor or receiving the 433 MHz data signal (which of
course only works if the command you send causes a data transmission).
</p>

<p>
Another option is looking at those TPMS tools which tire dealers and
car repair workshops use to check TPMS sensors. Some of those tools
might support switching a TPMS sensor into "Shipping" mode.
</p>

<p>
Those are the results I found (I won't go into the details to avoid misuse):
</p>

<ul>
<li><b>BMW:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. Also if the sensor detects a
  fast pressure change (e.g. by inflating the tire) the sensor leaves
  "Shipping" mode. The command length is four bytes so brute force is no option. 

</li>

<li><b>Ford:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" (the same manufacture as above for the BMW sensor) can be switched
  into "Shipping" mode, it is the same command as used by the BMW sensor
  from above. The deactivated TPMS sensor can be activated again with a
  different command.
  
  A certain sensor used in several car models from TPMS Sensor manufacturer
  "B" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. The command in this case is
  only two bytes and I tried all combinations which resulted in several more
  "interesting" commands, a few examples:


    <ul>
<li>
      It is possible to completely turn off the TPMS sensor. In this case it
      will no longer react on anything, you have to break open the sensor
      case and apply a hardware reset or disconnect the battery to reactivate
      it again.
</li>

<li>
      It is possible to switch the sensor into continuous "carrier transmit"
      mode on 433 MHz. In this mode the sensor will continuously transmit
      the 433 MHz carrier until the battery is empty or you apply a hardware
      reset (see above), it will not react on anything else. There are two
      other similar commands which transmit on the upper and lower shifted
      frequency (the sensor uses FSK modulation, Frequency Shift Keying, when
      transmitting data).
</li>
</ul>      

  Those examples show that it is basically possible to destroy this specific
  sensor by transmitting the appropriate command. Also if the sensor is in
  "carrier transmit" mode it probably disturbs the remote control car
  key fob which usually uses the same frequency as the TPMS sensor.
</li>
</ul>

<p>
You have to be close to the sensor to send those LF 125 kHz signals but it
only takes a few seconds to send the signal. Using a larger antenna (which is
basically a coil) for the transmitter, e.g. large enough to fit in a suitcase,
might extend the transmission range to more than a meter. 
</p>

<p>
How can those problems be avoided? This is actually quite easy, the command
to switch into "Shipping" mode should not be allowed if the measured tire
pressure is above a certain limit, which means that the sensor is mounted in
the tire of a vehicle. This also applies to those other commands of the sensor
from manufacturer "B" which are probably some kind of factory test or developer
commands. Please note that during my tests the commands I described were
possible even when the measured tire pressure was in the range of a typical
vehicle wheel.
</p>

<p>
I contacted the car manufactures (BMW and Ford) before I published this
article, this is the experience I made:
</p>

<ul>
<li>
  <b>BMW:</b>
  The contact information for reporting security issues can be found on
  the BMW website. I had a phone call with the responsible person within
  a few days after reporting the issue. BMW already knew the problem, they
  found it during an internal review. Their latest TPMS sensors have fixed
  the issue by blocking certain commands if the tire pressure is above a
  certain limit.
</li>

<li>
  <b>Ford:</b>
  I wasn't able to find a security contact on the website of Ford Germany
  so I contacted the person responsible for "Public Relation". He promised
  to look for someone who takes care of the issue I reported, after several
  days I got a reply that it is possible to disturb the TPMS system due to
  the nature of radio transmission and that this is a known problem. I wasn't
  able to communicate directly with the responsible person and I then replied
  that the reported issue is not about disturbance but a "Denial of Service"
  and that it is even possible to destroy a certain TPMS sensor used in Ford
  cars. I didn't receive any further information about the security issue, I
  notified them again after several weeks that I am now going to publish
  the issue which was acknowledged.
</li>
</ul>

<p>
Some notes about those "Universal" sensors tire dealers normally use: Those
sensors are "Universal" because they can be programmed for different car
models. The main benefit for the tire dealer is that only a few different
kind of "Universal" sensors have to be on stock, it’s not necessary to have
lots of different "OEM" TPMS sensors for every possible car model lying
around. The programming of those …</p></div></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</a></em></p>]]>
            </description>
            <link>http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312714</guid>
            <pubDate>Sat, 05 Dec 2020 07:53:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning all IDE shortcuts evolved my developing habits]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312712">thread link</a>) | @tkainrad
<br/>
December 4, 2020 | https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>I spent a few hours spread over the last couple of weeks to learn every single one of VSCode’s keyboard shortcuts, specifically the 149 shortcuts from the <a href="https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf">official keyboard shortcuts reference</a>. These are also present in <a href="https://keycombiner.com/collections/vscode/">KeyCombiner’s searchable table of VSCode shortcuts</a>.</p>
<p>Admittedly, I started this challenge to write a blog post about it afterward and as a way to promote <a href="https://keycombiner.com/">KeyCombiner</a> via content marketing. The blog post I had in mind would be similar to my previous one, <a href="https://tkainrad.dev/posts/how-i-learned-50-new-keyboard-shortcuts-in-42-minutes/">documenting my process of learning 50 new web application shortcuts in 42 minutes</a>.</p>
<p>But, as it usually happens only in romantic comedies, my intentions changed over time. This article turned out much different. It is not about the learning process but about how this challenge changed some of the developing habits I had for many years. Workflows that I grew used to during many projects, different IDEs, and even varying programming languages suddenly evolved.</p>

<p>As software engineers, we like to think that we are continually learning and improving our skills. This is certainly true when it comes to the technologies we are using. However, our development habits, such as which features of our IDEs we use, are much more rigid. I believe most of our core workflows are formed early on and very hard to change.
I don’t have data to back this up, but when I look at myself, my co-workers, and other developers I know, this certainly seems true. If you think about it, it is not surprising, the same thing happens in other areas of life. For this very reason, you will find that developers who have studied or worked together will often use similar shortcuts, similar IDE features, and have similar limitations in their workflows.</p>
<p>The usual way to combat this is reading books, blog posts, attending conferences, well, everything that is used in our industry to extend our knowledge. However, with fundamental developing habits, I have found that this works poorly. You might read about a neat feature of your IDE, or see someone demo their workflow, but when you are eventually sitting in front of your screen and writing code, it is easy to fall back to what we already know, what is already set up, and proven to work.</p>
<p>After this experiment, I am convinced that keyboard shortcuts are the main factor in how we form our developing habits, and they can also stop us from evolving our habits.
Even before this challenge, I felt that I was good with shortcuts. I knew quite a few refactoring shortcuts, knew how to pause and stop program executing during debugging, was decent at jumping around between files, searching through my project, and all the other usual stuff. When I saw a co-worker using a shortcut that I didn’t know, I was quick to incorporate it into my workflow, too. After all, I was enough into shortcuts that I built a whole side-project around learning them.
<strong>The thing is, all new shortcuts that I learned were the ones that would augment my existing habits.</strong></p>
<p>This is a hen and egg problem; if you don’t know the shortcuts, you will not start to change your habits and use new IDE features because without shortcuts, they are too tedious to use or not at all usable. But if you don’t form new habits, you will not learn the shortcuts.</p>
<p><strong>Without intending it, I think I found a way to break out of this cycle:
Learning all IDE shortcuts very well <em>before</em> getting back to work. By learning <em>all</em> shortcuts, you are not limited to what somebody shows you and might not be compatible with your situation. You can naturally include what makes sense, in addition to your existing skills.</strong></p>
<p>The next section shows how this worked for me.</p>

<p>I started the learning process as it is usually done with KeyCombiner: By importing some shortcuts from the <a href="https://keycombiner.com/collections/vscode/">public collection of VSCode shortcuts</a> into a personal collection. Intuitively, I started with the ones I already knew and some additional that seemed most useful to me. Back then I was still trying to show that I could learn all shortcuts very quickly with KeyCombiner. I didn’t expect that shortcuts that had nothing to do with my existing workflows will be the real deal.</p>
<p>Some of the first combinations that I picked and that I did not know previously were <kbd>alt</kbd>+<kbd>w</kbd>/<kbd>r</kbd>/<kbd>c</kbd> for toggling find options (match whole word, regex, case sensitivity) because I was already using those features. This went on for a few days. I did a couple practice runs every day and added new shortcuts whenever KeyCombiner was saying that I mastered all of the previous ones.</p>
<p>Eventually, I knew all shortcuts that seemed useful for how I was using VSCode back then. So I had to start adding shortcuts that had nothing to do with my existing habits. This brought up an interesting misconception. Often keyboard shortcuts are seen as a way to do things faster, compared to using the mouse. While that is true, I think there is an even more aspect to shortcut usage in IDEs: Many features are not used at all, if you don’t know the shortcut!</p>
<p>As I was learning new VSCode shortcuts every day, I started to use features that I previously didn’t even know of. One of the first things that suddenly made a lot of sense was <em>Select all Occurences of Find Match</em> with <kbd>Alt</kbd>+<kbd>Enter</kbd> as default binding, especially when combined with regex search. I was so excited about it, that I even <a href="https://twitter.com/ThomasKainrad/status/1305608337799761920">tweeted a Gif</a> showing how I use it to modify the CSV files that are the source for KeyCombiner’s public collection tables.</p>
<p>The process worked both ways: Sometimes, while I was practicing a shortcut on KeyCombiner, it seemed apparent that this was useful and that I should include it into my workflow. Sometimes it hit me while coding that I had just learned a shortcut that can make the current task more efficient.</p>
<p>In the following, I describe the most significant changes in my daily development habits. The list is far from complete though; there are many more small things that I picked up and frequently use now.</p>
<p><strong>Editor and Panel Management</strong><br>
Since knowing all the shortcuts to switch focus between panels and move editors around, I am using VSCode’s powerful layouting capabilities much more. I have 3-5 editor panels open at pretty much all times, seeing many related pieces of code at once. Working this way by using the mouse is very impractical.
I switch between editor panels with keyboard shortcuts and move editors from one group to the other.</p>
<p>There is one negative side-effect, though: I am starting to get annoyed when I use other IDEs (PyCharm, Eclipse), because they lack far behind VSCode when it comes to using multiple editors.</p>
<p><strong>Multi-cursor Editing</strong><br>
If you don’t know the shortcut to add additional cursors, I doubt you will ever use this incredibly powerful feature of VSCode. It is a typical feature that only blends into your habits once you know the shortcuts.
The basic commands are <kbd>Ctrl</kbd>+<kbd>Alt</kbd>+<kbd>Down</kbd>/<kbd>Up</kbd> for adding cursors above/below. However, I found the commands to <em>Insert cursor at end of each line selected</em> (<kbd>Shift</kbd>+<kbd>Alt</kbd>+<kbd>i</kbd>), and the above-mentioned <em>Select all Occurences of Find Match</em> (<kbd>Alt</kbd>+<kbd>Enter</kbd>) even more powerful. These commands are why I frequently paste text snippets into VSCode, apply a few operations, and then copy-paste it back into whatever application I was using.</p>
<p><strong>Opening views by shortcut</strong><br>
I sometimes tried to do this before, but it never stuck. Now I finally switch to all views (Explorer, Debug, Search, Problems, etc.) with dedicated keyboard shortcuts. These shortcuts translate very nicely to other IDEs. After learning the VSCode default bindings, which are <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>&lt;char&gt;</kbd>, I set the same bindings also for Eclipse and PyCharm. Especially <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>e</kbd> for switching to the explorer view and <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>d</kbd> for switching to the debug view are among my most used shortcuts now.</p>
<p><strong>Making Selections</strong><br>
I hate to admit it, but I did not use shortcuts to expand and shrink AST selections before. AST stands for <em>abstract syntax tree</em>, which means that the IDE will take the current language’s syntax into account for modifying the selection. Finally, I picked up <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>left</kbd>/<kbd>right</kbd> to shrink and expand selections. Not all IDEs handle this in the same way, which can be a bit annoying, but it works well for the most frequent tasks, such as expanding the selection to enclose the current string, method, class, or HTML tag.</p>
<p><strong>Folding</strong><br>
I have started to use folding much more. For years, I have rarely used this feature that all IDEs support to a great extent. Now, I do it frequently. Folding is one of these things that are just not feasible with the mouse. Of course, if you need to fold code, <a href="https://blog.codinghorror.com/the-problem-with-code-folding/">chances are that you need to structure your code better</a>. Many organizations even apply automatic code linters that will complain when methods or classes are too long. However, I have never seen someone recommend splitting up blog posts into multiple files. The same goes for other non-code file types, such as JSON. All we have there is folding.</p>
<p>I am not saying these are the things you should start to learn now, far from it. These are the things I personally integrated deep into my workflows after doing this challenge, without choosing them deliberately, but naturally. Who knows what you will pick up.</p>
<p>Of course, some of the shortcuts I learned still seem a bit, let’s say nonessential, but a little useless knowledge never killed nobody.</p>

<p>In addition to finally breaking out of old habits and experience a real evolution of my IDE usage, there were some additional, less significant, but still delightful second-order effects.</p>
<p>As a shortcut enthusiast, I often had the problem that I needed to decide which binding to use for a particular operation and application pair. KeyCombiner’s public shortcut search helps to find out which binding is the convention for a particular operation, but it can still be tricky. For example, take the frequently used <em>Step Over</em> operation used for debugging. <a href="https://keycombiner.com/collecting/collections/public/search/?description=step+over&amp;keys=&amp;mac_keys=&amp;submit=Search">KeyCombiner shows that VSCode, Eclipse, and JetBrains IDEs all use a different default binding</a>(<kbd>F6</kbd>,<kbd>F8</kbd>,<kbd>F10</kbd>). Learning every single VSCode shortcut has freed me from this mental load of deciding what the best …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/</a></em></p>]]>
            </description>
            <link>https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312712</guid>
            <pubDate>Sat, 05 Dec 2020 07:53:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: One last trip down memory lane with the Raspberry Pi Zero]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312560">thread link</a>) | @alexellisuk
<br/>
December 4, 2020 | https://blog.alexellis.io/memory-lane-raspberry-pi-zero/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/memory-lane-raspberry-pi-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>The <a href="https://www.raspberrypi.org/products/raspberry-pi-zero/?resellerType=home">Raspberry Pi Zero</a> and original Raspberry Pi both have a 32-bit ARM architecture which many projects have dropped support for. So when I saw that <a href="https://github.com/containerd/containerd/pull/4530">containerd recently merged a fix</a> for building containerd on armv6, started to think what I could do with it.</p>
<p>Earlier that month, a user of the <a href="http://github.com/openfaas/faasd">faasd project</a> which runs very well on VPSes, RPi 3 and RPi4 asked me whether it could work on the Zero and I told him it was not practical or worth his time. After all, an RPi4 with 2GB of RAM, 4 Cores and much faster I/O is only 25GBP/EUR/USD.</p>
<blockquote>
<p><a href="https://github.com/openfaas/faasd">faasd is OpenFaaS</a>, but for a single node, and designed for those who don't want to pay for and manage an entire Kubernetes cluster, GitOps, service-mesh, and IngressController just to deploy a few simple functions.</p>
</blockquote>
<p>My past experiences told me that it would be a challenge to get the zero working. It has such a paltry amount of memory available and its I/O is really slow. Still, sometimes it's fun to do things that we shouldn't. Had I been <a href="https://xkcd.com/356/">"nerd sniped"</a>?</p>
<p><img src="https://www.raspberrypi.org/homepage-9df4b/static/1dfa03d09c1f3e446e8d936dfb92267f/8924f/6b0defdbbf40792b64159ab8169d97162c380b2c_raspberry-pi-zero-1-1755x1080.jpg" width="60%">
&gt; The RPi Zero originally released in 2015.
</p><p>In this post I'll show you what you need to do to deploy functions through the <a href="https://github.com/openfaas/faas-cli">OpenFaaS CLI</a> and be able to invoke them, including multi-arch builds. At the end of the post I'll explain what the limitations are and whether we should leave the Raspberry Pi Zero with those fond memories we have of it when it was <a href="https://en.wikipedia.org/wiki/Raspberry_Pi">released in 2015</a>, 5 years ago.</p>
<h2 id="walkthrough">Walk-through</h2>
<h3 id="prereqs">Pre-reqs</h3>
<p>You will need:</p>
<ul>
<li>Raspberry Pi Zero</li>
<li>Ethernet adapter and USB &lt;&gt; USB A micro shim</li>
<li>16-32GB class 10 SD card</li>
<li>MicroUSB power adapter</li>
</ul>
<p>Flash the latest version of Raspberry Pi OS Lite to your SD card, and then create an <code>ssh</code> file in the <code>/boot/</code> folder.</p>
<p>Power up the Raspberry Pi and ssh to it with <code>ssh pi@raspberrypi.local</code>.</p>
<h3 id="installgo">Install go</h3>
<p>You can install Go from a package manager, but the version is likely to be rather old. Fortunately the Go team still ship a binary for armv6:</p>
<pre><code>export ARCH="armv6l"
echo "Downloading Go"

curl -SLsf https://dl.google.com/go/go1.13.15.linux-$ARCH.tar.gz --output /tmp/go.tgz
sudo rm -rf /usr/local/go/
sudo mkdir -p /usr/local/go/
sudo tar -xvf /tmp/go.tgz -C /usr/local/go/ --strip-components=1

export GOPATH=$HOME/go/
export PATH=$PATH:/usr/local/go/bin/
</code></pre>
<p>You now have Go installed, run <code>go version</code> to see it working.</p>
<h3 id="buildcontainerd">Build containerd</h3>
<p>faasd uses containerd rather than Docker, but there are no official binaries for any of the ARM CPUs, so we have to build them from source.</p>
<p>For armv7 and ARM64, you can use my repo <a href="https://github.com/alexellis/containerd-arm">alexellis/containerd-arm</a>. It's my hope to see ARM support upstreamed, but having spoken on several occasions to the containerd team, it seems very unlikely that we will see this happen.</p>
<p>On my first attempt of building I got the following error:</p>
<pre><code>+ bin/containerd
# github.com/containerd/containerd/cmd/containerd
/usr/local/go/pkg/tool/linux_arm/link: running gcc failed: fork/exec /usr/bin/gcc: cannot allocate memory
make: *** [Makefile:188: bin/containerd] Error 2
</code></pre>
<p>The RPi Zero and the largest RPi 1 only has 512MB of RAM and I slowly watched the RAM being eaten up with <code>watch -n "free -h"</code>.. I should have remembered this.</p>
<p>Fortunately I had the battle scars and knew what I had to do:</p>
<pre><code>sudo dd if=/dev/zero of=/swapfile bs=1024 count=1M &amp;&amp;\
  sudo mkswap /swapfile &amp;&amp; \
  sudo swapon /swapfile
</code></pre>
<p>This creates 1GB of swap, on the SD card.. which already has terrible I/O, but it may just work.</p>
<p>The other trick you may have seen me talk about is adding <code>gpu_mem=16</code> to <code>/boot/config.txt</code>. It seems pointless changing the split on an 8GB RPi4, but for our RPi Zero, we need every MB we can get.</p>
<p>Second time lucky?</p>
<p>No. It failed again due to some missing libraries. I reminded myself to read <a href="https://github.com/containerd/containerd/blob/master/BUILDING.md#build-containerd">BUILDING.md</a> from the containerd repo. After adding libseccomp and a few other packages, it started to move along again.</p>
<pre><code>make
+ bin/ctr
+ bin/containerd
+ bin/containerd-stress
+ bin/containerd-shim
+ bin/containerd-shim-runc-v1
+ bin/containerd-shim-runc-v2
+ binaries
</code></pre>
<p>I don't know if it was 10 minutes or over an hour, but it was slow progress.</p>
<p>I then ran <code>sudo make install</code> and copied the systemd unit file into place with:</p>
<pre><code>sudo cp containerd.service /etc/systemd/system/containerd.service
sudo systemctl enable containerd
</code></pre>
<p>I didn't want to start containerd at this time, to save on memory for the next task.</p>
<h3 id="buildfaasd">Build faasd</h3>
<p>The faasd Makefile needed a patch because it was set to cross-compile to armv7, but we needed armv6.</p>
<pre><code>.PHONY: dist
dist:
	CGO_ENABLED=0 GOOS=linux GOARCH=arm GOARM=6 go build -mod=vendor -ldflags $(LDFLAGS) -a -installsuffix cgo -o bin/faasd-armhf
</code></pre>
<p>This took so long to build on the zero that I gave up and built it on my Intel NUC. Fortunately Go is very good as cross-compiling, especially when linking into C/C++ libraries is disabled with <code>CGO_ENABLED=0</code>.</p>
<p>I then ran <code>scp</code> to copy the binary to the Raspberry Pi.</p>
<pre><code>sudo cp faasd-armhf /usr/local/bin/faasd
cd go/src/github.com/openfaas/faasd
</code></pre>
<p>The final step was to install faasd which creates two systemd unit files:</p>
<ul>
<li>faasd - for the OpenFaaS core services</li>
<li>faasd-provider - for the provider that supports CRUD and Invoke operations</li>
</ul>
<pre><code>sudo faasd install
</code></pre>
<p><img src="https://blog.alexellis.io/content/images/2020/12/faasd-install.jpg" alt="faasd-install"></p>
<h3 id="unexpectedissues">Unexpected issues</h3>
<p>I tried to log in with <code>faas-cli login</code>, but it didn't work. I saw a number of errors in the logs <code>sudo systemctl journalctl -u faasd</code>:</p>
<pre><code>Dec 03 23:18:49 zero-dns default:basic-auth-plugin[13218]: standard_init_linux.go:207: exec user process caused "exec format error"
Dec 03 23:18:50 zero-dns containerd[12169]: time="2020-12-03T23:18:50.338589900Z" level=info msg="starting signal loop" namespace=default path=/run/containerd/io.containerd.runtime.v2.task/default/gateway pid=13324
Dec 03 23:18:52 zero-dns default:gateway[13335]: standard_init_linux.go:207: exec user process caused "exec format error"
</code></pre>
<p>It turned out that out of nats, prometheus, and the openfaas gateway, the openfaas basic-auth plugin only nats was available for armv6. It seems that projects really have moved on and left armv6 behind.</p>
<h3 id="thenihadanidea">Then I had an idea</h3>
<p>What if we didn't run the whole OpenFaaS stack at all, but just the <code>faasd-provider</code>? It would allow this tiny device to support all the CRUD operations on functions, and invocations, but nothing more.</p>
<p>The provider seemed to be running well, and responding to <code>faas-cli</code> commands:</p>
<p><img src="https://blog.alexellis.io/content/images/2020/12/provider.png" alt="provider"></p>
<p>We'd lose the queue and async invocations, lose the UI, lose the metrics, but we could still deploy functions and invoke them.</p>
<p>It was already very late by this point so I decided to sleep on it.</p>
<h3 id="inthemorning">In the morning</h3>
<p>I powered up the RPi zero and tried deploying a container directly to the faasd endpoint, and it worked.</p>
<p><img src="https://blog.alexellis.io/content/images/2020/12/deploy.jpg" alt="deploy"></p>
<p>Now, I had to make a few changes. Rather than building with the OpenFaaS watchdog in the container, I just used a Dockerfile and a plain Go HTTP server.</p>
<p>Here's what I ended up with:</p>
<p>Dockerfile</p>
<pre><code>FROM --platform=${BUILDPLATFORM:-linux/amd64} golang:1.13-alpine3.11 as build
ARG TARGETPLATFORM
ARG BUILDPLATFORM
ARG TARGETOS
ARG TARGETARCH
RUN apk --no-cache add git

ENV CGO_ENABLED=0

RUN mkdir -p /go/src/handler
WORKDIR /go/src/handler
COPY . .

# Run a gofmt and exclude all vendored code.
RUN test -z "$(gofmt -l $(find . -type f -name '*.go' -not -path "./vendor/*" -not -path "./function/vendor/*"))" || { echo "Run \"gofmt -s -w\" on your Golang code"; exit 1; }

ARG GO111MODULE="off"
ARG GOPROXY=""

RUN CGO_ENABLED=${CGO_ENABLED} GOOS=${TARGETOS} GOARCH=${TARGETARCH} \
    go build --ldflags "-s -w" -a -installsuffix cgo -o handler .
RUN GOOS=${TARGETOS} GOARCH=${TARGETARCH} go test ./... -cover

FROM --platform=${TARGETPLATFORM:-linux/amd64} alpine:3.12
# Add non root user and certs
RUN apk --no-cache add ca-certificates \
    &amp;&amp; addgroup -S app &amp;&amp; adduser -S -g app app \
    &amp;&amp; mkdir -p /home/app \
    &amp;&amp; chown app /home/app

WORKDIR /home/app

COPY --from=build /go/src/handler/handler    .

RUN chown -R app /home/app

USER app

CMD ["./handler"]
</code></pre>
<p>handler.go</p>
<pre><code>package main

import (
	"fmt"
	"net/http"
)

func main() {
	s := &amp;http.Server{
		Addr:           fmt.Sprintf(":%d", 8080),
		MaxHeaderBytes: 1 &lt;&lt; 20, // Max header of 1MB
	}

	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		w.Write([]byte("Hello world"))
	})

	panic(s.ListenAndServe())
}
</code></pre>
<p>stack.yml</p>
<pre><code>version: 1.0
provider:
  name: openfaas
  gateway: http://127.0.0.1:8080
functions:
  http:
    lang: dockerfile
    handler: ./http
    image: alexellis2/http:0.1.4
    build_args:
      GO111MODULE: on
</code></pre>
<p>I ran this on my PC with the following:</p>
<pre><code>export OPENFAAS_URL=http://192.168.0.81:8081
faas-cli publish --platform linux/arm/v6

faas-cli deploy
</code></pre>
<p>Using the PC means we can cross-compile the Go HTTP server and push a multi-arch image to the container registry. The new <code>faas-cli publish</code> command comes in handy for this and can accept a list of architectures.</p>
<p>The <code>deploy</code> command talks to the remote machine over REST and tells it to deploy a function. The server-side handler <a href="https://github.com/openfaas/faasd/blob/master/pkg/provider/handlers/deploy.go">deploy.go</a> pulls the image into containerd and starts executing it as a container.</p>
<h3 id="onemorething">One more thing</h3>
<p>When I say that it worked. I should clarify that I'd forgotten to deploy CNI - the networking layer required for faasd and containerd.</p>
<p>I saw this error by running the following:</p>
<pre><code>sudo journalctl -u faasd
</code></pre>
<p>Not that long ago, <a href="https://github.com/openfaas/faasd/blob/master/docs/DEV.md">I'd documented all the steps required for a manual installation</a>, but somehow forgot this was needed.</p>
<pre><code>export ARCH=arm
export CNI_VERSION=v0.8.5

sudo mkdir -p /opt/cni/bin
curl -sSL https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz | sudo tar -xz -C /opt/cni/bin

# Make a config folder for CNI definitions
sudo mkdir -p /etc/cni/net.d

# Make an initial loopback configuration
sudo sh -c 'cat &gt;/etc/cni/net.d/99-loopback.conf &lt;&lt;-EOF
{
    "cniVersion": "0.3.1",
    "type": "loopback"
}
EOF'
</code></pre>
<p>Just changing "ARCH" to "arm" was enough to make it work. So the CNI project are still <a href="https://github.com/containernetworking/plugins/blob/master/.travis.yml">building the plugins against armv6</a> for the time being.</p>
<h3 id="finalattempt">Final attempt</h3>
<p>Then it was a case of simply running <code>faas-cli deploy</code> again, and finally, it actually worked.</p>
<p>An initial benchmark with <code>hey</code> identified that the …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/memory-lane-raspberry-pi-zero/">https://blog.alexellis.io/memory-lane-raspberry-pi-zero/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/memory-lane-raspberry-pi-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312560</guid>
            <pubDate>Sat, 05 Dec 2020 07:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Module Federation with Webpack 5]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312517">thread link</a>) | @selbekk
<br/>
December 4, 2020 | https://react.christmas/2020/5 | <a href="https://web.archive.org/web/*/https://react.christmas/2020/5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>In this article, we will look at one of webpack's exciting new features, Module Federation. This feature will allow dynamic code reloading from another project at runtime. Using module federation will enable sharing code from other projects with only a little tweaking in your webpack config. It can make a website consisting of multiple frontend applications appear as one seamless SPA. Neat, huh?</p>
</section><article><section><blockquote>
<p><a href="https://webpack.js.org/concepts/">webpack</a> is a module bundler. Its main purpose is to bundle JavaScript files for usage in a browser, yet it is also capable of transforming, bundling, or packaging just about any resource or asset.</p>
</blockquote>
<p>In webpack 5, a new exciting feature was released. <strong>Module Federation</strong>, a webpack plugin enabling dynamic code loading from multiple webpack builds at runtime. It supports dependency sharing, i.e.:</p>
<p><em>Application A, importing code from application B, will attempt to use its own dependencies before downloading payloads from B. Nevertheless, A will download the dependencies from B if they are missing from A.</em></p>
<p>This way of sharing code between webpack applications opens up a sea of possibilities. For instance, you may use react components from other projects while receiving updates, both during build and runtime. Moreover, if your website consists of many applications, you can have a dedicated app to load and route between all projects. Another use case is to incorporate a design system at runtime. Since you are fetching the components from a different origin at runtime, you can get the latest version from your design system without rebuilding and deploying.</p>

<p>I am more of a learning by doing kind of gal, so let us have a look at an example to see how it is done. We will create a Christmas calendar using module federation. For illustrative purposes, we will be using two separate npm projects:</p>
<ul>
<li><code>calendar-container</code>: Contains the calendar component.</li>
<li><code>calendar-card</code>: Contains the calendar card component.</li>
</ul>
<p>We will use module federation to import components from <code>calendar-card</code>into the <code>calendar-container</code> during runtime.</p>
<p>The wonderful thing about module federation is that we can easily outsource the development of various card components to fellow programmers, and reap the fruits of their efforts later on.</p>
<p>The complete example can be found <a href="https://github.com/hegehaav/christmas-calendar">here</a>!</p>
<p><img src="https://react.christmas/assets/ex_white.svg" alt="Figure of example architecture"></p>
<h3>App 1: The Container</h3>
<p>Let's start by creating our first application, <code>calendar-container</code>. <code>calendar-container</code> will be a simple react application containing a title and a container that, later on, will render the calendar cards. The application will run on <code>localhost:3001</code>.</p>
<div data-language="javascript"><pre><code>

<span>import</span> React <span>from</span> <span>'react'</span><span>;</span>

<span>const</span> <span>App</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>	
	<span>return</span> <span>(</span>
		<span>&lt;</span>main<span>&gt;</span>
			<span>&lt;</span>h1<span>&gt;</span>Christmas Calendar<span>&lt;</span><span>/</span>h1<span>&gt;</span>
			<span>&lt;</span>p<span>&gt;</span> Here we will put content <span>from</span> calendar<span>-</span>card <span>&lt;</span><span>/</span>p<span>&gt;</span>		 
		<span>&lt;</span><span>/</span>main<span>&gt;</span>
	<span>)</span><span>;</span>
<span>}</span><span>;</span>

<span>export</span> <span>default</span> App<span>;</span></code></pre></div>
<h3>App 2: Calendar Window</h3>
<p>Next, we will create the <code>CalendarCard</code>-component in an application we call <code>calendar-card</code>. Initially, you will only see the day of the month the window is hiding. If you click the card, it will tell you how many days there are until Christmas. This application will run on <code>localhost:3002</code>.</p>
<div data-language="javascript"><pre><code>

<span>import</span>  React<span>,</span> <span>{</span> useState <span>}</span> <span>from</span>  <span>'react'</span><span>;</span>

<span>const</span>  <span>CalendarCard</span> <span>=</span> <span>(</span><span><span>{</span> dayOfDecember <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
	<span>const</span> <span>[</span>isClicked<span>,</span> setIsClicked<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>false</span><span>)</span><span>;</span>
	<span>const</span>  daysUntilChristmas <span>=</span> <span>24</span> <span>-</span> dayOfDecember<span>;</span>
	
	<span>return</span> <span>(</span>
		<span>&lt;</span>div  onClick<span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span>  <span>setIsClicked</span><span>(</span><span>!</span>isClicked<span>)</span><span>}</span><span>&gt;</span>	
			<span>{</span>isClicked <span>?</span> <span>(</span>
				<span>&lt;</span>p<span>&gt;</span><span>{</span>daysUntilChristmas<span>}</span> days until Christmas 🎅<span>&lt;</span><span>/</span>p<span>&gt;</span>
			<span>)</span> <span>:</span> <span>(</span>
				<span>&lt;</span>p<span>&gt;</span><span>{</span>dayOfDecember<span>}</span><span>&lt;</span><span>/</span>p<span>&gt;</span>
			<span>)</span><span>}</span>
		<span>&lt;</span><span>/</span>div<span>&gt;</span>
	<span>)</span><span>;</span>
<span>}</span><span>;</span>
<span>export</span>  <span>default</span>  CalendarCard<span>;</span></code></pre></div>
<h3>Module federation</h3>
<p>Now that we have created the calendar container and the calendar card in separate applications, we are ready to set up the module federation to share code between the applications. This is done in each app's webpack.config.js utilizing webpack's ModuleFederation-plugin.</p>
<p>We need to expose the <code>CalendarCard</code>-component that we want to import into the <code>calendar-container</code>-application. This is done in <code>calendar-card</code>'s <code>webpack.config.js</code>. We need to add the ModuleFederationPlugin to the list of plugins. In the config, we need to give the app a filename, letting the module federation know to emit a remote entry. Then we must expose the component we want to use, in our case, the <code>CalendarCard</code>-component. Finally, we will add <code>react</code> and <code>react-dom</code> to the list of shared dependencies. That way, <code>calendar-container</code> will use its own <code>react</code> and <code>react-dom</code> dependencies if available. If one of the dependencies is not available, module federation will provide a fallback dependency from <code>calendar-card</code> anyway.</p>
<div data-language="javascript"><pre><code>

<span>const</span>  HtmlWebpackPlugin  <span>=</span>  <span>require</span><span>(</span><span>'html-webpack-plugin'</span><span>)</span><span>;</span>
<span>const</span>  ModuleFederationPlugin  <span>=</span>  <span>require</span><span>(</span><span>"webpack/lib/container/ModuleFederationPlugin"</span><span>)</span><span>;</span>

module<span>.</span>exports <span>=</span> <span>{</span>
	
	plugins<span>:</span> <span>[</span>
		<span>new</span>  <span>HtmlWebpackPlugin</span><span>(</span><span>{</span> template<span>:</span> <span>"./public/index.html"</span> <span>}</span><span>)</span><span>,</span>
		<span>new</span>  <span>ModuleFederationPlugin</span><span>(</span><span>{</span>
			name<span>:</span> <span>"calendar_card"</span><span>,</span>
			filename<span>:</span> <span>"remoteEntry.js"</span><span>,</span>
			exposes<span>:</span> <span>{</span>
				<span>"./CalendarCard"</span><span>:</span> <span>"./src/CalendarCard"</span> 
			<span>}</span><span>,</span>
			shared<span>:</span> <span>[</span> <span>"react"</span><span>,</span> <span>"react-dom"</span> <span>]</span>
		<span>}</span><span>)</span>
	<span>]</span>	
<span>}</span></code></pre></div>
<p>Now that the <code>CalendarCard</code> is exposed, we need to tell <code>calendar-container</code> where to find it. This is done in <code>calendar-container</code>'s <code>webpack.config.js</code>. The set up is similar to <code>calendar-card</code>, but we let webpack know that it is expecting a remote module called <code>calendar_card</code>. This is done in the <code>remotes</code>-field. Here, we also specify the location of the remote entry, which is  <code>http://localhos:3002/remoteEntry.js</code>.  As no other project is importing code from <code>calendar-container</code> - yet - there is no need to expose anything in this application. We need to list the shared dependencies in <code>calendar-container</code>  as well, to let <code>calendar-card</code> know it will not need to provide them as fallback dependencies.</p>
<div data-language="javascript"><pre><code>

<span>const</span>  HtmlWebpackPlugin  <span>=</span>  <span>require</span><span>(</span><span>'html-webpack-plugin'</span><span>)</span><span>;</span>
<span>const</span>  ModuleFederationPlugin  <span>=</span>  <span>require</span><span>(</span><span>"webpack/lib/container/ModuleFederationPlugin"</span><span>)</span><span>;</span>

module<span>.</span>exports <span>=</span> <span>{</span>
	
	plugins<span>:</span> <span>[</span>
		<span>new</span>  <span>HtmlWebpackPlugin</span><span>(</span><span>{</span> template<span>:</span> <span>"./public/index.html"</span> <span>}</span><span>)</span><span>,</span>
		<span>new</span>  <span>ModuleFederationPlugin</span><span>(</span><span>{</span>
			name<span>:</span> <span>"calendar_container"</span><span>,</span>
			filename<span>:</span> <span>"remoteEntry.js"</span><span>,</span>
			remotes<span>:</span> <span>{</span> calendar_card<span>:</span> <span>"calendar_card@http://localhost:3002/remoteEntry.js"</span> <span>}</span><span>,</span>
			shared<span>:</span> <span>[</span> <span>"react"</span><span>,</span> <span>"react-dom"</span> <span>]</span>
		<span>}</span><span>)</span>
	<span>]</span>	
<span>}</span></code></pre></div>
<h3>Putting it all together</h3>
<p>We need an async way to load the application, this can be done by moving all the code from <code>index.js</code> into a new file <code>bootstrap.js</code>. We do this in both applications:</p>
<div data-language="javascript"><pre><code>

<span>import</span> React <span>from</span> <span>'react'</span><span>;</span>
<span>import</span> ReactDOM <span>from</span> <span>'react-dom'</span><span>;</span>
<span>import</span> App <span>from</span> <span>'./App'</span><span>;</span> 

ReactDOM<span>.</span><span>render</span><span>(</span><span>&lt;</span>App <span>/</span><span>&gt;</span><span>,</span> document<span>.</span><span>getElementById</span><span>(</span><span>'calendar-container'</span><span>)</span><span>)</span><span>;</span></code></pre></div>
<p>Then we dynamically import the content in <code>index.js</code>:</p>

<p>Now we are ready to import the CalendarCard-component from <code>calendar-card</code>:</p>
<div data-language="javascript"><pre><code>

<span>import</span> React <span>from</span> <span>'react'</span><span>;</span>

<span>const</span> CalendarCard <span>=</span> React<span>.</span><span>lazy</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span>  <span>import</span><span>(</span><span>'calendar_card/CalendarCard'</span><span>)</span><span>)</span><span>;</span>

<span>const</span> <span>App</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
	<span>const</span>  calendarCards <span>=</span> Array<span>.</span><span>from</span><span>(</span><span>Array</span><span>(</span><span>24</span><span>)</span><span>.</span><span>keys</span><span>(</span><span>)</span><span>)</span><span>;</span>
	<span>return</span> <span>(</span>
		<span>&lt;</span>main<span>&gt;</span>
			<span>&lt;</span>h1<span>&gt;</span>This is the calendar<span>-</span>container app<span>&lt;</span><span>/</span>h1<span>&gt;</span>
			<span>&lt;</span>div<span>&gt;</span>
				<span>{</span>calendarCards<span>.</span><span>map</span><span>(</span><span>(</span><span>day</span><span>)</span> <span>=&gt;</span> <span>(</span>
					<span>&lt;</span>React<span>.</span>Suspense
						fallback<span>=</span><span>{</span><span>&lt;</span>p<span>&gt;</span>Loading content <span>from</span> calendar<span>-</span>card<span>...</span><span>&lt;</span><span>/</span>p<span>&gt;</span><span>}</span>
						key<span>=</span><span>{</span>day<span>}</span>
					<span>&gt;</span>
						<span>&lt;</span>CalendarCard  dayOfDecember<span>=</span><span>{</span>day <span>+</span> <span>1</span><span>}</span>  <span>/</span><span>&gt;</span>
					<span>&lt;</span><span>/</span>React<span>.</span>Suspense<span>&gt;</span>
				<span>)</span><span>)</span><span>}</span>
			<span>&lt;</span><span>/</span>div<span>&gt;</span>
		<span>&lt;</span><span>/</span>main<span>&gt;</span>
	<span>)</span><span>;</span>
<span>}</span><span>;</span>
<span>export</span> <span>default</span> App<span>;</span></code></pre></div>
<p>And voilà! We have a Christmas calendar that imports code from a separate application at runtime!</p>
<p>In this article, we took a quick look at webpack 5's Module Federation feature, enabling runtime code sharing between applications. This is an exciting new feature that can assist in building micro-frontends and cross-platform code sharing.</p>
<p>We made a simple Christmas calendar showcasing some Module Federation based features. There are still other features to explore. The next step could be to share code in both directions, or perhaps create several applications and add routing between them in a container app.</p></section></article></div>]]>
            </description>
            <link>https://react.christmas/2020/5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312517</guid>
            <pubDate>Sat, 05 Dec 2020 07:10:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's the difference between using `let` and `var` in JavaScript?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312407">thread link</a>) | @jimmyk99
<br/>
December 4, 2020 | https://qirolab.com/questions/whats-the-difference-between-using-let-and-var-in-javascript | <a href="https://web.archive.org/web/*/https://qirolab.com/questions/whats-the-difference-between-using-let-and-var-in-javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text" v-pre=""><p>Here are few differences between using <code>let</code> and <code>var</code>:</p>
<h3>1. Redeclaration:</h3>
<p>In strict mode, <code>var</code> will let you re-declare the same variable in the same scope while <code>let</code> throws a <code>SyntaxError</code>.</p>
<pre><code>'use strict';
var foo = "foo1";
var foo = "foo2"; // No problem, 'foo' is replaced.

let bar = "bar1";
let bar = "bar2"; // SyntaxError: Identifier 'bar' has already been declared
</code></pre>
<h3>2. Creating global object property:</h3>
<p><code>let</code>, in contrast to <code>var</code>, doesn't make a property on the global object:</p>
<pre><code>var foo = "Foo";  // globally scoped
let bar = "Bar"; // globally scoped

console.log(window.foo); // Foo
console.log(window.bar); // undefined
</code></pre>
<h3>3. Scoping rules:</h3>
<p>The most important difference is the scoping rules. Variables declared by <code>var</code> keyword are scoped to the immediate function body while <code>let</code> variables are scoped to the immediate enclosing block meant by <code>{ }</code>.</p>
<pre><code>function run() {
  var foo = "Foo";
  let bar = "Bar";

  console.log(foo, bar); // Foo Bar

  {
    let baz = "Bazz";
    console.log(baz); // Bazz
  }

  console.log(baz); // ReferenceError
}

run();
</code></pre>
<p>The motivation behind why let keyword was introduced with the language was function scope is confusing and was one of the main sources of bugs in JavaScript.</p>
<pre><code>var funcs = [];
// let's create 3 functions
for (var i = 0; i &lt; 3; i++) {
  // and store them in funcs
  funcs[i] = function() {
    // each should log its value.
    console.log("Value: " + i);
  };
}
for (var j = 0; j &lt; 3; j++) {
  // and now let's run each one to see
  funcs[j]();
}
</code></pre>
<p><code>Value: 3</code> was output to console each time <code>funcs[j]();</code> was used since anonymous functions were bound to the same variable.</p>
<p>Developers needed to make immediately invoked functions to catch correct value from the loops yet that was also hairy.</p>
<h3>4. Hoisting:</h3>
<p>While variables declared with <code>var</code> keyword are hoisted (initialized with undefined before the code is run) which implies they are accessible in their enclosing scope even before they are declared:</p>
<pre><code>function run() {
  console.log(foo); // undefined
  var foo = "Foo";
  console.log(foo); // Foo
}

run();
</code></pre>
<p><code>let</code> variables are not initialized until their definition is evaluated. Accessing them before the initialization brings about a <code>ReferenceError</code>. Variable said to be in "temporal dead zone" from the beginning of the block until the initialization is handled.</p>
<pre><code>function checkHoisting() {
  console.log(foo); // ReferenceError
  let foo = "Foo";
  console.log(foo); // Foo
}

checkHoisting();
</code></pre>
</div></div>]]>
            </description>
            <link>https://qirolab.com/questions/whats-the-difference-between-using-let-and-var-in-javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312407</guid>
            <pubDate>Sat, 05 Dec 2020 06:47:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Manpages Like a Pro (2018)]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25311867">thread link</a>) | @woodruffw
<br/>
December 4, 2020 | https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Jan 22, 2018</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#workflow">workflow</a>
    
  
  </p>


<h3 id="preword">Preword</h3>

<p>I often reference the <a href="https://en.wikipedia.org/wiki/Man_page">manpages</a> when giving a development
presentation or talk, but I’ve only recently come to realize how few people are both <em>comfortable</em>
with the <code>man</code> interface and adept at discovering information through it.</p>

<p>This post is my attempt to share some of the tricks and techniques I’ve picked up over years of
reading manpages.</p>

<h2 id="a-quick-recap">A Quick Recap</h2>

<p>The manpages (short for “manual pages”) are the oldest and longest-running documentation collection
on *nix, stemming back to the
<a href="https://www.bell-labs.com/usr/dmr/www/1stEdman.html">first edition of the Unix Programmer’s Manual</a>
in 1971.</p>

<p>On a modern system, the <code>man</code> command is the most common way to access the manpages:</p>

<div><div><pre><code><span># access the first manpage named "time", which happens to be time(1)</span>
man <span>time</span>

<span># access a specific section's "time", in this case the C time function</span>
man 2 <span>time</span>

<span># attempt to access a nonexistent "time" in section 5</span>
man 5 <span>time</span>
</code></pre></div></div>

<p>Because the manpages were originally published on paper, they were (and continue to be) typeset with
<a href="https://en.wikipedia.org/wiki/Troff"><code>troff</code></a> on most systems. Today, the <code>man</code> command (and other
manpage readers) invoke <code>troff</code> internally and pipe the output to the user’s
<a href="https://en.wikipedia.org/wiki/Terminal_pager">pager</a> (like <code>more</code> or <code>less</code>).</p>

<p>In fact, a very simple manpage reader (which only works with section 1) can be implemented with
just three commands pipelined together:</p>

<div><div><pre><code><span>function </span>myman <span>{</span>
    <span># `-t` and `-e`: run `tbl` and `eqn` on the input, for tables and equations</span>
    <span># `-mandoc`: use a set of troff macros specifically for manpages</span>
    <span># `-Tutf8`: output UTF-8 text rather than PostScript</span>
    <span>gunzip</span> &lt; /usr/share/man/man1/<span>"</span><span>${</span><span>1</span><span>}</span><span>.1.gz"</span> | groff <span>-t</span> <span>-e</span> <span>-mandoc</span> <span>-Tutf8</span> | less
<span>}</span>

myman gcc
myman <span>ls</span>
</code></pre></div></div>

<p>Apart from their simplicity and adherence to the UNIX philosophy, <code>man</code> and the manpages serve a
number of important roles:</p>

<ul>
  <li>
    <p>They provide a categorization: section 1 is for system commands, 2 for system calls, 3 for library
functions, and so forth. This categorization is followed both by the system itself (which populates
several of the sections) and by programs installed by the user or package manager.</p>
  </li>
  <li>
    <p>They provide offline documentation: <code>man</code> doesn’t require an internet connection, and can provide
much of the documentation that an internet search would yield.</p>
  </li>
  <li>
    <p>They offer <em>canonical</em> information: searching for a command or function online might tell you
whether it exists, but won’t tell you the flags, arguments, or behavior specific to your system.
For example, <code>man ls</code> will tell you whether your system’s <code>ls</code> is BSD or GNU (and the differences
therebetween). The manpages (on Linux) will also tell you which feature macros you’ll need to define
in a C program in order to use a function (or a variant of a function).</p>
  </li>
</ul>

<p>So, let’s move on to some techniques.</p>

<h2 id="colorized-manpages">Colorized manpages</h2>

<p>One of the simplest things you can do to enhance the readability of manpages within <code>man</code> is to
colorize the pager’s output:</p>

<p><img src="https://blog.yossarian.net/assets/gcc_man.png" alt="A colorized version of `man gcc`"></p>

<p>In <code>less</code>, this is accomplished by setting the <code>LESS_TERMCAP_*</code> environment variables to your
preferred ANSI color codes. Here are the variables you can set:</p>

<div><div><pre><code>LESS_TERMCAP_mb <span># blinking mode (not common in manpages)</span>
LESS_TERMCAP_md <span># double-bright mode (used for boldface)</span>
LESS_TERMCAP_me <span># exit/reset all modes</span>
LESS_TERMCAP_so <span># enter standout mode (used by the less statusbar and search results)</span>
LESS_TERMCAP_se <span># exit standout mode</span>
LESS_TERMCAP_us <span># enter underline mode (used for underlined text)</span>
LESS_TERMCAP_ue <span># exit underline mode</span>
</code></pre></div></div>

<p>You may be able to set others corresponding to the
<a href="https://www.gnu.org/software/termutils/manual/termcap-1.3/html_chapter/termcap_5.html">termcap capability names</a>,
but the variables above should cover all of your manpage needs.</p>

<p>By way of example, here is the <code>bash</code> function I use to colorize my manpages:</p>

<div><div><pre><code>man<span>()</span> <span>{</span>
    <span>env</span> <span>\</span>
    <span>LESS_TERMCAP_mb</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_md</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_me</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_se</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_so</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;44;33m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_ue</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_us</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;32m"</span><span>)</span><span>"</span> <span>\</span>
    man <span>"</span><span>${</span><span>@</span><span>}</span><span>"</span>
<span>}</span>
</code></pre></div></div>

<p>Note that you don’t need to use escape sequences as above — <code>tput</code> will work just fine.</p>

<h2 id="other-sections">Other sections</h2>

<p>I mentioned some of the big sections above: 1 for system commands, 2 for system calls, and so on.</p>

<p>90% of <code>man</code> lookups will be in those three, but there are a few lesser-known sections that can also
be useful:</p>

<ul>
  <li>
    <p><code>man 4</code> - Special files and devices</p>

    <p>On Linux, section 4 is used to document special files, usually representing some aspect of
  the machine or its peripherals. For example, <code>man 4 mem</code> will tell you how to use the
  <code>/dev/mem</code>, <code>/dev/kmem</code>, and <code>/dev/port</code> files to read from and write to the system’s main
  memory.</p>
  </li>
  <li>
    <p><code>man 5</code> - Configuration files and formats</p>

    <p>You probably know the <code>/etc/shadow</code> file, but do you know how its format is specified?
  <code>man 5 shadow</code> will tell you that. Similarly, <code>man 5 deb</code> describes the <code>.deb</code> package format,
  and <code>man 5 ppm</code> lists the spec for <a href="https://en.wikipedia.org/wiki/Netpbm_format">PPM images</a>.</p>
  </li>
  <li>
    <p><code>man Np</code> - POSIX pages</p>

    <p>These pages come in handy for contrasting POSIX behavior with the system’s behavior.</p>

    <p>Some examples:</p>

    <div><div><pre><code>  <span># compare the system ls (on Linux, GNU) to the POSIX ls behavior</span>
  man 1 <span>ls
  </span>man 1p <span>ls</span>

  <span># compare the read syscall to the POSIX read function</span>
  <span># note the categorization: POSIX read is a function, not a syscall!</span>
  man 2 <span>read
  </span>man 3p <span>read</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="searching-and-navigating">Searching and navigating</h2>

<p>Like colorization, searching is more of a general <code>less</code> feature than one specific to <code>man</code>. That
being said, <code>less</code>’s searching and navigating features can make browsing the manpages a much faster
and more pleasant experience.</p>

<p>Searches in <code>less</code> can be forwards or backwards, using the <code>/</code> and <code>?</code> commands respectively. The
search syntax is mostly POSIX ERE, but with some additions (<code>man less</code> has the details!).</p>

<p>For example, to find the first instance of “x86” in <code>man gcc</code> (watch the bottom of the screen for
the search prompt):</p>

<p><a href="https://asciinema.org/a/Wc0OiKVTrTDiP4tG9bPRWtDwM" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wc0OiKVTrTDiP4tG9bPRWtDwM.png">
</a></p>

<p>Observe that instances of the search term are highlighted with the standout colors from before.</p>

<p>Once a search term is entered, its results can be navigated via the <code>n</code> and <code>N</code> commands, which
move forwards and backwards in the results list respectively. For example, going through all
of the results for “Windows”:</p>

<p><a href="https://asciinema.org/a/n3S3wteHmbdPrtmyTSkCSVMiX" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_n3S3wteHmbdPrtmyTSkCSVMiX.png">
</a></p>

<p>When the last result has been jumped to, the statusbar changes to “Pattern not found”. Once that
happens, as in the video above, previous results can be returned to by hitting <code>N</code>.</p>

<p>Even this can be simplified: the <code>&amp;</code> command can be used to display only lines that match the given
pattern. For example, retrieving every line that contains either “ARM” or “ABI”:</p>

<p><a href="https://asciinema.org/a/Wh8QZ4eideLNmCMBmAkYExgEm" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wh8QZ4eideLNmCMBmAkYExgEm.png">
</a></p>

<p>The effect is more dramatic when searching for the definition of a flag (in this case <code>-D</code>):</p>

<p><a href="https://asciinema.org/a/17Kcnb8PBNIz8JdogOFKVeDQn" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_17Kcnb8PBNIz8JdogOFKVeDQn.png">
</a></p>

<p>These commands are just the tip of the iceberg — <code>less</code> supports searching multiple files at
once, jumping around scopes (opening and closing parentheses, braces, brackets), and marking the
current location for later return. Each of these is documented on the help screen, which you can
get to in any <code>less</code> session via the <code>h</code> command:</p>

<p><a href="https://asciinema.org/a/8i6kyFTbFttVTgDNbgnzyJvGB" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_8i6kyFTbFttVTgDNbgnzyJvGB.png">
</a></p>

<h2 id="wrapup">Wrapup</h2>

<p>Before picking up these tricks (especially searching), the manpages were an item of last resort
for me: I would search the internet or ask a friend, with mixed results. I had no real idea how to
use <code>less</code>, and would just clumsily page around until I found what I was looking for. More often
than not, I would give up entirely.</p>

<p>At the end of the day, the manpages (and the <code>man</code> interface) are not perfect — there’s no
hyperlinking or real cross-referencing, and the entire corpus is written in a 45+ year old
typesetting language designed for <em>physical</em> output, not display in a virtual terminal.</p>

<p>That being said, they’re a <em>fantastic</em> initial resource for pretty much anything concerning your
system — they remain up-to-date (unlike blogs and articles), they’re accurate and concise, and
they’re <em>very</em> UNIX-y (text files and pipelines!).</p>

<hr>

<h3 id="addendum">Addendum</h3>

<p>This post was discussed on <a href="https://news.ycombinator.com/item?id=25311867">HN</a>; a response
by <a href="https://news.ycombinator.com/item?id=25313405">‘djeiasbsbo</a> includes some additionally
useful tricks and advice.</p>


<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311867</guid>
            <pubDate>Sat, 05 Dec 2020 04:53:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Installing GalliumOS on an Old Chromebook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25311553">thread link</a>) | @ewpratten
<br/>
December 4, 2020 | https://retrylife.ca/blog/2020/12/04/galliumos | <a href="https://web.archive.org/web/*/https://retrylife.ca/blog/2020/12/04/galliumos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <!-- Main content -->
                    <p>My previous development laptop was an <a href="https://www.acer.com/ac/en/CA/content/series/acerchromebookr11">Acer R11</a> chromebook. I always ran it in <a href="https://chromium.googlesource.com/chromiumos/docs/+/master/developer_mode.md">developer mode</a> with all the Linux packages I needed installed via <a href="https://github.com/skycocker/chromebrew">chromebrew</a>. This setup worked great except for GUI programs, as (at the time), the built-in <a href="https://en.wikipedia.org/wiki/Wayland_(display_server_protocol)">Wayland</a> server on the chromebook was not exposed to the user in a meaningful way. I relied on an internal tool from Google called <a href="https://chromium.googlesource.com/chromiumos/platform2/+/HEAD/vm_tools/sommelier/">sommelier</a> to translate X11 calls to the internal Wayland server. None of this was ideal, but with a lot of scripts and aliases, I made it work.</p>

<p>Recently, I decided to remove the locked-down ChromeOS all together, and set the laptop up with <a href="https://galliumos.org/">GalliumOS</a> so it can be used as a lightweight code-review machine with access to some useful tools like <a href="https://code.visualstudio.com/">VSCode</a> and <a href="https://www.gitkraken.com/">GitKraken</a>. This whole process is actually fairly easy, and a good way to breathe new life in to an old chromebook. This guide will be R11-specific, but the process doesn’t vary too wildly between models.</p>

<h2 id="developer-mode">Developer mode</h2>

<p>A standard feature on chromebooks is “developer mode”. This is a hidden boot mode that is designed to give <a href="https://www.chromium.org/chromium-os">ChromiumOS</a> contributors and Google developers access to debug tools when testing new OS builds. Along with debug tools, this mode also exposes a Linux terminal with root access to the user via <kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>-&gt;</kbd>. On an extremely locked down system like a chromebook, this terminal access exposes a lot of new capability. For this use case, we will only use it to modify the system bootloader.</p>

<p>To enable developer mode, simply press <kbd>Esc</kbd> + <kbd>Refresh</kbd> + <kbd>Power</kbd>, and let the chromebook reboot. Once the recovery screen pops up, press <kbd>Ctrl</kbd> + <kbd>D</kbd>, and the device is now in developer mode.</p>

<h2 id="write-protection">Write protection</h2>

<p>This step will void your device’s warranty. Chromebooks are able to handle anything you throw at them. Even if you were to delete important system files to the point the device can no longer boot, hopping in to recovery mode can reset the device to a working state. This works via ChromeOS’s write protect mechanism. All important files are protected by hardware-enforced write protection. Since the process of loading a new operating system onto the device involves overwriting important system files (like the BIOS), we must physically disable write protection.</p>

<p>Luckily, on the Acer R11, this process is very simple. Firstly, unscrew the laptop’s bottom plate to expose the motherboard (some screws are hidden under rubber feet). With the backplate off, you will find a screw that looks like this:</p>

<p><img src="https://retrylife.ca/assets/images/arcer_r11_screw.jpg" alt="R11 write protect screw"></p>

<p>The screw is hard to miss, it is beside the WIFI card, an has an arrow pointing to it. Simply remove it, and put the laptop back together. You now have a fully unlocked device.</p>

<h2 id="flashing-a-custom-bootloader">Flashing a custom bootloader</h2>

<p><a href="https://mrchromebox.tech/">Mr Chromebox</a>, a well known person in the world of Chromebook modification, provides and maintains a very easy to use shell script that handles bootloader modifications automatically. To use this tool, open up the ChromeOS terminal (<kbd>Ctrl</kbd> + <kbd>Alt</kbd> + <kbd>-&gt;</kbd>), log in with the username <code>chronos</code> (you must already be logged in to your personal Google account. This will not work from the login screen), and run:</p>

<div><div><pre><code>crossystem <span>dev_boot_usb</span><span>=</span>1 <span>dev_boot_legacy</span><span>=</span>1
<span>cd</span><span>;</span> curl <span>-LO</span> mrchromebox.tech/firmware-util.sh
<span>sudo install</span> <span>-Dt</span> /usr/local/bin <span>-m</span> 755 firmware-util.sh
<span>sudo </span>firmware-util.sh
</code></pre></div></div>

<p>This will open up the <code>firmware-util</code> settings screen.</p>

<p><img src="https://retrylife.ca/assets/images/fwutil_cros_wp-on.png" alt="firmware-util screen"></p>

<p>You will want to select the <code>RW_LEGACY</code> option to load the <code>RW_LEGACY</code> / SEABIOS payload. The <code>UEFI</code> option is technically the better choice, but it will completely remove the device’s ability to run ChromeOS again in the future.</p>

<h3 id="setting-fuses">Setting fuses</h3>

<p>The <code>RW_LEGACY</code> payload only works if the laptop always has power. Once the device completely runs out of power, the boot settings are wiped from the device (not something we want). The solution is to modify the <a href="https://chromium.googlesource.com/chromiumos/platform/vboot/+/master/_vboot_reference/firmware/include/gbb_header.h">system <code>gbb</code> fuses</a>. This sounds complicated (and it is), but Mr Chromebox comes to the rescue again with the <code>GBB Flags</code> option in his script. <em>After</em> the <code>RW_LEGACY</code> payload has been configured, run his script again, and select <code>GBB Flags</code>.</p>

<h2 id="installing-galliumos">Installing GalliumOS</h2>

<p>On another computer, <a href="https://galliumos.org/download">download GalliumOS</a> (make sure to select the <code>Braswell</code> option), and <a href="https://wiki.galliumos.org/Installing/Creating_Bootable_USB">create a bootable USB</a>. Plug this USB into the Chromebook, reboot, and press <kbd>Ctrl</kbd> + <kbd>L</kbd> as the warning screen pops up. This will begin the GalliumOS setup process (which is identical to that of Ubuntu).</p>

<h3 id="enabling-verbose-boot">Enabling verbose boot</h3>

<p>It is nice to know what is happening when the device is booting. To disable the boot animation and replace it with the boot log, edit <code>/etc/default/grub</code>, and replace both the <code>quiet</code> and <code>splash</code> arguments with <code>noplymouth</code> in the <code>GRUB_CMDLINE_LINUX_DEFAULT</code> options. Next, run the following, then reboot:</p>



<!--
https://imgur.com/a/GuyYz

https://medium.com/@simstems/how-i-got-the-acer-chromebook-r11-cb5-132t-to-run-parrot-security-os-without-crouton-d282a110060a

https://wiki.galliumos.org/Hardware_Compatibility

https://chromium.googlesource.com/chromiumos/platform/vboot/+/master/_vboot_reference/firmware/include/gbb_header.h
-->


                    
                    <br>
                    <hr>
                    <div>

                        <!-- Thank you text -->
                        <p>Thank you for reading this post. If you enjoyed the content, and want to let me know, or
                            want
                            to
                            ask any questions, please contact me via one of the methods <a href="https://retrylife.ca/about">listed
                                here</a>. If
                            you would like to be notified about future posts, feel free to load <a href="https://retrylife.ca/feed.xml">my
                                rss
                                feed</a> into your favorite feed reader, or <a href="https://twitter.com/ewpratten">follow
                                me on Twitter</a> for notifications about my work and future posts.</p>

                        <!-- Other posts to check out -->
                        <p>If you have the time to read some more, I recommend checking out one of the following posts:
                        </p>
                        <div>
                            
                            
                            
                            
                            
                            <div>
                                <p>
                                    <h5>Connecting to a Minecraft server over IRC</h5>
                                    <h6>This post outlines the process of writing a custom IRC server that can bridge between your favorite IRC client, and any Minecraft server</h6>
                                </p>
                                
                            </div>
                            
                            
                            
                            
                            <div>
                                <p>
                                    <h5>My first mechanical keyboard: The Vortex Core</h5>
                                    <h6>I recently purchased my first mechanical keyboard, and decided to go "all in" with a 40% layout.</h6>
                                </p>
                                
                            </div>
                            
                            
                            
                            
                            <div>
                                <p>
                                    <h5>Using Bazel to create Minecraft modpacks</h5>
                                    <h6>I decided to modernize my system for producing builds of my personal Minecraft modpack using the Bazel buildsystem.</h6>
                                </p>
                                
                            </div>
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                        </div>

                    </div>
                    
                </div></div>]]>
            </description>
            <link>https://retrylife.ca/blog/2020/12/04/galliumos</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311553</guid>
            <pubDate>Sat, 05 Dec 2020 03:49:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Poker Hands Geometrically]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25311545">thread link</a>) | @chairmanwow1
<br/>
December 4, 2020 | https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands | <a href="https://web.archive.org/web/*/https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-labelledby="title-0">
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  
<p>An interesting way for getting an intuitive sense for why <a href="https://en.wikipedia.org/wiki/Poker_probability" title="Poker hand probabilities">certain hands</a> are rare in poker, I've laid out all the cards in a standard deck in a grid:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/blank_1024x1024.png?v=1607133617" alt="Array of Playing Cards" width="1024x1024" height="1024x1024">
</p>


<p>When I first learned to play poker, it took a while before I could get an intuitive understanding of the relationships between the various poker hands. Calculating their likelihood definitely helped get a handle on how many ways for a specific hand to actually occur there were.</p>

<p>Nonetheless, I think laying the hands out in a grid like this would have given me an intuitive understanding of the game much more quickly.&nbsp;</p>
<h2>Poker Hands shown geometrically</h2>
<p>So the lowest poker hand, high card, is the most common happening 50% of the time, but will rarely be the winning hand:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/High_Card_1024x1024.png?v=1607134813" alt="High Card" width="1023" height="1023"></p>

<p>The next highest hand is a single pair which has a geometric interpretation of one column with two dots in it:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Pair_1024x1024.png?v=1607134853" alt="Pair" width="1024x1024" height="1024x1024"></p>

<p>Two pair has a similar flair to it, except this one has 2 vertical lines:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Two_Pair_1024x1024.png?v=1607134962" width="1024x1024" height="1024x1024"></p>

<p>Three of a kind is similar in spirit, but is much rarer than the two preceding hands happening once every 50 hands:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/three_of_a_kind_1024x1024.png?v=1607135086" alt="3 of a kind" width="1024x1024" height="1024x1024"></p>

<p>For a straight, we need 5 cards that are in order without any gaps and can look kind of like a nice scatter plot:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_1024x1024.png?v=1607135179" alt="Straight" width="1024x1024" height="1024x1024"></p>

<p>A flush requires all 5 cards in the hand to be in a single horizontal row, but there can gaps between them:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/flush_84512f1f-428d-4ed7-b703-9372fc3575d6_1024x1024.png?v=1607135233" alt="Flush" width="1024x1024" height="1024x1024"></p>

<p>A full house requires that all points be split into two lines of 3 and 2 points each:</p>

<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/full_house_1024x1024.png?v=1607135454" alt="Full House" width="1024x1024" height="1024x1024"></p>

<p>Four of a Kind requires a vertical line that spans the entire grid with an extra point tucked away somewhere:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/4_of_a_kind_1024x1024.png?v=1607135655" alt="4 of a kind" width="1024x1024" height="1024x1024"></p>

<p>A straight flush is one of the tidiest hands as it requires all cards to be colinear on the same row and be immediately adjacent to each other:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_flush_1024x1024.png?v=1607135809" alt="Straight Flush" width="1024x1024" height="1024x1024"></p>

<p>The best hand that you can get is a subset of all the straight flushes that you can get. It's just a straight flush all the way against the right side of the grid with the 5 highest cards:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Royal_Flush_1024x1024.png?v=1607135877" alt="Royal Flush" width="1024x1024" height="1024x1024"></p>


<p>Looking at poker this way made me realize that there are some interesting hands that we could add to the game.&nbsp;</p>
<h2>Rectangle</h2>
<p>This hand is formed when you have 4 points that are <a href="https://mathworld.wolfram.com/Collinear.html" title="Mathematical Definition of colinearity">colinear</a> in both orthogonal axes (form a rectangle):&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Rectangle_1024x1024.png?v=1607136065" alt="Rectangle Hand" width="1024x1024" height="1024x1024"></p>

<h2>Flower</h2>
<p>This one seems like it would be complicated to spot in the wild, but in reality it's a lot like a full house. You need a Three of a Kind and the other two cards need to be the same suit as one of your 3oK cards, and just before and after it. So, maybe it is a little complicated to spot, but it certainly is an interesting idea.&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Screen_Shot_2020-12-04_at_18.42.56_1024x1024.png?v=1607136337" alt="Flower Hand" width="1024x1024" height="1024x1024"></p>

<h2>Want More?</h2>
<p>If you found this interesting, you'll probably love the 3D reconstruction we did of <a href="https://evermontbills.com/pages/walter-white-did-not-have-80m" title="Walter White's Cash Pile Counting">Walter White's cash pile</a> in order to count it.&nbsp;</p>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311545</guid>
            <pubDate>Sat, 05 Dec 2020 03:48:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring 101: Hierarchy of Analytical Needs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25311524">thread link</a>) | @mooreds
<br/>
December 4, 2020 | http://tmai.avinashkaushik.com/web-version?lc=f6c1fee0-bfd9-11ea-a3d0-06b4694bee2a&p=85a3b25d-35f9-11eb-a3d0-06b4694bee2a&pt=campaign&t=1607074557&s=59518f14bc577006a5c2899e074ca082b3d9193d1e2fc6a8ef973ef630669daf | <a href="https://web.archive.org/web/*/http://tmai.avinashkaushik.com/web-version?lc=f6c1fee0-bfd9-11ea-a3d0-06b4694bee2a&p=85a3b25d-35f9-11eb-a3d0-06b4694bee2a&pt=campaign&t=1607074557&s=59518f14bc577006a5c2899e074ca082b3d9193d1e2fc6a8ef973ef630669daf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://tmai.avinashkaushik.com/web-version?lc=f6c1fee0-bfd9-11ea-a3d0-06b4694bee2a&amp;p=85a3b25d-35f9-11eb-a3d0-06b4694bee2a&amp;pt=campaign&amp;t=1607074557&amp;s=59518f14bc577006a5c2899e074ca082b3d9193d1e2fc6a8ef973ef630669daf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311524</guid>
            <pubDate>Sat, 05 Dec 2020 03:43:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Subscription Creep]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25311353">thread link</a>) | @calicruisin
<br/>
December 4, 2020 | https://www.thriftythoughts.io/subscription-creep/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/subscription-creep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h3 id="given-that-thrifty-thoughts-operates-under-a-subscription-model-this-was-probably-inadvisable-">Given that thrifty thoughts operates under a subscription model this was probably inadvisable.</h3><p>Every year more and more subscription based services come into our lives. Given the ease of sign-up as well as the sheer quantity of must-have subscriptions, how much are we actually spending when it's all added up?</p><figure><img src="https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--10-.png" alt="recurring costs for subscription based services can add up over time" srcset="https://www.thriftythoughts.io/content/images/size/w600/2020/12/UNCLAIMED-PROPERTY--10-.png 600w, https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--10-.png 800w" sizes="(min-width: 720px) 720px"></figure>
                            <section>
                                <h2>Enjoying these posts? Subscribe for more</h2>
                                
                                <br>
                                
                            </section>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.thriftythoughts.io/subscription-creep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311353</guid>
            <pubDate>Sat, 05 Dec 2020 03:13:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to gRPC – Part 2]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25311149">thread link</a>) | @bswamina
<br/>
December 4, 2020 | https://www.polarsparc.com/xhtml/gRPC-2.html | <a href="https://web.archive.org/web/*/https://www.polarsparc.com/xhtml/gRPC-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <br>
    
    <br>
    
    
    <hr>
    
    <p>Overview</p>
    <div id="para-div">
      <p>In <a href="https://www.polarsparc.com/xhtml/gRPC-1.html" target="_blank"><span>Part 1</span></a> of
        this series, we provided a high-level overview of <span>gRPC</span>, installed the necessary software, setup the
        environment, and finally demonstrated the <span>Unary</span> RPC communication in both Go and Java.</p>
      <p>In this part, we will continue the journey to the next RPC communication pattern - <span>Server Streaming</span>.</p>
    </div>
    <p>Server Streaming RPC</p>
    <p>The following diagram illustrates the high-level architecture of <span>Server Streaming</span> communication
        pattern:</p>
    <div id="img-outer-div"> <p><img src="https://www.polarsparc.com/xhtml/images/grpc-06.png" alt="Server Streaming Architecture"></p><p>Figure-6</p>
    </div>
    
    <p>In the Server Streaming RPC mode, the client sends a request to the server and the server responds with sequence (or stream)
        of messages back to the client.</p>
    <p>For the Server Streaming RPC demonstration, we will implement a fictitious Currency Rate service, where the client sends the
        'from' currency and the 'to' currency as the request and the server responds with a stream of 'rates' from different 'agents'.</p>
    <div id="para-div">
      <p>We will first demonstrate the Currency Rate service using the Go programming language.</p>
      <p>In the <span>$GOPATH</span> directory, create the project directory hierarchy by executing the following
        commands:</p>
    </div>
    <div id="cmd-div">
      <p>$ cd $GOPATH/src/polarsparc.com/grpc</p>
      <p>$ mkdir -p serverstream serverstream/currencypb serverstream/server serverstream/client</p>
    </div>
    <p>The following are the contents of the file <span>currency.proto</span> located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/serverstream/currencypb</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>currency.proto</legend>
      <pre>/*
    @Author: Bhaskar S
    @Blog:   https://www.polarsparc.com
    @Date:   04 Dec 2020
*/

syntax = "proto3";

package serverstream;

option go_package = "polarsparc.com/grpc/serverstream/currencypb";

option java_multiple_files = true;
option java_package = "com.polarsparc.gss";

message CurrencyRateRequest {
  string from = 1;
  string to = 2;
}

message CurrencyRateResponse {
  string agent = 1;
  string from = 2;
  string to = 3;
  double rate = 4;
}

service CurrencyService {
  rpc getCurrencyRate(CurrencyRateRequest) returns (stream CurrencyRateResponse) {};
}</pre>
    </fieldset>
    <p>The request message is defined as <span>CurrencyRateRequest</span> and the response message is defined as
        <span>CurrencyRateResponse</span>. The service interface is defined as <span>CurrencyService</span>
        with an RPC method <span>getCurrencyRate</span> that takes in a <span>CurrencyRateRequest</span>
        as an input and returns a sequence (or <span>stream</span>) of <span>CurrencyRateResponse</span>
        objects.</p>
    <p>To compile the <span>currency.proto</span> file, execute the following commands:</p>
    <div id="cmd-div">
      <p>$ cd $GOPATH/src/polarsparc.com/grpc/serverstream</p>
      <p>$ protoc currencypb/currency.proto --go_out=plugins=grpc:$GOPATH/src</p>
    </div>
    <p>On success, this will generate the Go code file called <span>currency.pb.go</span> located in the directory
        <span>$GOPATH/src/polarsparc.com/grpc/serverstream/currencypb</span>.</p>
    <p>From the file <span>currency.pb.go</span>, we see the <span>CurrencyServiceServer</span> interface,
        as shown below, that the server needs to implements:</p>
    <fieldset id="sc-fieldset">
      <legend>currency.pb.go</legend>
      <pre>.
.
.
type CurrencyServiceServer interface {
	GetCurrencyRate(*CurrencyRateRequest, CurrencyService_GetCurrencyRateServer) error
}
.
.
.</pre>
    </fieldset>
    <p>The following are the contents of the file <span>currency_provider.go</span> that simulates an in-memory
        store for initializing and returning currency rates from fictitious agents and is located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/serverstream/server</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>currency_provider.go</legend>
      <pre>/*
  @Author: Bhaskar S
  @Blog:   https://www.polarsparc.com
  @Date:   04 Dec 2020
*/

package main

import (
  "fmt"
  "github.com/pkg/errors"
  "log"
  "strings"
)

type CurrencyRate struct {
  Agent string
  Rate float64
}

type RatesCache map[string][]CurrencyRate

type server struct {
  cache RatesCache
}

func (s *server) Init() {
  l1 := []CurrencyRate{{Agent: "Alice", Rate: 1.30}, {Agent: "Bob", Rate: 1.302},{Agent: "Dave", Rate: 1.31}}
  s.cache["USD:CAD"] = l1
  l2 := []CurrencyRate{{Agent: "Alice", Rate: 0.85}, {Agent: "Charlie", Rate: 0.84}}
  s.cache["USD:EUR"] = l2
  l3 := []CurrencyRate{{Agent: "Bob", Rate: 0.75}, {Agent: "Charlie", Rate: 0.751},{Agent: "Eve", Rate: 0.74}}
  s.cache["USD:GBP"] = l3
}

func (s *server) GetAgentRates(from string, to string) ([]CurrencyRate, error) {
  key := strings.ToUpper(from + ":" + to)

  log.Printf("Currency rate request for key: %s\n", key)

  rates := s.cache[key]
  if rates == nil {
    return nil, errors.New(fmt.Sprintf("No rate for currency from: %s, to: %s", from, to))
  }

  log.Printf("Currency rates for key: %s = %v", key, rates)

  return rates, nil
}</pre>
    </fieldset>
    <p>The following are the contents of the file <span>server.go</span> for the Server Streaming RPC server that
        implements the <span>CurrencyServiceServer</span> interface and is located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/serverstream/server</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>server.go</legend>
      <pre>/*
  @Author: Bhaskar S
  @Blog:   https://www.polarsparc.com
  @Date:   04 Dec 2020
*/

package main

import (
  "google.golang.org/grpc"
  "log"
  "net"
  "polarsparc.com/grpc/serverstream/currencypb" // [1]
  "time"
)

func (s *server) GetCurrencyRate(req *currencypb.CurrencyRateRequest,
  stream currencypb.CurrencyService_GetCurrencyRateServer) error { // [2]
  log.Printf("Received a CurrencyRate request with req: %v\n", req)

  from := req.From
  to := req.To

  rates, err := s.GetAgentRates(from, to)
  if err == nil {
    log.Printf("Rates from agents: %v\n", rates)
    for _, r := range rates {
      res := ¤cypb.CurrencyRateResponse{Agent: r.Agent, From: from, To: to, Rate: r.Rate}
      stream.Send(res) // [3]
      time.Sleep(250 * time.Millisecond)
    }
    return nil
  }

  return err
}

func main()  {
  cs := &amp;server{
    cache: RatesCache{},
  }
  cs.Init() // [4]

  log.Println("Ready to start the CurrencyRate server...")

  lis, err := net.Listen("tcp", "localhost:20002")
  if err != nil {
    log.Fatalf("Failed to create listener on localhost:20002")
  }

  srv := grpc.NewServer() // [5]

  currencypb.RegisterCurrencyServiceServer(srv, cs) // [6]

  if err = srv.Serve(lis); err != nil {
    log.Fatalf("Failed to start server: %v", err)
  }
}</pre>
    </fieldset>
    <div id="para-div">
      <p>The following are brief descriptions for some of the Go type(s)/method(s) used in the code above:</p>
      <ul id="blue-ol">
        <li>
          <p><span>[1]</span> :: import the code from the package <span>polarsparc.com/grpc/serverstream/currencypb
            </span> generated by the <span>protoc</span> compiler</p>
        </li>
        <li>
          <p><span>[2]</span> :: associate the service method <span>GetCurrencyRate</span> as receiver method
            of the custom type <span>server</span>. This method takes two input arguments - a <span>
              CurrencyRateRequest</span> object and a stream object called <span>CurrencyService_GetCurrencyRateServer
            </span></p>
        </li>
        <li>
          <p><span>[3]</span> :: send a sequence (or stream) of <span>CurrencyRateResponse</span> objects (one
            for each of the agents) back to the client that made the request</p>
        </li>
        <li>
          <p><span>[4]</span> :: initialize the in-memory currency rates store (with some fictitious entries)</p>
        </li>
        <li>
          <p><span>[5]</span> :: create an instance of the <span>gRPC</span> server</p>
        </li>
        <li>
          <p><span>[6]</span> :: register an instance of the <span>server</span> object (that implements
            the service method <span>GetCurrencyRate</span>) with the <span>gRPC</span> server</p>
        </li>
      </ul>
    </div>
    <p>The following are the contents of the file <span>client.go</span> that implements the Server Streaming RPC
        client for the <span>CurrencyServiceServer</span> located in the directory <span>
        $GOPATH/src/polarsparc.com/grpc/serverstream/client</span> as shown below:</p>
    <fieldset id="sc-fieldset">
      <legend>client.go</legend>
      <pre>/*
  @Author: Bhaskar S
  @Blog:   https://www.polarsparc.com
  @Date:   04 Dec 2020
*/

package main

import (
  "golang.org/x/net/context"
  "google.golang.org/grpc"
  "io"
  "log"
  "polarsparc.com/grpc/serverstream/currencypb"
)

func main() {
  log.Println("Ready to start the CurrencyRate client...")

  conn, err := grpc.Dial("localhost:20002", grpc.WithInsecure())
  if err != nil {
    log.Fatalf("Failed to connect to localhost:20002")
  }
  defer conn.Close()

  cl := currencypb.NewCurrencyServiceClient(conn) // [1]

  // Success
  req := ¤cypb.CurrencyRateRequest{From: "usd",
    To: "eur"} // [2]
  stream, err := cl.GetCurrencyRate(context.Background(), req) // [3]
  if err != nil {
    log.Fatalf("[1] Failed to send CurrencyRate request to localhost:20002")
  }
  for {
    res, err := stream.Recv() // [4]
    if err == io.EOF {
      break
    }
    if err != nil {
      log.Fatalf("[1] Received and error from CurrencyRate at localhost:20002: %v", err)
    }
    log.Printf("[1] ===&gt; Agent: %s, Rate: %.03f\n", res.Agent, res.Rate)
  }

  // Error
  req2 := ¤cypb.CurrencyRateRequest{From: "usd",
    To: "jpy"}
  stream2, err := cl.GetCurrencyRate(context.Background(), req2)
  if err != nil {
    log.Fatalf("[2] Failed to send CurrencyRate request to localhost:20002")
  }
  for {
    res, err := stream2.Recv()
    if err == io.EOF {
      break
    }
    if err != nil {
      log.Fatalf("[2] Received and error from CurrencyRate at localhost:20002: %v", err)
    }
    log.Printf("[2] ===&gt; Agent: %s, Rate: %.03f\n", res.Agent, res.Rate)
  }
}</pre>
    </fieldset>
    <div id="para-div">
      <p>The following are brief descriptions for some of the Go type(s)/method(s) used in the code above:</p>
      <ul id="blue-ol">
        <li>
          <p><span>[1]</span> :: create an instance of the <span>gRPC</span> client stub
            <span>NewCurrencyServiceClient</span> generated by the <span>protoc</span> compiler</p>
        </li>
        <li>
          <p><span>[2]</span> :: create an instance of the request object <span>CurrencyRateRequest</span></p>
        </li>
        <li>
          <p><span>[3]</span> :: invoke the <span>gRPC</span> method <span>GetCurrencyRate</span>
            using the client stub. The method invocation returns a stream object</p>
        </li>
        <li>
          <p><span>[4]</span> :: invoke the <span>Recv()</span> method on the stream object until the
            end of the stream (return code of <span>io.EOF</span>)</p>
        </li>
      </ul>
    </div>
    <p>Open two <span>Terminal</span> windows - one for the server and one for the client.</p>
    <p>In the server Terminal, execute the following commands:</p>
    <div id="cmd-div">
      <p>$ cd $GOPATH/src/polarsparc.com/grpc/serverstream/server</p>
      <p>$ go run server.go currency_provider.go</p>
 …</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.polarsparc.com/xhtml/gRPC-2.html">https://www.polarsparc.com/xhtml/gRPC-2.html</a></em></p>]]>
            </description>
            <link>https://www.polarsparc.com/xhtml/gRPC-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311149</guid>
            <pubDate>Sat, 05 Dec 2020 02:36:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Esperanto Technologies to Reveal Chip with 1000 Cores at RISC-V Summit]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310931">thread link</a>) | @FullyFunctional
<br/>
December 4, 2020 | https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/ | <a href="https://web.archive.org/web/*/https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
				
			<header>
				
				
			</header>
							
				
		
				
				
			
			

						<main id="main">
				<div>

<section id="content">
	
					<article id="post-2771">
										<span>Esperanto Technologies to Reveal Chip with 1000+ Cores at RISC-V Summit</span>
			
				
						<div>
				<div><div><div><div><div><span><img width="504" height="168" title="riscv summit" src="https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit.jpg" srcset="https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit-200x67.jpg 200w, https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit-400x133.jpg 400w, https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit.jpg 504w" sizes="(max-width: 1024px) 100vw, 504px"></span></div><div><h3><strong>Esperanto Technologies to Reveal Chip with 1000+ Cores </strong><strong>at RISC-V Summit</strong></h3>
<p><em>Art Swift, CEO of Esperanto Technologies, will present chip that accelerates Machine Learning based on RISC-V ISA</em></p>
<p><strong>MOUNTAIN VIEW, Calif., Dec. 1, 2020</strong> – <a href="https://www.esperanto.ai/">Esperanto Technologies</a>™, developer of high-performance, energy-efficient computing solutions based on RISC-V for Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL) applications, will participate in the <a href="https://tmt.knect365.com/risc-v-summit/">RISC-V Summit</a>, December 8-10, 2020. <a href="https://tmt.knect365.com/risc-v-summit/speakers/art-swift/">Art Swift, CEO of Esperanto</a>, will deliver the presentation: <a href="https://tmt.knect365.com/risc-v-summit/speakers/art-swift/#hardware-coressocs_esperanto-accelerates-machine-learning-with-risc-v">Esperanto Accelerates Machine Learning with 1000+ Low-Power RISC-V Cores on a Single Chip</a> on Tuesday, December 8.</p>
<ul>
<li><strong>What</strong>: <a href="https://tmt.knect365.com/risc-v-summit/">RISC-V Summit.</a></li>
<li><strong>Where</strong>: Virtual event, online.</li>
<li><strong>When</strong>: December 8, 2020.</li>
<li><strong>Agenda</strong>: <a href="https://tmt.knect365.com/risc-v-summit/agenda/1/">View the agenda here</a>.</li>
<li><strong>Register here</strong>: <a href="https://riscv.informatech.com/2020/registrations/Attendee">https://riscv.informatech.com/2020/registrations/Attendee</a></li>
</ul>
<p><strong>Presentation: </strong><strong>Esperanto Accelerates Machine Learning With 1000+ Low-Power RISC-V Cores on a Single Chip</strong></p>
<ul>
<li>Esperanto Technologies has developed a ground-breaking accelerator chip for large-scale machine learning applications employing over 1000 RISC-V cores.</li>
<li>In this talk, Esperanto provides an overview of the company’s new ET-SoC-1 chip, which features two kinds of general-purpose 64-bit RISC-V cores. The ET-Maxion, previewed at the RISC-V Summit in 2018, is a superscalar out-of-order core delivering high performance for modern operating systems and applications. The complementary ET-Minion core designed by Esperanto is a leaner, energy efficient, in-order multithreaded core with a vector/tensor accelerator unit at the heart of the massively parallel compute array.</li>
<li>The chip’s performance and efficiency is derived from a combination of factors, including the simplicity of the RISC-V instruction set, wide vector/tensor units on every ET-Minion core, a uniquely optimized memory hierarchy, state of the art process technology, and custom pipeline architecture and low-voltage circuits which enables more energy-efficient operation. The result is that Esperanto will deliver better performance per watt than legacy CPU and GPU solutions, as well as competing fixed-function designs without compromising generally purpose flexibility.</li>
</ul>
<p><strong>About Esperanto Technologies</strong></p>
<p>Esperanto Technologies develops high-performance, energy-efficient computing solutions for Artificial Intelligence / Machine Learning based on the open standard RISC-V instruction set architecture. Esperanto is headquartered in Mountain View, California with engineering sites in Portland, Oregon and Austin, Texas in the United States and multiple sites in Europe. Esperanto has brought together a seasoned team of experienced processor and software engineers with the goal of making RISC-V the architecture of choice for compute-intensive applications such as AI and Machine Learning. For more information, please visit <a href="https://www.esperanto.ai/">https://www.esperanto.ai/</a></p>
<p><strong>About the RISC-V Summit</strong></p>
<p>The third annual RISC-V Summit will highlight the continued rapid expansion of the RISC-V ecosystem, presenting both commercial offerings and exciting open-source developments. Newcomers to RISC-V, as well as the seasoned developers who are interested in broadening their toolsets, are invited to choose from the broad range of tutorials. The comprehensive 100% virtual event will feature keynotes from industry pioneers as well as thought-provoking panel discussions. Network with thought-leaders, technology companies, and researchers spearheading the adoption of this evolutionary change in the silicon market.</p>
<p><em>All trademarks or registered trademarks are the property of Esperanto Technologies or their respective holders.</em></p>
</div></div></div></div></div>
							</div>

												<span><span><a href="https://www.esperanto.ai/author/hstump/" title="Posts by Holly Stump" rel="author">Holly Stump</a></span></span><span>2020-12-01T08:33:52-08:00</span>													
													<section>
				
			
	
	
	
	
				<!-- fusion-carousel -->
</section><!-- related-posts -->


																	</article>
	</section>
						
					</div>  <!-- fusion-row -->
				</main>  <!-- #main -->
				
				
								
					
		 <!-- fusion-footer -->

		
					

												</div> <!-- wrapper -->
		</div> <!-- #boxed-wrapper -->
		
		
		
		<a></a>

		

			
		


</div>]]>
            </description>
            <link>https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310931</guid>
            <pubDate>Sat, 05 Dec 2020 02:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Microsoft crushed Slack]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310547">thread link</a>) | @theBashShell
<br/>
December 4, 2020 | https://www.platformer.news/p/how-microsoft-crushed-slack | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/how-microsoft-crushed-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.platformer.news/p/how-microsoft-crushed-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310547</guid>
            <pubDate>Sat, 05 Dec 2020 01:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No One Ever Got Fired for Choosing React]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25310462">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a web app without a framework. There are a bunch of potential advantages (no bloat! bespoke to your project!) and being able to say you built something with minimal dependencies gets you Engineer Points.</p>
<p>That is, if you can pull it off.</p>
<p>I started a new side project recently. It’s a web-based graphics editor, so it needs to be a single page app. My time spent profiling <a href="https://songrender.com/">SongRender</a> for performance issues has made me a little wary of React for building interfaces that update at 60 frames per second, so I decided to avoid it. I’d go (mostly) vanilla and see how far that took me.</p>
<p>I installed <a href="https://lit-html.polymer-project.org/">lit-html</a> and got to work. “Components” were simply functions that returned lit-html template results. A big singleton at the top of the tree held onto all the application state, stored as a global variable within that module.</p>
<p>The first hurdle came when a component needed local state. I could have lifted it to the singleton, but that would have broken the component’s encapsulation. I noticed that lit-html directives can keep state, so I decided to use them to build a tiny component library — ignoring a warning from the lit-html developers that this wasn’t a supported use case.</p>
<p>My home-brewed library worked great… until I needed to run some code when a component appeared on the screen. I started digging through lit-html documentation and issues looking for a way to detect a directive’s lifecycle, but it became clear to me that going down that path would be painful.</p>
<p>At that point, I recalled <a href="https://tomdale.net/2015/11/javascript-frameworks-and-mobile-performance/">this quote by Tom Dale</a>:</p>
<blockquote>
<p>I have heard from many developers who have told me that they accepted the argument that vanilla JavaScript or microlibraries would let them write leaner, meaner, faster apps. After a year or two, however, what they found themselves with was a slower, bigger, less documented and unmaintained in-house framework with no community. As apps grow, you tend to need the abstractions that a framework offers. Either you or the community write the code.</p>
</blockquote>
<p>Fair enough. Let’s avoid that trap. What about a small framework? I’d heard a lot of good things about Svelte, and although I was slightly worried about the size of the Svelte community I figured it would be fine.</p>
<p>My migration attempt quickly ground to a halt when I wanted a parent component to apply some styles to a child component. In React, I’d pass a class name in from the parent as a <code>className</code> prop. In Svelte, that’s considered a workaround, and the actual feature is the subject of an <a href="https://github.com/sveltejs/rfcs/blob/master/text/0000-style-properties.md">RFC</a>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Maybe this is an example of <a href="https://prog21.dadgum.com/160.html">dangling by a trivial feature</a>. But it’s so basic a capability that I’m surprised Svelte is on version three without an officially blessed way to do it. I ran into this limitation when I created my <strong>second component</strong>. Way before I got to try out any of the cool reactivity that earns Svelte all that buzz.</p>
<p>So I changed my mind and went with React. After an hour or so, I’d finished moving everything over — and my anxiety had vanished. I stopped worrying about having most efficient component system, and picked up work on the thing I wanted to build in the first place.</p>
<p>No, React isn’t perfect. It’s optimized for apps that make network requests and then display lists of things (i.e. most apps) which isn’t really what I’m doing here<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The performance is fine now, although I expect I’ll have to optimize as my project gets more complex.</p>
<p>But React lets me stop thinking about the framework. React gets out of my way. React is <a href="https://mcfunley.com/choose-boring-technology">boring</a>. React is actively developed. React has a giant ecosystem and a giant community. React is battle-tested on some of the most visited websites in the world.</p>
<p>I’m sure there are technically better ways to build a highly interactive interface on the web, but life is too short for me to spend hours trying to figure them out. There are things I want to create, and the only way I can actually create them is to stop spending so much time on tooling.</p>
<p>For now, I’m choosing React.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The solution they seem to have landed on — letting the child expose CSS custom properties as props — is actually pretty cool, though I don’t like that Svelte will silently wrap your component with an extra <code>div</code>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Although Dan, if you read this, the <a href="https://twitter.com/dan_abramov/status/1133341485133438982">“animation pass” mode</a> you’ve mentioned offhandedly sounds very relevant! <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310462</guid>
            <pubDate>Sat, 05 Dec 2020 00:52:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales numbers for my game and every piece of marketing I did]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310457">thread link</a>) | @chr15m
<br/>
December 4, 2020 | https://chr15m.itch.io/asterogue/devlog/201756/sales-numbers-for-asterogue | <a href="https://web.archive.org/web/*/https://chr15m.itch.io/asterogue/devlog/201756/sales-numbers-for-asterogue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="game_devlog_post_page_28789"><div><div><section><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MTMuZ2lm/original/2WhLWn.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MTMuZ2lm/x200/6pclNd.gif" data-image_id="4488813" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0OTMzNDguZ2lm/original/0NaSBi.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0OTMzNDguZ2lm/x200/ZLnRgb.gif" data-image_id="4493348" height="200"></a><a href="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzUuZ2lm/original/tRRdDT.gif" target="_blank" data-image_lightbox=""><img src="https://img.itch.zone/aW1hZ2UvNzYwMDkxLzQ0ODg4MzUuZ2lm/x200/bwgJDH.gif" data-image_id="4488835" height="200"></a></section><section><p>Asterogue has been out for a little over a month now, so it’s a good time to reflect on the sales numbers of the game. Games generally have a short-lived sales cycle so I am not expecting a huge increase in sales after this.</p>
<p>I’m writing this up to help other indie developers calibrate their expectations. You often read about the success stories because people love to read that it’s possible to make it big with a hit game, but few people bother to write up mediocre outcomes, which is the outcome of <em>most</em> game development efforts. This is called “selection bias”.</p>
<p>You can find a list of all the marketing and promotion I did below, to give you an idea of what kind of an effect you can expect from a single person doing all coding and all promotion by themselves.</p>

<p>Let’s cut to the chase.</p>
<ul>
<li><code>30</code> copies of <a href="https://play.google.com/store/apps/details?id=cx.mccormick.asterogue" rel="nofollow noopener">Asterogue for Android</a> were sold netting <code>$89 USD</code>.</li>
<li><code>18</code> copies of <a href="https://chr15m.itch.io/asterogue">Asterogue for Windows</a> were sold netting <code>$132 USD</code></li>
</ul>
<p>Total sales = <code>$221 USD</code></p>
<p>The game got a couple of five star ratings on each platform. Interestingly, the average payment for the Windows version was around $6 which is double the suggested $3 (people were able to choose any amount higher than $3).</p>
<p>The main cost making the game was my own time. If I had been charging one of my freelance clients to make this game it would have cost around <code>$5k - $10k</code> over 1.5 months of part time development at my normal hourly rate. Incidentally if you’re interested in having a game like this made, <a href="mailto:chris@mccormick.cx" rel="nofollow noopener">hit me up</a>. :)</p>

<p>It’s interesting to look at the visits to the game’s pages on each platform, and the click-through-rate of people who visited the page and then went on the buy the game.</p>
<ul>
<li>The Windows page on Itch saw <code>1,937</code> views with a click-through purchase rate of just under 1%.</li>
<li>The Google Play store doesn’t give raw numbers but it says the conversion rate is about 1% too.</li>
</ul>
<p>There’s an implication here that if I could drive more traffic to these pages I could expect 1 out of every 100 visitors to buy the game.</p>

<p>Here’s a list of all the marketing and promotion I did while building the game:</p>
<ul>
<li><a href="https://twitter.com/mccrmx/status/1306223700199448577" rel="nofollow noopener">Kept a Twitter thread up to date with the latest changes</a> (about 1250 followers).</li>
<li><a href="https://forums.tigsource.com/index.php?topic=70875.0" rel="nofollow noopener">Posted devlogs to the TIGSource forum</a>.</li>
<li><a href="https://www.reddit.com/r/roguelikedev/search/?q=saturday%20sharing&amp;source=recent&amp;restrict_sr=1" rel="nofollow noopener">Participated in Saturday Sharing on /r/roguelikedev</a>.</li>
<li>I sent a couple of updates to my own email newsletter subscribers (there are 90 subscribers).</li>
<li>Some <a href="https://dev.to/chr15m" rel="nofollow noopener">dev.to posts</a>.</li>
</ul>
<p>Here is a list of everywhere I launched the game:</p>
<ul>
<li><a href="https://www.reddit.com/r/roguelikes/comments/jkt4ue/asterogue_released_today_sci_fi_pixel_graphics/" rel="nofollow noopener">Launched on /r/roguelikes</a></li>
<li><a href="https://mccormick.cx/news/entries/it-s-asterogue-launch-day" rel="nofollow noopener">On my own blog</a>.</li>
<li>Emailed the <a href="https://infinitelives.github.io/" rel="nofollow noopener">infinitelives mailing list</a>.</li>
<li>Emailed my own email newsletter subscribers.</li>
<li>Created a listing on <a href="http://roguebasin.roguelikedevelopment.org/index.php?title=Asterogue" rel="nofollow noopener">RogueBasin</a> and in the news section too.</li>
<li>Kenney.nl discord in #promotion</li>
<li>Roguelikes discord in #advertise-releases</li>
<li>On the local game dev discord in my city.</li>
<li>On the local web dev front-enders Slack chat in my city (the game is built with front-end web technology).</li>
</ul>
<p>After release I also wrote some blog posts here on the game’s Itch devlog and linked a couple of these to Hacker News. The post <a href="https://chr15m.itch.io/asterogue/devlog/190653/my-game-wont-sell-and-thats-ok">My game won’t sell and that’s ok</a> got 7k hits.</p>

<p>There are three main strategies I can think of to improve sales for this game and future games:</p>
<ul>
<li>Kaizen. Improving the game. Fixing issues people have flagged and making quality of life improvements from player feedback.</li>
<li>Keep making more games. Compound on the interest and marketing garnered by this game. This is the strategy of <a rel="nofollow noopener">Sokpop games</a> and when I did an analysis of their collective I realized they probably didn’t make a profit until game number 8.</li>
<li>Use a 3rd party company for promotion instead of doing it myself.</li>
</ul>

<p>I am going to allocate time in my schedule to improve Asterogue. I got some great feedback and I want to polish those rough edges and fix all the issues people have flagged.</p>
<p>I will almost certainly make more graphically rich roguelike games in the future, because it was so much fun to do so. Thank you very much to everybody who bought the game, I really appreciate it.</p>
<p>I think the key is to do this without great expectations, just try to make the best games possible, and have fun doing it.</p>
<p>If you want to hear about games and other stuff I make you can follow me <a href="https://twitter.com/mccrmx" rel="nofollow noopener">on Twitter @mccrmx</a> or <a href="https://mccormick.cx/" rel="nofollow noopener">subscribe to my newsletter at mccormick.cx</a>. Thanks for reading!</p>
</section><section><h2>Get Asterogue</h2></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://chr15m.itch.io/asterogue/devlog/201756/sales-numbers-for-asterogue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310457</guid>
            <pubDate>Sat, 05 Dec 2020 00:51:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I accidentally built a spying app]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25310316">thread link</a>) | @akeck
<br/>
December 4, 2020 | https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>In the fall of 2007, my parents gave me an unforgettable gift for my sixteenth birthday: a first-generation iPhone.</p><p>I still clearly remember watching the keynote in which Steve Jobs announced the first Apple-branded phone a few months earlier. As a teenager attending high school in my hometown of Vicenza, Italy, I tuned into the livestream just before dinner, carefully listening to every word he said. That evening, Jobs started announcing a “widescreen iPod with touch controls”, a “revolutionary mobile phone” and a “breakthrough Internet communications device”–theatrically pausing before confessing that he was actually talking about one single device: the iPhone. Thousands of miles away from me, you could hear attendees exploding cheerfully through the live feed. Jobs went on demoing this amazing invention that, a decade later, would end up changing much more than the mobile phones market: it directly or indirectly impacted our society through mobile web, app stores, changing work-life balance, and social media.</p><p>October came, and so did the day I finally got my iPhone. I was really excited as I was the first one in my social circle with one. Every other teenager (and adult!) that saw my phone reacted in awe and with lots of curiosity. More than a few were also secretly envious, something I secretly did not mind. To add to the novelty, at the time the iPhone was only available for sale in the US.</p><p>To get an iPhone for me, my father had to ask a friend traveling to New York on a business trip to bring one back on the plane with her. That was not the end of it, however, as all phones were locked to the AT&amp;T network. In order for me to be able to use my iPhone in Italy, I had to unlock it.</p><p>That process required learning a variety of tools and techniques developed by hackers in the community, then documented in various blogs and forums. The first step was to <em>jailbreak</em> the phone, which gave you full access to the system and allowed you to run third-party apps. Then you’d have add one of those “hacking” apps to your phone, which patched the bootloader to remove the lock the US carrier had put on it. Despite sounding like a mouthful, the iPhone hacking community had worked hard on the User Experience (UX), making this entire process relatively easy for most people with basic tech skills.</p><hr><p>I really loved my shiny, new iPhone, and I was so excited about it that I was willing to accept many of its original limitations. It only supported slow 2G networks, didn’t have copy/paste, couldn’t transfer files via Bluetooth to my friends, and <a href="https://www.apple.com/hotnews/thoughts-on-flash/">famously</a> didn’t support Adobe Flash, which was ubiquitous on the web at the time.</p><p>However, there was one thing I really couldn’t stand: the Messages application could only store 1,000 texts (SMS).</p><p>That was 2007 — before the days of WhatsApp, Facebook Messenger, Telegram, etc. Instant messaging was something people did on their PCs only, with things like Windows Live Messenger (née MSN Messenger) or AIM.</p><p>For a high schooler like me, text messaging was the main way I kept in touch with my friends daily (<em>what was I supposed to do, call them?</em>). With my carrier giving me a whopping 100 free texts per day (seriously, we had to pay for them), between sent and received texts it would take less than a week to reach the storage limit of 1,000.</p><p>That’s when it all started.</p><p>Because my iPhone was already “hacked” (jailbroken), as a requirement for unlocking it and use it in Italy, I had full system access already. That allowed me to c extract any document I wanted, including my phone’s text message database.</p><p>It wasn’t even a month since I got my iPhone that I had already built a small “app” running on my laptop to archive my text messages forever. I would manually extract the SMS database from my iPhone, copy it to my laptop, then use a set of scripts written in PHP (the only programming language I knew at the time) to store the messages in a local database, and finally display them using a web-based interface.</p><p>This thing I put together worked just fine for me, but I immediately realized the “business potential” of what I had just created. Just like myself, I assumed many others had the same annoyance. I could have used what I learned to help them too, and maybe make some pocket change in the process. As a matter of fact, I did consider myself an enterprising teenager.</p><p>The idea had potential, and the “app” I built for myself already provided solid foundations, so I just needed to do a bit more work to turn it into a commercially-viable project.</p><p>The biggest challenge was making the solution more accessible to others, including those who were not particularly tech-savvy. That’s when I started learning about app development for iPhone.</p><p>Famously, Apple did not want the iPhone to support third-party apps at the beginning, saying developers should build web apps instead. That policy didn’t last long, and with the iPhone OS 2 update, launched in mid-2008, the official App Store came to life: the rest, as they say, is history.</p><p>However, the hacking community had already found a way to sideload apps and had even developed an “app store” called Cydia where you could find games, apps, and even mods to enhance the capabilities of the operating system itself. Cydia came preinstalled on every <em>jailbroken</em> iPhone, which meant potentially hundreds of thousands of people had access to it.</p><p>Everyone could build apps that would be published on Cydia, as long as you knew how to–something that was not remotely as easy to do as it is with today’s tools. As an enterprising teenager with quite a bit of free time on my hand during those winter afternoons and evenings, I took on that challenge.</p><hr><p>The first version of YouArchive.It came out in January 2008.</p><p>Today, you would describe YouArchive.It as a cloud service to store iPhone text messages. You could store all your messages in there, then read and search them using a web-based application.</p><p>There’s still a video left on YouTube showing the application in action (this was the third, and last, version):</p><p><iframe src="https://www.youtube-nocookie.com/embed/ps5ohEhO3S4" allowfullscreen="" title="YouTube Video"></iframe></p><p>With YouArchive.It came an iPhone application too. Published on the Cydia app store, it allowed importing messages into the “cloud service” directly from the phone.</p><p>YouArchive.It was free to use with a limit of 80,000 text messages. Because personal communications can be sensitive, all messages were stored encrypted. With a one-time payment of just €5 (about $6), you could become a VIP, remove any limit and enjoy unlimited storage.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*vTxYRljXFl3IBXGRsXOVag.png" alt="A screenshot of iTextUploader running on a first-generation iPhone"></p><figcaption>A screenshot of iTextUploader running on a first-generation iPhone</figcaption><p>For the next year and a half, YouArchive.It continued to grow organically. A few blogs and websites dedicated to iPhone “hacking” and to the underground app stores wrote about the app. Even a small radio program in the US featured it</p><p>I continued developing the app as a side project while in high school. I was also providing tech support and maintaining the infrastructure.</p><p>Listening to users' feedback, I would periodically add new features. YouArchive.It started displaying emojis as soon as the iPhone supported that (outside of Japan, it required downloading an app to enable them). Users asked for and got the ability to restore texts in another iPhone, before iCloud was available. I also implemented other privacy features such as requiring a password to open the mobile app.</p><blockquote><h3 id="what-i-didnt-realize-at-the-time-however-is-that-i-had-unknowingly-and-unwillingly-built-a-spying-tool-and-a-really-convenient-and-efficient-one">What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</h3></blockquote><p>Enough users were paying the fee to become VIP that I could cover the costs of running the service–this was before everyone was using Amazon Web Services or Microsoft Azure, so I was renting a co-located physical server which wasn’t cheap–and keep some pocket cash. Not much, but enough to pay for some hobbies and outings with friends.</p><p>Most importantly, building YouArchive.It gave me a lot of satisfaction and the opportunity to learn a lot of things about software development, business, dealing with customers and listening to their feedback.</p><hr><p>When I finally shut the service down, in June 2010, YouArchive.It had about 32,000 registered users who stored over 76 million messages.</p><p>The first, and stated, reason for the deprecation was a technical one: YouArchive.It’s iPhone app required using private APIs, which meant it could not be published on the App Store (and it still couldn’t to this day), limiting it to <em>jailbroken</em> phones only.</p><p>The second reason however was the most important to me, even though I have not revealed it until now.</p><p>About a year before the app closed, in April 2009 I implemented a new feature that was requested by many users: the ability to upload texts automatically, in background, without user intervention. For paying “VIP” users only, the mobile app could automatically send all new text messages to YouArchive.It, as often as every 15 minutes.</p><p>Automatic upload was an incredible convenience for many users that wanted to hoard their texts like me, to keep them forever, search within them, print or export them, or just liked having a backup.</p><p>What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</p><p>Thanks to background uploads, people could install the YouArchive.It app on another person’s iPhone, set it up, maybe even hide it (something possible on a <em>jailbroken</em> iPhone), and then watch as the text messages come in, almost real-time. Jealous partners, stalkers and the likes could install this tool on an unknowing victim’s phone with relative ease.</p><p>I can’t remember how I discovered that — it might have been a support request from a user or a post in a bulletin board. I also can’t know how many people were using YouArchive.It for their own archiving rather than to spy on others. Realizing what my users were doing, however, made me feel really uncomfortable and I did not want any part of that anymore.</p><p>As a senior in high school, barely eighteen years-old, I realized for the first time how technology can have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</a></em></p>]]>
            </description>
            <link>https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310316</guid>
            <pubDate>Sat, 05 Dec 2020 00:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tirana – Bloodshed Avoided at Queens Birthday Party]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310172">thread link</a>) | @Hansig_jw
<br/>
December 4, 2020 | https://www.mydiplomaticlife.com/tirana-bloodshed-avoided-at-queens-birthday-party/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/tirana-bloodshed-avoided-at-queens-birthday-party/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><strong>Tirana – Bloodshed Avoided At Queens Birthday Party</strong> is a story that came about thus. Sitting out and enduring the lockdown , I spent a lot of time trawling through YouTube videos especially trooping the colour and the celebrations of the Queen’s birthday. I love our history and traditions and make no apologies for saying so.</span></p><p>Every year, on the occasion of the Queen’s official birthday, all British embassies and Posts throughout the world organise their own Queen’s birthday celebration.</p><p>So, this took me back to a time and place when the apparently straightforward task of arranging an event of this magnitude can often be fraught with uncertainty and a whiff of danger, especially abroad.</p><p>It was the first week in June 1998 in Tirana, where the focus then was on the upcoming <strong>Queens</strong> <strong>Birthday Party,</strong> (QBP) which I had been told I was to organise.</p><p>Although I took the embassy lead with the organisation and logistics, all QBP’s are very much a team effort.</p><p>Given the importance of this event, all staff in the embassy, from drivers right up to the Ambassador, have a role to play in putting together this, our showcase social occasion of the year.</p><p>My chief role as lead was to coordinate all the various strands, make sure everyone knew exactly what they were expected to do, liaise with the venue for catering and entertainment and of course assist with the compilation of the all important guest list.</p><p>Planning progressed well. Perhaps a little too well. When the great day arrived we were all in position, well prepared and briefed as to what our role would be during the two hour long event. The Tirana International hotel had pulled out all the stops and really done a splendid job. Flower baskets abounded, the food was laid out on silver platters buffet style along the terrace, spotlessly white- jacketed waiters were primed and ready to mingle and dispense drinks.</p><p>For background, I had even hired a small classical musical quartet as well as a solo lady harpist.</p><figure id="attachment_112" data-shortcode="caption" aria-describedby="caption-attachment-112"></figure><p>For an event such as this, protocol dictated that as well as other foreign diplomats and notables, we invite the heads of the two main political parties, who were the President of Albania from the current governing party and his chief political rival from the opposition party, who just so happened to be the former President of Albania.</p><p>There was bad history between both men, they despised each other and there had been outbreaks of serious violence and bloodshed between their supporters in the recent past.</p><p><a href="https://www.mydiplomaticlife.com/sas-rescue-trapped-diplomats-in-albania/">SAS Rescue 3 Trapped British Diplomats in Albania</a></p><p>Therefore, given this mutual loathing, we didnâ€™t expect either to turn up. For us, the best-case scenario would have been both sending lower level minions for appearances sake or, better still, nobody from either party showing up.</p><p>Therefore, based on this presumption, I catered for one hundred official guests. No RSVP was received from either current or former President, therefore it was assumed that they would not be coming. Even last minute phone calls to their respective offices evoked non-committal answers</p><p>Well, I was wrong.</p><p>First to turn up was the incumbent President of Albania with a whole host of bodyguards, drivers and associated hangers-on. The Ambassador, thinking that the President was not coming was initially caught on the hop, but thinking fast on his feet announced that he was honoured and thrilled that the President had decided to accept our invitation.</p><p>I was then tasked with ushering him and his party to a shady spot on one side of the harpist who began to look extremely nervous at being so near to the President but more so I think because of his bodyguards, all black leather jackets and bulges under their armpits.</p><p>Not long after, more official guests arrived. But what was this?</p><p>I could not believe it. The Presidentâ€™s chief political rival had also decided to accept our invitation. So in he came, with even more bodyguards, drivers and associated hangers on. Why had he come? He must have known that the President would be coming. Was this an excuse for some form of confrontation?</p><p>The by now clearly rattled Ambassador greeted the former President announcing again how honoured and thrilled he was that he had decided to accept our invitation. At this stage of the proceedings I was trying to merge into the background fearing the worst, but (bugger) the Ambassador spotted me and motioned for me to take charge of the party and find them a suitable spot. Well, the only free space large enough was on the other side of where the lady harpist was playing and so I directed the former President and his entourage there.</p><p>The poor harpist.</p><p>I had no idea what Albanian piece she was playing but with two warring factions on either side of her the pace of her playing definitely increased in tempo and volume. Also, a<span>t that stage, I really did not think that a harp would be a sturdy enough barrier if the two factions decided to have a go at each other.</span></p><p>However, my main concern at this stage was not about confrontation, it was the catering arrangements. I had only catered for one hundred and now with the recent, unexpected arrivals it looked to be about one hundred and fifty. Horror of horrors, it now appeared as if we might run out of food and drink at an early stage, a cardinal sin of the first magnitude at a QBP.</p><p>If so, I was in trouble. If this was not bad enough, we had two factions who would at the drop of a hat be at each others throats, a twitchy harpist who was literally going into overdrive with the speed of her playing and an Ambassador who seemed to be hyperventilating under an awning in the corner with a very shaky largeÂ&nbsp; Â&nbsp; Â&nbsp; Â&nbsp; G &amp; T.</p><p>Things were definitely taking a turn for the worse. I could see my career ending before it started. I was the one put in charge, I had arranged all of this. If things went wrong it was down to me.</p><p>The uneasy atmosphere persisted as it came time for the speeches (very short thankfully), which, both the Ambassador and the President managed to deliver without incident or interruption. On conclusion of the speeches, the two national anthems were played followed soon after with the orderly departure of the President and his party.</p><p>A few minutes later, having been advised that the Presidentâ€™s convoy of cars had left the hotel and sped off into the distance, the former President and his entourage also left. Both parties fortunately (for me) had not touched any of the food instead limiting themselves to soft drinks or iced water.</p><p>My relief was palpable. It had turned out eventually to be a good QBP given the uncomfortable circumstances and unexpected guests. At least the Ambassador who had by now recovered his composure, was content with the proceedings which was the main thing. This was a good, steep learning curve for me as I was destined to organise a number of QBPs in the future in various locations and under some pretty extreme constraints.</p><p>So, valuable lesson learned, never take anything for granted.</p></div></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/tirana-bloodshed-avoided-at-queens-birthday-party/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310172</guid>
            <pubDate>Sat, 05 Dec 2020 00:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up CI/CD with GitHub Actions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310155">thread link</a>) | @nickyvanurk
<br/>
December 4, 2020 | https://codingwizardry.com/2020/12/02/how-to-set-up-ci-cd-with-github-actions-for-rails/ | <a href="https://web.archive.org/web/*/https://codingwizardry.com/2020/12/02/how-to-set-up-ci-cd-with-github-actions-for-rails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="penci-post-entry-inner">
			
<p>In this guide I am going to show you how to setup <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/CI/CD" target="_blank">CI/CD</a> with GitHub Actions for Rails. I assume you are running Linux and have Rails 6 installed together with PostgreSQL and Git. If you need help, I wrote a guide on <a rel="noreferrer noopener" href="https://codingwizardry.com/2020/11/10/how-to-install-ruby-on-rails-on-ubuntu-20-04/" target="_blank">how to install Rails with PostgreSQL on Ubuntu 20.04</a>. In this tutorial we will create a basic Rails application. We will upload the application to GitHub, integrate GitHub Actions, and setup a CI/CD workflow that deploys to Heroku. Let’s begin!</p>



<h2>Setting Up PostgreSQL</h2>



<p>Create a PostgreSQL user for the Rails app we’ll create in the next step. To do this, switch into the <code>postgres</code> user and fire up <code>psql</code>:</p>



<pre><code>$ sudo -u postgres -i
$ psql</code></pre>



<p>Then create a new user (or “role”, as PostgreSQL calls it):</p>



<pre><code>$ create role social_network with createdb login password 'password1';</code></pre>



<p>To go back you type <code>\q </code>to exit psql and <code>exit</code> to return to your main terminal.</p>



<h2>Creating a New Rails App</h2>



<p>Navigate to a directory on your computer where you want to store the project (I like to use <code>~/dev</code>) and execute the following commands:</p>



<pre><code>$ rails new social_network -d postgresql
$ cd social_network</code></pre>



<p>Open up the <code>config/database.yml</code> file in a text editor and under <code>default</code> find the line that says <code>pool: &lt;%= ENV.fetch("RAILS_MAX_THREADS") { 5 } %&gt;</code> and add the following lines: </p>



<pre><code>host: localhost
username: social_network
password: &lt;%= ENV['SOCIAL_NETWORK_DATABASE_PASSWORD'] %&gt;</code></pre>



<p>We are going to need an environment variable to store the database password. The password should match the password used in the previous step. Execute the following commands:</p>



<pre><code>$ echo 'export SOCIAL_NETWORK_DATABASE_PASSWORD="password1"' &gt;&gt; ~/.bashrc
$ source ~/.bashrc</code></pre>



<p>Finally, we’ll create our database and launch our application.</p>



<pre><code>$ rails db:create
$ rails server</code></pre>



<p>You can now visit <a rel="noreferrer noopener" href="http://localhost:3000/" target="_blank">http://localhost:3000</a> and if everything has gone right you will be greeted by the following website:</p>



<figure><img loading="lazy" width="1024" height="679" src="https://codingwizardry.com/wp-content/uploads/2020/11/image-1-1024x679.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/image-1-1024x679.png 1024w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-300x199.png 300w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-768x509.png 768w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-1170x776.png 1170w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-780x516.png 780w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-585x388.png 585w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1-263x175.png 263w, https://codingwizardry.com/wp-content/uploads/2020/11/image-1.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>Add Project to GitHub</h2>



<p>Next up, let’s create a new repository on GitHub. You can create a new repository <a rel="noreferrer noopener" href="https://github.com/new" target="_blank">here</a> once you’re logged into GitHub.</p>



<figure><img loading="lazy" width="724" height="716" src="https://codingwizardry.com/wp-content/uploads/2020/11/image-2-e1605980210642.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/image-2-e1605980210642.png 724w, https://codingwizardry.com/wp-content/uploads/2020/11/image-2-e1605980210642-300x297.png 300w, https://codingwizardry.com/wp-content/uploads/2020/11/image-2-e1605980210642-585x579.png 585w" sizes="(max-width: 724px) 100vw, 724px"></figure>



<p>Then we want to link the GitHub repository to our local project. In the <code>social_network</code> folder execute the following command:</p>



<pre><code>$ git remote add origin git@github.com:your_username/social-network.git</code></pre>



<p>Or if you prefer to use HTTPS instead of SSH, run the following command:</p>



<pre><code>$ git remote add origin https://github.com/your_username/social-network.git</code></pre>



<p>Verify that we’ve set the remote origin correctly:</p>



<pre><code>$ git remote -v
origin  git@github.com:your_username/social-network.git (fetch)
origin  git@github.com:your_username/social-network.git (push)</code></pre>



<p>Because we’ve let GitHub create a README.md and .gitignore file for us, let’s remove the the ones generated by Rails, and pull the new files (including a LICENCE file) from GitHub into our local project folder:</p>



<pre><code>$ rm .gitignore README.md
$ git pull origin main
From github.com:your_username/social-network
 * branch            main       -&gt; FETCH_HEAD</code></pre>



<p>Now to push all our local files onto GitHub, execute the following commands. Note here that we have to rename our master branch to main, <a href="https://www.zdnet.com/article/github-to-replace-master-with-alternative-term-to-avoid-slavery-references/" target="_blank" rel="noreferrer noopener nofollow">GitHub no longer uses the name master</a> in order to rid itself from references to slavery.</p>



<pre><code>$ git add -A
$ git commit -m "Initial commit"
$ git branch -m master main
$ git push --set-upstream origin main</code></pre>



<p>If everything went well, we’ve successfully uploaded our newly created Rails application to GitHub.</p>



<h2>Continuous Integration with GitHub Actions</h2>



<p>To set up GitHub Actions for our project we’ll need a workflow file. A workflow is an automated procedure that you can add to a repository. Workflows are made up of one or more jobs and can be scheduled or triggered by an event. The workflow can be used to build, test, package, release, or deploy a project on GitHub. You can read more about GitHub Actions <a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions" target="_blank" rel="noreferrer noopener">here</a>. In this tutorial we’re going to use a workflow to test the project and, if all tests pass, deploy the project to <a href="https://heroku.com/" target="_blank" rel="noreferrer noopener">Heroku</a>.</p>



<p>Let’s start by creating a functional workflow file. This file will be able to automatically run the, currently non-existent, tests. In your project folder create a new directory <code>.github/workflows/</code>. Within the newly created workflows directory create a new workflow file <code>social-network.yml</code>:</p>



<pre><code>name: Social Network
on: [push]
jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres
        ports: ['5432:5432']
        env:
          POSTGRES_USER: social_network
          POSTGRES_PASSWORD: postgres
        options: &gt;-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Check out repository code
        uses: actions/checkout@v2
      - name: Set up Node.js
        uses: actions/setup-node@v1
        with:
          node-version: '14.x'
      - name: Set up Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: 2.7
          bundler-cache: true
      - name: Install dependencies
        run: |
          bundle install --jobs 4 --retry 3
          yarn
      - name: Set up database
        run: bundle exec rails db:prepare
        env:
           SOCIAL_NETWORK_DATABASE_PASSWORD: postgres
      - name: Run tests
        run: bundle exec rails test
        env:
           RAILS_ENV: test
           SOCIAL_NETWORK_DATABASE_PASSWORD: postgres       </code></pre>



<p>To understand the workflow file I recommend you take a moment to read the “Understanding the workflow file” section in the GitHub Actions documentation <a href="https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions/introduction-to-github-actions#understanding-the-workflow-file" target="_blank" rel="noreferrer noopener">here</a>. Now, commit and push the file to GitHub:</p>



<pre><code>$ git add -A
$ git commit -m "Add automated tests workflow"
$ git push</code></pre>



<p>Head over to GitHub and select the <strong>Actions</strong> tab in the social-network repository and click on “Add automated tests workflow”, you will see the following output:</p>



<figure><img loading="lazy" width="1015" height="654" src="https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684.png 1015w, https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684-300x193.png 300w, https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684-768x495.png 768w, https://codingwizardry.com/wp-content/uploads/2020/12/image-3-e1606833342684-585x377.png 585w" sizes="(max-width: 1015px) 100vw, 1015px"></figure>



<p>We’ve successfully set up continuous integration! In the next section we will focus on automatic deployment to Heroku.</p>



<h2>Continuous Deployment with GitHub Actions</h2>



<p>Create a new Heroku account if you haven’t already got on <a href="https://signup.heroku.com/" target="_blank" rel="noreferrer noopener">here</a>. Then, create a new app within Heroku <a href="https://dashboard.heroku.com/new-app" target="_blank" rel="noreferrer noopener">here</a>. Choose an app name and select your region, I like to prefix the app name with my last name:</p>



<figure><img loading="lazy" width="655" height="327" src="https://codingwizardry.com/wp-content/uploads/2020/12/image-1.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/12/image-1.png 655w, https://codingwizardry.com/wp-content/uploads/2020/12/image-1-300x150.png 300w, https://codingwizardry.com/wp-content/uploads/2020/12/image-1-585x292.png 585w" sizes="(max-width: 655px) 100vw, 655px"></figure>



<p>In order to deploy to Heroku we will need to setup a GitHub Secret with the Heroku API key. The API key can be found <a href="https://dashboard.heroku.com/account" target="_blank" rel="noreferrer noopener">here</a>. Create a new GitHub secret:</p>



<ol><li>On GitHub, navigate to the main page of the repository.</li><li>Under the repository name, click <strong>Settings</strong>.</li><li>In the left sidebar, click <strong>Secrets</strong>.</li><li>Click <strong>New repository secret</strong>.</li><li>Type <code>HEROKU_API_KEY</code> in the <strong>Name</strong> input box.</li><li>Paste the Heroku API key in the <strong>Value</strong> input box.</li></ol>



<p>We can now use this secret in the workflow file. Update the workflow file to deploy to Heroku once all tests pass:</p>



<pre id="block-a8c659b2-f50c-4043-8a74-f7fc3eb6a65f"><code>name: Social Network
on: [push]
jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres
        ports: ['5432:5432']
        env:
          POSTGRES_USER: social_network
          POSTGRES_PASSWORD: postgres
        options: &gt;-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Check out repository code
        uses: actions/checkout@v2
      - name: Set up Node.js
        uses: actions/setup-node@v1
        with:
          node-version: '14.x'
      - name: Set up Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: 2.7
          bundler-cache: true
      - name: Install dependencies
        run: |
          bundle install --jobs 4 --retry 3
          yarn
      - name: Set up database
        run: bundle exec rails db:prepare
        env:
           SOCIAL_NETWORK_DATABASE_PASSWORD: postgres
      - name: Run tests
        run: bundle exec rails test
        env:
           RAILS_ENV: test
           SOCIAL_NETWORK_DATABASE_PASSWORD: postgres
  deploy:
    needs: test
    runs-on: ubuntu-latest
    steps:
     - uses: actions/checkout@v2
     - uses: akhileshns/heroku-deploy@v3.6.8
       with:
         heroku_api_key: ${{secrets.HEROKU_API_KEY}}
         heroku_app_name: 'Your Heroku app name'
         heroku_email: 'Your email'</code></pre>



<p>In order to execute commands on Heroku once the project is deployed, we need a <code>Procfile</code>. We will need to execute commands that set up the database and start the application. Go ahead and create the file in the project root directory with the following contents:</p>



<pre><code>release: bundle exec rails db:prepare
web: bundle exec puma -C config/puma.rb</code></pre>



<p>Commit the changes:</p>



<pre><code>$ git add -A
$ git commit -m "Add automated deployment to workflow"</code></pre>



<p>We are almost ready to push to GitHub. But first, add a root route so that the project knows what to display whenever a users surfs to the website. Add a function named <code>index</code> to <code>app/controllers/application_controller.rb</code>:</p>



<pre><code>class ApplicationController &lt; ActionController::Base
  def index
    render html: 'Hello, world!'
  end
end</code></pre>



<p>Then, add a root route to <code>config/routes.rb</code>:</p>



<pre><code>Rails.application.routes.draw do
  root 'application#index'
end</code></pre>



<p>Commit the changes once more and push to GitHub:</p>



<pre><code>$ git add -A
$ git commit -m "Add root route"
$ git push</code></pre>



<p>Head over to GitHub Actions and confirm that all tests pass:</p>



<figure><img loading="lazy" width="1015" height="408" src="https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105.png 1015w, https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105-300x121.png 300w, https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105-768x309.png 768w, https://codingwizardry.com/wp-content/uploads/2020/12/image-2-e1606833375105-585x235.png 585w" sizes="(max-width: 1015px) 100vw, 1015px"></figure>



<p>And that’s it! The project is now successfully deployed to Heroku.</p>



<figure><img loading="lazy" width="631" height="81" src="https://codingwizardry.com/wp-content/uploads/2020/12/image-5.png" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/12/image-5.png 631w, https://codingwizardry.com/wp-content/uploads/2020/12/image-5-300x39.png 300w, https://codingwizardry.com/wp-content/uploads/2020/12/image-5-585x75.png 585w" sizes="(max-width: 631px) 100vw, 631px"></figure>




			
			
			
												
									</div>
	</div></div>]]>
            </description>
            <link>https://codingwizardry.com/2020/12/02/how-to-set-up-ci-cd-with-github-actions-for-rails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310155</guid>
            <pubDate>Sat, 05 Dec 2020 00:14:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Visual Browser History, from Netscape 4 to Mozilla Firefox]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25309817">thread link</a>) | @Lammy
<br/>
December 4, 2020 | http://www.andrewturnbull.net/mozilla/history.html | <a href="https://web.archive.org/web/*/http://www.andrewturnbull.net/mozilla/history.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The development and evolution of the Mozilla browser, from its Netscape-seeded beginnings through the Firefox releases of today, can be fascinating.  Numerous changes occurred to the software in terms of technology, features, and appearance; particularly when Mozilla and Mozilla Firefox were both in their infancy and many groundbreaking developments were made.  Much of this software was not widely seen or used when initially released, with its focus limited to enterprising testers and developers for several years.  Several releases however provided the basis for Netscape 6.x and 7.x releases that were oriented towards end users, which as an essential part of the context are also covered here.</p><p>Although I could have conceivably traced this chronology all the way back to <a href="http://www.andrewturnbull.net/nscape1.html">Netscape in 1994</a>,  I have chosen to limit my focus to the post-Netscape 4.x browser development that began from the time Netscape released its preliminary "5.0" source code on March 31, 1998 through the present day.  For consistency, I have also chosen to show the browsers running on Windows 95 (which was current at the time the original code was released) at the same screen size displaying the respective browser's "About" page when possible.</p><div>

<tbody><tr>
<td><img src="http://www.andrewturnbull.net/mozilla/ns404.png" alt="[Netscape Navigator 4.04 screenshot]"></td>
<td>As a point of reference, we'll begin our look back at the history of Mozilla with a screenshot of Netscape Navigator 4.04, which was current at the time when Netscape released most of the source code to its next browser release in development on March 31, 1998.</td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/ns50.png" alt="[Unofficial Netscape 5.0 screenshot]"></td>
<td>After the Netscape source code was released, some enterprising users attempted to compile it.  This is a screenshot of one such unofficial "Netscape 5.0" build, available for download <a href="ftp://sillydog.org/pub/misc/mozilla5.zip">here</a>.<p>
The user interface at this point was substantially the same as that of Netscape 4.x, although Netscape trademark references were changed to the codename "Mozilla" or removed altogether.</p><p>
The fire-breathing Mozilla lizard graphic used on this "About" screen was originally one of many <a href="http://home.snafu.de/tilman/mozilla/">mascot graphics</a> used on Netscape's website in 1994-95, and would reappear on Mozilla later on.</p><p>
Many features are non-functional, and this happens to be the buggiest piece of software I have ever used; with frequent error dialogues and crashes.  Given circumstances such as these, perhaps it's not surprising that later in 1998 the decision was made to practically rewrite the browser from scratch...</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/geckoprev.png" alt="[Netscape Gecko Preview screenshot]"></td>
<td>There is little detailed documentation of what "Netscape 5.0" development went on throughout 1998, and due to the circumstances of the time nearly all development work was limited to inside the walls of Netscape headquarters.  (A page was once created on MozillaZine containing screenshots from this era...and it <a href="http://www.mozillazine.org/alookback/">still exists</a>!)
<p>
In December 1998, however, Netscape did publicly release a developer preview based upon this development work and its new rendering engine, called NGLayout or "Gecko."  This preview was not intended as a traditional browser beta as much as a press demonstration of the new rendering technology.</p><p>
Curiously, this build produces the user agent string of "</p><tt>Mozilla/4.05 [en] (Win95; I)</tt>," leading me to wonder if Netscape created the preview by taking Navigator 4.05 and somehow grafting the new rendering engine into it.</td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m3.png" alt="[Mozilla Milestone 3 screenshot]"></td>
<td>In March 1999, the first "proper" next-generation Netscape browser preview was released under the moniker of "Milestone 3" (Milestones 1 and 2 were apparently limited to internal development).<p>
A new user interface with bluish-purple toolbar buttons was introduced, and due to the open-source nature of the program Netscape trademarks were again absent.</p><p>
Interestingly, the "throbber" graphic used on this build was the same blue "N" used as an interim logo on <a href="http://www.andrewturnbull.net/nscape1.html">Netscape Navigator</a> 0.96 and <a href="http://www.andrewturnbull.net/nscape1.html">1.0</a> back in 1994.</p><p>
Although this is usually considered the first proper "Mozilla" release, there are in fact no overt references to "Mozilla" on the browser:  The start page calls it "the Gecko Browser," while the Help menu instead references "Communicator Prototype."</p><p>
These early Mozilla milestones had quite a few bugs:  This particular release has many non-functional features, and the status bar runs off the bottom of the screen at low display resolutions; as seen here.</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m4.png" alt="[Mozilla Milestone 4 screenshot]"></td>
<td>Mozilla Milestone 4 introduced a number of developments and changes.<p>
The Netscape 1.0 throbber was replaced by a new Gecko-themed one, in which many words and phrases (including "search," "ecstatic," "together," "free," "hungry," "all for you," and "feel good") scrolled past in four directions as the browser retrieved information.</p><p>
The caption "Mozilla" was (temporarily) added to the title bar, a vestigial "Help" menu option was added, fewer links were placed on the Personal Toolbar by default, the purple-tinted Taskbar and status bar were now visible at low screen resolutions, and the sidebar—a characteristic feature of almost all subsequent Mozilla and Netscape releases—was enabled by default.</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m5.png" alt="[Mozilla Milestone 5 screenshot]"></td>
<td>The changes in Milestone 5 were again minor, with some extra 3D definition added to the top and left edges of the toolbars and the word "Mozilla" removed from the title bar yet again.<p>
The sidebar had been visually revamped, although it was still primarily non-functional.  The sidebar panel in this screenshot rather resembles a mock-up of AOL Instant Messenger, although Don Luchini tells me he thinks it was intended to be a Resource Description Framework-based navigator at one point.</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m8.png" alt="[Mozilla Milestone 8 screenshot]"></td>
<td>As already mentioned, these early Mozilla milestones were very buggy, and in fact I couldn't get M6 or M7 to run at all without freezing.  By the time Milestone 8 had been released to prospective testers in July 1999, most of the user interface had acquired a lavender tint, the toolbar icons were more widely spaced, and a "Translate" button had been added.<p>
The "Chat" button had been removed from the Taskbar, and text on the status bar now had 3D borders drawn around them.  Additionally, the browser no longer defaulted to an internal start page, the "Mozilla" caption reappeared on the title bar (this time for good), and the "QA" menu compiling frequently-used testing tools had made its first appearance.</p><p>
Interestingly, the Help menu still referenced the software as "Communicator Prototype" at this time.</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m9.png" alt="[Mozilla Milestone 9 screenshot]"></td>
<td>Branding had improved slightly in Mozilla Milestone 9, with the familiar "m" throbber now in position replacing the earlier Gecko one and the Help menu now making references to only "Communicator" proper.<p>
Given away by their purple tint and "grippy" control, custom-drawn menus first appeared in the Windows and (presumably) Linux versions at this point.</p><p>
Some buttons and controls had also been changed:  The "Translate" button was removed, the 3D borders on the status bar were again omitted, the component icons moved from the right side to the left side of the Taskbar, and other elements on the Taskbar were now limited to three menus titled "Mozilla," "Shopping," and "Open Windows."</p><p>
Milestone 10 (which I was unable to run due to a crash error) is similar.</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m11.png" alt="[Mozilla Milestone 11 screenshot]"></td>
<td>The visual changes that came to Mozilla with Milestone 11 were dramatic, at the very least.
A totally new teal and blue look with stylized round toolbar buttons was adopted, throwing normal OS-native interface conventions into the blender.  It matched Netscape's web page layout of the time, though.<p>
The sidebar was streamlined, the separate executable used to run the program was retitled from "apprunner" to "mozilla," an "About" screen (seen here) was now implemented, a "Search" button was added to the location field, and the "Shopping" menu on the Taskbar was (wisely, IMO) omitted.  The Personal Toolbar was reduced to a sliver above the main toolbar, and also duplicated the Bookmarks menu.</p><p>
By this point, virtually all remaining references to "Communicator 5.0" in the browser or directory structure had been removed.</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m12.png" alt="[Mozilla Milestone 12 screenshot]"></td>
<td>Minor changes continued to work their way into the software in M12, with the "My Netscape" option removed from the Personal Toolbar and a custom-drawn scrollbar replacing the lingering OS-native element.</td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m13.png" alt="[Mozilla Milestone 13 screenshot]"></td>
<td>Mozilla Milestone 13 was released in January 2000 and looked almost identical to the previous release.
The Personal Toolbar and Taskbar captions were increased ever so slightly in size, and the "What's Related" sidebar panel was closed by default when first running the program:  Changes clearly on the hair-splitting side.<p>
In terms of packaging, however, Milestone 13 introduced an option of an installer to Windows and Macintosh users.  The installer screens and resulting Start Menu item (in Windows) are captioned "Mozilla Seamonkey," with "Seamonkey" being the codename for the application.</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/moz-m14.png" alt="[Mozilla Milestone 14 screenshot]"></td>
<td>More significant changes made their way into Mozilla M14.<p>
The cryptic text-line application runner had been removed (or at very least, rendered invisible).  The software "About" screen was redesigned and now included the famous mozilla.org star logo and user agent string (though the wrong milestone number was denoted in it!).</p><p>
There were some minor visual tweaks as well:  The drop-arrow was removed from the location field and the "Search" button moved from inside to outside it.</p><p>
<img src="http://www.andrewturnbull.net/mozilla/mozicon14.png" alt="[Mozilla Milestone 14 application icon]">
Furthermore, the first Mozilla application icon was added (seen at right), and the old fire-breathing Mozilla lizard graphic from circa 1994 was brought back as an <a href="http://www.andrewturnbull.net/mozilla/mozilla-splashold.png">application splash screen</a> retained through Mozilla 1.2.1 in 2002.
</p></td>
</tr>

<tr>
<td><img src="http://www.andrewturnbull.net/mozilla/ns6pr1.png" alt="[Netscape 6.0 Preview Release 1 screenshot]"></td>
<td>The first preview release, or formal beta, for Netscape 6.0 was released in April 2000, and with the exception of the Gecko developer preview from late 1998 this was the first Netscape-branded release since the groundbreaking of post-4.x browser development.<p>
This presented an interesting circumstance, as the previous Mozilla-branded milestones already effectively served as betas for Netscape 6.0.  This nevertheless was the first release to get extensive media attention and it introduced a number of proprietary features and other differences not in Mozilla M14; upon which it was based.</p><p>
<img src="http://www.andrewturnbull.net/mozilla/ns6icon.png" alt="[Netscape 6.0 application icon]">
Aside from the obvious presence of the Netscape …</p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.andrewturnbull.net/mozilla/history.html">http://www.andrewturnbull.net/mozilla/history.html</a></em></p>]]>
            </description>
            <link>http://www.andrewturnbull.net/mozilla/history.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25309817</guid>
            <pubDate>Fri, 04 Dec 2020 23:41:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Coding Challenge That Sucks Less]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25309605">thread link</a>) | @arnon
<br/>
December 4, 2020 | https://peka.la/pieces/a-coding-challenge-that-sucks-less | <a href="https://web.archive.org/web/*/https://peka.la/pieces/a-coding-challenge-that-sucks-less">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Published on</p><!-- --> <!-- --><p>December 4th, 2020</p></div> </div><p>In my career, I have found myself on both sides of the hiring process many
times. Every company's approach is different but when it comes to a software
developer role, there was almost always a form of a take-home coding challenge
involved.</p><p>For both the candidate and the company, they are a necessary evil. It would be
hard to find someone claiming they like solving or reviewing coding assignments.
However, there are different levels of evil, and making that part of the process
suck less should be in everyone's best interest.</p><blockquote><p><em>Note #1</em></p><p>This piece ended up much longer than I expected. If you would prefer to skip
the background starter and go straight to the main course, here is the link to
<a href="#the-rules-of-a-good-challenge">the rules of a good coding challenge</a>.</p></blockquote><blockquote><p><em>Note #2</em></p><p>Some companies choose to skip this step in their hiring process, sometimes
conditionally (e.g. for folks with substantial open source contributions or
for referrals) and sometimes completely. While there are alternatives that
allow to do that and still hire confidently, and while I think some of them
might have advantages, a take-home assignment remains an industry standard.</p><p>In this piece, I will focus on how to improve it, and not on questioning its
merit or value. I can recommend
<a href="https://css-irl.info/why-i-dont-have-time-for-your-coding-challenge/">this post by Michelle Barker</a>
if you want to explore that topic.</p></blockquote><blockquote><p><em>Note #3</em></p><p>Most of what I describe in this piece likely applies to any software engineer
role. However my experience is heavily skewed towards frontend development. If
you plan to apply these learnings to other roles, your mileage may vary.</p></blockquote><h2 id="first-impressions">First impressions</h2><p>A coding assignment usually comes pretty early in the process, right after the
first screening. From the perspective of the candidate, it can set a tone for
how they perceive the company they are trying to get hired by. A bad experience,
which is not rare, can make it hard to remain excited about the role later on.
Come to think of it, so far I've only accepted positions from companies where I
at least didn't hate the coding assignment ‒ it was never the deciding factor,
but an early indicator for which places to avoid.</p><p>For the company, a malformed coding challenge can distort the first impression
of the candidate. It can accidentally reward things like an abundance of free
time while failing to evaluate traits that actually matter for the job at hand.</p><h2 id="on-the-flip-side">On the flip side</h2><p>Ironically, when I joined these companies and got the chance to be at the other
end of the same process that I found enjoyable as a candidate, things looked
much different. I've often found reviewing those coding challenges to be a
painfully long, demanding, and confusing task.</p><p>When I recently got a chance to rethink the hiring process for frontenders at my
current company I've decided to take a better look at where that mixed
experience comes from. I embarked on a mission to design an assignment that
works for both the candidate and the reviewer while still doing a good job at
evaluating the match. I started by considering what the incentives are for
everyone involved.</p><h2 id="the-deadlock-of-incentives">The deadlock of incentives</h2><h3 id="candidate--outside-looking-in">Candidate ‒ outside, looking in</h3><p>As a candidate you want to get hired ‒ that's the main reason people apply for
jobs. If the company asks you to solve a take-home coding challenge, you will
probably first roll your eyes, but your best chance to get the job is to solve
it as well as you can.</p><p>A few observations follow from this. First, knowing what criteria for "well" are
is very helpful and welcomed by the candidate. Second, you want the assignment
to allow you to showcase what you consider your strongest skills. Depending on
your personal situation, optimizing for the least time "wasted" on it can be
very important too.</p><p>Additionally, from my experience, the challenges I've hated the least were the
ones that didn't feel dull, or as if I was asked to do unpaid work for the
company, solving a random ticket from their backlog.</p><p>I also enjoyed when, as an added benefit, a hiring task was an opportunity to
try a library or technique I was planning on learning anyhow, so I could
<a href="https://english.stackexchange.com/questions/274369/another-term-phrase-for-kill-two-birds-with-one-stone#:~:text=fill%20two%20needs%20with%20one%20deed">fill two needs with one deed</a>.</p><p>And after all is said and done, learning how well you've done and getting
feedback about it is much appreciated. There are few things as annoying as
submitting an assignment and then never hearing about it again.</p><h3 id="reviewer--inside-looking-out">Reviewer ‒ inside, looking out</h3><p>Since the coding assignments are technical, the task of reviewing the submission
will usually end up on the desk of a developer. As a reviewer, you want to
fairly and accurately evaluate how well the candidate solved the challenge and
how their solutions compared to other people's applying for the role. You also
want to do so efficiently, you have a whole backlog of things to work on after
all. How difficult of a task all that is depends to a large extent on how the
assignment is designed.</p><p>If every hiring submission that lands in your inbox is a unique snowflake that
doesn't follow any predictable structure, you're in for bad times. Unconstrained
solution space forces the reviewer to either spend a long time getting familiar
with that particular solution or to make the evaluation based on a rough skim of
it. In both cases, the company loses, either in the time of the reviewer or the
quality of the review and thus the confidence level it can have from the review.</p><p>Reviewer's best friends are clear guidelines for what a good and bad submission
looks like, as well as a familiar review process. Switching processes, tools,
and criteria just to evaluate someone's take-home challenge code can be a
frustrating ordeal.</p><h3 id="company--looking-inside-out">Company ‒ looking inside out</h3><blockquote><p>The person or people that represent the interest of the company in the hiring
process will vary, but usually it will be an internal hiring manager,
engineering manager, CTO, or all of these together. The reviewer can be seen
in this role too. "The company" in this piece refers to that group.</p></blockquote><p>What the company wants is to hire the best candidate, the one that is a match
for the role and will be the optimal contributor. A daunting task, really.</p><p>A coding challenge is a tool that can help with shedding some light on a narrow
portion of the full picture needed to make the decision ‒ and an imperfect tool
at that. It will help to answer some questions about the candidate, but which
questions will depend on how it's designed. For example, it can answer a
question: "How well does the candidate know the quirks of JavaScript?". Or "What
technologies would the candidate choose to start a new project today?". Answers
to these questions do tell something about the candidate, but it's unlikely they
would be very helpful in hiring the best candidate for the role.</p><p>The question we really want to finetune our coding challenge to answer is "How
good of a technical contributor to our projects would the candidate be?". Note
that "technical contributor" can mean more than just coding ‒ a good take-home
coding assignment can teach the company about more aspects of a candidate's
profile than just their ability to write code.</p><p>Ideally, the challenge is calibrated and flexible enough that it allows
detecting outstanding candidates. Identifying highly desirable people early in
the process can help in ultimately hiring them, e.g. by shortening the process
later on.</p><p>Finally, all this should be accomplished without damaging the perception of the
company that the candidates go into the process with. A poorly designed or
poorly executed assignment can easily have a net negative value for the company.</p><h2 id="balancing-act">Balancing act</h2><p>As it's clear now, there is a lot at stake here. It's also easy to see where the
potentially vastly different experiences for candidates and reviewers come from.
Their incentives can seem contradictory, and without careful consideration, it's
easy to end up with a test that caters to the needs of one of these audiences,
while ignoring those of the others.</p><p>Can we optimize for everyone's needs, or do we need to sacrifice the experience
or best interest of the candidate, reviewer, or the company? It's not an easy
task and might require significant investment to execute well, but I believe
it's possible to find a balance that satisfies everyone involved.</p><h2 id="the-rules-of-a-good-challenge">The rules of a good challenge</h2><p>We've finally arrived at the bullet point list of Certified Good Advice, based
on my experiences reviewing and solving coding assignments as well as my recent
experience designing one myself. Here is how to make your coding test suck less:</p><h3 id="1-replicate-the-way-you-work-on-code-day-to-day-as-close-as-possible">1. Replicate the way you work on code day-to-day as close as possible.</h3><ul><li><strong>Base the challenge on an existing codebase</strong>, if you hire for a role that
involves working on one. Once hired, the candidate likely won't have to start
new projects from scratch as part of the job, so don't test that skill. It
doesn't have to be a big project but needs at least some parts with a
non-trivial level of complexity to be realistic. Using an existing "base" with
a familiar initial structure makes a world of difference when reviewing as
well. Especially when submissions are based on PRs or commits, it's easy to
focus on the candidate's contributions and filter out the "glue code".</li><li><strong>Align the submission process with your delivery process</strong>. For example, if
you use pull requests to propose and describe code changes, ask the candidates
to submit their solutions as PRs. You will get a glimpse into how well the
candidate adheres to a clearly defined process, how well they communicate and
provide context for their work, prepare changes for review, etc. ‒ much more
than just coding skills.</li><li>Using your standard contribution process means that you can also <strong>use your
standard code review process</strong>. This means assignment reviewers won't have to
switch to a different "mode" when evaluating coding hiring assignment. It
should all end up being easier and fairer.</li></ul><h3 id="2-dont-make-it-too-open">2. Don't make it too open...</h3><ul><li><strong>Lock the fundamental technology choices.</strong> Use the same core frameworks or
libraries you use in your codebase, or the ones you'd like to migrate to. The
exact choice is less important than the fact that all solutions will follow
the same …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://peka.la/pieces/a-coding-challenge-that-sucks-less">https://peka.la/pieces/a-coding-challenge-that-sucks-less</a></em></p>]]>
            </description>
            <link>https://peka.la/pieces/a-coding-challenge-that-sucks-less</link>
            <guid isPermaLink="false">hacker-news-small-sites-25309605</guid>
            <pubDate>Fri, 04 Dec 2020 23:15:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Technologies That’ll Make Your Life Easier]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25309585">thread link</a>) | @dataguy12
<br/>
December 4, 2020 | https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/#page-content | <a href="https://web.archive.org/web/*/https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/#page-content">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img width="1024" height="683" src="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?fit=1024%2C683&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?w=2560&amp;ssl=1 2560w, https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?resize=2048%2C1365&amp;ssl=1 2048w, https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?resize=1620%2C1080&amp;ssl=1 1620w" sizes="(max-width: 1024px) 100vw, 1024px" data-attachment-id="805" data-permalink="https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/1__lfefxoj-ncr1oe0lqmfga/" data-orig-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?fit=2560%2C1707&amp;ssl=1" data-orig-size="2560,1707" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1__lFEFXoJ-NCR1oe0LQMFGA" data-image-description="" data-medium-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1__lFEFXoJ-NCR1oe0LQMFGA-scaled.jpeg?fit=1024%2C683&amp;ssl=1"></p><p>Amazon Web Services (AWS) has simplified much of developers’ workflows and development over the past decade.<br>
AWS allows engineers to command and control cloud-based infrastructure, data, and other technical pieces of infrastructure without the hassle of developing entire frameworks from scratch.</p>
<p>Initially, AWS was launched to take care of online retail operations for Amazon, but it has turned into one of the most used cloud service providers.<br>
It can be essential for small, medium, and large business to keep up to date with all of the new services AWS is rolling out — as you never know what service might simplify your team’s development.</p>
<p>In this piece, we wanted to cover a few great services we’ve found useful over the past few years to help develop and deploy solutions.</p>
<h3>Cognito</h3>
<p><img data-attachment-id="806" data-permalink="https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/png/" data-orig-file="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/unnamed-file.png?fit=499%2C207&amp;ssl=1" data-orig-size="499,207" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cognito.png" data-image-description="" data-medium-file="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/unnamed-file.png?fit=300%2C124&amp;ssl=1" data-large-file="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/unnamed-file.png?fit=207%2C207&amp;ssl=1" loading="lazy" src="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/unnamed-file.png?resize=499%2C207&amp;ssl=1" alt="cognito aws" width="499" height="207" srcset="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/unnamed-file.png?w=499&amp;ssl=1 499w, https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/unnamed-file.png?resize=300%2C124&amp;ssl=1 300w" sizes="(max-width: 499px) 100vw, 499px" data-recalc-dims="1"></p>
<p>From authentication to authorization, this technology offers complete user management for your web applications. Cognito can help you by simplifying your authentication workflow.</p>
<p>It even tracks things like user logins so you can track users who log in for security reasons.</p>
<p>Amazon’s Cognito service collects the user’s profile information into user pools, which a web application uses to configure the access to AWS resources. The data-synchronization feature allows users to access information from any device. This data can also be saved locally while offline.</p>
<p>It can also pair with authentication and authorization APIs and plugins from Facebook and Google to further make things easier for you to manage.</p>
<p><strong>Pricing</strong>: The charges are based on the amount of data in the sync store and synchronization operations. With the free version, companies can save up to 10 GB data and perform 1 million operations for 1 year. Once the administer has completed this 1-year period, Cognito charges 15 cents/GB of sync storage and 15 cents/10,000 sync operations.</p>
<h3>Elastic Beanstalk</h3>
<p><img data-attachment-id="811" data-permalink="https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/1_vsbtn8ilt0lyxmxytmhypa/" data-orig-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_VSbtN8IlT0LYXmXYtmhypA.png?fit=225%2C225&amp;ssl=1" data-orig-size="225,225" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aws elastic beanstalk" data-image-description="" data-medium-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_VSbtN8IlT0LYXmXYtmhypA.png?fit=225%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_VSbtN8IlT0LYXmXYtmhypA.png?fit=225%2C225&amp;ssl=1" loading="lazy" src="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_VSbtN8IlT0LYXmXYtmhypA.png?resize=225%2C225&amp;ssl=1" alt="Aws elastic beanstalk" width="225" height="225" srcset="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_VSbtN8IlT0LYXmXYtmhypA.png?w=225&amp;ssl=1 225w, https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_VSbtN8IlT0LYXmXYtmhypA.png?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 225px) 100vw, 225px" data-recalc-dims="1"></p>
<p>Have you ever wished you could just hit deploy and see your website online without too much configuration? With the service AWS Beanstalk, you can easily deploy your web applications developed in Java, Python, .NET, PHP. and several other languages without having to spend too much time configuring servers.</p>
<p>The Elastic Beanstalk service is used to deploy and scale applications using servers such as Apache, Nginx, and IIS. In order to use this service, you just have to upload the code on AWS, and all of the deployment processes — such as autoscaling, application monitoring, and capacity provisioning and balancing — are handled automatically by beanstalk.</p>
<p>Supported platforms: Elastic Beanstalk offers a variety of platforms for developers to work with, including NodeJS, Java, PHP, Python, and Ruby on Docker containers, and application servers such as Puma and Tomcat.</p>
<p><strong>Pricing</strong>: The charges of running Beanstalk depend on the number of EC2 instances used to handle the web traffic and the bandwidth consumed by your application. With the free version, users can utilize one repository with 100 MB storage for a period of 12 months.</p>
<p>Afterward, plans for companies start from $50/month which offers 12 GB storage, 40 users, 10 servers, and 50 repositories. Individual freelancers can access a package for $15/ month that offers 3 GB storage with 5 users, 3 servers, and 10 repositories.</p>
<h3>EventBridge</h3>
<p><img data-attachment-id="809" data-permalink="https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/1_jnoyrcejkutsmpc8bwldoq/" data-orig-file="https://i2.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_jnOyrcEjkUTsmPc8bwLDoQ.png?fit=427%2C241&amp;ssl=1" data-orig-size="427,241" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="aws event bridge" data-image-description="" data-medium-file="https://i2.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_jnOyrcEjkUTsmPc8bwLDoQ.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i2.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_jnOyrcEjkUTsmPc8bwLDoQ.png?fit=241%2C241&amp;ssl=1" loading="lazy" src="https://i2.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_jnOyrcEjkUTsmPc8bwLDoQ.png?resize=427%2C241&amp;ssl=1" alt="aws event bridge" width="427" height="241" srcset="https://i2.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_jnOyrcEjkUTsmPc8bwLDoQ.png?w=427&amp;ssl=1 427w, https://i2.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_jnOyrcEjkUTsmPc8bwLDoQ.png?resize=300%2C169&amp;ssl=1 300w" sizes="(max-width: 427px) 100vw, 427px" data-recalc-dims="1"></p>
<p>Amazon EventBridge acts as a management layer that coordinates events between different serverless modules by using an event bus with the rules-driven router.</p>
<p>The EventBridge builds over CloudWatchEvents by using the same service API as well as the same endpoint. The service provides way for seamlessly connecting data from the SaaS providers and customer applications.</p>
<p>For those who have built serverless applications, this service allows you to easily manage all your various modules.</p>
<p>Through the direct linking that EventBridge offers users can experience high availability and improved speed for the specific service. EventBrige’s easy setup includes zero coding, and it not only enhances performance but also security. It only takes up to one week of the developer’s time for its deployment. At the moment, the only concern is its limited adoption among SaaS providers.</p>
<p>Supporting platforms: About 10 SaaS partners currently support EventBridge. These include: Symantec, ZENData, SugarCRM, OneLogin, Segment, Saviynt, SignalFx, and Whispir</p>
<p><strong>Pricing</strong> plans: Amazon EventBridge hasn’t provided pricing information for the service online.</p>
<h3>RDS</h3>
<p><img data-attachment-id="810" data-permalink="https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/1_kqnnfytavshgxbuguctoqw/" data-orig-file="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_KqNnfYtaVshGXbuGUCTOQw.png?fit=800%2C500&amp;ssl=1" data-orig-size="800,500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1_KqNnfYtaVshGXbuGUCTOQw" data-image-description="" data-medium-file="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_KqNnfYtaVshGXbuGUCTOQw.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_KqNnfYtaVshGXbuGUCTOQw.png?fit=500%2C500&amp;ssl=1" loading="lazy" src="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_KqNnfYtaVshGXbuGUCTOQw.png?resize=800%2C500&amp;ssl=1" alt="" width="800" height="500" srcset="https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_KqNnfYtaVshGXbuGUCTOQw.png?w=800&amp;ssl=1 800w, https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_KqNnfYtaVshGXbuGUCTOQw.png?resize=300%2C188&amp;ssl=1 300w, https://i1.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_KqNnfYtaVshGXbuGUCTOQw.png?resize=768%2C480&amp;ssl=1 768w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1"></p>
<p>With the Amazon RDS service, you can generate dedicated instances for your database in a matter of minutes. These instances are supported by AWS’s support team — which is also capable of supporting multiple different database engines, such as SQL Server, PostgreSQL, and MySQL.<br>
This takes away the hassle of needing to buy a new server every time you need to spin up a new instance. Need a test or dev instance? Done.<br>
The Relational Database Service (RDS) allows users to create and operate with relational databases that can be managed through any AWS management console. Moreover, using RDS allows you to access databases and files from anywhere in a very cost-effective and highly scalable manner. RDS offers high availability for primary instance — which are made synchronous with the secondary instance so you can fail over to the exact point at which a problem occurs.</p>
<p>Supporting platforms: Amazon RDS currently supports MariaDB, Oracle, MySQL, PostgreSQL, and the Microsoft SQL server. Each of these database engines have their own support features.</p>
<p><strong>Pricing</strong>: The free tier is valid for 12 months in which you can get 5 GB of storage, 750 RDS hours, and a 25 GB DynamoDB. Afterward, pricing is based on the services and storage you choose.</p>
<h3>CloudTrail</h3>
<p><img data-attachment-id="808" data-permalink="https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/1_bxmgutm2almdqkyyh0iycw/" data-orig-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_BxMGUTM2ALMdqkYyh0Iycw.png?fit=281%2C179&amp;ssl=1" data-orig-size="281,179" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1_BxMGUTM2ALMdqkYyh0Iycw" data-image-description="" data-medium-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_BxMGUTM2ALMdqkYyh0Iycw.png?fit=179%2C179&amp;ssl=1" data-large-file="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_BxMGUTM2ALMdqkYyh0Iycw.png?fit=179%2C179&amp;ssl=1" loading="lazy" src="https://i0.wp.com/www.theseattledataguy.com/wp-content/uploads/2019/12/1_BxMGUTM2ALMdqkYyh0Iycw.png?resize=281%2C179&amp;ssl=1" alt="" width="281" height="179" data-recalc-dims="1"></p>
<p>Amazon’s CloudTrail service enables enterprises to carry out operational auditing, risk auditing, compliance, and governance for their AWS account.<br>
With this service, you can monitor and retain account activity across your entire AWS infrastructure. The overall service simplifies troubleshooting, security analysis, and resource tracking.</p>
<p>With the multiregion configuration feature, you can deliver log files into multiple regions with a single Amazon S3 bucket, which applies configuration across all regions consistently.</p>
<p>Once enabled, the CloudTrail service is always on as it records account activity upon creation. You can view/download files of the last 90 days and modify operations without having to manually set up the Amazon CloudTrail service.</p>
<p>Supporting platforms: CloudTrail supports logging events for almost all AWS services, including Alexa, Amazon API Gateway, App Mesh, Amazon Athena, AppStream 2.0, and Cloud9.</p>
<p><strong>Pricing</strong>: The CloudTrail service is free of charge for 90 days — you can view, download, and filter the account activity in this time. Afterward, you can get management events at $2/100,000 events, record data events for $0.10/100,000 events, and get insights for $0.35/100,000 events’ analysis.</p>
<p>Final Thoughts</p>
<p>AWS offers many more services as well, but the primary objective of this article was to highlight some well-known as well as lesser-known services that Amazon offers to cloud users.</p>
<p>Currently, if there is some redundant task developers need to constantly do over and over again that’s a hassle, AWS probably has a service for it.</p>
<p>If you liked this post, then feel free to read the posts below!</p>
<p><a href="http://www.acheronanalytics.com/acheron-blog/data-science-use-cases-that-are-improving-the-finance-industry">How Data Science Can Improve The Finance Industry&nbsp;</a></p>
<p><a href="https://www.theseattledataguy.com/4-skills-data-scientist-must-have/">4 Must Have Skills For Data Scientists</a></p>
<p><a href="https://www.theseattledataguy.com/the-advantages-healthcare-providers-have-in-healthcare-analytics/">The Advantages Healthcare Providers Have In Healthcare Analytics</a></p>
<p><a href="https://medium.com/better-programming/the-software-engineering-study-guide-bac25b8b61eb">142 Resources for Mastering Coding Interviews</a></p>
<p><a href="https://www.coriers.com/25-of-the-best-data-science-courses-online/">Learning Data Science: Our Top 25 Data Science Courses</a></p>
<p><a href="https://www.coriers.com/the-last-python-tutorial-you-will-ever-need-to-watch/">The Best And Only Python Tutorial You Will Ever Need To Watch</a></p>

    </div></div>]]>
            </description>
            <link>https://www.theseattledataguy.com/5-aws-technologies-thatll-make-your-life-easier/#page-content</link>
            <guid isPermaLink="false">hacker-news-small-sites-25309585</guid>
            <pubDate>Fri, 04 Dec 2020 23:13:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I keep a personal log of bugs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25309120">thread link</a>) | @ColinWright
<br/>
December 4, 2020 | https://josemdev.com/articles/why-i-keep-a-personal-log-of-bugs/ | <a href="https://web.archive.org/web/*/https://josemdev.com/articles/why-i-keep-a-personal-log-of-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://josemdev.com/images/apple-black-and-white-black-and-white-169573.jpg" alt="Notebook" title="Notebook">
<span>Photo by <a target="_blank" href="https://www.pexels.com/@negativespace">Negative Space</a></span></p><p><br>When creating software, you’ll make mistakes. Sometimes they’ll be huge, sometimes they’ll be small but you can always learn from them if you spend some extra time documenting them.</p><p>After working for more 10 years as a software engineer I’ve realized it doesn’t change. You might develop some techniques to prevent some from happening but others will show up, it never ends.</p><p>In order to learn from those mistakes and try to avoid them in the future you can develop a bug log. We’ll see here what that is and how it works but I promise it helps.</p><p>I recently introduced this idea at <a href="https://buffer.com/">Buffer</a> where I’ve been working for almost 5 years now and I thought it’d be cool to share it publicly here as well.</p><h2 id="the-endless-cycle-of-software-development">The (endless) cycle of software development</h2><pre><code>1. Work on a new feature
2. Fix bug(s)
3. Go back to 1.
</code></pre><p>Sometimes you might focus on only developing new features or only fixing bugs but those are the biggest chunks of your work if you’re building software.</p><p>I think we focus a lot on the how to develop more effectively new features: using the latest framework, text editor or IDE, a new programming paradigm, etc. and when we build something new again, we try to apply the things we’ve learnt and improve.</p><p>On the other hand, when we fix a bug, we tend to do it as quick as possible and then move on to something else, almost like it didn’t happen in the first place. Very few people spend any time trying to learn new debugging techniques instead of learning the latest framework that came out.</p><p>If we spent more time reflecting on those errors, learning from them and understanding where they came from we could improve a lot.</p><h2 id="documenting-a-personal-mistake">Documenting a personal mistake</h2><p>I’ve started to document those bugs, only the ones where I was the only engineer who did it so I can totally understand the context and reflect on what I personally did.</p><p>There are many different ways to do this, but I thought it’d be cool to have one place where I can gather all of them and search in the future for references and patterns. I don’t know if the term already exist but I called it the “bug log”. 🤷‍♂️ 😅</p><h2 id="what-s-a-bug-log">What’s a bug log?</h2><p>A bug log is a collection of your past introduced bugs with different sections for each bug:</p><ul><li>The context where the bug was introduced and what you were trying to achieve (fixing another bug, adding a new feature, etc).</li><li>Why the bug happened. What was wrong in production that made you realize that there was a bug.</li><li>How you fixed it.</li><li>The lesson you learned afterwards. A summary of what you’ve learned in the process.</li></ul><p>These sections are the ones that work for me, but feel free to adapt them to your needs if you want to start a bug log.</p><h2 id="an-example-of-an-entry-in-the-bug-log">An example of an entry in the bug log</h2><div><pre><code data-lang="md"><span># Context
</span><span></span>When working on this JIRA ticket ____, trying to track an action on the backend,
I merged the pull request and it failed in production in a certain environment.

<span>-</span> Link to ticket: ....
<span>-</span> Link to pull request: ....

<span># Why the bug happened
</span><span></span>The environment variable was not set in one of the environments and that caused
an error in production.

<span># How I fixed it.
</span><span></span>I created the new environment variable by doing X and Y.

<span># Lesson learned.
</span><span></span>When using an environment variable make sure it's available in all the environments
before deploying.</code></pre></div><p>As you can see it’s not anything formal and it’s just for you so feel free to use the format and tone that makes the most sense.</p><p>The nice aspect about this is that if I see this becomes a pattern like if I introduced more than one bug of this type in the next year or so, I can work on a better solution. For example, a parser that compares the env. variables used in a new pull request with the ones that are in production.</p><h2 id="where-do-i-store-the-bug-log">Where do I store the bug log?</h2><p>I’ve become a big fan of <a href="https://notion.so/">Notion</a> and I’ve added it there so other team members can see it but it could be anywhere, any note-taking app or even a Github repo with some markdown files could work.</p><h2 id="what-to-do-with-the-lesson-learned-sections">What to do with the “lesson learned” sections?</h2><p>Something I’ve realized is that by summarizing in one sentence the bug I introduced and why I can easily reflect and learn the lesson. I’ve taken one extra step to not forget it for the future so I use <a href="https://apps.ankiweb.net/" target="_blank">Anki</a>, a solution for reviewing cards from time to time, helping you learn what’s in the card.</p><p>I used it before for other purposes but I created a new collection for this. What I do is creating a card whose front is the situation I faced when I introduced the bug and the back is the lesson learned. For example, here it’d be:</p><pre><code>Front
--------
What should I do when I use an environment variable in the code?

Back
--------
Check by doing X/Y if it's set in the right environments.
</code></pre><p>Here’s how it looks in Anki:</p><p><img src="https://josemdev.com/images/anki-bug-log.png" alt="Anki Bug Log" title="Anki Bug Log"></p><p>This will reinforce my learning and it’s easier that I remember it in the future. It can also include some code samples so you associated the situation to new code that you’ll be modifying in the future.</p><p>I’m a big fan of <a href="https://apps.ankiweb.net/" target="_blank">Anki</a> and how it can help you improve as an engineer so I’ll write an article about it soon.</p><p>The other thing I do is before filling a new entry, I can try to search in the log something similar. Sometimes that helps me understand if I tend to make the same kind of mistakes.</p><p><br>I hope this was useful to you! Do you have any thoughts or feedback? Let me know <a href="https://twitter.com/gilgado_">on Twitter</a>! 😉</p></div></div>]]>
            </description>
            <link>https://josemdev.com/articles/why-i-keep-a-personal-log-of-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25309120</guid>
            <pubDate>Fri, 04 Dec 2020 22:27:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feature Engineering and Selection: A Practical Approach for Predictive Models]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25308515">thread link</a>) | @kylebenzle
<br/>
December 4, 2020 | http://www.feat.engineering/intro-intro.html | <a href="https://web.archive.org/web/*/http://www.feat.engineering/intro-intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">
<div id="intro-intro">

<p>Statistical models have gained importance as they have become ubiquitous in modern society. They enable us by generating various types of predictions in our daily lives. For example, doctors rely on general rules derived from models that tell them which specific cohorts of patients have an increased risk of a particular ailment or event. A numeric prediction of a flight’s arrival time can help understand if our airplane is likely to be delayed. In other cases, models are effective at telling us what is important or concrete. For example, a lawyer might utilize a statistical model to quantify the likelihood that potential hiring bias is occurring by chance or whether it is likely to be a systematic problem.</p>
<p>In each of these cases, models are created by taking existing data and finding a mathematical representation that has acceptable fidelity to the data. From such a model, important statistics can be estimated. In the case of airline delays, a prediction of the outcome (arrival time) is the quantity of interest while the estimate of a possible hiring bias might be revealed through a specific model parameter. In the latter case, the hiring bias estimate is usually compared to the estimated uncertainty (i.e., noise) in the data and a determination is made based on how uncommon such a result would be relative to the noise–a concept usually referred to as “statistical significance.” This type of model is generally thought of as being <em>inferential</em>: a conclusion is reached for the purpose of understanding the state of nature. In contrast, the prediction of a particular value (such as arrival time) reflects an <em>estimation problem</em> where our goal is not necessarily to understand if a trend or fact is genuine but is focused on having the most accurate determination of that value. The uncertainty in the prediction is another important quantity, especially to gauge the trustworthiness of the value generated by the model.</p>
<p>Whether the model will be used for inference or estimation (or in rare occasions, both), there are important characteristics to consider. <em>Parsimony</em> (or simplicity) is a key consideration. Simple models are generally preferable to complex models, especially when inference is the goal. For example, it is easier to specify realistic distributional assumptions in models with fewer parameters. Parsimony also leads to a higher capacity to interpret a model. For example, an economist might be interested in quantifying the benefit of postgraduate education on salaries. A simple model might represent this relationship between years of education and job salary linearly. This parameterization would easily facilitate statistical inferences on the potential benefit of such education. But suppose that the relationship differs substantially between occupations and/or is not linear. A more complex model would do a better job at capturing the data patterns but would be much less interpretable.</p>
<p>The problem, however, is that <strong>accuracy should not be seriously sacrificed for the sake of simplicity</strong>. A simple model might be easy to interpret but would not succeed if it does not maintain acceptable level of faithfulness to the data; if a model is only 50% accurate, should it be used to make inferences or predictions? Complexity is usually the solution to poor accuracy. By using additional parameters or by using a model that is inherently nonlinear, we might improve accuracy but interpretability will likely suffer greatly. This trade-off is a key consideration for model building.</p>
<p>Thus far the discussion has been focused on aspects of the model. However, the variables that go into the model (and how they are represented) are just as critical to success. It is impossible to talk about modeling without discussing models, but one of goal this book is to increase the emphasis on the predictors in a model.</p>
<p>In terms of nomenclature, the quantity that is being modeled or predicted is referred to as either: the <em>outcome</em>, response, or dependent variable. The variables that are used to model the outcome are called the <em>predictors</em>, <em>features</em>, or independent variables (depending on the context). For example, when modeling the sale price of a house (the outcome), the characteristics of a property (e.g., square footage, number of bed rooms and bath rooms) could be used as predictors (the term features would also be suitable). However, consider artificial model terms that are composites of one or more variables, such as the number of bedrooms <em>per</em> bathroom. This type of variable might be more appropriately called a feature (or a derived feature). In any case, features and predictors are used to explain the outcome in a model<a href="#fn4" id="fnref4"><sup>4</sup></a>.</p>
<div>

<p>
Figure 1.1: Houses for sale in Ames, Iowa, colored by neighborhood.
</p>
</div>
<p>As one might expect, there are good and bad ways of entering predictors into a model. In many cases, there are multiple ways that an underlying piece of information can be represented or encoded. Consider a model for the sale price of a property. The location is likely to be crucial and can be represented in different ways. Figure <a href="http://www.feat.engineering/intro-intro.html#fig:intro-Ames">1.1</a> shows locations for properties in and around Ames Iowa, that were sold between 2006 and 2010. In this image, the colors represent the reported neighborhood of residence. There are 28 neighborhoods represented here and the number of properties per neighborhoods range from a single property in Landmark, to 443 in North Ames. A second representation of location in the data is longitude and latitude. A realtor might suggest using ZIP code as a predictor in the model as a proxy for school district since this can be an important consideration for buyers with children. But from an information theory point of view, longitude and latitude offer the most specificity for measuring physical location and one might make an argument that this representation has higher information content (assuming that this particular information is predictive).</p>
<p>The idea that there are different ways to represent predictors in a model, and that some of these representations are better than others, leads to the idea of <strong>feature engineering</strong> - the process of creating representations of data that increase the effectiveness of a model.</p>
<p>Note that model effectiveness is influenced by many things. Obviously, if the predictor has no relationship to the outcome then its representation is irrelevant. However, it is very important to realize that there are a multitude of types of models and that each has its own sensitivities and needs. For example:</p>
<ul>
<li>Some models cannot tolerate predictors that measure the same underlying quantity (i.e., multicollinearity or correlation between predictors).</li>
<li>Many models cannot use samples with any missing values.</li>
<li>Some models are severely compromised when irrelevant predictors are in the data.</li>
</ul>
<p>Feature engineering and variable selection can help mitigate many of these issues. <strong><em>The goal of this book is to help practitioners build better models by focusing on the predictors</em></strong>. “Better” depends on the context of the problem but most likely involves the following factors: accuracy, simplicity, and robustness. To achieve these characteristics, or to make good trade-offs between them, it is critical to understand the interplay between predictors used in a model and the type of model. Accuracy and/or simplicity can sometimes be improved by representing data in ways that are more palatable to the model or by reducing the number of variables used. To demonstrate this point, a simple example with two predictors is shown in the next section. Additionally, a more substantial example is discussed in Section <a href="http://www.feat.engineering/a-more-complex-example.html#a-more-complex-example">1.3</a> that more closely resembles the modeling process in practice.</p> 
</div>

            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>http://www.feat.engineering/intro-intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308515</guid>
            <pubDate>Fri, 04 Dec 2020 21:44:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Runner: a lightweight wrapper for cron jobs]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25308141">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://www.dzombak.com/blog/2020/12/Introducing-Runner--a-lightweight-wrapper-for-cron-jobs.html | <a href="https://web.archive.org/web/*/https://www.dzombak.com/blog/2020/12/Introducing-Runner--a-lightweight-wrapper-for-cron-jobs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<header>
				
				
				<time pubdate="" datetime="2020-12-04T13:39:32-05:00">
					<span>December</span>
					<span>04</span>
					<span>2020</span>
				</time>
				
			</header>
			
			<p><em>It’s been a while since I blogged anything here, but that doesn’t mean I haven’t done anything in the past couple years! Over the next months, I’m going to try to make some posts about the various projects I’ve worked on recently.</em></p>

<p>On my personal servers, I have quite a number of cron jobs that do useful things for me (notably, running <a href="https://github.com/cdzombak/gmail-cleaner">gmail-cleaner</a>, which will be the subject of another blog post in the future). These machines send me the output from these jobs <a href="https://web.archive.org/web/20201204185837/https://www.jamroom.net/brian/documentation/guides/1312/set-up-postfix-with-mailgun-for-reliable-e-mail-delivery">via email</a>. But with a large number of jobs — I have something like 10 or 20 <code>gmail-cleaner</code> jobs — this gets noisy. I really only want to get these emails if a job fails, or if it produces some interesting output. One can work around this problem (say, by redirecting standard output but not standard error to <code>/dev/null</code>), but this only works to a point. Some programs have output behavior that’s incompatible with this solution, and to filter out all but a certain output one needs to add <code>grep</code> into the shell command, and it gets unwieldy quickly.</p>

<p><strong>Enter <a href="https://github.com/cdzombak/runner"><code>runner</code></a>.</strong> This is a pretty simple program which can wrap a command and swallow its output, unless certain conditions are met. It’s written in Go to simplify deployment and cross-compilation.</p>

<p>By default, it only prints the command’s output if the command returns a nonzero exit code (ie. it fails). You can tell it to treat certain other exit codes as healthy, and to print the output if it contains (or doesn’t contain) a specific string. It can write the command’s output to a log directory, regardless of how the command exited; and it can also print the command’s environment as part of the output, which is useful for debugging.</p>

<p><a href="https://github.com/cdzombak/runner#usage">The README</a> covers these features in some detail, so let’s examine a couple real-world uses from my <code>crontab</code>s:</p>

<pre><code>RUNNER_LOG_DIR=/home/cdzombak/log/runner

*/30    *   *   *   *   runner -work-dir /home/cdzombak/changedetection -- ./env/bin/urlwatch
</code></pre>

<p>This example runs <a href="https://web.archive.org/web/20201204190811/https://urlwatch.readthedocs.io/en/latest/#"><code>urlwatch</code></a> every 30 minutes. The output gets printed &amp; emailed to me only if <code>urlwatch</code> returns with a nonzero exit code. If that happens, the resulting email also contains the environemt in which <code>urlwatch</code> ran. Regardless of whether <code>urlwatch</code> ran successfully, the output is always written to a timestamped file in <code>/home/cdzombak/log/runner</code>.</p>

<pre><code>RUNNER_LOG_DIR=/home/cdzombak/log/runner

04  */6 *   *   *   runner -print-if-not-match "0 entries affected" -hide-env -work-dir /home/cdzombak/scripts/feedbin-auto-archiver -job-name "Feedbin Archiver" -- ./venv/bin/python3 ./feedbin_archiver.py --rules-file /home/cdzombak/Sync/feedbin-archiver-rules.json --dry-run false
</code></pre>

<p>This sample demonstrates a few more of <code>runner</code>’s features! This’ll run my <a href="https://github.com/cdzombak/feedbin-auto-archiver">automatic Feedbin archiver</a> (another topic for a future post) a few times per day. Output is emailed to me if <code>feedbin_archiver.py</code> fails, or if its output <em>doesn’t contain</em> the string <code>0 entries affected</code> — that is, I get an email when this program does touch anything in my Feedbin account. This email doesn’t contain the environment in which <code>feedbin_archiver.py</code> ran. Finally, as before, the output is always written to a timestamped file in <code>/home/cdzombak/log/runner</code>.</p>

<hr>

<p>I think that covers the most important points. If you find yourself wanting to manage the output from a bunch of cron jobs, consider giving <a href="https://github.com/cdzombak/runner"><code>runner</code></a> a try.</p>

			
		</article></div>]]>
            </description>
            <link>https://www.dzombak.com/blog/2020/12/Introducing-Runner--a-lightweight-wrapper-for-cron-jobs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308141</guid>
            <pubDate>Fri, 04 Dec 2020 21:17:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Down Here, They Sometimes Call It 'Boy']]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25308101">thread link</a>) | @pelt
<br/>
December 4, 2020 | https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html | <a href="https://web.archive.org/web/*/https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                            

                                                        <!-- sphereit start -->
                            <!-- startprint -->

                            <!-- end article source sponsored -->

                                                                                                                                                                                                                                                                                                    
                                                                                        
                            
                            
                            
                            
                                
                                
                                                                                        
                                                            <div>
<p><a href="https://www.amazon.com/stores/page/60E52DB6-B5F7-48D8-8FC5-73A5CE8F8AF4"> <img src="https://assets.realclear.com/images/52/527328_5_.jpg"> </a></p>

<p>Regnery Publishing</p>


</div>
<p><em>The following is an excerpt from "<a href="https://www.amazon.com/stores/page/60E52DB6-B5F7-48D8-8FC5-73A5CE8F8AF4">Big White Ghetto: Dead Broke, Stone-Cold Stupid, and High on Rage in the Dank Woolly Wilds of the "Real America"</a>" by Kevin D. Williamson.</em></p>
<p>"Dogfood—yeah, <em>d</em><em>o</em><em>g</em><em>f</em><em>o</em><em>o</em><em>d</em>—because it looks like ground-up dog food.” He’s embarrassed to be talking about this. “Or sand, because it’s brown. Or diesel. Or killa or 9-1-1. That’s the influence of rap culture down here.” He is a young, clean-cut, Eagle Scout–ish white kid, hesitant about using the words “rap culture,” like he’s not sure if he’s allowed to say that. But he goes on, matter-of-factly. He’s been off heroin for only a few months, so the details are fresh in his mind, even if he remains a little hazy on parts of his autobiographical timeline. “The 9-1-1, they call it that because they want you to know it’s potent, that you’ll have to go to the emergency room.”</p>
<p>That’s a weird and perverse and nasty kind of advertising, but then dope-buying psychology isn’t very much like Volvo-buying psychology: Crashing is just another part of the ride. One spiteful dealer boasts about spiking his product with excessive amounts of fentanyl—a pharmaceutical analgesic used for burn victims and cancer patients—his plan being to intentionally send overdosed users to the hospital or the morgue . . . for <em>m</em><em>a</em><em>r</em><em>k</em><em>e</em><em>t</em><em>i</em><em>n</em><em>g</em> <em>p</em><em>u</em><em>r</em><em>p</em><em>os</em><em>e</em><em>s</em>. Once the word got out about the hideous strength of his product, that killa went right out the door ricky-tick.</p>
<p>The young man explaining the current vocabulary of opiate addiction in Birmingham is barely old enough to buy a beer, and his face and voice are soft. He describes the past several years of his life: “dope-sick and stealing,” going from job to job—eight jobs in six months—robbing his employers of everything not physically nailed to the floor, alienating his family, descending. He was an addict on a mission: “You’re always chasing that first shot of dope, that first high—and the first one for me almost killed me. I was seventeen or eighteen years old, and I met a guy who had just got out of prison, doing a thirteen-year sentence for heroin possession and distribution. He was staying at the Oak Mountain Lodge, which is a nice little classic place.” (In 2013, four police officers and a drug dog had to be treated for exposure to dangerous chemicals after raiding a suspected meth lab in that hotel; the customer reviews online are decidedly mixed.) “I was <em>snorting </em>heroin when I met up with him, and set him up with my connect. He offered to shoot me up, and I wanted to do it. And I remember him looking me in the eyes and telling me, ‘If you do this, you’ll never stop, and you’ll never go back.’ And I said, ‘Let’s do it.’”</p>
<p>He doesn’t know what happened for the next several hours. When he regained consciousness, his junkie buddy’s girlfriend was worriedly ministering to him.</p>
<p>“That was first thing in the morning,” he says. “That night, I did another one.”</p>
<p>Same results. “I’d nodded out from snorting it, but there’s nothing like shooting it.”</p>
<p>He was, he says, a “pretty good junkie” for a time.</p>
<p>This particular opiate odyssey starts off in a Walgreens, something that turns out to be absolutely appropriate. I’m headed up the south coast and then inland on the heroin highway up to Atlanta, starting from the Port of Houston, which connects that city with 1,053 ports in nearly 200 countries and which in December alone welcomed the equivalent of 63,658 20-foot cargo containers of goods into the United States. There was, the feds are pretty sure, some dope squirreled away in there. In fact, all sorts of interesting stuff comes in and out of Houston. In May, U.S. Customs seized a Fast Attack Vehicle with gun mounts headed to the Netherlands. It hadn’t been ordered by the Dutch military. (Organized crime in the Netherlands is bananas: A raid in the summer of 2020 found Dutch police opening up a shipping container expecting to find it loaded with narcotics or stolen goods, but what they found instead was a dentist’s chair bolted to the floor and handcuffs hanging overhead—it was set up as a mobile torture chamber, God knows why.) I’m at Walgreens because I’ve got a long drive ahead and I’m going to be out of pocket for a bit, and I have a prescription to fill: an honest-to-goodness Schedule II Controlled Substance, in the official nomenclature, a term that covers some pretty interesting stuff, including the oxycodone and fentanyl I’ll be hearing so much about in the next few days. Some of us are going to heaven, some of us are going to hell, but all of us have to stop at Walgreens first.</p>
<p>The clerk is on the phone with a doctor’s office: “What’s your DEA number?”</p>
<p>For working-class white guys who haven’t found their way into the good jobs in the energy economy or the related manufacturing and construction booms that have reverberated throughout the oil patch, who aren’t college-bound or in possession of the skills to pay the bills, things aren’t looking so great: While much of the rest of the world gets healthier and longer-lived, the average life expectancy for white American men without college educations is declining. Angus Deaton, the Princeton economist who won the Nobel Prize in 2015, ran the numbers and found (in a study co-authored by his Princeton colleague Anne Case) that what’s killing what used to be the white working class isn’t diabetes or heart disease or the consumption of fatty foods and Big Gulps that so terrifies Michael Bloomberg, but alcohol-induced liver failure, along with overdoses of opioid prescription painkillers and heroin: Wild Turkey and hillbilly heroin, and regular old heroin, too, the use of which has increased dramatically in recent years as medical and law-enforcement authorities crack down on the wanton overprescription of oxy and related painkillers.</p>
<p>Which is to say: While we were <em>ignoring </em>criminally negligent painkiller prescriptions, we helped create a gigantic population of opioid addicts, and then, when we started paying attention, the first thing we did was take away the legal (and quasi-legal) stuff produced to exacting clinical standards by Purdue Pharma (maker of OxyContin) and others. So: lots of opiate addicts, fewer prescription opiates.</p>
<p>What was left was diesel, sand—<em>d</em><em>o</em><em>g</em><em>f</em><em>o</em><em>o</em><em>d</em>.</p>
<p>The clerks at this Walgreens are super friendly, but the place is set up security-wise like a bank, and that’s to be expected. This particular location was knocked over by a young white man with a gun the summer before last, an addict who had been seen earlier lurking around the CVS down the road. This is how you know you’re a pretty good junkie: The robber walked in and pointed his automatic at the clerk and demanded oxy first, then a bottle of Tusinex cough syrup, and then, almost as an afterthought, the $90 in the till. Walgreens gets robbed a lot: In January, armed men stormed the Walgreens in Edina, Minnesota, and stole $8,000 worth of drugs, mainly oxy. In October, a sneaky young white kid in an Iowa State sweatshirt made off with more than $100,000 worth of drugs—again, mainly oxy and related opioid painkillers, from a Walgreens in St. Petersburg, Florida. Other Walgreens locations—in Liberty, Kansas; East Bradford, Pennsylvania; Elk Grove, California; Kaysville, Utah; Virginia Beach; New Orleans—all have been hit by armed robbers or sneak thieves over the past year or so, and there have been many more oxy thefts.</p>
<p>It won’t make the terrified clerks feel any better, but there’s poetic justice in that: In 2013, Walgreens paid the second-largest fine ever imposed under the Controlled Substances Act for being so loosey-goosey in handling oxy at its distribution center in Jupiter, Florida, that it enabled untold quantities of the stuff to reach the black market. The typical pharmacy sells 73,000 oxycodone pills a year; six Walgreens in Florida were going through more than 1 million pills a year—each. A few years before that, Purdue was fined $634.5 million for misleading the public about the addictiveness of oxycodone. Kentucky, which has been absolutely ravaged by opiate addiction, is still pursuing litigation against Purdue, and it has threatened to take its case all the way to the Supreme Court, if it comes to that.</p>
<p>Ground Zero in the opiate epidemic isn’t some exotic Taliban-managed poppy field or some cartel boss’s fortified compound: It’s right there at Walgreens, in the middle of every city and town in the country.</p>
<p>I pick up my prescription and get on my way.</p>
<p>The next afternoon, having driven past billboards advertising boudin and strip joints with early-bird lunch specials and casino after casino after sad little casino; help-wanted signs for drilling-fluid businesses and the Tiger Truck Stop (which has a twenty-four-hour Cajun café and an actual no-kidding <em>live tiger </em>in a cage out front); past Whiskey Bay and Contraband Bayou, where the pirate Jean Lafitte once stashed his booty; around the Port of New Orleans, another <em>entrepôt </em>for heroin and cocaine—it is almost as close to Cartagena as it is to New York—I arrive at a reasonably infamous New Orleans drug corner, where I inquire as discreetly as I can about the availability of prescription …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html">https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html</a></em></p>]]>
            </description>
            <link>https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308101</guid>
            <pubDate>Fri, 04 Dec 2020 21:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the builder pattern to define test scenarios]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25308079">thread link</a>) | @todsacerdoti
<br/>
December 4, 2020 | https://jmmv.dev/2020/12/builder-pattern-for-tests.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/12/builder-pattern-for-tests.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article><p>I’ve been playing with the builder patter to express test scenarios in a succinct and declarative manner. I’ve liked the outcome and feel that this design can yield to pretty good test code, so I’ll dig through this idea here. Note that, while this post and the associated code talk about Rust, <strong>the ideas presented here apply to any language</strong>. So don’t leave just because I said Rust!</p>
<hr>
<p>While Rust provides excellent facilities to execute unit and integration tests via <code>cargo test</code>, the APIs to write such tests are… extremely limited. In essence, we can tag tests functions with <code>#[test]</code> and we can then use the <code>assert*</code> family of macros plus <code>unwrap()/expect()</code> calls to validate values. But that’s about it. No fixtures. No <a href="https://junit.org/junit5/">JUnit-like advanced features</a>. No <a href="https://truth.dev/">Truth-like expressive assertions</a>. No nothing.</p>
<p>These limitations, and in particular the lack of fixtures, can lead to convoluted test code. The fact is that some tests, even if they are true unit tests, require quite a bit of boilerplate: prepare fake objects with golden values, inject those into the code under test, and validate results. If we want to adhere to the principle of making each individual test case (aka each <code>#[test]</code> function) focus on a single behavior, we find ourselves with a lot of code duplication. Code duplication blurs the essence behind each test, which then makes tests harder to maintain—and hard to maintain tests is something you <em>really</em> do not want in a codebase.</p>
<p>To mitigate these limitations and keep the content of test functions focused on behavior, I’ve found myself writing helpers of the form <code>do_ok_test_for_blah()</code>. These helpers wrap the <code>blah()</code> under test and abstract away all of the uninteresting setup/teardown noise, customizing these based on input parameters.</p>
<p>The problem is that functions like <code>do_ok_test_for_blah()</code> quickly become complex. As you add more test cases, the amount of parameters to pass to these functions grows too, and the tests that used to be succinct aren’t any more. To compensate, you might add extra functions like <code>do_ok_test_for_blah_with_bleh()</code> that provide even further wrapping… but then you end up with a real mess that goes counter the original goal of simplifying the test code. Mind you, a lot of the older tests in EndBASIC suffer from this problem and it’s a pain to touch them, so I had to find a solution.</p>
<p>Of course, there are crates out there to provide extra testing facilities for Rust. But how far can we get with the simple Rust primitives? Pretty far actually.</p>
<blockquote>
<p>What if we used the builder pattern to define the test scenario with required and optional properties, set expectations in a declarative manner, and then hid the test logic within it?</p>
</blockquote>
<p>The idea is to define a <em>type</em> (or <code>struct</code>, or <code>class</code>, or whatever your language of choice offers to encapsulate data) that holds all details needed to set up a test and also carries the expectations of the test. The type requires the minimum amount of parameters to run a “null” test scenario, and allows passing all other parameters in an optional manner. Lastly, a single <code>run()</code>-like function takes care of preparing the test scenario and running through it.</p>
<hr>
<p>Let’s illustrate all these words with a trivial example.</p>
<p>Consider a simple and non-generic <code>sum_all</code> function that takes an array of <code>i32</code> values and sums them all:</p>
<div>
  
  
  <div><pre><code data-lang="rust"><span>#[cfg(test)]</span><span> </span><span>mod</span> <span>tests</span><span>;</span><span>
</span><span>
</span><span></span><span>/// Sums all input `values` and returns the total.
</span><span></span><span>pub</span><span> </span><span>fn</span> <span>sum_all</span><span>(</span><span>values</span>: <span>&amp;</span><span>[</span><span>i32</span><span>])</span><span> </span>-&gt; <span>i32</span> <span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span><span>    </span><span>for</span><span> </span><span>v</span><span> </span><span>in</span><span> </span><span>values</span><span> </span><span>{</span><span>
</span><span>        </span><span>result</span><span> </span><span>+=</span><span> </span><span>v</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>result</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div>
  
  </div>

<p>Yes, this is a simplistic function that can be trivially tested: using the builder pattern here is overkill, but hopefully you get the idea of how this helps verify more complex interfaces.</p>
<p>To test this function, we define a <code>SumAllTest</code> type to represent the builder pattern, with these properties:</p>
<ul>
<li>Given that <code>sum_all()</code> always returns a value, the test must always know what value to expect; therefore, we express this requirement as part of the type’s constructor.</li>
<li>The data to pass to the function is variable, though, so we make it optional via an <code>add_value()</code> method. I’ve chosen to use an accumulator method here to further illustrate how a builder might be helpful.</li>
<li>We define a <code>run()</code> method that <em>consumes the builder</em> and executes the test.</li>
</ul>
<p>Our test code looks like this:</p>
<div>
  
  
  <div><pre><code data-lang="rust"><span>#![deny(warnings)]</span><span>
</span><span>
</span><span></span><span>use</span><span> </span><span>crate</span>::<span>*</span><span>;</span><span>
</span><span>
</span><span></span><span>/// Builder pattern for tests that validate `sum_all`.
</span><span></span><span>#[must_use]</span><span>
</span><span></span><span>struct</span> <span>SumAllTest</span><span> </span><span>{</span><span>
</span><span>    </span><span>expected</span>: <span>i32</span><span>,</span><span>
</span><span>    </span><span>values</span>: <span>Vec</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>,</span><span>
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>impl</span><span> </span><span>SumAllTest</span><span> </span><span>{</span><span>
</span><span>    </span><span>/// Creates the test scenario and initializes it with the result we expect.
</span><span></span><span>    </span><span>fn</span> <span>expect</span><span>(</span><span>value</span>: <span>i32</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span>
</span><span>        </span><span>Self</span><span> </span><span>{</span><span> </span><span>expected</span>: <span>value</span><span>,</span><span> </span><span>values</span>: <span>vec</span><span>!</span><span>()</span><span> </span><span>}</span><span>
</span><span>    </span><span>}</span><span>
</span><span>
</span><span>    </span><span>/// Registers a value to pass to `sum_all` as an input.
</span><span></span><span>    </span><span>fn</span> <span>add_value</span><span>(</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>value</span>: <span>i32</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span>
</span><span>        </span><span>self</span><span>.</span><span>values</span><span>.</span><span>push</span><span>(</span><span>value</span><span>);</span><span>
</span><span>        </span><span>self</span><span>
</span><span>    </span><span>}</span><span>
</span><span>
</span><span>    </span><span>/// Runs `sum_all` with all recorded values and checks the result.
</span><span></span><span>    </span><span>fn</span> <span>run</span><span>(</span><span>self</span><span>)</span><span> </span><span>{</span><span>
</span><span>        </span><span>let</span><span> </span><span>actual</span><span> </span><span>=</span><span> </span><span>sum_all</span><span>(</span><span>&amp;</span><span>self</span><span>.</span><span>values</span><span>);</span><span>
</span><span>        </span><span>assert_eq</span><span>!</span><span>(</span><span>self</span><span>.</span><span>expected</span><span>,</span><span> </span><span>actual</span><span>);</span><span>
</span><span>    </span><span>}</span><span>
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>#[test]</span><span>
</span><span></span><span>fn</span> <span>test_sum_all_with_no_values</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>SumAllTest</span>::<span>expect</span><span>(</span><span>0</span><span>).</span><span>run</span><span>();</span><span>
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>#[test]</span><span>
</span><span></span><span>fn</span> <span>test_sum_all_with_one_value</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>SumAllTest</span>::<span>expect</span><span>(</span><span>5</span><span>).</span><span>add_value</span><span>(</span><span>5</span><span>).</span><span>run</span><span>();</span><span>
</span><span></span><span>}</span><span>
</span><span>
</span><span></span><span>#[test]</span><span>
</span><span></span><span>fn</span> <span>test_sum_all_with_many_values</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>SumAllTest</span>::<span>expect</span><span>(</span><span>8</span><span>).</span><span>add_value</span><span>(</span><span>3</span><span>).</span><span>add_value</span><span>(</span><span>4</span><span>).</span><span>add_value</span><span>(</span><span>1</span><span>).</span><span>run</span><span>();</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div>
  
  </div>

<p>The beauty of this design is that each test case is now declarative. The test case expresses, <em>in code</em>, what the test scenario looks like and what the expectations are. And given the simplicity of the calls, we can trivially express each scenario in its own test case. When we run the tests, we get what we expect:</p>
<div><pre><code data-lang="text">running 3 tests
test tests::test_sum_all_many_values ... ok
test tests::test_sum_all_no_values ... ok
test tests::test_sum_all_one_value ... ok

test result: ok. 3 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
</code></pre></div><p>Great!</p>
<p>But before we go, there is <em>one key detail</em> I glanced over. This detail is critical to ensure that your tests always do the right thing:</p>
<p><strong>IMPORTANT: The test builder has to be annotated with <code>#[must_use]</code>.</strong> You may want also want to accompany that with the optional <code>#[deny(warnings)]</code>.</p>
<p>You see: given the above design, it’s all too easy to forget to call <code>run()</code> on the test builder—and if you forget to do that, the test will do nothing and will always pass. That’s too risky for test code. Fortunately, by using the <code>#[must_use]</code> annotation on the builder type, the compiler will catch such problems.</p>
<p>To witness: if we remove the <code>run()</code> call from any of the tests above and try to build:</p>
<div><pre><code data-lang="text">error: unused `SumAllTest` that must be used
  --&gt; src/tests.rs:33:5
   |
33 |     SumAllTest::expect(0);
   |     ^^^^^^^^^^^^^^^^^^^^^^
   |
</code></pre></div><p>Rust fails the build and tells us that we forgot to consume the builder object. There is no way we can forget to call <code>run()</code> once we have initialized a <code>SumAllTest</code> object, so the test code will always be exercised.</p>
<hr>
<p>What do you think? Interesting? Problematic?</p>
<p>For a more realistic example, check out <a href="https://github.com/jmmv/endbasic/blob/bd15aa4f2ff44c7491e5890976725ddae465d5d6/core/src/console.rs#L703">EndBASIC <code>read_line</code>’s own tests</a>.</p></article>
            </div>
          </div><div>
            <div>
              <p><b>Want more posts like this one? Take a moment to subscribe!</b></p>
            </div>
            <div>
              
              <p>
                  <a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;screen_name=jmmv">
                    <img src="https://jmmv.dev/images/badges/Twitter_logo_blue_32.png" alt="Follow @jmmv on Twitter">
                  </a>
                </p>
              <p><a href="https://jmmv.dev/feed.xml"><img src="https://jmmv.dev/images/badges/feed-icon-28x28.png" alt="RSS feed"></a></p>
            </div>
          </div><div>
            <div>
              <p><b>Enjoyed this article? Spread the word or join the ongoing discussion!</b></p>
            </div>
            
          </div></div>]]>
            </description>
            <link>https://jmmv.dev/2020/12/builder-pattern-for-tests.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308079</guid>
            <pubDate>Fri, 04 Dec 2020 21:14:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PHP8, from a Security Point of View]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25308078">thread link</a>) | @todsacerdoti
<br/>
December 4, 2020 | https://dustri.org/b/php8-from-a-security-point-of-view.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/php8-from-a-security-point-of-view.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="content">
  <article>
    <header>
      
    </header>
    <div>
      <p>PHP8 was <a href="https://www.php.net/releases/8.0/en.php">released</a> on the
26<sup>th</sup> of November 2020. It brought a lot of interesting things,
security-wise, but also showcases a couple of (minor) missed opportunities in my
opinion.</p>
<h2 id="type-safety"><a href="#type-safety">Type safety</a></h2>
<p>I'm a big fan on relying on typing to ensure security properties,
like <a href="https://web.dev/trusted-types/">Trusted types</a> in javascript: it
shouldn't compile if it's not secure.</p>
<p>PHP8 won't try to cast string into numbers anymore, thanks to the 
<a href="https://wiki.php.net/rfc/string_to_number_comparison">Saner string to number comparisons RFC</a>,
meaning that collision with hashes starting with <code>0e</code> and the likes are finally
a thing of the past! This is a subset of Snuffleupagus' <a href="https://snuffleupagus.readthedocs.io/features.html#preventing-sloppy-comparisons">sloppy comparison
prevention</a> feature.</p>
<p>The <a href="https://wiki.php.net/rfc/consistent_type_errors">Consistent type errors for internal functions RFC</a>
will prevent things like <code>0 == strcmp($_GET['username'], $password)</code> bypasses,
since <code>strcmp</code> won't return <code>null</code> and spit a warning any longer,
but will throw a proper exception instead. This was also a <a href="https://externals.io/message/106522">nice opportunity</a>
for PHP to add annotations for functions parameters and return types.</p>
<p>The <a href="https://wiki.php.net/rfc/arithmetic_operator_type_checks">Stricter type checks for arithmetic/bitwise operators</a>
and <a href="https://wiki.php.net/rfc/engine_warnings">PHP RFC: Reclassifying engine warnings</a> RFC
are in the same spirit.</p>
<h2 id="jit"><a href="#jit">JIT</a></h2>
<p>PHP8 comes with a <a href="https://wiki.php.net/rfc/jit">JIT</a> based on
<a href="https://luajit.org/dynasm.html">DynASM</a>, bringing an RWX memory space into
PHP's memory space, into a shared allocation, meaning that its offset won't
change between different PHP8+ processes.</p>
<p>Moreover, DynASM isn't designed with processing/compilation/execution of
untrusted code in mind, and doesn't do things like constants blinding and
advanced folding to mitigate against spraying, nor random padding/nop
insertion, nor ensuring that the memory region is never both writeable <em>and</em>
executable to prevent direct code injection. This means that it's now way
easier to gain native code execution when exploiting memory corruptions,
albeit to be fair, most attackers are happy with a php code execution,
and won't push further.</p>
<p>Having a JIT comes with a lot of code complexity and maintenance burden. I'll
be without doubt a <a href="https://bugs.php.net/search.php?cmd=display&amp;order_by=ts1&amp;direction=DESC&amp;limit=30&amp;package_name[]=JIT">great source of
bugs</a>,
for a minor speed improvement on real-life workloads.</p>
<h2 id="cryptography"><a href="#cryptography">Cryptography</a></h2>
<ul>
<li><code>password_hash</code> now automatically generates a salt, accepting a
    user-provided one is deprecated.</li>
<li><code>crypt</code> will now fail instead of silently falling back to
    <a href="https://en.wikipedia.org/wiki/Crypt_(C)#Traditional_DES-based_scheme">DES</a>
    when an unknown salt format was provided. The parameter is also made
    mandatory, hashing without a salt is now unsupported.</li>
<li><a href="https://tools.ietf.org/html/rfc5652">RFC 5652</a> is now exposed via the OpenSSL extension.</li>
</ul>
<h2 id="misc"><a href="#misc">Misc</a></h2>
<ul>
<li>The <a href="https://www.php.net/manual/en/language.operators.errorcontrol.php">error control operator</a>, aka <code>@</code>
    won't silence fatal errors anymore, meaning that poorly written webshells will have more chances
    to leave traces in your logs.</li>
<li><code>libxml_disable_entity_loader</code> is now deprecated, even if it's not (yet) reflected in php's documentation.
    This is acceptable since PHP8 now requires at least libxml 2.9.0,
    which comes with external entity loading disabled by default.</li>
<li>Access to undefined constants will throw an error, instead of being silently
  interpreted as a string, no more <code>SALT</code> being silently converted to <code>"SALT"</code>.</li>
<li><code>create_function</code> was <a href="https://github.com/php/php-src/commit/ee16d99504f0014c3d292809da927fb622293f41">removed</a>, closing its infamous code injection vector.</li>
<li><code>array_key_exists</code> throws when passed an array/object, instead of silently
  doing nonsense.</li>
<li>The <code>e</code> modifier in <code>mb_ereg_replace</code> has been removed.</li>
<li>Metadata associated with a phar will
  <a href="https://wiki.php.net/rfc/phar_stop_autoloading_metadata">no longer be unserialized</a>,
    killing a low-hanging
    <a href="https://github.com/s-n-t/presentations/blob/master/us-18-Thomas-It's-A-PHP-Unserialization-Vulnerability-Jim-But-Not-As-We-Know-It.pdf">RCE vector</a>.</li>
<li><code>FILTER_SANITIZE_MAGIC_QUOTES</code>, <code>get_magic_quotes_gpc</code> and <code>get_magic_quotes_runtime</code> have been removed,
  people will now have to do proper sanitization instead.</li>
<li>As usual, a couple of memory safety issues were fixed,
    <a href="https://bugs.php.net/bug.php?id=80242">some</a>
    <a href="https://bugs.php.net/bug.php?id=76618">exploitable</a>.</li>
<li><a href="https://github.com/jvoisin/snuffleupagus">Snuffleupagus</a> is currently being
    ported to php8!</li>
</ul>
<h2 id="missed-opportunities"><a href="#missed-opportunities">Missed opportunities</a></h2>
<p><a href="https://wiki.php.net/rfc/engine_warnings#undefined_variable">Undefined
variables</a>, as
opposed to constants, are still not an error, meaning that things like <code>solt</code>
instead of <code>salt</code> might (and will) go unnoticed.</p>
<p>Converting an <code>Array</code> to a string will only yield a <code>Warning</code> instead of an
error, albeit that now that <code>__toString</code> <a href="https://wiki.php.net/rfc/tostring_exceptions">can <em>finally</em>
throw</a>, it might hopefully change
in the near future.</p>
<p>Albeit significant <a href="https://wiki.php.net/rfc/easy_userland_csprng">CSPRNG</a>
<a href="https://wiki.php.net/rfc/random-function-exceptions">improvements</a> have been
merged in PHP7, PHP8 didn't seize the opportunity to keep the momentum and to
aliases <code>rand</code> and <code>mt_rand</code> to <code>random_int</code>, like
<a href="https://snuffleupagus.readthedocs.io/features.html#weak-prng-via-rand-mt-rand">Snuffleupagus</a> is doing.</p>
<p>An other missed opportunity in my opinion is that there is <a href="https://bugs.php.net/bug.php?id=50715">still no
way</a> to disable some <a href="https://www.php.net/manual/en/wrappers.php">PHP's wrappers</a>, except via
<a href="https://www.php.net/manual/en/function.stream-wrapper-unregister.php"><code>stream_wrapper_unregister</code></a>
but this can be reversed with
<a href="https://www.php.net/manual/en/function.stream-wrapper-restore.php"><code>stream_wrapper_restore</code></a>.
Wrappers are scary: the main use I've seen for the <a href="https://www.php.net/manual/en/wrappers.php.php#wrappers.php.filter"><code>filter://</code>
one</a> is
exfiltrating data via <code>php://filter/convert.base64-encode/resource=/some/file</code>, and is a <a href="https://www.netsparker.com/blog/web-security/php-stream-wrappers/">decent
amount of</a>
<a href="https://lightless.me/archives/include-file-from-zip-or-phar.html">arcane</a>
<a href="https://gynvael.coldwind.pl/?lang=en&amp;id=671">stuff</a> lurking in the shadows.
Providing a way to reduce this attack surface (like making streams opt-in)
would be welcome.</p>
    </div>
  </article>
</section>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/php8-from-a-security-point-of-view.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308078</guid>
            <pubDate>Fri, 04 Dec 2020 21:14:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zettelkasten for Indie Devs and Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25307658">thread link</a>) | @EduardMe
<br/>
December 4, 2020 | https://blog.noteplan.co/zettelkasten-for-devs/ | <a href="https://web.archive.org/web/*/https://blog.noteplan.co/zettelkasten-for-devs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <a href="https://blog.noteplan.co/static/3d18615fb1282a94d8ccaf2550a86487/6052f/noteplan-screenshot.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="NotePlan note with backlinks" title="NotePlan note with backlinks" src="https://blog.noteplan.co/static/3d18615fb1282a94d8ccaf2550a86487/fcda8/noteplan-screenshot.png" srcset="https://blog.noteplan.co/static/3d18615fb1282a94d8ccaf2550a86487/12f09/noteplan-screenshot.png 148w,
https://blog.noteplan.co/static/3d18615fb1282a94d8ccaf2550a86487/e4a3f/noteplan-screenshot.png 295w,
https://blog.noteplan.co/static/3d18615fb1282a94d8ccaf2550a86487/fcda8/noteplan-screenshot.png 590w,
https://blog.noteplan.co/static/3d18615fb1282a94d8ccaf2550a86487/efc66/noteplan-screenshot.png 885w,
https://blog.noteplan.co/static/3d18615fb1282a94d8ccaf2550a86487/c83ae/noteplan-screenshot.png 1180w,
https://blog.noteplan.co/static/3d18615fb1282a94d8ccaf2550a86487/6052f/noteplan-screenshot.png 2030w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>I finally figured it out. I’m not an academic, I build apps. So, I wondered how I could apply Zettelkasten to my work.</p>
<p>I’m not just coding, I’m also receiving constructive user feedback. This is usually about bug reports and feature suggestions. However, sometimes I get flooded by emails and messages. There are more good features than time to build and every feature needs some serious thinking and planning. So, my role I cover here is a mix of developer and product manager.</p>
<p>I was using Jira, a project management software to collect, manage and plan feature ideas and bug reports. But it quickly grew to over 1000 items. It’s mostly useless now.</p>
<p><span>
      <a href="https://blog.noteplan.co/static/b88a1129c49f39649645d4c849897402/774b6/jira-screenshot.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Jira issues" title="Jira issues" src="https://blog.noteplan.co/static/b88a1129c49f39649645d4c849897402/fcda8/jira-screenshot.png" srcset="https://blog.noteplan.co/static/b88a1129c49f39649645d4c849897402/12f09/jira-screenshot.png 148w,
https://blog.noteplan.co/static/b88a1129c49f39649645d4c849897402/e4a3f/jira-screenshot.png 295w,
https://blog.noteplan.co/static/b88a1129c49f39649645d4c849897402/fcda8/jira-screenshot.png 590w,
https://blog.noteplan.co/static/b88a1129c49f39649645d4c849897402/774b6/jira-screenshot.png 738w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Then I started my Zettelkasten and I’m not opening Jira any more.</p>
<h2>What is Zettelkasten?</h2>
<p>German for ‘slip-box’. It’s a simple, but powerful note-taking system allowing you to build a second brain. The Zettelkasten was invented by Niklas Luhmann, a highly productive German sociologist. He published more than 70 books and 400 scholarly articles and attributed his productivity to his notes. His slip-box contained more than 90,000 notes.</p>
<p>Intentionally, the Zettelkasten fits and complements our imperfect and biased brains and I think that’s how it ‘just works’. Many good productivity principles are baked in.</p>
<h2>Here is how I translate it to my work</h2>
<p>In Luhmann’s work, Zettelkasten was used in an academic environment. Here is how I translate the academic Zettelkasten to a ‘Product Development’ Zettelkasten. On the left is Luhmann’s version and on the right mine:</p>
<ol>
<li><strong>Input:</strong> Reading books and academic articles = Feedback emails</li>
<li><strong>Capture:</strong> Literature notes on books = Feedback notes</li>
<li><strong>File notes and link:</strong> Permanent Zettelkasten notes are the same for me, short, atomic ideas for features, clarifications, question, interconnected where it makes sense.</li>
<li><strong>Interim Output:</strong> Manuscript for an article or book = Feature specification document</li>
<li><strong>Final Output:</strong> Final Draft for an article or book = Written code implementing a feature</li>
</ol>
<h2>The process is largely the same</h2>
<p>Every morning, when I read my emails, I take quick notes about the content and copy/paste the link to the original email (Gmail link in my case). My notes are very short and written in my words. Sometimes the title of the note is all I need, other times I elaborate a good idea or clue I found in the email. These notes are only temporary. I store them into an inbox folder at first (as recommended by GTD), waiting to be processed later.</p>
<p><strong>It’s critical to write all notes in your words</strong> and as short as possible, don’t copy and paste the content. It’s unlikely you read the full email again and often a waste of time. But just in case, you got the link.</p>
<p>Then, on the next morning, I process all accumulated inbox notes at once. By splitting the capturing from the processing process, your brain doesn’t have to switch contexts and you can work with less effort.</p>
<p>In that process I take the inbox note, quickly evaluate if it adds anything valuable to my system and either delete it or elaborate, then file it. If I decide there is something useful in it, I create a permanent slip-box note which contains a single, atomic idea. Again it’s written in my words. I look into my network of existing notes (sometimes using the search function) to find other notes which have the same context and link them together to a chain of thoughts with branches (not unlike GitHub).</p>
<p>During that process your brain often starts to have more ideas, so I create more permanent notes as good ideas come to me.</p>
<h2>How is this useful?</h2>
<p>After some time, you build a dense network of ideas. Clusters emerge. In my case, around feature ideas. If a particular feature has many connected notes, my understanding on that feature is probably very mature. I can browse through the notes (since they have clickable links) and create a draft for a specification document.</p>
<p>Without the Zettelkasten you would have to brainstorm and rely on your fragile memory to write that spec or worse, dig up the emails and read them <em>again</em>, out of context. So, naturally you spend much more time and miss important details.</p>
<p>And finally, you write well thought through code out of that specification document. The details are based on actual user feedback have matured over time.</p>
<h2>Where I’m now</h2>
<p>Today, I have 909 notes and I have used this system for a few months. I created several slip-box folders: features, bugs, general and business. Notes can be still interconnected between the folders, it’s just easier to find related end-points this way. In general you shouldn’t restrict yourself to specific topics though.</p>
<p><span>
      <a href="https://blog.noteplan.co/static/2804c5010fa5771550133321c05764dd/78612/folders.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Folders" title="Folders" src="https://blog.noteplan.co/static/2804c5010fa5771550133321c05764dd/fcda8/folders.png" srcset="https://blog.noteplan.co/static/2804c5010fa5771550133321c05764dd/12f09/folders.png 148w,
https://blog.noteplan.co/static/2804c5010fa5771550133321c05764dd/e4a3f/folders.png 295w,
https://blog.noteplan.co/static/2804c5010fa5771550133321c05764dd/fcda8/folders.png 590w,
https://blog.noteplan.co/static/2804c5010fa5771550133321c05764dd/efc66/folders.png 885w,
https://blog.noteplan.co/static/2804c5010fa5771550133321c05764dd/c83ae/folders.png 1180w,
https://blog.noteplan.co/static/2804c5010fa5771550133321c05764dd/78612/folders.png 1260w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p></section></div>]]>
            </description>
            <link>https://blog.noteplan.co/zettelkasten-for-devs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25307658</guid>
            <pubDate>Fri, 04 Dec 2020 20:44:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Don't Retweet Anything]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25307654">thread link</a>) | @sonicrocketman
<br/>
December 4, 2020 | https://brianschrader.com/archive/why-i-dont-retweet-anything/ | <a href="https://web.archive.org/web/*/https://brianschrader.com/archive/why-i-dont-retweet-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>I still read Twitter (despite my <a href="https://brianschrader.com/_drafts/retweeting/">efforts to quit entirely</a>), but I've stopped retweeting. My last retweet was on July 17th and it was of a tweet I wrote for <a href="https://adventurerscodex.com/">a company I co-own</a>. And if things continue as planned, that will be the last retweet I ever do.</p>
<h3>Why No Retweets?</h3>
<p>Retweets are Twitter's original sin. Akin to Facebook's Share, or Tumblr's Re-blog, the Retweet is what allows content on Twitter to spread virally. It allows for users to effortlessly spread false or misleading information with impunity and encourages readers to never go past the title of an article (despite <a href="https://slate.com/technology/2020/10/twitter-retweet-change-election.html">Twitter's admittedly laudable attempts</a> to address this issue). Retweets allow users to easily dunk on each other and act as super-spreaders of identity-reenforcing and tribalistic memes that only serve to make Twitter a worse platform.</p>
<p>Quote retweets are a little better (at least they require the user to express some opinion about the content they're spreading), but they still allow for the easy dunking that's a mainstay of the platform.</p>
<p>To their credit, Twitter has long known that the retweet button causes problems on their platform. The original designer of the feature has even said as much.</p>
<p><a href="https://www.buzzfeednews.com/article/alexkantrowitz/how-the-retweet-ruined-the-internet">Chris Wetherell</a>:</p>
<blockquote>
<p>“We might have just handed a 4-year-old a loaded weapon,” Wetherell recalled thinking as he watched the first Twitter mob use the tool he created. “That’s what I think we actually did.”</p>
</blockquote>
<p>Both Pine.blog and Micro.blog don't have retweets, and Manton does a great job explaining why (I used the same reasoning for Pine.blog).<sup>1</sup></p>
<p><a href="https://www.manton.org/2016/11/22/fake-news-and.html">Manton Reece</a>:</p>
<blockquote>
<p>When you have to put a little work into posting, you take it more seriously. I wonder if fake news would have spread so quickly on Facebook if it was a little more difficult to share an article before you’ve read more than the headline.</p>
</blockquote>
<p>Putting in the extra effort to actually articulate an intelligible thought helps me better understand the content myself and it helps me gauge whether or not the given post is even worth sharing. On more than one occasion, I've stopped myself from sharing something because I realized that it just wasn't all that interesting.</p>
<h3>How I (Still) Use Twitter</h3>
<p>While I still read Twitter, the vast majority of my posts are cross-posted from <a href="https://pine.blog/u/sonicrocketman">my microblog</a>. I still favorite posts (because my favorites are automatically saved to Pinboard so I can find them later), but for the most part, my interactions are read-only.</p>
<p>Because I spend most of my "social media time" either reading articles on <a href="https://pine.blog/">Pine.blog</a> or browsing <a href="https://micro.blog/">Micro.blog</a>, reading Twitter now feels like wading through a nuance-lacking, toxic cesspit rather than acccessing the real-time information platform I once knew and loved, which in turn drives me further away from the platform. I see people I follow there cooking amazing meals, telling fanciful stories, sharing hilarious memes, but all of that is drowned out by the hate and vitriol in every next post.</p>
<p>With all that said though, I do still share stuff on the Web. I just do it by writing a post.</p>
<div>
<p><img alt="A sample pseudo-retweet" src="https://brianschrader.com/images/blog/pseudo-retweet.png"></p><center><small>I'd love a browser plugin that removes the Retweet button and hides all retweets. It seems like a few exist, but none that I tried worked. Presumably Twitter tries to circumvent them.</small></center>
</div>

<p>Virality is a fact of life on the Web; neither innately good nor bad. For too long we've seen it as something to be harnessed, to utilize. But a virus is incredibly difficult to control and, like with today's real-world troubles, a pandemic of memes and satire does enormous harm to our individual health and to the health of our society.<sup>2</sup></p>
<p>tl;dr Pandemics are bad. Both online and in meatspace. We should limit their spread and stop retweeting.</p>
<p><sup>1</sup> Pine.blog will show you when someone retweets or re-posts your blog posts if you allow for Webmentions, though I'm considering letting users configure this behavior. Retweets also poison the mind of the poster, not just the reader.
</p>

<p><sup>2</sup> In an effort to be transparent, I have asked others to retweet my posts before an an attempt to gain some traction outside my bubble. I'm going to stop doing that too.
</p>
        </div></div>]]>
            </description>
            <link>https://brianschrader.com/archive/why-i-dont-retweet-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25307654</guid>
            <pubDate>Fri, 04 Dec 2020 20:44:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React is slow, what now?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25307536">thread link</a>) | @franleplant
<br/>
December 4, 2020 | https://nosleepjavascript.com/react-performance/ | <a href="https://web.archive.org/web/*/https://nosleepjavascript.com/react-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2 id="tldr-the-gist"><a href="#tldr-the-gist" aria-label="tldr the gist permalink"></a>TLDR: the gist</h2>
<ul>
<li>Measure performance! If you don’t measure it’s the same as doing nothing.</li>
<li>You can optimize your React performance by improving <strong>what</strong> (🤔) and <strong>which</strong> (🧙) components render.</li>
<li>
<p>🧙 To improve <strong>which</strong> component renders you can use</p>
<ul>
<li><code>React.memo</code></li>
<li><code>useCallback</code></li>
<li><code>useMemo</code></li>
<li>Make sure your props have stable references</li>
<li>Virtualization</li>
</ul>
</li>
<li>
<p>🤔 To improve <strong>what</strong> components render you should</p>
<ul>
<li>identify the slow components</li>
<li>simplify, use more efficient abstractions, make smaller trees, etc</li>
</ul>
</li>
</ul>
<p>If this got your attention read on:</p>
<h2 id="table-of-contents"><a href="#table-of-contents" aria-label="table of contents permalink"></a>Table of Contents</h2>

<h2 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h2>
<p>In general computer programs can be:</p>
<ul>
<li><strong>io-bound</strong>: spend most of their time making inputs and outputs</li>
<li><strong>cpu-bound</strong>: spend most of their time making calculations</li>
</ul>
<p>And how do these translate into Front End apps and in particular React apps?</p>
<h2 id="io-performance-problems-in-react"><a href="#io-performance-problems-in-react" aria-label="io performance problems in react permalink"></a>io performance problems in React</h2>
<ul>
<li>Browser apps can be <strong>io-bounded</strong> mostly in terms of asynchronous http calls.</li>
<li>a poor management of these network requests can slow down your app</li>
</ul>
<h3 id="potential-solutions"><a href="#potential-solutions" aria-label="potential solutions permalink"></a>Potential solutions</h3>
<p>Although this will not be the focus of this post let’s quickly cover some
important areas where solutions and improvements might be found for io-bound
problems:</p>
<ul>
<li>lazy load as much as you can.</li>
<li>careful with the initial load of assets and also backend requests.</li>
<li>reduce the amount of times you load highly static stuff (select options, configurations, etc)</li>
<li>debounce the amount of times you make certain requests.</li>
<li>parallelize request as much as possible via <code>Promise.all</code>.</li>
<li>make your critical BE endpoints more efficient (i.e. by tweaking DB accesses and such).</li>
</ul>
<h2 id="cpu-performance-problems-in-react"><a href="#cpu-performance-problems-in-react" aria-label="cpu performance problems in react permalink"></a>CPU performance problems in React</h2>
<blockquote>
<p>This is going to be the main focus of this post.</p>
</blockquote>
<p>Before talking about performance we need to define it in a more concrete way:</p>
<ul>
<li>browser apps are <a href="https://stackoverflow.com/questions/30932870/why-doesnt-javascript-get-its-own-thread-in-common-browsers">single thread</a> programs for the most part.</li>
<li>scripting, i.e. Javascript, DOM rendering, event handling, etc; all run in the same thread.</li>
<li>if a Javascript module is slow it can block the main thread.</li>
<li>if the main thread is blocked then the UI will seem unresponsive (<strong>fps</strong> will drop).</li>
<li>unresponsive UIs are one of the worst offenders in terms of <strong>User Experience</strong>.</li>
</ul>
<p>This all boils down to the concept of <code>fps</code> or <strong>Frames Per Second</strong>.
Responsive UIs will deliver a minimum of 30 fps or more ideally 60 fps, this means
that every frame of your app, even the more demanding code paths, should compute in <strong>30 ms or less</strong>.</p>
<blockquote>
<p>If your Javascript is slow it might cause “frames to be dropped” which means
computing a frame in more than 30 ms.</p>
</blockquote>
<p>To fully understand how this applies to React we need to understand how React works
and what React’s <strong>render and commit phase</strong> are but in short we can say that:</p>
<blockquote>
<p>If a React component update is triggered then the <strong>entire sub tree needs to be
rendered in less than 30ms</strong>.</p>
</blockquote>
<p>This becomes specially problematic when you have complex and long component structures
such as Tables, Trees and Lists and in which sometimes (for example the first time) you will
need to re render large parts of them.</p>
<blockquote>
<p><strong>Summary:</strong> we should figure out which expensive interactions are dropping frames,
measure them to confirm and fix them.</p>
</blockquote>
<h2 id="react-render-and-commit-phase"><a href="#react-render-and-commit-phase" aria-label="react render and commit phase permalink"></a>React render and commit phase</h2>
<p>React works (at a high level) in two phases</p>
<p><strong>Render phase:</strong></p>
<ul>
<li>Happens when a component updates i.e. props or hooks changed.</li>
<li>React traverses the component sub tree rendering each child and computing the virtual DOM (VDOM) sub tree.</li>
<li>Only the “dirty” sub tree needs to be recomputed i.e. the updated component parents might not need to be re rendered.</li>
<li>This phase is proportional to the size of the sub tree being rendered.</li>
<li>This phase is also proportional to how expensive it is to compute each child component.</li>
<li>We can give React hints to make this process more efficient i.e. <code>React.memo</code>.</li>
</ul>
<p><strong>Commit phase:</strong></p>
<ul>
<li>The render phase outputs a new virtual DOM of the entire UI.</li>
<li>In the commit phase Reacts compares the new tree with the previous one (VDOM diffing).</li>
<li>React calculates the minimum DOM mutations needed to reflect the new VDOM tree.</li>
<li>React mutates the DOM.</li>
<li>Your UI is now updated.</li>
<li>This phase is pretty efficient by default.</li>
</ul>
<p>This whole process needs to happen in less than 30 or 16 ms (30 fps and 60 fps respectively) for your UI to be considered
responsive, as you can see there’s a lot of work and that work is proportional to the size of your app.</p>
<p>We will explore ways to make mostly the <strong>Render phase</strong> more efficient but first let’s discuss
how to measure and how to find out what are the slow parts of our app and how bad they are.</p>
<h2 id="measuring"><a href="#measuring" aria-label="measuring permalink"></a>Measuring</h2>
<p>In 2020 we have pretty solid tools for measuring browser side performance, these
are the ones I use the most:</p>
<ul>
<li>Chrome dev tool’s Performance tab.</li>
<li>React dev tool’s Performance tab.</li>
</ul>
<h3 id="chrome-dev-tools-performance-tab"><a href="#chrome-dev-tools-performance-tab" aria-label="chrome dev tools performance tab permalink"></a>Chrome dev tool’s Performance tab</h3>
<p>This is the most comprehensive tool, it is useful for any browser application,
it measures frames per second, records stack traces, identifies slow / hot parts of your code,
and much more. The main UI is the <a href="http://www.brendangregg.com/flamegraphs.html">flame chart</a>.</p>
<p>Here’s a <a href="https://reactjs.org/docs/optimizing-performance.html#profiling-components-with-the-chrome-performance-tab">good doc</a>
of Chrome’s Performance Tab applied to React.</p>
<h3 id="react-dev-tools-performance-tab"><a href="#react-dev-tools-performance-tab" aria-label="react dev tools performance tab permalink"></a>React dev tool’s Performance tab</h3>
<p>You need to install the <a href="https://reactjs.org/blog/2019/08/15/new-react-devtools.html">React dev tool extension</a> in your browser.</p>
<p>It specializes the information in the Chrome dev tool’s Performance tab to
React. You can see the different <strong>commit phases</strong> and the Javascript code that was run in its respective
<strong>render phase</strong> through a <strong>flame chart</strong>.</p>
<p>Through this tool you can easily find out:</p>
<ul>
<li>when a component re renders</li>
<li>what props changed</li>
<li>what hooks changed i.e. state, context, etc.</li>
</ul>
<p>Check the <a href="https://reactjs.org/blog/2018/09/10/introducing-the-react-profiler.html">introductory post</a> for more information.</p>
<h3 id="measuring-1"><a href="#measuring-1" aria-label="measuring 1 permalink"></a>Measuring</h3>
<p>This is the <strong>methodology</strong> I like to use when measuring front end applications:</p>
<ul>
<li><strong>identify the problem</strong>: identify page interactions that make the UI feel unresponsive.</li>
<li><strong>create a hypothesis</strong>: optionally, we might have some ideas where the problem might be.</li>
<li><strong>measure</strong>: verify the problem by measuring and looking at important metrics such as <strong>fps</strong>.</li>
<li><strong>measure</strong>: identify problematic pieces of code, optionally: validate your hypothesis.</li>
<li><strong>create a solution</strong>: apply a solution based off the previous steps</li>
<li><strong>measure the solution</strong>: validate that the problem has been resolved or alleviated by looking at the important metrics.</li>
</ul>
<blockquote>
<p>If you optimize something without measuring then you are practically doing nothing.</p>
</blockquote>
<p>There might be cases where the problem is super obvious and I won’t tell you that going straight
to fixing it is naturally bad, but most of the problems are not obvious and measuring will be
cornerstone of the performance improvement process.</p>
<p>Additionally, if you measure you can later tell your users, stakeholders and more importantly your <strong>boss
that you have improved the performance of a given area of your app by x%</strong> which is always a good
way of communicating upwards what we accomplish inside the rabbit hole.</p>
<h2 id="general-solutions-to-cpu-bound-problems-in-react-applications"><a href="#general-solutions-to-cpu-bound-problems-in-react-applications" aria-label="general solutions to cpu bound problems in react applications permalink"></a>General solutions to cpu-bound problems in React applications</h2>
<p>Now that we have measured and identified the problematic areas let’s cover
potential solutions.</p>
<blockquote>
<p>You can optimize your React performance by
improving <strong>what</strong> components render and
<strong>which</strong> components render.</p>
</blockquote>
<h3 id="-improving-what-components-render"><a href="#-improving-what-components-render" aria-label=" improving what components render permalink"></a>🤔 Improving <em>what</em> components render</h3>
<p>Identifying the slow parts of our React app will usually
point out to some particular components that are slow to render
(or that have too many instances in a single page, more on this in the <strong>which</strong> section).</p>
<p>There might be a number of reasons those components are slow, including:</p>
<ul>
<li>they do blocking calculations</li>
<li>they render large trees</li>
<li>they use expensive / non efficient libraries</li>
</ul>
<p>Most of these boil down to improving how fast your components render,
sometimes critical components cannot rely on too complicated libraries
and so you need to go back to basic and roll your own simpler implementation.</p>
<p>I have experienced something like this when using <a href="https://formik.org/">Formik</a> (which I love)
or should I say abusing Formik on several cells of every single row of a complex table.</p>
<p>You can go a long way making your components more efficient but eventually you will need
to focus on <strong>which</strong> components render:</p>
<h3 id="🧙-improving-which-components-render"><a href="#%F0%9F%A7%99-improving-which-components-render" aria-label="🧙 improving which components render permalink"></a>🧙 Improving <em>which</em> components render</h3>
<p>There are two broad categories where we can improve this aspect:</p>
<ul>
<li>Virtualization</li>
<li>Prop optimization</li>
</ul>
<h4 id="virtualization"><a href="#virtualization" aria-label="virtualization permalink"></a>Virtualization</h4>
<p>It means <strong>only render what is visible in the viewport</strong>, i.e. only render the
table rows that the user can see or the list items the user can see.</p>
<p>This is great because it can be applied to complex UIs without going through the <strong>what</strong> step,
although I recommend it; and modern libraries tend to have decent support for virtualizing
your tables and lists. A good example of this is <a href="https://github.com/bvaughn/react-virtualized">react-virtualized</a>.</p>
<blockquote>
<p>Virtualizing means that we <strong>reduce the amount of components React needs to render in a given frame</strong>.</p>
</blockquote>
<h4 id="props-optimization"><a href="#props-optimization" aria-label="props optimization permalink"></a>Props Optimization</h4>
<p>React tries to make your components look like pure functions but still will try to render
more times than it should.</p>
<h5 id="code-classlanguage-textreactmemocode"><a href="#code-classlanguage-textreactmemocode" aria-label="code classlanguage textreactmemocode permalink"></a><code>React.memo</code></h5>
<p>Most components in React can be <strong>memoized</strong>, which means that they do not have internal side effects
or depend on any external side effects so that we can guarantee than <strong>with the same props the component
will return the same tree</strong> (hooks, state and context are still respected though).</p>
<p>For that we can use <a href="https://reactjs.org/docs/react-api.html#reactmemo">React.memo</a>.
This tells React to skip re rendering these memoized components if their
props didn’t change.</p>
<h5 id="fake-prop-changes-code-classlanguage-textusecallbackcode"><a href="#fake-prop-changes-code-classlanguage-textusecallbackcode" aria-label="fake prop changes code classlanguage textusecallbackcode permalink"></a>Fake prop changes: <code>useCallback</code></h5>
<p>Additionally we have the problem of <strong>fake prop changes</strong> which means that although
the content of a given prop didn’t change, the reference did. The most classic example
of this is the event handler one:</p>
<div data-language="typescript"><pre><code><span>export</span> <span>function</span> <span>MyComponent</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>onChange</span> <span>=</span> <span>(</span><span>e</span><span>)</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span>e<span>)</span><span>;</span>

  <span>return</span> <span>&lt;</span>input onChange<span>=</span><span>{</span>onChange<span>}</span> <span>/</span><span>&gt;</span><span>;</span>
<span>}</span></code></pre></div>
<p>The <code>onChange</code> callback, although semantically and content wise will be the same on every render, will be
be stored in a completely separate memory direction so React will detect it as different from the previous one.</p>
<p>This is related to how <code>React.memo</code> does shallow comparison by default (although there’s no good way of
deeply comparing functions in Javascript AFAIK).</p>
<p>An easy fix for this is to use <code>useCallback</code> which was designed exactly for this:</p>
<div data-language="typescript"><pre><code><span>export</span> <span>function</span> <span>MyComponent</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> onChange <span>=</span> <span>useCallback</span><span>(</span><span>(</span><span>e</span><span>)</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span>e<span>)</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span>

  <span>return</span> <span>&lt;</span>input onChange<span>=</span><span>{</span>onChange<span>}</span> <span>/</span><span>&gt;</span><span>;</span>
<span>}</span></code></pre></div>
<h5 id="fake-prop-changes-code-classlanguage-textusememocode"><a href="#fake-prop-changes-code-classlanguage-textusememocode" aria-label="fake prop changes code classlanguage textusememocode permalink"></a>Fake prop changes: <code>useMemo</code></h5>
<p>A similar problem can rise when building complex data structures and not memoizing them
correctly before …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nosleepjavascript.com/react-performance/">https://nosleepjavascript.com/react-performance/</a></em></p>]]>
            </description>
            <link>https://nosleepjavascript.com/react-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25307536</guid>
            <pubDate>Fri, 04 Dec 2020 20:37:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Gerhard Sabathil spy probe fell apart]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25307513">thread link</a>) | @bigpumpkin
<br/>
December 4, 2020 | https://www.politico.eu/article/germany-china-why-the-gerhard-sabathil-spy-probe-fell-apart/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/germany-china-why-the-gerhard-sabathil-spy-probe-fell-apart/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div>


<p>BERLIN — A dead ex-journalist, a blind Chinese dissident and a suspected spy codenamed “Johnny.”</p>



<p>These are just a few of the players in the motley cast of characters German counterintelligence assembled to <a href="https://www.politico.eu/article/gerhard-sabathil-brussels-china-spy-probe/">build a case</a> against Gerhard Sabathil, the former EU ambassador cleared last month of spying for China, in a high-profile investigation that heightened fears of Chinese infiltration in core European institutions and sent tremors across the Continent.</p>



<p>The collapse of the nearly year-long investigation underscores the difficulties Western authorities face in distinguishing legitimate business and academic dealings from espionage, as governments from Washington to Brussels have grown <a href="https://www.politico.eu/article/belgium-security-service-probes-top-eu-think-tanker-for-links-to-china/">increasingly wary</a> of Beijing’s heightened global ambitions and influence.&nbsp;&nbsp;</p>



<p>More immediately, the acknowledgement by Germany’s Federal Prosecutor’s Office that it <a href="https://www.politico.eu/article/gerhard-sabathil-german-prosecutor-drops-spy-case-ex-eu-envoy/">couldn’t support a prosecution</a> of Sabathil despite a lengthy police investigation that included extensive wiretaps is a major embarrassment for German authorities that raises serious questions about their modus operandi.</p>



<p>In a lengthy interview with POLITICO this week, Sabathil said the reason he ended up in the crosshairs of German intelligence was simple: “Incompetence.”</p>



<p>“That such a thing can happen in Germany with the&nbsp;Verfassungsschutz&nbsp;is a disgrace,” he said, referring to Germany’s domestic intelligence agency. “This was a comedy of errors.”</p>



<p>Though Sabathil was neither charged nor arrested, details of the probe were leaked to the German press even as he was being questioned by police. The publicity created a cloud of suspicion that cost the 66-year-old father of nine not just his good name and social life, but his livelihood. Within days of the allegations becoming public, he resigned from his position as a senior executive at EUTOP, a Munich-based lobbying firm, and has been unemployed ever since.</p>



<p>The affair also upended the life of Sabathil’s partner, Shen Wenwen, a Chinese academic with whom he has two young children. Shen said that even though there was never any evidence implicating her for wrongdoing, she was nonetheless singled out.</p>



<p>“There wouldn’t be such a media hype or even a spy probe if I&nbsp;wasn’t&nbsp;Chinese and a woman,” said Shen, who earned a PhD in international relations from the University of Bath.&nbsp;&nbsp;</p>



<p>Prosecutors have yet to provide Sabathil and his lawyers full access to either their dossier on him or a detailed written explanation they drafted to justify dropping the case. Yet the facts that are known suggest investigators acted on thin evidence from dubious sources and exaggerated or twisted the details of what they discovered to support the conclusion that Sabathil was guilty of spying for the Chinese.</p>



<p>German authorities involved in the case — the Federal Prosecutor’s Office, the Verfassungsschutz&nbsp;and the foreign intelligence service, known as BND — all declined to answer questions for this article about what went wrong and why.</p>



<h3>Nothing to hide</h3>



<p>By the time German and Belgian police raided Sabathil’s residences and offices early on January 15, the diplomat-turned-consultant had been under electronic surveillance for more than a year, according to court filings.</p>



<p>The surprise dawn raids, people close to the operation say, were undertaken to find a smoking gun.</p>



<p>Dozens of police officers were involved in the searches from Brussels to Bad Kötzing, a small spa town in southeast Germany where Sabathil owns an apartment, collecting everything from family photos to Shen’s personal diaries.</p>



<p>That morning Sabathil and Shen were taken in for questioning at separate locations. Police officers escorted Shen to her daughter’s kindergarten, where she dropped the child off. The police then drove her across town to the headquarters of Germany’s federal police, originally a Prussian army barracks, where she was questioned for eight hours, taking breaks to nurse her eight-month-old son. Unlike Sabathil, who was placed under official suspicion, Shen was considered a “witness.” </p>



<p>Though Sabathil’s lawyers, who weren’t present for his initial questioning, counseled him against speaking to the police, he decided to do so anyway, hoping that his full cooperation would bring a quick end to what he assumed was a grave misunderstanding.</p>



<p>“I didn’t have anything to hide,” he said.</p>



<p>Sabathil’s hopes of a quick resolution were quickly dashed. After police questioned him about his ties to China, they fingerprinted him and took his mugshot. They accused him of taking €70,000 in payment in exchange for his work, which they claimed included recruiting at least two other agents. As evidence, they cited a telephone conversation they had recorded between him and his estranged Czech wife in which he said he “also worked for others.”</p>



<p>Sabathil explained that the suspect money transfer was from Shen’s mother, who happened to be visiting Berlin at the time of the raids, for her granddaughter. They planned to invest the money in real estate. He said the comment to his Czech wife had been taken out of context during an argument over money.</p>



<p>Amid the questioning and the search of his apartment, Sabathil says the police forgot to pick his daughter up from kindergarten as they’d promised him, leaving her stranded there.</p>



<p>Despite those strains, his answers appear to have planted a seed of doubt in the minds of the investigators, and they decided not to arrest him as they’d originally intended. “We won’t be needing the arrest warrant,” Sabathil says they told him at the end of the discussion. </p>



<h3>‘Johnny’</h3>



<p>About two weeks later, he was questioned again, this time in the presence of his lawyer, Peter Gauweiler, a university acquaintance from Bavaria and one of Germany’s foremost jurists.</p>



<p>During the interrogation, investigators expressed particular interest in Sabathil’s connection to the Shanghai Institute for European Studies, a Chinese think tank that sponsored two of his trips to China for conferences.</p>



<p>Investigators alleged Sabathil met his handler, “Johnny,” through the institute, which they believed was a front for Chinese intelligence, according to investigation files seen by Sabathil’s legal team and described to POLITICO.</p>



<p>But the Chinese man investigators called “Johnny” used the name “Jimmy” in email correspondence with Sabathil (Chinese people often assume Western names for dealings with Americans and Europeans). While only a detail, the mistake proved to be an early sign that much of the evidence against Sabathil was slapdash.</p>



<p>Sabathil said that while Jimmy had managed the logistics and other organization of his trips, he wasn’t his “handler.”&nbsp;</p>



<p>Investigators further alleged that Sabathil recruited two German associates, luring them on trips to China sponsored by the Shanghai institute in the hope that “Johnny” could recruit them too. Only one of the men even made it to China. Though the man’s trip was sponsored by the Shanghai Institute, Sabathil did not accompany him there. (The two men, one a journalist and the other a PR executive, were probed along with Sabathil, and the investigations against them were also dropped. POLITICO has decided not to name them).</p>



<p>In China, as in many other countries, the lines between academia, think tanks and the intelligence world are fluid. But even if the Shanghai Institute for European studies is a front, as investigators allege, it’s one well established in German and European circles.</p>



<p>Before agreeing to travel to Shanghai, one of Sabathil’s associates contacted the German consulate there to enquire if the organization was legitimate and respected and was told it was, he says.</p>



<p>Just a month before the raids on Sabathil, Mingqi Xu, the institute’s president, delivered a speech on reforming the multilateral order at an <a href="https://www.kas.de/de/web/china/veranstaltungen/detail/-/content/belt-and-road-initiative-and-sino-european-strategic-cooperation-1" target="_blank">event</a> co-sponsored by the Konrad Adenauer Stiftung, a German foundation closely aligned with the Christian Democratic Union, the center-right party of Chancellor Angela Merkel.</p>



<p>The Shanghai event — “Belt and Road Initiative and Sino-European Strategic Cooperation” — was also attended by officials from the CDU and the European People’s Party, the center-right bloc in the European Parliament.</p>



<h3>‘Everybody loves pandas’</h3>



<p>German authorities haven’t disclosed the details of what led them to suspect Sabathil, but according to court filings seen by his legal team, the government’s case rested on two primary sources: Friedrich Kurz, a longtime friend of Sabathil’s with ties to the Verfassungsschutz, and a “well-informed intelligence service.”</p>



<p>A former journalist for German public broadcasting, Kurz had become, like Sabathil, a consultant. The firm he worked with, Berlin-based WMP Eurocom, specializes in “nation branding,” with a roster of sovereign clients that has included the likes of Qatar and Saudi Arabia.</p>



<p>In 2018, Kurz developed a PR concept for China’s Belt and Road project, an effort to polish the country’s image in Germany, according to an article that appeared in German weekly <a href="https://www.stern.de/politik/deutschland/ein-deutscher-berater-schrieb-ein-pr-konzept-fuer-die-chinesen-9312452.html" target="_blank">Stern</a> earlier this year.</p>



<p>Kurz’s idea: Swap the Chinese flags on trains arriving in Germany from China with pandas. “Everybody loves pandas,” he wrote, according to Stern.</p>



<p>As a journalist, Kurz had earned a&nbsp;<a rel="noreferrer noopener" href="https://taz.de/!1408979/" target="_blank">checkered reputation</a>. Colleagues accused him of exaggerating stories and even making things up, like a piece in the 1990s about a balloon that supposedly drifted from the German city of Hanover into a child’s hands in Bosnia.&nbsp;</p>



<p>It was Kurz, Sabathil says, who introduced him to the Shanghai Institute for European Studies. In June of 2017, the two men traveled together to Shanghai for a symposium on the upcoming German election, where they both delivered speeches. Sabathil and Kurz can be seen standing in the front row with other participants in a <a href="http://sies-cn.org/Show.aspx?articleid=941&amp;lan=en" target="_blank">photograph</a> on the institute’s website. </p>



<p>Sabathil describes Kurz as a close personal friend. The two met at university in Munich in the 1970s and had …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.politico.eu/article/germany-china-why-the-gerhard-sabathil-spy-probe-fell-apart/">https://www.politico.eu/article/germany-china-why-the-gerhard-sabathil-spy-probe-fell-apart/</a></em></p>]]>
            </description>
            <link>https://www.politico.eu/article/germany-china-why-the-gerhard-sabathil-spy-probe-fell-apart/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25307513</guid>
            <pubDate>Fri, 04 Dec 2020 20:35:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moving Away from UUIDs (2018)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25307097">thread link</a>) | @thorum
<br/>
December 4, 2020 | https://neilmadden.blog/2018/08/30/moving-away-from-uuids/ | <a href="https://web.archive.org/web/*/https://neilmadden.blog/2018/08/30/moving-away-from-uuids/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>If you need an unguessable random string (for a session cookie or access token, for example), it can be tempting to reach for a <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_(random)">random UUID</a>, which looks like this:</p>
<pre> 88cf3e49-e28e-4c0e-b95f-6a68a785a89d</pre>
<p>This is a 128-bit value formatted as 36 hexadecimal digits separated by hyphens. In Java and most other programming languages, these are very simple to generate:</p>
<pre> import java.util.UUID;  
String id = UUID.randomUUID().toString();</pre>
<p>Under the hood this uses a cryptographically secure pseudorandom number generator (CSPRNG), so the IDs generated are pretty unique. However, there are some downsides to using random UUIDs that make them less useful than they first appear. In this note I will describe them and what I suggest using instead.</p>

<h2>How random is a UUID anyway?</h2>
<p>As stated on the <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_(random)">Wikipedia entry</a>, of the 128 bits in a random UUID, 6 are fixed variant and version bits leaving 122 bits of actual random. 122 bits is still quite a lot of random, but is it actually enough? If you are generating OAuth 2 access tokens, then <a href="https://tools.ietf.org/html/rfc6749#section-10.10">the spec says no</a>:</p>
<blockquote><p>The probability of an attacker guessing generated tokens (and other<br>
credentials not intended for handling by end-users) MUST be less than<br>
or equal to 2^(-128) and SHOULD be less than or equal to 2^(-160).</p></blockquote>
<p>Well, even if the attacker only makes a single guess, the probability of guessing a 122-bit random value can never be less than 2<sup>-122</sup>, so strictly speaking a random UUID is in violation of the spec. But does it really matter?</p>
<p>To work out how long it would take an attacker to guess a valid token/cookie, we need to consider a number of factors:</p>
<ul>
<li>How quickly can the attacker make guesses? An attacker that can try millions of candidate tokens per second can find a match much faster than somebody who can only try a hundred. We will call this rate (in guesses per second) <em>A</em>.</li>
<li>How many bits of randomness are in each token? A 128-bit random token is more difficult to guess than a 64-bit token. We will label the number of random bits <em>B</em>.</li>
<li>How many tokens are valid at any given time? If you have issued a million active session cookies then an attacker can try and guess <em>any</em> of them, making their job easier than if there was just one. Such <a href="https://blog.cr.yp.to/20151120-batchattacks.html">batch attacks</a> are often overlooked. We will label the number of valid tokens in circulation at any one time <em>S</em>.</li>
</ul>
<p>Given these parameters, <a href="https://www.owasp.org/index.php/Insufficient_Session-ID_Length">OWASP give a formula for calculating how long it will take an attacker to guess a random token as</a>:</p>
<p><img data-attachment-id="3321" data-permalink="https://neilmadden.blog/2018/08/30/moving-away-from-uuids/img_1549/" data-orig-file="https://neilmadden.files.wordpress.com/2018/08/img_1549.jpg" data-orig-size="242,187" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1549" data-image-description="" data-medium-file="https://neilmadden.files.wordpress.com/2018/08/img_1549.jpg?w=242" data-large-file="https://neilmadden.files.wordpress.com/2018/08/img_1549.jpg?w=242" src="https://neilmadden.files.wordpress.com/2018/08/img_1549.jpg?w=840" alt="(2^B+1)/(2AS)" srcset="https://neilmadden.files.wordpress.com/2018/08/img_1549.jpg 242w, https://neilmadden.files.wordpress.com/2018/08/img_1549.jpg?w=150 150w" sizes="(max-width: 242px) 85vw, 242px"></p>
<p>Let’s plug in some numbers and see what we get. But what are reasonable numbers? Well, for security we usually want to push the numbers <em>well beyond</em> what we think is actually possible to be really sure. So what is actually possible now?</p>
<p>When we consider how fast a well resourced attacker could guess a token, we can use the <a href="https://blockchain.info/charts/hash-rate?timespan=30days">Bitcoin hash rate</a> as a reasonable upper-bound approximation. A lot of people are investing a lot of time and money into generating random hashes, and we can view this as roughly equivalent to our attacker’s task. When I looked back in February (you can see how long my blog queue is!), the maximum rate was around 24293141000000000000 hashes per second, or around 2<sup>64</sup>.</p>
<p>That’s a pretty extreme number. It’s fairly unlikely that anyone would direct that amount of resource at breaking your site’s session tokens, and you can use rate limiting and other tactics. But it is worth considering the extremes. After all, this is clearly <em>possible</em> with current technology and will only improve over time.</p>
<p>How many tokens might we have in circulation at any time? Again, it is helpful to consider extremes. Let’s say your widely successful service issues access tokens to every IoT (Internet of Things) device on the planet, at a rate of 1 million tokens per second. As you have a deep instinctive trust in the security of these devices (what could go wrong?), you give each token a 2-year validity period. At a peak you will then have around 63 trillion (2<sup>46</sup>) tokens in circulation.</p>
<p>If we plug these figures into the equation from before, we can see how long our 122-bit UUID will hold out:</p>
<p><em>A</em> = 2<sup>64</sup><br>
<em>B</em> = 122<br>
<em>S</em> = 2<sup>46</sup></p>
<p><img data-attachment-id="3322" data-permalink="https://neilmadden.blog/2018/08/30/moving-away-from-uuids/img_1550/" data-orig-file="https://neilmadden.files.wordpress.com/2018/08/img_1550.jpg" data-orig-size="469,182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1550" data-image-description="" data-medium-file="https://neilmadden.files.wordpress.com/2018/08/img_1550.jpg?w=300" data-large-file="https://neilmadden.files.wordpress.com/2018/08/img_1550.jpg?w=469" src="https://neilmadden.files.wordpress.com/2018/08/img_1550.jpg?w=840" srcset="https://neilmadden.files.wordpress.com/2018/08/img_1550.jpg 469w, https://neilmadden.files.wordpress.com/2018/08/img_1550.jpg?w=150 150w, https://neilmadden.files.wordpress.com/2018/08/img_1550.jpg?w=300 300w" sizes="(max-width: 469px) 85vw, 469px"></p>
<p>That comes out as … 2048 seconds. Or a bit less than 35 minutes. Oh.</p>
<p>OK, so those extreme numbers look pretty terrifying, but they are also quite extreme. The Bitcoin community spend enormous sums of money (certainly in the tens of millions of dollars) annually to produce that kind of output. Also, testing each guess most likely requires actually making a request to one of your servers, so you are quite likely to notice that level of traffic – say by your servers melting a hole through the bottom of your datacentre. If you think you are likely to attract this kind of attention then you might want to carefully consider which side of the <a href="https://www.schneier.com/blog/archives/2015/08/mickens_on_secu.html">Mossad/not-Mossad threat divide</a> you live on and maybe check your phone isn’t a piece of Uranium.</p>
<p>All this is to say that if you have deployed random UUIDs in production, <a href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#Don%27t_Panic">don’t panic</a>! While I would recommend that you move to something better (see below) at some point, plugging more likely numbers into the equation should reassure you that you are unlikely to be at risk immediately. An attacker would still have to invest considerable time and money into launching such an attack.</p>
<h2>Other nits</h2>
<p>The borderline acceptable level of entropy in a random UUID is my main concern with them, but there are others too. In the standard string form, they are quite inefficient. The dash-separated hexadecimal format takes 36 characters to represent 16 bytes of data. That’s a 125% expansion, which is pretty terrible. Base64-encoding would instead use just 24 characters, and just 22 if we remove the padding, resulting in just 37.5% expansion.</p>
<p>Finally, a specific criticism of Java’s random UUID implementation is that internally it uses a single shared <code>SecureRandom</code> instance to generate the random bits. Depending on the backend configured, this can acquire a lock which can become heavily contended if you are generating large numbers of random tokens, especially if you are using the system blocking entropy source (don’t do that, use /dev/urandom). By rolling your own token generation you can use a thread-local or pool of SecureRandom instances to avoid such contention. (NB – the NativePRNG uses a shared static lock internally, so this doesn’t help in that case, but it also holds the lock for shorter critical sections so is less prone to the problem).</p>
<h2>What should we use instead?</h2>
<p>My recommendation is to use a 160-bit (20 byte) random value that is then <a href="https://en.wikipedia.org/wiki/Base64#URL_applications">URL-safe base64</a>-encoded. The URL-safe base64 variant can be used pretty much anywhere, and is reasonably compact. In Java:</p>
<pre>import java.security.SecureRandom;
import java.util.Base64;

public class SecureRandomString {
    private static final SecureRandom random = new SecureRandom();
    private static final Base64.Encoder encoder = Base64.getUrlEncoder().withoutPadding();

    public static String generate() {
        byte[] buffer = new byte[20];
        random.nextBytes(buffer);
        return encoder.encodeToString(buffer);
    }
}
</pre>
<p>This produces output values like the following:</p>
<pre>Xl3S2itovd5CDS7cKSNvml4_ODA</pre>
<p>This is both shorter than a UUID and also more secure having 160 bits of entropy. I can also make the SecureRandom into a ThreadLocal if I want.</p>
<p>So how long would it take our extreme attacker to find a 160-bit random token? Around <strong>17.9 million years</strong>. By tweaking the format of our tokens just a little we can move from worrying about attacker capabilities and resources to inner peace and happiness. It is so far beyond the realm of possible that we can stop worrying.</p>
<p>Why not go further? Why not 256 bits? That would push the attack costs into even more absurd territory. I find that 160 bits is a sweet spot of excellent security while still having a compact string representation.</p>


<div>
	<!-- .author-avatar -->

	<div>
		

		<p>
			Security Director at ForgeRock. Experienced software engineer with a PhD in computer science. Interested in application security, applied cryptography, logic programming and intelligent agents.			<a href="https://neilmadden.blog/author/neilmadden/" rel="author">
				View all posts by Neil Madden			</a>
		</p><!-- .author-bio -->
	</div><!-- .author-description -->
</div><!-- .author-info -->
	</div></div>]]>
            </description>
            <link>https://neilmadden.blog/2018/08/30/moving-away-from-uuids/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25307097</guid>
            <pubDate>Fri, 04 Dec 2020 20:09:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building an Audience Is a Marathon]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25307048">thread link</a>) | @dbustac
<br/>
December 4, 2020 | https://danielbusta.com/marathon/ | <a href="https://web.archive.org/web/*/https://danielbusta.com/marathon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-196">

	
<!-- .entry-header -->

	<div>

		<div>

			
<figure><img loading="lazy" src="https://images.unsplash.com/photo-1519703936-c4a3b3eb88e4?ixlib=rb-1.2.1&amp;ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&amp;auto=format&amp;fit=crop&amp;w=1050&amp;q=80" alt="" width="610" height="406"><figcaption><em>Credit to <a href="https://unsplash.com/@benst287" target="_blank" rel="noreferrer noopener">@benst287</a></em></figcaption></figure>



<p>Although they might seem very similar, running and sprinting are two very different sports.</p>



<p>Running is a game of long distances. It requires steadiness and endurance. Sprinting, on the other hand, is a game of speed. It requires intensity and power.</p>



<p>Runners can’t race as fast as sprinters. And sprinters can’t last as long as runners. They are different games.</p>



<p>If audience building were a sport, it would be more like running than like sprinting.</p>



<p>You don’t build an audience in just one sprint — you need thousands of them. And if you try to sprint every day, you’ll end up burned out. It’s not sustainable.</p>



<p>You need to show up often and stay at it as long as possible. So instead of sprinting, you should try to run or even jog but at a pace you can keep up. That way it becomes sustainable.</p>



<p>When it comes to content, steadiness beats intensity. Put another way, sharing good content frequently beats sharing superb content infrequently.</p>



<p>Your content might be incredibly valuable, but if people only hear from you once in a blue moon they might not even remember who you are in the first place. They need to hear you often. They need to know you. They need to trust you.</p>



<p>Why should they give you their attention otherwise?</p>


<p><em>This piece is part of a series of 30 atomic essays where I explore what it means to be a&nbsp;<a rel="noreferrer noopener" href="https://rationalcreatives.substack.com/" target="_blank">rational creative</a>&nbsp;and the different aspects of being a creator online. You can read all the others essays&nbsp;<a rel="noreferrer noopener" href="https://twitter.com/dbustac/status/1328419048070279174?s=20" target="_blank">here</a>.</em></p>
		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://danielbusta.com/marathon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25307048</guid>
            <pubDate>Fri, 04 Dec 2020 20:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Employee Guide to Navigating IPOs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25306969">thread link</a>) | @zuhayeer
<br/>
December 4, 2020 | https://withcompound.com/r/ipo | <a href="https://web.archive.org/web/*/https://withcompound.com/r/ipo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h3>“We’re going public!”</h3></p><div><section>
  <p>For a startup employee, learning about your company’s initial public offering (IPO) is an exciting time. But it’s also overwhelming from a financial planning perspective. You have a variety of different equity grants, and you must decide what to do with each one. How many stock options should you exercise and sell, and when? What will your tax obligations be, and how can you minimize them?</p>
  <p>This guide covers what a startup employee needs to know to make well-informed decisions about all of this. We’ll start with tax considerations around exercising and selling stock. Then, we’ll discuss strategies and timelines for selling stock after the IPO. Finally, we’ll go over ways to further minimize your tax burden after selling.
  </p>
</section></div><h3>Taxes</h3><div><section>
<p>Money made from selling stock is taxed either as ordinary income (i.e. <span>federal<label for="sn-federal"></label></span><span>In 2020, the federal tax brackets
        were: 10%, 12%, 22%, 24%, 32%, 35%, and 37%. Your bracket depends on your income and filing status; more
        details
        <a href="https://www.nerdwallet.com/article/taxes/federal-income-tax-brackets">here.</a></span> plus
      <span>state<label for="sn-state"></label></span>
      
      <span>In 2020, California state tax brackets
        <a href="https://www.nerdwallet.com/article/taxes/california-state-tax#:~:text=California%20state%20tax%20brackets%20are,subject%20to%20California%20state%20tax.">ranged</a>from
        1% to 12.3%. New York state tax brackets
        <a href="https://www.tax-brackets.org/newyorktaxtable">ranged</a> from 4% to 8.82%. Your bracket
        depends on your income and filing status.</span>
      income taxes), or as long-term capital gains. If you acquire a stock (e.g. by exercising an option or vesting an
      RSU) and hold it for over a year before selling it, then your profit is classified as a long-term capital gain.
      Profits from stocks held for less than a year are short-term capital gains, and they’re taxed at the same rate
      as
      ordinary income.
    </p>
    <p>
      Long-term capital gains are taxed at about half the
      <span>ordinary income tax rate<label for="sn-oitr"></label></span>
      
      <span>For unmarried individuals, the long-term capital gains federal tax rate
        <a href="https://www.nerdwallet.com/article/taxes/capital-gains-tax-rates">is</a>: 0% for income below
        $40k; 15% for income
        between $40k-$441,450; 20% for income exceeding $441,450. In California, though, you’ll have to <a href="https://pocketsense.com/capital-gains-taxes-state-california-8405869.html">pay</a> additional
        state income tax on all capital gains (see footnote 2).</span>
      . So, in general, to minimize your tax
      burden, maximize your long-term capital gains.
    </p>

    <p>
      Let’s look at how this plays out for ISOs, NSOs, and RSUs.
    </p>
</section></div><p><img src="https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb8100b85626a8067b0c690_cg3.png" loading="lazy" width="720" sizes="(max-width: 767px) 92vw, (max-width: 991px) 88vw, 53vw" srcset="https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb8100b85626a8067b0c690_cg3-p-500.png 500w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb8100b85626a8067b0c690_cg3-p-800.png 800w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb8100b85626a8067b0c690_cg3-p-1080.png 1080w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb8100b85626a8067b0c690_cg3.png 1440w" alt=""></p><h4>Employee Stock Options (ISOs and NSOs)</h4><div><section>    <p>
      Employee stock options represent the right to purchase a certain number of shares of your company at a certain
      price, once the options have vested. There are two types—ISOs and NSOs—and early-stage companies will typically
      issue a mix of both to their employees.
    </p>
    <p>
      For each tranche of options that you’ve been issued, be aware of three key numbers:
    </p>
    <ul>
      <li>Your strike price (aka exercise price): how much you pay to purchase each share.</li>
      <li>The 409A value (aka fair market value) of the shares, as of the time you exercise the options. For private
        companies, the 409A value is an independent appraisal of how much the private company’s stock is worth. After
        the
        IPO, this value becomes
        <span>the company’s public stock price.<label for="sn-psp"></label></span>
        
        <span>Leading up to the IPO, the fair market value of your shares will likely rise greatly
          towards the company’s preferred price (or at least fluctuate). These fluctuations may greatly impact your tax
          calculations, and your company's finance team should keep you up-to-date on them.</span></li>
      <li>Your sale price: the price at which you later sell the shares.</li>
    </ul>

    <p>
      On a high level, here is the difference between ISOs and NSOs:
    </p>
    <p>
      <b>For NSOs</b>
    </p><ul>
      <li>Pay ordinary income tax on (409A value - exercise price) when you exercise your options. So, if you pay $2 to
        purchase each share and the 409A value is $10, then you’re taxed on the $8 spread.</li>
      <li>Pay
        <span>capital gains tax<label for="sn-cgt"></label></span>
        
        <span>Depending whether you held the shares for over a year before selling them, you’ll either
          pay long-term capital gains or ordinary income tax on them.</span>
        on (sale price - 409A at the time of exercise) when you sell the shares. So, if you exercise the shares when the
        409A value is $10, then sell those shares for $50, then you’ll be taxed on the $40 capital gain.</li>
    </ul>
    

    <p>
      <b>For ISOs</b>
    </p><ul>
      <li>Pay no tax when you exercise—unless you trigger the AMT (details below)</li>
      <li>Pay long-term capital gains tax on (sale price - exercise price) when you sell—if the shares are sold at least
        one year after exercising, and at least two years after your options were granted. Otherwise, (sale price -
        exercise price) will be taxed as short-term capital gains (roughly ordinary income). </li>
    </ul>
    
</section></div><p><img src="https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e520ee86f4c5b5ab5c00_nsoiso.png" loading="lazy" width="720" sizes="(max-width: 767px) 92vw, (max-width: 991px) 88vw, 53vw" srcset="https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e520ee86f4c5b5ab5c00_nsoiso-p-500.png 500w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e520ee86f4c5b5ab5c00_nsoiso-p-800.png 800w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e520ee86f4c5b5ab5c00_nsoiso-p-1080.png 1080w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e520ee86f4c5b5ab5c00_nsoiso.png 1440w" alt=""></p><h4>Alternative Minimum Tax for ISOs<br></h4><div><section> 
<p>
      Upon exercising your ISOs, you will likely qualify for the Alternative Minimum Tax, or
      <span>AMT.<label for="sn-amt"></label></span>
      
      <span>Back in 1969, 155 individuals with incomes over $200,000 managed to pay zero federal income
        taxes, triggering popular outrage. The AMT was introduced to prevent this from happening again.</span>
    </p>
    <p>
      The AMT is calculated based on the bargain element: the (409A value - exercise price). You owe AMT if:
    </p>
    <ol type="1">
      <li>
        Your total bargain value ( [409A value - exercise price] * total ISOs exercised ) exceeds the AMT exemption
        amount (which
        was
        <span>$72,900 for unmarried individuals<label for="sn-amt"></label></span>
        
        <span>For married couples filing jointly, the 2020 AMT exemption amount was $113,400.</span>
        in 2020).

      </li>
      <li>
        The tax you owe under the <span>AMT calculation<label for="sn-amtcalc"></label></span>
        
        <span>We won’t discuss how to calculate your exact AMT burden in this article, but it will come
          out to 26-28% of your total bargain value.

        </span>
        exceeds the tax you owe under regular tax calculations.
      </li>
    </ol>
  

    <p>
      You will have to pay AMT when you file your tax return for the year that you exercise your ISOs (it is not
      withheld at the time you exercise), so make sure to plan accordingly.
    </p>
</section></div><h4>AMT Credits<br></h4><div><section> 
<p>
      Upon exercising your ISOs, you pay AMT . Then, when you
      sell those shares, you’re taxed again on your capital gains. To lessen the blow of thus being taxed twice on ISOs,
      Congress introduced AMT credits.
    </p>
    <p>
      Suppose you paid $5000 in AMT in 2019. In any subsequent year where you don't owe AMT (say, 2020), you might be
      able to get back some or all of that $5000. There are a few
      conditions for getting this tax credit:
    </p>
    <ol type="1">
      <li>You can't owe AMT in 2020.</li>
      <li>The maximum amount of AMT credit you can claim for 2020 is [regular tax bill for 2020 - AMT amount for 2020].
        After you claim your credits for 2020, any of the original $5000 that's left over can be used toward a
        subsequent year's tax deduction.</li>
    </ol>
    <p>
      There are many other caveats that may warrant speaking with a financial advisor. But the bottom line is: you may
      want to try to strategically maximize the amount of AMT credit that you can claim later. Or, you can limit the
      number of ISOs that you exercise and stay below the AMT exemption amount (thus avoiding the AMT altogether).
    </p>
</section></div><h4>Restricted Stock Units (RSUs)<br></h4><div><section> 
<p>
      RSUs turn into shares of your company’s stock when they vest. They’re typically issued by companies valued at over
      $1 billion.
    </p>
    <p>
      RSUs are subject to either single- or double-trigger vesting. Single-trigger RSUs can vest before IPO. This means
      you’ll owe taxes on them as they vest (because you’re coming into ownership of new shares of stock). However, if
      the company is still private, you won’t be able to sell those shares to make money to pay the taxes you owe on
      them.
    </p>
    <p>
      That’s why many companies instead offer double-trigger RSUs, which only vest after the IPO. That way, you’ll only
      owe taxes once the company is public and you can actually sell those shares. So, for the year that your company
      IPOs, be prepared to pay taxes on
      <span>any double-trigger RSUs that you vest.<label for="sn-dtr"></label></span>
      
      <span>Your RSUs may vest either on IPO day or after the lockup period, depending on the
        company.</span>
    </p>
    <p>
      When your RSUs vest (whether before or after IPO), you’ll owe ordinary income tax on the
      <span>409A value of your newly issued shares as of that day.<label for="sn-4nid"></label></span>
      
      <span>As a reminder, the 409A value after IPO is equivalent to the company’s public stock
        price.</span>
      Then, when you sell those shares, your profit (i.e. [sale price - 409A value as of the day the shares vested])
      <span>will be taxed as capital gains.<label for="sn-wtcp"></label></span>
      
      <span>Again, these qualify for long-term capital gains tax treatment if you hold onto the shares
        for over a year.</span>
    </p>
</section></div><p><img src="https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e47909f6f82e80a70772_rsu.png" loading="lazy" width="720" sizes="(max-width: 767px) 92vw, (max-width: 991px) 88vw, 53vw" srcset="https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e47909f6f82e80a70772_rsu-p-500.png 500w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e47909f6f82e80a70772_rsu-p-800.png 800w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e47909f6f82e80a70772_rsu-p-1080.png 1080w, https://uploads-ssl.webflow.com/5f89a88f5a23982843f8d21f/5fb7e47909f6f82e80a70772_rsu.png 1440w" alt=""></p><h4>Qualified small business stock (QSBS)<br></h4><div><section> <p>
      You can actually exempt your stock from all the federal taxes we’ve discussed above, if it counts as qualified
      small business stock (QSBS). Your stock might qualify as QSBS if:
    </p>
    <ul>
      <li>At the time that your stock was issued (i.e. when you exercised your options), your company’s gross assets did
        not exceed $50 million.</li>
      <li>You’ve held the stock for at least five years before selling it.</li>
    </ul>
    <p>
      There are a number of <a href="https://www.investopedia.com/terms/q/qsbs-qualified-small-business-stock.asp"></a>other caveats. But, if
      you can get QSBS treatment, you’ll almost certainly save a lot of
      money in taxes.
    </p>
</section></div><h3>Selling your stock<br></h3><div><section>
<p>
      With these tax considerations in mind, let’s discuss plans for selling your shares.
    </p>
    <p>The soonest that you can sell your shares is after the lockup period. The lockup period lasts around six months,
      starting from the IPO date, and is meant to prevent employees from flooding the market with their shares
      <span>(and thus lowering the stock price).<label for="sn-lup"></label></span>
      
      <span>This is generally true for traditional IPOs. If your company is going public via a direct
        listing, there might not be a lockup period.</span>
      After the lockup period, employees generally employ one of a few selling strategies:
    </p>
    <ul>
      <li>Sell most of their equity immediately.</li>
      <li>Sell most of their shares as soon as they qualify for long-term capital gains tax treatment.</li>
      <li>Plan to sell a constant number …</li></ul></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withcompound.com/r/ipo">https://withcompound.com/r/ipo</a></em></p>]]>
            </description>
            <link>https://withcompound.com/r/ipo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306969</guid>
            <pubDate>Fri, 04 Dec 2020 19:59:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Continuous Integration Mystery]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25306898">thread link</a>) | @basicallydan
<br/>
December 4, 2020 | https://danhough.com/blog/ci/ | <a href="https://web.archive.org/web/*/https://danhough.com/blog/ci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
			<p>
				<span>Published 03 December 2020 in Vancouver, BC, Canada</span>
				
				<span title="It took me about 5 minutes to read this blog post back to myself.">(~5min read)</span>
				
			</p>
		</header>
		<p>Yesterday I faced a version control situation I rarely face.</p>

<p>It showed me that I may rely a little too much on the green light from CI tools like CircleCI and GitHub Actions when deciding whether it’s safe to merge a branch.</p>

<p>Here’s what happened:</p>

<ol>
  <li>My colleague added new <code>expect</code> clauses to a test, plus the code to <strong>pass it</strong>.</li>
  <li>They merged this into the main branch via a PR.</li>
  <li>Later, I forked off of the main branch.</li>
  <li>I added <strong>more new clauses</strong> to the test my colleague had earlier modified.<br>I worked on it for the rest of the day.</li>
  <li>I made a <strong>pull request</strong>.</li>
  <li>Next, two colleagues reviewed my work and approved it on GitHub.<br>All the pre-merge checks on CircleCI were passing, including tests and style checks.<br>I rebased and decided to save the merge for the morning.</li>
  <li>Soon after, an error was found related to the code the first colleague had deployed.<br>They <strong>reverted</strong> the PR they had merged on Day 1.</li>
  <li>Not long after, I checked my PR again - there were no merge conflicts.<br><strong>I merged my code</strong>.</li>
</ol>

<p>An hour or so later, another colleague tells me that, according to CircleCI, a test I wrote was failing on the main branch. How could this be, they said? It appears to have been passing on the branch it came from!</p>

<p>What is the cause of this mysterious failure?</p>

<p>I’d recently touched that test, so I looked at the error and quickly worked out what it was: The test I’d added to was failing because one of it’s <code>expect</code> clauses relied on code which had been been reverted - it was no longer a valid expectation. GitHub didn’t run a new diff on my PR after the removal of the clause in question from the main branch; the reverted test code simply looks ‘unchanged’ in the diff, as if it had been and was still there.</p>

<p>I didn’t remove it, I didn’t rebase, and my PR ended up re-adding the recently-removed <code>expect</code> clause even though it didn’t appear to.</p>

<p>Is there a lesson to be learned here?</p>

<p>On one hand, the process is working. There was a merge error caused by the <code>git</code> equivalent of a race condition, we were told about it, and we were able to resolve it. Why bother running tests on the main branch before you deploy unless you are concerned that there is a chance they’ll fail?</p>

<p>Maybe the lesson is to keep on doing what we’re doing.</p>

<p>On the other hand, the process felt like it was disrupting the order of things. Something like this is often said: “if you have a reliable QA and CI process, then if something is on the main branch it should be deployable.” And yet here was an anomalous case which suggested otherwise.</p>

<p>Perhaps, then, the lesson is that our QA and CI process isn’t robust enough. Should CI create a merged branch behind-the-scenes and run tests on <em>that</em> before allowing the branch to be merged?</p>

<p>I’m not sure. In the meantime, while I try to decide what the lesson is, I think I’ll just rebase my branches more often.</p>

<p>A <a href="https://news.ycombinator.com/item?id=25306898">discussion has begun on Hacker News</a>, please share your thoughts if you have any.</p>

		<p>Heckle me on Twitter <a href="http://twitter.com/basicallydan">@basicallydan</a>.</p>
	</div></div>]]>
            </description>
            <link>https://danhough.com/blog/ci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306898</guid>
            <pubDate>Fri, 04 Dec 2020 19:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wozniak's Efforce energy efficiency token white paper]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25306803">thread link</a>) | @nebulous1
<br/>
December 4, 2020 | https://efforce.io/wpdirect | <a href="https://web.archive.org/web/*/https://efforce.io/wpdirect">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://efforce.io/wpdirect</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306803</guid>
            <pubDate>Fri, 04 Dec 2020 19:45:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JWT Authentication Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25306620">thread link</a>) | @mehdios
<br/>
December 4, 2020 | https://blog.asayer.io/jwt-authentication-best-practices | <a href="https://web.archive.org/web/*/https://blog.asayer.io/jwt-authentication-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="introduction">Introduction</h2><p>Microservices are a great tool when it comes to designing scalable and extensible architectures. They can be used to encapsulate different behaviors or responsibilities in a way that not a lot  of other architecture paradigms can represent.
And if you pair them with a REST-based interface, then you’re not only writing and creating a platform that can grow and scale automatically (given the right infrastructure of course), but you’re also creating a standard and easy-to-use product. </p><p>If you haven’t noticed, I’m a fan of microservices and they’re usually the pattern I go with when designing new architectures, working with Big Data on a day-to-day basis, I tend to require flexibility and scalability out of the box, and they provide that to me.</p><p>The thing not everyone considers when writing microservices though is that they require a way for you to authenticate against them. Both if you’re using a front-end client or just communicating with them through another microservice. And although there are several options out there to solve authentication, I want to cover one of the easiest, yet most powerful, alternative: JSON Web Tokens.</p><h2 id="jwt-based-authentication">JWT-based Authentication</h2><p>The basic thing you need to understand JWT-based authentication is that you’re dealing with an encrypted JSON which we’ll call “token”. This token has all the information required for the back-end system to understand who you are and if, indeed, you are who you say you are.</p><p>The following diagram shows the steps involved in this process:</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/eae220053d72e95dbe803496c8aac458/d2d42/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606545347515_jwt.png" srcset="https://blog.asayer.io/static/eae220053d72e95dbe803496c8aac458/d2d42/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606545347515_jwt.png 545w" sizes="(max-width: 545px) 100vw, 545px" alt="null"></p><p>As you can see, leaving out the user-based steps, you only need 4 steps:</p><ul><li>First, the client application (here I used a front-end app, but you can do the same with another service) will send a sign-in request. This means you’re sending the log-in credentials, just this once.</li><li>Second, the API will validate these credentials and if they’re correct, it’ll generate the token. This is the most important step because the generated token as I mentioned is nothing more than an encrypted JSON object. This allows you to add as much data into it as you want, and you will want to add data because JWT allows you to perform stateless authorization, which I’ll cover in a second.</li><li>Third, with the JWT generated, all you have to do is return it back to the client application. </li><li>Finally, the client app will later send this token on every subsequent request. This token means you’ve been authenticated and can access the secret section of the application.</li></ul><p>That is it, the flow is very straightforward and you don’t need to redirect the user anywhere (I’m looking at you OAuth!).
But let’s get into it with more details, let me break up each step for you to fully understand what is happening behind code.</p><h3 id="the-back-end-side-of-things">The back-end side of things</h3><p>For the back-end, or the microservice if you will, there are two major steps that you need to understand: </p><ol><li>Generating the JSON Web Token. This is key, as I mentioned before because the information you add will be used later (kinda like saying “everything you say will be used against you in a court of law”).</li><li>Validating the token for received requests. I left this part out of the authentication process because this is actually part of the authorization flow. Very similar, and easy to implement, but worth noting as well.</li></ol><p>So, let’s get into it.</p><h4 id="generating-the-jwt">Generating the JWT</h4><p>To generate the token on your back-end microservice, you’ll normally use an existing server-side library. There is no need for you to understand how the token is generated, you just need to understand what goes into it. </p><p>So, what actually goes into the token? You can literally use a JSON object such as:</p><p>And that will be used and sent back to the front-end client, which may be for your business logic it makes sense, maybe your front-end client is waiting for the “foo” key. However, other than the custom attributes you can add, there are also pre-defined options that have a functional meaning for the specific algorithm that the library is using.</p><p>Given I’ll be using the <a href="https://www.npmjs.com/package/jsonwebtoken" target="_blank" rel="noreferrer">jsonwebtoken</a> library for Node.js, the main option you want to take into account is  <code>expiresIn</code>. This is critical to generating a proper JWT because you want the token to have an expiration date. Otherwise, it will last forever, potentially leaving an open vulnerability for someone who can capture it and later use it to impersonate your identity.
For this particular library, this value is expressed in seconds if you provide a number (or you can provide a string using a time unit for something like <code>"``2 days``"</code> to signify 2 days of validity). </p><p>And in turn, the library will add another one called <code>iat</code> which stands for <strong>Issued At</strong> and is a date reference used for expiration checks (i.e that’s the date it’ll take into account when checking if your token is still valid).</p><p>And how do you add all this information into the token then? By signing it:</p><div><pre><p><span>1</span><span>const</span><span> jwt </span><span>=</span><span> </span><span>require</span><span>(</span><span>'jsonwebtoken'</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span>    </span></p><p><span>3</span><span>    </span><span>const</span><span> token </span><span>=</span><span> jwt</span><span>.</span><span>sign</span><span>(</span><span>{</span><span></span></p><p><span>4</span><span>        data</span><span>:</span><span> </span><span>'foobar'</span><span></span></p><p><span>5</span><span>      </span><span>}</span><span>,</span><span> </span><span>'your-secret-key-here'</span><span>,</span><span> </span><span>{</span><span> expiresIn</span><span>:</span><span> </span><span>60</span><span> </span><span>*</span><span> </span><span>60</span><span> </span><span>}</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>6</span><span>       </span></p><p><span>7</span><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>token</span><span>)</span><span></span></p><p><span>8</span><span>    </span></p></pre></div><p>Using the <code>sign</code> method you can create the token, notice that your main object (the one containing the actual information you want to transfer to the front-end) is the first parameter, the second one is the secret key or phrase (you can either pass a secret phrase of your choosing, something that you’ll have to share with your clients) or the content of a PEM key. Either way, the second parameter is used for the encryption algorithm to encode and create the token. Finally, the third attribute contains the configuration options (in our case only the expiration time).</p><p>This token (notice the output on the code above) is then returned as part of the authentication response, for the client to use. </p><h4 id="storing-the-token">Storing the token</h4><p>As an optional step, you can also store the token in your database  to associate it with your user. Normally, you wouldn’t need to do this if all the user information can be stored in your token.
However, if there is more information to manage that you can comfortably store in your token, then keeping an association with your user’s profile inside the database might be a good idea.
In fact, given that looking up this token would be something you’d do on every request, a good alternative is to keep both, the token and the relevant information about your user inside some in-memory storage,  such as <a href="https://redis.io/" target="_blank" rel="noreferrer">Redis</a>. </p><p>The new flow, with storage incorporated and verification support is the following one:</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/fe0c8ead812da347af4abd251f5f0a7e/e0d28/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606580178077_jwt3.png" srcset="https://blog.asayer.io/static/fe0c8ead812da347af4abd251f5f0a7e/e0d28/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606580178077_jwt3.png 689w" sizes="(max-width: 689px) 100vw, 689px" alt="null"></p><p>The taxing interaction here is not the first one (#4) with Redis, but rather the second one (#9) because this one would happen on every request received. We’ll see more about that in a second.</p><h4 id="checking-the-token">Checking the Token</h4><p>Just because we’re getting a token as part of the request, it doesn’t mean such a request is safe, it could very well be a fake one or have an invalid or even expired token. This is why on every request of a secured resource (i.e an endpoint that requires an authenticated user to be accessed, or a section of your website that lives inside the member’s zone) you need to validate the token received.
If you’ve skipped the storage step, then this is a relatively cheap task. All you have to do is use the same server-side framework to validate it:</p><div><pre><p><span>1</span><span>const</span><span> decodedToken </span><span>=</span><span> jwt</span><span>.</span><span>verify</span><span>(</span><span>token</span><span>,</span><span> </span><span>'your-secret-key-here'</span><span>)</span><span></span></p><p><span>2</span><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>decodedToken</span><span>)</span></p></pre></div><p>Notice how I’m using the same “secret phrase”, that’s definitely important because you need to keep using the same one throughout the same project otherwise validation will not work.
An expired token would throw an exception such as:</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/b943837a3499dec9c41a2c4309385182/66f0f/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606627819976_Captura%2Bde%2Bpantalla%2B2020-11-29%2Ba%2Blas%2B6.30.08.png" srcset="https://blog.asayer.io/static/b943837a3499dec9c41a2c4309385182/66f0f/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606627819976_Captura%2Bde%2Bpantalla%2B2020-11-29%2Ba%2Blas%2B6.30.08.png 2034w" sizes="(max-width: 2034px) 100vw, 2034px" alt="null"></p><p>And a valid one would just return a valid JSON that you can decode and use however you need.</p><div><pre><p><span>1</span><span>{</span><span> data</span><span>:</span><span> 'foobar'</span><span>,</span><span> iat</span><span>:</span><span> </span><span>1606581962</span><span>,</span><span> exp</span><span>:</span><span> </span><span>1606581963</span><span> </span><span>}</span></p></pre></div><p>Notice the <code>iat</code> and <code>exp</code> parameters added by the library.
An exception in this context would mean you need to invalidate the client’s request and send an invalid response. Normally you would send back a 403 error code since the request is (and the client) is no longer authenticated.</p><h3 id="spa-authentication">SPA authentication</h3><p>Now that we understand what it means for an API (or a microservice if you will) to be protected by a JWT authentication process, I wanted to cover the same process from the POV of a SPA application acting as the client app.
In this case, as I mentioned, you’ll be contacting a service initially by sending your credentials and receiving a token which you’ll have to use on every following request.
The first thing we need to understand though is that session-based authentication is not the same as token-based auth. </p><h4 id="session-based-vs-token-based-authentication">Session-based vs Token-based authentication</h4><p>At a first glance, both of these strategies might seem similar, which is why I wanted to cover the difference.
Essentially both methods work the same way:</p><ol><li>You authenticate against a service.</li><li>That service validates your credentials and sends back a token</li><li>On every following request, you send that token to authenticate yourself with the service.</li></ol><p>So as you can see, the process and the flow of data seem to be the same, but there are some major differences hidden.</p><ul><li>For session-based tokens, the server returns a session key, which references the session data (all data relevant to you as a logged-in user). This data, however, is kept in the memory of the server. This essentially breaks one of the benefits of RESTful APIS: stateless services can scale effortlessly because there is no session information stored in memory. You see, the moment you log-in with a server that keeps session information in memory, every subsequent request sent by you needs to go to that server (because memory can’t be shared between different servers, or at least not easily). If you’re trying to scale up your architecture to handle more traffic, duplicating services to increase your capacity will not be as straightforward as it would be if you had stateless services.</li><li>Session-based auth stores the session key in the browser’s cookies. They send the information as a cookie, and because of that, browsers have a problem when having microservices being served from different domains. This is not a problem for …</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.asayer.io/jwt-authentication-best-practices">https://blog.asayer.io/jwt-authentication-best-practices</a></em></p>]]>
            </description>
            <link>https://blog.asayer.io/jwt-authentication-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306620</guid>
            <pubDate>Fri, 04 Dec 2020 19:32:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create 1305 tests targeting Gitlab in 5 minutes]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25306522">thread link</a>) | @bruschee
<br/>
December 4, 2020 | https://blog.humlix.com/how-to-create-1040-tests-targeting-gitlab-in-5-minutes-with-humlix/ | <a href="https://web.archive.org/web/*/https://blog.humlix.com/how-to-create-1040-tests-targeting-gitlab-in-5-minutes-with-humlix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><a href="https://www.humlix.com/" rel="noopener nofollow">Humlix</a> is a web API request builder and quality assurance tool that automatically generates tests. All you need to do is provide examples of how to call your API methods, and Humlix will use it to start doing its magic.</p><p>To put Humlix to a real test, we decided to try it on a real industry giant, and GitLab seemed to be a suitable candidate because of its size and that we can run it locally. Therefore, in this post, we will let Humlix create tests targeting <em><em>GitLab Community Edition (gitlab-ce)</em></em> and specifically its <em><em>GitLab Groups API</em></em>. We will use <em><em>gitlab/gitlab-ce:11.2.0-ce.0</em></em> docker image and later try to repeat the same scenario on the currently latest version <em><em>gitlab/gitlab-ce:13.1.0-ce.0</em></em></p><h2 id="let-s-start-with-the-end">Let’s start with the end</h2><p>By showing Humlix how to call the /a<em><em>pi/v4/groups Gitlab Group API</em></em> method, we could discover a bug that would have been hard to detect using regular unit tests. You can see that Humlix generated 1305 tests towards <em><em>gitlab-ce</em></em> in the screenshot below and that calling:</p><p><em><em>/api/v4/groups?page=461168601842738792</em></em></p><p>resulted in a status <em><em>500 Internal Server Error</em></em>.</p><figure><img src="https://blog.humlix.com/content/images/2020/11/screenshot3-1.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/screenshot3-1.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/screenshot3-1.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/screenshot3-1.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/screenshot3-1.png 2400w"></figure><p>We can see the cause of the problem by going into the production.log file for GitLab and see that during the execution of some SQL statement, the error was:</p><blockquote>2020-10-02_19:43:52.85686 ERROR: &nbsp;bigint out of range</blockquote><blockquote>2020-10-02_19:43:52.85689 STATEMENT: &nbsp;SELECT "namespaces".* FROM "namespaces" WHERE "namespaces"."type" = 'Group' ORDER BY "namespaces"."name" ASC, "namespaces"."id" ASC LIMIT 20 OFFSET 9223372036854775820</blockquote><figure><img src="https://blog.humlix.com/content/images/2020/10/production-log.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/10/production-log.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/10/production-log.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/10/production-log.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/10/production-log.png 2400w"><figcaption>Production log showing the error</figcaption></figure><p>So in just a couple of minutes, we were able to detect bugs in production code.</p><p>A user has already reported this issue in the <a href="https://gitlab.com/gitlab-org/gitlab/-/issues/30113" rel="noopener nofollow">GitLab issue tracker system</a>. To check if GitLab has fixed the bug, we can repeat the same scenario on the currently latest version <em><em>gitlab/gitlab-ce:13.1.0-ce.0.</em></em> Humlix once again located the same problem.</p><figure><img src="https://blog.humlix.com/content/images/2020/11/1205-errors.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/1205-errors.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/1205-errors.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/1205-errors.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/1205-errors.png 2400w"></figure><p>We can also verify it using this cURL command:</p><blockquote>curl -I localhost/api/v4/groups?page=461168601842738792 </blockquote><blockquote>HTTP/1.1 500 Internal Server Error</blockquote><p>As you can see, this problem has existed for a long time, even between different versions, but Humlix was able to find the bug within minutes.</p><h2 id="how-to-generate-tests-with-humlix">How to generate tests with Humlix</h2><p>You need to <a href="https://www.humlix.com/">download Humlix</a>. Remember to <a href="https://www.humlix.com/" rel="noopener nofollow">sign up for the Humlix mailing list</a> to stay up to date with the latest news. You can follow the Humlix <a href="https://docs.humlix.com/" rel="noopener nofollow">getting started guide</a> if you don’t know how to run it.</p><p>Select the <em><em>HOME</em></em> menu and click on <em><em>ADD SUITE </em></em>and create a test suite called <em><em>GitLab Suite.</em></em></p><figure><img src="https://blog.humlix.com/content/images/2020/11/gitlab-suite.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/gitlab-suite.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/gitlab-suite.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/gitlab-suite.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/gitlab-suite.png 2400w"></figure><p>Press the <em><em>Add request</em></em> link and create a new test request called <em><em>Get a group list by page.</em></em></p><figure><img src="https://blog.humlix.com/content/images/2020/11/gitlab-request.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/gitlab-request.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/gitlab-request.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/gitlab-request.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/gitlab-request.png 2400w"></figure><p>Go to the ENVIRONMENT VARIABLES tab and change the environment name to GitLab Environment. Add two variables <em><em>base_url</em></em> and <em><em>gitlab_token</em></em>. Set the values according to your setup.</p><figure><img src="https://blog.humlix.com/content/images/2020/11/gitlab-environment.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/gitlab-environment.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/gitlab-environment.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/gitlab-environment.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/gitlab-environment.png 2400w"></figure><p>Go to the REQUEST tab so that you can see the Humlix test request builder. Select <em><em>GET</em></em> verb and <em><em>Http</em></em> protocol and add <em><em>{{base_url}}/api/v4/groups. </em></em>Add a new query parameter <em><em>page</em></em> of type <em><em>integer</em></em> according to the picture below.</p><figure><img src="https://blog.humlix.com/content/images/2020/11/gitlab-request-builder.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/gitlab-request-builder.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/gitlab-request-builder.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/gitlab-request-builder.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/gitlab-request-builder.png 2400w"></figure><p>Now we are ready to perform some tests. To verify that your setup is working, you can run a test with precisely the data you entered in the request builder by pressing the <em><em>Run </em>single test</em> button.</p><figure><img src="https://blog.humlix.com/content/images/2020/11/single-test-button.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/single-test-button.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/single-test-button.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/single-test-button.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/single-test-button.png 2400w"></figure><p>If everything works as expected, you should receive something like this in the log area.</p><figure><img src="https://blog.humlix.com/content/images/2020/11/gitlab-single-test-result.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/gitlab-single-test-result.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/gitlab-single-test-result.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/gitlab-single-test-result.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/gitlab-single-test-result.png 2400w"></figure><p>The result above shows that our setup works and that your Gitlab API token is correct.</p><p><strong><strong>Disclaimer: Don’t perform the next step unless you are sure you are targeting a test environment running GitLab that you can re-create without losing anything important. Humlix will generate many requests and could cause a heavy load on production servers.</strong></strong></p><p>Now you can press the <em><em>Generate tests</em></em> button to see some real magic.</p><figure><img src="https://blog.humlix.com/content/images/2020/11/1305-errors.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/1305-errors.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/1305-errors.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/1305-errors.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/1305-errors.png 2400w"></figure><p>If you don’t get the same result, you can experiment with the test request settings. E.g., you can change the <em><em>Max number of generated test calls</em></em> to 1000 and rerun the test generation.</p><figure><img src="https://blog.humlix.com/content/images/2020/11/settings.png" srcset="https://blog.humlix.com/content/images/size/w600/2020/11/settings.png 600w, https://blog.humlix.com/content/images/size/w1000/2020/11/settings.png 1000w, https://blog.humlix.com/content/images/size/w1600/2020/11/settings.png 1600w, https://blog.humlix.com/content/images/size/w2400/2020/11/settings.png 2400w"></figure><p>Now you have seen what Humlix is capable of in just a few minutes and how easy it is to let Humlix create tests for you. <a href="https://www.humlix.com/">Download</a> and try it out if you haven’t already!</p>

				<!-- Begin Mailchimp Signup Form -->
				
				
				<!--End mc_embed_signup-->

			</section></div>]]>
            </description>
            <link>https://blog.humlix.com/how-to-create-1040-tests-targeting-gitlab-in-5-minutes-with-humlix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306522</guid>
            <pubDate>Fri, 04 Dec 2020 19:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Biggest Tech Mafia You've Never Heard Of]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25306425">thread link</a>) | @donnyNz
<br/>
December 4, 2020 | https://contrarycap.com/content/trilogy-software | <a href="https://web.archive.org/web/*/https://contrarycap.com/content/trilogy-software">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><hr>
<h2><a name="the-biggest-tech-mafia-youve-never-heard-of"></a>The biggest tech mafia you've never heard of</h2>
<p>A Stanford dropout founder. "AI" technology. Recruits fresh out of MIT and Harvard. Skyrocketing valuations, huge paychecks, and a lightning-fast culture. All the makings of a legendary tech startup story. Was this Yahoo? Nope. Snapchat? Try again.</p>
<p>This was Trilogy Software in the 90s.</p>
<p>Although their glory has long since faded, their impact remains. Here's an incomplete list of Trilogy mafia members:</p>
<ul>
<li>Elie Seidman, the CEO of Tinder</li>
<li>Cyrus Massoumi and Nick Ganju, the founders of ZocDoc. They had shared a desk together at Trilogy.</li>
<li>Henry Ward, CEO and founder of Carta</li>
<li>John Lilly, former CEO of Mozilla, investor with Greylock Partners, and founder of Reactivity (acquired by Cisco).</li>
<li>Andy Palmer, CEO of Tamr Inc., former CEO of Vertica (acquired), and major angel investor (invested in Carta in part due to his connection with Henry).</li>
</ul>
<p>Crunchbase has a list of Trilogy mafia founded companies <a href="https://www.crunchbase.com/hub/trilogy-alumni-founded-companies#section-leaderboard">here</a>. There are 87 entries.</p>
<p>All in all, they are one of tech's most successful, albeit relatively unknown, "mafias". Their story is a fascinating dive into the dot-com boom tech scene, and holds lessons on recruitment and culture that founders will still find relevant today. How do tech mafias form?</p>
<h2><a name="what-was-trilogy"></a>What Was Trilogy?</h2>
<p>"Trilogy Development Group" was founded in 1989 by Joe Liemandt, a Stanford CS student who dropped out to start the company. He brought along 5 classmates to join him in Austin, Texas, where the cost of living was cheap and the taxes were lower.</p>
<p>From these humble beginnings, Trilogy became a 90s pioneer of enterprise software. Their main product was "config-price-quote" software, which allowed sales forces to accurately quote and configure complex solutions such as mainframes, central office switches, airplanes, and automobiles. In fact, their software could even identify and recommend the ideal combination of products and services for each customer. At the time, this was a game-changer for their clients.</p>
<p>They also built sales compensation software, which allowed sales leaders and HR teams to move sales commissions from spreadsheets to a software database and workflow engine. Their main clients were Fortune 500 companies, especially in the auto and airline sectors.</p>
<p>Although not the "coolest" product, Trilogy was wildly successful. By the mid 1990s they had grown to $250M in revenue, were valued at well over a billion dollars, and Joe Liemandt became the youngest self-made man to enter the Forbes 400. In 1996 he graced <a href="https://www.forbes.com/sites/abrambrown/2018/11/19/holy-cow-no-ones-done-this/#6700faa92927">the cover of the magazine</a>, with a net worth of $500 million.</p>
<p><img src="https://specials-images.forbesimg.com/imageserve/5bef0d784bbe6f78bda861c1/960x0.jpg?fit=scale" alt="https://specials-images.forbesimg.com/imageserve/5bef0d784bbe6f78bda861c1/960x0.jpg?fit=scale"></p>
<p>During this late 90's golden age they became famous for lavish parties, furious recruiting at college campuses, and massive onboardings — at one point they onboarded 250 people at once, a 50% increase in their headcount. They even spun off a publicly traded subsidiary, an early B2B marketplace for computer parts called PCOrder.com. It was the best of times for Trilogy... until the dot-com crash. PCOrder.com's stock price fell to near 0, Trilogy's valuation fell as well, and the company never regained the same stature. By 2001, Liedmandt had fallen off the Forbes 400, and many employees left or were let go, though the company never fully shut down.</p>
<p>At the time, it was a heavy loss for the burgeoning Austin tech scene.</p>
<h2><a name="trilogy-university-birthplace-of-the-mafia"></a>Trilogy University: Birthplace of the Mafia</h2>
<p>During their golden age, Trilogy was a recruitment machine, more than tripling their headcount in under three years. Liemandt wanted top talent, but they were competing for an extremely limited pool of computer science graduates, and couldn't pay as much as the "safe", established tech players of the 90s. So, they developed a pitch that distinguished them from the competition:</p>
<p>"Rather than paying you lots of money and stock options to pound out code for eight hours a day, we'll give you a ton of responsibility right away. You can lead projects, build new products, and even start a company. Have at it! Oh yeah, and we'll spend an average of $10,000 per recruit flying you out to Austin where you can play roulette with the CEO before you decide."</p>
<p>This was key. Trilogy was selecting for big risk-takers with an entrepreneur's mindset at the top of their recruitment funnel.</p>
<p>Once these recruits (all fresh out of college) got to Austin, they were enrolled at Trilogy University. This corporate bootcamp, modeled after Marine Corps training, was possibly Trilogy's greatest innovation, and participants cite its influence as having a huge impact on their careers. It lasted 12 weeks, and during that time employees would be split into 80 different teams working in intense R&amp;D projects for Trilogy, some of which became separate companies under the Trilogy umbrella. Classes started at 8am and went to midnight. You would spend almost all your waking hours with your team, and the bonds formed here ran deep.</p>
<p>One participant, Vince Mallet, recalls: “on the second day, we were all asked to tell the most significant emotional experience of our lives.” The first month focused on this emotional bonding, and instilling the values of Trilogy: humility, teamwork, customer-obsession, and, most of all, risk-taking. Employees say the bonds formed just during this first month persisted through their time at Trilogy and beyond, even as they eventually split off into different teams or left the company.</p>
<p>In month two, recruits "have to come up with a frame-breaking great new business idea." They have to come up with an idea, create a business model for it, build the product, and develop the marketing plan. It's wasn't hypothetical either. Liemandt hand-picked the best products to launch. By month three- graduation month, most employees are picked by or matched with different teams at Trilogy and graduate from the university. Some continue to work on their project, if it was in the lucky 15% selected to go on.</p>
<p>Trilogy University lived the work hard, play hard culture. The rigorous program was tempered by luxurious amenities like company cab cards to travel anywhere in Austin for free, sponsored trips to the beach and Las Vegas, more snacks than a convenience store, and free kegs of beer every Friday. It was 90s dot-com boom excess from start to finish.</p>
<p>In this environment, it's easy to see how risk-taking fresh graduates could be transformed into creative, effective entrepreneurs with incredible bonds to their fellow Trilogy University alums — all the makings for a future tech mafia. As Trilogy declined in the early 2000s, many of these employees left to start ventures that seeded the early Austin tech scene.</p>
<h2><a name="the-trilogy-mafia-impact"></a>The Trilogy Mafia Impact</h2>
<p><em>"Liemandt knows most of the kids he's hiring are too smart to work for him — or anyone else — for long. "There are a lot of people here to learn how to start a software company," he says. "That's great." He says he'd rather get a few years of boundless entrepreneurial energy from his employees than get many years of mediocre performance."</em></p>
<p>This except from a <a href="https://www.forbes.com/sites/abrambrown/2018/11/19/holy-cow-no-ones-done-this/#6700faa92927">Forbes article</a> proclaiming Liemandt as "computerdom's newest magnate" foreshadows the massive impact that the team he put together at Trilogy would have. For example, Trilogy's eventual decline was Austin's gain. Trilogy introduced over a thousand entrepreneurial, creative, and techhnically skilled people to Texas, like Joshua Baer, founder of Austin technology incubator Capital Factory and Heather Brunner, CEO of WP Engine.</p>
<p><a href="https://www.statesman.com/article/20120901/NEWS/309012327">This article</a> from the Austin Statesman cites Trilogy's lasting influence on the city. "Austin high-tech recruiter Marc Davis, himself a Trilogy alumnus, counts more than <strong>four dozen</strong> Austin tech companies that have Trilogy veterans in top leadership roles. Among those where Trilogy veterans populate the upper ranks: HomeAway, Bazaarvoice, WhaleShark Media (RetailMeNot), <a href="http://indeed.com/">Indeed.com</a>, <a href="http://vast.com/">Vast.com</a> and Socialware."</p>
<p>Their influence extends beyond Austin. For example, Bryon Krug appears as an eager college senior at Carnegie-Mellon and a potential Trilogy recruit in <a href="https://www.wiley.com/college/man/schermerhorn332879/site/student/ic/oneman.htm">this Rolling Stone piece</a> from 1998, titled "Wooing the Geeks". He ended up joining Trilogy, then went on to found his own publishing company, and co-founded CEG Solutions in 2008, a major energy efficiency company where he still serves as president.</p>
<p>As for Trilogy's founder, Joe Liemandt? He's back on the Forbes 400, with a net worth of over $3.5 billion, thanks to his private equity investments in software companies.</p>
<p>There are some parallels between the Trilogy mafia and their more famous counterpart, the <a href="https://money.cnn.com/2007/11/13/magazines/fortune/paypal_mafia.fortune/index.htm">Paypal mafia</a>.</p>
<ul>
<li>Both emerged at around the same time — the early 2000s, as the tech industry recovered and matured post dot-com crash.</li>
<li>In both cases, there was a mass exodus. Trilogy never got to a successful exit and started shedding employees. After PayPal's successful acquisition by eBay, the original team felt stifled under their new, more corporate bosses, and left.</li>
<li>Both companies selected for entrepreneurial people, then gave them confidence in their abilities, whether it was through Trilogy University's "build a company in a month" program or the near-bankruptcy battles fought at PayPal.</li>
<li>Perhaps most importantly, the founders encouraged tight bonds among their employees, all of whom skewed extremely young.</li>
</ul>
<p>Could this be the formula to build a new tech mafia?</p>
<p>Tech mafias are rare, and it's not obvious one has formed until years later. The first article on the success of PayPal's former employees was from 2007, 5 years after their acquisition. Spotting one is harder than finding a unicorn. In this case, you're looking for a whole herd.</p>
<p>In terms of tech mafias operating today, <a href="https://www.nytimes.com/2019/03/13/technology/silicon-valley-network-mafias.html">Uber and Airbnb have been selected as likely candidates</a>. Andrew Chen, who led Rider Growth at Uber and now is a partner at a16z, estimates that two dozen venture-backed startups have come out of Uber so far. Clearly, their alumni are already adding an extra jolt of entrepreneurial energy to the Valley, but what about outside California? Could some city be flying under the radar, in the way Austin was before Trilogy? Epic Games, for example, has …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://contrarycap.com/content/trilogy-software">https://contrarycap.com/content/trilogy-software</a></em></p>]]>
            </description>
            <link>https://contrarycap.com/content/trilogy-software</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306425</guid>
            <pubDate>Fri, 04 Dec 2020 19:15:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discovering the Y Combinator by Mistake]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25306294">thread link</a>) | @davehcker
<br/>
December 4, 2020 | https://www.lambdacircle.com/discovering-the-y-combinator-by-mistake-1-2/ | <a href="https://web.archive.org/web/*/https://www.lambdacircle.com/discovering-the-y-combinator-by-mistake-1-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p id="content">
    You don't understand anything until you learn it more than one way.
</p>
<p id="source">
    - Marvin Minsky
</p>
</div>

<div>
    <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Serpiente_alquimica.jpg/603px-Serpiente_alquimica.jpg"></p><p>
    The <a href="https://en.wikipedia.org/wiki/Ouroboros"> ouroboros </a>, a symbol often interepreted as cyclic renewal or a cycle of life, death, and rebirth. Doesn't it look like recursion?
    </p>
</div>
<p><span>R</span>ecursion has haunted me ever since I first encountered it. So a few days ago, I deliberately forced myself into implementing recursion in some non-conventional way. In some ways, I was trying to achieve the general outcome of recursion without having to rely on explicit recursion. After burning the midnight oil and countless keystrokes, what I had before me was akin to a slain dragon. The dragon was, as I confirmed later, nothing other than the famous fixed-point combinator, otherwise referred to as the Y-combinator. At this point, you don't need to be able to understand all the words in the last sentence. That is exactly what we are here for.</p>
<p>Let's figure out the underlying mechanism of the Y-combinator out of necessity. In other words, we will <strong>limit our programming language to disallow explicit recursion</strong>, and yet try to achieve recursive mechanism in the constrained language. The working programmers will find this post a much more delightful experience than actually examining definitions and syntax from the lambda calculus. Let's begin by solving a simple challenge:</p>

<p>
Write a function in Python (or any language for that matter) that calculates the factorial of a given number <strong>n</strong>. You may only use function calls, but you may not call a function from inside its body i.e. no explicit recursion! In other words, your solution should be rewriteble as a lambda expression which returns the factorial of <strong>n</strong>. Also, assume that you language doesn't support looping mechanisms.
</p>
<p>For instance, here's a correct but invalid implementation of a function that calculates factorial.</p>
<div data-language="py"><pre><code>factorial <span>=</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n <span>==</span> <span>0</span> <span>else</span> n <span>*</span> factorial<span>(</span>n<span>-</span><span>1</span><span>)</span>
factorial<span>(</span><span>5</span><span>)</span> </code></pre></div>
<p>The above solution is invalid since we are calling the function <code>factorial</code> from inside its body. I am using lambda expressions instead of function definition(s) because I find them more convenient; but you may start out using <code>def</code> as long as you can later rewrite your valid solution into an equivalent lambda expression.</p>
<p>How can we rewrite <code>factorial</code> such that we don't use any function name(s) inside its body? In other words, can you run a recursive algorithm in a general-purpose Turing-complete programming language that doesn't allow calling functions by name from within their bodies? You may assume, of course, that the language supports passing functions as arguments.</p>

<p>Let's define <code>part_factorial</code>, an incomplete but valid implementation. It might seem like a useless step, but this is the best baby step we could take in the functional programming universe we are stuck in.</p>
<div data-language="py"><pre><code>

part_factorial <span>=</span> <span>lambda</span> f<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n <span>==</span> <span>0</span> <span>else</span> n <span>*</span> f<span>(</span>n<span>-</span><span>1</span><span>)</span></code></pre></div>
<p>Now we can chain <code>part_factorial</code> to 'manually' achieve a pseudo-recursive solution. </p>
<div data-language="py"><pre><code>part_factorial<span>(</span>part_factorial<span>)</span><span>(</span><span>0</span><span>)</span> 
part_factorial<span>(</span>part_factorial<span>(</span>part_factorial<span>)</span><span>)</span><span>(</span><span>1</span><span>)</span> 
part_factorial<span>(</span>part_factorial<span>(</span>part_factorial<span>(</span>part_factorial<span>)</span><span>)</span><span>)</span><span>(</span><span>2</span><span>)</span> 
part_factorial<span>(</span>part_factorial<span>(</span>part_factorial<span>(</span>part_factorial<span>)</span><span>)</span><span>)</span><span>(</span><span>3</span><span>)</span> </code></pre></div>
<p>Even though we didn't achieve much in the above code, we did manage to write a correct (however incomplete) function definition which can be fully replaced with a lambda expression. For instance, we can rewrite <code>part_factorial(part_factorial)(0)</code> as </p>
<div data-language="py"><pre><code><span>(</span><span>lambda</span> f<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n <span>==</span> <span>0</span> <span>else</span> n <span>*</span> f<span>(</span>n<span>-</span><span>1</span><span>)</span><span>)</span><span>(</span><span>lambda</span> f<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n <span>==</span> <span>0</span> <span>else</span> n <span>*</span> f<span>(</span>n<span>-</span><span>1</span><span>)</span><span>)</span><span>(</span><span>0</span><span>)</span> </code></pre></div>
<p>Now if the above is clear to you, let's get to the main solution we arrived at i.e. the chained way: <code>part_factorial(part_factorial....)..)(n)</code>. Aren't we close to a solution? We are, if we can somehow use a 'meta' function which will keep applying the <code>part_factorial</code> function for as long as needed.</p>

<p>Let's define <code>meta_factorial(copy0, copy1)</code> which takes two copies of some function that 'does' the factorial calculation part. We would want to give two copies of the same underlying function definition so that the <code>meta_factorial</code> function can line up one copy after the other (and hopefully halts). More importantly, since the function definitions (of <code>copy0</code> and <code>copy1</code>) will be present within the scope of <code>meta_factorial</code>, it will always be available and <code>meta_factorial</code> will orchestrate the functionality of applying the function without explicitly calling the function using a name- hence solving the problem.</p>
<div data-language="py"><pre><code>meta_factorial <span>=</span> <span>lambda</span> copy0<span>,</span> copy1<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n<span>==</span><span>0</span> <span>else</span> n <span>*</span> copy0<span>(</span>copy1<span>,</span> copy1<span>)</span><span>(</span>n<span>-</span><span>1</span><span>)</span></code></pre></div>
<p><code>copy0</code> and <code>copy1</code> are placeholders for indeed the same function implementation. Don't worry what that function should be, but do pay attention to how we are planning to solve the problem. Instead of passing a function name, we are sending function 'mechanics' (i.e. function definition, also called abstraction) in the form of lambda expressions, which, when evaluated (also called application), 'progresses' the solution. But what should be the lambda expressions that we should pass for <code>copy0</code> and <code>copy1</code>? The answer is... <code>meta_factorial</code> itself!</p>
<p>You can confirm that <code>meta_factorial(meta_factorial, meta_factorial)(n)</code> is indeed the function that would calculate the factorial for us recursively (and yet, without having to rely on recursion). In other words, say your language stopped supporting recursion, you could still achieve recursion. And it works! </p>
<p>You can confirm that our solution is indeed valid by replacing every <em>symbol</em> <code>meta_factorial</code> with its lambda equivalent definition. The reason we can do this verbatim replacement is because <code>meta_factorial</code> is a combinator. <strong>A combinator, in lambda calculus, is a lambda expression that has no free variables.</strong> That is, any variable (or function) name that was used during the evaluation of the expression <code>meta_factorial(meta_factorial, meta_factorial)</code> was already contained within) the body of <code>meta_factorial</code> itself. </p>
<p>As to why feeding copies of <code>meta_factorial</code> to itself (as in <code>meta_factorial(meta_factorial, meta_factorial)</code>) works and how I came up with the answer is difficult to explain- it was a pure gut feeling. I can attempt to explain it, but I'd be doing you more harm. The proof is in the pudding. Therefore, I think you should sit down (or stand up), stare at the everything above that you've fed into your IDLE by now, scribble a bit and try to re-explain everything to yourself... Now, the reason it works and why I must have come up with this solution is that what we generally call a function (say, in Python) has two meanings- 1. the actual definition (also called abstraction in the lambda calculus), and 2. the application of it. Try to pick that nuance and you'd hopefully get everything here too without too much trouble.</p>
<p>For the sake of completeness, you may confirm that the equivalent lambda expressens, when evaluated, will calculate the factorial:</p>
<div data-language="py"><pre><code><span>(</span><span>lambda</span> copy0<span>,</span> copy1<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n<span>==</span><span>0</span> <span>else</span> n <span>*</span> copy0<span>(</span>copy1<span>,</span> copy1<span>)</span><span>(</span>n<span>-</span><span>1</span><span>)</span><span>)</span><span>(</span>
    <span>lambda</span> copy0<span>,</span> copy1<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n<span>==</span><span>0</span> <span>else</span> n <span>*</span> copy0<span>(</span>copy1<span>,</span> copy1<span>)</span><span>(</span>n<span>-</span><span>1</span><span>)</span><span>,</span>
    <span>lambda</span> copy0<span>,</span> copy1<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n<span>==</span><span>0</span> <span>else</span> n <span>*</span> copy0<span>(</span>copy1<span>,</span> copy1<span>)</span><span>(</span>n<span>-</span><span>1</span><span>)</span><span>)</span> <span>(</span><span>5</span><span>)</span> </code></pre></div>

<p>We have solved the original problem. But if you stare long enough at the above code, it is begging to be refactored. As a matter of, we can do it all with just one copy of <code>meta_factorial</code>.</p>
<div data-language="py"><pre><code>meta_factorial <span>=</span> <span>lambda</span> copy0<span>,</span> n<span>:</span> <span>1</span> <span>if</span> n<span>==</span><span>0</span> <span>else</span> n<span>*</span>copy0<span>(</span>copy0<span>,</span><span>(</span>n<span>-</span><span>1</span><span>)</span><span>)</span>
meta_factorial<span>(</span>meta_factorial<span>,</span> <span>11</span><span>)</span> </code></pre></div>
<p>If you want to fix the function <code>meta_factorial</code> to take only only argument, you can easily fix that.</p>
<div data-language="py"><pre><code>meta_factorial <span>=</span> <span>lambda</span> copy0<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n<span>==</span><span>0</span> <span>else</span> n<span>*</span>copy0<span>(</span>copy0<span>)</span><span>(</span>n<span>-</span><span>1</span><span>)</span>
meta_factorial<span>(</span>meta_factorial<span>)</span><span>(</span><span>11</span><span>)</span> </code></pre></div>
<p>In pure lambda expressions form,</p>
<div data-language="py"><pre><code><span>(</span><span>lambda</span> copy0<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n<span>==</span><span>0</span> <span>else</span> n<span>*</span>copy0<span>(</span>copy0<span>)</span><span>(</span>n<span>-</span><span>1</span><span>)</span><span>)</span><span>(</span>
    <span>lambda</span> copy0<span>:</span> <span>lambda</span> n<span>:</span> <span>1</span> <span>if</span> n<span>==</span><span>0</span> <span>else</span> n<span>*</span>copy0<span>(</span>copy0<span>)</span><span>(</span>n<span>-</span><span>1</span><span>)</span><span>)</span><span>(</span><span>11</span><span>)</span> </code></pre></div>
<p>The problem is solved; and yes you do not need your programming language to support recursion to achieve recursion. What is going on here and how it worked is actually due to a fixed-point combinator called the Y-combinator (discovered first by Haskell Curry). <strong>A fixed-point combinator is a combinator (defined above) returns some fixed point of its argument function (i.e. it returns a function that is applied to its argument (which could very well be a function too)).</strong> And this is what generalizes the concept of recursion without having to call a function from inside itself. </p>
<p>Right now, we do not see the Y-combinator because it is buried somewhere in the implementation above. Once we extract out the Y-combinator, we would be able to use it as a generalized higher-order function that convert any explicitly recursive problem into a non-recursive one! Let's say if the Y-combinator was callable as <code>Y(f)</code>, then we could have solved our original problem in one shot, by calling <code>part_factorial(Y(f))(n)</code> where <code>part_factorial = lambda f: lambda n: 1 if n == 0 else n * f(n-1)</code>. </p>
<p>In the follow-up post, we will derive the Y-combinator from all the work that we did above and use it to build solutions for common recursion-based problems.</p>
<hr>
<h2 id="where-to-go-from-here">Where to go from here:</h2>
<ol>
<li>Try solving the original problem, but without looking at the solutions in the post. I spent a good night and three cups of <a href="https://en.wikipedia.org/wiki/Turkish_coffee" target="_blank" rel="nofollow noopener noreferrer">Turkish coffee</a> to come up with the solutions! </li>
<li>Try deriving the Y-combinator yourself. The <a href="https://en.wikipedia.org/wiki/Fixed-point_combinator#Y_combinator" target="_blank" rel="nofollow noopener noreferrer">Wikipedia</a> entry is a good place to start.</li>
<li>Some optimal resources on lambda calculus; each has its own flavor:</li>
</ol>
<ul>
<li><a href="https://www.inf.fu-berlin.de/lehre/WS03/alpi/lambda.pdf" target="_blank" rel="nofollow noopener noreferrer">https://www.inf.fu-berlin.de/lehre/WS03/alpi/lambda.pdf</a>, </li>
<li><a href="https://www.cs.bham.ac.uk/~axj/pub/papers/lambda-calculus.pdf" target="_blank" rel="nofollow noopener noreferrer">https://www.cs.bham.ac.uk/~axj/pub/papers/lambda-calculus.pdf</a>, </li>
<li><a href="https://plato.stanford.edu/entries/lambda-calculus/" target="_blank" rel="nofollow noopener noreferrer">https://plato.stanford.edu/entries/lambda-calculus/</a></li>
</ul>
<ol start="4">
<li><a href="https://mvanier.livejournal.com/2897.html" target="_blank" rel="nofollow noopener noreferrer">The Y Combinator (Slight Return)</a> by Mike Vanier is an excellent post. It's so good that if I had found it earlier, I wouldn't have written this very post.</li>
<li>Wait for my follow-up post next week (Dec 7, 2020) :) </li>
</ol>
</div></div>]]>
            </description>
            <link>https://www.lambdacircle.com/discovering-the-y-combinator-by-mistake-1-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306294</guid>
            <pubDate>Fri, 04 Dec 2020 19:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple is sued in EU over iPhones that wear out too quickly]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25306260">thread link</a>) | @fsflover
<br/>
December 4, 2020 | https://www.bnnbloomberg.ca/apple-faces-eu-lawsuits-over-iphones-that-wear-out-too-quickly-1.1530577 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/apple-faces-eu-lawsuits-over-iphones-that-wear-out-too-quickly-1.1530577">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>      
      
      <section>
        
        <div>
            		    
                  
    
  
    
  
    
    
        




      
    
    
        










        

    



<section data-obj-id="axisCollectionObj_7_339835_1525068379" ng-controller="AxisCollection" ng-init="init()">

                        
        
			
                        
        
	        

    

    <p>The information you requested is not available at this time, please check back again soon.</p>

			        <a href="https://www.bnnbloomberg.ca/video" title="">More Video</a>
    	
</section>

	

      
    
    
        

                        
        


      
    
    
        
            
    

      
  
        		      			      				    
                  
    
  
    
  
    
    
            


      
  
        			    		          </div>
        <div>
                                          
        
                                
            
    
        
    
    
                        
                        
                    

                

                                        <article>
            
            <div>

                                <header>
                                            		                                                                        
                    
        	    
                        
                    
                                                            
                    
                </header>

                                                <div>
                                                                    

<div>
    <div ng-controller="PersistentPlayer">
        <div>
                
                                    
                
    
            <p id="persistent-title"><h3>Norman Levine discusses Apple</h3></p>
    
                <p><span onclick="BmAuth.handleSignOut(); Tracking.trackLogout(); return false;">VIDEO SIGN OUT</span>
    </p>
        </div>
    </div>

    </div>
                
                
                                </div>
    
                                                    
                                
                                <div><p>Apple Inc. is facing lawsuits in several European countries seeking about 180 million euros (US$217 million) over misleading claims about the battery life of older iPhones.</p>

<p>A group of five European consumer organizations filed class-action suits in Belgium and Spain and plans to sue in Italy and Portugal over the coming weeks, Euroconsumers said in an emailed statement Wednesday. The lawsuits concern users of various iPhone 6 devices.</p>

<p>The lawsuits mirror U.S. cases over claims that the company misled consumers about iPhone battery power and software updates that slowed the performance of the devices. The California-based company last month&nbsp;agreed&nbsp;to pay US$113 million to settle a case with multiple U.S. regulators while customers are seeking approval from a U.S. court for a class-action settlement that could be worth as much as US$500 million.</p>

<p>â€œConsumers are increasingly upset by products wearing out too quickly, the iPhone 6 models being a very concrete example of that,â€� said Els Bruggeman, head of policy and enforcement at Euroconsumers. â€œNot only does it cause frustration and financial harm, from an environmental point of view it is also utterly irresponsible.â€�</p>

<p>The group sent a cease and desist letter to Apple in July, asking it to stop a practice that allegedly forces users to install updates that slow down their phones so much that they become obsolete and a new model is needed.</p>

<p>Apple said in a statement that it would never â€œdo anything to intentionally shorten the life of any Apple product, or degrade the user experience to drive customer upgrades.â€�</p>

<p>The Financial Times previously reported on the European lawsuits.</p>
</div>

            </div>

        </article>



                
    
        
    
    


                                  
                  
    
  
    
  
    
    
        
  

      
    
    
        
<article id="feed-widget">
	            
    
                    </article>
      
  
              </div>
      </section>
    </div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/apple-faces-eu-lawsuits-over-iphones-that-wear-out-too-quickly-1.1530577</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306260</guid>
            <pubDate>Fri, 04 Dec 2020 19:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gold vs. Bitcoin is a self-defeating doom-loop]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25306259">thread link</a>) | @StuntPope
<br/>
December 4, 2020 | https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/ | <a href="https://web.archive.org/web/*/https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/#comments">
			2 <span></span>
		</a></p>
		
		
				<h3><img loading="lazy" src="https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med.jpg" alt="" width="800" height="600" srcset="https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med.jpg 800w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-300x225.jpg 300w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-150x113.jpg 150w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-768x576.jpg 768w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-65x49.jpg 65w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-220x165.jpg 220w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-133x100.jpg 133w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-358x269.jpg 358w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-533x400.jpg 533w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-600x450.jpg 600w, https://outofthecave.io/wp-content/uploads/2020/12/keynsian_bliss_med-680x510.jpg 680w" sizes="(max-width: 800px) 100vw, 800px"></h3>

<p><em>With all due respect to the people arguing this one way or the other – many of whom are super intelligent. This argument is a self-defeating doom loop that can only be resolved via an act of faith.</em></p>
<h3>Introducing your Economic Apocalypse Toolkit</h3>
<p>With both Bitcoin and gold (and stonks, for that matter) at or recently off of all time highs the age old debate of whether gold is better than Bitcoin or vice versa is everywhere. I finally sat down and mapped out the <strong>Economic Apocalypse Toolkit</strong> after listening to Grant Williams and Bill Fleckenstein’s <a href="https://podcasts.apple.com/lv/podcast/the-end-game-ep-12-fred-hickey/id1508585135?i=1000501094047">End Game podcast episode with Fred Hickey</a>, who writes <strong>The High Tech Strategist</strong>.</p>
<p>In it they hit on the perennial question of “gold vs Bitcoin” and Hickey laid out his objections to it. I’ve been a subscriber of The HTS for several years now and think it’s absolutely fantastic, and of course I also subscribe to <a href="https://ttmygh.com/">Grant Williams TTMYGH</a> and <a href="https://www.fleckensteincapital.com/home.aspx">Fleck’s newsletter</a> as well. All great stuff, well written, from extremely intelligent people. I do get the sense that Williams is somewhat open to Bitcoin and he <em>wants&nbsp;</em>to talk about it and explore the idea that it may be something more than the usual tropes: <a href="https://outofthecave.io/articles/this-time-is-different-part-i-what-bitcoin-isnt/">a ponzi, based on nothing, Tulipmania, etc</a>, but maybe he’s hesitant at prospect of taking heat for suggesting it.<span id="more-1451"></span></p>
<p>I just find the entire debate pointless because people who invest in either asset class&nbsp;<em>are doing so for the same reasons.&nbsp;</em>They are reacting to the same threat, they see the same unsustainability, they are preparing for the same End Game, if you will.</p>
<p>Given that many of the people who see the underlying issues are of a capital allocator, long term mindset, why is this being thought of in terms of either/or and not in terms of probabilities and scenarios?</p>
<p>If the job at hand is to protect one’s wealth from systemically rigged and disintegrating monetary regime, arguing for one over the other feels like trying to defend against it with only half the available toolkit. Is there a mechanic who wouldn’t be caught dead with a screwdriver in his toolbox because he can give you a list of reasons why every problem can be solved with a wrench? “Screwdrivers for suckers!”</p>
<p>The entire gold vs crypto argument goes away when one realizes that there is more overlap in the objectives of each asset than there are differences. And if you can get your own biases out of the way, then even the differences when looked at objectively seem to have uncanny parallels</p>
<blockquote><p><strong>Gold</strong> has a 5,000 year track record, and has never failed to hold its value, which is quite impressive and has to count for something….<br>
<strong>Bitcoin</strong> has broken out of nowhere and taken the world by storm in an astonishingly small amount of time, which is quite impressive and has to count for something…</p>
<p><strong>Bitcoin</strong> is backed by nothing.<br>
<strong>Gold</strong> is just a shiny rock.</p>
<p>Without electricity, Bitcoin is useless.<br>
You can’t eat gold.</p>
<p><strong>Quantum computing</strong> will eventually destroy Bitcoin’s encryption.<br>
<strong>Asteroid mining</strong> will eventually make gold abundant and cheap.</p>
<p>Bitcoin is a ponzi.<br>
What’s the definition of a gold mine? A hole in the ground with a liar standing beside it.</p></blockquote>
<p>I could go on….</p>
<p>Since the future is unknowable and certainty elusive, aligning with one aspect of the above over the other has to be a choice not a fact. It’s an act of faith. So why not embrace agnosticism and make use of both sets of tools in your financial survival toolkit?</p>
<h3>The Toolkit</h3>
<p>Let’s just step briefly through some of the items in the mindmap. We have metals on one side, cryptos on the other.</p>

<div id="attachment_1452"><p><a href="https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit.png" target="_new" rel="noopener noreferrer"><img aria-describedby="caption-attachment-1452" loading="lazy" src="https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit.png" alt="" width="800" height="492" srcset="https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit.png 2074w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-300x185.png 300w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-1024x630.png 1024w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-150x92.png 150w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-768x473.png 768w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-1536x945.png 1536w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-2048x1260.png 2048w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-65x40.png 65w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-220x135.png 220w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-163x100.png 163w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-358x220.png 358w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-650x400.png 650w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-731x450.png 731w, https://outofthecave.io/wp-content/uploads/2020/12/TheToolkit-829x510.png 829w" sizes="(max-width: 800px) 100vw, 800px"></a></p><p id="caption-attachment-1452">Click for large version</p></div>
<p>On the cryptos side, I just think Bitcoin is the crypto-reserve currency and will continue to be for the foreseeable future. My preferred way to accumulate BTC is to earn it via my businesses. <a href="https://easydns.com/">easyDNS</a> has been accepting Bitcoin since 2013 and we’re <a href="https://easydns.com/landers/earn-crypto/">developing a payments service for clients</a> that will be based on <a href="https://btcpayserver.org/">BTCPayserver.</a></p>
<p>I put Litecoin and alts in there to trigger the maximalists. As per the Supersuckers song, <em>“I like it all man. (All or nothin’ I’m all in even when I’m bluffin’)”.</em></p>
<p>Ethereum is different animal, I think the Bitcoin vs Ethereum schism is every bit as fucking stupid as Gold vs Bitcoin. They do different things, and while they overlap in some aspects, that doesn’t mean there should only be one path forward.</p>
<p>The way I think about it, Bitcoin is the value, Ethereum is the execution. When I hear people dismiss Bitcoin because “there is as yet no ‘killer app’ that anybody has come up with for Bitcoin” I like to ask them “what is the killer app for the money in your wallet?”. Do you want to be able to play video games on your money? Collaborate on a document with your coworkers before you spend it? Dollars or&nbsp; euros aren’t dismissed as useless because nobody has come up with a compelling use case for them. You just spend it. <em>That’s&nbsp;</em>the use case.</p>
<p>Ethereum on the other hand, well that’s a whole different ball game. Smart contracts, DeFi, even Dao’s (despite early setbacks) will completely transform our lives. Ethereum, and other projects like it (Cardano, EOS, and even Ravencoin, which is actually a Bitcoin fork)&nbsp; are going to provide ways to code parameters and instructions around value and wealth that will be guaranteed to execute and can outrun government overreach.</p>
<p>We’re now coming out of that <a href="https://outofthecave.io/articles/welcome-to-bitcoins-trough-of-disillusionment/">“Trough of Disillusionment”</a> I wrote about back in 2018 and we have actual companies, actual businesses and ways to derive income now in crypto. We can invest in miners, in crypto based publicly traded companies, we can stake our assets or lend them and earn a return on them. Multiple income streams available here so we actually have some ability to compound whatever wealth we’ve managed to port to the crypto-economy separate from any nominal gains garnered in fiat terms.</p>
<p>And of course, with crypto we have the ability to move capital, in figurative terms, simply by thinking about it. If Actual Communism comes to your habitat and the best you can manage is to get out with your skin and some pass phrases you’ve remembered in your head, you can retrieve some of your assets wherever you come up for air (read <a href="https://amzn.to/2IghIzy">“We The Living”</a>. Take it to heart. This is the fate we seek to avoid, and large chunks of the world are barreling straight at it).</p>
<p>On the precious metals side you have your physical metals which, if all goes well, you simply keep vaulted in various places and your currency never collapses and you teach your kids that they should preserve the hoard and only use it in extreme emergencies down the road. And to teach their kids the same. You have junk silver in case there <em>is&nbsp;</em>a currency crisis and you don’t want to have to carve off a piece of a Krugerrand in order to buy some food at the market.</p>
<p>You have some gold tucked away in international vaults like <a href="http://www.bullionvaultaffiliate.com/trustable">Bullionvault</a> and <a href="https://www.goldmoney.com/w/wealthnet">Goldmoney</a>. My cousins run <a href="https://www.trustablegold.com/">TrustableGold.com</a> which rates these places.</p>
<p>All of this stuff, especially on the crypto side, has to be set up in advance, and you have to know how to navigate these systems before TSHTF. When a mob of mostly peaceful democratic socialists are tearing through your town and burning down your homes and businesses, or when the government is hanging both goldbugs and HODL-ers from lamposts, you do not want to be learning how to set up a Monero wallet and frantically converting as much as you can into it, nor do you want to be just then opening your Goldmoney account and trying to wire in some funds.</p>
<p>It has to be ready <em>now</em>, so&nbsp; when the inevitable&nbsp;<em>Financial Repressions </em>intensifies, or God forbid, the <em>Financial Tyranny</em> occurs, you can focus on executing your exit plans and coming out on the other end with enough capital and wealth to rebuild.</p>
<h3>The missing link</h3>
<p>What we really need are bridges between crypto-currencies and gold. Not metaphorical “can’t we all be friends” bridges, I mean gateways, tokenized/staked storage and transfer of precious metals. Conversion into or out of crypto from metals. This is not easy.</p>
<p>There have been attempts in the past, <a href="https://theagora.libsyn.com/gold-vs-crypto">Roger Ver, in Sal the Agorist’s recent “Gold vs Bitcoin” podcast</a> mentioned e-gold. easyDNS was the only domain registrar to accept e-gold back in the day and that’s how we amassed our physical gold which remains on our balance sheet even now. But contrary to Ver’s assertion that the government’s shutdown of E-gold speaks to gold’s inferiority to Bitcoin – that’s not entirely accurate. E-gold turned a blind eye to governance and it really was a wild west of ponzi schemes and criminal activity. Contrast with other DGCs of the day, like Pecunix or Goldmoney, the latter of which still exists. Goldmoney had far more stringent KYC and governance protocols, self-enforced, and here they are – still up and running.</p>
<p>In fact it was Goldmoney who had one of the more recent attempts at Bitcoin to vaulted gold convertability under their incarnation as Bitgold. They’ve since discontinued this precisely because of the governance hurdles.</p>
<p>I won’t trivialize how hard this is, but for people droning on about the need for a ‘killer app’, this one would probably do well.</p>
<h3>It’s all about optionality</h3>
<p>Both metals and crypto tribes look at the financial system and our legacy institutions as entering some form of breakdown and decline. Because the future is inherently unknowable, what makes more sense?</p>
<p>A) Betting on one half of a toolbox that may pay off huge in some scenarios but be worthless in others, or</p>
<p>B) Having a full toolbox that can give you some good outcomes under most imaginable circumstances?</p>
<p><strong>If you’re a goldbug</strong>, would it kill you to have a&nbsp;<em>fraction&nbsp;</em>of your liquidity in Bitcoin, knowing that from past events crypto superspikes tend to 10X or 100X or more with stubborn repetitiveness and increasing magnitude?</p>
<p><strong>If you’re into Bitcoin</strong>, buying the right gold miners now with a fraction of your capital may very well set you up with an increasingly fat, cushy dividend stream in a few years that you can use for living expenses while you continue to HODL.</p>
<p>Now there are many End Gamer luminaries out there who are invested in both even though …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/">https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/</a></em></p>]]>
            </description>
            <link>https://outofthecave.io/articles/gold-vs-bitcoin-is-fucking-stupid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306259</guid>
            <pubDate>Fri, 04 Dec 2020 19:01:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blogging for Devs Trends]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25306129">thread link</a>) | @colinbartlett
<br/>
December 4, 2020 | https://bloggingfordevs.com/trends/ | <a href="https://web.archive.org/web/*/https://bloggingfordevs.com/trends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Hello and Welcome!</h2><p><strong>Blogging for Devs Trends</strong> is meant to be a fun way to discover the most discussed technical content on Twitter, without doomscrolling your day away.</p><p>To do this, we track <strong>181</strong> of the best technical blogs by developers and industry experts, across over two dozen categories.</p><p>Points are weighted to reward mentions and replies by individual developers more than likes and retweets.</p><p>You can help by recommending your favorite developer blogs &amp; blogs about software, or telling your friends and followers if you like this resource.</p><p>Hope you find something cool here.</p><p><a href="https://bloggingfordevs.com/trends/how-it-works/">Learn how it works</a></p><div><p><img alt="Monica Lent" src="https://bloggingfordevs.com/images/my-face.jpg" color="black"></p><div><p><span>Creator, BloggingforDevs.com</span></p></div></div></div><p>The more people know about Trends, the more developers' blogs are discovered and followed. Help us get the word out!</p></div>]]>
            </description>
            <link>https://bloggingfordevs.com/trends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306129</guid>
            <pubDate>Fri, 04 Dec 2020 18:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Myth of Code Coverage]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25306071">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://preslav.me/2020/12/03/the-myth-of-code-coverage/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/12/03/the-myth-of-code-coverage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body"><p>One question I often ask potential software engineering candidates is to pinpoint the percentage of code coverage in an ideal project. Interestingly enough, many of them jump to the sky with numbers beyond 90%. They would start preaching how well-tested code is more reliable and brings more value to all stakeholders. When I ask about the current projects they work on, the reality looks a bit more down to earth.</p><p>Want to know my answer? I'd say it's <strong>around 66.7%</strong>.</p><p>The reasons for that vary, but allow me to be blunt and say that <strong>1/3 of the code every software project is irrelevant, buggy, overly complicated, or simply sucks.</strong> It has a reason to be where it is, but chances are, one year down the road, it will become a liability. Being dogmatic about tests and covering every line will only make it more difficult to get rid of it.</p><p>See, no two lines of code are equal in value and importance. Adding a new feature to an existing application affects its capabilities only marginally. However, it takes a proportionally large amount of time to develop and integrate due to the existing complexity. The bigger the complexity, the longer it takes to introduce new functionality. By the time the feature finds itself in production, it may as well be already irrelevant.</p><blockquote>The only sure-fire way to improve code coverage (and by that keep software relevant) is to identify and remove the unnecessary code.</blockquote><p>How do you identify irrelevant code? Don't search for it. Instead, let it reveal itself to you. One dimension of software that few teams make good use of, is its history. Git is a great analysis tool. Start using it not only to prevent future problems but also, to understand where and how often certain parts of the code change over time.</p><p>Chances are, you will find pieces of code that have undergone fewer changes than the rest in long periods. Those are the pillars of your application - the 2/3s that <strong>must be well-tested</strong>.</p><p>You will also find others where changes occur more or less every week. Ask yourselves whether those are still relevant, both from a technical and business perspective. Adding tests for the sake of coverage would have the opposite effect of increasing the code quality. In a perfectly-design software project, the part that is allowed to change most often is the configuration. A simple analysis of the code change frequency would show whether that is the case. If it isn't, try separating the moving parts from the core logic. If this is not feasible either, most probably those portions of the code don't belong to the codebase anyway. Turning them into interchangeable scripts (even stored in a separate repository) is one way of tackling them in their own right.</p><p>Let's not get too much into technical details. I have already alluded to the work of <a href="https://twitter.com/AdamTornhill">Adam Tornhill</a> on code analysis in a previous post of mine:</p><figure><a href="https://preslav.me/2020/03/01/use-the-git-history/"><div><p>Use the Git History to Identify Pain Points in Any Project</p><p>Have you heard of Adam Tornhill [https://twitter.com/AdamTornhill]’s work? If
not, I highly recommend that you set some time aside and check out Your Code as
a Crime Scene [https://amzn.to/32DM1G9] or Software DEsign X-Rays
[https://amzn.to/2vtbjdR…</p><p><img src="https://preslav.me/favicon.png"><span>Preslav Rachev</span></p></div><p><img src="https://www.gravatar.com/avatar/fd47e6bba1f42ecacf2e7af9e4c5fb52?s=250&amp;d=mm&amp;r=x"></p></a></figure><p>In a future post, I will discuss some of the new ideas I applied to the simple git one-liner I presented there.</p></div>
</div></div>]]>
            </description>
            <link>https://preslav.me/2020/12/03/the-myth-of-code-coverage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306071</guid>
            <pubDate>Fri, 04 Dec 2020 18:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built powered motorcycle panniers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25305957">thread link</a>) | @nicbou
<br/>
December 4, 2020 | https://nicolasbouliane.com/projects/powered-panniers | <a href="https://web.archive.org/web/*/https://nicolasbouliane.com/projects/powered-panniers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
        <article>
            <p>
                Built in <time datetime="2020-12-04 12:32:00">2020</time>.
            </p>
                        <p>On longer motorcycle trips, I&nbsp;often struggle to keep all my devices charged. When I&nbsp;camp for a few days, I can't find a wall socket. When I&nbsp;sleep in hostels, I&nbsp;don't want to leave my things unattended. Even when I sleep in hotels, I'm too exhausted to think about it.</p>
<p>It might seem like a trifle, but when you travel by motorcycle, you only get a few hours a day to feed yourself, clean yourslef, plan the route ahead, keep the bike running, and charge your gear. The small annoyances add up.<br></p>
<p>Instead, I wanted to charge my devices on the motorbike, inside my panniers, and preserve my energy for other things.</p>
<figure><img src="https://nicolasbouliane.com/images/_fullWidth2x/The-general-plan.png" alt=""><figcaption>The general idea</figcaption></figure>
                        <h2>Thinking inside the box</h2>
<p>Bringing power <em>inside</em> the pannier was no walk in the park. I needed a connector that could be exposed to mud, dust and torrential downpours, and still work safely. It had to be easy to connect and disconnect, because I&nbsp;take the  panniers off every night.<br></p>
<p>I wasted a whole  day on&nbsp;<a href="https://www.digikey.com/">Digikey</a>,  looking for the perfect connector. As 
the bill of material ran close to 100€, 
I remembered about <a href="https://nicolasbouliane.com/images/sae-connector.jpg">SAE connectors</a>. They're tough, they're
waterproof, and they're an automotive industry standard. Oh, and they're also dirt cheap. I found an <a href="https://amzn.to/2L0EoEQ">SAE panel mount connector</a> on Amazon, and lots of cheap cables and connectors to bring the system together.<br></p>
<figure><img src="https://nicolasbouliane.com/images/_fullWidth2x/pass-through-diagram.png" alt=""></figure>
<p>I placed the connector on the rear of the pannier. This way, I
 can check if the luggage is secured, locked and connected in one 
glance. If I placed it in the front, I'd bump into it when moving on the bike
 and destroy it. The front side also tends to get caked in 
bugs and mud. If I placed it on the inner side, I'd likely forget it's there and tear it off on the first day.<br></p>
<p>I used a <a href="https://amzn.to/2JEYd4d">step drill bit</a> to make holes for the connector, and bolted it in place with a layer of automotive silicon in the middle. That's the same silicon they use to install windscreens, so it ought to keep the water out. I used waterproof washers on the other side, just in case. As I&nbsp;tightened the bolts, the extra silicon oozed out, and I&nbsp;wiped it off with a rag.&nbsp;I put the connector under running water for 15 minutes, and it didn't leak.</p>
<p>I wanted to use <a href="https://en.wikipedia.org/wiki/ISO_metric_screw_thread">M5 bolts</a> for the connector, because I already pack the right tools, but the holes were too small. I used smaller M3 bolts and added a 5.5mm socket to my packing list.<br></p>

                            
                <p>All in all, it turned out exactly as I hoped. The connector is tough and waterproof, and it looks halfway decent.<br></p>
                            
                <p>Inside the panniers, I fit two 12V cigarette lighter plugs in a plastic enclosure. The enclosure can quickly be opened for inspection during border crossings.</p>
<p>I used the 4 bolts that stick out of the SAE connector to secure the enclosure to the pannier.&nbsp;Instead of soldering the wires in place, I used removable <a href="https://amzn.to/3gcMvcR">Wago connectors</a>. This should make field repairs much easier. I only need a Phillips screwdriver and a 5.5mm socket. I could also transfer the enclosure to a different set of panniers later.</p>
                            
                <p>This project coincided with my switch to USB-C. I charge all my devices with the same cables, wall sockets and car adapters. It saves a lot of space and weight.</p>
<p>I&nbsp;put a USB-C PD adapter in each cigarette lighter plug. One charges two devices at once, and the other delivers up to 72 Watts, enough to charge my Macbook.</p>
<p>If USB-C falls out of fashion, I can replace those adapters with something else.</p>
                        <h2>From the battery to the panniers<br></h2>
<p>This is roughly how I wired everything together between the battery and the panniers.&nbsp;I designed the circuit to be modular, flexible and field-repairable. I used <a href="https://nicolasbouliane.com/images/sae-connector.jpg">SAE connectors</a> to connect the components together. Nothing is glued or soldered in <br>place. If something needs maintenance, I can just disconnect it and pull it out. My mini compressor and my battery tender also use SAE&nbsp; connectors, so I can just plug them in.</p>
<figure><img src="https://nicolasbouliane.com/images/_fullWidth2x/wiring-diagram.png" alt=""></figure>
<p>My Macbook draws up to 87 Watts (4.3A @ 20.2V), my phone up to 15 
Watts (1.67A @ 15V), and everything else up to 10 Watts (2A @ 5V). In 
any case, the power draw is capped by my USB-C car adapters. One 
delivers up to 72 Watts, and the other up to 36 Watts. In other 
words, we top off at 108 Watts.</p>
<p>My heated grips also draw up to 39 Watts<sup><a href="https://www.webbikeworld.com/koso-apollo-heated-grips-review/">1</a></sup>. That  brings us to roughly 150 Watts.</p>
<p>I also have a <a href="https://amzn.to/2VEKhcQ">mini air compressor</a> that draws up to 72 Watts. If we wanted to charge <em>everything</em>, keep our hands warm <em>and</em> reinflate a tire at the same time, we'd draw roughly 220 Watts. Realistically, that never happens, so let's stick to <strong>150 Watts</strong>. At 12 volts, that's 12.5 Amps. 16 gauge wire should be enough<sup><a href="https://en.wikipedia.org/wiki/American_wire_gauge#Tables_of_AWG_wire_sizes">1</a>, <a href="https://www.powerstream.com/Wire_Size.htm">2</a></sup>.<br></p>
                            
                <p>That black enclosure in the middle is the  relay box. It connects the other components to the ignition switch. When the ignition is off, the entire circuit is off. If I leave something plugged in overnight, I&nbsp;won't wake up to a dead battery. That's a risk I can't afford to take when I'm driving through deserts, several thousand kilometres from home.<br></p>
<p>Inside the relay box, I use <a href="https://en.wikipedia.org/wiki/Screw_terminal">screw terminals</a> and <a href="https://amzn.to/3gcMvcR">Wago connectors</a>, no soldering. I&nbsp;can modify the circuit using <a href="https://nicolasbouliane.com/blog/motorcycle-packing-list">the tools I usually carry</a>. Again, this greatly simplifies field repairs. The relay circuit itself is Bigpie's Fuse Box. It's great, except that it uses full-sized ATC fuses, while the motorbike uses mini ATC fuses. I need to carry two kinds of spare fuses. Fortunately, they're not very heavy.</p>
<p>I&nbsp;also had some issues with the screw terminals. They're a tad flimsy. When I opened the relay box to take photos, one of the connections came undone.</p>
                            
                <p>The relay box is right under the seat. I&nbsp;was a bit worried about water getting in there. After spending a few hours researching expensive waterproof grommets, I called my father, who reminded me about  hot glue.<br></p>
                            
                <h2>Finishing touches</h2>
<p>Once the circuit was tested and working, I held everything in place with cable ties. I&nbsp;added green tape on everything I&nbsp;added, to make it easier to identify what came with the bike, and what didn't.</p><h2>Final result</h2>
<p>It's winter, and we're in the middle of a global pandemic, so my powered luggage didn't see much action. However, I tested it with all of my devices, and it works great. I'm looking forward to a proper field test.</p>
            
            
                
        </article>

                            </div>
            
                        </div></div>]]>
            </description>
            <link>https://nicolasbouliane.com/projects/powered-panniers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305957</guid>
            <pubDate>Fri, 04 Dec 2020 18:36:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we saved our indie coworking from Covid and got into growth mode]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25305760">thread link</a>) | @JohanCutych
<br/>
December 4, 2020 | https://www.crazymonkeys.io/written-bits/how-we-saved-our-indie-coworking-from-covid-and-got-into-growth-mode | <a href="https://web.archive.org/web/*/https://www.crazymonkeys.io/written-bits/how-we-saved-our-indie-coworking-from-covid-and-got-into-growth-mode">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>When COVID hit the first time, we lost 80% of our little independent coworking space revenue within a month 😱.</p><p>The math were pretty simple: 30% of our revenue come from the venue booking for events, 40% from sponsorship, 10% from our own events &amp; 20% from actual coworking membership. With no event, we don't only loose the revenue from this channel but also the value creation we are selling to sponsors: traffic and exposure. So all others channels are getting impacted 💥.</p><p>After a month of tears and cry, I realised that this was not a threat: it was actually a surge to upgrade our model. The way events are done and value creation perceived will never be the same again. And we better embrace it now!<br>So we turned one of our meeting room into a fully equipped studio and started promoting hybrid events to companies.</p><p>At the beginning, very few got the point: "Why would I need you when I can simply do a Facebook live on my own". Then they eventually realised that there is 99 ways to do a shitty online event 💩. And finally, when they saw the quality and engagement of our own hybrid event, it was WAY easier to sign some deals.</p><p>Quickly, hybrid events became a major part of our revenue. What so interesting is that it became an asset to leverage the existing sponsorship deals we signed pre covid. In deed we will never get the level attention we have today. Meanwhile, most companies social media are cruelly missing high quality content. Thanks to that sponsorship, they were able to deliver value added &amp; relevant content to their audience without having to create it.</p><p>Smaller content creators and individuals were also interested by the value creation: a plug and play space where they could create live content in the best possible condition without having to manage the technical parts.</p><p>Today, our revenue is mainly driven by content creation needs. Podcast, videocast, live events, interview, it really looks like more and more people understood that quality has a cost but also a return on investment and they are willing to pay for it.</p><p>Based on our successful execution, we got the attention of bigger companies and had the honor to co-create <a href="https://www.antistud.io/" target="_blank">https://www.antistud.io</a>, a series a coworking coffee in France turned into production ready spaces.</p><p>To put some context, our coworking space (<a href="https://www.facebook.com/lespot.coworking.guadeloupe" target="_blank">https://www.facebook.com/lespot.coworking.guadeloupe</a>) is based in Guadeloupe, a tiny island in the Caribbean. So you can imagine how proud we are to start from there something that is creating value for a way bigger company.</p><p>➡ The take away for you: Where ever you are, what ever is the size of what you're doing, keep in mind that in the internet world, it can be seen by anyone and inspire. So make sure you turn your valuable work into an asset by documenting it. I know, the process is often tiring but if you are doing is creating value for others, the magic of the internet karma powered by your intention will create some magic for you !</p><p>🔗 Our coworking: <a href="https://www.facebook.com/lespot.coworking.guadeloupe/" target="_blank">https://www.facebook.com/lespot.coworking.guadeloupe/</a><br>🔗 The coworking cafe startup Anticafé: <a href="https://anticafe.eu/" target="_blank">https://anticafe.eu</a><br>🔗 Our co-creation with Anticafé: <a href="https://www.antistud.io/" target="_blank">https://www.antistud.io/</a></p><p>‍</p></div></div><div id="signup"><p>💌 &nbsp;No pressure...</p><div><h2>Come, be a little crazy too</h2><p>Subscribe to our newsletter. We share many things here, but there is even more. Trust me.</p><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div><p><a href="#"><img src="https://assets.website-files.com/5fbb8bd8394558e7d25efb77/5fca02c239c7dc65b0dc4ce1_logo_cm.png" loading="lazy" width="149" alt=""></a></p></div></div>]]>
            </description>
            <link>https://www.crazymonkeys.io/written-bits/how-we-saved-our-indie-coworking-from-covid-and-got-into-growth-mode</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305760</guid>
            <pubDate>Fri, 04 Dec 2020 18:17:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git stash doesn’t have to be scary]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25305738">thread link</a>) | @chmaynard
<br/>
December 4, 2020 | https://jemma.dev/blog/git-stash | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/git-stash">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It was only when I recently heard someone else say, “git stash is scary” that I realized it was top of my list of fears too. It just usually feels like there’s a chance I’ll just lose all of my in progress work to the depths of stashes and never be able to get the right incantation of <code>git</code> commands to reincarnate my code.</p>

<h3 id="what-does-git-stash-do">What does git stash do?</h3>

<p>Let me backtrack a minute! I haven’t yet explained what <code>git stash</code> even does. On the most basic level, <code>git stash</code> is one way to store in progress work in <code>git</code> for subsequent access, leaving behind a clean working directory.</p>

<p><em>Meta-note</em>: this post will be easiest to follow along if you open up a terminal and play around with <code>git stash</code> as you’re reading! The lack of syntax highlighting makes it a little tricky to see git additions / deletions. You can play around with any git repo you have, or clone <a href="https://github.com/githubtraining/hellogitworld">this hello world one</a> locally to work in a complete sandbox!</p>

<h3 id="stacks">Stacks</h3>

<p>Stashes are more easily understood as a basic last in, first out stack.</p>

<ul>
  <li><code>git stash push</code> (equivalent to <code>git stash</code> when used with no arguments) will push any local changes onto the stash and leave a clean working directory.</li>
</ul>

<div><div><pre><code><span>$ </span>git status
On branch main
Your branch is up to <span>date </span>with <span>'origin/main'</span><span>.</span>

Changes not staged <span>for </span>commit:
  <span>(</span>use <span>"git add &lt;file&gt;..."</span> to update what will be committed<span>)</span>
  <span>(</span>use <span>"git restore &lt;file&gt;..."</span> to discard changes <span>in </span>working directory<span>)</span>
	modified:   README.md

no changes added to commit <span>(</span>use <span>"git add"</span> and/or <span>"git commit -a"</span><span>)</span>

<span>$ </span>git stash push
Saved working directory and index state WIP on main: 6ab43aa Initial commit

<span>$ </span>git status
On branch main
Your branch is up to <span>date </span>with <span>'origin/main'</span><span>.</span>

nothing to commit, working tree clean

</code></pre></div></div>

<p>There are a plethora of arguments we can pass to <code>git stash push</code>. The ones I find most helpful are:</p>

<ul>
  <li><code>-m &lt;message&gt;</code> saves the stash with a message, can be helpful for our future selves</li>
</ul>

<div><div><pre><code><span>$ </span>git stash push <span>-m</span> <span>"description"</span>
Saved working directory and index state On main: description
</code></pre></div></div>

<ul>
  <li><code>-p</code> patches changes (used like <code>git add -p</code>), allowing us to select which hunks to add to the stash. <a href="https://www.gnu.org/software/diffutils/manual/html_node/Detailed-Unified.html">Hunks</a> are areas where two files differ. Git will partition files into hunks for us!</li>
</ul>

<div><div><pre><code><span>$ </span>git stash push <span>-p</span>
....
Details about the hunk
....
<span>(</span>1/1<span>)</span> Stash this hunk <span>[</span>y,n,q,a,d,e,?]?
</code></pre></div></div>

<ul>
  <li><code>-u</code> includes untracked files in the stash. Without this flag, a file that <code>git</code> had never seen before would not be included in a stash</li>
</ul>

<div><div><pre><code><span>$ </span><span>touch </span>new-file
<span>$ </span>git status
On branch main
Your branch is up to <span>date </span>with <span>'origin/main'</span><span>.</span>

Untracked files:
  <span>(</span>use <span>"git add &lt;file&gt;..."</span> to include <span>in </span>what will be committed<span>)</span>
	new-file

nothing added to commit but untracked files present <span>(</span>use <span>"git add"</span> to track<span>)</span>

<span>$ </span>git stash push <span>-u</span>
Saved working directory and index state WIP on main: 6ab43aa Initial commit
</code></pre></div></div>

<ul>
  <li><code>-k</code> keeps the files (or hunks) which were staged. Without this option, when we apply a stash, nothing will be staged. More on applying in the next section!</li>
</ul>

<h3 id="accessing-the-stash">Accessing the stash</h3>

<p>Okay, we can now push changes onto the stash. But…. they’re still the stash abyss if we have no way of accessing them.</p>

<p><code>git stash list</code> shows us what is on the stash:</p>

<div><div><pre><code><span>$ </span>git stash list
stash@<span>{</span>0<span>}</span>: On main: Clear description of these changes
stash@<span>{</span>1<span>}</span>: WIP on main: 6ab43aa Initial commit
</code></pre></div></div>

<p>This is where the <code>-m</code> message flag from earlier will be incredibly helpful. The first item in my stash had a message (<code>Clear description of these changes</code>), the second did not.</p>

<p>Okay, okay. We can now <em>see</em> what’s on the stash. But how do we access anything on the stash? Or remove it from the stash?</p>

<p><code>git stash show</code> will show us the difference between the top item on the stash, and our current working directory:</p>

<div><div><pre><code><span>$ </span>git stash show
 README.md | 1 +
 1 file changed, 1 insertion<span>(</span>+<span>)</span>
</code></pre></div></div>

<p>If we want to reference a different set of changes on the stash, and not the most recent one, we can use the stash index of those changes. As we can see above, each item on the stash has an index, and can be referred to by <code>stash@{index}</code></p>

<p>So, to see the set of changes in the next item on our stack, we can run:</p>

<div><div><pre><code><span>$ </span>git stash show stash@<span>{</span>1<span>}</span>
 README.md | 2 +-
 1 file changed, 1 insertion<span>(</span>+<span>)</span>, 1 deletion<span>(</span>-<span>)</span>
</code></pre></div></div>
<p>Neat, so we now know how to get the differences and look at what’s in the stash. But to actually access what’s on the stash, we’ll need <code>git stash apply [&lt;stash&gt;]</code>. It similarly can take an argument with the stash index to reference something later in the stash. If no argument is provided, it will default to the most recent set of changes we put in the stash (the ones at <code>stash@{0}</code>)</p>

<div><div><pre><code><span>$ </span>git stash apply stash@<span>{</span>1<span>}</span>
On branch main
Your branch is up to <span>date </span>with <span>'origin/main'</span><span>.</span>

Changes not staged <span>for </span>commit:
  <span>(</span>use <span>"git add &lt;file&gt;..."</span> to update what will be committed<span>)</span>
  <span>(</span>use <span>"git restore &lt;file&gt;..."</span> to discard changes <span>in </span>working directory<span>)</span>
	modified:   README.md

no changes added to commit <span>(</span>use <span>"git add"</span> and/or <span>"git commit -a"</span><span>)</span>
</code></pre></div></div>

<h4 id="removing-from-the-stash">Removing from the stash</h4>

<p>However, <code>git stash apply</code> will not <em>remove</em> the changes from the stash. If we look at the stash now, we’ll see it’s the same as it was:</p>

<div><div><pre><code><span>$ </span>git stash list
stash@<span>{</span>0<span>}</span>: On main: Clear description of these changes
stash@<span>{</span>1<span>}</span>: WIP on main: 6ab43aa Initial commit
</code></pre></div></div>

<p>In order to remove a set of changes from the stash, we can use <code>git stash drop [&lt;stash&gt;]</code></p>

<div><div><pre><code><span>$ </span>git stash drop stash@<span>{</span>0<span>}</span>
Dropped refs/stash@<span>{</span>0<span>}</span> <span>(</span>b09812812eb27de2cb49bfd02aba43889362b6de<span>)</span>

<span>$ </span>git stash list
stash@<span>{</span>0<span>}</span>: WIP on main: 6ab43aa Initial commit
</code></pre></div></div>

<p>We can see that the set of changes at <code>stash@{0}</code> are now no longer on the stash, and the set of changes which were at <code>stash@{1}</code> are now at <code>stash@{0}</code>.</p>

<p>If we want to <code>apply</code> and <code>drop</code> a set of changes, we can conveniently use <code>git stash pop [&lt;stash&gt;]</code>. <code>pop</code> will only also <code>drop</code> if there’s no merge conflict.</p>

<p>To clear the stash completely, we can run <code>git stash clear</code>. This is the <em>actual</em> scary command which will cause us to lose any work in progress that you had stashed. Only run <code>git stash clear</code> if you never again want to access what is currently on the stash.</p>

<h3 id="why-stash">Why stash?</h3>

<p>So we’ve learned how to use <code>git stash</code>, but still haven’t covered <em>why</em> to use it. Stashing is intended to be a quick and easy way to get to a clean working state while not losing in progress work. And it is! Both quick, and now hopefully easy!</p>

<p>One example of when I might use <code>git stash</code> is if I’m in progress on some changes, but realize I want to amend a prior commit. I can stash the changes, amend the commit, and then apply the stash to get back to where I was.</p>

<p>Another is if I am trying to experiment with a few different ways to solve a problem, and want small, quick examples down each solution path. I might create stashes with all of my examples, and then pick the best and pursue that set of changes in a branch structure.</p>

<p>Additionally, stashing is especially helpful because it is branch agnostic. That is to say, if we switch branches, our stash will remain the same. This means stashing can also be a convenient way to carry changes through different branches.</p>

<h3 id="when-not-to-stash">When not to stash</h3>

<p>Equally import to why stash is when <em>not</em> to use it.</p>

<p>Stashing was built for convenience, and is not intended to be a permanent way to save work; that’s what branches and commits are for. Stashing also only works locally, you can’t push stashes to a repo or have others pull them down.</p>

<h3 id="branches-from-stash">Branches from stash</h3>

<p>Speaking of branches, another fun feature of stashes is that we can create a branch directly from a stash. This is done using <code>git stash branch &lt;branch_name&gt; [&lt;stash&gt;]</code> This will also drop the changes from the stash, equivalent to a <code>git stash pop</code> not a <code>git stash apply</code>.</p>

<div><div><pre><code><span>$ </span>git stash branch new-branch
Switched to a new branch <span>'new-branch'</span>
On branch new-branch
Changes not staged <span>for </span>commit:
  <span>(</span>use <span>"git add &lt;file&gt;..."</span> to update what will be committed<span>)</span>
  <span>(</span>use <span>"git restore &lt;file&gt;..."</span> to discard changes <span>in </span>working directory<span>)</span>
	modified:   README.md

no changes added to commit <span>(</span>use <span>"git add"</span> and/or <span>"git commit -a"</span><span>)</span>
Dropped refs/stash@<span>{</span>0<span>}</span> <span>(</span>d6a804a40c0b477d8e3be27939310ff677f45670<span>)</span>
</code></pre></div></div>

<h3 id="in-summary">In summary</h3>

<ul>
  <li><code>git stash</code> operates on a LIFO stack of sets of changes</li>
  <li><code>git stash list</code> shows what’s on the stash</li>
  <li><code>git stash push</code> pushes to the stash</li>
  <li><code>git stash apply</code> access changes on the stash</li>
  <li><code>git stash drop</code> removes changes from the stash</li>
  <li><code>git stash pop</code> does an <code>apply</code> and a <code>drop</code></li>
  <li>These default to the most recent item on the stash, to reference another one use <code>stash@{index}</code> where you can determine the index from <code>git stash list</code></li>
  <li>Some of these have flags which make them more convenient, including: <code>-m</code> message, <code>-p</code> patch, <code>-u</code> include untracked files, <code>-k</code> keep staged changes staged</li>
</ul>

<p>Hopefully you, too, can now add <code>git stash</code> to the list of fears you’ve conquered!</p>

<p>For further reading on stashing, take a look at the <a href="https://git-scm.com/docs/git-stash">git stash docs</a>. For further reading on <a href="https://www.brainyquote.com/topics/fear-quotes">conquering fears</a>, here is a favorite quote of mine, “Nothing in life is to be feared, it is only to be understood. Now is the time to understand more, so that we may fear less.” - <a href="https://en.wikipedia.org/wiki/Marie_Curie">Marie Curie</a></p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/git-stash</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305738</guid>
            <pubDate>Fri, 04 Dec 2020 18:15:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fable 3: F# to JavaScript compiler]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 123 (<a href="https://news.ycombinator.com/item?id=25305650">thread link</a>) | @adamnemecek
<br/>
December 4, 2020 | https://fable.io/blog/Announcing-Nagareyama-4.html | <a href="https://web.archive.org/web/*/https://fable.io/blog/Announcing-Nagareyama-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today is the day, Fable 3 Nagareyama is officially released! Does this mean the latest version is bug-free? Probably not, but at least the install command is shorter. We have also tested the release candidates in many projects and managed to fix all the outstanding issues so if you find a problem when upgrading your Fable 2 project you may even consider yourself lucky (also, please report).</p>
<p>First things first, I have to acknowledge all the people that have contributed to this release: from Don Syme himself to ncave, our mysterious contributor, and all the early-users that have helped polish this release. Very importantly, the teachers too that take care of my children in difficult times so I can focus on programming. The fact that so many people can collaborate together to put a project like Fable forward still feels like magic to me and I can only say a big THANK YOU to you all. I'm also very happy this is coincidental with the release of F# 5, as incredibly smart people are putting a lot of effort to make the development experience with the language really pleasant. Quoting Krzysztof Cieślak, what a great time to be an F# developer!</p>
<p>How can you try Fable 3, you say? This is it:</p>
<pre><code>dotnet tool install fable
dotnet fable src</code></pre><p>(Change "src" with the path to your project.) It's that easy, type <code>dotnet fable --help</code> to see more options. Of course you still need extra tooling to bundle the JS code, spin off a development server, etc. If you're upgrading an app using Webpack, please <a href="https://github.com/MangelMaxime/fulma-demo/pull/43">check this PR for reference</a>.</p>
<p>Let's quickly go through the highlights of Nagareyama:</p>
<ul>
<li>It's Fable v3. Three is bigger than two, that's already a win.</li>
<li>There are no breaking changes, your Fable 2 project should compile as is with Nagareyama (you may need to update some libraries).</li>
<li>It's a dotnet tool, following suit with most F# project. Remember when Fable, Paket and Fake had each their own way to be downloaded and version-managed? Those days are happily gone!</li>
<li>It removes the inter-process communication with JS, greatly simplifying Fable usage and development.</li>
<li>The previous point together with other fixes have improved the compilation speed by a big deal. Expect it to be at least cut in half in most cases!</li>
<li>Fable is not tightly coupled with a specific bundler anymore like Webpack so you can use any tool you like! (Webpack is still a great choice.)</li>
<li>A lot of effort has been also put to prettify the generated code, making it more readable and easier to debug if needed.</li>
<li>Nagareyama can accept plugins by library authors. Zaid is already using this feature to make it much simpler to <a href="https://youtu.be/a6Ct3CM_lj4?t=860">write React components compatible with JS tooling</a>.</li>
</ul>
<p>You can check the <a href="https://fable.io/blog/Announcing-Nagareyama-3.html">previous posts</a> for more details.</p>


<p>So what are you waiting for? Give Nagareyama a try and let the world know if it goes well... and let us know (privately) if it doesn't 😅 Have fun!</p>
</div></div>]]>
            </description>
            <link>https://fable.io/blog/Announcing-Nagareyama-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305650</guid>
            <pubDate>Fri, 04 Dec 2020 18:08:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1979 Playboy Interview: Wendy/Walter Carlos [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25305541">thread link</a>) | @jelliclesfarm
<br/>
December 4, 2020 | http://transascity.org/files/history/Carlos_Wendy_Playboy_Interview_1979.pdf | <a href="https://web.archive.org/web/*/http://transascity.org/files/history/Carlos_Wendy_Playboy_Interview_1979.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>¶}¬ôû&gt;Ë»Õ€[³és¬|—Ž?ëoW­Ðr-hAq^•þ.¾²ž¹‰éXIH‚|[Ø®üeôï±uW8ÿŸñ	)HúÉÖúŽC+®ë^IOÈ½‡«·!øvŠOé6‘ûËË?ÅVxÄêF³þ…¿1ªö $§Ã.úã×0^k}ö5Í0C¹üWSþ.ú÷Uë9¿¦±ï¨4Ì�'·eÍ}o¿öçZ°0ráS~^Õì}#§WÑñ™C&gt;}ÊJm½Û9^UÔ&gt;»æýeÎn&amp;9ôë{Ã=¿H‰ÔÊô­]Gö_NºÞá„‹´ÌÿÅOû_SõÒ¦—|Îƒò¤§²úÿ×3¾®ãTüm;\â7vÑpgüfõŸôƒüÆÿrö\ÜVçRêÞ¤5ó®UÇ0òÒGÜRSêÿâóëOQúÄû~Ñ¬hÚCvû¾K”Ïÿýkç°¼7kˆÚXÝ?Üÿ‹;›H`è—4ÇÆW5þ7zs+²›Ú.Ž&gt;1ÂJq+ÿ�nt´ýFÿrôn¹Õ:†Dépkïló´^gþ/
c¬R@ŸÑ{‘Õ%&gt;$ÆoZÿHßóýË¦è__²±zm™y³d¿Ó¨4É‰:ø.3ë;2ºÅÕÔ :ÒÐ™…é]ºV=}	õ€*kK#Å°?”ùß^úùÔ:ã€'Ó`2Î&gt;gºö^…˜zŽ6þû~p¾v^áþ-2þ×Ñë%…ÌûŠJz�»WŸÿŒ¾³Õz%•¿îedA 7O}¡._üc�z5ò;7þ¨$§ËøÀë'þÔ;îo÷/BÿÝ_¨õŠ¬³)ÅílqxÌh¼t¯&nbsp;&gt;ªÔÚºu§èÛùS_ëî}Ý;¤Ùm.,p-‡7Ÿ¤¼ª¿ñ‡Ö«âò~!§ø/MÿFz5³âßú¥ÇÿŠž…N}—_kÃ!­„»ž|’SŽ?Æo[oøVŸìµ!þ4:Ðÿßó²¾¶ÒÊz¦CXÇ@]7ø¦À§3*ïU�x¼F¾i)É»ücõ«GóäU­Áu¿^¾²un�^3éykX.xh2ÿ‰“ÿ]"®‘ÕÚšÇö´p'ŸÅz×£?WI�Í«ø$§ÎÿñÅë÷!ßs¹?þ8½oþä;îo÷.nÐ�›zmÌiš™ËAüÑä’ŸøÃëNÿµùÿrôª�o7#êý¹.q²Öú…¥Úý7þ4&gt;«ÑÒŸ^E×´q¸k#âºßñXÝ½¿×åIOÿŽ§YžÏó¦Ïñ¯ÖAÕÌ?Ø#ë¥L§«d5&nbsp;4o0ÚÿÝ¬fZÛëkk�®¥Á%:}3ür]YŒšC‡�giûŒ¯CèX1&gt;±Uêc¾@úMáÍø…æŸãê5=­ÉÆXN×³˜'‚&lt;Šæ&gt;«ý`·êîc-aÒaãÅ§””ýD¨vJ»[{C›¨ ð)ö¤¦	‰!H&nbsp;eä··XýÐ\ãäS�õ«ëv?ÕjƒŸî±ßA€óæ|ó¿ñ™Õò,.m�ƒ÷ZÑŒ•‘õ�­Y×ó{ûŸhðhà/QúƒõO§²Ûkkì´n%àià	IO5Ò?ÆæM
-Ê¬Y§µÌö™óì»?©_[�õ­¶9ÕŠö43Ì®üdýV«¢d6ÚFÚíŸhá®Âè?ÄèŠ2?¬ßÈRSèëë'Ö¼_ªõƒl’éÚÆò‚Ùp¿ão§¶îžÛ�Ò­à|C’SÊçÿŒÜî¡’Ç0úUµÀìoëëÙéxµ­pà€GÍ|ÊÐßT3~ßÓ(}€}Ú”ëÄ¯&amp;ëßã'ªtÌëinÍ¬yh½�^³!yoøäÃª·ÑcZ�¸9Àjb"RS”ÆçU«ÿ7ý¨øŸã‡:³úZëxò–ÿ¸Þ‘K22êcõkžÐ~¯TúÉþ-0s){±YéXÑ-�®ŽÄ”ë}Zúû…õŒúmšìýÇ÷øë¦_3±ïÇ~àK\nAÝ~¤}awÖžÛeíö?â;üÒSÏ}wúûŸõw;Ñ¥­Û´\Ù’~kŸÿÇwªŽ[Wù§û×[þ5±«·¥úŽhÜ×·k£Q&lt;…ãnqqIO¸}@úÏ•õž›xhÚàZ#²ê¸Y_V±jÃÀ¥µ´44˜’9Z€¤¥Ö__ë˜ßWñÍ×˜š.&gt;i—á¿_&gt;±;¯ç»išë;+OÍ%:]Külußú¶¶öÓyûÏ÷+=ümåU`LkÛÝÌ\?‚»þ-þ©ceâ›ë.qÜ$&lt;–?øÊú±GC½–ÐÝ¬¶e£€ááñIO­áfÓÔêmÕ�Íp�B1Âò¯ñQõ‰ØÙ	çÛd¹žNÞ»Ÿ®ÝmÝ¦Ùk&gt;‘†3È»¿É%9Z?ÆV/C°ÓS}kÒÖÓá&gt;+ŸÂÿ6oý=
ÛÿL�½sT¾¯­Â§8†Á{ÝÞ?Ú»Ÿ¬ŸâË	˜n~(slcwjwn„”ÛgøÔé×\ÚëeŽÜ@˜kñ=—jÎÝFe?×oå_E$¥‹S¤'-¤L$¦;A)ˆÕJ“ÂJF§ÚŸè¦ÜR:B´ÉUªVA„”Ï„î 	Q‰JR»¦22!9á%,'ºN“\S»„”ˆˆL^!e4”ÆaI¥4ÁR!%.¢çISî&nbsp;F©)dÑ%I"a%(Õ#	€��%.:&amp;'	)‰€S�™%-&nbsp;HÉJ‚’—2�<iil tñªhikð¤="" ¨'%2¤í5;µ$¥)l&�©="" rrÁÛ’.h¦‚j\�%j%@è’”uá!¢e6µ%.5="" ´'‚š="" $¥§t¥="" 5nbjxjtÉqjw¤¦:r¢äå7="" )ó¯ñ½‡ºš-ŽæŸ˜Ÿà¸¿©#«ã»±~ßó´^Ÿþ2ñ="">ÓÒ,?¸ZÿÆ?Šñ¬KÎ-Ìxü×}Å%&gt;óõ³+ì]3"Ï
Ü&gt;ý?Šùþe{'øÍÎèúç\Áòú_Áxß))ößñs•ö®�Wò73î+…ÿy^¿TØ?Á±£ï×ø®‡üPäïÄº¯Ýx?çö.;®Û}uíŸp`øNÔ”úÿÕÌA�Ó©®8­¿ˆ•æÿãhƒŸWü_ýø¯Y­¾˜
„/&amp;ÿCoP¯þ(Õ”äÿ‹ðX£âêJ÷à¼?ü^
Ýf�‹¿êJô/¯_\.ú²+e-i{ä�ÚÃBJzl®‹‡žñeµ1îop¬¿¯NŽ�“ýOâß«=Iýc«ßÏvñÊ¥õðØùÔþ!%&gt;Uî‡ÔOIÌªáùŽü;þ
çÕž€&gt;°[mrAmN±‘ûÍˆ•ŠD”ý	Õ¬m¸6�t58�›WŽ}B×¬cÿ[øèUú§íO«Ï“.®·Öïì·OÁpâüOX&nbsp;yŸú’’ŸDÿ¯ÿ$:?}Ÿ•xä/dÿÌ
èî�ßgå^6©)ú#¥i‹WõÿR™�ÌPÌÊ­ýöAþÉÿjôî™¦-Cù
ÿ©‚ÿ,öcŸ7�È’žKêS=3ªÔgÚóé»àïö®ÓüntïS«ÀÕŽ,?¹y~=ž��pä8ò+Ý&gt;³à³Òmo%Õï7$§Åz&amp;qé™•\?1àþ:¯yêÝI½?
Ëû5…ÃîÑ|òö–hW¢}cúÇö�«XÍÝl1ß
¹þ	)Çÿ˜'ªufØívMŽøöüJöpWþ):g¥‹fA½ÛGÁ¿í]ü$§�ÿYæœJèW»qø7ý¥KüQôïKËˆúnÚ“Þ¹¿ñ£Ÿö¾§éŽ*hoÌêW¦}Réß³zmðv‡‹µIN¬/úñ…ö­{{nÚÕ{Û›%x÷øÛÄô:“,ýúÇý	)Úÿ[±ï¯÷\÷�ö!ÿ�ü¡éQ_‹œï¸BÉÿ¹†®&nbsp;ú»=‡ïiMþ63=^¢Úû2±÷¸ÊJy~ƒ’p³©°¢öþUôEž›§€OÜÍÁå¦Geî}Sª�]x?J€~nl”ùoÕV©Öê'Y°¼ü¥Ë¾ÿÙ¿gé‚±Í�ä5\·ø§Åõz“¬#FV~÷h®ŽÍÙSû­/?3Á%&gt;w+ÕÄæYv=õ~ëƒ¿Îì^iÔ:e½4³ÔÎ1¶·ú®ávâ‹,ÕÔ\èö½¦RSìArßãŸØ×ÿgþ¨.¥°å¿ÆF�ïìÿÕ”øiè?« ��ÿßÈ¾{_Bý\ö~&gt;ŸàÛÿR’“u¾�O\ÅuÎ×GÑçE_êÿÕì«”©˜'q.Ô’¶#pP:$§çÿ®z®Güc—Uþ'cíWÿPÕ.Oë_ü©‘ÿïÊºÿñ8?XÈ?ÈoåIOgõ‹êVÖwµ÷n`‰i�&lt;ÖøÉ¬côG1¼[GÀØí\�øÑÿ‘ßýf~T”ø¡èÎ…íÁ&nbsp;Á³þ¤/�
ú
¾¡WDélºÉÛ]MqŽ~ˆIIzÿÕì¬´z7LHp-0d)tN‡OÕìqE$íŸq“ª£õ[ë–?Ö²ÿIŽo§¾;üÿ))ð®úõ|ŸøÂºñ8ÝÙwŸú¥Ë}pwùW'þ1Ë¬ÿBrr4üÆÿÕ$§¬ÿmßÑmò-ÿªÃ—µÿ�&lt;†ÑÑÞÓËÜÖ�¾‚ñz«uî
h’ã|RSôÕ+
ý+ÎçÓo÷-iTé_³ñj«÷ÖüÀV¡%1qUÇ�.¨pºY¬hmpoË’»0%yoøäÉ›¨¨vk�÷˜þ	)óv7s€ñ_GtªE8Õ²&gt;‹&gt;à¾wÁh}ì‚à4ø¯¤kfÀ#À$§˜ÿ}Ý[¦8VÒç°‡´ÅeÿŠŒ°¨»Õc˜K„nÛÍwà(‘ªJT/;ÿ»1é¦~“‹ÏÁ¢?ŠôEãŸãg3íHV8­€|ÝªJx©^×þ*³FGI
ï[ÜßãüWŒåaÙ„òË€`ù‰^“þ&amp;rÏééþ«ÿ‚J}=y—øç3öoíÿéÃUæ?ã˜k�ý¿à’Ÿ=èmœêãÿT¾Š_&lt;}^nìú?ãÿT¾‡y¤§çN¸ÆÕ›sGÇÕ/CÿV»nC;×~UçNï´dØñùÏqûÊõñ;ÓÍ8—\=á£àß÷¤¦ïøÔ3Òýv/^Õþ5á½ÿÆ3ø¯i3¢J~‰è`*âÙÿRæÂ£ÑaSèÛÿRé„”âýsê²º]ÖƒnÖü]¢ðBazÏøÜÊ5ôúëýû?êBòY	)÷ï¨ô}›¤c´�ÌŸóµ\÷øÝÇéÕ¿÷lü&nbsp;®·êÐéÔø6Ô¬ñªÍýÇÁì))ñÞ™œî�“]ÍÐ±Áßq^—þ7r½\,}¿EÏ.ÿ£§å^Tã+Ñ~¶ïê?Vp¯çihwÜ[üSKüRåŠº“˜tßYû&amp;W°º&nbsp;î~æÜû:eìº³aÜ¾}WúËOÖ\Qk8höwk’SãÇ§ýƒ­z$hÛ€ùn^ð4C~;ycK¿x´OÞŒ¤¦&lt;&amp;"TÈQ))‰€&nbsp;[(§P¡%0h”Ð¥±-©)Z+#EY†ªÃ5	),§•W×Ž•ƒkª²à×0Áî~ä”î�S�ƒõ¿¦u'Õ{ãÀ˜?Œ+W¯btF´ä&lt;08Ãfyù$§Bt,ŽŸõ§§õ[}mkß&nbsp;OäµœtIKI	†çlÈs(8YÔõÅ´¸=†aÃÉ%6eI§EŸÕzÆ/F`~E‚¶“™çä
«ƒõ·¦u[U7µÏw
¯à’�ÉPq‚°ìúñÒiqc² Áÿr'QúÛÓ:e¾�×5Ž€`ÏŽJvd$¬|?­�39û*È­Äð&amp;?*Õ.„”�ñµTÌêxý5›ï{k/  ôï¬8]\~‚ÖXG!§_»””ér›…G;­bt°={[\è7AÄúÉ�žý•_[ÝÐ8¤§H�Ê'U’~¸t®&gt;ÓW†Ž•©))”$¢ç	:â«7ªb¿Qkö›ýé)½Ržê�½OÛlµ�10ç4Ä£}©…›÷
±;¤DxÊJHSžUVõ|G´‘khÜHsLß•^¿¬½9Â~ÓQþÛRS¥ª“u6ß¬Ý6¡.Èª?®ßïVÔ±êc^lhÕ¤¸G’Jm¥Â¥ûcž¯üöÿz•}F‹˜ç¶Æ·éà@ø””Ü:¤«7&gt;‡A2ò‡÷¢‹C„ƒ#Å%3)
°Î¤’ßQ²?”=f¸H �’’IQ‰CnMn0�!7¬À`¸}á%$&amp;˜‚ûÙX’àâHLÌº§é·üà’›D¨ÈW9•“½°924N2êy€ö“àR]JJ°ÏÇÿHßó‡÷©¿"ºŒ9ÀBJJ¦óÙ
«[ke¤{ƒ!Ú¤¥¸M!#à›²Jsþ°bý·êùÜÇÁ|òíÒÑ!|ëÖñNeµÍ{‡â’ž«ë¿WûoJéí�K7»û 5r™Ý*Ü
iµÜ\ÒöüœB¯eöZÖµÄ�ÀCG„™ü«½úÿÒþËÒpLjÆ†í4à’�Šž£ö&lt;‹Úx5ÿ˜³~£PzŸ[©Ç÷�§å%atî¡oM±Ï¬ÁsYø<a]¯ø¡Äõ3m´�¡^Ññqÿ�bj}\ $ÿ�Æ:�ñcþ©ËÖö¯#ÿ�zõ&Åú¢’ž?¦u;º="í¾“o‰çDN«Ö2ºå¦ëß¹Üx@ðk‹ê›X¤8í¿šWAþ4ºXoªúX,~ÁG$§µú„?ÈØÿ�Õþ%/¯Gü�‘ýOâ¾£_IÇ~gñ*^´èù?Õþ!%">}þ)ÇùMßñNü¡c}wé?±ú�¬ãê3àíV×ø¨×©»þ-ß”-Ïñ»Ò=Z*ÊVŽø;�Çò¤§�ÿ�SÑf^9:&gt;—½¿´Ïà¨‹±=f�‰ÿ©+žeŽ¨ËI�&lt;×Gþ.¿åš?µÿRRSè_ã@ÿ‘Ý¾ÏÊ¼hr½—ühˆèîþ»?*ñ¦ò’Ÿ£:{c¿ê7þ¤.üp�ÐcÿYß�.ïÛEÕoä\'øá Q�ýg~@’Ÿ-á}ÒH~S¬Ößú�¾r•ôoJ¬×‹XðcGàSàXúì¼û©ý×˜ørRËZ$†ÎÑá&lt;Âí?ÆÖhêM°„`'âÓ�ú«†Üî¥EnáÏòÕ%&gt;Õõ[§þÊéõSCDüN§ò­G80I:ã…�õÃ?öoL¾É�ihø»D”ù-AßYz×üm¿„ÿr÷v7h�À^=þ*ºÚz‰´�+a?7h½�“	)ž‹ÍÿÇ&amp;úh»ÁÎgÞ'ø/F!r_ã7í}ç½nkÿþ))ó¨¹Ÿbêô;±vÏó´SúåkúÇ[µ¬Ô—Šš&gt;ÕƒMÎÆ±¯n…¤8|BÝú¢Çõ^·K�©6ò÷$§ú�Ž÷1Ú’ÓñÐ3:¶ïª¶u.šâ \Ï×Œ?±ukÛØ»xþÖªƒú­�Án)ú-°ÚÅ±	)ô?ñ=‹¶›íñs[÷	þ+˜úýyê�nÆ7X-¨~ÅwßâÛaôf&lt;þqu‡áþ¡yïÕÆµ×˜ã®ëM‡à	rJvÆ·LgÀq_§þdzÀú�—ö&gt;¯C�ç;oùÂþ6±}nšÇþåƒþ�!yGOÈû.Ev~ëšï¸¤§é0erßã-ßäk¿³ÿTIKÅ&nbsp;Þ
æ¿ÆV½ïìÿÕ”øw+è�«â0(ðlÿ©çr¾ˆú¿ý�ø¶Ô„”ér"'E’ŸŸ¾¶ÊyñŽü«°ÿ¿Ïdä·ò•È}m×ªdÆ;ò®ÃüMÿ;‘ýVþR’ŸP•È�G’ýv.¼Žÿ±û ÿÆ7ø¤§Æ
ëz÷øÃ¿­à·V+h
3»vÑðÑrr½'ëgÔ,N–2±�kØÖ¹âIžxå%2ÿC\“ýOâ½8¯5ÿMöäŸ6éa°’Ÿž¾¶kÕ2ã]ùVßø½ú×‰õa×»#qÞÖ†í0xXŸZ¿å&lt;�ø×ÿÕ#}^ú©ÖJîu$n©¡ÛOçLè&gt;ä”ÙúåõÊß­×6²¶}L’OsæºOñqõßU¹¹--
Ö¶;’z&lt;—ÐzÕŸWr…Ìk\[¡kÄÿ¸¯xè=nŸ¬X­È«@îGv‘È))¾S;U8Uä”Ä+Ç¿Æí…ÝM£Â±ùJö	•ãŸãe¥½VàÛüRSÊôv›2éo3cê—Ñ­2H_;ý]ŸGüc*ú"))�0˜™)Ú (˜%%/ÂzÛÿnõ×�®ûƒÂv¯nêËù­s¾à¼gü_c~ÐëU¸‰
.°ÿ¯Å%&amp;ÿX#ªH=�?w·ø)ŠœÏ³õ`ÞÖ1ÍûµþküpáÀÇ·úÌ'ñŠú¥™ö©�g…€ž‰)ú†˜ÿŽwOÙ¿·ü§4Êó/ñÎ=ØßÛþ	)óÎ‹–Ì,ÚmÑcÚç|]ïÖßñ¡VU£:^!Ö8Dû£•Àaôã›k*Ö80	îJ/ZèYWò
7ˆpðàŽÄy$¦ÇAúµ‘õ’ðÊvþ{ÏÑoŽ«Þ:GN¯£ã2ŠÇµ‚&gt;&gt;k“ÿ?]+êì�kk±¢[´C\—ŠîRSÅÿ�_ù$ÿÆ7ø¯’½«üj·ü�ãüW‹BJ~‹éÝ‡Wü[êB¶U^‘'Ÿø¶ÿÔ…d‰IO›ÿŽ{1‡›ÿ‚ó½7üq·Û�ý¿à¼Í¢L$§è¾ŠvaR&lt;+`ÿ¢øÏƒÑìþ³?*è:@ýR¢?q¿õ!aŒÖÏF·âÏú¤”øzöª}=�wêÓqßÃƒš�Ü`ýëÇ�+Û¿Å‹	èÕü]ÿT’Ÿê=&gt;Þ—sé´C˜`…wê×Ö;þ­d‹ªÔpövs|ª}~ú�&gt;°ÕëR¹ƒOå�Ýøø/²§Râ×0AIOÑ­S×1Û}&amp;Zï¼´AžW†ÿ‹ï¬®è9¡Ž?¢´íxð=œ½ÄIL¸
)å1IJÚ˜¤tQ.IKh¥2šR*°5@¥º#´BJdt^5þ5ñ«£©‚Æ€\ÀçGs'Uì³+Ç¿ÆäŽ¦ßø±ùJJIõïêŽ'HÀ£*�±Çk^$ë-™ø«Wd½õLÛpÜúNÖ¼ó£€ü†^§…õ‡ë¨¦·QéÖÀ"}­ãéÕt}{¡·êïÕ‹1ÁÜ@ÇÅÅâJJs¿ÄöO®ë¶�à†x4‰^’á!yçø�Ó#úíü‹ÐÉÑ%&lt;�øÍÊ~7Iv×ì.sZcó‡p³Å'TâÙŽNµ»pþ«¿Ú£þ0Zî¹Ô1zsLIÞøì�s_Ròõk¯z/Ð:‡}þßÆSêXz]ÔØ'Iaý×v+ÊÅí•ô¾¶ÚïhÝX'ó_þº/h+ÇÆ�I;©™&nbsp;¹»ôýá¡IMÞ—Ðq&gt;µ}`¹ÌlQ[¥ÀpãÇâuDÿ8uÓn;ÚqkšO“b&gt;åÔÿ‹^Œ:oKcÿ:ïÒ;ø.oürˆv?ÁÿÁ%9ŸX¾«baô,|ÊÛ¶Â¿Rwo¯ÿ½mù Ùy$R\ÝÇ÷Z'ðáp½kªu&lt;ÎŸ��‘Q§Å�¤îh~îË¶Èf'Oú±hÃp{=3ïîKˆÜO�IO+Ñ˜ïñ‹Ö‹òI5´lž&gt;‹½Yúùõ~¯ªQ—…5É"?HkßÇºñ8ßÖ¯?ÈõKsün´
�qoýô¤¦×TÁ§ëïFmíoé63Éãé7àar?â®Üjó­eÀn5�Žw`&gt;˜ù…ÕÿŠ«gIƒÚÇøÀý{é'¡õG†ý#cÁÜ�Ê’�o©ŸU±&gt;±õ®#·{']tø¯X"&gt;ê7H¦VÏÎpõñwûéIH2qÙ™[«w®ø„áôš¯êíÅ“°Û²{Àr÷¸xŸG¾±¶?ÓŸú¢’�ñ³ÒiÄº«Ù!Ö×x{…¥þ.3êë�:ÞŸ~¡&nbsp;éü‡ÿqSÿô¶û°˜á!ÖGˆ%«˜«Ô½èGÆ§ÿwðIM¿©W[�N~Ílk]M}¾”ÿr�\ú‹_Õþˆ/¸´¶uÑ&nbsp;Î‘ÂÝÿ/ÞüÇ ¼Aÿ9i�Bdÿ×üRSÅtï©C¬ô?´ã´ºñaôš;BèÆHm=Ïl&gt;­ŒRÝGàµ¿Ågü�?ãüÆ©Ž“ÿ\oñIO3õ+êÖ&lt;u¥áåÎh-"q¤-Ÿª¿T,éý72Œ¶Lkôƒ¡æ¹.—õÓ/¢tŸC…¤ØO¯È×óF‘+×,µÖ`IªOÄ±%&gt;CõêÆ?Ö|‹Yqpfá´Æ³_èùSzßØ÷—Vl¸v‡pèìuY¿Qþ´×õZël±Ž~ö†�¾3ÞVßÕŽ�•õ»©þÒ´Ôlõ9KxhIMñ—õi�,]\í¸¹Æ{:uü«Ñ&gt;­ôüK:5u²}++;¤ëîúZüU?ñ›ÒþÝÒœñÍN|¸?•s?W~²Œo«Y'ÝT±¿õÞ?ŠJ_ü[}\£+"Ì½Kjym3ùOÉaÿŒ\áug†ú@,3âîW¤}Béÿ³ºU òñêí±yÿøÑ3Ö?°Ä”ô?]º8�&nbsp;	&amp;�»Lþÿ2°þ¤ýEÇúÑˆûl±ìs_´mˆàë­ÿ†:Ÿ×Ð&gt;º]õw¦ÙM,;ÞýÂÓôFƒñIOQõ?êKÛFf.c÷45ÜNÙ‡5`‹žŸE�]õ\$µ�
×¿Ñ?„¯XéÙ“‰SÞeÎc\ï‰Êîxú±õ¨¹Ú0Ù$ŸÝ´µ%4.è8ý3ëq&gt;—ªÐ5×k&nbsp;�WSþ2º5¹¸­d‹nw¦|6ñó\7\êvfuæAÚëIaìvü!wøY¬úÅõ‘¶�kÇ§wŽ®oþd’žÓ¤tšº6;(ªv°F¼üU·®;êÿøÇo]êf–µÓ±Ó'Û®¡v.))‰×”¸	ùL’”WˆÿŒŒO²u‹¿—ÿ8/o+Ë?ÇÌªmýæÿšÚ’ž¥ã}³*ªÿ}íoÞW°ÿŒÜwGyàË\&gt;F?Šó�ñ{…öÞ±HìÒ^²±}dÄ½&gt;úÿz·~IIOÏA¤¯Xÿ8ž–ÖŸÏ~Ñý‘þÕå½Ãü]bý›£Óü­ÏûÊJz:Ø+;x¯%ÿ�Ž¥_üPÿªrõ¸…äŸãi³Ô™ÿ?êŠJs?ÅÓGíšµÿRW·Út"~+ÄÅÖ�fŸíÔ•î2’–k@0×±·£äSþü/øÁúí‘õvÚéÆ 8‚ç—
ÚpŽ¹ŸoSú¬ëì�Ï©®tX$§�ÿÿò›ÿâÏåÓº÷MoYÂ¶ƒùí |yŠó/ñN#©¿þ,þP½p·D”üÙuf·»B4#àº/ñsÿ,Óý¯ú’‹þ1ú7ì¾¨ò6ßÒ7çÏâ‡þ.´ë4kþ¤¤§ÐÆ‘ÿ#»úì^6ÞW±�CþH?ñ�^8Ñ$$§èì!×ýVþEçŸã‰â1›ýsù¡á¥ŸÕoä^Uþ6³ÙõÕ?Ašü\RSÈôŒo¶eÕ_ï=­ûÊú-&nbsp;0@à/ÿ}(çõFØG¶&nbsp;^~&lt;ìñµ%&gt;Sþ8ûe?ñgþ©sÿQuëÿ×þnÿŽNu_ñ÷â°¾¡ÇíŒë’Ÿv\øÜê&gt;–-TÏqqø7ýë¾•ã¿ãC?í�PÖ8©¡¿3©ü©)ê¿Å?Nô0_qæÇ@ø7ý«»ktXÿUp?fôê*:ÀOÅÚŸÊµãD”ºÌúÉ‰öþŸ}¼Ç~E¤&amp;pÐ÷IOÍWkþ)ñ}~¦ë#FVOùÚ.[¬bœ,»j?š÷Åzø�Ä
fE½Ék?ŠJr?ÆÖ«¨²Ø�õ�½¦JõOñÃ‰»‹|[÷‰þÌúv9ÊÉ®±ùÏk~ò’ŸdÍwüßú·Ðóx�â¼ÇêgÖ
~­fía°µ¡±Éø¯@ÿù_féŒ¤~{Àù4.kêgø½§ë.¯¶Ç0î-nØà|RSgë/øÊÄëØcŠlÀm$¶yä¯SøœÇd?üÑýëÌr(v;ÜÃù¤·îIO¿}VÌûoNÇ²fXÙùYßã ÿ‘nþÏýPU?ÅfXÈé!½ës›üŠ³þ2ùïìÿÕ”ø‚ú#¡ëƒOü[êBùÚWÑ‘…Oü[êBJt[íhî”®ë�Ö¿ù­ŒËË�´cÍYú±×Ö,&amp;äì.$m™àø¤§Å~´»ü§�áùWeþ&amp;þžAòoñ\WÖƒ=O#þ5ÿ•vßâng$y3ø¤§ÓfWþ5äŸúãŠìBã?Æ¹Ž”&lt;ìoñIOŽD¯¢èÆ¯/µØ%®`k�î6¯�«‚úGE,þ«"Jkô_«ø}®n;6o2íIãâ´ÊÈúÁ×kú½†ì‡�Á°Gr{*_T&gt;¸­µØáY¯Ó s3?rJ|kë1'©døWÿÕÜ‰‘.É&gt;Lþ+…úÆAêÿÆ?þ¨®÷üLûOö?ïÉ)ã¾¼tÿÙ½ZöDííø?UÖ‰Î¨YeØÇ‚�ø�
­þ80½&lt;Ú­ìöAø°ÿµbÿ‹¾¡ö.±I&lt;&gt;k?ÚÞ’Ÿu%BBs)’˜ÂòOñÁIõ?Æ¸û‰^¶u^uþ80�”Qpü×9‡ûZ�È’Ÿ:ènuþ¿•}¾mÁ£{àæŸÅ}[·€|RR^S8ÁU:ŸQoKÆ²÷	it|Õo¯Uýj±Õ¶²ÂÑ¸ÉBJgþ0óþÃÑíñ|V?´Wœ‹ï¬X_W2,·#t–†·hÝßUÓÿŽÝ´QGï8¼ÿdGñXW?Å¥¿X0ÆGª+ÜL4´�~RSëç×n™õ�UNýíxpÜØ}×Mž“Ã‡ ƒ÷.÷3üPß‰KÞ/k‹Z]N°&amp;9\$§é.›”Ü¼zìœÖ»ïÏ?Ç1×ÿ_ø.§ü_æ}³£Ðy-‡û%rã˜Ë±¿·üSÂý[ÿ”qÿãYÿT½üpôíÕS’­q­ÇÈêž}[oùKþ5ŸõKÚ&gt;¾à£Ò/ov�ãâÝRSâ�¨;¥fÕsLlx?.ëèÖ8X$wÕ|ÉèO©ýGö§K¢ÎûOÅº$§üjƒû!Çùl^%½·üj�ò;¿®ÏÊ¼M%?Eôq8•Q¿õ!\ˆUº;@Ã§þ-¿õ!gýfúÑ�õZ¶&gt;æ¹ÛÝ´Dþ))å?Ç3�Cüá÷�ö/+×&gt;»d×õ£êøË¨ƒáÜˆ%§…ägT”ýÐýøtŸø6ÿÔ…Ïÿ�GGõ›ùVÏÕ[}n—Žïø6þE�þ6,
éQãcŠJ|b½‹ìs�Ñ¨¸.ÿ8•àá»ŒëØ~°}d·ê&gt;+Xy-Úw#kG‡Å%=Ë†‹Ï?ÆgÔÖåÖìÚ½£ô�œßÞø…ÓýTëëØ
¼è\L�+YÀXØ"G%?5ßþ¦õ3Õºe6“'n×|[¢ñ?¬�?öV}ÔŽóBõ/ñPì¯úã¿‚J{RIòOÀQå%,Fš¨’B'dÒ’˜1É÷&amp;ˆ:%%%0©Yj­PV[¢J\ÊñÏñµÿ*7þ-¿Å{ ÕpÝcüUUÕò_{²É0Zyr’ž·§öz§÷ÿRøÅ;z5ßÙÿªg¡tƒÑqA°Ù³óœ³&gt;·ýS³ëML­·ƒI.!Þ¨á%&lt;ïøžoê—Ÿÿ¢º�õ²®§Ô®Ã­§ôBM“¡‚ó\Ý?â£'Vk˜!¡ÍŸ¹ÊÏKÿWt–]³(‡ZÍ›ÚØ�p'¿t”óÍ§©}hë98/5��äÇ·èˆÐóëOJê=1¶e¸:ÇûÃÚyÛòÒ~¨}E»ê¶C¬õ÷µÍ‡06$ö&lt;öCúÙõ
ÿ­^¯ÚZ
alíñî9IOKÑóÇUÄ®ñÃÚýÿŠó¯ñÂXÇþ£¿ê—eõCêÍÿViuo»Ôi …</a]¯ø¡äõ3m´�¡^ññqÿ�bj}\></iil></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://transascity.org/files/history/Carlos_Wendy_Playboy_Interview_1979.pdf">http://transascity.org/files/history/Carlos_Wendy_Playboy_Interview_1979.pdf</a></em></p>]]>
            </description>
            <link>http://transascity.org/files/history/Carlos_Wendy_Playboy_Interview_1979.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305541</guid>
            <pubDate>Fri, 04 Dec 2020 17:58:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: TerminusDB 4.0 'Data and Content Management in a Box']]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25305296">thread link</a>) | @LukeEF
<br/>
December 4, 2020 | https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          

<p><strong>Version 4.0 of TerminusDB - the Star’s End Release</strong> * - is a big step forward in solidifying and extending the functionality of TerminusDB and TerminusHub.</p>

<p><a href="https://terminusdb.com/">TerminusDB</a> is an <a href="https://github.com/terminusdb/terminusdb">open source</a>, revision control graph database designed for distributed collaboration. TerminusDB allows you to push, pull, time-travel and merge data, much in the way that is possible with code in Git.</p>

<p>With this release TerminusDB takes a significant step towards our vision of a general-purpose tool for data &amp; content management and collaboration.</p>

<p>TerminusDB 4.0 extends the revision control features to allow greater visibility and reproducability by allowing you to look inside individual commits to see what changes were made. Provenance, lineage, and compliance are increasingly essential in the management of data and content.</p>

<p>The <em>major</em> additional features are:</p>

<h3 id="model-building-tool">Model Building Tool</h3>

<p>The database ships with an integrated visual schema building tool. It allows users to build complex data models using point and click tooling. This makes building models significantly quicker, more efficient, and inclusive of a broader range of people by lowering the technical bar for the application of business rules to your data.</p>

<p>It lets you visually design knowledge graphs in the same way they are presented to business users. We have tried to make the tool easy to use, while preserving the ability to model the most complex domains.</p>

<p>Like everything in TerminusDB, the models are versioned so you can make changes in testing and if it breaks your database, you can easily roll back to an earlier working version. This <strong>collaborative knowledge graph design and implementation functionality</strong> does not exist elsewhere.</p>

<p>You can currently share your models/schemas through TerminusHub - the next step is to make modelling and collaboration even easier by providing data-libraries on TerminusHub, including schema.org but also basic standard models for common domains such as CRM, accounting, and inventory. Users can then generate and share models with collaborators or the broader public.</p>

<h3 id="document-editor">Document Editor</h3>

<p>TerminusDB 4.0 has full surfability, clickability and editability of database documents through the console. It is a wiki or catalogue of all your data that you can edit in place. You don’t have to write code or execute a query, just edit the document directly. If you have a collaborative project, this is a useful approach to building and curating data assets.</p>

<p>The documents link to associated documents delivering a linked data application. You can filter documents, you can find the document you want using search, you can create a new document in the interface - it is a <strong>general-purpose tool for managing your data</strong>.</p>

<p>This is the beginning of the TerminusDB content management system, which we will be expanding over the coming months - next step is to provide web accessibility to TerminusHub databases and then a publisher API to provide the ability to publish the results of any query as a static content set.</p>

<h3 id="csv-manager">CSV Manager</h3>

<p>With a single click, you can now build a database from a CSV or a group of CSVs. You can easily use TerminusDB and TerminusHub as a place to version and collaborate when working with CSV data. This will be especially useful with fast changing data as frequently used in machine learning and data science projects.</p>

<p>We have tried to make it as simple as possible for users to interact with the CSV tooling. You can view and edit CSVs directly in the document viewer. You can also add CSVs from this interface. No need to write code.</p>

<p>The database automatically spots if the CSV is already in the database and will just add the delta. There is an append mode that just adds the data that is not there and an update mode that updates the entire CSV.</p>

<p><strong>Manage your CSVs and other data via TerminusDB and Hub.</strong></p>

<h3 id="command-line-interface">Command Line Interface</h3>

<p>We are excited to launch the TerminusDB CLI. You can connect to TerminusDB with a Git-like CLI to run queries or use the revision control features.</p>

<p>You can create databases and branches, you can list databases/branches, you can query in the command line and you can load CSVs. You also get full error reporting in the CLI. Use the CLI to import a CSV, commit changes and push the changes to TerminusHub.</p>

<p>The CLI will continue to develop and add new operations. We will make it easier to execute queries directly from the CLI. We’re also planning to launch CLIs for the JavaScript and Python clients.</p>

<p>TerminusDB is a big step towards our ambition to be a complete decentralized data and content management system that is accessible to all.</p>

<p><strong>END</strong></p>

<p>* Star’s End is a reference to the mysterious location of the Second Foundation in the Asimov series of novels. The home of the First Foundation was Terminus.</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/4.0_2.png" alt=""></p>

        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305296</guid>
            <pubDate>Fri, 04 Dec 2020 17:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Fast Is My FPGA Design? Types Will Tell Me!]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25305242">thread link</a>) | @durst
<br/>
December 4, 2020 | https://davidbdurst.com/blog/how_fast.html | <a href="https://web.archive.org/web/*/https://davidbdurst.com/blog/how_fast.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="header">
                <div>
                    <div>
                        <p>
                            <h3>How Fast Is My FPGA Design? Types Will Tell Me!</h3>
                        </p>
                    </div>
                    
                </div>
            </div><div>
                <p>
                    Let's look at a type-directed approach for implementing
                    image processing applications on FPGAs. This approach will
                    enable us to statically verify a design's throughput. If you
                    like this post, check out my PLDI 2020 paper <a href="https://aetherling.org/">Aetherling</a>, which
                    provides a formal definition of the types and uses them
                    to make trade-offs automatically during the FPGA design process.
                </p>
            </div><div id="main_content">
                <div>
                    <!--target audience: someone at google who already knows its hard to make stuff fast, not hardware person, knows that apple and google are doing custom hardware (maybe), interested in design choices apple/google would have to make-->
                    <p>
                        Hardware designs on FPGAs offer a different set of
                        performance trade-offs compared to software running on a
                        CPU. Greater parallelism can be achieved on an FPGA by
                        allocating more resources, like adders and multipliers.
                        This is unlike a CPU with a fixed number of cores and
                        vector lanes per cores. However, FPGA have limited
                        resources, so trade-offs must be made between
                        parallelism (or throughput) and resource utilization. In
                        this blog post, we're going to look at the
                        throughput-resource utilization trade-offs for FPGA
                        implementations of image processing operations like
                        image blurring. There are many ways to blur images on an
                        FPGA. Some designs have higher throughput, and others
                        require fewer resources. I'm going to demonstrate a type
                        system for expressing designs with different
                        throughput-resource tradeoffs that enables you to
                        statically determine a design's throughput.
                        <a href="#types_of_resources">
                            (See below for a refresher on the types of resources
                            available on an FPGA.)
                        </a>
                    </p>

                    <h4 id="what_else">
                        <a href="#what_else">
                            FPGA designs for image blurring with different throughput-resources trade-offs
                        </a>
                    </h4>
                    <p>
                        Before we get to the type system, let's look at a few
                        different ways to blur an image on an FPGA. These
                        designs will have different throughout-resources
                        trade-offs. The below video shows one design that
                        processes one pixel per clock cycle. It does so by
                        streaming over the input pixels, accepting one at a
                        time, storing two prior input pixels in registers, and
                        computing the average of the current input and the prior
                        two.
                    </p>

                    

                    <p>
                        Design a in the image below shows the same one pixel per
                        clock design as the above animation. Designs b and c
                        show two other implementations with different
                        throughput-resource utilization trade-offs. Design b
                        processes two elements per clock, doubling the
                        throughput relative to design a and the animation above.
                        Design b requires double the adders and dividers
                        compared to design a in order to achieve this
                        throughput. Design c saves on adders but can only
                        process one pixel every third clock cycle.
                    </p>

                    <div>
                        <div id="three_blurs">
                            <figure>
                                <p>Design a</p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/1px_per_clock_no_clk.svg">
                                <p>Design b</p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/2px_per_clock_no_clk.svg">
                                <p>Design c</p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/1_3px_per_clock_no_clk.svg">
                                <figcaption>
                                    Three different implementations of a blur.
                                    The gray nodes accept and emit data every
                                    clock. The red nodes accept and emit data
                                    every third clock.  For simplicity, these
                                    designs only do a blur on a 1D image.
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p>
                        You could write up all these different designs in
                        Verilog. Assuming you wrote correct code, they would
                        synthesize to a bitstream, run on an FPGA, and provide
                        the expected throughput. But, it would be challenging to
                        statically verify that the designs achieved the correct
                        performance.
                    </p>

                    <h4 id="st_types">
                        <a href="#st_types">
                            Space-time types encode throughput
                        </a>
                    </h4>
                    <p>
                        Now that we've seen some different designs, we're ready
                        for the types that encode their throughputs. Since we're
                        building application-specific hardware, we can encode
                        the throughput of the designs down to the clock cycle
                        without complex performance issues common in software
                        like multi-threading. I'm going to introduce these types
                        using a simpler example than blur: <code>map
                        add10</code>. This code adds 10 to each element in an
                        input sequence. When implementing a map on an FPGA,
                        there are two basic implementations. The first
                        implementation, <code>map_s add10</code> (or
                        <code>map</code> in space), is fully parallel and
                        duplicates <code>add10</code>. If the <code>map_s</code>
                        is applied to a sequence of four elements, then four
                        elements arrive on one clock cycle, <code>map_s</code>
                        adds 10 to every element, and the four elements depart
                        on the same clock cycle. The second implementation,
                        <code>map_t add10</code> (or <code>map</code> in time),
                        is fully sequential and requires only one copy of the
                        <code>add10</code> circuit. The four input elements
                        arrive on four separate clocks and <code>map_t</code>
                        adds 10 to one element at a time.
                    </p>

                    <div>
                        <div id="st_maps">
                            <figure>
                                <p><code>map_s add10</code></p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/map_s_4_add10_no_arrow.svg">
                                <p><code>map_t add10</code></p>
                                <img src="https://davidbdurst.com/blog/aetherling_media/map_t_4_0_add1_no_arrow.svg">
                                <figcaption>
                                    Two different implementations of a map
                                    on an FPGA.
                                </figcaption>
                            </figure>
                        </div>
                    </div>

                    <p>
                        The types of <code>map_s</code> and <code>map_t</code>
                        encode their throughputs. <code>map_s add10 :: SSeq 4
                        int -&gt; SSeq 4 int</code> is a function on two space
                        sequences. Each space sequence (<code>SSeq 4 int</code>)
                        encodes both the length of the sequence and that all the
                        elements occur on the same clock cycle. The type
                        signature of <code>map_s add10</code> encodes it's a
                        function which accepts four <code>int</code>s on one
                        clock and emits them on one clock. This is a throughput
                        of four <code>int</code>s per clock. <code>map_t add10 :: TSeq 4 0
                        int -&gt; TSeq 4 0 int</code> is a function on two time
                        sequences. Each time sequence (<code>TSeq 4 0 int</code>)
                        encodes that all the elements elements occur on different clocks, one after another. The type
                        signature of <code>map_t add10</code> encodes it's a
                        function which accepts four <code>int</code>s on separate
                        clocks and emits them on separate clocks. This is a throughput
                        of one <code>int</code> per clock. The fully sequential
                        throughput, like the fully parallel one for <code>map_s
                        add10</code>, is easily expressed using the space-time
                        types.
                    </p>

                    <h4 id="other_throughputs">
                        <a href="#other_throughputs">
                            Space-time types enable expressing more
                            complex throughputs than just fully parallel or
                            sequential
                        </a>
                    </h4>
                    <p>
                        The prior <code>map</code> examples only had fully
                        parallel or sequential throughputs. We need to support
                        other types of throughputs in order to handle all of the
                        image blur designs. We can nest and modify the
                        parameters of the space-time types to express a wider
                        range of throughputs. The two pixel per clock blur
                        design b is partially parallel: it processes more than
                        one pixel per clock but doesn't do the entire image at
                        once. We can encode partially parallel throughputs by
              …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidbdurst.com/blog/how_fast.html">https://davidbdurst.com/blog/how_fast.html</a></em></p>]]>
            </description>
            <link>https://davidbdurst.com/blog/how_fast.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305242</guid>
            <pubDate>Fri, 04 Dec 2020 17:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tiny Case Study in Automation]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25305206">thread link</a>) | @sahillavingia
<br/>
December 4, 2020 | https://philipkiely.com/essays/helpscout_links.html | <a href="https://web.archive.org/web/*/https://philipkiely.com/essays/helpscout_links.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Recently, I’ve been learning about high-leverage work. Automation is a great example of high-leverage work because you can save people time. The easiest way to add automation to your platform is to let users add their own code. Help Scout has a little box on some far-flung page that you can use to add custom JavaScript to a site. I think it is designed for analytics trackers and such, but I used it to save my support team hours on the way to saving our users even more&nbsp;time.</p>
<p>Gumroad maintains over 200 help documents for creators and their customers. Many of these documents are long, with many pictures, gifs, headers, and paragraphs. When I’m writing a customer support email, I want to link specific parts of the help&nbsp;page.</p>
<p>An anchor link is an <span>HTML</span> attribute that lets you link to somewhere in the page. Help Scout supports anchor links, but you have to set them manually. With over 200 documents between the creator and customer docs, this would be hours of tedious manual work to add, and then they would need to be kept up to date as the docs are edited over&nbsp;time.</p>
<p>Example: <a href="https://help.gumroad.com/article/82-membership-products#MultipleTiers">https://help.gumroad.com/article/82-membership-products#MultipleTiers</a></p>
<p>Help Scout supports custom JavaScript, so I wrote a snippet that dynamically assigns anchor links to each h2 and h3 on the page. I also had it exclude the main pages because they are not articles, so those pages are unaffected by the change (otherwise, their <span>UI</span> breaks). Thus, every single header is now directly linkable and those links will stay up to date over&nbsp;time.</p>
<p>2 small&nbsp;drawbacks:</p>
<ol>
<li>The links are the first 20 characters of the header, so they can end in the middle of a word, which is not ideal but shouldn’t be an issue, they are still&nbsp;descriptive.</li>
<li>If you change the header text, old anchor links will no longer work, as the anchor is dynamically generated so it automatically updates. However, if an anchor link is broken, it just brings the user to the top of the page, which was the previous functionality, so it isn’t a worse user experience. Still, these links are designed for a message or other temporary place, not for permanent&nbsp;use.</li>
</ol>
<p>The code, in case you’re interested (note for the custom script in <code>help.gumroad.com</code> the <code>window.location.href</code> check has an accordingly different&nbsp;value):</p>
<pre><code>&lt;script&gt;
//auto link all h2 and h3
function linkText(s) {
    return s.replace(/\W/g, '').substring(0, 20)
}
function makeTitleLink(tag) {
    Array.from(document.getElementsByTagName(tag)).forEach(
        function(element, index, array) {
            console.log(element, index, array)
            element.id = linkText(element.innerText)
            element.innerHTML = "&lt;a href=\"#" + element.id + "\"&gt;" + element.innerHTML + "&lt;/a&gt;"
        }
    );
}
document.addEventListener("DOMContentLoaded", function(){
    loc = window.location.href.substring(6, window.location.href.length)
    if (loc != "//customers.gumroad.com" &amp;&amp; loc != "//customers.gumroad.com/") {
        makeTitleLink("h2")
        makeTitleLink("h3")
    }
});
&lt;/script&gt;
</code></pre>

<p>The thing I found most interesting about all of this is how anchor links interact with the page load sequence. The function doesn’t trigger until the <span>DOM</span> contents are fully loaded, but the browser still knows to jump to the appropriate place on the&nbsp;page.</p>
<p>If you are a Help Scout user, feel free to adopt this code snippet under the <span>MIT</span>&nbsp;License.</p>
		</div></div>]]>
            </description>
            <link>https://philipkiely.com/essays/helpscout_links.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305206</guid>
            <pubDate>Fri, 04 Dec 2020 17:33:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating is just copying intelligently]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25305037">thread link</a>) | @KlimYadrintsev
<br/>
December 4, 2020 | https://klimy.co/blog/creating-is-copying-04-12-2020 | <a href="https://web.archive.org/web/*/https://klimy.co/blog/creating-is-copying-04-12-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>Innovation</h2>
<p>We, humans, are unable to come up with anything new and completely groundbreaking. Most of the time, we are trapped in a rat race pursuing next new shiny thing. </p>
<p>Every single innovation that has been invented in the past has been a better version of something that already existed.</p>
<p>Everything that looks somewhat new and that didn’t exist before; scientist stumbled upon it by mistake.</p>
<p>If someone had a crazy theory that no-one believed it and that eventually was proven true, was most likely due to someone having a brain problem.</p>
<p>Our brain can think of the unknown, but only when it has some relationship with the current world.</p>
<p>As an example:</p>
<p>Google's search engine is a huge innovation. They looked at the way data is searched through and categorised in libraries(plus copied from bing and yahoo).</p>
<p>Electricity was based upon static electricity that people knew about since 600 BC.</p>
<p>The ability to communicate has been invented because other animals had to communicate as well somehow, and the more social problems an animal has, the harder and more complex the language would get.</p>
<p>If all that didn’t prove to you that we don’t just create out of thin air, then I don’t know what will.</p>
<h2>How can you innovate</h2>
<p>All of the humans deep inside have a powerful creative side.</p>
<p>All of us occupying different niches of work. Programming, marketing, psychology, and management positions. But all of us have a creative side that sometimes, without even realising it, we apply.</p>
<ul>
<li>Every time a programmer tweaks a ready code on stack overflow with a different method. This is creativity.</li>
<li>Every time a marketer chooses to experiment and run a/b test on some of the campaigns or websites. This is creativity.</li>
<li>Every time a psychologist changes their routine to help a person better. This is creativity.</li>
<li>Every time a manager is faced with an employee that is leaving and is trying to bring points on why the employee should stay. This is creativity.</li>
</ul>
<p>There are a lot of ways for people to be creative. As long as there are new projects and ideas, <a href="https://klimy.co/blog/the-world-doesnt-stop-when-you-are-tired">that means that people are creating.</a> </p>
<h2>Copying</h2>
<p>There is no known reason not to be inspired by others work when creating. Our brain uses profound and unknown pattern recognition algorithms to link our work to the work of others so that we could improve.</p>
<p>If you have seen a particular post by someone and you fell in love with the idea, don’t hesitate to write your personal opinion on the topic, or even make exactly the same post but in your own words.</p>
<p>There is nothing bad about copying for inspiration. The best of the artists have said:</p>
<p><code>Mark Earls, leading expert in marketing and consumer behaviour, quashes the stigma around copying, and shows that it can help us to rethink how we go about solving problems. By understanding what other people are doing and the choices they make, we can develop strategies to solve the challenges that we face inside and outside the organization.</code></p>
<p>We are all here to learn. If you are unable to learn from the best, you will be much slower than others, and your quality will suffer too.</p>
<p>Start with something. Read some of your favourite books. The motivation and ideas will come passively as long as there are enough inputs.</p>
<p>Start now. Get perfect later.</p>
<p>Klim Y</p> 
                    
                </div></div>]]>
            </description>
            <link>https://klimy.co/blog/creating-is-copying-04-12-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305037</guid>
            <pubDate>Fri, 04 Dec 2020 17:21:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a Serverless School Management System with React, Auth0 and FaunaDB]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25305012">thread link</a>) | @Osinachi
<br/>
December 4, 2020 | https://osi.codes/create-a-serverless-school-management-system-with-react-auth0-and-faunadb | <a href="https://web.archive.org/web/*/https://osi.codes/create-a-serverless-school-management-system-with-react-auth0-and-faunadb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>Many schools across the world have transitioned into fully online experiences with the recent pandemic. With each school's backend stack witnessing new highs in usage, serverless solutions are more important than ever. Here's a walkthrough on how to create a robust school management system using Auth0 for identity management and FaunaDB as a serverless database. FaunaDB allows us to create globally distributed databases with virtually no traffic limits. You can perform as many reads/writes as you desire.</p>
<p>The School Management System we're building (named "skulment") has three categories of users: students, teachers and managers. Below is a basic description of what each role should be able to do.</p>
<h2 id="users">Users</h2>
<p><strong>Students should be able to:</strong>
register/unregister for courses
see courses they registered for
see the teachers assigned to each of their courses</p>
<p><strong>Teachers should be able to:</strong>
see all students taking their course
see all the courses they manage</p>
<p><strong>Managers should be able to:</strong>
read and modify Student, Course and Teacher resources</p>
<p>This is a basic set of rules for each role. In a real-world scenario, there would be more protections and rules on each role. We will work with this for simplicity sake.</p>
<h2 id="architecture">Architecture</h2>
<p>For many years now, No-SQL databases have severely lacked relational database features. The ability to model relationships allows for healthy and stable maturation of databases, as applications are iterated on. FaunaDB's founders knew that support for relational data was a must if FaunaDB were to be competitive.</p>
<p>In this application, we'll be modelling for one-to-many and many-to-many relationships. Aside from our users, we'll also need to model for Courses and Classes. Below is a diagram of our soon to be school management system. Please note that real-world usage will likely involve larger data structures, but for the sake of this example, we'll keep things simple.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/e3sr2m7a1l1pgibs0n3v.png" alt="skulment-db"></p>
<h3 id="relationships">Relationships</h3>
<p>Students to Courses (Many : Many): A student can have many courses and a course can have many students
Teachers to Courses (Many : Many): A teacher can have many courses and a course can have multiple teachers
Class to Courses (1 : Many): A course can only belong to one class and a class can have many courses</p>

<p>We're going to start with our backend resources, FaunaDB and Auth0 in particular, and then make our way to the more front-facing elements of this project, with ReactJS. For convenience sake, I've written an example environment file (<code>.env</code>) which you can copy to create your own, along with a node.js script to scaffold the backend. To use them, you will need to clone <a target="_blank" href="https://github.com/vicradon/skulment-demo">my repo</a> and initialize the frontend like so:</p>
<pre><code>git <span>clone</span> https://github.com/vicradon/skulment-demo.git
<span>cd</span> skulment-demo
yarn 
cp .env.example .env
</code></pre>

<p>FaunaDB as a <strong>serverless database</strong> allows us to focus on our business logic and worry less about <em>setup</em> and <em>maintenance</em>. Creating a database is as simple as running a <code>CreateDatabase({name:"some_db"})</code> command. All maintenance is taken care of behind the scenes by engineers and automated DevOps at FaunaDB. The hassles associated with other databases, such as choosing regions and configuring storage, are nonexistent with FaunaDB; which is global/multi-region by default </p>
<p>Create a fauna account <a target="_blank" href="https://dashboard.fauna.com/accounts/register?utm_source=DevTo&amp;utm_medium=referral&amp;utm_campaign=WritewithFauna_SchoolManagementSystem_OChukwujama">here</a> if you don't have one already. We'll make use of the <a target="_blank" href="https://github.com/fauna/fauna-shell">fauna shell</a> which allows us to create/modify resources on FaunaDB. Note that Fauna also has a web shell in the cloud console, with a great user interface for debugging FQL.</p>
<pre><code>npm install -g fauna-shell
fauna cloud-login
</code></pre>
<p>Great! Now, let's create our first database.</p>
<pre><code>fauna create-database skulment_demo &amp;&amp; fauna shell skulment_demo
</code></pre>
<p>This launches a repl-like environment where we can execute FQL queries. While many databases which don’t have SQL interfaces opt for simple CRUD APIs, FaunaDB offers the <a target="_blank" href="https://docs.fauna.com/fauna/current/api/fql">Fauna Query Language (FQL)</a>, a functional database query language. If you’re familiar with SQL, here’s <a target="_blank" href="https://docs.fauna.com/fauna/current/start/fql_for_sql_users">a fantastic comparison between the two</a>. FaunaDB turns our data into an API either through its <a target="_blank" href="https://docs.fauna.com/fauna/current/start/graphql">GraphQL client</a> or through FQL. This means you don’t have to build APIs from scratch, just to use your database in an application! We can now create our first collection.</p>
<pre><code>CreateCollection({ name: <span>"Students"</span> })







</code></pre>
<p>This will create a Collection named <code>Students</code>. A FaunaDB Collection is similar to a table in a relational database. However, it stores documents instead of rows and has loose data structure requirements by default (enforcement can be built). We will now create other Collections in the shell, just as we did before.</p>
<pre><code>
CreateCollection({name: <span>"Teachers"</span>});
CreateCollection({name: <span>"Managers"</span>});
CreateCollection({name: <span>"Courses"</span>});
CreateCollection({name: <span>"Classes"</span>});
</code></pre>
<p>All 5 of our Collections are currently empty.  Let's see how we can fill the void by adding a student to the <code>Students</code> collection.</p>

<p>We will add a student document to the Students collection using the FQL <code>Create</code> function. </p>
<pre><code>Create(Collection(<span>"Students"</span>), {
  data: {
    firstName: <span>"Wangari"</span>,
    lastName: <span>"Maathai"</span>,
    email: <span>"wangari.maathai@skulment.edu"</span>,
  },
});










</code></pre>
<h2 id="refs">Refs</h2>
<p>When we inspect the returned JSON, we see a <code>ref</code> field. A reference (or "ref" for short) is a native FaunaDB object used to uniquely identify a Document along with its Collection and can be used much like a foreign key. The 18 digit number within the ref is the document's id. Although it's possible to extract a document's id and store it for other purposes, it's highly encouraged to keep it paired with its respective Collection name, as the id alone isn't enough to be a pointer or retrieve a Document. </p>
<p>Using the <code>Paginate</code> and <code>Documents</code> functions, we can retrieve the ref of our recently created Student (since it's the only document in the collection so far).</p>
<pre><code>Paginate(Documents(Collection(<span>"Students"</span>)))


</code></pre>
<p>If we pretend that our database is a physical library, where you can read or borrow books, and that all of its books are collections: the <code>Collection</code> function returns a book's location (or "ref") in the library, the <code>Documents</code> function opens the book, and the <code>Paginate</code> function reads a page from the book. However, in this case, a book's page is an array of document refs, not the entirety of a document's data. Note that <code>Paginate</code> can return data other than refs when using custom Indexes (more on this later). For now, we can read an entire document by copy-pasting our first Student's ref into a <code>Get</code> function.</p>
<pre><code>Get(Ref(Collection(<span>"Students"</span>), <span>"277574932032913921"</span>))
</code></pre>
<p>NB: The ref that should be in your <code>Get</code> function should be the one from your terminal, not the one above.</p>
<h2 id="update-and-delete">Update and Delete</h2>
<p>To mutate this document, we use the <code>Update</code> function. The <code>Update</code> function takes in a ref and the fields to be written to and returns the modified document.</p>
<pre><code>Update(Ref(Collection(<span>"Students"</span>), <span>"277574932032913921"</span>), {
    data: {
      email: <span>"wangari-nobel@skulment.edu"</span>
    }
  }
)

</code></pre>
<p>To delete this document we call the FQL delete function on its ref like so</p>
<pre><code>Delete(Ref(Collection(<span>"Students"</span>), <span>"277574932032913921"</span>))
</code></pre>

<p>Now that we know how to CRUD documents using FQL, we will use the <code>populate-collections.js</code> script, in the scripts directory of the project, to populate all of the newly created collections with demo data; creating:</p>
<ul>
<li>50 students</li>
<li>10 teachers</li>
<li>2 managers</li>
<li>20 courses and </li>
<li>6 classes.</li>
</ul>
<p>Since we are using a script, it means we are manipulating the database outside the shell. For this, we need the FaunaDB JavaScript driver and a <strong>server key</strong>. </p>
<p>The JavaScript driver is an npm package that allows us to use FQL within a JavaScript file. The <a target="_blank" href="https://docs.fauna.com/fauna/current/security/index.html">server key</a> is a key that bypasses all permission checks within its database. It must be handled with care.</p>
<p>You can always invalidate server keys with the <code>Delete</code> function or on the Fauna dashboard if they have been compromised. See image below.</p>
<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/ulh0ydj2d72f9dfzvu8j.png" alt="revoking a key"></p>
<p>Run this command in the shell and copy the secret from the result.</p>
<pre><code>CreateKey({ role: <span>"server"</span> })








</code></pre>
<p>Paste the secret into the FAUNA_SERVER_SECRET key of your .env file. Afterwards, open a new terminal and run the command below from where you cloned into the repo earlier.</p>
<pre><code>node scripts/populate-collections


</code></pre>
<p>If no errors are thrown, you should be able to see the generated documents in the newly created collections </p>
<pre><code>Map(
  Paginate(Documents(Collection(<span>"Students"</span>))),
  Lambda(<span>"ref"</span>, Get(Var(<span>"ref"</span>)))
);

</code></pre>
<p>The populate-collections script was a pleasure to write because FQL is a well-designed language, where functional programmers will feel right at home. Although we used the JavaScript driver, FaunaDB also offers drivers for other languages, such as Scala, Go, Python, Java, etc. Because FQL is so flexible and accommodating, developers can shift a majority of their business/backend logic onto Fauna’s servers, where FQL is executed in fully ACID distributed transactions. Composition and code reuse is also a breeze with User Defined Functions (UDF) and Indexes, more on these later. With FQL, it’s never been easier to write serverless backend code; yes, even easier than traditional serverless functions, as deployment processes are nonexistent.</p>

<p>If we don’t know a document’s ref, we can use other fields such as email or firstName to search for a document, using a FaunaDB Index. Indexes can also be used to sort and reverse the refs and data of specific documents. Finally, they can also impose constraints, such as uniqueness, preventing duplicate results from being returned. Learn more about indexes <a target="_blank" href="https://docs.fauna.com/fauna/current/api/fql/functions/createindex">here</a>.</p>
<h2 id="index-example-getting-a-user-by-email">Index example: getting a user by email</h2>
<p>The user documents of this app are in the <code>Students</code>, <code>Teachers</code> and <code>Managers</code> collections. This means that in building this index, we will include those collections as the index's source, which is to be searched on.  The fields to be searched will be put in the <code>terms</code> property. The user's email is searched in the <code>data.email</code> property of their document, which in FQL, is written as an array path: <code>["data", "email"]</code>.</p>
<pre><code>CreateIndex({
  name: <span>"users_by_email"</span>,
  <span>source</span>: [
    {collection: Collection(<span>"Students"</span>)},
    {collection: Collection(<span>"Teachers"</span>)},
    {collection: Collection(<span>"Managers"</span>)},
  …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://osi.codes/create-a-serverless-school-management-system-with-react-auth0-and-faunadb">https://osi.codes/create-a-serverless-school-management-system-with-react-auth0-and-faunadb</a></em></p>]]>
            </description>
            <link>https://osi.codes/create-a-serverless-school-management-system-with-react-auth0-and-faunadb</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305012</guid>
            <pubDate>Fri, 04 Dec 2020 17:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One last trip down memory lane with the Raspberry Pi Zero]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25304897">thread link</a>) | @alexellisuk
<br/>
December 4, 2020 | https://blog.alexellis.io/memory-lane-raspberry-pi-zero/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/memory-lane-raspberry-pi-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>The <a href="https://www.raspberrypi.org/products/raspberry-pi-zero/?resellerType=home">Raspberry Pi Zero</a> and original Raspberry Pi both have a 32-bit ARM architecture which many projects have dropped support for. So when I saw that <a href="https://github.com/containerd/containerd/pull/4530">containerd recently merged a fix</a> for building containerd on armv6, started to think what I could do with it.</p>
<p>Earlier that month, a user of the <a href="http://github.com/openfaas/faasd">faasd project</a> which runs very well on VPSes, RPi 3 and RPi4 asked me whether it could work on the Zero and I told him it was not practical or worth his time. After all, an RPi4 with 2GB of RAM, 4 Cores and much faster I/O is only 25GBP/EUR/USD.</p>
<blockquote>
<p><a href="https://github.com/openfaas/faasd">faasd is OpenFaaS</a>, but for a single node, and designed for those who don't want to pay for and manage an entire Kubernetes cluster, GitOps, service-mesh, and IngressController just to deploy a few simple functions.</p>
</blockquote>
<p>My past experiences told me that it would be a challenge to get the zero working. It has such a paltry amount of memory available and its I/O is really slow. Still, sometimes it's fun to do things that we shouldn't. Had I been <a href="https://xkcd.com/356/">"nerd sniped"</a>?</p>
<p><img src="https://www.raspberrypi.org/homepage-9df4b/static/1dfa03d09c1f3e446e8d936dfb92267f/8924f/6b0defdbbf40792b64159ab8169d97162c380b2c_raspberry-pi-zero-1-1755x1080.jpg" width="60%">
&gt; The RPi Zero originally released in 2015.
</p><p>In this post I'll show you what you need to do to deploy functions through the <a href="https://github.com/openfaas/faas-cli">OpenFaaS CLI</a> and be able to invoke them, including multi-arch builds. At the end of the post I'll explain what the limitations are and whether we should leave the Raspberry Pi Zero with those fond memories we have of it when it was <a href="https://en.wikipedia.org/wiki/Raspberry_Pi">released in 2015</a>, 5 years ago.</p>
<h2 id="walkthrough">Walk-through</h2>
<h3 id="prereqs">Pre-reqs</h3>
<p>You will need:</p>
<ul>
<li>Raspberry Pi Zero</li>
<li>Ethernet adapter and USB &lt;&gt; USB A micro shim</li>
<li>16-32GB class 10 SD card</li>
<li>MicroUSB power adapter</li>
</ul>
<p>Flash the latest version of Raspberry Pi OS Lite to your SD card, and then create an <code>ssh</code> file in the <code>/boot/</code> folder.</p>
<p>Power up the Raspberry Pi and ssh to it with <code>ssh pi@raspberrypi.local</code>.</p>
<h3 id="installgo">Install go</h3>
<p>You can install Go from a package manager, but the version is likely to be rather old. Fortunately the Go team still ship a binary for armv6:</p>
<pre><code>export ARCH="armv6l"
echo "Downloading Go"

curl -SLsf https://dl.google.com/go/go1.13.15.linux-$ARCH.tar.gz --output /tmp/go.tgz
sudo rm -rf /usr/local/go/
sudo mkdir -p /usr/local/go/
sudo tar -xvf /tmp/go.tgz -C /usr/local/go/ --strip-components=1

export GOPATH=$HOME/go/
export PATH=$PATH:/usr/local/go/bin/
</code></pre>
<p>You now have Go installed, run <code>go version</code> to see it working.</p>
<h3 id="buildcontainerd">Build containerd</h3>
<p>faasd uses containerd rather than Docker, but there are no official binaries for any of the ARM CPUs, so we have to build them from source.</p>
<p>For armv7 and ARM64, you can use my repo <a href="https://github.com/alexellis/containerd-arm">alexellis/containerd-arm</a>. It's my hope to see ARM support upstreamed, but having spoken on several occasions to the containerd team, it seems very unlikely that we will see this happen.</p>
<p>On my first attempt of building I got the following error:</p>
<pre><code>+ bin/containerd
# github.com/containerd/containerd/cmd/containerd
/usr/local/go/pkg/tool/linux_arm/link: running gcc failed: fork/exec /usr/bin/gcc: cannot allocate memory
make: *** [Makefile:188: bin/containerd] Error 2
</code></pre>
<p>The RPi Zero and the largest RPi 1 only has 512MB of RAM and I slowly watched the RAM being eaten up with <code>watch -n "free -h"</code>.. I should have remembered this.</p>
<p>Fortunately I had the battle scars and knew what I had to do:</p>
<pre><code>sudo dd if=/dev/zero of=/swapfile bs=1024 count=1M &amp;&amp;\
  sudo mkswap /swapfile &amp;&amp; \
  sudo swapon /swapfile
</code></pre>
<p>This creates 1GB of swap, on the SD card.. which already has terrible I/O, but it may just work.</p>
<p>The other trick you may have seen me talk about is adding <code>gpu_mem=16</code> to <code>/boot/config.txt</code>. It seems pointless changing the split on an 8GB RPi4, but for our RPi Zero, we need every MB we can get.</p>
<p>Second time lucky?</p>
<p>No. It failed again due to some missing libraries. I reminded myself to read <a href="https://github.com/containerd/containerd/blob/master/BUILDING.md#build-containerd">BUILDING.md</a> from the containerd repo. After adding libseccomp and a few other packages, it started to move along again.</p>
<pre><code>make
+ bin/ctr
+ bin/containerd
+ bin/containerd-stress
+ bin/containerd-shim
+ bin/containerd-shim-runc-v1
+ bin/containerd-shim-runc-v2
+ binaries
</code></pre>
<p>I don't know if it was 10 minutes or over an hour, but it was slow progress.</p>
<p>I then ran <code>sudo make install</code> and copied the systemd unit file into place with:</p>
<pre><code>sudo cp containerd.service /etc/systemd/system/containerd.service
sudo systemctl enable containerd
</code></pre>
<p>I didn't want to start containerd at this time, to save on memory for the next task.</p>
<h3 id="buildfaasd">Build faasd</h3>
<p>The faasd Makefile needed a patch because it was set to cross-compile to armv7, but we needed armv6.</p>
<pre><code>.PHONY: dist
dist:
	CGO_ENABLED=0 GOOS=linux GOARCH=arm GOARM=6 go build -mod=vendor -ldflags $(LDFLAGS) -a -installsuffix cgo -o bin/faasd-armhf
</code></pre>
<p>This took so long to build on the zero that I gave up and built it on my Intel NUC. Fortunately Go is very good as cross-compiling, especially when linking into C/C++ libraries is disabled with <code>CGO_ENABLED=0</code>.</p>
<p>I then ran <code>scp</code> to copy the binary to the Raspberry Pi.</p>
<pre><code>sudo cp faasd-armhf /usr/local/bin/faasd
cd go/src/github.com/openfaas/faasd
</code></pre>
<p>The final step was to install faasd which creates two systemd unit files:</p>
<ul>
<li>faasd - for the OpenFaaS core services</li>
<li>faasd-provider - for the provider that supports CRUD and Invoke operations</li>
</ul>
<pre><code>sudo faasd install
</code></pre>
<p><img src="https://blog.alexellis.io/content/images/2020/12/faasd-install.jpg" alt="faasd-install"></p>
<h3 id="unexpectedissues">Unexpected issues</h3>
<p>I tried to log in with <code>faas-cli login</code>, but it didn't work. I saw a number of errors in the logs <code>sudo systemctl journalctl -u faasd</code>:</p>
<pre><code>Dec 03 23:18:49 zero-dns default:basic-auth-plugin[13218]: standard_init_linux.go:207: exec user process caused "exec format error"
Dec 03 23:18:50 zero-dns containerd[12169]: time="2020-12-03T23:18:50.338589900Z" level=info msg="starting signal loop" namespace=default path=/run/containerd/io.containerd.runtime.v2.task/default/gateway pid=13324
Dec 03 23:18:52 zero-dns default:gateway[13335]: standard_init_linux.go:207: exec user process caused "exec format error"
</code></pre>
<p>It turned out that out of nats, prometheus, and the openfaas gateway, the openfaas basic-auth plugin only nats was available for armv6. It seems that projects really have moved on and left armv6 behind.</p>
<h3 id="thenihadanidea">Then I had an idea</h3>
<p>What if we didn't run the whole OpenFaaS stack at all, but just the <code>faasd-provider</code>? It would allow this tiny device to support all the CRUD operations on functions, and invocations, but nothing more.</p>
<p>The provider seemed to be running well, and responding to <code>faas-cli</code> commands:</p>
<p><img src="https://blog.alexellis.io/content/images/2020/12/provider.png" alt="provider"></p>
<p>We'd lose the queue and async invocations, lose the UI, lose the metrics, but we could still deploy functions and invoke them.</p>
<p>It was already very late by this point so I decided to sleep on it.</p>
<h3 id="inthemorning">In the morning</h3>
<p>I powered up the RPi zero and tried deploying a container directly to the faasd endpoint, and it worked.</p>
<p><img src="https://blog.alexellis.io/content/images/2020/12/deploy.jpg" alt="deploy"></p>
<p>Now, I had to make a few changes. Rather than building with the OpenFaaS watchdog in the container, I just used a Dockerfile and a plain Go HTTP server.</p>
<p>Here's what I ended up with:</p>
<p>Dockerfile</p>
<pre><code>FROM --platform=${BUILDPLATFORM:-linux/amd64} golang:1.13-alpine3.11 as build
ARG TARGETPLATFORM
ARG BUILDPLATFORM
ARG TARGETOS
ARG TARGETARCH
RUN apk --no-cache add git

ENV CGO_ENABLED=0

RUN mkdir -p /go/src/handler
WORKDIR /go/src/handler
COPY . .

# Run a gofmt and exclude all vendored code.
RUN test -z "$(gofmt -l $(find . -type f -name '*.go' -not -path "./vendor/*" -not -path "./function/vendor/*"))" || { echo "Run \"gofmt -s -w\" on your Golang code"; exit 1; }

ARG GO111MODULE="off"
ARG GOPROXY=""

RUN CGO_ENABLED=${CGO_ENABLED} GOOS=${TARGETOS} GOARCH=${TARGETARCH} \
    go build --ldflags "-s -w" -a -installsuffix cgo -o handler .
RUN GOOS=${TARGETOS} GOARCH=${TARGETARCH} go test ./... -cover

FROM --platform=${TARGETPLATFORM:-linux/amd64} alpine:3.12
# Add non root user and certs
RUN apk --no-cache add ca-certificates \
    &amp;&amp; addgroup -S app &amp;&amp; adduser -S -g app app \
    &amp;&amp; mkdir -p /home/app \
    &amp;&amp; chown app /home/app

WORKDIR /home/app

COPY --from=build /go/src/handler/handler    .

RUN chown -R app /home/app

USER app

CMD ["./handler"]
</code></pre>
<p>handler.go</p>
<pre><code>package main

import (
	"fmt"
	"net/http"
)

func main() {
	s := &amp;http.Server{
		Addr:           fmt.Sprintf(":%d", 8080),
		MaxHeaderBytes: 1 &lt;&lt; 20, // Max header of 1MB
	}

	http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
		w.Write([]byte("Hello world"))
	})

	panic(s.ListenAndServe())
}
</code></pre>
<p>stack.yml</p>
<pre><code>version: 1.0
provider:
  name: openfaas
  gateway: http://127.0.0.1:8080
functions:
  http:
    lang: dockerfile
    handler: ./http
    image: alexellis2/http:0.1.4
    build_args:
      GO111MODULE: on
</code></pre>
<p>I ran this on my PC with the following:</p>
<pre><code>export OPENFAAS_URL=http://192.168.0.81:8081
faas-cli publish --platform linux/arm/v6

faas-cli deploy
</code></pre>
<p>Using the PC means we can cross-compile the Go HTTP server and push a multi-arch image to the container registry. The new <code>faas-cli publish</code> command comes in handy for this and can accept a list of architectures.</p>
<p>The <code>deploy</code> command talks to the remote machine over REST and tells it to deploy a function. The server-side handler <a href="https://github.com/openfaas/faasd/blob/master/pkg/provider/handlers/deploy.go">deploy.go</a> pulls the image into containerd and starts executing it as a container.</p>
<h3 id="onemorething">One more thing</h3>
<p>When I say that it worked. I should clarify that I'd forgotten to deploy CNI - the networking layer required for faasd and containerd.</p>
<p>I saw this error by running the following:</p>
<pre><code>sudo journalctl -u faasd
</code></pre>
<p>Not that long ago, <a href="https://github.com/openfaas/faasd/blob/master/docs/DEV.md">I'd documented all the steps required for a manual installation</a>, but somehow forgot this was needed.</p>
<pre><code>export ARCH=arm
export CNI_VERSION=v0.8.5

sudo mkdir -p /opt/cni/bin
curl -sSL https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-linux-${ARCH}-${CNI_VERSION}.tgz | sudo tar -xz -C /opt/cni/bin

# Make a config folder for CNI definitions
sudo mkdir -p /etc/cni/net.d

# Make an initial loopback configuration
sudo sh -c 'cat &gt;/etc/cni/net.d/99-loopback.conf &lt;&lt;-EOF
{
    "cniVersion": "0.3.1",
    "type": "loopback"
}
EOF'
</code></pre>
<p>Just changing "ARCH" to "arm" was enough to make it work. So the CNI project are still <a href="https://github.com/containernetworking/plugins/blob/master/.travis.yml">building the plugins against armv6</a> for the time being.</p>
<h3 id="finalattempt">Final attempt</h3>
<p>Then it was a case of simply running <code>faas-cli deploy</code> again, and finally, it actually worked.</p>
<p>An initial benchmark with <code>hey</code> identified that the …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.alexellis.io/memory-lane-raspberry-pi-zero/">https://blog.alexellis.io/memory-lane-raspberry-pi-zero/</a></em></p>]]>
            </description>
            <link>https://blog.alexellis.io/memory-lane-raspberry-pi-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304897</guid>
            <pubDate>Fri, 04 Dec 2020 17:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Programming Languages]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25304566">thread link</a>) | @marcuskaz
<br/>
December 4, 2020 | https://mkaz.blog/code/on-programming-languages/ | <a href="https://web.archive.org/web/*/https://mkaz.blog/code/on-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content">

		<article>
			
			

			<div>
				
<p>I like types.<br>I like curly braces.<br>I like semi-colons.</p>



<p>Types guide you to better code.<br>Curly braces clearly define blocks of codes.<br>Semi-colons clearly define lines of code.</p>
			</div>

			
				 <!-- .meta -->

				
				<!-- .post-pagination -->

			
				

			
		

					

		</article></div></div>]]>
            </description>
            <link>https://mkaz.blog/code/on-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304566</guid>
            <pubDate>Fri, 04 Dec 2020 16:51:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to prevent modules from growing unmaintainable]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25304474">thread link</a>) | @_elergy_
<br/>
December 4, 2020 | https://evgenii.info/reckless-reuse | <a href="https://web.archive.org/web/*/https://evgenii.info/reckless-reuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://evgenii.info/content/images/size/w300/2020/11/wayne-robinson-O-TM2E-7cn4-unsplash--1-.jpg 300w,
                            https://evgenii.info/content/images/size/w600/2020/11/wayne-robinson-O-TM2E-7cn4-unsplash--1-.jpg 600w,
                            https://evgenii.info/content/images/size/w1000/2020/11/wayne-robinson-O-TM2E-7cn4-unsplash--1-.jpg 1000w,
                            https://evgenii.info/content/images/size/w2000/2020/11/wayne-robinson-O-TM2E-7cn4-unsplash--1-.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://evgenii.info/content/images/size/w2000/2020/11/wayne-robinson-O-TM2E-7cn4-unsplash--1-.jpg" alt="Reckless Reuse: How Modules Grow Big">
            </figure>

            <section>
                <div>
                    <p>Does your project have an enormous module called <em>something-manager</em> or <em>something-controller</em> that grew beyond any possible limits and became completely unmaintainable? How many do you have?</p><p>Usually, <a href="https://en.wikipedia.org/wiki/Code_smell">code smells</a> are the results of deliberate actions:</p><blockquote>We had a tight deadline and agreed to ship overcomplicated and unreadable code. We never prioritized writing tests, and now we little confidence in changing old logic.</blockquote><p>Large modules are a different story. They do not happen overnight, and I'm yet to see a person suggesting to put a ton of random methods to one pile and call this pile <em>GlobalManager </em>or <em>Utils</em>. It is never a choice, but rather the result of many good intentions: small enough to attract attention, but still dangerous to cause harm.</p><h2 id="evolution-of-one-module">Evolution of one module</h2><p>Let me start from an oversimplified fictional example.<br>Imagine that you work on a piece of software for college students and their teachers.<br>First of all, we need to allow teachers to see all assignments that a particular student has. Let's write a module for it!</p><p>This is what we need to do:</p><ul><li>Check that a user is a teacher and hence has necessary permissions</li><li>Get all we need from the database</li><li>Format the result and show it to the user</li></ul><figure><img src="https://evgenii.info/content/images/2020/11/image-5.png" alt=""><figcaption>One public <code>showAssignments</code> and some private functions</figcaption></figure><p>A work in progress, but nothing terrible is happening so far.</p><p>Time goes, and teachers request another feature: they also want to see which <em>books</em> their students have. Sounds like a weird request, but we can live with that.</p><p>For this feature, we can reuse several functions we wrote before (<em>getRole, formatResult</em> and <em>showContent</em>). All we need to do is to add this small change:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-6.png" alt=""><figcaption>A small change</figcaption></figure><p>At some point later, we get another request, but it is not about teachers anymore — students also want to keep track of their books to know what they need to return to the library.<br>This one is even easier to implement:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-7.png" alt=""><figcaption>Another small change</figcaption></figure><p>tiny function that reuses previously implemented capabilities — easy choice, easy code review.<br>But now students have one more request: they need more information about their books, i.e. the date when it should be returned. Something that <em>formatResult </em>cannot do. Luckily, we are programmers and can make them happy:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-8.png" alt=""><figcaption>Splitting <em>formatResult</em> and <em>formatBooksForStudents</em></figcaption></figure><p>Job is done!<br>The last piece of news for this example: teachers decided that the strange case about seeing students' books was redundant, and there is no real situation for which it would be needed.<br>Who does not like removing code, huh?</p><figure><img src="https://evgenii.info/content/images/2020/11/image-9.png" alt=""><figcaption>Another simple change</figcaption></figure><h2 id="boiling-frogs">Boiling frogs</h2><p>We must be proud because we maximized code reuse and iteratively supported new use cases with minimal code changes. All commits were concise and sensible, at least at first glance.</p><p>However, it is worth checking the module once again — not only the changes but full content:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-10.png" alt=""><figcaption>Two unrelated use-cases in one file</figcaption></figure><p>Two different types of content for two different types of users. Not much overlap.</p><p>What's much worse is that this module is prone to unlimited expansion. Every small change related to students, teachers, books or assignments is justifiable until at some time we wake up with a module so big that the only thing left to do is teach it how to make coffee. Fortunately, <a href="https://en.wikipedia.org/wiki/Boiling_frog">the water is already boiling</a>.</p><h2 id="why-it-happens">Why it happens</h2><p>Several factors are contributing to this process.</p><p>We, developers, love reusing code. It saves us a lot of effort — can you imagine the world where we had to write everything from scratch?</p><p>At the same time, we do not like changing old code. Sometimes it is hard, sometimes it is unsafe, sometimes it just makes us think.</p><blockquote>Code that we can reuse — investment.<br>Code that we have to change — legacy.</blockquote><p>That leads to the thinking pattern which I call <em>Reckless Reuse</em>:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-11.png" alt=""><figcaption>Reckless Reuse</figcaption></figure><h2 id="how-to-avoid">How to avoid</h2><p>To prevent <em>Reckless Reuse</em>, keep in mind the original purpose of a module you intend to change:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-12.png" alt=""><figcaption>Refactor before reuse</figcaption></figure><p>In our example, we could move the functions <em>getRole</em> and <em>showContent</em> outside of the module that serves teachers, so we still can reuse them from other places of the application without having to grow the teachers' module.</p><p>Unfortunately, it is never enough to just do it yourself – all collaborators should adopt the same practices. There are a couple of tricks that can help you with that:</p><ul><li>Invest in proper naming. <br>Make sure the names of your files reflect their purposes. If naming is hard, it may mean that you try to call something that should never exist.</li><li>Write comments about the goals of your modules. <br>If the name alone is not explanatory, consider adding a paragraph or two about which set of problems a given module is supposed to solve.</li></ul><p>It should help you to notice when modules start doing something beyond their initial scope. Even when a change is small and reasonable, it will raise questions when somebody adds the method <em>trackAttendance</em> into the module <em>book-data-provider.</em></p><hr><p>As always, you can <a href="https://evgenii.info/reckless-reuse#subscribe">subscribe to Resilient Systems</a> and receive new articles by email if you haven't done it yet. <br>You also can <a href="https://twitter.com/_elergy_">find me on Twitter</a> or somewhere else – I am always happy to chat :-) </p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Resilient Systems</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://evgenii.info/reckless-reuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304474</guid>
            <pubDate>Fri, 04 Dec 2020 16:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 Lüftung leicht gemacht]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25304440">thread link</a>) | @based2
<br/>
December 4, 2020 | https://www.mpg.de/15962809/corona-lueftung-aerosole-luft | <a href="https://web.archive.org/web/*/https://www.mpg.de/15962809/corona-lueftung-aerosole-luft">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <p>Eine einfache Anlage kann 90 Prozent potenziell Coronavirus-haltiger Aerosole aus der Raumluft entfernen</p>
  

  

  <p>Die Luft in Klassenzimmern und anderen Räumen von infektiösen Aerosolen zu befreien, kann künftig deutlich einfacher werden. Forschende des Max-Planck-Instituts für Chemie haben eine Lüftungsanlage konstruiert, die sich mit Materialien aus dem Baumarkt nachbauen lässt. Das rheinland-pfälzische Bildungsministerium prüft nun den Einsatz auch an anderen Schulen. Die Integrierte Gesamtschule Mainz-Bretzenheim testet die Anlage bereits. Ein Baubericht für den Nachbau ist online zu finden.</p>
  
  
<figure data-description="<div class=&quot;details expanded&quot; style=&quot;display: inline;&quot;>
<p>Ein einfaches Abluftsystem für Klassenräume: Thomas Klimach montiert eine der Hauben, die die warme Luft der Schüler über einem Tisch sammeln und in das Abluftrohr leiten soll. Im Hintergrund der Schulleiter der IGS Mainz-Bretzenheim, Roland Wollowski.</p>
</div>" data-picture="base64;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">
      
    

    
    <figcaption>
        <div>
          <p>Ein einfaches Abluftsystem für Klassenräume: Thomas Klimach montiert eine der Hauben, die die warme Luft der Schüler über einem Tisch sammeln und in das Abluftrohr leiten soll. Im Hintergrund der Schulleiter der IGS Mainz-Bretzenheim, Roland Wollowski.</p>
        </div>
        <p>
          © Elena Klimach
        </p>
    </figcaption>
</figure>



<p>Schulen stehen während der Covid-19-Pandemie vor dem Problem, wie sie während des Unterrichts richtig lüften können. Forscherinnen und Forscher des Max-Planck-Instituts für Chemie haben nun gemeinsam mit der Integrierten Gesamtschule Mainz-Bretzenheim erfolgreich eine Abluftanlage getestet, die in Laborversuchen rund 90 Prozent künstlich erzeugter Aerosolpartikel aus den Klassenzimmern entfernen kann. Das Prinzip: Jeder Mensch produziert warme Luft, die nach oben steigt. Richtet man diesen Luftstrom nach draußen, nimmt er Aerosolpartikel und mögliche Coronaviren mit sich.</p>
<p>Die Konstruktion ist denkbar einfach und wurde mit Materialien aus dem Baumarkt im Wert von etwa 200 Euro umgesetzt: Über jedem Tisch hängt in etwa zwei Meter Höhe ein breiter Schirm, der mit einem Rohr verbunden ist. Alle Rohre führen in ein zentrales Rohr, das wiederum durch ein gekipptes Fenster nach draußen führt. Ein Ventilator am Ende des Rohrs sorgt dafür, dass die Luft aktiv nach außen transportiert wird.</p>
<h2>Aerosole werden über jedem Tisch eingesammelt</h2>
<p>Erdacht hat sich die Konstruktion Frank Helleis, dessen Frau Lehrerin in Mainz ist. Über sie kam auch der Kontakt zur Schule zustande. „Es hörte sich so einfach und überzeugend an, dass wir uns sofort entschlossen haben, mitzumachen,“ sagt Roland Wollowski, Schulleiter an der Integrierten Gesamtschule Mainz-Bretzenheim. So entstand schnell ein Prototyp, den Helleis mit seinen Kollegen bereits im Sommer in einem Klassenraum mit Dummies montierte und seit dieser Zeit testet. Als Dummies nutzte er Kartons mit Wärme- und Aerosolquellen. Derzeit läuft die Validierung der Anlage im realen Schulbetrieb.</p>
<p>„Unsere Messungen haben gezeigt, dass das Abluftsystem mit den Hauben unter Laborbedingungen über 90 Prozent der Aerosole kontinuierlich entfernt“, sagt Helleis. Zwar funktioniert die simple Anlage auch ohne die trichterförmigen Hauben über den einzelnen Tischen, diese sammeln die Aerosole dort aber gezielt ein. Dies hat der Physiker mit Aerosolspektrometern und künstlich erzeugten Aerosolen nachgewiesen. Ausgehend von den bisherigen Messergebnissen ist zu erwarten, dass auch unter realen Unterrichtsbedingungen ein wesentlicher Anteil der potentiell infektiösen Aerosolpartikel aus der Atemluft entfernt werden kann.</p>


<figure data-description="Schematische Darstellung der Abluftanlage in einem Klassenraum." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Schematische Darstellung der Abluftanlage in einem Klassenraum.
        </p>
        <p>
          © Andrea Koppenborg
        </p>
    </figcaption>
</figure>



<p>Helleis hat die Anlage bewusst für den praktischen Einsatz konzipiert: Wegen der geringen Material- und Betriebskosten könnte sie eine clevere Alternative zum Stoßlüften und zu teuren Filteranlagen bieten. Da zudem die Anforderungen an den Raum niedrig sind – es braucht nur eine Steckdose, und ein kippbares Fenster oder Oberlicht –, ist das modulare System beispielsweise auch in Turnhallen geeignet. Ob die Anlage auch an anderen Schulen in Rheinland-Pfalz eingesetzt werden kann, diskutieren derzeit Mitarbeiter des Bildungsministeriums Rheinland-Pfalz, die die Funktionalität der Konstruktion bereits vor Ort geprüft haben. „Auch unseren Schulträger, die Stadt Mainz, konnten wir für das Projekt begeistern und erfahren hierbei konstruktive Unterstützung“, berichtet Wollowski. „Wir freuen uns sehr über die hervorragende Zusammenarbeit mit dem MPIC und haben uns vorgenommen, in den kommenden Wochen möglichst viele Unterrichtsräume mit der tatkräftigen Hilfe der gesamten Schulgemeinschaft auszustatten. Darüber hinaus werden auch die lüftungsbedingten Energieverluste verringert, was wiederum dem Klima zu Gute kommt.“</p>
<h2>Anleitung und Kontaktformular auf der Webseite des Instituts</h2>
<p>Derzeit braucht es noch etwas handwerkliches Geschick, da die Einzelteile individuell zusammengebaut und montiert werden müssen. Dazu erstellten Helleis und Kollegen einen Baubericht, um die Hürde für den Nachbau möglichst niedrig zu halten. Die Mainzer Forscher stehen zudem in Kontakt mit Unternehmen, die einzelne Formteile für die Konstruktion fertigen könnten – das würde den Nachbau noch leichter machen.</p>
<p>Frank Helleis, bekannt als kreativer Tüftler am Mainzer Max-Planck-Institut, ist überzeugt, dass die Anlage auch nach der Pandemie im Einsatz bleiben wird. „Unser System löst auch das lange bekannte CO<sub>2</sub>-Problem in Klassenräumen. Denn sie befördert nicht nur Aerosole nach draußen, sondern reduziert auch die CO<sub>2</sub>-Anreicherung, so dass sich die Schüler besser auf den Unterricht konzentrieren können.“</p>
<p>Professionelle Lüftungssysteme sind dazu selbstverständlich auch in der Lage und sollten bei geeigneter Konstruktion und Dimensionierung noch bessere Eigenschaften aufweisen, stehen bisher aber in vielen Schulen nicht zur Verfügung. In der aktuellen Pandemie und Ausnahmesituation bemühen sich zahlreiche wissenschaftliche Einrichtungen aktiv um einen Beitrag zur Lösung anstehender Probleme. Die hier vorgestellte behelfsmäßige Lüftungsanlage entstand aus einem konkreten Bedarf an kurzfristig und einfach umsetzbaren Maßnahmen zur Verringerung von C0vid-19-Infektionsrisiken durch Aerosolübertragung in Schulen vor Ort. Aufgrund des großen Anklangs und zunehmender Nachfrage wurde der Baubericht veröffentlicht. Auch darin wird darauf hingewiesen, dass die Dokumentation einen vorläufigen Charakter hat und nach Bedarf weiter ergänzt wird.</p>
<p>Die Pressemeldung wurde am 29.11.2020 ergänzt, um potentielle Fehlinterpretationen und Missverständnisse zu vermeiden.</p>

  
</div></div>]]>
            </description>
            <link>https://www.mpg.de/15962809/corona-lueftung-aerosole-luft</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304440</guid>
            <pubDate>Fri, 04 Dec 2020 16:44:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Containers the Hard Way]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25304432">thread link</a>) | @mariuz
<br/>
December 4, 2020 | https://containers.gitbook.io/build-containers-the-hard-way/ | <a href="https://web.archive.org/web/*/https://containers.gitbook.io/build-containers-the-hard-way/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="4" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="4c1a50da3ba940ada3bc0294feabead9"><span><span data-key="a30e54d92f29405dbf3cf422e043be19"><span data-offset-key="a30e54d92f29405dbf3cf422e043be19:0"><em data-slate-leaf="true">Like </em></span></span><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way" target="_blank" rel="noopener noreferrer" data-key="c0e87534af8140bb9e5e1c899db6996d"><span data-key="fb5a63333f6d4866b95ab938f82fc76c"><span data-offset-key="fb5a63333f6d4866b95ab938f82fc76c:0"><em data-slate-leaf="true">Kubernetes the Hard Way</em></span></span></a><span data-key="27c84bbb5d284c6b90ec924176793285"><span data-offset-key="27c84bbb5d284c6b90ec924176793285:0"><em data-slate-leaf="true">, but for building containers.</em></span></span></span></p><p data-key="c8264be32c274fcf8c7986683c966d06"><span><span data-key="5d177422828845a697a54ac0bbebe521"><span data-offset-key="5d177422828845a697a54ac0bbebe521:0">This guide is geared towards anyone interested in learning the low-level details regarding how to build containers. This guide is </span><span data-offset-key="5d177422828845a697a54ac0bbebe521:1"><em data-slate-leaf="true">not</em></span><span data-offset-key="5d177422828845a697a54ac0bbebe521:2"> intended for those who wish to learn to build container images with high-level tools like Docker.</span></span></span></p><p data-key="8b2455fd19dc4e44b0b2e3261d1ae16f"><span><span data-key="d5c955e7f41e4b4cad4f2ad1ebb04335"><span data-offset-key="d5c955e7f41e4b4cad4f2ad1ebb04335:0">At the end of this guide, you should understand the internals of a container image, how to construct a container image, and how to push a container image to a Docker container registry piece-by-piece.</span></span></span></p><p data-key="944fc26c538349aab3b2828ce6127d96"><span><span data-key="1567e25f784441b699777d818a8f153c"><span data-offset-key="1567e25f784441b699777d818a8f153c:0">A </span><span data-offset-key="1567e25f784441b699777d818a8f153c:1"><em data-slate-leaf="true">container</em></span><span data-offset-key="1567e25f784441b699777d818a8f153c:2"> is a way of executing processes with isolation provided by 3 Linux technologies - </span><span data-offset-key="1567e25f784441b699777d818a8f153c:3"><code spellcheck="false" data-slate-leaf="true">chroot</code></span><span data-offset-key="1567e25f784441b699777d818a8f153c:4">, </span><span data-offset-key="1567e25f784441b699777d818a8f153c:5"><code spellcheck="false" data-slate-leaf="true">namespaces</code></span><span data-offset-key="1567e25f784441b699777d818a8f153c:6">, and </span><span data-offset-key="1567e25f784441b699777d818a8f153c:7"><code spellcheck="false" data-slate-leaf="true">cgroups</code></span><span data-offset-key="1567e25f784441b699777d818a8f153c:8">.</span></span></span></p><p data-key="02b403fec6384defadab6f3b59965201"><span><span data-key="7ce5d753bf5d491c833ae98d08776c2c"><span data-offset-key="7ce5d753bf5d491c833ae98d08776c2c:0"><code spellcheck="false" data-slate-leaf="true">chroot</code></span><span data-offset-key="7ce5d753bf5d491c833ae98d08776c2c:1"> changes the file system root (</span><span data-offset-key="7ce5d753bf5d491c833ae98d08776c2c:2"><code spellcheck="false" data-slate-leaf="true">/</code></span><span data-offset-key="7ce5d753bf5d491c833ae98d08776c2c:3">) that a process can see. This allows a process to use any directory as if it were a file system root instead of the actual file system root.</span></span></span></p><p data-key="294030eb0efd4f0c9ccb13ef3b8c2fc9"><span><span data-key="b396f96778fa493f9cd05016e844db9c"><span data-offset-key="b396f96778fa493f9cd05016e844db9c:0"><code spellcheck="false" data-slate-leaf="true">namespaces</code></span><span data-offset-key="b396f96778fa493f9cd05016e844db9c:1"> group resources together (like network and process IDs) so that only processes within a namespace can see the resources of that namespace.</span></span></span></p><p data-key="4ff65cc2a90549f9af2ce4d00dc44e81"><span><span data-key="6b429a643cbe4fdb98134285f7fa405f"><span data-offset-key="6b429a643cbe4fdb98134285f7fa405f:0"><code spellcheck="false" data-slate-leaf="true">cgroups</code></span><span data-offset-key="6b429a643cbe4fdb98134285f7fa405f:1"> set CPU and memory limits for processes.</span></span></span></p><p data-key="badf2a91f39b485699ed8b76f38b101d"><span><span data-key="d6c2359d27774adfb4dd3d213002bb38"><span data-offset-key="d6c2359d27774adfb4dd3d213002bb38:0">The combination of these allows processes to run in isolation from other processes both on the file system level and on the resource utilization level. Processes inside a container do not see other processes in other containers. Rather, they only see their own view of the system that is not cluttered other processes.</span></span></span></p><p data-key="b333c340dd9d4800bf37c6cf658dbd04"><span><span data-key="5ef55ec05d554f908a65f2804a3080ef"><span data-offset-key="5ef55ec05d554f908a65f2804a3080ef:0">A </span><span data-offset-key="5ef55ec05d554f908a65f2804a3080ef:1"><em data-slate-leaf="true">container image</em></span><span data-offset-key="5ef55ec05d554f908a65f2804a3080ef:2"> a way to package up an application so that it can run as a </span><span data-offset-key="5ef55ec05d554f908a65f2804a3080ef:3"><em data-slate-leaf="true">container</em></span><span data-offset-key="5ef55ec05d554f908a65f2804a3080ef:4">. This package includes the application and any run-time dependencies and is simply a directory of files along with metadata about how to run the container.</span></span></span></p><div data-key="7154786c928646d39c6de1710153caec"><p data-key="d1f773aae1ce47f595687942f3df500c"><span><span data-key="990e38914a5740a2837739345ccba7e4"><span data-offset-key="990e38914a5740a2837739345ccba7e4:0">A </span><span data-offset-key="990e38914a5740a2837739345ccba7e4:1"><em data-slate-leaf="true">container image</em></span><span data-offset-key="990e38914a5740a2837739345ccba7e4:2"> is simply a directory of files along with metadata about how to run the container.</span></span></span></p></div><p data-key="ee7070dee67b46bb9dbefe3018d9429b"><span><span data-key="3abe0b7924a54d0eac17b437dd39ddce"><span data-offset-key="3abe0b7924a54d0eac17b437dd39ddce:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://ericchiang.github.io/post/containers-from-scratch/" target="_blank" rel="noopener noreferrer" data-key="7de8566aa3524b479cfeb3c95469bfb4"><span data-key="8b802a60f7bd4dfc9d36307f63fc6b81"><span data-offset-key="8b802a60f7bd4dfc9d36307f63fc6b81:0">Containers from Scratch</span></span></a><span data-key="4d387a9e4e7b42f1b01b0971f9f01ee8"><span data-offset-key="4d387a9e4e7b42f1b01b0971f9f01ee8:0"> is a good article explaining how to run your own containers using simple Linux commands.</span></span></span></p><h2 id="build-a-container-image-with-docker" data-key="860523a8ffc24941ae74bc2ceddc2b74"><p><span><span data-key="e7b97da3d865439f9f9a44ab7331d2a8"><span data-offset-key="e7b97da3d865439f9f9a44ab7331d2a8:0">Build a container image with Docker</span></span></span><a href="#build-a-container-image-with-docker" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="f378356efc254cf1bba3a4b7837fa77f"><span><span data-key="abf7d3e3b2994a289ac0a5761d08109e"><span data-offset-key="abf7d3e3b2994a289ac0a5761d08109e:0">Docker is the most popular tool for working with container images. It has built-in support for building and running containers. Docker defines its own scripting language for defining how to build a container image.</span></span></span></p><p data-key="01b47dc9cb234ab5ab6c28f395818c67"><span><span data-key="69bcc68ba1d34b5989963fd402381855"><span data-offset-key="69bcc68ba1d34b5989963fd402381855:0">For example, this Dockerfile builds a simple Docker image that serves any static files in the current working directory as webpages:</span></span></span></p><div><pre data-key="6b288e3d0b704f0d8cfc620054b8da6e" spellcheck="false"><p><span>Dockerfile</span></p><p><span data-key="c88a2510cd7940c4a17e170e0a330f86"><span data-offset-key="c88a2510cd7940c4a17e170e0a330f86:0">FROM python</span></span></p><p><span data-key="90e0bf6093f547ce94a82dac1d928401"><span data-offset-key="90e0bf6093f547ce94a82dac1d928401:0">COPY . /public</span></span></p><p><span data-key="c2eaccc13a434853bc2a429ce2a524d2"><span data-offset-key="c2eaccc13a434853bc2a429ce2a524d2:0">WORKDIR /public</span></span></p><p><span data-key="83c6bb1d00b54fc5aa5192c9af5def43"><span data-offset-key="83c6bb1d00b54fc5aa5192c9af5def43:0">ENTRYPOINT ["python3", "-m", "http.server"]</span></span></p></pre></div><p data-key="ffe0c014b24944789dc776bbb45d06e6"><span><span data-key="7b3f73c5849f48f6bed862ff83203c4d"><span data-offset-key="7b3f73c5849f48f6bed862ff83203c4d:0">To build the Docker image, save the </span><span data-offset-key="7b3f73c5849f48f6bed862ff83203c4d:1"><code spellcheck="false" data-slate-leaf="true">Dockerfile</code></span><span data-offset-key="7b3f73c5849f48f6bed862ff83203c4d:2"> in the current working directory and tell Docker build it:</span></span></span></p><div><pre data-key="00bad55cabba4a4e896b1f5b8c81f501" spellcheck="false"><p><span data-key="9b11f81a54954760b33f045747e0c4c3"><span data-offset-key="9b11f81a54954760b33f045747e0c4c3:0">Sending build context to Docker daemon  3.072kB</span></span></p><p><span data-key="f2df24816a2b4079b0c06162aac08772"><span data-offset-key="f2df24816a2b4079b0c06162aac08772:0">Step 1/4 : FROM python</span></span></p><p><span data-key="f3f6a532352c46ea9c7cd2106b0e4cad"><span data-offset-key="f3f6a532352c46ea9c7cd2106b0e4cad:0"> ---&gt; 338b34a7555c</span></span></p><p><span data-key="d8fab5e3a94d49caaa05d7f28fabab7a"><span data-offset-key="d8fab5e3a94d49caaa05d7f28fabab7a:0">Step 2/4 : COPY . /public</span></span></p><p><span data-key="4fddbf700db84e38bc1f1424a69684b8"><span data-offset-key="4fddbf700db84e38bc1f1424a69684b8:0"> ---&gt; edcd805ec657</span></span></p><p><span data-key="3d19a2d23b784157bd55dca019f21e76"><span data-offset-key="3d19a2d23b784157bd55dca019f21e76:0">Step 3/4 : WORKDIR /public</span></span></p><p><span data-key="2dc8d6c5470141c1a79c900e803d823b"><span data-offset-key="2dc8d6c5470141c1a79c900e803d823b:0"> ---&gt; Running in cd5f924a79fe</span></span></p><p><span data-key="1999300a0017437dbda72ba96c52077d"><span data-offset-key="1999300a0017437dbda72ba96c52077d:0">Removing intermediate container cd5f924a79fe</span></span></p><p><span data-key="3e49cead45da4f8e9e10c5b1217ab440"><span data-offset-key="3e49cead45da4f8e9e10c5b1217ab440:0"> ---&gt; bba7b6ca42fc</span></span></p><p><span data-key="91eb612d0cd349cc8ba17e1e9989ca8d"><span data-offset-key="91eb612d0cd349cc8ba17e1e9989ca8d:0">Step 4/4 : ENTRYPOINT ["python", "-m", "http.server"]</span></span></p><p><span data-key="b7a14d4116b9472ca36c16e66a15bcf0"><span data-offset-key="b7a14d4116b9472ca36c16e66a15bcf0:0"> ---&gt; Running in 4198534c1c9c</span></span></p><p><span data-key="e9b694989c464879a3cb062e3ada4b3b"><span data-offset-key="e9b694989c464879a3cb062e3ada4b3b:0">Removing intermediate container 4198534c1c9c</span></span></p><p><span data-key="25b9c9d7b33c4ae1999ab4c8edf401ad"><span data-offset-key="25b9c9d7b33c4ae1999ab4c8edf401ad:0"> ---&gt; 5550043a7340</span></span></p><p><span data-key="e76c56c84bda49848f6acfda014f0344"><span data-offset-key="e76c56c84bda49848f6acfda014f0344:0">Successfully built 5550043a7340</span></span></p></pre></div><p data-key="5249432fb25647b9b1966b7965df6cd6"><span><span data-key="9b0ecd0054814e5e8a140d1b7b91f682"><span data-offset-key="9b0ecd0054814e5e8a140d1b7b91f682:0">The logs of the </span><span data-offset-key="9b0ecd0054814e5e8a140d1b7b91f682:1"><code spellcheck="false" data-slate-leaf="true">docker build</code></span><span data-offset-key="9b0ecd0054814e5e8a140d1b7b91f682:2"> command clearly show how Docker executes the build based on our Dockerfile.</span></span></span></p><p data-key="fc526d35f7854211a630aed838419923"><span><span data-key="a38393e544174ed591b08a58f52cfd71"><span data-offset-key="a38393e544174ed591b08a58f52cfd71:0">The </span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:1"><code spellcheck="false" data-slate-leaf="true">docker</code></span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:2"> CLI is the client that you use to send commands and data to the </span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:3"><em data-slate-leaf="true">Docker daemon</em></span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:4">. The Docker daemon stores and runs containers. First, the </span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:5"><code spellcheck="false" data-slate-leaf="true">docker build .</code></span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:6"> command tells Docker to use the local current working directory (</span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:7"><code spellcheck="false" data-slate-leaf="true">.</code></span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:8">) as the </span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:9"><em data-slate-leaf="true">Docker context</em></span><span data-offset-key="a38393e544174ed591b08a58f52cfd71:10">. The Docker context is sent to the Docker daemon.</span></span></span></p><p data-key="88a8ee347a99494b9cdd8eb47402a4e5"><span><span data-key="66ec68bf7ceb485890d8ef733de56955"><span data-offset-key="66ec68bf7ceb485890d8ef733de56955:0">The commands in the Dockerfile are then run in the given order. The Docker daemon runs a container to execute each command and generates a new container image at the end of each step.</span></span></span></p><p data-key="95131666efa74c6398528cde0f6450c4"><span><span data-key="887f8da6d6a34e07a7e8422e1768aa21"><span data-offset-key="887f8da6d6a34e07a7e8422e1768aa21:0">The </span><span data-offset-key="887f8da6d6a34e07a7e8422e1768aa21:1"><code spellcheck="false" data-slate-leaf="true">FROM python</code></span><span data-offset-key="887f8da6d6a34e07a7e8422e1768aa21:2"> step tells Docker to build the new container starting with the </span></span><a href="https://hub.docker.com/_/python" target="_blank" rel="noopener noreferrer" data-key="0c44fc3769ce4223ae37bcb42d0fc955"><span data-key="5199e2e536a8413a909adb24e9fbc2ad"><span data-offset-key="5199e2e536a8413a909adb24e9fbc2ad:0">python container image from Docker Hub</span></span></a><span data-key="65a60da5a64d46e9a1855347d52d9a61"><span data-offset-key="65a60da5a64d46e9a1855347d52d9a61:0"> as the base.</span></span></span></p><p data-key="6ec7ce3cb379450ba083d40dd3f8396e"><span><span data-key="6e0f646d69484af095bf87ddebaeef34"><span data-offset-key="6e0f646d69484af095bf87ddebaeef34:0"><code spellcheck="false" data-slate-leaf="true">COPY . /public</code></span><span data-offset-key="6e0f646d69484af095bf87ddebaeef34:1"> copies all the files in the Docker context into the </span><span data-offset-key="6e0f646d69484af095bf87ddebaeef34:2"><code spellcheck="false" data-slate-leaf="true">/public</code></span><span data-offset-key="6e0f646d69484af095bf87ddebaeef34:3"> directory on our container image. This includes all the files in our local current working directory that was sent over to the daemon as the Docker context.</span></span></span></p><p data-key="6c707557584a465792f4fdf1160c4d2f"><span><span data-key="5442ac82949b457893843eaa76517967"><span data-offset-key="5442ac82949b457893843eaa76517967:0"><code spellcheck="false" data-slate-leaf="true">WORKDIR /public</code></span><span data-offset-key="5442ac82949b457893843eaa76517967:1"> sets the working directory for the container image we are building, so that when the container image is run, the current working directory for the process is </span><span data-offset-key="5442ac82949b457893843eaa76517967:2"><code spellcheck="false" data-slate-leaf="true">/public</code></span><span data-offset-key="5442ac82949b457893843eaa76517967:3">.</span></span></span></p><div data-key="5d0b724ce4064b7a8d29b6bfc1fa82d6"><p data-key="622278335c9345bc929d1c9634ed3d75"><span><span data-key="64bf12fca13e4c22902d1abcf99caf3a"><span data-offset-key="64bf12fca13e4c22902d1abcf99caf3a:0">Note that the container that was created by the </span><span data-offset-key="64bf12fca13e4c22902d1abcf99caf3a:1"><code spellcheck="false" data-slate-leaf="true">WORKDIR</code></span><span data-offset-key="64bf12fca13e4c22902d1abcf99caf3a:2"> command is removed. Steps that do not change the container file system only modify the </span><span data-offset-key="64bf12fca13e4c22902d1abcf99caf3a:3"><em data-slate-leaf="true">container configuration</em></span><span data-offset-key="64bf12fca13e4c22902d1abcf99caf3a:4"> and are removed. The container configuration is metadata that describes how to run the container entrypoint process.</span></span></span></p></div><p data-key="3419edd297004d0aa4b18b5cf24a7936"><span><span data-key="dd445a0d29b44cee8e252b4910d78f8f"><span data-offset-key="dd445a0d29b44cee8e252b4910d78f8f:0"><code spellcheck="false" data-slate-leaf="true">ENTRYPOINT ...</code></span><span data-offset-key="dd445a0d29b44cee8e252b4910d78f8f:1"> sets the command to run when the container is run, which, in this case, runs an HTTP server that serves all the files in </span><span data-offset-key="dd445a0d29b44cee8e252b4910d78f8f:2"><code spellcheck="false" data-slate-leaf="true">/public</code></span><span data-offset-key="dd445a0d29b44cee8e252b4910d78f8f:3">. So, for example, if we had HTML files in our local current working directory, those would be served by this container.</span></span></span></p><p data-key="1901737d67794d5f870a9edcffb3c0ac"><span><span data-key="734808545e0e4ad3aac3e680cbb7c107"><span data-offset-key="734808545e0e4ad3aac3e680cbb7c107:0">The final image built has ID </span><span data-offset-key="734808545e0e4ad3aac3e680cbb7c107:1"><code spellcheck="false" data-slate-leaf="true">5550043a7340</code></span><span data-offset-key="734808545e0e4ad3aac3e680cbb7c107:2">, which can be used in subsequent </span><span data-offset-key="734808545e0e4ad3aac3e680cbb7c107:3"><code spellcheck="false" data-slate-leaf="true">docker</code></span><span data-offset-key="734808545e0e4ad3aac3e680cbb7c107:4"> commands.</span></span></span></p><p data-key="66669c6490764c918b2c174dec8f8fec"><span><span data-key="126f8175fc9a472bb7e487ae07083ea8"><span data-offset-key="126f8175fc9a472bb7e487ae07083ea8:0">This container can then be run with:</span></span></span></p><div><pre data-key="edb53a1a6aeb4d269e2e4e5cfcd5523f" spellcheck="false"><p><span data-key="a4d677c15ab44016b1f76fbe3368a83b"><span data-offset-key="a4d677c15ab44016b1f76fbe3368a83b:0">$ docker run -p 8000:8000 5550043a7340</span></span></p></pre></div><p data-key="64b00c0eece348f59222941c6f5c1dd7"><span><span data-key="10e82be1cf5e4c73ade57b9a422ec89f"><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:0">This runs the container and forwards the port to </span><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:1"><code spellcheck="false" data-slate-leaf="true">localhost:8000</code></span><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:2">. If you had, say, an </span><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:3"><code spellcheck="false" data-slate-leaf="true">index.html</code></span><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:4"> in your local current working directory, going to </span><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:5"><code spellcheck="false" data-slate-leaf="true">localhost:8000</code></span><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:6"> would serve the contents of </span><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:7"><code spellcheck="false" data-slate-leaf="true">index.html</code></span><span data-offset-key="10e82be1cf5e4c73ade57b9a422ec89f:8">.</span></span></span></p><div data-key="14febaa008a4405aa517faf2cbbb3b21"><p data-key="89fbf733a2d04c96afc912f70380f2e9"><span><span data-key="508316bb5927435db34c25d2801f4259"><span data-offset-key="508316bb5927435db34c25d2801f4259:0">Another common Dockerfile instruction is </span><span data-offset-key="508316bb5927435db34c25d2801f4259:1"><code spellcheck="false" data-slate-leaf="true">RUN &lt;command&gt;</code></span><span data-offset-key="508316bb5927435db34c25d2801f4259:2">, which executes the </span><span data-offset-key="508316bb5927435db34c25d2801f4259:3"><code spellcheck="false" data-slate-leaf="true">&lt;command&gt;</code></span><span data-offset-key="508316bb5927435db34c25d2801f4259:4"> using whichever shell is present in the container, creating a new container following the result of executing that command.</span></span></span></p></div><h2 id="advanced-docker-builds" data-key="da68494b506646daad13dcd405e4d2fc"><p><span><span data-key="c5521a86ef89402e8c366d2bd63ed421"><span data-offset-key="c5521a86ef89402e8c366d2bd63ed421:0">Advanced Docker Builds</span></span></span><a href="#advanced-docker-builds" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="57f9f3622f7441e3b210bfdcad52553b"><span><span data-key="f1c79d2797e942f6a99be7d085f22694"><span data-offset-key="f1c79d2797e942f6a99be7d085f22694:0">Docker has its own caching mechanism that helps Dockerfile-based builds run faster. Essentially, Docker caches the container image generated after each Dockerfile step. If it determines that a step has not changed, it will use the container image cached for that step rather than run that step again. However, if a step changes, it will invalidate the cache for that step and all steps afterwards. The way the caching mechanism works in Docker merits some tips for writing a more efficient Dockerfile.</span></span></span></p><h3 id="frequently-changing-steps-go-last" data-key="273921e87ed04a289842cbaba6691c33"><p><span><span data-key="2889b450acbd4fbdb61a4f842104e839"><span data-offset-key="2889b450acbd4fbdb61a4f842104e839:0">Frequently changing steps go last</span></span></span><a href="#frequently-changing-steps-go-last" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3><p data-key="be5b34900a2b4a76a1dd6fb57f5e7000"><span><span data-key="c7e855aded924756b88a217f95bb0e1d"><span data-offset-key="c7e855aded924756b88a217f95bb0e1d:0">Dockerfile builds can take quite a while, especially with heavy steps that download dependencies or compile your application. </span></span></span></p><div data-key="ae59d8f6da774114a334330237026a5f"><p data-key="bf25c1b419154d77bdc475f18f15d8c8"><span><span data-key="e70985518f2f452bba7916b56ce331f9"><span data-offset-key="e70985518f2f452bba7916b56ce331f9:0">Docker caches the result of each instruction in a Dockerfile, but once a step's cached result is invalidated, the results of all subsequent steps are invalidated as well.</span></span></span></p></div><p data-key="a0da7c9799c84403b54a21f6f5d0968a"><span><span data-key="bfd04ed4732e420d9543a2b9647089a1"><span data-offset-key="bfd04ed4732e420d9543a2b9647089a1:0">Since any step that changes invalidates steps afterwards, better Dockerfiles tend to place more frequently-changing steps last. Heavy steps that do not change much tend to be front-loaded so that subsequent builds can just use the cached result.</span></span></span></p><h3 id="keep-the-number-of-steps-minimal" data-key="95e086e37e0f4b728c6060a7d8fe42c6"><p><span><span data-key="e9c4b992dfa24f5b82973b454be5817f"><span data-offset-key="e9c4b992dfa24f5b82973b454be5817f:0"><strong data-slate-leaf="true">Keep the number of steps minimal</strong></span></span></span><a href="#keep-the-number-of-steps-minimal" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3><p data-key="98e805efe33b4a5487b7e58f2b53fb9a"><span><span data-key="149ec6eed82f4c9899ae62973ac39df8"><span data-offset-key="149ec6eed82f4c9899ae62973ac39df8:0">Since each step generates a separate cached container image, steps should be kept minimal to reduce the number of layers (each cached step has its own overhead). For example, a group of </span><span data-offset-key="149ec6eed82f4c9899ae62973ac39df8:1"><code spellcheck="false" data-slate-leaf="true">RUN</code></span><span data-offset-key="149ec6eed82f4c9899ae62973ac39df8:2">s can usually be combined:</span></span></span></p><p data-key="3fd8040f1e0d41f3a66158c296eab310"><span><span data-key="3c472b73a2064347bd4bb6962d5bbb6f"><span data-offset-key="3c472b73a2064347bd4bb6962d5bbb6f:0"><em data-slate-leaf="true">Bad:</em></span></span></span></p><div><pre data-key="f281574f1c184fbc8ed97c4a7798432c" spellcheck="false"><p><span data-key="b7a322f1c2924f03b4877fca44cf5cbd"><span data-offset-key="b7a322f1c2924f03b4877fca44cf5cbd:0">RUN mkdir mydirectory</span></span></p><p><span data-key="3dcc9d9a790e4dd4a2261ce7f8785256"><span data-offset-key="3dcc9d9a790e4dd4a2261ce7f8785256:0">RUN touch mydirectory/myexecutable</span></span></p><p><span data-key="3bbe1f9e048a459f8f97490bf8bc279e"><span data-offset-key="3bbe1f9e048a459f8f97490bf8bc279e:0">RUN chmod +x mydirectory/myexecutable</span></span></p></pre></div><p data-key="98b13f9e3a1d40ad8486d916415bac1d"><span><span data-key="8334cdab9f5f4f8d8319c4090026a6c3"><span data-offset-key="8334cdab9f5f4f8d8319c4090026a6c3:0"><em data-slate-leaf="true">Better:</em></span></span></span></p><div><pre data-key="e5eb63783f6b4f7586cf811380896925" spellcheck="false"><p><span data-key="b72937d0d1be40cd9aad22b27d0a15b7"><span data-offset-key="b72937d0d1be40cd9aad22b27d0a15b7:0">RUN mkdir mydirectory &amp;&amp; \</span></span></p><p><span data-key="deb6d4f4f1114464a5fdb0b87939712d"><span data-offset-key="deb6d4f4f1114464a5fdb0b87939712d:0">    touch mydirectory/myexecutable &amp;&amp; \</span></span></p><p><span data-key="f8e8bb7729064efca7aabfe2a97c73d7"><span data-offset-key="f8e8bb7729064efca7aabfe2a97c73d7:0">    chmod +x mydirectory/myexecutable</span></span></p></pre></div><p data-key="25c2b3f6614c468080ac6adf761ec35a"><span><span data-key="f696918b48b44a838bc089763d28c604"><span data-offset-key="f696918b48b44a838bc089763d28c604:0">However, frequently-changing steps should not be combined with infrequently-changing heavy steps - rather, an efficient Dockerfile should try to separate these as much as possible to avoid running infrequently-changing steps.</span></span></span></p><div data-key="09d03636b2844ef58a167137c32ed86e"><p data-key="cc856bf4d18a4be38c3486cf736d2b00"><span><span data-key="b227f958ffaa4eabab3fc844375c0273"><span data-offset-key="b227f958ffaa4eabab3fc844375c0273:0">One important caveat to note is how Docker caches RUN instructions. Even though RUN commands may produce different results each time, Docker only invalidates the cache for a RUN instruction if the command itself changes. This may produce unexpected results if you intended a RUN instruction to not use a cached version.</span></span></span></p></div><h3 id="use-multi-stage-builds-for-more-flexibility-than-just-a-linear-dockerfile-build" data-key="2c48fe03fe234651bddd442b23ea57cb"><p><span><span data-key="a99d72263ce44fd6a76ca1dd5dabf576"><span data-offset-key="a99d72263ce44fd6a76ca1dd5dabf576:0"><strong data-slate-leaf="true">Use multi-stage builds for more flexibility than just a linear Dockerfile build</strong></span></span></span><a href="#use-multi-stage-builds-for-more-flexibility-than-just-a-linear-dockerfile-build" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h3><p data-key="868278c11ae141bcaaa55f78b05882b4"><span><span data-key="da60d11161bf47e3980f5a4faf2c0e9f"><span data-offset-key="da60d11161bf47e3980f5a4faf2c0e9f:0">Single-stage Dockerfile builds (builds with a single </span><span data-offset-key="da60d11161bf47e3980f5a4faf2c0e9f:1"><code spellcheck="false" data-slate-leaf="true">FROM</code></span><span data-offset-key="da60d11161bf47e3980f5a4faf2c0e9f:2"> instruction) builds a single image starting with the </span><span data-offset-key="da60d11161bf47e3980f5a4faf2c0e9f:3"><code spellcheck="false" data-slate-leaf="true">FROM</code></span><span data-offset-key="da60d11161bf47e3980f5a4faf2c0e9f:4"> image as the base. These builds run in a purely linear format from start to finish and the results of all intermediate steps become part of the resulting image. However, since a container image should only contain what is necessary to run your application, much of the files from intermediate steps are junk that is not needed at run-time.</span></span></span></p><p data-key="10e6f22004b74715958268a46b80f6d7"><span><span data-key="9ac4ec0367d2443cbab0b2cb28ae3390"><span data-offset-key="9ac4ec0367d2443cbab0b2cb28ae3390:0">For example, for a Java (Maven) project, you may need the JDK to build the JAR, but only the JRE to run the JAR. The multi-stage Dockerfile build would look something like:</span></span></span></p><div><pre data-key="50c7f6f0943840a7b4fb247edeb0b2e4" spellcheck="false"><p><span data-key="04d5fbc7ca974f45a07206cd3eb8ebce"><span data-offset-key="04d5fbc7ca974f45a07206cd3eb8ebce:0">FROM maven AS builder</span></span></p><p><span data-key="2d77c73065c043b4bcd423ab0c9faa45"><span data-offset-key="2d77c73065c043b4bcd423ab0c9faa45:0">COPY . .</span></span></p><p><span data-key="7a14913d9b6b47e1a64294e44f806d16"><span data-offset-key="7a14913d9b6b47e1a64294e44f806d16:0">RUN mvn package</span></span></p><p><span data-key="bd9ede62d2d940578f5aee88420b07fe"><span data-offset-key="bd9ede62d2d940578f5aee88420b07fe:0"><span data-slate-zero-width="n">​</span></span></span></p><p><span data-key="6352ec58073e4addabaa843526532c4c"><span data-offset-key="6352ec58073e4addabaa843526532c4c:0">FROM openjdk:8-jre-alpine</span></span></p><p><span data-key="f25ce24f09804d35b792f9524126efa1"><span data-offset-key="f25ce24f09804d35b792f9524126efa1:0">COPY --from=builder target/my-app-*.jar app.jar</span></span></p><p><span data-key="ad7fc92e23ae4c8a8e103d5571549050"><span data-offset-key="ad7fc92e23ae4c8a8e103d5571549050:0">ENTRYPOINT ["java", "-jar", "app.jar"]</span></span></p></pre></div><ol data-key="d6a9bc9c0869451b82024a0651a18479"><li><p data-key="67d3a0509c1b41c1b96cdac4b0ee18a3"><span><span data-key="431e67003bac4dc38df3d3f8363a70b4"><span data-offset-key="431e67003bac4dc38df3d3f8363a70b4:0">This multi-stage build starts with the Docker Hub </span><span data-offset-key="431e67003bac4dc38df3d3f8363a70b4:1"><code spellcheck="false" data-slate-leaf="true">maven</code></span><span data-offset-key="431e67003bac4dc38df3d3f8363a70b4:2"> image as the base for an intermediate image called </span><span data-offset-key="431e67003bac4dc38df3d3f8363a70b4:3"><code spellcheck="false" data-slate-leaf="true">builder</code></span><span data-offset-key="431e67003bac4dc38df3d3f8363a70b4:4">.</span></span></span></p></li><li><p data-key="d611ce24065c4eea9dfe32bfcaa841d1"><span><span data-key="1663b3009d3340e8953aa323efdf461e"><span data-offset-key="1663b3009d3340e8953aa323efdf461e:0">It then copies all the project files into the </span><span data-offset-key="1663b3009d3340e8953aa323efdf461e:1"><code spellcheck="false" data-slate-leaf="true">builder</code></span><span data-offset-key="1663b3009d3340e8953aa323efdf461e:2"> image.</span></span></span></p></li><li><p data-key="5e4fb40925c54692ace9d2b33c72c92f"><span><span data-key="5b6b48b31f2649bdb1e94d544f13c5ff"><span data-offset-key="5b6b48b31f2649bdb1e94d544f13c5ff:0"><code spellcheck="false" data-slate-leaf="true">mvn package</code></span><span data-offset-key="5b6b48b31f2649bdb1e94d544f13c5ff:1"> builds the fatjar for the project.</span></span></span></p></li><li><p data-key="06cb2c52b8774b6383bddcc4d9724972"><span><span data-key="4db771ea26824ad982041ba4f805274a"><span data-offset-key="4db771ea26824ad982041ba4f805274a:0">The main stage starts with the Docker Hub </span><span data-offset-key="4db771ea26824ad982041ba4f805274a:1"><code spellcheck="false" data-slate-leaf="true">openjdk</code></span><span data-offset-key="4db771ea26824ad982041ba4f805274a:2"> image that just has the JRE.</span></span></span></p></li><li><p data-key="67ff8857b7c14800ae54fd786fa52432"><span><span data-key="8cb1486a7cf34959a78a4c9f7d6fa8c8"><span data-offset-key="8cb1486a7cf34959a78a4c9f7d6fa8c8:0">It copies just the fatjar from the </span><span data-offset-key="8cb1486a7cf34959a78a4c9f7d6fa8c8:1"><code spellcheck="false" data-slate-leaf="true">builder</code></span><span data-offset-key="8cb1486a7cf34959a78a4c9f7d6fa8c8:2"> image.</span></span></span></p></li><li><p data-key="f197cd59b76e4f858d18748d15323e4d"><span><span data-key="e453b0f13dbf4629bf7f5c734fd44885"><span data-offset-key="e453b0f13dbf4629bf7f5c734fd44885:0">And sets the container to run that fatjar when executed.</span></span></span></p></li></ol><p data-key="6c96d91532484d7d83c7ff44e743cb5f"><span><span data-key="31f810f19a98479692dae490ded9c80c"><span data-offset-key="31f810f19a98479692dae490ded9c80c:0">The resulting container contains only what is necessary to run the application - the application JAR and the Java run-time.</span></span></span></p><div data-key="71431d717d694943967615335a1c65ba"><p data-key="0c62e190a9f0488fbd466c8d5c0f4ff2"><span><span data-key="dcd9e63e533842f5be7208a72fe33842"><span data-offset-key="dcd9e63e533842f5be7208a72fe33842:0">You can also leverage multi-stage builds to take advantage of better caching, since you're not limited by a purely linear cache invalidation.</span></span></span></p></div><p data-key="86cf71ead7b04d878467bf9dbca219fd"><span><span data-key="046c644a0eef41aaae05edab33382216"><span data-offset-key="046c644a0eef41aaae05edab33382216:0">Container images can be built in a few formats. Different runtimes may support different formats. The most common formats are the </span><span data-offset-key="046c644a0eef41aaae05edab33382216:1"><em data-slate-leaf="true">Docker image format</em></span><span data-offset-key="046c644a0eef41aaae05edab33382216:2"> and </span></span><a href="https://github.com/opencontainers/image-spec" target="_blank" rel="noopener noreferrer" data-key="032e07cfff04463e8d7c7999cd2ea8e6"><span data-key="2048812a586a418ca98d6503af1c828e"><span data-offset-key="2048812a586a418ca98d6503af1c828e:0"><em data-slate-leaf="true">Open Container Initiative (OCI) format</em></span></span></a><span data-key="ed1a1690bf6e4488b598a250e23ec677"><span data-offset-key="ed1a1690bf6e4488b598a250e23ec677:0">.</span></span></span></p><p data-key="b154615495a242cf8b27a27a0bfc90c9"><span><span data-key="def643ae315b49c69b5ca78a5d090606"><span data-offset-key="def643ae315b49c69b5ca78a5d090606:0">Some common runtimes include:</span></span></span></p><ul data-key="75d2c253a53f4a8ca97bd90e33a0efc9"><li><p data-key="c3871998157547eca7072a1e452ce59a"><span><span data-key="5e28f47858dd4990945339cda017fbf9"><span data-offset-key="5e28f47858dd4990945339cda017fbf9:0">Docker itself, which uses </span></span><a href="https://github.com/containerd/containerd" target="_blank" rel="noopener noreferrer" data-key="2c3580be4fb7420ba63bf48811a0add1"><span data-key="4ab172a1b5bd46d0a54818a5dc502c4b"><span data-offset-key="4ab172a1b5bd46d0a54818a5dc502c4b:0">containerd</span></span></a><span data-key="0cfd96ba43364a6cac7ea8fb003b05e5"><span data-offset-key="0cfd96ba43364a6cac7ea8fb003b05e5:0"> underneath</span></span></span></p></li><li><p data-key="fd9dd6cc5ecb4987bd27adbd32da8d12"><span><span data-key="d50f459fb0214166bfcf4396ab339079"><span data-offset-key="d50f459fb0214166bfcf4396ab339079:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://github.com/rkt/rkt" target="_blank" rel="noopener noreferrer" data-key="f0e3b2a821494eb2868b53e43ea99818"><span data-key="a26283aab0874a1994cb4921860570e7"><span data-offset-key="a26283aab0874a1994cb4921860570e7:0">rkt</span></span></a><span data-key="f1dde19885a548b3a98c1e9cb3c12068"><span data-offset-key="f1dde19885a548b3a98c1e9cb3c12068:0">, which supports Docker and OCI images, and can be used in Kubernetes</span></span></span></p></li><li><div data-key="74e3f794565740d08cd1f528ffa469b4"><p data-key="0086e80dd81b4ae5872729c0bf61a154"><span><span data-key="3c5133a652194a52abf147fbb6e9d510"><span data-offset-key="3c5133a652194a52abf147fbb6e9d510:0">Kubernetes also provides the </span></span><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md" target="_blank" rel="noopener noreferrer" data-key="d563182838d040f5bf911ae3a316a0de"><span data-key="c48061aa2b544a7095b7b4f0eb86208e"><span data-offset-key="c48061aa2b544a7095b7b4f0eb86208e:0">container runtime interface (CRI)</span></span></a><span data-key="3508797972d4440cbdbde9736b0c6cca"><span data-offset-key="3508797972d4440cbdbde9736b0c6cca:0">, which allows for different runtime implementations to be used, including </span></span><a href="https://github.com/kubernetes-sigs/cri-o" target="_blank" rel="noopener noreferrer" data-key="32dd202ca20e412ab42b593439d32ce4"><span data-key="e4aab2621b594d0dba297a9bcbae2ca0"><span data-offset-key="e4aab2621b594d0dba297a9bcbae2ca0:0">cri-o</span></span></a><span data-key="a515e9d4db954ea786a9676ac2fb72f4"><span data-offset-key="a515e9d4db954ea786a9676ac2fb72f4:0">, the </span></span><a href="https://github.com/kubernetes-sigs/cri-o" target="_blank" rel="noopener noreferrer" data-key="2d8c0411c4794767aeab0d2797068c8d"><span data-key="5494e6999be348a3ac44cef455c2527d"><span data-offset-key="5494e6999be348a3ac44cef455c2527d:0">cri plugin for containerd</span></span></a><span data-key="28c0d5b76cac4e3d8105f201d8df5a27"><span data-offset-key="28c0d5b76cac4e3d8105f201d8df5a27:0">, and </span></span><a href="https://github.com/kubernetes-incubator/rktlet" target="_blank" rel="noopener noreferrer" data-key="21a27270a7fd4bbcbfa7f5b9c8caa306"><span data-key="66a6d0c787be4d9cad3d1def2554ae5a"><span data-offset-key="66a6d0c787be4d9cad3d1def2554ae5a:0">rktlet</span></span></a><span data-key="80ba4232ce0c45f9935a199f4f39a0f9"><span data-offset-key="80ba4232ce0c45f9935a199f4f39a0f9:0"><span data-slate-zero-width="z">​</span></span></span></span></p></div></li></ul><p data-key="3f514c166dd1433ea2896e3209aa79f1"><span><span data-key="6ffe0e648ac54d2ab7241f86e215a332"><span data-offset-key="6ffe0e648ac54d2ab7241f86e215a332:0">There are also many tools for building images besides Docker:</span></span></span></p><ul data-key="b92bfd307161480ab3ecd8440f227cf4"><li><p data-key="4dd15e6ef266475d83ebc17a181f38ab"><span><span data-key="905d09bf303e4a768d2a5a9ccc2a8c9c"><span data-offset-key="905d09bf303e4a768d2a5a9ccc2a8c9c:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://github.com/GoogleContainerTools/jib" target="_blank" rel="noopener noreferrer" data-key="9bce7d94de994b2688ef98485d8171e4"><span data-key="dc47dc38a2e548ad883ce3d0f17e355a"><span data-offset-key="dc47dc38a2e548ad883ce3d0f17e355a:0">Jib</span></span></a><span data-key="0c5c1e6899954993b45a72a44b73b069"><span data-offset-key="0c5c1e6899954993b45a72a44b73b069:0"> builds Docker and OCI images in Java</span></span></span></p></li><li><p data-key="ff3e4141dc7a47d0b5c7ec7448135bb9"><span><span data-key="b3be5031cb38418b89a8e8fc05ce8990"><span data-offset-key="b3be5031cb38418b89a8e8fc05ce8990:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://github.com/GoogleContainerTools/kaniko" target="_blank" rel="noopener noreferrer" data-key="356939d5a5754aa195ee5ff4c39e836a"><span data-key="2b1d126317d6446c9d9740b20e49a263"><span data-offset-key="2b1d126317d6446c9d9740b20e49a263:0">Kaniko</span></span></a><span data-key="78f596cda9194116a2dea01c62d77014"><span data-offset-key="78f596cda9194116a2dea01c62d77014:0"> builds images in Kubernetes using a Dockerfile</span></span></span></p></li><li><p data-key="c3c71c3f955c44148f3addd752125857"><span><span data-key="f2aa46d0543243e58cc554d4570fd27d"><span data-offset-key="f2aa46d0543243e58cc554d4570fd27d:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://github.com/bazelbuild/rules_docker" target="_blank" rel="noopener noreferrer" data-key="6f4b570d5a4345349cf70869082db365"><span data-key="0cfcace4988444bca18992d8f3f25d37"><span data-offset-key="0cfcace4988444bca18992d8f3f25d37:0">rules_docker</span></span></a><span data-key="5c22f5d2ae1a4068a0a9469b978b064b"><span data-offset-key="5c22f5d2ae1a4068a0a9469b978b064b:0"> provides Bazel rules for building images</span></span></span></p></li><li><p data-key="6b2e51e7505b483ba7ff59bb060784aa"><span><span data-key="75b115eee98c4cceb1f250d8973935ef"><span data-offset-key="75b115eee98c4cceb1f250d8973935ef:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://github.com/moby/buildkit" target="_blank" rel="noopener noreferrer" data-key="7d6f0e62f5ce44f191d77319a0a2878d"><span data-key="3aa25723e52b41c8b1da48a5eb2b5698"><span data-offset-key="3aa25723e52b41c8b1da48a5eb2b5698:0">BuildKit</span></span></a><span data-key="04806d82440f41379f53605496ebb867"><span data-offset-key="04806d82440f41379f53605496ebb867:0"> is the underlying engine used by Docker to build images</span></span></span></p></li><li><p data-key="208b3d3e48c3403cb5dae317e3b63234"><span><span data-key="da000319544245728c266149a55927bf"><span data-offset-key="da000319544245728c266149a55927bf:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://github.com/genuinetools/img" target="_blank" rel="noopener noreferrer" data-key="f35d814cc7ba490295508b2b4e9b5fd9"><span data-key="2b4c90bc2d394131bb94cceb6deca68a"><span data-offset-key="2b4c90bc2d394131bb94cceb6deca68a:0">img</span></span></a><span data-key="95240b4c06d8429aa2bd17883012f342"><span data-offset-key="95240b4c06d8429aa2bd17883012f342:0"> provides a standalone frontend for BuildKit</span></span></span></p></li><li><div data-key="88a0c4813fa94c72ace25b36e6744c9e"><p data-key="581cf423b717460e8caf55cd22774f70"><span><span data-key="c94ba38c0410416bbde1eb8587053490"><span data-offset-key="c94ba38c0410416bbde1eb8587053490:0"><span data-slate-zero-width="z">​</span></span></span><a href="https://github.com/containers/buildah" target="_blank" rel="noopener noreferrer" data-key="28725c107f6d400a863f018afb8205bb"><span data-key="99865274535349fc91bde5fca726d9bf"><span data-offset-key="99865274535349fc91bde5fca726d9bf:0">buildah</span></span></a><span data-key="a9b0b5be91cc4013a38bdaf6b182342a"><span data-offset-key="a9b0b5be91cc4013a38bdaf6b182342a:0"> builds OCI images</span></span></span></p></div></li></ul><h2 id="layers" data-key="870a76d4d26f472ebf9eaa0c9448468e"><p><span><span data-key="b30ba438114a47c78c563ab33d469c0e"><span data-offset-key="b30ba438114a47c78c563ab33d469c0e:0">Layers</span></span></span><a href="#layers" contenteditable="false"><span><svg preserveAspectRatio="xMidYMid meet" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" stroke="currentColor"><g><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></g></svg></span></a></p></h2><p data-key="834eaebb729b4a3788800411b29acb65"><span><span data-key="cc55c9c0607c4e1daa1b1e0cd0ceece9"><span data-offset-key="cc55c9c0607c4e1daa1b1e0cd0ceece9:0">As mentioned, a container image is simply a directory of files (along with metadata). In the image format, this directory of files is split up into layers that are compatible with </span></span><a href="https://en.wikipedia.org/wiki/Union_mount" target="_blank" rel="noopener noreferrer" data-key="0046e32f3f6143c1b8d5e4616bd1d70b"><span data-key="c206d6619e444ecd9b6a6a0a65623667"><span data-offset-key="c206d6619e444ecd9b6a6a0a65623667:0">union mounting</span></span></a><span data-key="af38f71fa2b041159f83d99db3833946"><span data-offset-key="af38f71fa2b041159f83d99db3833946:0">.</span></span></span></p><p data-key="05f9e54a91864b3c8dafa355ad44c52a"><span><span data-key="c0d708e3450c4d2fa5e812107aaebf3c"><span data-offset-key="c0d708e3450c4d2fa5e812107aaebf3c:0">Layers are independent, but are composed together with a defined order in the image format. The order of the layers in the image matters for files that exist in multiple layers. The contents of a file that appears in a later layer replaces the contents of the same file …</span></span></span></p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://containers.gitbook.io/build-containers-the-hard-way/">https://containers.gitbook.io/build-containers-the-hard-way/</a></em></p>]]>
            </description>
            <link>https://containers.gitbook.io/build-containers-the-hard-way/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304432</guid>
            <pubDate>Fri, 04 Dec 2020 16:44:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vegetarians are our main target market]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25304237">thread link</a>) | @shafyy
<br/>
December 4, 2020 | https://blog.yeticheese.com/vegetarians-are-our-main-target-customers/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/vegetarians-are-our-main-target-customers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>We make plant-based cheese, so why would our main target market be vegetarians, who of course do eat cheese from animals?</p><p>The reason is the same why we started Yeti in the first place: We want to make animals obsolete in food production. Therefore, we need to convince people who otherwise do eat dairy-based cheese to eat Yeti instead. For every gram of plant-based cheese they eat instead of dairy-based, we come a small step closer to our mission.</p><p>Of course, that doesn't mean we're unhappy when vegans eat our products - not at all. However, it's much easier to convince people who are already on a plant-based diet to buy our cheese. In order to convince vegetarians or omnivores, our cheese needs to be as good as or better than cheese from animals. Therefore, clearly focusing efforts on non-vegans sets a high bar for our cheeses and forces us to make excellent products. This is the goal we set for ourselves.</p><p>Now, you might ask yourself why we target vegetarians specifically and not also omnivores. The reason is a practical one: We believe that it's easier to reach and convince vegetarians, because we've been vegetarians for a long time before going 100% plant-based and cheese was what was holding us back. If you talk to any vegetarian, I'd wager that a vast majority of them will tell you that cheese is the reason that they're not vegan.</p><p>Or, put differently, we know that a big problem in the vegatarian market is the absence of great plant-based cheese. A clearly defined problem makes it easier for us to reach our customers effectively and get them try our cheese.</p>
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/vegetarians-are-our-main-target-customers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304237</guid>
            <pubDate>Fri, 04 Dec 2020 16:32:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can You Remain Unbiased When Reading the News?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25304216">thread link</a>) | @amoorthy
<br/>
December 4, 2020 | https://blog.thefactual.com/can-you-remain-unbiased-when-reading-the-news | <a href="https://web.archive.org/web/*/https://blog.thefactual.com/can-you-remain-unbiased-when-reading-the-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>


<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Just before the 2020 general election, a friend on Twitter paraphrased a famous quote that says, “if you don't stand for something, you'll fall for anything.” And later, another friend on Whatsapp said, “you have to take a side. Not taking a side, in the face of what we are seeing, is actually taking sides.” The <a href="https://fivethirtyeight.com/features/biden-may-have-won-the-election-but-the-deep-partisan-divide-in-america-remains/"><span>narrow margin</span></a> of victory suggests such anecdotes may be shared by a large portion of the population.&nbsp;</p>
<!--more--><p>Many journalists also <a href="https://www.nybooks.com/daily/2020/11/01/americas-press-and-the-asymmetric-war-for-truth/"><span>struggle</span></a> with the issue of taking sides. Most were trained to write in an objective manner and keep their opinions out of the story. But this style has lately been accused of having the “<a href="https://www.economist.com/books-and-arts/2020/07/16/how-objectivity-in-journalism-became-a-matter-of-opinion"><span>view from nowhere</span></a>” (i.e., reporting information on “both sides” and possibly implying false equivalence when one side is obviously right). Perhaps it is no surprise that the <a href="https://www.rand.org/news/press/2019/05/14.html"><span>level of opinionatedness</span></a> has gone up in journalism.</p>
<p>For individuals in the general public who want to be well informed, what are the implications of increasing partisanship in our communities and rising opinionatedness in the news? Should we remain loyal to our favorite news sources or challenge our perspectives by reading information we disagree with?&nbsp;</p>
<p>At a fundamental level, can you remain unbiased when reading the news?</p>
<p><img src="https://www.visualcapitalist.com/wp-content/uploads/2019/09/us-political-polarization-crop.gif" alt="Political Polarization"></p>
<p>Source: <a href="https://www.pewresearch.org/politics/2017/10/05/the-partisan-divide-on-political-values-grows-even-wider/" rel="noopener">Pew Research</a></p>
<h3>Multiple perspectives crucial to combating partisanship</h3>
<p>While many readers want unbiased news, a basic truth is that everyone is <a href="https://www.theguardian.com/science/2019/jan/12/psychology-of-group-reasoning-versus-individual"><span>subject to biases</span></a>. While some reporters and news sources claim these biases explicitly, others are less aware and may frame facts and arguments in a way they feel is truthful yet remains colored by their own experiences and beliefs.&nbsp;</p>
<p>Because of pervasive bias, a rising level of opinionatedness in journalism is not necessarily cause for alarm and reinforces a core precept of reading the news: that no single article or source will present all the facts and arguments for an issue. Hence the importance of reading multiple perspectives, ideally across the political spectrum.</p>
<p>Incidentally, this practice is more common in the history of news consumption than we think. In the days of print news, many households received multiple dailies, often representing different political viewpoints.&nbsp;</p>

<h3>False equivalence concerns may be overstated</h3>
<p>When reading multiple perspectives, we must challenge ourselves to think critically. Here are some questions to consider:</p>
<ul>
<li>What facts are presented and are any left out?</li>
<li>What’s the history of this issue and are there trends in the data presented?</li>
<li>What can we learn from other countries/locations that can inform our understanding?&nbsp;</li>
</ul>
<p>When provided with all of the facts and varying viewpoints, and some time to think things through, most readers are equipped to draw accurate conclusions. Veteran journalists such as <a href="https://twitter.com/mtaibbi/status/1329599947503767552?s=20"><span>Matt Taibbi</span></a> recommend empowering readers to be independent thinkers as a best practice. It also means that worries about false equivalency may be overstated because people can judge for themselves if they believe the evidence supporting one side even if the other side was presented in as much detail.</p>
<p>As an aside, this is how we conduct jury trials — we assume that a panel of average citizens, presented with the facts arguing for and against a conviction, will reach the <a href="https://theconversation.com/all-about-juries-why-do-we-actually-need-them-and-can-they-get-it-wrong-112703"><span>right conclusion</span></a> most of the time. So why not expect the same of our society when it comes to reading the news?&nbsp;</p>

<h3>Bias is OK, empathy is better</h3>
<p>Just as all writers are biased, so too are all readers. Reading the news doesn’t require us to put aside our biases or opinions. Rather, reading the news is a way to get the facts and arguments for and against an issue so that whatever opinions you hold are grounded in the facts.</p>
<p>Finally, by reading multiple perspectives, even if your opinions and biases don’t change, you may develop empathy for people who have viewpoints different than yours. A more empathetic society is something to strive for in a world that seems increasingly divided.</p></span>
</p>



<!-- Optional: Blog Author Bio Box -->
<div>

<div>
<h3>Written by <a href="https://blog.thefactual.com/author/arjun-moorthy">Arjun Moorthy</a></h3>
<p>Arjun Arjun is co-founder and CEO of The Factual. He's has always been passionate about news from when he was a paperboy in middle school through becoming Editor-in-chief of The Stanford Reporter. Outside of work Arjun slaves away for his children hoping they will be grateful one day.</p>

</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://blog.thefactual.com/can-you-remain-unbiased-when-reading-the-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304216</guid>
            <pubDate>Fri, 04 Dec 2020 16:31:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enabling Hardware Acceleration on AWS Firecracker]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25304208">thread link</a>) | @_ananos_
<br/>
December 4, 2020 | https://blog.cloudkernels.net/posts/vaccel_v2/ | <a href="https://web.archive.org/web/*/https://blog.cloudkernels.net/posts/vaccel_v2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>In our <a href="https://blog.cloudkernels.net/posts/vaccel/">previous post</a> we spoke about the potential solutions for
deploying serverless offerings with hardware acceleration support. With the
increasing adoption of the serverless and FaaS paradigms, providers will need
to offer some form of hardware acceleration semantics.</p>

<p>For some time now, Amazon has <a href="https://github.com/firecracker-microvm/firecracker/issues/1179">identifed</a> this as a “compelling use
case” for their AWS Firecracker hypervisor which powers the Amazon Lambda
service. What is more, they identify traditional techniques for GPU support in
VMs such as GPU passthrough comes with limitations and significantly increases
the attack surface of the hypervisor.</p>

<p>As an alternative to passing through the accelerator device inside the guest,
paravirtual interfaces can expose hardware acceleration capabilities inside
the VM with minimal overhead and offering a simple user interface for
offloading code to the host for acceleration.</p>

<p>In fact, such interfaces already exist. <code>virtio-crypto</code> is an example, where
the guest VM uses a simple crypto API while the actual computation is
offloaded, through the paravirtual driver, to the host.</p>

<p>We believe that the same paradigm can be applied to any kind of computation
that can benefit from acceleration. Whether that is crypto operations, Machine
Learning or linear algebra operators, the workflow from the point of view of
the developer these days is the same; You will use a framework such as
cryptodev, Jetson Inference or the BLAS library, to write your applications and
you will not deal with the low-level complexities of the actual accelerator.
Moreover, that workflow should not be different whether your application runs
on baremetal or inside a VM.</p>

<p>In the rest of this post we present  <em>vAccel</em>, an acceleration framework that
enables <strong>portable</strong> and <strong>hardware agnostic</strong> acceleration for cloud
and edge applications.</p>

<h2 id="vaccel-design">vAccel design</h2>

<p>In simple terms, vAccel is an accleration API. It offers support for a set of
operators that commonly use hardware acceleration to increase performance,
such as machine learning and linear algebra operators.</p>

<p>The API is implemented by <em>VaccelRT</em> a thin and efficient runtime system that links
against the user application and is responsible for dispatching operations to
the relevant hardware accelerators. The interaction with the hardware itself is
mediated by plugins which implement the API for the specific hardware
accelerator.</p>

<p>This design is driven by our requirements for high degree of portability, an
application that consumes the vAccel API can run without modification or even
re-compilation to any platform for which there is suitable back-end plugin.</p>

<p>In fact, this opens up the way to enable the vAccel API inside a VM guest. The missing
bits are a virtio driver that implements the vAccel API and a backend plugin that
speaks with the virtio device. Once you have this components in place, you can
run your existing vAccel application inside a VM, just by using the virtio-plugin at
runtime.</p>

<p><img src="https://blog.cloudkernels.net/static/vaccel_v2/vaccelrt.png#center" alt="vAccel runtime" title="VaccelRT"></p>

<h2 id="vaccel-support-in-aws-firecracker">vAccel support in AWS Firecracker</h2>

<p>Once we implemented the frontend vAccel-virtio driver and virtio plugin for VaccelRT,
we need a hypervisor to test this on. We already showed, in the previous post some
initial vAccel results with QEMU as the target hypervisor. In this post, we will focus
on AWS Firecracker.</p>

<p>AWS Firecracker has been designed having in mind really small boot times and small attack
surface, which makes it a compelling choice for cloud and edge deployments.
Moreover, it powers up Lambda, Amazon’s serverless platform, which we see as a
paradigm for which vAccel’s hardware abstraction level is a perfect fit.</p>

<p>AWS Firecracker already implements virtio backend drivers for net, block and vsock. That
was good news for us, we have all the required virtio machinery. All we had to do, was
add a new device for vAccel and link the hypervisor with VaccelRT.</p>

<p>The last bit required us to create the necessary Rust bindings for calling C from AWS Firecracker
which is written in Rust. This was actually a good exercise for us, since we plan to anyway
provide bindings for the vAccel API in more high-level languages.</p>

<p>With all the components in place our stack looks like this:</p>

<p><img src="https://blog.cloudkernels.net/static/vaccel_v2/vaccele2e.png#center" alt="vAccel VM execution" title="vaccel-e2e"></p>

<p>The user application is consumes the vAccel API and links against VaccelRT. Inside the VM
the application uses the vAccel-virtio backend plugin. When a vAccel function is called, the
plugin will offload the request to <code>/dev/accel</code> device which is the interface of the virtio
driver. Next, the virtio driver will forward the request to the vAccel-enabled AWS Firecracker
instance which will the host-residing VaccelRT. Finally, in the host side, VaccelRT will use
one of the available plugins, to execute the operation on the hardware accelerator.</p>

<p>But how does this perform?</p>

<p>We first grabbed a copy of jetson-inference, a rich repo full of ML inference models and example applications based on TensorRT. We patched it to be able to run on an x86 GPU (we had an NVIDIA RTX 2060 SUPER handy), and we built the vAccelRT backend for an image classification operation. To compare vAccel on AWS firecracker we patched the example imagenet-console application to properly calculate the time of execution and to account for more than 1 iteration. The average execution time for image classification on two sets of Image files (set “*_0.jpg” and “*_1.jpg) are shown below:</p>

<p><img src="https://blog.cloudkernels.net/static/vaccel_v2/vaccel_bf_0.png#center" alt="vAccel VM execution" title="vaccel-bf-0"></p>

<p>The set above is sorted by the overhead percentage (GUEST vs HOST), while the set below, is sorted by Image size (in KB). One thing to note is that on all cases, the overhead of running an image classification operation in the guest compared to the host is less than 5%.</p>

<p><img src="https://blog.cloudkernels.net/static/vaccel_v2/vaccel_bf_1.png#center" alt="vAccel VM execution" title="vaccel-bf-1"></p>

<h2 id="putting-it-all-together">Putting it all together</h2>

<p>So, are you brave (or curious) enough to try it out yourself ? Full disclosure, vAccel is WiP, in terms of software development terms, the project should be considered in a pre-alpha phase. However, since we think the idea is useful, there might be someone willing to try it out. So here we go:</p>

<p>TL;DR
The easy way to try vAccel on AWS Firecracker is to run the docker container bundled with all necessary libraries/tools etc. The only prerequisite is [Docker][<a href="https://github.com/NVIDIA/nvidia-container-runtime">https://github.com/NVIDIA/nvidia-container-runtime</a>] &amp; nvidia-container-runtime[<a href="https://github.com/NVIDIA/nvidia-container-runtime">https://github.com/NVIDIA/nvidia-container-runtime</a>] installed.</p>

<p>To fire a VM up try running:</p>

<pre><code>docker run -e LD_LIBRARY_PATH=/usr/local/lib -e VACCEL_BACKENDS=/usr/local/lib/libvaccel-jetson.so --rm -it --gpus all --privileged nubificus/jetson-runtime
</code></pre>

<p>Now what the above command does is the following:
- sets up a couple of env vars to let the container know where to find the necessary libraries
- runs in a privileged mode so that /dev/kvm is available to the container instance (we need to boot a VM in there ;))
- provides access to the GPU from the container.</p>

<p>The entrypoint for the above container image (<code>nubificus/jetson-runtime</code>) simply starts a firecracker VM with a pre-built kernel &amp; rootfs.img, available <a href="https://github.com/nubificus/fc-x86-guest-build">here</a>. This repository contains the dockerfile from which these binaries have been produced. You can download ready-made binaries from the <a href="https://github.com/nubificus/fc-x86-guest-build/releases/latest">releases</a> page.</p>

<p>If (for any reason) you want to try out jetson-inference, without the AWS Firecracker VM boot, then just run the container with /bin/bash as an entrypoint, using the following command:</p>

<pre><code>docker run --network=host --rm -it --gpus all --privileged -v nubificus/jetson-runtime /bin/bash
</code></pre>

<h3 id="host">Host</h3>

<p>The current available version of vAccelRT supports the jetson-inference plugin. Adding a new plugin is as easy as linking with vAccelRT and writing the glue code in the plugin directory – more information should be available in the coming weeks!</p>

<p>To use this plugin, the Host machine should have an NVIDIA GPU (supporting CUDA), the relevant drivers installed, as well as <a href="https://github.com/dusty-nv/jetson-inference">jetson-inference</a> installed.</p>

<p>The next step is to build &amp; install <a href="https://github.com/cloudkernels/vaccelrt">vAccelRT</a>, the glue that ties everything together. You can build it from source, or just install the binaries available from the <a href="https://github.com/cloudkernels/vaccelrt/releases/latest">releases</a> page. Make sure you specify <code>LD_LIBRARY_PATH</code> to the folder where libvaccel.so is located, as well as to choose the necessary backend by setting <code>VACCEL_BACKENDS</code> to <code>libvaccel-jetson.so</code>.</p>

<pre><code>export LD_LIBRARY_PATH=/usr/local/lib
export VACCEL_BACKENDS=/usr/local/lib/libvaccel-jetson.so
</code></pre>

<h3 id="vm">VM</h3>

<p>To run a vAccel-enabled VM, we need four basic components:</p>

<ul>
<li>the AWS firecracker VMM (with the vAccel backend patch) <a href="https://github.com/cloudkernels/firecracker">github</a> <a href="https://github.com/cloudkernels/firecracker/releases/latest">releases</a></li>
<li>a firecracker guest Linux kernel supporting modules + the virtio-accel module <a href="https://github.com/nubificus/fc-x86-guest-build">github</a> <a href="https://github.com/nubificus/fc-x86-guest-build/releases/latest">releases</a></li>
<li>the vAccel runtime system (vAccelRT) for the Host and the guest <a href="https://github.com/cloudkernels/vaccelrt">github</a> <a href="https://github.com/cloudkernels/vaccelrt/releases/latest">releases</a></li>
</ul>

<p>To facilitate the process of packing all these software components, we include links to binaries built from the respective github repositories.</p>

<p>Grab, or build <code>vmlinux</code> &amp; the <code>rootfs.img</code> from the links above, and use a template config for firecracker like the following:</p>

<pre><code>{
	"boot-source": {
		"kernel_image_path": "vmlinux",
		"boot_args": "console=ttyS0 reboot=k panic=1 pci=off loglevel=0 root=/dev/vda quiet"
	},
	"drives": [
		{
			"drive_id": "rootfs",
			"path_on_host": "rootfs.img",
			"is_root_device": true,
			"is_read_only": false
		}
	],
	"network-interfaces": [
	{
		"iface_id": "eth0",
		"guest_mac": "AA:FC:00:00:00:01",
		"host_dev_name": "tap"
	}
	],
	"crypto": {
		"crypto_dev_id": "vaccel0",
		"host_crypto_dev": "/dev/vaccel0"
	},
	"machine-config": {
		"vcpu_count": 1,
		"mem_size_mib": 1024,
		"ht_enabled": false
	}
}
</code></pre>

<p>Make sure vmlinux, rootfs.img are in the same directory as the invocation of the firecracker command. Also, ensure that you have set <code>LD_LIBRARY_PATH</code> and <code>VACCEL_BACKENDS</code> correctly, and that you’ve downloaded the ML networks needed for inference. This step can be done using <a href="https://github.com/dusty-nv/jetson-inference/blob/master/tools/download-models.sh">this script</a>. Just get this script and run:</p>

<pre><code>./download-models.sh NO
</code></pre>

<p>and the models will be placed by default at <code>../data/networks</code>. Change the path in the script if you need to. For the AWS Firecracker backend to work, we need the models in the same directory as the invocation of the firecracker binary, in a folder called networks.</p>

<p>Now, we’re ready to fire up our VM:</p>

<pre><code>firecracker --api-sock …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cloudkernels.net/posts/vaccel_v2/">https://blog.cloudkernels.net/posts/vaccel_v2/</a></em></p>]]>
            </description>
            <link>https://blog.cloudkernels.net/posts/vaccel_v2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304208</guid>
            <pubDate>Fri, 04 Dec 2020 16:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting a 100% local app to the web]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25304100">thread link</a>) | @jlongster
<br/>
December 4, 2020 | https://actualbudget.com/blog/porting-local-app-web | <a href="https://web.archive.org/web/*/https://actualbudget.com/blog/porting-local-app-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>While researching <a href="https://actualbudget.com/blog/cursed-caching-curious">a curious caching bug</a>, I got inspired to take another look at how Actual stores data locally on the web. There's some history I need to explain. Years ago, Actual was only going to be a desktop app. That means <em>all</em> of your data is stored locally. No server.</p><p>Then I realized how important mobile is, and that most people don't want to worry about losing their data if they drop their computer in the ocean. A syncing engine was born, and desktop and mobile apps have happily synced their data ever since. A copy is kept on a server so users can login and easily view their data, and if they worry about privacy they can enable <a href="https://actualbudget.com/docs/overview/syncing-across-devices/#end-to-end-encryption">end-to-end encryption</a>.</p><p>In the last year I grew jealous of web apps. Look at how easily they can deploy… how quickly they can drop users right into the app. No install required. Here I am asking users to download an 80MB file just to run the app. That download absolutely kills conversion rates, and makes the login flow, support, a/b testing and <em>everything</em> much harder.</p><p>I love desktop apps because you have access to much better tech (like native sqlite3), the app is super fast (no network calls), and the user owns their data. However, I can't ignore that the benefits of the web <a href="https://www.kalzumeus.com/2009/09/05/desktop-aps-versus-web-apps/">dwarfs these advantages</a>.</p><p>I started thinking about a web version of Actual. After some hacking, <a href="https://app.actualbudget.com/">I got it working</a> without changing the architecture. That means all your data is still stored locally in the browser, and there are no network calls. It's a completely 100% "local" app in the browser [0].</p><p>I haven't marketed the web version much because it hasn't been tested enough, and it needs improvements like lazy loading code to make it load faster. The biggest thing I'm worried about is the data storage layer. Since <strong>all your data is local</strong>, if something goes wrong there you could potentially lose data. And we're really stressing the browser's persistant db by storing everything in it.</p><p>To be clear: <strong>we are not deprecating the desktop version</strong>. However in the future the web version will be the primary platform, with the choice to download the desktop version if desired.</p><p>The way it works a bit unusual. Here's a high-level overview:</p><ul><li>Actual uses <a href="https://www.sqlite.org/index.html">sqlite3</a>. This is a hard requirement. The app runs tons of complex SQL queries to aggregate financial data and it's so good at doing it. Queries are easy to express and run super fast.</li><li>On desktop and mobile, native sqlite3 is used. The web does not support sqlite3, however. To get around this, Actual uses a <a href="https://github.com/sql-js/sql.js">wasm version</a> of sqlite3 and creates an in-memory db.</li><li>The obvious problem is persistence. When you make changes, we need to persist them somewhere so when the user reloads they don't lose their data. Luckily we are using <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type#State-based_CRDTs">state-based CRDT's</a> and all updates come through as a list of "messages". If you are online, these messages get synced to our server so when you reload, all your data should sync up.</li><li>It's not ideal to require a big sync every time you open the app though. Also, if you are offline there shouldn't be any chance of losing data. To solve this, Actual persists each message into IndexedDB. When the app opens, it applies all messages from the local IndexedDB to get up-to-date.</li><li>It's <em>still</em> not ideal to require applying any messages on load. It won't scale - if you use the app for months you'll accumulate tens of thousands of messages. IndexedDB would grow indefinitely and loading the app would get slower. To solve this, when the stored messages crosses a threshold it flushes the entire sqlite3 db to IndexedDB and clears all the messages.</li><li>That means both a binary representation of the sqlite3 db and a list of messages is persisted in IndexedDB. On load, the app creates the in-memory sqlite3 db from the snapshot and applies any remaining messages from IDB.</li></ul><p>Turns out this is similar to how a <a href="https://sqlite.org/wal.html">write-ahead log</a> works.</p><p>I was worried about the reliability of IndexedDB. Reading the docs it seems like browsers might delete databases as needed, but in practice this doesn't seem to happen [1]. It's probably a much bigger problem on mobile where memory is scarce, but I don't mess with the mobile web (use a native app instead). I was also worried about hitting the limit of IDB storage, but as explained next that hasn't been a problem.</p><p>This technique started as an experiment, but it has worked surprisingly well. I have 5 years worth of data in Actual, and the size of the sqlite3 db is 9.7MB. The threshold of the messages table is around 50KB, so in total I'm storing ~10MB in IndexedDB for a user who's been around for 5 years. It's not even close to hitting the IndexedDB max storage limit, which these days is at least 500MB.</p><p>While it has worked so far, I want to be 100% confident in this approach. I've been digging deep into how each browser stores IndexedDB data on disk and discovered a couple improvements I can make. I was going to write about them in this post, but I ended up writing more about the overall approach. In the next post I'll dig deep into how IndexedDB works across browsers.</p><p>[0] While I didn't talk about it in this post, this also means that the entire app runs in the browser. The "backend" runs in a background worker thread and everything happens locally.</p><p>[1] If the local data does somehow get corrupted or deleted, it's not a <em>huge</em> deal. All changes are still sent off and stored on a server (which is how all other devices get synced). If something goes wrong, the app can re-download your data from the server. The only case where you'd lose data is if you were offline and lost your local data, which is to be expected.</p></div></div></div>]]>
            </description>
            <link>https://actualbudget.com/blog/porting-local-app-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304100</guid>
            <pubDate>Fri, 04 Dec 2020 16:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rich People Are Going to Colonize Mars Without You]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25304090">thread link</a>) | @marianicolae
<br/>
December 4, 2020 | https://www.listle.io/video/v016_pe3tCk | <a href="https://web.archive.org/web/*/https://www.listle.io/video/v016_pe3tCk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.listle.io/video/v016_pe3tCk</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304090</guid>
            <pubDate>Fri, 04 Dec 2020 16:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Try – The Philosophy of Charles Bukowski]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25304075">thread link</a>) | @marianicolae
<br/>
December 4, 2020 | https://listle.io/video/eMTDAHK-tkE | <a href="https://web.archive.org/web/*/https://listle.io/video/eMTDAHK-tkE">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://listle.io/video/eMTDAHK-tkE</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304075</guid>
            <pubDate>Fri, 04 Dec 2020 16:22:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Histools: Visualizing my browser history over time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25304032">thread link</a>) | @thesephist
<br/>
December 4, 2020 | https://dotink.co/posts/histools/ | <a href="https://web.archive.org/web/*/https://dotink.co/posts/histools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        

        <p>Today I made <a href="https://github.com/thesephist/histools"><strong>Histools</strong></a>, a small set of tools for visualizing browser history data from Apple’s Safari browser. It renders a heatmap of pages visited on Safari over time, alongside a searchable, sorted list of pages I’ve visited most often with mini-heatmaps for each URL.</p>
<p><img src="https://dotink.co/img/histools.png" alt="Histools screenshot"></p>
<p>Histools is built on my homebrew tech stack: Ink for the analysis script and server and the Torus UI library for the interactive visualizations. If you want to run Histools over your own Safari history file, you can find the how-to’s in the GitHub readme linked here. In the rest of this post, I want to explore how Safari stores its history entries on disk.</p>
<p><a href="https://github.com/thesephist/histools">See Histools on GitHub →</a></p>
<h2 id="inspecting-safaris-history-database">Inspecting Safari’s history database</h2>
<p>Histools works by transforming history data from the database into a format that can be usefully visualized on a heatmap. In macOS Catalina, Safari keeps history in a simple SQLite3 database, at <code>~/Library/Safari/History.db</code>. So the first step for me was to copy this database file out to a safe location, and open the sqlite shell to look at the database schema.</p>
<pre><code>sqlite History.db ".schema"
</code></pre><p>This returns us all of the table definitions, which you can also check out <a href="https://github.com/thesephist/histools/blob/main/meta/History.schema.sql">here</a>. For the sake of looking at history, we’re only really concerned with two tables: <code>history_items</code> and <code>history_visits</code>. Here’s what those tables looks like.</p>
<pre><code>CREATE TABLE history_items
(
    id INTEGER PRIMARY KEY autoincrement,
    url text NOT NULL UNIQUE,
    domain_expansion text NULL,
    visit_count INTEGER NOT NULL,
    daily_visit_counts BLOB NOT NULL,
    weekly_visit_counts BLOB NULL,
    autocomplete_triggers BLOB NULL,
    should_recompute_derived_visit_counts INTEGER NOT NULL,
    visit_count_score                     INTEGER NOT NULL
);

CREATE TABLE history_visits
(
    id           INTEGER PRIMARY KEY autoincrement,
    history_item INTEGER NOT NULL REFERENCES history_items(id) ON DELETE CASCADE,
    visit_time REAL NOT NULL,
    title text NULL,
    load_successful boolean NOT NULL DEFAULT 1,
    http_non_get    boolean NOT NULL DEFAULT 0,
    synthesized     boolean NOT NULL DEFAULT 0,
    redirect_source INTEGER NULL UNIQUE REFERENCES history_visits(id) ON DELETE CASCADE,
    redirect_destination INTEGER NULL UNIQUE REFERENCES history_visits(id) ON DELETE CASCADE,
    origin     INTEGER NOT NULL DEFAULT 0,
    generation INTEGER NOT NULL DEFAULT 0,
    attributes INTEGER NOT NULL DEFAULT 0,
    score      INTEGER NOT NULL DEFAULT 0
);
</code></pre><p>Safari stores new history entries in two different formats, one for efficiently looking through <em>distinct</em> history entries, and one for recording visits, with timestamp information. Namely, <code>history_items</code> stores distinct history entries by their URL, and <code>history_visits</code> stores information Safari expects to change with every visit, like the timestamp, load success state, and (curiously) the page title.</p>
<p>From this schema, we can also see that each history visit points to exactly one history item – there can be one or more visits to the same URL. On each visit, Safari will add a new history visit entry and increment some aggregate information for the corresponding history item, like the total <code>visit_count</code>.</p>
<p>Like any good exploration, the answer to one question also opens up many others. What are the <code>score</code>s next to each page? What’s a <code>synthesized</code> visit? What are <code>autocomplete_triggers</code> used for? I haven’t had a chance to dive into those yet, because there’s also plenty of fun to be had playing around with the Histools visualization itself. From the heatmap, I can see when I go to sleep each day and when I wake up in the morning (or the few times I was woken up overnight). I can see when my homework was due, when I was researching certain topics, and so on and on and on.</p>
<p>I’m looking forward to spinning up Histools from time to time to get another perspective on how I’ve been using the Web in my life.</p>

        <hr>
        <p>
            
            ←
            <a href="https://dotink.co/posts/schrift-code/"><em>Schrift: a faster, bytecode-driven interpreter for Ink</em></a>
            
        </p>
        <p>
            
            <a href="https://dotink.co/posts/weight-of-abstraction/"><em>Weighing software abstractions to design better programs</em></a>
            →
            
        </p>
    </article></div>]]>
            </description>
            <link>https://dotink.co/posts/histools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304032</guid>
            <pubDate>Fri, 04 Dec 2020 16:20:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A World Rendered Beautifully: The Making of the BFCM 3D Data Visualization]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303999">thread link</a>) | @dmalik
<br/>
December 4, 2020 | https://shopify.engineering/bfcm-3d-data-visualization | <a href="https://web.archive.org/web/*/https://shopify.engineering/bfcm-3d-data-visualization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>
  <em><strong><a href="https://shopify-bfcm.splashthat.com/" target="_blank" title="How it's made: The Black Friday &amp; Cyber Monday Live Map" rel="nofollow noopener noreferrer">Join us on Monday, December 7</a>, for a behind the scenes look at how and why we visually bring this
      exciting data to life. Shopify’s AR/VR team will take you through the
      technical journey from idea to execution and answer your questions
      live!</strong></em>
</p>
<p>
  <strong>﻿By Mikko Haapoja and Stephan Leroux</strong>
</p>
<p>
  2020 Black Friday Cyber Monday (BFCM) is over, and another BFCM Globe has
  shipped. We’re extremely proud of the globe, it focused on realism,
  performance, and the impact our merchants have on the world.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/LPm0xjr2lzo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>The Black Friday Cyber Monday Live Map</figcaption>
</figure>
<p>
  We knew we had a tall task in front of us this year, building something that
  could represent orders from our one million merchants in just two months. Not
  only that, we wanted to ship a data visualization for our merchants so they
  could have a similar experience to the BFCM globe every day in their Live
  View.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/_r6ut_Z7pss?playlist=_r6ut_Z7pss&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>Prototypes for the 2020 BFCM Globe and Live View. **</figcaption>
</figure>
<p>
  With tight timelines and an ambitious initiative, we immediately jumped into
  prototypes with three.js and planned our architecture.
</p>

<p>
  As we planned this project, we converged architecturally on the idea of
  layers. Each layer is similar to a React component where state is minimally
  shared with the rest of the application, and each layer encapsulates its own
  functionality. This allowed for code reuse and flexibility to build both the
  Live View Globe, BFCM Globe, and beyond.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/D56O11Y46o0?playlist=D56O11Y46o0&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>A showcase of layers for the 2020 BFCM Globe. **</figcaption>
</figure>
<p>
  When realism is key, it’s always best to lean on fantastic artists, and that’s
  where
  <a href="https://twitter.com/byrondelgado" target="_blank" title="Byron Delgado on Twitter" rel="nofollow noopener noreferrer">Byron Delgado</a>
  came in. We hoped that Byron would be able to use the 3D modeling tools he’s
  used to, and then we would incorporate his 3D models into our experience. This
  is where the <code>EarthRealistic</code> layer comes in.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/N4oeDV4rNQo?playlist=N4oeDV4rNQo&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    <code>EarthRealistic</code> layer from the 2020 BFCM Globe. **
  </figcaption>
</figure>
<p>
  <code>EarthRealistic</code> uses a technique called physically based
  rendering, which most modern 3D modeling software supports. In three.js,
  physically based rendering is implemented via the
  <code>MeshPhysicalMaterial</code> or
  <code>MeshStandardMaterial</code> materials.
</p>
<p>
  To achieve realistic lighting, <code>EarthRealistic</code> is lit by a 32bit
  EXR Environment Map. By using a 32bit EXR, it means we can have smooth image
  based lighting. Image based lighting is a technique where a “360 sphere” is
  created around the 3D scene, and pixels in that image are used to calculate
  how bright Triangles on 3D models should be. This allows for complex lighting
  setups without much effort from an artist. Traditionally images on the web
  such as JPGs and PNGs have a color depth of 8bits. If we were to use these
  formats and 8bit color depth, our globe lighting would have had horrible
  gradient banding, missing realism entirely.
</p>

<p>
  Once we converged on physically based rendering and image based lighting,
  building the carbon offset layer became clearer. Literally!
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/GQ2OJCiT-wA?playlist=GQ2OJCiT-wA&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    Carbon Offset visualization layer from the 2020 BFCM Globe. **
  </figcaption>
</figure>
<p>
  Bubbles have an interesting phenomenon where they can be almost opaque at a
  certain angle and light intensity but in other areas completely transparent.
  To achieve this look, we created a custom material based on
  MeshStandardMaterial that reads in an Environment Map and simulates the bubble
  lighting phenomenon. The following is the easiest way to achieve this with
  three.js:
</p>
<ol>
  <li>
    Create a custom Material class that extends off of MeshStandardMaterial.
  </li>
  <li>
    Write a custom Vertex or Fragment Shader and define any Uniforms for that
    Shader Program.
  </li>
  <li>
    Override
    <code>onBeforeCompile(shader: Shader, _renderer: WebGLRenderer): void&nbsp;</code>on your custom Material and pass the custom Vertex or Fragment Shader and
    uniforms via the Shader instance.
  </li>
</ol>
<p>
  Here’s our implementation of the above for the Carbon Offset Shield Material:
</p>
<ul>
  <li>
    <a href="https://gist.github.com/ShopifyEng/5e8bfa0de5630779ad7350c7a73cb650" target="_blank" rel="nofollow noopener noreferrer">ShieldMaterial.ts</a>
    - Our custom Carbon Offset Visualization Material
  </li>
  <li>
    <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf" target="_blank" rel="nofollow noopener noreferrer">CustomMeshStandardMaterial.ts</a>
    - Abstraction on top of MeshStandardMaterial
  </li>
  <li>
    <a href="https://gist.github.com/ShopifyEng/cc1679cfb054f85c8689037e5d168f68" target="_blank" rel="nofollow noopener noreferrer">shield.frag</a>
    - Custom Fragment shaders that make MeshStandardMaterial look like a bubble
  </li>
</ul>
<p>
  Let’s look at the above, starting with our Fragment shader. In shield.frag
  lines 94-97
</p>
<figure>
  
</figure>
<p>
  These two lines are all that are needed to achieve a bubble effect in a
  fragment shader.
</p>
<p>
  To calculate the <code>brightness</code> of an rgb pixel, you calculate the
  length or magnitude of the pixel using the GLSL length function. In three.js
  shaders, <code>outgoingLight</code> is an RGB <code>vec3</code> representing
  the outgoing light or pixel to be rendered.
</p>
<p>
  If you remember from earlier, the bubble’s brightness determines how
  transparent or opaque it should appear.&nbsp; After calculating brightness, we can
  set the outgoing pixel’s alpha based on the brightness calculation. Here we
  use the GLSL <code>mix</code> function to go between the expected alpha of the
  pixel defined by <code>diffuseColor.a</code> and a new custom uniform defined
  as <code>maxOpacity</code>. By having the concept of min or expected opacity
  and max opacity, Byron and other artists can tweak visuals to their exact
  liking.
</p>
<p>
  If you look at our shield.frag file, it may seem daunting! What on earth is
  all of this code?&nbsp; three.js materials handle a lot of functionality, so it’s
  best to make small additions and not modify existing code. three.js materials
  all have their own shaders defined in the
  <a href="https://github.com/mrdoob/three.js/blob/dev/src/renderers/shaders/ShaderLib/" target="_blank" title="ShaderLib folder in three.js repo" rel="nofollow noopener noreferrer">ShaderLib folder</a>. To extend a three.js material, you can grab the original material shader
  code from the <code>src/renderers/shaders/ShaderLib/</code> folder in the
  three.js repo and perform any custom calculations before setting
  <code>gl_FragColor</code>. An easier option to access three.js shader code is
  to simply <code>console.log</code> the <code>shader.fragmentShader</code> or
  <code>shader.vertexShader</code> strings, which are exposed in the
  <code>onBeforeCompile</code> function:
</p>
<figure>
  
</figure>
<p>
  <code>onBeforeCompile</code> runs immediately before the Shader Program is
  created on the GPU. Here you can override shaders and uniforms.
  CustomMeshStandardMaterial.ts is an abstraction we wrote to make creating
  custom materials easier. It overrides the
  <code>onBeforeCompile</code> function and manages uniforms while your
  application runs via the
  <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf#file-custommeshstandardmaterial-ts-L51" target="_blank" title="setCustomUniform in CustomMeshStandardMaterial.ts" rel="nofollow noopener noreferrer"><code>setCustomUniform</code></a>
  and
  <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf#file-custommeshstandardmaterial-ts-L60" target="_blank" title="getCustomUniform in CustomMeshStandardMaterial.ts" rel="nofollow noopener noreferrer"><code>getCustomUniform</code></a>
  functions. You can see this in action in our custom Shield Material when
  getting and setting <code>maxOpacity</code>:
</p>
<figure>
  
</figure>
<h2>Using Particles to Display Orders</h2>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/jGUDfU1c_xE?playlist=jGUDfU1c_xE&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    Displaying orders on Shopify from across the world using particles. **
  </figcaption>
</figure>
<p>
  One of the BFCM globe’s main features is the ability to view orders happening
  in real-time from our merchants and their buyers worldwide. Given Shopify’s
  scale and amount of orders happening during BFCM, it’s challenging to visually
  represent all of the orders happening at any given time. We wanted to find a
  way to showcase the sheer volume of orders our merchants receive over this
  time in both a visually compelling and performant way.&nbsp;
</p>
<p>
  In the past, we used visual “arcs” to display the connection between a buyer’s
  and a merchant’s location.
</p>
<figure>
  <img alt="The BFCM Globe from 2018 showing orders using visual arcs." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/old-globe.jpg?v=1607052787" src="https://cdn.shopify.com/s/files/1/0779/4361/files/old-globe.jpg?v=1607052787">
  <figcaption>
    The BFCM Globe from 2018 showing orders using visual arcs.
  </figcaption>
</figure>
<p>
  With thousands of orders happening every minute, using arcs alone to represent
  every order quickly became a visual mess along with a heavy decrease in
  framerate. One solution was to cap the number of arcs we display, but this
  would only allow us to display a small fraction of the orders we were
  processing. Instead, we investigated using a particle-based solution to help
  fill the gap.
</p>
<p>With particles, we wanted to see if we could:</p>
<ul>
  <li>Handle thousands of orders at any given time on screen.</li>
  <li>Maintain 60 frames per second on low-end devices.</li>
  <li>
    Have the ability to customize style and animations per order, such as
    visualizing local and international orders.
  </li>
</ul>
<p>
  From the start, we figured that rendering geometry per an order wouldn't scale
  well if we wanted to have thousands of orders on screen. Particles appear on
  the globe as highlights, so they don’t necessarily need to have a 3D
  perspective. Rather than using triangles for each particle, we began our
  investigation using three.js <code>Points</code> as a start, which allowed us
  to draw using dots instead. Next, we needed an efficient way to store data for
  each particle we wanted to render. Using <code>BufferGeometry</code>, we
  assigned custom attributes that contained all the information we needed for
  each particle/order.
</p>
<figure>
  
</figure>
<p>
  To render the points and make use of our attributes, we created a
  <code>ShaderMaterial</code>, and custom vertex and fragment shaders. Most of
  the magic for rendering and animating the particles happens inside the vertex
  shader. Each particle defined in the attributes we pass to our
  <code>BufferGeometry</code> goes through a series of steps and
  transformations.
</p>
<p>
  First, each particle has a starting and ending location described using
  latitude and longitude. Since we want the particle to travel along the surface
  and not through it, we use a geo interpolation function on our coordinates to
  find a path that goes along the surface.
</p>
<figure>
  <img alt="A photo of a globe with an order represented as a particle traveling from New York City to London. The vertex shader uses each location’s latitude and longitude and determines the path it needs to travel." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-1.jpg?v=1607053616" src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-1.jpg?v=1607053616">
  <figcaption>
    An order represented as a particle traveling from New York City to London.
    The vertex shader uses each location’s latitude and longitude and determines
    the path it needs to travel. **
  </figcaption>
</figure>
<p>
  Next, to give the particle height along its path, we use high school geometry,
  a parabola equation based on time to alter the straight path to a curve.
</p>
<figure>
  <img alt="A photo of a globe with particles that follow a curved path away from the earth’s surface using a parabola equation to determine its height." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-2.jpg?v=1607053702" src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-2.jpg?v=1607053702">
  <figcaption>
    Particles follow a curved path away from the earth’s surface using a
    parabola equation to determine its height. **
  </figcaption>
</figure>
<p>
  To render the particle to make it look 3D in its travels, we combine our
  height and projected path data then convert it to a vector position our shader
  uses as it’s <code>gl_Position</code>. With our particle now knowing where it
  needs to go, using a <code>time</code> uniform, we drive animations for other
  changes such as size and color. At the end of the vertex shader, we pass the
  position and point size to render onto the fragment shader that combines the
  calculated color and alpha at the time for each particle.
</p>
<p>
  Once …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/bfcm-3d-data-visualization">https://shopify.engineering/bfcm-3d-data-visualization</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/bfcm-3d-data-visualization</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303999</guid>
            <pubDate>Fri, 04 Dec 2020 16:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A week by week plan for starting to manage a new team]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303976">thread link</a>) | @mcrittenden
<br/>
December 4, 2020 | https://critter.blog/2020/12/04/a-week-by-week-plan-for-starting-to-manage-a-new-team/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/04/a-week-by-week-plan-for-starting-to-manage-a-new-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-3628">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I’m starting at a new company on Monday so I’ve been panic-reading management and leadership books. I’ve boiled a lot of that advice down into this week by week plan.</p>



<p><em>Important caveat: “plans are useless, but planning is indispensable” and all that. Stay flexible, shift things around as needed, don’t hold off on something that needs to happen just because it’s not in the plan, blah blah blah.</em></p>



<p><strong>Week 1</strong>: Find someone, anyone, and grab a 30 minute call with them. Here’s the agenda (stolen from <a href="https://boz.com/articles/career-cold-start">this post</a>):</p>



<ul><li>“Tell me everything you think I should know.” – 25 minutes</li><li>“What are the biggest challenges the team has right now?” – 3 minutes</li><li>“Who else should I talk to?” – 2 minutes</li></ul>



<p>Next, repeat that process with all of the names you get from that last question, and <em>keep repeating with every name you get until you run out of new names</em>. That should get you a nice jump start on knowledge transfer. You may even find a few easy problems to solve for quick wins.</p>



<p><strong>Weeks 1-3</strong>: Listen in on regular meetings and ask lots of questions. Don’t shy away from asking for clarification on things asynchronously after the meeting is over. And remember, <a href="https://critter.blog/2020/11/17/stop-trying-to-be-impressive-start-trying-to-be-warm/">be warm, not impressive</a>.</p>



<p>Don’t start 1-1s yet, and don’t try to do anything useful. Your goal for weeks 1-3 is to meet as many people as you can and learn as much as you can.</p>



<p>Also, sometime in weeks 1-3, start asking about any <a href="https://critter.blog/2020/11/16/the-2-responsibilities-of-a-manager/">shared measurable goals</a> for the team. How do you know if you’re succeeding? How is your impact being measured? Do those measures exist? If they don’t exist, then we’ll come back to this in a few weeks.</p>



<p><strong>Week 3</strong>: Send an email or a group chat message about starting 1-1s and list some available times so that people can choose the times that are best for them. Mention the format you plan to use so they can prep.</p>



<p><strong>Week 4</strong>: Start having weekly 1-1s. You won’t be giving any feedback in these 1-1s (or elsewhere) for a few more weeks. So for now your job is to get to know your directs and to support them however they need.</p>



<p><strong>Week 8</strong>: If the team already has measurable goals related to impact and business outcomes, then skip this step. Otherwise, now is the time to start figuring out what those goals should be. I talked about this in “<a href="https://critter.blog/2020/11/16/the-2-responsibilities-of-a-manager/">The 2 responsibilities of a&nbsp;manager</a>.”</p>



<p><strong>Week 12</strong>: Now that you have 3 months under your belt, fill out <a href="https://gist.github.com/mikecrittenden/faf2e60282912a809f1aac1423116268">the assessment at the end of “The Five Dysfunctions of a Team”</a>. That should give you a sense of which, if any, dysfunctions to focus on.</p>



<p>Also, start giving positive feedback. Send an email or group message letting people know that you’re going to start this, and tell them about <a href="https://critter.blog/2020/11/26/5-second-feedback/">the format it’ll follow</a>.</p>



<p><strong>Weeks 12-20</strong>: Give only positive feedback, early and often. To start, aim to give 1 piece of positive feedback to someone everyday, then increase it from there. Build up to a steady stream.</p>



<p><strong>Week 20</strong>: Now that you hopefully have earned some trust, you can start also giving negative feedback. Let your reports know ahead of time that it’s coming so they won’t be caught off guard. And remember, <a href="https://critter.blog/2020/11/27/future-focused-feedback/">don’t debate the past</a>.</p>



<p><strong>Week 30</strong>: By now you’ve been giving feedback for a while, so you should have a good sense of where to add <a href="https://www.manager-tools.com/2009/07/coaching-model-revised">more formal coaching</a>. Set goals with your reports and talk through a granular step by step plan for achieving it.</p>



<p>And just like that, you’re more than half a year in. You’re on your own from here. Good luck!</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/04/a-week-by-week-plan-for-starting-to-manage-a-new-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303976</guid>
            <pubDate>Fri, 04 Dec 2020 16:15:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to send privacy friendly emails]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25303911">thread link</a>) | @jivings
<br/>
December 4, 2020 | https://blog.leavemealone.app/how-to-send-privacy-friendly-emails/ | <a href="https://web.archive.org/web/*/https://blog.leavemealone.app/how-to-send-privacy-friendly-emails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.leavemealone.app/content/images/size/w300/2020/12/cover.png 300w,
                            https://blog.leavemealone.app/content/images/size/w600/2020/12/cover.png 600w,
                            https://blog.leavemealone.app/content/images/size/w1000/2020/12/cover.png 1000w,
                            https://blog.leavemealone.app/content/images/size/w2000/2020/12/cover.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.leavemealone.app/content/images/size/w2000/2020/12/cover.png" alt="How to send privacy friendly emails">
            </figure>

            <section>
                <div>
                    <p>As a privacy friendly company who work mainly with newsletters, we spend a lot of time thinking about the ethics of email. </p><p>We've recently been working on a sort of "code of ethics" for email senders who are interested in privacy, and after getting a lot of feedback have condensed our main points down to the following. This is still a work in progress (and in some places <em>highly</em> subjective), so if you have any feedback at all then please raise a ticket on the <a href="https://github.com/leavemealone-app/ethical-email-manifesto">GitHub repo</a>, or leave a comment on the <a href="https://news.ycombinator.com/item?id=25303911">Hacker News discussion</a>. </p><p>Let's start off with a simple one. Above all else, recurring emails should be opt-in. If I receive an email from you it <strong><em>should not be a surprise</em></strong>.</p><p>In real terms this means;</p><ul><li>For newsletter creators, if someone signed up for your monthly newsletter, then don't sometimes send them weekly without asking.</li><li>For app makers and SaaS, a welcome email is okay, but don't automatically add a new customer to your automated Drip campaign of 25 on-boarding emails.</li></ul><p>This really is a no-brainer and benefits everyone. If you send emails that people don't expect, you make them angry and more likely to mark you as spam, hurting your reputation.</p><p>I've spoken about this before, letting your recipients easily unsubscribe from emails helps to maintain a healthy mailing list. But lets go one step further...</p><p>Being granted permission to send an email to a persons inbox <strong>should be treated as a privilege</strong>, and we should respect their right to easily deny us that permission at any time and for any reason.</p><p>This means we must provide an unsubscribe link within each email that is accessible to the recipient, this link should ideally unsubscribe in <em>one-click</em> and not require any additional steps.</p><!--kg-card-begin: html--><blockquote>Being granted permission to send an email to a persons inbox should be treated as a privilege</blockquote><!--kg-card-end: html--><p>The best way to do this is to provide an "unsubscribe" link in the email body. This should be clear and purposeful by;</p><!--kg-card-begin: markdown--><ul>
<li>Using clear language
<ul>
<li>"Click here to unsubscribe" is good</li>
<li>"Manage your preferences here" is not.</li>
</ul>
</li>
<li>Being accessible
<ul>
<li>Make your unsubscribe link obvious</li>
<li>Keep the contrast ratio high - eg don't use light grey text on a white background. This is not cool.</li>
</ul>
</li>
</ul>
<!--kg-card-end: markdown--><p>If possible, it's also good to provide a machine-readable <code>List-Unsubscribe</code> header with every email (<a href="https://www.ietf.org/rfc/rfc2369.txt">RFC 2369</a>). This allows automated tools to help your recipients unsubscribe. The URL in the List-Unsubscribe can be the same as the one you use in your unsubscribe link in the email body.</p><!--kg-card-begin: markdown--><pre><code>List-Unsubscribe: 
    &lt;http://www.host.com/list.cgi?cmd=unsub&amp;lst=list&gt;,
    &lt;mailto:<a href="https://blog.leavemealone.app/cdn-cgi/l/email-protection" data-cfemail="9df1f4eee9b0eff8ece8f8eee9ddf5f2eee9b3fef2f0">[email&nbsp;protected]</a>?subject=unsubscribe&gt;
</code></pre>
<!--kg-card-end: markdown--><p>In case this doesn't go without saying, if a recipient unsubscribes from your mailing list then you should not send them any more emails from that address!</p><p>P.S. Recently I've seen more mailing lists including an unsubscribe link at the top of the email as well as at the bottom. This seems like a great idea.</p><p>There should be no doubt why someone is receiving your email, or how frequently they should expect it. It sucks to receive an email but not know why.</p><p>I understand that recipients may forget that they signed up for your service or to receive your newsletter (especially if it is not sent frequently), so make the intent of the email clear at the start. For example, by leading the content with the sentence "You are receiving this email because you signed up for an account on example.com".</p><p>Newsletter creators, if you sent emails on a schedule then let your recipient know when they will receive your next email.</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/12/image.png"><figcaption>Here's how we manage this in some of our recurring emails</figcaption></figure><!--kg-card-end: image--><p>There's also an email header for this as well, the <code>List-Help</code> header. This provides a place to discover more information about the mailing list.</p><!--kg-card-begin: markdown--><pre><code>List-Help: &lt;http://www.host.com/list/&gt;, &lt;mailto:<a href="https://blog.leavemealone.app/cdn-cgi/l/email-protection" data-cfemail="8de1e4fef9a0e4e3ebe2cde5e2fef9a3eee2e0">[email&nbsp;protected]</a>&gt;
</code></pre>
<!--kg-card-end: markdown--><p>Probably the most controversial point I need to make - emails should not contain spy-pixels/pixel-trackers or any other mechanism that measures open-rates.</p><p>I know it's nice to see how many people are opening your emails, but since this tracking can be done without the consent of the recipient, it should be considered a violation of privacy. Requiring recipients to disable images in their email client in order to not be tracked is <strong>not </strong>acceptable.</p><!--kg-card-begin: image--><figure><img src="https://blog.leavemealone.app/content/images/2020/12/image-1.png"><figcaption>Read tracking can be crazy intrusive (image courtesy of the SuperHuman exposé last year)</figcaption></figure><!--kg-card-end: image--><p>If you wish to see if recipients are engaging with your emails, then provide actionable elements for them. For example, clicking a link in the email is easily measurable, shows engagement, and is less intrusive.</p><p>Ideally, I think it would be nice to return to mainly plaintext emails, with a few embedded images here and there. Embedded images don't have to be fetched from an external server, and thus can't be used for tracking purposes. I <a href="https://twitter.com/JamesIvings/status/1334796362416877569">tweeted some info</a> on how to embed images recently if you want more info on this.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>I think these 4 points cover most shady email practices, a good start!</p><p>None of this is governed by any specific law, but a bunch of it probably falls under either CAN-SPAM or GDPR email regulations. </p><p>That said, governments have been consistently slow to react with regards to protecting online privacy and barely enforce any protections they have managed to pass. So I think the best way forward is encourage email senders to act ethically, and as consumers, point out ethical violations and not do business with those who do not meet our standards wherever possible.</p><p>There's a long way to go in this space, and I want to explore it in the open with as much feedback as possible. My first draft of an <em>Ethical Email Manifesto</em> that we will be following at my company is <a href="https://github.com/leavemealone-app/ethical-email-manifesto">public on GitHub</a> and open to contributions.</p><p>If you want to support this movement and tell the world you're an "ethical email sender", then <a href="https://github.com/leavemealone-app/ethical-email-manifesto/issues">open an issue</a> and we'll add your company as a signatory to the document ❤</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><p>Agree (or disagree) with me about any of this? Jump on the <a href="https://news.ycombinator.com/item?id=25303911">HN thread</a>, or <a href="https://twitter.com/JamesIvings">follow me on Twitter</a>, where I post a lot about shady email practices.</p><!--kg-card-begin: html--><!--kg-card-end: html-->
                </div>
            </section>

            <section>
                <h3>Subscribe to Leave Me Alone Blog</h3>
                <p>Get the latest posts delivered right to your inbox</p>
                


            </section>

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.leavemealone.app/how-to-send-privacy-friendly-emails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303911</guid>
            <pubDate>Fri, 04 Dec 2020 16:11:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Continuous Delivery]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303843">thread link</a>) | @lukastyrychtr
<br/>
December 4, 2020 | https://kflansburg.com/posts/rust-continuous-delivery/ | <a href="https://web.archive.org/web/*/https://kflansburg.com/posts/rust-continuous-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Over the last few years I have iterated several times on continuous delivery
pipelines for Rust applications. Designing these pipelines involves balancing
a number of factors including cost, complexity, ergonomics, and rigor. In this
post I will describe several of these iterations, lessons learned, and share my
most recent solution in detail.</p>
<h2 id="requirements-for-continuous-delivery">Requirements for Continuous Delivery</h2>
<p>For most teams a continuous delivery (CD) process involves a series of
automated steps, with occasional human gates, which move code from pull request
to production. This ensures that high quality code reaches production, while
reducing the human effort involved in a release.</p>
<p>My use case involved a number of quirks:</p>
<ul>
<li>I was the sole maintainer on over a dozen projects. This meant that complex
<code>git</code> workflows did not add much value, but I desired a high level of
automation and as much help validating the code as possible.</li>
<li>In rare cases I would need to get a patch into production as quickly as
possible (10 minutes or less).</li>
<li>Rust can have long compile times, so incremental builds were important.</li>
</ul>
<h2 id="gitlab-and-docker-swarm">GitLab and Docker Swarm</h2>
<p>GitLab was an early mover when it came to integrating CI/CD directly with code
repositories. I was already hosting my code with GitLab at the time, and was
eager to automate the testing and release process. For simplicity, I elected to
use GitLab’s container registry for storing images built by the pipeline.</p>
<p>I was also beginning to be overwhelmed with the number services that I was
managing, and looking at container orchestration solutions to integrate with
this pipeline. Like many small ventures, I felt that Kubernetes was too complex
for my needs, and instead opted for Docker Swarm. Despite its limited adoption,
Docker Swarm was a good stepping stone before taking on the complexity of
Kubernetes.</p>
<h3 id="cached-rust-container-builds">Cached Rust Container Builds</h3>
<p>The most important optimization for Rust build pipelines involves modifying
Dockerfiles to better leverage build caching and produce smaller production
images. This isn’t a novel solution, but it is worth mentioning.</p>
<p>First, <code>cargo build</code> is split into two steps. The first builds all dependencies
based on <code>Cargo.toml</code> and <code>Cargo.lock</code>. These layers will only be rebuilt if
Rust releases a new stable version or you modify dependencies. Second, the
application itself is built, this will be rebuilt whenever you modify your
application’s source code. Finally, the application’s binary is copied to a
second stage which builds the runtime container. It is possible to build an
even slimmer runtime image by statically linking against <code>musl</code> and creating
a <code>FROM scratch</code> container, but I have not found this to be definitively
better.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span id="0"> 0
</span><span id="1"> 1
</span><span id="2"> 2
</span><span id="3"> 3
</span><span id="4"> 4
</span><span id="5"> 5
</span><span id="6"> 6
</span><span id="7"> 7
</span><span id="8"> 8
</span><span id="9"> 9
</span><span id="10">10
</span><span id="11">11
</span><span id="12">12
</span><span id="13">13
</span><span id="14">14
</span><span id="15">15
</span><span id="16">16
</span><span id="17">17
</span><span id="18">18
</span><span id="19">19
</span><span id="20">20
</span></code></pre></td>
<td>
<pre><code data-lang="Docker"><span># Stable</span><span>
</span><span></span><span>FROM</span><span> rust:latest as build</span><span>
</span><span>
</span><span></span><span># Build Dependancies</span><span>
</span><span></span><span>WORKDIR</span><span> /build</span><span>
</span><span></span><span>RUN</span> <span>USER</span><span>=</span>root cargo new --bin app<span>
</span><span></span><span>WORKDIR</span><span> /build/app</span><span>
</span><span></span><span>COPY</span> Cargo.toml .<span>
</span><span></span><span>COPY</span> Cargo.lock .<span>
</span><span></span><span>RUN</span> cargo build --release<span>
</span><span>
</span><span></span><span># Build Application</span><span>
</span><span></span><span>RUN</span> rm src/*.rs<span>
</span><span></span><span>RUN</span> rm ./target/release/deps/app<span>
</span><span></span><span>COPY</span> src/ src/<span>
</span><span></span><span>RUN</span> cargo build --release<span>
</span><span>
</span><span></span><span># Build Run</span><span>
</span><span></span><span>FROM</span><span> debian:stable-slim AS run</span><span>
</span><span></span><span>COPY</span> --from<span>=</span>build /build/app/target/release/app app<span>
</span><span></span><span>ENTRYPOINT</span> <span>[</span><span>"./app"</span><span>]</span><span>
</span></code></pre></td></tr></tbody></table>
</div>
</div><p>You will need to push both your <code>build</code> and <code>run</code> images to your registry in
order to properly cache layers. If you only push your <code>run</code> image, build
layers will not be included, and will not be available for caching in
subsequent builds. Your build pipeline should first pull previous <code>build</code> and
<code>run</code> images, then build and tag the new images, and finally push them both.
Since I’m the only user of these images, I typically tag them by commit hash
for precise referencing.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span id="0"> 0
</span><span id="1"> 1
</span><span id="2"> 2
</span><span id="3"> 3
</span><span id="4"> 4
</span><span id="5"> 5
</span><span id="6"> 6
</span><span id="7"> 7
</span><span id="8"> 8
</span><span id="9"> 9
</span><span id="10">10
</span><span id="11">11
</span><span id="12">12
</span><span id="13">13
</span><span id="14">14
</span><span id="15">15
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span># Ignore pull failures since this is just for the cache.</span>
docker pull <span>${</span><span>REGISTRY_URL</span><span>}</span>:cache <span>||</span> <span>true</span>
docker pull <span>${</span><span>REGISTRY_URL</span><span>}</span>:latest <span>||</span> <span>true</span>

docker build --target build <span>\
</span><span></span>    --cache-from <span>${</span><span>REGISTRY_URL</span><span>}</span>:cache <span>\
</span><span></span>    --tag <span>${</span><span>REGISTRY_URL</span><span>}</span>:cache .
docker build --target run <span>\
</span><span></span>    --cache-from <span>${</span><span>REGISTRY_URL</span><span>}</span>:latest <span>\
</span><span></span>    --cache-from <span>${</span><span>REGISTRY_URL</span><span>}</span>:cache <span>\
</span><span></span>    --tag <span>${</span><span>REGISTRY_URL</span><span>}</span>:<span>$(</span>git rev-parse HEAD<span>)</span> <span>\
</span><span></span>    --tag <span>${</span><span>REGISTRY_URL</span><span>}</span>:latest .

docker push <span>${</span><span>REGISTRY_URL</span><span>}</span>:cache
docker push <span>${</span><span>REGISTRY_URL</span><span>}</span>:<span>$(</span>git rev-parse HEAD<span>)</span>
docker push <span>${</span><span>REGISTRY_URL</span><span>}</span>:latest
</code></pre></td></tr></tbody></table>
</div>
</div><h3 id="terraform">Terraform</h3>
<p>After an image is built, I wanted to continue manually triggering the actual
update process. To complete the automation of this deployment pattern,
Terraform was used to provision Docker Swarm nodes and configure workloads in
the cluster itself by connecting to the daemon via mTLS. In this way I could
update the image tag in one place and Terraform would update the many services
using that image. I don’t think Terraform is perfect, but I much prefer it to
Helm for composing and validating complex cluster deployments.</p>
<h2 id="sourcehut-then-github">sourcehut then GitHub</h2>
<p>Eventually I grew frustrated with GitLab’s application performance. I found the
user interface to be fairly inefficient to navigate, and this was coupled with
slow page load times. I felt that the build pipeline on the free tier did not
match other free offerings, and there was not a paid plan which directly
addressed these concerns. A number of minor outages resulted in the inability
to build images for hours at a time every few weeks. Even with caching, build
times were quite long, and I briefly experimented with using GitLab’s
self-hosted runner integration. This was quite slick, but was a lot of work to
manage for what was intended to be an integrated solution.</p>
<p>Around this time sourcehut was launched and the lightweight pages with fast
load times were quite appealing. sourcehut also introduced its own integrated
build pipelines, and I felt that even if these were too slow I would be no
worse off than with GitLab. I decided to migrate a few repositories as a pilot.
I determined that sourcehut was great for the reasons described, and is
definitely something I would consider for personal projects, but I quickly
decided that it was too early for production use (which marketing material was
pretty clear about).</p>
<p>These issues were not critical, but I began looking at GitHub again for the
first time since 2016. Microsoft had acquired GitHub, and built out a number of
new features, including Actions, Projects, and Packages. I played around with
some of these features, but the deciding factor was their decision to grant
free accounts unlimited private repositories. At this point, I began migrating
all of my repositories to a new GitHub organization. It is worth noting that
I was still using the same general deployment architecture, just with Actions
and Packages in place of GitLab’s offerings.</p>
<p>All of these services are great options, and none of these concerns are deal
breakers. I know that all of these platforms are actively working to address
these concerns. I have clearly spent a lot of time hopping between platforms,
and I would not recommend this unless one of your hobbies is optimizing
developer quality of life.</p>
<p>One thing that I did during this process that I <em>would</em> recommend is making
your repositories as uniform as possible. My platform-specific CICD
configurations are exactly the same for every repository of a given language.
This means that migrating between platforms involves updating and testing <em>one</em>
script, and then pulling, patching, and pushing can be automated with a Bash
script. If you do need to migrate platforms for some reason, this process can
take just a few hours when combined with Terraform.</p>
<h2 id="rust-continuous-integration">Rust Continuous Integration</h2>
<p>I employ a number of steps for validating my Rust code. These are not
revolutionary, but I will include them here for those that are not aware.</p>
<ol>
<li><code>cargo fmt --check</code> Applies <code>rustfmt</code>, and fails if there are any changes
that are expected. This may seem pedantic, but Rust can be hard to parse
for new Rust programmers, and maintaining a highly idiomatic format in your
codebase is super easy and can reduce cognitive overhead of reading new
code.</li>
<li><code>cargo clippy</code> applies code-level checks to your application, identifying
unused imports, non-idiomatic control flow, and unnecessary clones. This
prevents cruft build up and occasionally improves performance (slightly).</li>
<li>The compiler does a lot to detect where type-level API changes break
consumers of that API. I use unit tests to validate business logic which is
not caught by the compiler. A common example here is when manually parsing
binary messages, unit tests can help detect off-by-one errors and other
subtle bugs that occur when slicing arrays.</li>
<li>Rust documentation can include examples which can be run as tests as well to
validate that they compile and run without error (thus maintaining valid
documentation). For my use, extensive documentation is not very valuable,
however these tests can be used to assert that things <em>don’t compile</em>, which
can be good for verifying that invalid states are recognized as invalid by
the compiler. These tests are very brittle, so I use them sparingly.</li>
<li>For performance sensitive code, I recommend <code>criterion</code> for benchmarking
critical functions and detecting performance regressions. I currently use
this only on my local development machine, but it could be integrated into
a continuous delivery pipeline as well.</li>
</ol>
<p>These tests will obviously not eliminate bugs, but they can eliminate a lot
of the toil involved in spotting these types of issues, and in doing so ensure
that this is done thoroughly on every commit.</p>
<h2 id="aws-codebuild-and-kubernetes">AWS CodeBuild and Kubernetes</h2>
<p>Finally, I would like to share my current pipeline. This evolved over several
months following my move to GitHub. A number of things changed over this time.
First, I had become competent enough with Kubernetes that Docker Swarm began
to feel like the more complex option when compared with Terraform and AWS'
Elastic Kubernetes Service (EKS). The remaining itch I had was build times. In
my previous experiments with GitLab runners, the idea of having control over
the VM size for building was very appealing, but having to either pay for this
machine full time or develop complex behavior for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kflansburg.com/posts/rust-continuous-delivery/">https://kflansburg.com/posts/rust-continuous-delivery/</a></em></p>]]>
            </description>
            <link>https://kflansburg.com/posts/rust-continuous-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303843</guid>
            <pubDate>Fri, 04 Dec 2020 16:05:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could Plasma Dilution Be the Answer to Age-Related Diseases–and Cytokine Storm?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25303377">thread link</a>) | @deegles
<br/>
December 4, 2020 | https://www.clinicalresearchnewsonline.com/news/2020/06/29/could-plasma-dilution-be-the-answer-to-age-related-diseases-and-cytokine-storm | <a href="https://web.archive.org/web/*/https://www.clinicalresearchnewsonline.com/news/2020/06/29/could-plasma-dilution-be-the-answer-to-age-related-diseases-and-cytokine-storm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        <div><p><strong>By Deborah Borfitz</strong></p>
<p><strong>June 29, 2020 |</strong> A 30-year-old clinical procedure could explode in popularity if its mouse equivalent holds true in humans—reduction in damaging proteins that have been implicated in diseases such as Alzheimer’s disease and heart failure. Therapeutic plasma exchange (TPE) is currently being used to treat more than 50 relatively uncommon diseases, primarily autoimmune disorders, but not more frequently occurring, age-related disorders, says Dobri Kiprov, M.D., medical director of Apheresis Care Group in San Francisco and an internationally recognized expert in the field.</p>
<p>Irina and Mike Conboy, both bioengineering experts at UC Berkeley, have been studying systemic aging and rejuvenation since early 2000s. Their seminal 2005 paper (<a href="https://doi.org/10.1038/nature03260">DOI: 10.1038/nature03260</a>) established that multiple old tissues become quickly and robustly rejuvenated when young and old mice are experimentally made into co-joined twins.</p>
<p>Their recent work on rejuvenation by plasma dilution (<a href="https://doi.org/10.18632/aging.103418">DOI: 10.18632/aging.103418</a>) introduces an entirely new scientific paradigm that improving the health and function of multiple old organs doesn’t require complex approaches or the search for novel molecules. An equally if not more robust method is to replace a portion of blood plasma with saline and replenishing lost albumin.</p>
<p>Among the important findings is that “young” proteins, which are needed for tissue health and repair and become deficient with age, are restored when their age-elevated inhibitors are diluted, explains I. Conboy. In other words, the “bloodstream milieu is reset to youth and health” for both age-elevated and age-diminished determinants.</p>
<p>“It wasn’t that we added something that was an elixir,” says M. Conboy.</p>
<p>The clinical significance of this work is underscored by collaboration with Kiprov, who suspected TPE in people might be rejuvenative, continues I. Conboy. He provided the Conboy group with samples of human blood from patients who underwent the procedure.</p>
<p>After finding that plasma dilution significantly improved the health of old mice and made old human blood supportive for tissue repair, the researchers conducted a proteomic analysis of the blood plasma of the animals to find out how the proteins in their blood changed following the procedure. They performed a similar analysis on blood plasma from humans who had undergone TPE. In both cases, says I. Conboy, the plasma exchange process acted somewhat like a “molecular reset” button for health and youth.</p>
<p><strong>Efficacy Trial Planned</strong></p>
<p>The next step is to reposition TPE for preventing and treating diseases that affect people at an older age, Kiprov says, adding that he just completed a “very significant clinical trial” related to Alzheimer’s disease that looked at this question and is now in press. Among the unknowns to be tackled with the new, placebo-controlled study are how many TPE procedures are required to prevent a disease or stop its progression and if the protective effects are short- or long-lived.</p>
<p>As with many other planned trials, the start date of the phase II efficacy study has been delayed by the COVID-19 pandemic. But the protocol is written and has the approval of a national institutional review board, says Kiprov, who will be a clinical co-investigator on these trials.</p>
<p>Patients don’t have to be followed for years, as the goal and expectation is a rapid reversal of age-imposed diseases—including inflammatory, fibrotic, degenerative, and metabolic illnesses, says I. Conboy. A diagnosis of cancer might be one of the exclusion criteria.</p>
<p>“If we can prolong the healthspan of participants we can possibly prolong their lifespan because most people don’t die of old age but from disease,” Kiprov says. The study already has pilot funding and a list of people waiting to be enrolled.</p>
<p>Among the long list of potential enrollees are people with fibrosis disorders, diabetes, cirrhosis of liver and degenerative diseases such as muscle wasting, Alzheimer’s, and Parkinson’s, says I. Conboy. The plan is to start with about 50 patients at one clinic and see if, in addition to health improvements and functional rejuvenation, their blood develops a more youthful profile.</p>
<p>Admittedly, TPE can be an unpleasant experience because it’s a two-hour procedure that involves needle sticks in both arms, says Kiprov. But the computer-controlled apheresis machine is sophisticated and used by highly trained professionals. Side effects are mild and occur in only 3% to 4% of cases.</p>
<p><strong>COVID-19 Connection</strong></p>
<p>As Kiprov recently reported in a video <a href="https://www.apheresispro.com/blog">blog</a>, multiple clinical trials are underway to see if TPE can be used in the treatment of the overwhelming inflammatory response, or cytokine storm, seen in severe cases of COVID-19. TPE has been successfully used to treat cytokine storm in other medical conditions, including sepsis and cancer patients being treated with chimeric antigen receptor (CAR)-T cell therapy.</p>
<p>Similarly, infusion devices capable of removing cytokines in COVID-19 patients are being used in several clinical trials in the U.S. and Europe, he adds. These include CytoSorbents’ <a href="https://cytosorbents.com/products/cyto-sorb/">CtyoSorb</a> and SeaStar Medical’s <a href="https://www.seastarmedical.com/product/">CLR</a> system, both of which work in conjunction with continuous renal replacement therapy. A potential problem is obstruction of the filter by small thrombi in the circulation of many critically ill COVID-19 patients.</p>
<p>Terumo BCT also recently <a href="https://www.terumobct.com/Pages/News/Press%20Releases/Terumo-BCT-and-Marker-Therapeutics-received-the-first-device-FDA-Emergency-Use-Authorization-(EUA)-to-treat-acute-respirato.aspx">announced</a> that its Spectra Optia Apheresis System is being combined with Marker Therapeutics’ D2000 Adsorption Cartridge to reduce cytokine levels in COVID-19 patients with confirmed or imminent respiratory failure.</p>
<p>It is no coincidence that the people hit hardest by COVID-19 are mostly elderly and have preexisting conditions, Kiprov says, as both the aging process and chronic diseases are associated with prolonged inflammation. When they’re infected with the virus, new pro-inflammatory factors join the already existing ones to bring on a cytokine storm that rapidly results in organ damage.</p>
<p>“The lungs are the primary target for this immune response, but no organ is spared,” says Kiprov. In fact, it has been observed that the kidneys are affected in between 30% and 60% of hospitalized COVID-19 patients.</p>
<p>Physicians have no more than 36 hours to initiate treatment if cytokine storm is suspected; organ damage will be permanent, if patients survive at all, once they’re intubated. The criteria used by Kiprov includes respiratory distress, elevated white blood cell count, low lymphocyte count, and high levels of C-reactive protein, ferritin, and lactate dehydrogenase (a biomarker of tissue damage), he shares in the video.</p>
<p>TPE with convalescent plasma for severe COVID-19 has been tried experimentally in China and more recently the U.S. and shown promising results when used early in the disease, Kiprov notes. Circulating immunoglobulin G antibodies in the plasma of people who have recovered from COVID-19 can provide “passive immunization” during the wait for an effective vaccine.</p>
<p>Eventually, convalescent plasma could be used to make coronavirus-specific antibodies, he says. Sorrento Therapeutics, for example, recently <a href="https://investors.sorrentotherapeutics.com/news-releases/news-release-details/sti-1499-potent-anti-sars-cov-2-antibody-demonstrates-ability">announced</a> that it had developed a potent anti-SARS-CoV-2 antibody that has demonstrated its ability to inhibit infection in preclinical studies. The goal is an antibody cocktail that would provide a long-term, vaccine-like shield of protection.</p>
<p><strong>No ‘Silver Bullets’</strong></p>
<p>To date, the role of the Food and Drug Administration with TPE has been in approving the machine used to separate blood into its different parts and then remove and replace most of the plasma. Physicians decide when to order the treatment and in general follow the recommendations of various medical societies, Kiprov says. The American Society for Apheresis, for its part, issues clinical guidelines that puts diseases into one of three categorizes based on the strength of the evidence supporting TPE use.</p>
<p>Its first effective use was in the late 1970s for Waldenström's macroglobulinemia, predominantly a disease of elderly white men characterized by an overproduction of large proteins called immunoglobulins that interfere with blood circulation, causing hyperviscosity, says Kiprov. The blood of some patients can become as thick as jelly.</p>
<p>TPE proved to be quite good at clearing out antibodies that promote autoimmune diseases and inflammation, he continues. They’re less efficient at depleting small molecules, such as cytokines, whose function are less defined but are in plentiful supply in the circulation of patients with autoimmune diseases.</p>
<p>The 2005 <em>Nature </em>paper set off a flurry of research into whether the blood of young mice might serve as a "fountain of youth" for the old mice—and the compelling possibility that the same might hold true in humans, says I. Conboy. What many overlooked in that report, which her group has replicated in a more recent study, is that exchanging blood between young and old animals without physically joining them ages the young mice. That means young blood circulating through young veins couldn’t compete with old blood.</p>
<p>Research enthusiasm around the idea that young plasma contains “silver bullets” for aging has been hard to dampen, says Kiprov. But he remains hopeful that the more recently published findings will divert attention to plasma exchange for both combatting aging and promoting productive immunomodulation.</p>
<p>While TPE may seem like a simple concept, says I. Conboy, repositioning it for new classes of age-related disorders would not be effective or safe without dedicated clinical trials. She has also launched a biotech company, IMYu, where the R&amp;D focus will be on understanding how “designer TPE” simultaneously rejuvenates multiple tissues and then applying that knowledge to the development of next-generation anti-aging therapeutics.</p></div>

        
    </div></div>]]>
            </description>
            <link>https://www.clinicalresearchnewsonline.com/news/2020/06/29/could-plasma-dilution-be-the-answer-to-age-related-diseases-and-cytokine-storm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303377</guid>
            <pubDate>Fri, 04 Dec 2020 15:34:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Origin of the blink HTML Tag – www]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25303324">thread link</a>) | @siliconmountain
<br/>
December 4, 2020 | http://www.montulli.org/theoriginofthe%3Cblink%3Etag | <a href="https://web.archive.org/web/*/http://www.montulli.org/theoriginofthe%3Cblink%3Etag">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="sites-canvas-main">
<div id="sites-canvas-main-content">
<div xmlns="http://www.w3.org/1999/xhtml"><div><div dir="ltr"><p>&nbsp;&nbsp;&nbsp; I am widely credited as the inventor of the &lt;blink&gt; tag. &nbsp; For those of you who are relatively new to the Web, the &lt;blink&gt; tag is an HTML command that causes text to blink, and many, many people find its behavior to be extremely annoying. &nbsp;&nbsp; I won't deny the invention, but there is a bit more to the story than is widely known.</p><p>&nbsp;&nbsp;&nbsp; Back in 1994 I was a founding engineer at Netscape, prior to that I had written the Lynx browser, which predated all of the other popular browsers at that time.&nbsp;&nbsp;&nbsp; Lynx had been and still is a text only browser and is commonly used in a console window on UNIX machines.&nbsp;&nbsp; At Netscape we were building software that used a graphical user interface and could express vastly more text styles and layouts as well as images and other media.&nbsp;&nbsp; We spent a lot of time thinking about the future of the web and new technologies that would enable new classes of documents, applications and uses. &nbsp;&nbsp; A few examples of those thoughts were, HTML Tables, SSL for secure communications, Plugins for extensions, and JavaScript to enable dynamic HTML.&nbsp;&nbsp;&nbsp;&nbsp;</p><p>&nbsp;&nbsp;&nbsp; Sometime in late summer I took a break with some of the other engineers and went to a local bar on Castro street in Mountain View.&nbsp;&nbsp; The bar was the St. James Infirmary and it had a 30 foot wonder woman statue inside among other interesting things.&nbsp;&nbsp;&nbsp; At some point in the evening I mentioned that it was sad that Lynx was not going to be able to display many of the HTML extensions&nbsp; that we were proposing,&nbsp; I also pointed out that the only text style that Lynx could exploit given its environment was blinking text.&nbsp;&nbsp;&nbsp; We had a pretty good laugh at the thought of blinking text, and talked about blinking this and that and how absurd the whole thing would be.&nbsp;&nbsp;&nbsp;&nbsp; The evening progressed pretty normally from there, with a fair amount more drinking and me meeting the girl who would later become my first wife. </p><p>&nbsp; Saturday morning rolled around and I headed into the office only to find what else but, blinking text.&nbsp;&nbsp;&nbsp; It was on the screen blinking in all its glory, and in the browser.&nbsp;&nbsp;&nbsp; How could this be, you might ask?&nbsp;&nbsp; It turns out that one of the engineers liked my idea so much that he left the bar sometime past midnight, returned to the office and implemented the blink tag overnight.&nbsp;&nbsp; He was still there in the morning and quite proud of it.</p><p>&nbsp;&nbsp;&nbsp; At the time there were 3 versions of the browser that ran on UNIX, Windows and Mac operating systems.&nbsp;&nbsp;&nbsp; For a short 12 hours the blinking was constrained only to the UNIX version, but it didn't take long for the blinking to spread to Windows and then the Mac version.&nbsp;&nbsp;&nbsp;&nbsp; I remember thinking that this would be a pretty harmless easter egg, that no one would really use it, but I was very wrong.&nbsp;&nbsp;&nbsp;&nbsp; When we released Netscape Navigator 1.0 we did not document the blink functionality in any way, and for a while all was quiet.&nbsp;&nbsp; Then somewhere, somehow the arcane knowledge of blinking leaked into the real world and suddenly everything was blinking.&nbsp;&nbsp;&nbsp; "Look here", "buy this", "check this out", all blinking.&nbsp;&nbsp; Large advertisements blinking in all their glory.&nbsp;&nbsp; It was a lot like Las Vegas, except it was on my screen, with no way of turning it off. &nbsp; &nbsp;</p><p>&nbsp;&nbsp;&nbsp; In the end, much was said, most of it in the form of flaming posts to various discussion boards, and the &lt;blink&gt; tag will probably be remembered as the most hated of all HTML tags.&nbsp;&nbsp; I would like to publicly state that at no time did I actually write code or even seriously advocate for the &lt;blink&gt; tag.&nbsp;&nbsp; It is true that I put forth the initial inspiration, but it really was merely a thought experiment.&nbsp;&nbsp;&nbsp; I am not going to name any names of the people who coded the dastardly deed, if they wish to step forward, they will need to do it themselves.&nbsp;&nbsp;&nbsp; In the end, the thing that I am truly sad about, is that Lynx never did get to blink.&nbsp;&nbsp;&nbsp;&nbsp; I am also sad to report that the St James Infirmary burned to the ground in 1997, it was a great place to hang out and will be missed.<br></p><p>&lt;blink&gt; on,</p><p>:lou<br></p></div></div></div>
</div> 
</div></div>]]>
            </description>
            <link>http://www.montulli.org/theoriginofthe%3Cblink%3Etag</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303324</guid>
            <pubDate>Fri, 04 Dec 2020 15:29:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Murder of Wilbur Wright – How many of our greatest minds have we lost?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25303289">thread link</a>) | @leopold_a
<br/>
December 4, 2020 | https://applieddivinitystudies.com/murder-of-wilbur/ | <a href="https://web.archive.org/web/*/https://applieddivinitystudies.com/murder-of-wilbur/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
       <p>How many of our greatest minds have we lost?</p>
<p>From The Dream Machine (p50) on John Atanasoff:</p>
<blockquote>
<p><strong>He was determined to build a computing machine… But with all his teaching responsibilities, he’d had very little time to focus on the problem.</strong> Finally, however, on a bitterly cold winter night in late 1937, he just couldn’t take it anymore; he had to get away to concentrate. So he jumped into his car in Ames, Iowa, and drove east through the subzero temperature at more than eighty miles per hour. Almost three hours later, after he crossed the Mississippi River into Illinois, he stopped at a roadhouse to warm up. And there, somewhere between his first and second bourbons, he conceived four crucial ideas to make him computer work.”</p>
</blockquote>
<p>Incredible! Atanasoff was busy, but finally got down to doing the thing he really loved, the world recognized his genius, and he was given all the resources he needed to complete his work.</p>
<p>At least, that’s what would have happened in any reasonable society. Instead, we’re told:</p>
<blockquote>
<p>Atanasoff didn’t develop his invention any further, as it happened. Soon after the United States entered the war, in December 1941, he went to the Naval Ordinance Laboratory in Washington, D.C., where he supervised the counting testing of mines. <strong>He never returned to computing.</strong></p>
</blockquote>
<p>Who knows what else he could have given us? Instead, his entire lifetime produces one brief period of real scientific producitivity, bookended by teaching responsibilities and war.</p>
<p>Once you start looking, these stories are everwhere. Here’s <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/History_of_Unix">The Daemon, the Gnu and the Penguin</a> on the invention of Unix:</p>
<blockquote>
<p>In August 1969, Ken Thompson’s wife Bonnie took their year-old son on a trip to California to show off to their families. As a temporary bachelor, Ken had time to work. “I allocated a week each to the operating system, the shell, the editor and the assembler [he told me]… and during the month she was gone, it was totally rewritten in a form that looked like an operating system”</p>
</blockquote>
<p>Maybe this is a greatly exaggerated myth, but how terrifying would it be if that was true? Is it possible that Thompson was burdened by responsibilities his entire life, and then in a brief moment of freedom did some of the most important work anyone has ever done?</p>
<p>And then from <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Wright_brothers#Wilbur">Wikipedia</a>, on Wilbur Wright:</p>
<blockquote>
<p>…Wilbur never flew again. He gradually became occupied with business matters for the Wright Company and dealing with different lawsuits. Upon dealing with the patent lawsuits, which had put great strain on both brothers, Wilbur had written in a letter to a French friend, “<strong>When we think what we might have accomplished if we had been able to devote this time to experiments, we feel very sad</strong>, but it is always easier to deal with things than with men, and no one can direct his life entirely as he would choose.”</p>
</blockquote>
<p>But why on earth not? Why couldn’t Wilbur Wright, now admired as one of history’s greatest investors, find time to continue his most important work? The story continues:</p>
<blockquote>
<p>Wilbur spent the next year before his death traveling, where he spent a full six months in Europe attending to various business and legal matters… He was also constantly back and forth between New York, Washington and Dayton. All of the stresses were taking a toll on Wilbur physically. Orville would remark that he would “come home white”.</p>
</blockquote>
<p>Then finally:</p>
<blockquote>
<p>After returning to Dayton in early May 1912, worn down in mind and body, he fell ill again and was diagnosed with typhoid fever. He lingered on, his symptoms relapsing and remitting for many days. Wilbur died, at age 45, at the Wright family home on May 30.</p>
</blockquote>
<p>These were some of the most brilliant minds we had, and they were each nearly unable to fulfil even a tiny fraction of their potential. We should ask how much more each of them could have accomplished, but also how much we’ve lost from would-be inventors unable to find even a month of genuine free time with which to pursue their dreams. And of course, how many have been effectively barred from research by poverty or discrimination.</p>
<p>What hits me hardest is not the material loss, but the squandering of human spirit. As <a target="_blank" rel="noopener" href="https://vimeo.com/115154289">Bret Victor once explained</a>:</p>
<blockquote>
<p>We recognize that a dog has to be allowed the full free expression of its entire range of capabilities. Sticking him in a cage or constraining his range of experience, you’re not letting him do all the things that dogs can do. And this is exactly what we’ve done to ourselves.</p>
</blockquote>
<p>And so the stories above strike me not even as tragedies, but as something more inhumane.</p>
<p>My greatest fear is that intelligent life will arrive on earth. It won’t be an invasion, or colonization, or anything horrible. They’ll just sit us down, and ask about the lives of our heroes.</p>
<p>We’ll proudly tell them about this guy Wilbur Wright. How he and his brother invented a machine to fly in the sky as gods. We’ll tell them about our culture of research and innovation, and how Wilbur, self-taught engineer from Ohio, changed the entire world.</p>
<p>And then we’ll have to explain how gruesomely we murdered him.</p>
<p>Not with sticks and stones, but with a barrage of patent lawsuits. We will have to tell the aliens how we used this great system of socially legitimate torture to slowly wear him down over the years.</p>
<p>We will tell them how in the end, poor brilliant Wilbur became old and tired and incapable of producing anything beautiful ever again.</p>
<p>I do not think they will forgive us. I am not sure we should forgive ourselves.</p>
<hr>
<p><strong>See Also</strong><br><a target="_blank" rel="noopener" href="https://guzey.com/patronage-and-research-labs/">Reviving Patronage and Revolutionary Industrial Research</a></p>
<hr>
<p><em>Yes, I understand that Wilbur also sued people. I’m not claiming that he was a good person. My point is that in a humane world, no part of this story would even be possible.</em></p>
 
    </div></div>]]>
            </description>
            <link>https://applieddivinitystudies.com/murder-of-wilbur/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303289</guid>
            <pubDate>Fri, 04 Dec 2020 15:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Motivate Myself Everyday]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303279">thread link</a>) | @phongduong
<br/>
December 4, 2020 | https://phongduong.dev/blog/motivate-myself-everyday/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/motivate-myself-everyday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Every day I get up, I find it hard to keep up the momentum. Things don't happen as I expected. When I publish a piece of content, I expect many people would consume it. But it doesn't. Although it's fun to create content and express my creativity, I'm sometimes frustrated because it doesn't get any engagement.</p>
<p>I have to motivate myself to keep going. I have watched an anime series recently. It's Run with the Wind. The series is about a group of 10 college students who are trying to take part in a marathon contest. They don't have any experience in running and have to run 5km in 16 minutes to meet the qualification. After all, they meet the qualification and take part in the contest. They get in the top 10.</p>
<p>There are many inspiring quotes in the series. I rewatch it 3 times and will watch one more time. These quotes help to motivate me. I find myself in the series. I am doing what I like and happy with it. But I can't be happy all the time. My process is not always linear. </p>
<p>To motivate myself, I choose to consume other creator's content. I read blogs and books, watch videos and anime. While consuming content, I can have new ideas for my content. It also inspires me to keep going because if they can, me too.</p>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/motivate-myself-everyday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303279</guid>
            <pubDate>Fri, 04 Dec 2020 15:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gumroad vs. Amazon KDP – Which Is Better for Authors?]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303244">thread link</a>) | @tagawa
<br/>
December 4, 2020 | https://www.writerontheside.com/gumroad-vs-amazon-kdp/ | <a href="https://web.archive.org/web/*/https://www.writerontheside.com/gumroad-vs-amazon-kdp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><main id="genesis-content"><article aria-label="Gumroad vs. Amazon KDP – Which is Better for Authors?"><div>
<figure><img loading="lazy" width="1024" height="576" src="https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-1024x576.png" alt="Gumroad vs Amazon KDP - Which is better for Authors" srcset="https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-1024x576.png 1024w, https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-300x169.png 300w, https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-768x432.png 768w, https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-1536x864.png 1536w, https://www.writerontheside.com/wp-content/uploads/2020/07/Gumroad-vs-Amazon-KDP-2048x1152.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>For authors, deciding between Gumroad vs. Amazon KDP is not always a straightforward answer. </p>



<p>I’ve been a huge advocate of Amazon KDP (Kindle Direct Publishing) for several years now, and most of my books are published on that platform. </p>



<p>However, I decided to self publish my latest book on Gumroad, and I wanted to share my thoughts about which one I think is best for authors.</p>



<p>I have also gathered some insights from other authors who have used one or both platforms.</p>







<h2>Gumroad vs. Amazon KDP: Quick Summary</h2>



<p>This is a <em>really </em>long post (3,900+ words, which will take you around 17 minutes to read), so here’s the TL;DR version if you don’t have a lot of time:</p>



<p>Both Amazon and Gumroad have some advantages and disadvantages for authors. And what works best depends on your objective and on your current situation.</p>



<p>If you want to <strong>maximize profits</strong>, already have a <strong>fairly large audience</strong>, and <strong>have the time and energy</strong> to direct traffic to your book, then <strong>Gumroad </strong>is the best option for you.</p>



<p>If you care more about <strong>brand value</strong>, have a <strong>smaller audience</strong>, and want to <strong>rely more on organic traffic/ reach</strong> for readers to find your book, then <strong>Amazon KDP</strong> is the best option for you.</p>



<p>You can, of course, publish on both platforms at the same time, but there are some considerations that you have to factor in.</p>



<p>Here are some more details about the advantages and disadvantages of each, and which one wins in each category.</p>







<h2>Gumroad vs. Amazon KDP: Fees &amp; Royalties</h2>



<p>Let’s start with a foundational question. What are the fees you have to pay and royalties (i.e. profit margins) you get on each platform?</p>



<h3>Amazon KDP</h3>



<p>With Amazon, you can publish your book for free (i.e. there are no listing fees), and there are no monthly fees. Your royalties fall between <strong>35%</strong> and <strong>70%</strong>, depending on the book’s price point. </p>



<p>If you list your book’s price between <strong>$2.99</strong> and <strong>$9.99</strong>, then you’ll get a <strong>70%</strong> royalty (i.e., your profit is 70% of the book’s price point).</p>



<p>However, if you list your book’s price between<strong> $0.99 </strong>(lowest price allowed) and <strong>$2.99 </strong>or between<strong> $9.99</strong> and <strong>$200.00</strong> (highest price allowed), then you’ll get a <strong>35%</strong> royalty (i.e., you only get paid 35% of the book’s price point).</p>



<p>In other words, Amazon tries to incentivize you to price your book between <strong>$2.99 and $9.99</strong> because that’s a sweet spot for sales. </p>



<p><em>Note: This applies to the ebook (i.e. Kindle) version of your book’s price point. The paperback version on Amazon has a different royalty structure.</em><br></p>



<h3>Gumroad</h3>



<p>With Gumroad, you have two options to publish your book. You can do it for free (i.e. no monthly fees), or you can upgrade to a premium account that costs you $10 per month (or $108 per year).</p>



<p>Upgrading to a premium account gives you a few advantages that you can read about <a href="https://gumroad.com/features/pricing">here</a>.</p>



<p>In terms of fees, you pay an <strong>8.5% + $0.30</strong> fee per sale on the free account, and <strong>3.5% + $0.30</strong> fee per sale on the premium account.</p>



<p>In other words, your royalty will be between approximately <strong>91% and 96%</strong> of your book’s price point (which is much higher than Amazon’s <strong>35% to 70%</strong>). </p>



<p>So Gumroad definitely wins here.</p>



<p>Another important factor that plays in Gumroad’s favor is “price anchoring.” Given that Amazon persuades authors to price their book between $2.99 and $9.99, most books are listed within that range, which makes it’s very hard to justify selling a $47 Kindle ebook.</p>



<p>Gumroad doesn’t have that problem.</p>



<h4><strong>Winner</strong>: <strong>Gumroad</strong></h4>







<h2>Gumroad vs. Amazon KDP: eBook Formats</h2>



<p>When you submit your ebook to Amazon, you have to meet their specific guidelines because Amazon converts your book into their proprietary ebook file format. You can format your book using Microsoft Word or by using Amazon’s own tool called “<a href="https://www.amazon.com/Kindle-Create/b?ie=UTF8&amp;node=18292298011">Kindle Create</a>.” </p>



<p>You can also submit other formats, such as PDF, but those end up causing some formatting challenges when they’re converted to Kindle-specific files.</p>



<p>The way your readers read your Kindle book is either on a Kindle device (e.g., a Kindle Fire Tablet or a Kindle Paperwhite) or on a free Kindle app installed on any other device (e.g., iPhone, iPad, Android phone, computer, etc.). </p>



<p>When you submit your ebook to Gumroad, you basically upload whatever file format your readers will end up downloading. You can also upload multiple files of the same book.</p>



<p>For example, you might want to offer your book in PDF format only.  Or you might want to offer it in PDF, MOBI, ePUB, and HTML. Gumroad basically acts as a document repository and you can upload the same files that you want your customers to view.</p>



<p><em>Note: If you want your Gumroad customers to be able to read your book on their Kindle devices, then make sure you upload the Kindle-friendly MOBI version of your book.</em></p>



<p>Gumroad wins in this category because of the file format flexibility. </p>



<p>For example, I’m writing a new book about <a href="https://www.thecouchmanager.com/home-office-book-launch">how to design a home office</a> and because it’s picture heavy (and the layout needs tweaking) the best format that will work for me is PDF.</p>



<p>And because I wouldn’t be able to do replicate that layout in Amazon without some serious design challenges, I’ll be selling that book exclusively on Gumroad.</p>



<h4>Winner: Gumroad</h4>







<h2>Gumroad vs. Amazon KDP: Paperback Copies</h2>



<p>Most authors want to (and probably should) sell paperback copies of their book. That’s because some readers still prefer to hold physical copies of books, and it would be a mistake to ignore that potential revenue stream.</p>



<p>Here’s a recent screenshot of revenue from my books. Notice the difference between the ebook and paperback royalties.</p>



<figure><img loading="lazy" width="871" height="290" src="https://www.writerontheside.com/wp-content/uploads/2020/07/image.png" alt="Amazon ebook royalty vs. paperback royalty" srcset="https://www.writerontheside.com/wp-content/uploads/2020/07/image.png 871w, https://www.writerontheside.com/wp-content/uploads/2020/07/image-300x100.png 300w, https://www.writerontheside.com/wp-content/uploads/2020/07/image-768x256.png 768w" sizes="(max-width: 871px) 100vw, 871px"></figure>



<p>With Amazon, creating a paperback version of your book is very simple. You’ll need to convert your manuscript to a print-ready file (easy to do within Amazon KDP) and then upload a print-ready cover (that you’ll need to have designed).</p>



<p>After you publish, Amazon then simply prints your book as soon as someone orders it (called POD, which stands for print-on-demand) and ships it to them. So you don’t have to worry about inventory or paying for print copies upfront.</p>



<p>Gumroad unfortunately does not provide any of those print-on-demand capabilities, which means that you will not be able to sell any paperback copies of your book.</p>



<p>The only potential alternative is to do this manually by pre-printing copies of your book yourself and then physically sell &amp; ship them when someone makes an order (not very practical, and not very cheap). </p>



<h4>Winner: Amazon KDP</h4>







<h2>Gumroad vs. Amazon KDP: Organic Reach</h2>



<p>Organic reach is about how people find your book and how effectively each platform recommends it. </p>



<p>With Amazon, over <strong>95%</strong> of my book sales come from organic sales. In other words, it’s mostly from Amazon’s own algorithm. I don’t get a lot of sales from my own efforts of directing people to buy my books. </p>



<p><em>Note: Amazon does not disclose any data about statistics or traffic sources, so I couldn’t give you exact numbers. However, I do track my own sales channels through affiliate links to my books, and that’s why I can estimate organic sales at around 95%.</em></p>



<p>With Gumroad, it’s almost the exact opposite. For sales of my last book, only around <strong>7%</strong> of the sales came in from Gumroad’s organic reach, and <strong>93%</strong> came from my own direct efforts, so I have to do a lot more marketing to sell those books. </p>



<p>So for me, Amazon wins because of three reasons. </p>



<p>First, I can depend a bit more on sales as passive income and I don’t have to constantly market my books.</p>



<p>Second, the volume of readers and traffic on Amazon is much higher than the volume on Gumroad.</p>



<p>Third, Amazon has a sophisticated search algorithm that recommends books to readers based on recent events or on their search/ purchase history.</p>



<p>And all three factors converged for me during the COVID-19 pandemic.</p>



<p>I wrote a book around 6 years ago (called “<em><a href="https://amzn.to/2EAeP7I">Influencing Virtual Teams</a></em>“) and it was making around $200 a month. Then, during the pandemic, there was a sudden spike in interest about remote work, and the book ended up making 10X that amount in a couple of those months. </p>



<p>Although Amazon wins in this category, I do have to give Gumroad two advantages here. First, they are open about their sales sources, so I can get much better statistics. And second, I made over <a href="https://www.writerontheside.com/final-results-3294usd-in-30-days-from-the-book-part-9/">$3,294 in sales in one month</a> from one book, so the higher price-point of the book could pay off for you.</p>



<h4>Winner: Amazon KDP</h4>







<h2>Gumroad vs. Amazon KDP: Reader Emails</h2>



<p>An essential feature for authors is the ability to collect emails from their customers. There are many reasons why, but in summary, it’s to be able to stay in touch with readers and build a relationship with them so you can sell other books (or products/ services) down the line. </p>



<p>Amazon does not give authors the capability to view any of those email addresses. In fact, authors have absolutely no visibility about who their customers are. There is a workaround, where authors can offer customers a freebie in exchange for their email address, but that takes <a href="https://www.writerontheside.com/how-to-collect-email-addresses-from-readers/">a bit of effort to set up</a>, and you’ll still not capture 100% of your customers.</p>



<p>Gumroad not only gives you your customers’ information (including email addresses), but it also allows you to communicate with them through Gumroad’s email messaging system directly. You can even export those email addresses and import them into your email management system (such as <a href="https://www.writerontheside.com/aweber" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">AWeber</a>) if you’d like to. So it’s a no brainer that Gumroad wins here.</p>











<h2>Gumroad vs Amazon KDP: Listing Your Book for Free</h2>



<p>Some authors like the idea of offering one or more of their books for free to help them with branding and even making <a href="https://www.writerontheside.com/ep-025-getting-200x-more-downloads-by-offering-your-book-for-free/">money indirectly</a>. </p>



<p>With Amazon, you can list your book for free on a limited basis only (for 5 days every 90 day period if you’re enrolled in <a href="https://kdp.amazon.com/en_US/select" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">KDP Select</a>).  You can also list it as a “Permanently Free” book, but that’s not a simple process.</p>



<p>However, if you are able to list your book for free on Amazon, you’ll get the advantage of the high volume of traffic. I listed one of my books …</p></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.writerontheside.com/gumroad-vs-amazon-kdp/">https://www.writerontheside.com/gumroad-vs-amazon-kdp/</a></em></p>]]>
            </description>
            <link>https://www.writerontheside.com/gumroad-vs-amazon-kdp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303244</guid>
            <pubDate>Fri, 04 Dec 2020 15:24:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Indian is an Indian phone?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25303208">thread link</a>) | @coolsnakeman
<br/>
December 4, 2020 | https://restofworld.org/2020/xiaomi-made-in-india/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/xiaomi-made-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he Indiranagar 100-Feet Road is the commercial heart of India’s technology capital Bangalore, lined with international brand stores, bars, restaurants, and food courts. Owning retail space here, alongside consumer giant Reliance Digital and German footwear brand Puma, is a marker of success for brands breaking into mainstream consciousness. Chinese smartphone maker Xiaomi’s two-story, 6,000-square-foot flagship store is right at the heart of the district. Behind its saffron frontage is a showcase for its as-yet-unlaunched handsets, televisions, laptops, fitness bands, e-scooters, and water purifiers.&nbsp;</p>



<p>In June, the store had a complete facelift. A new logo was put on the front of the building that read: “Made In India.” By August, the interior had been decorated with tricolored balloons in the green, white, and orange of the Indian flag. Along the walls, a company timeline showed the history of Xiaomi’s manufacturing operations in India. Mentions of the company’s heritage — it was founded in Beijing in 2010 — disappeared. <a href="https://www.indiatoday.in/india/story/xiaomi-puts-up-made-in-india-banner-outside-stores-to-counter-boycott-china-campaign-1692633-2020-06-25">Hundreds</a> of the company’s stores across the country underwent the same transformation. “Super proud to share that majority of our TVs are #MadeInIndia! We employ thousands of team members across our India factories #ProudIndian,” <a href="https://twitter.com/manukumarjain/status/1276052185638252544?s=20">tweeted</a> Manu Kumar Jain, the India head of Xiaomi.&nbsp;</p>



<p>Anti-China sentiment had already been rising in India’s heartlands before a skirmish in June in a disputed Himalayan border region left 20 Indian soldiers dead. Nationalists started <a href="https://www.thequint.com/news/india/bharat-mata-and-chinese-tvs-a-tale-of-boycotting-goods-from-china">smashing</a> Chinese-made televisions; one minister called for shutting down <a href="https://economictimes.indiatimes.com/news/politics-and-nation/restaurants-and-hotels-that-sell-chinese-food-should-be-shut-down-union-minister-ramdas-athawale/videoshow/76442910.cms">Chinese restaurants</a>. A few weeks after the skirmish, the Indian government banned TikTok, along with hundreds of Chinese apps, and, in August, passed an <a href="https://www.ft.com/content/55642551-f6e8-4f9d-b5ba-a12d2fc26ef9">unofficial</a> order to phase out dependence on Chinese telecom equipment, including 5G networks. Prime Minister Narendra Modi made a special appearance on television encouraging Indians to be <a href="https://www.youtube.com/watch?v=0xmx92Q_kQ4">“vocal” in their support for “local” products</a>, creating the #vocalforlocal slogan.&nbsp;</p>



<p>Chinese smartphone makers like Oppo, Vivo, and Xiaomi — who made up 81% of the Indian market — were left in a precarious position after the clash. Right-wing groups gathered outside Oppo’s factory in the outskirts of Delhi and <a href="https://www.newindianexpress.com/nation/2020/jun/20/anti-china-demonstration-held-outside-oppo-factory-in-greater-noida-32-protesters-booked-2159224.html">burnt effigies of Xi Jinping</a>, as they demanded that the plant be closed. Some companies battened down the hatches, <a href="https://economictimes.indiatimes.com/industry/cons-products/electronics/chinese-brands-endorsers-may-go-slow-on-promotions-some-pull-out-ads-some-plan-to-play-up-make-in-india-credentials/articleshow/76429828.cms?from=mdr">suspending their prime-time advertising campaigns</a>. Vivo <a href="https://sports.ndtv.com/cricket/ipl-title-sponsor-vivo-pulls-out-of-tournament-this-year-amid-row-2274036">pulled out</a> as the title sponsor of the country’s biggest sporting event, the Indian Premier League cricket competition, after an aggressive campaign against it on social media. Stray protests took place outside some Xiaomi stores, as threats of vandalism loomed large and mobile shipments from China were <a href="https://telecom.economictimes.indiatimes.com/news/smartphone-makers-in-panic-mode-over-stranded-shipments/76536342">stalled for manual inspection at Indian ports</a>.</p>



<p>But while other Chinese brands retreated from the limelight, Xiaomi pursued a unique — and potentially high-risk — strategy: It presented itself as not being Chinese after all, but Indian. Jain, its figurehead in India, took to television, newspapers, and social media to talk up the company’s all-Indian local leadership team and the thousands of jobs it had created in manufacturing and retail. “We are more Indian than anyone else,” Jain told <a href="https://twitter.com/manukumarjain/status/1274316181235568645?lang=en">CNBC-TV18</a>. The company even donated money to the families of soldiers “<a href="https://www.mi.com/in/service/support/crpffund.html">martyred</a>” in Kashmir.</p>



<p>Jain has proven adept in using social media and his own personal brand to launder Xiaomi’s origins. But the company faces growing pressure in an unstable political environment. Narendra Modi’s government is once again proclaiming its desire to bring manufacturing back to India, offering <a href="https://www.bloomberg.com/news/articles/2020-09-10/india-mulls-23-billion-package-to-lure-global-manufacturers?sref=QYWxDQ1o">lavish incentives</a> for export-led manufacturers, which may help once-moribund local phone brands. Xiaomi has indeed moved some of its production onshore, but the core components of its devices are still made in China. With the country’s nationalist surge unlikely to end soon, Jain and Xiaomi will eventually have to face up to the question: How Indian is Indian enough?</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-842778188-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-842778188-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-842778188-400x285.jpg 400w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-842778188-600x428.jpg 600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-842778188-1000x713.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-842778188-1600x1140.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-842778188-2800x1995.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Manu Jain speaks during the launch of the Xiaomi Mi A1 smartphone in New Delhi in 2017.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Sajjad Hussain/AFP/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p><strong>Jain, 39, “is</strong> the Indian middle-class dream personified,” in the words of a former colleague. As a child, he lived in Meerut in northern India, alongside 150 members of his extended family, in an isolated housing compound inside a military quarters built by his great grandfather. “I had never even been exposed to the outside world,” Jain says.</p>



<p>After studying at the prestigious Indian Institute of Technology and at the Indian Institute of Management business school, he joined the global consulting firm McKinsey.</p>



<p>Jain’s early career in technology was successful but low profile. He quit McKinsey in 2012 to launch e-commerce portal Jabong.com, which was sold to SoftBank-backed (now Walmart-owned) rival Flipkart for $70 million in 2016. By then, Jain had already moved on to <a href="https://www.thehindubusinessline.com/companies/Jabong%E2%80%99s-former-MD-switches-attention-to-wearable-smart-devices/article20718785.ece#">start a short-lived wearables company</a>. In 2014, he became Xiaomi India’s first hire, recruited by Hugo Barra, the former Android executive who had been tasked with expanding Xiaomi outside China.</p>



<p>At the time, the market was dominated by Samsung and by Indian brands, such as Micromax, Karbonn, and Lava, whose model was to import unbranded Chinese products and sell them as their own. “There was no R&amp;D team, no product team, and no product design. They would basically just buy those products and sell them here,” says Jain.</p>



<p>Xiaomi’s entry was not just about cutting out the middleman. In China, Xiaomi, along with Oppo and Vivo, had evolved beyond their origins in cheap but unreliable products and were now designing and producing higher-quality but affordable devices that were well adapted to a market like India, where disposable income was increasing in step with demand for mobile data.</p>



<p>Jain began his tenure at Xiaomi with a big gamble. In 2014, only 6% of Indian retail sales happened through e-commerce, but Jain launched Xiaomi as an online-only brand, replicating an approach that had worked in China.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-40x39.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-400x394.png 400w, https://restofworld.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-600x592.png 600w, https://restofworld.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.54.13-AM-1000x986.png 1000w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Xiaomi dominates the Indian market.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Data: Counterpoint Research</span>
			</figcaption>
		</figure>


<p>“Most people said, You are going to fail. You are going to be a disaster,” he said during a 2017 TED Talk. “Most smartphone brands until then focused on building large distribution networks, and we didn’t do that.”&nbsp;</p>



<p>To drum up interest, the company organized flash sales and made sure the phones sold out quickly, to enhance their perceived popularity, a technique known as “hunger marketing.” They spent relatively little on advertising, instead relying on their users to become evangelists for the brand.</p>



<p>Xiaomi’s phones seemed to hit a sweet spot of pricing and specifications. “Their phones were undercutting basically every other device on the market by half,” says Harish Jonalaggada, Asia editor at mobile review portal Android Central. The company launched phones for $180, with high specs like 64GB storage and 4GB RAM that were previously seen on only devices over $400.</p>



<p>The rush of orders for the launch of the Mi 3 model crashed the Indian e-commerce website Flipkart in the summer of 2014.&nbsp;</p>



<p>But Xiaomi’s success wasn’t just about its hardware. Under Jain’s leadership, the company tailored its Android-based operating system, MIUI, to the local market. One feature, Smart SMS, identifies the cluttered text messages that Indian Railways sends to its customers and extracts booking information, turning it into a ticket-like document. Xiaomi was the first company in India to incorporate a popular “dual app” feature that allows users to run duplicate versions of the same app — such as WhatsApp — on the same phone.</p>



<p>As online channels exploded in popularity and started to become saturated, Xiaomi shifted direction. In 2017, the company dramatically expanded its physical retail presence, pushing deep into rural areas. In October 2018, it set a mark recognized by the Guinness World Records by opening <a href="https://gadgets.ndtv.com/mobiles/news/xiaomi-opens-over-500-retail-stores-in-a-single-day-in-rural-india-1950375">500 stores</a> in a day. “One of the reasons Xiaomi has done well is — from both a product perspective and channel perspective — they made decisions unique to the India market,” says a Shanghai-based financial analyst covering Xiaomi who requested to remain anonymous, citing geopolitical tensions. In September, Xiaomi piloted its unique <a href="https://gadgets.ndtv.com/mobiles/news/xiaomi-mi-store-on-wheels-mobile-stores-moving-trucks-launch-india-villages-watch-xiaomi-2298745">Mi Store on Wheels</a>, a van that sells everything from trimmers to phones throughout the hinterlands of India.&nbsp;</p>



<p>This sensitivity to the local market is in no small part due to the unusual autonomy that Jain has had in running Xiaomi in India. The Indian operations of Oppo and Vivo are both run by Chinese nationals. “Chinese companies are often very inward-looking and wouldn’t devolve the power in the same way Xiaomi has,” the analyst says.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-954020916-40x60.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-954020916-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-954020916-400x600.jpg 400w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-954020916-600x900.jpg 600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-954020916-1000x1499.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-954020916-1600x2399.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-954020916-2800x4198.jpg 2800w, " sizes="(max-width: 640px) 100vw, 300px" alt="Lei Jun, Xiaomi’s founder and CEO.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"> Giulia Marchi/Bloomberg/Getty Images</span>
			</figcaption>
		</figure>


<p>That unusual autonomy stems from the relationship that Jain has built with Lei Jun, Xiaomi’s founder and CEO, a self-confessed acolyte of Apple founder Steve Jobs. Jain says that, when he and Jun first met, “both of us were wearing black T-shirts and denim jeans. It was cool.”</p>



<p>One former employee, who worked closely with Jain while setting up the India operations, told <em>Rest of World</em>: “Over a period of time when Xiaomi India was growing, Manu was able to earn Jun’s trust, which is actually very hard. … Manu’s bets on the Indian market proved him right. And so, after a while, the CEO decided to just let Manu make his own decisions, which is very rare.”&nbsp;</p>



<p>By 2019, Xiaomi was the largest smartphone brand in India, shifting 100 million units, according to data from the International Data Corporation. The company has expanded beyond mobile and offers everything from luggage to beard trimmers. Its rise came at the cost of Indian brands, whose market share fell from close to 50% to just 13% by the end of 2018, according to market intelligence firm Counterpoint Research.&nbsp;</p>



<p>Jun and Jain share a love of the limelight. Jun is a <a href="https://www.nytimes.com/2013/06/05/business/global/in-china-an-empire-built-by-aping-apple.html">social media celebrity</a> in China, posting mobile teasers and specifications to his 5 million …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/xiaomi-made-in-india/">https://restofworld.org/2020/xiaomi-made-in-india/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/xiaomi-made-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303208</guid>
            <pubDate>Fri, 04 Dec 2020 15:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Gentle Introduction to Power Flow]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303072">thread link</a>) | @eperim
<br/>
December 4, 2020 | https://invenia.github.io/blog/2020/12/04/pf-intro/ | <a href="https://web.archive.org/web/*/https://invenia.github.io/blog/2020/12/04/pf-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>04 Dec 2020</span></p>
  <p>Although governed by simple physical laws, power grids are among the most complex human-made systems.
The main source of the complexity is the large number of components of the power systems that interact with each other: one needs to maintain a balance between power injections and withdrawals while satisfying certain physical, economic, and environmental conditions.
For instance, a central task of daily planning and operations of electricity grid operators<sup id="fnref:Tong04" role="doc-noteref"><a href="#fn:Tong04">1</a></sup> is to dispatch generation in order to meet demand at minimum cost, while respecting reliability and security constraints.
These tasks require solving a challenging constrained optimization problem, often referred to as some form of optimal power flow (OPF).<sup id="fnref:Cain12" role="doc-noteref"><a href="#fn:Cain12">2</a></sup></p>

<div><p>In a series of two blog posts, we are going to discuss the basics of power flow and optimal power flow problems.
In this first post, we focus on the most important component of OPF: the power flow (PF) equations.
For this, first we introduce some basic definitions of power grids and AC circuits, then we define the power flow problem.
</p></div>

<p><img src="https://invenia.github.io/blog/public/images/us_power_grid.jpg" alt="us_power_grid">
Figure 1. Complexity of electricity grids: the electric power transmission grid of the United States (source: FEMA and <a href="https://en.wikipedia.org/wiki/North_American_power_transmission_grid">Wikipedia</a>).</p>


<h2 id="power-grids-as-graphs">Power grids as graphs</h2>

<p>Power grids are networks that include two main components: buses that represent important locations of the grid (e.g. generation points, load points, substations) and transmission (or distribution) lines that connect these buses.
It is pretty straightforward, therefore, to look at power grid networks as graphs: buses and transmission lines can be represented by nodes and edges of a corresponding graph.
There are two equivalent graph models that can be used to derive the basic power flow equations<sup id="fnref:Low14" role="doc-noteref"><a href="#fn:Low14">3</a></sup>:</p>
<ul>
  <li>directed graph representation (left panel of Figure 2): \(\mathbb{G}_{D}(\mathcal{N}, \mathcal{E})\);</li>
  <li>undirected graph representation (right panel of Figure 2): \(\mathbb{G}_{U}(\mathcal{N}, \mathcal{E} \cup \mathcal{E}^{R})\),</li>
</ul>

<div><p>where \(\mathcal{N}\), \(\mathcal{E} \subseteq \mathcal{N} \times \mathcal{N}\) and \(\mathcal{E}^{R} \subseteq \mathcal{N} \times \mathcal{N}\) denote the set of nodes (buses), and the forward and reverse orientations of directed edges (branches) of the graph, respectively.
</p></div>

<p><img src="https://invenia.github.io/blog/public/images/power_grid_graphs.png" alt="power_grid_graphs">
Figure 2. Directed graph representation of synthetic grid 14-ieee (left) and undirected graph representation of synthetic grid 30-ieee (right). Red and blue circles denote generator and load buses, respectively.</p>


<h2 id="complex-power-in-ac-circuits">Complex power in AC circuits</h2>

<p>Power can be transmitted more efficiently at high voltages as high <a href="https://en.wikipedia.org/wiki/Voltage">voltage</a> (or equivalently, low <a href="https://en.wikipedia.org/wiki/Electric_current">current</a>) reduces the loss of power due to its dissipation on transmission lines.
Power grids generally use <a href="https://en.wikipedia.org/wiki/Alternating_current">alternating current</a> (AC) since the AC voltage can be altered (from high to low) easily via transformers.
Therefore, we start with some notation and definitions for AC circuits.</p>

<p>The most important characteristics of AC circuits is that, unlike in <a href="https://en.wikipedia.org/wiki/Direct_current">direct current</a> (DC) circuits, the currents and voltages are not constant in time: both their <em>magnitude</em> and <em>direction</em> vary periodically.
Because of several technical reasons (like low losses and disturbances), power generators use sinusoidal alternating quantities that can be straightforwardly modeled by <a href="https://en.wikipedia.org/wiki/Complex_number%7D%7Bcomplex%20numbers">complex numbers</a>.</p>

<p>We will consistently use capital and small letters to denote complex and real-valued quantities, respectively.
For instance, let us consider two buses, \(i, j \in \mathcal{N}\), that are directly connected by a transmission line \((i, j) \in \mathcal{E}\).
The <a href="https://en.wikipedia.org/wiki/AC_power">complex power</a> flowing from bus \(i\) to bus \(j\) is denoted by \(S_{ij}\) and it can be decomposed into its active (\(p_{ij}\)) and reactive (\(q_{ij}\)) components:</p><p>

\[\begin{equation}
S_{ij} = p_{ij} + \mathrm{j}q_{ij},
\end{equation}\]

</p><p>where \(\mathrm{j} = \sqrt{-1}\).
The complex power flow can be expressed as the product of the complex voltage at bus \(i\), \(V_{i}\) and the complex conjugate of the current flowing between the buses, \(I_{ij}^{*}\):</p><p>

\[\begin{equation}
S_{ij} = V_{i}I_{ij}^{*},
\label{power_flow}
\end{equation}\]

</p><p>It is well known that transmission lines have power losses due to their <a href="https://en.wikipedia.org/wiki/Electrical_resistance_and_conductance">resistance</a> (\(r_{ij}\)), which is a measure of the opposition to the flow of the current.
For AC-circuits, a dynamic effect caused by the line <a href="https://en.wikipedia.org/wiki/Electrical_reactance">reactance</a> (\(x_{ij}\)) also plays a role.
Unlike resistance, reactance does not cause any loss of power but has a delayed effect by storing and later returning power to the circuit.
The effect of resistance and reactance together can be represented by a single complex quantity, the <a href="https://en.wikipedia.org/wiki/Electrical_impedance">impedance</a>: \(Z_{ij} = r_{ij} + \mathrm{j}x_{ij}\). 
Another useful complex quantity is the <a href="https://en.wikipedia.org/wiki/Admittance">admittance</a>, which is the reciprocal of the impedance: \(Y_{ij} = \frac{1}{Z_{ij}}\).
Similarly to the impedance, the admittance can be also decomposed into its real, <a href="https://en.wikipedia.org/wiki/Electrical_resistance_and_conductance">conductance</a> (\(g_{ij}\)), and imaginary, <a href="https://en.wikipedia.org/wiki/Susceptance">susceptance</a> (\(b_{ij}\)), components: \(Y_{ij} = g_{ij} + \mathrm{j}b_{ij}\).</p>

<p>Therefore, the current can be written as a function of the line voltage drop and the admittance between the two buses, which is an alternative form of <a href="https://en.wikipedia.org/wiki/Ohm%27s_law">Ohm’s law</a>:</p><p>

\[\begin{equation}
I_{ij} = Y_{ij}(V_{i} - V_{j}).
\end{equation}\]

</p><p>Replacing the above expression for the current in the power flow equation (eq. \(\ref{power_flow}\)), we get</p><p>

\[\begin{equation}
S_{ij} = Y_{ij}^{*}V_{i}V_{i}^{*} - Y_{ij}^{*}V_{i}V_{j}^{*} = Y_{ij}^{*} \left( |V_{i}|^{2} - V_{i}V_{j}^{*} \right).
\end{equation}\]

</p><p>The above power flow equation can be expressed by using the polar form of voltage, i.e. \(V_{i} = v_{i}e^{\mathrm{j} \delta_{i}} = v_{i}(\cos\delta_{i} + \mathrm{j}\sin\delta_{i})\) (where \(v_{i}\) and \(\delta_{i}\) are the voltage magnitude and angle of bus \(i\), respectively), and the admittance components:</p><p>

\[\begin{equation}
S_{ij} = \left(g_{ij} - \mathrm{j}b_{ij}\right) \left(v_{i}^{2} - v_{i}v_{j}\left(\cos\delta_{ij} + \mathrm{j}\sin\delta_{ij}\right)\right),
\end{equation}\]

</p><p>where for brevity we introduced the voltage angle difference \(\delta_{ij} = \delta_{i} - \delta_{j}\).
Similarly, using a simple algebraic identity of \(g_{ij} - \mathrm{j}b_{ij} = \frac{g_{ij}^{2} + b_{ij}^{2}}{g_{ij} + \mathrm{j}b_{ij}} = \frac{|Y_{ij}|^{2}}{Y_{ij}} = \frac{Z_{ij}}{|Z_{ij}|^{2}} = \frac{r_{ij} + \mathrm{j}x_{ij}}{r_{ij}^{2} + x_{ij}^{2}}\), the impedance components-based expression has the following form:</p><p>

\[\begin{equation}
    S_{ij} = \frac{r_{ij} + \mathrm{j}x_{ij}}{r_{ij}^{2} + x_{ij}^{2}} \left( v_{i}^{2} - v_{i}v_{j}\left(\cos\delta_{ij} + \mathrm{j}\sin\delta_{ij}\right)\right).
\end{equation}\]

</p><p>Finally, the corresponding real equations can be written as</p><p>

\[\begin{equation}
\left\{
    \begin{aligned}
        p_{ij} &amp; = g_{ij} \left( v_{i}^{2} - v_{i} v_{j} \cos\delta_{ij} \right) - b_{ij} \left( v_{i} v_{j} \sin\delta_{ij} \right) \\
        q_{ij} &amp; = b_{ij} \left( -v_{i}^{2} + v_{i} v_{j} \cos\delta_{ij} \right) - g_{ij} \left( v_{i} v_{j} \sin\delta_{ij} \right), \\
    \end{aligned}
\right.
\label{power_flow_y}
\end{equation}\]

</p><p>and</p><p>

\[\begin{equation}
\left\{
    \begin{aligned}
        p_{ij} &amp; = \frac{1}{r_{ij}^{2} + x_{ij}^{2}} \left[ r_{ij} \left( v_{i}^{2} - v_{i} v_{j} \cos\delta_{ij} \right) + x_{ij} \left( v_{i} v_{j} \sin\delta_{ij} \right) \right] \\
        q_{ij} &amp; = \frac{1}{r_{ij}^{2} + x_{ij}^{2}} \left[ x_{ij} \left( v_{i}^{2} - v_{i} v_{j} \cos\delta_{ij} \right) + r_{ij} \left( v_{i} v_{j} \sin\delta_{ij} \right) \right]. \\
    \end{aligned}
\right.
\label{power_flow_z}
\end{equation}\]

</p><h2 id="power-flow-models">Power flow models</h2>

<p>In the previous section we presented the power flow between two connected buses and established a relationship between complex power flow and complex voltages.
In power flow problems, the entire power grid is considered and the task is to calculate certain quantities based on some other specified ones.
There are two equivalent power flow models depending on the graph model used: the bus injection model (based on the undirected graph representation) and the branch flow model (based on the directed graph representation).
First, we introduce the basic formulations.
Then, we show the most widely used technique to solve power flow problems.
Finally, we extend the basic equations and derive more sophisticated models including additional components for real power grids.</p>

<h3 id="bus-injection-model">Bus injection model</h3>

<p>The bus injection model (BIM) uses the undirected graph model of the power grid, \(\mathbb{G}_{U}\).
For each bus \(i\), we denote by \(\mathcal{N}_{i} \subset \mathcal{N}\) the set of buses directly connected to bus \(i\).
Also, for each bus we introduce the following quantities<sup id="fnref:Low14:1" role="doc-noteref"><a href="#fn:Low14">3</a></sup><sup id="fnref:Wood14" role="doc-noteref"><a href="#fn:Wood14">4</a></sup> (Figure 3):</p>
<ul>
  <li>\(S_{i}^{\mathrm{gen}}\): generated power flowing into bus \(i\).</li>
  <li>\(S_{i}^{\mathrm{load}}\): demand power or load flowing out of the bus \(i\).</li>
  <li>\(S_{i}\): net power injection at bus \(i\), i.e. \(S_{i} = S_{i}^{\mathrm{gen}} - S_{i}^{\mathrm{load}}\).</li>
  <li>\(S_{i}^{\mathrm{trans}}\): transmitted power flowing between bus \(i\) and its adjacent buses.
</li>
</ul>

<p><img src="https://invenia.github.io/blog/public/images/power_quantities.png" alt="...">
Figure 3. Power balance and quantities of a bus connected to three adjacent buses and including a single generator and a single load.</p>

<p><br>
<a href="https://en.wikipedia.org/wiki/Tellegen/%27s_theorem">Tellegen’s theorem</a> establishes a simple relationship between these power quantities:</p><p>

\[\begin{equation}
S_{i} = S_{i}^{\mathrm{gen}} - S_{i}^{\mathrm{load}} = S_{i}^{\mathrm{trans}} \ \ \ \ \forall i \in \mathcal{N}.
\label{power_balance}
\end{equation}\]

</p><p>Eq. \(\ref{power_balance}\) expresses the law of conservation of power (energy): the power injected (\(S_{i}^{\mathrm{gen}}\)) to bus \(i\) must be equal to the power going out from the bus, i.e. the sum of the withdrawn (\(S_{i}^{\mathrm{load}}\)) and transmitted power (\(S_{i}^{\mathrm{trans}}\)).
In the most basic model, a bus can represent either a generator (i.e. \(S_{i} = S_{i}^{\mathrm{gen}}\)) or a load (i.e. \(S_{i} = -S_{i}^{\mathrm{load}}\)).
For a given bus, the transmitted power can be obtained simply as a sum of the powers flowing in to and out from the bus, \(S_{i}^{\mathrm{trans}} = \sum \limits_{j \in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invenia.github.io/blog/2020/12/04/pf-intro/">https://invenia.github.io/blog/2020/12/04/pf-intro/</a></em></p>]]>
            </description>
            <link>https://invenia.github.io/blog/2020/12/04/pf-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303072</guid>
            <pubDate>Fri, 04 Dec 2020 15:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Easily send anonymous suggestions to any email address]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25302848">thread link</a>) | @fersarr
<br/>
December 4, 2020 | https://feedfeedback.com/write_anon | <a href="https://web.archive.org/web/*/https://feedfeedback.com/write_anon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="second_body">
            
            
            <p id="subtitle" data-translation_id="writeanon_h2">Send anonymous comments or suggestions to any email address</p>

            
            



            <p id="contact_at_bottom" data-translation_id="global_contact_us">Contact us at feedfeedback.app@gmail.com or use <a href="https://feedfeedback.com/feedfeedback">feedfeedback.com/feedfeedback</a></p>
        </div></div>]]>
            </description>
            <link>https://feedfeedback.com/write_anon</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302848</guid>
            <pubDate>Fri, 04 Dec 2020 14:54:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mannequin.js: An Articulated Mannequin Figure Library]]>
            </title>
            <description>
<![CDATA[
Score 149 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25302602">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://boytchev.github.io/mannequin.js/ | <a href="https://web.archive.org/web/*/https://boytchev.github.io/mannequin.js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<ul>
  <li><a href="#About">About</a></li>
  <li><a href="#Initialization">Initialization</a>
    <ul>
      <li><a href="#Minimal-program">Minimal program</a></li>
      <li><a href="#Figure-types">Figure types</a></li>
    </ul>
  </li>
  <li><a href="#Body-parts">Body parts</a>
    <ul>
      <li><a href="#Central-body-parts">Central body parts</a></li>
      <li><a href="#Upper-limbs">Upper limbs</a></li>
      <li><a href="#Lower-limbs">Lower limbs</a></li>
    </ul>
  </li>
  <li><a href="#Body-posture">Body posture</a>
    <ul>
      <li><a href="#Static-posture">Static posture</a></li>
      <li><a href="#Dynamic-posture">Dynamic posture</a></li>
    </ul>
  </li>
  <li><a href="#Other-functions">Other functions</a>
    <ul>
      <li><a href="#Custom-colors">Custom colors</a></li>
      <li><a href="#Hiding-body-parts">Hiding body parts</a></li>
      <li><a href="#Custom-body-parts">Custom body parts</a></li>
      <li><a href="#Global-position">Global position</a></li>
    </ul>
  </li>
  <li><a href="#Future-plans">Future plans</a></li>
</ul>


<p><strong>Mannequin.js</strong> is a simple library of an articulated mannequin figure. The shape of the figure
and its movements are done purely in JavaScript. The graphics is implemented in
<a href="https://threejs.org/">Three.js</a>. Click on an image to open a live demo.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-posture.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-figure-types.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-custom-body-parts.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-custom-body-parts.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-point.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-point.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-scene.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-scene.jpg" width="150"></a></p>

<p>This is the fourth incarnation of the mannequin figure. The first one was implemented
in Elica. The second one was implemented in C/C++ and OpenGL. The third one
was implemented in JS/Three.js and is a direct predecessor of the current mannequin.js.
Since its first incarnation, mannequin.js is used in the course <em>Fundamentals of Computer Graphics</em> for Computer Sciences undergraduate students from the
<a href="https://www.fmi.uni-sofia.bg/en">Faculty of Mathematics and Informatics</a>
at <a href="https://www.uni-sofia.bg/index.php/eng">Sofia University</a>.</p>

<p>Mannequin.js is licensed under <strong>GPL-3.0</strong>.</p>

<p>Three.js is included in this repository to safeguard against incompatibilities with future versions. Three.js is not a part of mannequin.js.</p>



<p>The <strong>mannequin.js</strong> library is provided as a JavaScript file that has to
be include along with three.js.</p>

<h3 id="minimal-program">Minimal program</h3>

<p>Here is a minimal program that creates a male figure in the browser (<a href="https://boytchev.github.io/mannequin.js/examples/example-minimal.html">live example</a>):</p>

<div><div><pre><code><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;html&gt;</span>
  <span>&lt;head&gt;</span>
    <span>&lt;script</span> <span>src=</span><span>"three.min.js"</span><span>&gt;&lt;/script&gt;</span>
    <span>&lt;script</span> <span>src=</span><span>"mannequin.min.js"</span><span>&gt;&lt;/script&gt;</span>
  <span>&lt;/head&gt;</span>
  <span>&lt;body&gt;</span>
    <span>&lt;script&gt;</span>
      createScene();
      var man = new Male();
    <span>&lt;/script&gt;</span>
  <span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span>
</code></pre></div></div>

<p>The helper function <code>createScene()</code> provides a default set-up of the scene and its elements, like lighting, camera, ground, etc. Another helper function, <code>animate(t)</code> is responsible for defining figures’ postures at moment <em>t</em>. If the set-up is done with a custom function, then it should also manage the animation loop by itself.</p>

<h3 id="figure-types">Figure types</h3>

<p>Mannequin figures are created as instances of classes <code>Male()</code>, <code>Female()</code> or <code>Child()</code> (<a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html">live example</a>):</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-figure-types.jpg"></a></p>

<div><div><pre><code><span>var</span> <span>man</span> <span>=</span> <span>new</span> <span>Male</span><span>();</span>
    <span>man</span><span>.</span><span>position</span><span>.</span><span>set</span><span>(</span><span>20</span><span>,</span><span>3.5</span><span>,</span><span>0</span><span>);</span>
    <span>man</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>120</span><span>);</span>
    <span>:</span>
<span>var</span> <span>woman</span> <span>=</span> <span>new</span> <span>Female</span><span>();</span>
    <span>woman</span><span>.</span><span>position</span><span>.</span><span>set</span><span>(</span><span>-</span><span>20</span><span>,</span><span>2</span><span>,</span><span>0</span><span>);</span>
    <span>woman</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>60</span><span>);</span>
    <span>:</span>
<span>var</span> <span>kid</span> <span>=</span> <span>new</span> <span>Child</span><span>();</span>
    <span>kid</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>-</span><span>8</span><span>;</span>
    <span>kid</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>90</span><span>);</span>
    <span>:</span>
</code></pre></div></div>

<p>These three classes have a common predecessor – the class <code>Mannequin(feminine,height)</code>, where <em>feminine</em> is boolean and defines whether the shape is feminine or masculine, and the second parameter is a number for relative height (adults have height 1).</p>



<p>All types of figures have the same structure of joints. For example, the right arm of a figure is accessed by <code>r_arm</code>. Left and right body parts are in respect to the figure, not to the viewer (<a href="https://boytchev.github.io/mannequin.js/examples/example-body-parts.html">live example</a>):</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-body-parts.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-body-parts.jpg"></a></p>

<p>Each body part has rotation methods that turn it around a pivot point.
The first parameter <em>angle</em> of the methods is the angle of rotation in degrees,
so 180 is half turn and 360 is full turn. Negative angles are allowed and
they represent turning in the opposite direction. Some methods have an optional
second parameter for <em>direction</em> of motion, which could be the constant <code>LEFT</code> or
<code>RIGHT</code>.</p>

<h3 id="central-body-parts">Central body parts</h3>

<p>The central body parts are the ones which have single instances - <em>head</em>, <em>neck</em>, <em>torso</em>, <em>pelvis</em> and the body as a whole. To move the whole <strong>body</strong> use methods <em>bend</em>, <em>turn</em> and <em>tilt</em> of the figure (<a href="https://boytchev.github.io/mannequin.js/examples/example-body.html">live example</a>):</p>

<ul>
  <li><code>figure.bend ( angle )</code></li>
  <li><code>figure.turn ( angle )</code></li>
  <li><code>figure.turn ( angle, direction )</code></li>
  <li><code>figure.tilt ( angle )</code></li>
  <li><code>figure.tilt ( angle, direction )</code></li>
</ul>

<p>The <strong>head</strong> supports similar methods: <em>nod</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-head.html">live example</a>):</p>

<ul>
  <li><code>figure.head.nod ( angle )</code></li>
  <li><code>figure.head.turn ( angle )</code></li>
  <li><code>figure.head.turn ( angle, dir )</code></li>
  <li><code>figure.head.tilt ( angle )</code></li>
  <li><code>figure.head.tilt ( angle, dir )</code></li>
</ul>

<p>The <strong>torso</strong> has the same methods as the whole body: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-torso.html">live example</a>):</p>

<ul>
  <li><code>figure.torso.bend ( angle )</code></li>
  <li><code>figure.torso.turn ( angle )</code></li>
  <li><code>figure.torso.turn ( angle, direction )</code></li>
  <li><code>figure.torso.tilt ( angle )</code></li>
  <li><code>figure.torso.tilt ( angle, direction )</code></li>
</ul>

<p>Although the <strong>neck</strong> is a separate part of the body, it is not controlled individually. Instead, a part of the head motion is distributed over the neck. Similarly, the <strong>pelvis</strong> is not controlled individually. Instead, the whole body is controlled by bending, turning and tilting.</p>

<h3 id="upper-limbs">Upper limbs</h3>

<p>The upper limbs are symmetrical body parts: <em>arm</em>, <em>elbow</em>, <em>wrist</em> and <em>fingers</em>.</p>

<p>Both <strong>arms</strong> support methods <em>raise</em>, <em>straddle</em> and <em>turn</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-arm1.html">live example</a>). The following list refers to the right arm, however, the same methods are available for the right hand:</p>

<ul>
  <li><code>figure.r_arm.raise ( angle )</code></li>
  <li><code>figure.r_arm.straddle ( angle )</code></li>
  <li><code>figure.r_arm.straddle ( angle, direction )</code></li>
  <li><code>figure.r_arm.turn ( angle )</code></li>
  <li><code>figure.r_arm.turn ( angle, direction )</code></li>
</ul>

<p>If the <em>direction</em> parameter is omitted, then the default motions of <em>straddle</em> and <em>turn</em> are symmetrical. For example, the left arm is straddled to the left, while the right arm is straddled to the right (<a href="https://boytchev.github.io/mannequin.js/examples/example-arm2.html">live example</a>).</p>

<p>The motion of the <strong>elbow</strong> is only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-elbow.html">live example</a>). Negative values for <em>angle</em> result in unnatural elbow position.</p>

<ul>
  <li><code>figure.r_elbow.bend ( angle )</code></li>
</ul>

<p>The <strong>wrists</strong> have the same methods as the torso: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-wrist.html">live example</a>), but similar to the arms, the directions are symmetrical, if <em>direction</em> is not set:</p>

<ul>
  <li><code>figure.r_wrist.bend ( angle )</code></li>
  <li><code>figure.r_wrist.turn ( angle )</code></li>
  <li><code>figure.r_wrist.turn ( angle, direction )</code></li>
  <li><code>figure.r_wrist.tilt ( angle )</code></li>
  <li><code>figure.r_wrist.tilt ( angle, direction )</code></li>
</ul>

<p>The last body parts of the upper limbs are the <strong>fingers</strong>. They can only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-fingers.html">live example</a>), however, they are composed of two segments and the bending angle is distributed over both of them.</p>

<ul>
  <li><code>figure.r_fingers.bend ( angle )</code></li>
</ul>

<h3 id="lower-limbs">Lower limbs</h3>

<p>The lower limbs are symmetrical body parts: <em>leg</em>, <em>knee</em> and <em>ankle</em>.</p>

<p>Both <strong>legs</strong> support methods <em>raise</em>, <em>straddle</em> and <em>turn</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-leg.html">live example</a>). Straddling and turning are symmetrical if <em>direction</em> is not set.</p>

<ul>
  <li><code>figure.r_leg.raise ( angle )</code></li>
  <li><code>figure.r_leg.straddle ( angle )</code></li>
  <li><code>figure.r_leg.straddle ( angle, direction )</code></li>
  <li><code>figure.r_leg.turn ( angle )</code></li>
  <li><code>figure.r_leg.turn ( angle, direction )</code></li>
</ul>

<p>The motion of the <strong>knee</strong> is only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-knee.html">live example</a>). Negative values for <em>angle</em> result in unnatural knee position.</p>

<ul>
  <li><code>figure.r_knee.bend ( angle )</code></li>
</ul>

<p>The <strong>ankles</strong> have the same methods as the wrists: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-ankle.html">live example</a>), but similar to the legs, the directions are symmetrical, if <em>direction</em> is not set:</p>

<ul>
  <li><code>figure.r_ankle.bend ( angle )</code></li>
  <li><code>figure.r_ankle.turn ( angle )</code></li>
  <li><code>figure.r_ankle.turn ( angle, direction )</code></li>
  <li><code>figure.r_ankle.tilt ( angle )</code></li>
  <li><code>figure.r_ankle.tilt ( angle, direction )</code></li>
</ul>



<p>The posture of a figure is defined by a setting the rotations of body parts. The order of rotations is fixed independent on the order of rotations in the user program (<a href="https://boytchev.github.io/mannequin.js/examples/example-order.html">live example</a>). For example:</p>

<div><div><pre><code><span>figure</span><span>.</span><span>head</span><span>.</span><span>nod</span><span>(</span><span>30</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>45</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>tilt</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
</code></pre></div></div>

<p>produces the same posture as:</p>

<div><div><pre><code><span>figure</span><span>.</span><span>head</span><span>.</span><span>tilt</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>45</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>nod</span><span>(</span><span>30</span><span>);</span>
</code></pre></div></div>

<p>Sometimes this might lead to unexpected results, especially if the user assumes an order of rotations that is different from what mannequin.js uses. This might happen when a body part is rotated around 3 or 2 axes.</p>

<h3 id="static-posture">Static posture</h3>

<p>The static posture defines the position of body part that do not change. By default, when a figure is created, its body parts are set to the default posture. This version of mannequin.js does not provide posture editor, so all rotations has to be defined programmatically.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-posture.jpg"></a></p>

<p>Sometimes it is better to define the figure step by step. Tai Chi Chuan posture (<a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html">live example</a>) could start by defining the whole body position:</p>

<div><div><pre><code><span>// overall body position</span>
<span>man</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>-</span><span>7.7</span><span>;</span>
<span>man</span><span>.</span><span>tilt</span><span>(</span><span>5</span><span>,</span><span>LEFT</span><span>);</span>
<span>man</span><span>.</span><span>bend</span><span>(</span><span>15</span><span>);</span>

<span>// torso and head</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>turn</span><span>(</span><span>30</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>tilt</span><span>(</span><span>15</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>bend</span><span>(</span><span>-</span><span>15</span><span>);</span>
<span>man</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>70</span><span>,</span><span>RIGHT</span><span>);</span>
</code></pre></div></div>

<p>Then the orientation of the legs can be set:</p>

<div><div><pre><code><span>// right leg</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>raise</span><span>(</span><span>85</span><span>);</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>);</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>straddle</span><span>(</span><span>40</span><span>,</span><span>LEFT</span><span>);</span>
<span>man</span><span>.</span><span>r_knee</span><span>.</span><span>bend</span><span>(</span><span>90</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>bend</span><span>(</span><span>35</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>tilt</span><span>(</span><span>-</span><span>15</span><span>);</span>

<span>// left leg</span>
<span>man</span><span>.</span><span>l_leg</span><span>.</span><span>raise</span><span>(</span><span>-</span><span>30</span><span>);</span>
<span>man</span><span>.</span><span>l_knee</span><span>.</span><span>bend</span><span>(</span><span>25</span><span>);</span>
<span>man</span><span>.</span><span>l_ankle</span><span>.</span><span>bend</span><span>(</span><span>42</span><span>);</span>
</code></pre></div></div>

<p>Finally, the arms are fixed:</p>

<div><div><pre><code><span>// left arm</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>raise</span><span>(</span><span>10</span><span>);</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>40</span><span>);</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>tilt</span><span>(</span><span>-</span><span>60</span><span>);</span>
<span>man</span><span>.</span><span>l_elbow</span><span>.</span><span>bend</span><span>(</span><span>155</span><span>);</span>
<span>man</span><span>.</span><span>l_wrist</span><span>.</span><span>turn</span><span>(</span><span>50</span><span>);</span>
<span>man</span><span>.</span><span>l_fingers</span><span>.</span><span>bend</span><span>(</span><span>-</span><span>10</span><span>);</span>

<span>// right arm</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>raise</span><span>(</span><span>-</span><span>10</span><span>);</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>tilt</span><span>(</span><span>70</span><span>);</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>);</span>
<span>man</span><span>.</span><span>r_elbow</span><span>.</span><span>bend</span><span>(</span><span>40</span><span>);</span>
<span>man</span><span>.</span><span>r_wrist</span><span>.</span><span>turn</span><span>(</span><span>30</span><span>);</span>
<span>man</span><span>.</span><span>r_fingers</span><span>.</span><span>bend</span><span>(</span><span>90</span><span>);</span>
</code></pre></div></div>

<h3 id="dynamic-posture">Dynamic posture</h3>

<p>The dynamic posture – i.e. a posture that changes over time – is set with the same methods that are used for static posture. Mannequin.js defines an empty function <code>animate(t)</code>, which is called in the animation loop once for each frame. All changes of a posture should be defined inside this function (<a href="https://boytchev.github.io/mannequin.js/examples/example-dynamic.html">live example</a>). The parameter <em>t</em> is the time, measured in tenths of seconds. This function is set up in <code>createScene()</code>. If <em>createScene</em> and <em>animate</em> are not used, then the animation loop should be managed manually.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-dynamic.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-dynamic.jpg"></a></p>

<div><div><pre><code><span>function</span> <span>animate</span><span>(</span><span>t</span><span>)</span>
<span>{</span>
    <span>var</span> <span>time1</span> <span>=</span> <span>(</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>t</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>3</span><span>*</span><span>t</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>5</span><span>*</span><span>t</span><span>))</span><span>/</span><span>3</span><span>,</span>
        <span>time2</span> <span>=</span> <span>(</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>t</span><span>-</span><span>60</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>3</span><span>*</span><span>t</span><span>-</span><span>90</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>5</span><span>*</span><span>t</span><span>-</span><span>120</span><span>))</span><span>/</span><span>3</span><span>;</span>

    <span>ball</span><span>.</span><span>position</span><span>.</span><span>x</span> <span>=</span> <span>-</span><span>3</span><span>*</span><span>time1</span><span>;</span>

    <span>child</span><span>.</span><span>position</span><span>.</span><span>x</span> <span>=</span> <span>-</span><span>3</span><span>*</span><span>time1</span><span>;</span>
    <span>child</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>4</span><span>+</span><span>cos</span><span>(</span><span>90</span><span>*</span><span>time1</span><span>);</span>

    <span>child</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>90</span><span>-</span><span>20</span><span>*</span><span>time1</span><span>+</span><span>20</span><span>*</span><span>time2</span><span>);</span>
    <span>child</span><span>.</span><span>tilt</span><span>(</span><span>10</span><span>*</span><span>time1</span><span>);</span>
    <span>:</span>
	
    <span>scene</span><span>.</span><span>rotation</span><span>.</span><span>y</span> <span>=</span> <span>rad</span><span>(</span><span>30</span><span>*</span><span>time1</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>To make the animation loop faster, all constant rotations should be defined outside <em>animate</em>. Also, if a rotation changing in the loop, there is no need to set it up outside the loop.</p>



<p>Apart for moving body parts, the current version of mannequin.js provides basic functionality for additional modification or accessing the figure.</p>

<h3 id="custom-colors">Custom colors</h3>

<p>By default, all figures use a predefined set of global colors for body parts. Global colors are stored in <code>Mannequin.colors</code> array as six <a href="https://threejs.org/docs/#api/en/math/Color">Three.js colors</a> or lowercase <a href="https://www.w3schools.com/colors/colors_names.asp">HTML/CSS color names</a> in specific order – head, shoes, pelvis, joints, limbs and torso:</p>

<div><div><pre><code><span>Mannequin</span><span>.</span><span>colors</span> <span>=</span> <span>[</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// head</span>
    <span>'</span><span>gray</span><span>'</span><span>,</span>		<span>// shoes</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// pelvis</span>
    <span>'</span><span>burlywood</span><span>'</span><span>,</span>	<span>// joints</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// limbs</span>
    <span>'</span><span>bisque</span><span>'</span>		<span>// torso</span>
<span>];</span>
</code></pre></div></div>

<p>The global color of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boytchev.github.io/mannequin.js/">https://boytchev.github.io/mannequin.js/</a></em></p>]]>
            </description>
            <link>https://boytchev.github.io/mannequin.js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302602</guid>
            <pubDate>Fri, 04 Dec 2020 14:35:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No One Ever Got Fired for Choosing React]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302502">thread link</a>) | @jakelazaroff
<br/>
December 4, 2020 | https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a web app without a framework. There are a bunch of potential advantages (no bloat! bespoke to your project!) and being able to say you built something with minimal dependencies gets you Engineer Points.</p>
<p>That is, if you can pull it off.</p>
<p>I started a new side project recently. It’s a web-based graphics editor, so it needs to be a single page app. My time spent profiling <a href="https://songrender.com/">SongRender</a> for performance issues has made me a little wary of React for building interfaces that update at 60 frames per second, so I decided to avoid it. I’d go (mostly) vanilla and see how far that took me.</p>
<p>I installed <a href="https://lit-html.polymer-project.org/">lit-html</a> and got to work. “Components” were simply functions that returned lit-html template results. A big singleton at the top of the tree held onto all the application state, stored as a global variable within that module.</p>
<p>The first hurdle came when a component needed local state. I could have lifted it to the singleton, but that would have broken the component’s encapsulation. I noticed that lit-html directives can keep state, so I decided to use them to build a tiny component library — ignoring a warning from the lit-html developers that this wasn’t a supported use case.</p>
<p>My home-brewed library worked great… until I needed to run some code when a component appeared on the screen. I started digging through lit-html documentation and issues looking for a way to detect a directive’s lifecycle, but it became clear to me that going down that path would be painful.</p>
<p>At that point, I recalled <a href="https://tomdale.net/2015/11/javascript-frameworks-and-mobile-performance/">this quote by Tom Dale</a>:</p>
<blockquote>
<p>I have heard from many developers who have told me that they accepted the argument that vanilla JavaScript or microlibraries would let them write leaner, meaner, faster apps. After a year or two, however, what they found themselves with was a slower, bigger, less documented and unmaintained in-house framework with no community. As apps grow, you tend to need the abstractions that a framework offers. Either you or the community write the code.</p>
</blockquote>
<p>Fair enough. Let’s avoid that trap. What about a small framework? I’d heard a lot of good things about Svelte, and although I was slightly worried about the size of the Svelte community I figured it would be fine.</p>
<p>My migration attempt quickly ground to a halt when I wanted a parent component to apply some styles to a child component. In React, I’d pass a class name in from the parent as a <code>className</code> prop. In Svelte, that’s considered a workaround, and the actual feature is the subject of an <a href="https://github.com/sveltejs/rfcs/blob/master/text/0000-style-properties.md">RFC</a>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Maybe this is an example of <a href="https://prog21.dadgum.com/160.html">dangling by a trivial feature</a>. But it’s so basic a capability that I’m surprised Svelte is on version three without an officially blessed way to do it. I ran into this limitation when I created my <strong>second component</strong>. Way before I got to try out any of the cool reactivity that earns Svelte all that buzz.</p>
<p>So I changed my mind and went with React. After an hour or so, I’d finished moving everything over — and my anxiety had vanished. I stopped worrying about having most efficient component system, and picked up work on the thing I wanted to build in the first place.</p>
<p>No, React isn’t perfect. It’s optimized for apps that make network requests and then display lists of things (i.e. most apps) which isn’t really what I’m doing here<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The performance is fine now, although I expect I’ll have to optimize as my project gets more complex.</p>
<p>But React lets me stop thinking about the framework. React gets out of my way. React is <a href="https://mcfunley.com/choose-boring-technology">boring</a>. React is actively developed. React has a giant ecosystem and a giant community. React is battle-tested on some of the most visited websites in the world.</p>
<p>I’m sure there are technically better ways to build a highly interactive interface on the web, but life is too short for me to spend hours trying to figure them out. There are things I want to create, and the only way I can actually create them is to stop spending so much time on tooling.</p>
<p>For now, I’m choosing React.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The solution they seem to have landed on — letting the child expose CSS custom properties as props — is actually pretty cool, though I don’t like that Svelte will silently wrap your component with an extra <code>div</code>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Although Dan, if you read this, the <a href="https://twitter.com/dan_abramov/status/1133341485133438982">“animation pass” mode</a> you’ve mentioned offhandedly sounds very relevant! <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302502</guid>
            <pubDate>Fri, 04 Dec 2020 14:27:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Has AI 'solved' protein folding?]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25302487">thread link</a>) | @stuartbman
<br/>
December 4, 2020 | https://explainthispaper.com/ai-solving-protein-folding/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/ai-solving-protein-folding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<h2><b>Has AI 'solved' protein folding? 📎</b></h2>
<div>
<p><i>article</i></p>
<div>
<p>Improved protein structure prediction using potentials from deep learning</p>
<p>Andrew W. Senior, Richard Evans, John Jumper, James Kirkpatrick, Laurent Sifre, Tim Green, Chongli Qin, Augustin Žídek, Alexander W. R. Nelson, Alex Bridgland, Hugo Penedones, Stig Petersen, Karen Simonyan, Steve Crossan...</p>
<p><a href="https://www.nature.com/articles/s41586-019-1923-7.epdf?author_access_token=Z_KaZKDqtKzbE7Wd5HtwI9RgN0jAjWel9jnR3ZoTv0MCcgAwHMgRx9mvLjNQdB2TlQQaa7l420UCtGo8vYQ39gg8lFWR9mAZtvsN_1PrccXfIbc6e-tGSgazNL_Xd">Nature</a>
</p></div>
</div>
<div>
<h3>TL;DR</h3>
<p><span><p>Predicting protein folding is a massive problem with huge potential to help us understand disease. It’s been stuck in a rut for the past 50 years, but one team of researchers has come out of nowhere and claims to have solved the problem. But have they?</p></span>
</p></div>
<h3 grey-text="" text-darken-4="">Clinical Need</h3>
<section>
<div>
<p><span>
<div><p>Proteins are made up of amino acids. Getting the amino acid sequence for a protein is pretty easy these days. But going from this sequence to the 3-dimensional shape of the protein is really hard.</p><p>For decades, researchers have worked out protein structures using slow and expensive techniques such as <sample>x-ray crystallography</sample>. So far we’ve only solved about 170,000 proteins using these approaches. Yet more than 200 million proteins have been discovered across all forms of life 😳</p><p>Being able to predict a protein’s shape based on its amino acid sequence would be a game changer. We could design drugs faster by targeting proteins more effectively. But computer-based predictions haven’t been accurate enough to be useful. Until now…</p></div>
</span>
</p>
<div>

<p>X-ray crystallography uses the diffraction of x-rays to work out the shape of a protein. The pictures are murky and there's a lot of guesswork involved!</p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>

</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">What did they do?</h3>
<div><p>The team created a deep learning pipeline for predicting protein shape from its amino acid sequence.</p><p>They entered this neural network into the “Critical Assessment of Protein Structure Prediction” (CASP) competition. Teams are given amino acids sequences for ~100 proteins with unknown structures and asked to predict protein shape. The predictions are given a score from 0-100. Slow techniques (like x-ray crystallography) score above 90.</p></div>
<h3 grey-text="" text-darken-4="">How did the model work?</h3>
<section>
<div>
<p><span>
<div><p>The first version of their model (AlphaFold) performs the following stages:</p><p>First, it looks for similar sequence fragments to the protein of interest from a large protein sequence database. This helps identify features of the protein at interest. An <sample>autoencoder</sample> predicts which protein shape the sequence fragment most likely represents.</p><p>These features are then fed into a convolutional neural network which predicts the distances between different parts of the protein sequence. Predicting distances enables it to also predict contact points.</p><p>Then, using the predicted distances and contact points, the model considers all the possible shapes of the protein and identifies the most likely one.</p></div>
</span>
</p>
<div>

<p>This is a type of neural network that compresses data into a bottleneck of it's most important features, and measures it's performance by reconstructing that bottleneck back up to size. It's an in depth topic worth <a href="https://www.jeremyjordan.me/autoencoders/#:~:text=Autoencoders%20are%20an%20unsupervised%20learning,representation%20of%20the%20original%20input.">reading more on</a></p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<p>With the updated model (AlphaFold-2) they made some changes. They haven't released a paper yet (only an abstract), but from what we can tell they used an <sample>attention-based deep learning</sample> to fit over the whole shape of the protein, not just the fragments.</p>
</span>
</p>
<div>

<p>Instead of working over the whole sequence at once, this method allows the learning to 'attend' to subsections individually. This is a bit like trying to translate a long german word- instead of trying to decode the whole word, you break it into sub-words and see how they match, then put it all together.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">How did the model perform?</h3>
<div><p><img alt="Animated Protein" height="450" src="https://explainthispaper.s3.amazonaws.com/images/protein.width-800.png" width="800"></p><p>From the start of the competition in 1994 up to 2016, CASP scores had been around 40. The first time DeepMind entered, they scored up to 60. This year- AlphaFold scored an average of 92.4, smashing the threshold of 90/100!</p><p>In fact, the organisers of the competition thought that DeepMind had been cheating, so they set them a special challenge- a membrane protein from an ancient species of <i>archaea</i>. For 10 years with no success, research teams tried every trick in the book to get an x-ray crystal structure of the protein.</p><p>AlphaFold had no problem, returning an image of a three part protein with two helical arms. In hindsight, this structure fit the x-ray crystallography data perfectly, effectively going beyond the limitations of current human research.</p></div>
<h3 grey-text="" text-darken-4="">So what?</h3>
<section>
<div>
<p><span>
<div><p>This is a thorny problem that researchers and pharmaceutical companies have been working on for 50+ years. This model could predict the shape of proteins without unreliable experimental measurements. This would mean faster development of a wide range of drugs, from cancer drugs that better target proteins for cell replication, to antibiotics that target surface receptors of microbes.</p><p>What’s more, this model was cheap to train- just weeks on quite a <sample>small cluster of servers</sample></p><p>It's worth saying that this isn't the whole picture of protein folding- this still doesn't inform how proteins change shape in the presence of other molecules (like oxygen near haemoglobin). These are also the crystallised protein forms rather than the true 'in vivo' structures, so there may be some errors in translation, but that remains to be seen.</p></div>
</span>
</p>
<div>

<p>Using Google's <a href="https://cloud.google.com/tpu/pricing#pricing_calculator">pricing calculator</a> and the details from the blog post, this could be trained for around $21,000. In the grand scheme of biology and pharmaceuticals, this is pennies!<br></p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>

</div>
</div><div>
<h2>The latest papers in your inbox</h2>
<p>Keep up to date with the latest research, summarised concisely and clearly.</p>



</div></div>]]>
            </description>
            <link>https://explainthispaper.com/ai-solving-protein-folding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302487</guid>
            <pubDate>Fri, 04 Dec 2020 14:25:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[25 Days of Ruby Gems – Ruby Advent Calendar 2020]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302468">thread link</a>) | @mooreds
<br/>
December 4, 2020 | http://planetruby.github.io/gems/ | <a href="https://web.archive.org/web/*/http://planetruby.github.io/gems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      

<h2 id="25-days-of-ruby-gems---ruby-advent-calendar-2020-december-1st---december-25th">25 Days of Ruby Gems - Ruby Advent Calendar 2020, December 1st - December 25th</h2>

<p>
  Brought to you by
</p>

<!-- or sort authors a to z or random shuffle - why? why not -->
<p>
   <a href="https://github.com/swanson" title="Matt Swanson">    <img alt="swanson" width="32" height="32" data-proofer-ignore="true" src="https://avatars0.githubusercontent.com/swanson?v=3&amp;s=32" srcset="https://avatars0.githubusercontent.com/swanson?v=3&amp;s=32 1x, https://avatars0.githubusercontent.com/swanson?v=3&amp;s=64 2x, https://avatars0.githubusercontent.com/swanson?v=3&amp;s=96 3x, https://avatars0.githubusercontent.com/swanson?v=3&amp;s=128 4x"> </a> <!-- day 1 n 7 -->
   <a href="https://github.com/picandocodigo" title="Fernando Briano"> <img alt="picandocodigo" width="32" height="32" data-proofer-ignore="true" src="https://avatars0.githubusercontent.com/picandocodigo?v=3&amp;s=32" srcset="https://avatars0.githubusercontent.com/picandocodigo?v=3&amp;s=32 1x, https://avatars0.githubusercontent.com/picandocodigo?v=3&amp;s=64 2x, https://avatars0.githubusercontent.com/picandocodigo?v=3&amp;s=96 3x, https://avatars0.githubusercontent.com/picandocodigo?v=3&amp;s=128 4x"> </a> <!-- day 2 n 9-->
   <a href="https://github.com/marckohlbrugge" title="Marc Köhlbrugge"> <img alt="marckohlbrugge" width="32" height="32" data-proofer-ignore="true" src="https://avatars0.githubusercontent.com/marckohlbrugge?v=3&amp;s=32" srcset="https://avatars0.githubusercontent.com/marckohlbrugge?v=3&amp;s=32 1x, https://avatars0.githubusercontent.com/marckohlbrugge?v=3&amp;s=64 2x, https://avatars0.githubusercontent.com/marckohlbrugge?v=3&amp;s=96 3x, https://avatars0.githubusercontent.com/marckohlbrugge?v=3&amp;s=128 4x"> </a> <!-- day 3 -->
   <a href="https://github.com/excid3" title="Chris Oliver">   <img alt="excid3" width="32" height="32" data-proofer-ignore="true" src="https://avatars0.githubusercontent.com/excid3?v=3&amp;s=32" srcset="https://avatars0.githubusercontent.com/excid3?v=3&amp;s=32 1x, https://avatars0.githubusercontent.com/excid3?v=3&amp;s=64 2x, https://avatars0.githubusercontent.com/excid3?v=3&amp;s=96 3x, https://avatars0.githubusercontent.com/excid3?v=3&amp;s=128 4x"> </a> <!-- day 4, 6 n 8 -->
   <a href="https://github.com/jasonswett" title="Jason Swett">     <img alt="jasonswett" width="32" height="32" data-proofer-ignore="true" src="https://avatars3.githubusercontent.com/jasonswett?v=3&amp;s=32" srcset="https://avatars3.githubusercontent.com/jasonswett?v=3&amp;s=32 1x, https://avatars3.githubusercontent.com/jasonswett?v=3&amp;s=64 2x, https://avatars3.githubusercontent.com/jasonswett?v=3&amp;s=96 3x, https://avatars3.githubusercontent.com/jasonswett?v=3&amp;s=128 4x"> </a> <!-- day 5 -->
   <a href="https://github.com/rlgreen91" title="Rachel Green">    <img alt="rlgreen91" width="32" height="32" data-proofer-ignore="true" src="https://avatars2.githubusercontent.com/rlgreen91?v=3&amp;s=32" srcset="https://avatars2.githubusercontent.com/rlgreen91?v=3&amp;s=32 1x, https://avatars2.githubusercontent.com/rlgreen91?v=3&amp;s=64 2x, https://avatars2.githubusercontent.com/rlgreen91?v=3&amp;s=96 3x, https://avatars2.githubusercontent.com/rlgreen91?v=3&amp;s=128 4x"> </a> <!-- day 10 -->
   <a href="https://github.com/abhaynikam" title="Abhay Nikam">     <img alt="abhaynikam" width="32" height="32" data-proofer-ignore="true" src="https://avatars0.githubusercontent.com/abhaynikam?v=3&amp;s=32" srcset="https://avatars0.githubusercontent.com/abhaynikam?v=3&amp;s=32 1x, https://avatars0.githubusercontent.com/abhaynikam?v=3&amp;s=64 2x, https://avatars0.githubusercontent.com/abhaynikam?v=3&amp;s=96 3x, https://avatars0.githubusercontent.com/abhaynikam?v=3&amp;s=128 4x"> </a> <!-- day 11 -->
   <a href="https://github.com/pascalwengerter" title="Pascal Wengerter">  <img alt="pascalwengerter" width="32" height="32" data-proofer-ignore="true" src="https://avatars1.githubusercontent.com/pascalwengerter?v=3&amp;s=32" srcset="https://avatars1.githubusercontent.com/pascalwengerter?v=3&amp;s=32 1x, https://avatars1.githubusercontent.com/pascalwengerter?v=3&amp;s=64 2x, https://avatars1.githubusercontent.com/pascalwengerter?v=3&amp;s=96 3x, https://avatars1.githubusercontent.com/pascalwengerter?v=3&amp;s=128 4x"> </a> <!-- day 12 n 16 -->
  
   <a href="https://github.com/ledestin" title="Dmitry Maksyoma"> <img alt="ledestin" width="32" height="32" data-proofer-ignore="true" src="https://avatars0.githubusercontent.com/ledestin?v=3&amp;s=32" srcset="https://avatars0.githubusercontent.com/ledestin?v=3&amp;s=32 1x, https://avatars0.githubusercontent.com/ledestin?v=3&amp;s=64 2x, https://avatars0.githubusercontent.com/ledestin?v=3&amp;s=96 3x, https://avatars0.githubusercontent.com/ledestin?v=3&amp;s=128 4x"> </a> <!-- day 13 -->
   <a href="https://github.com/hlascelles" title="Harry Lascelles"> <img alt="hlascelles" width="32" height="32" data-proofer-ignore="true" src="https://avatars1.githubusercontent.com/hlascelles?v=3&amp;s=32" srcset="https://avatars1.githubusercontent.com/hlascelles?v=3&amp;s=32 1x, https://avatars1.githubusercontent.com/hlascelles?v=3&amp;s=64 2x, https://avatars1.githubusercontent.com/hlascelles?v=3&amp;s=96 3x, https://avatars1.githubusercontent.com/hlascelles?v=3&amp;s=128 4x"> </a> <!-- day 14 -->
   <a href="https://github.com/adrianthedev" title="Adrian Marin">    <img alt="adrianthedev" width="32" height="32" data-proofer-ignore="true" src="https://avatars0.githubusercontent.com/adrianthedev?v=3&amp;s=32" srcset="https://avatars0.githubusercontent.com/adrianthedev?v=3&amp;s=32 1x, https://avatars0.githubusercontent.com/adrianthedev?v=3&amp;s=64 2x, https://avatars0.githubusercontent.com/adrianthedev?v=3&amp;s=96 3x, https://avatars0.githubusercontent.com/adrianthedev?v=3&amp;s=128 4x"> </a> <!-- day 15 -->

   <a href="https://github.com/igorkasyanchuk" title="Igor Kasyanchuk">   <img alt="igorkasyanchuk" width="32" height="32" data-proofer-ignore="true" src="https://avatars2.githubusercontent.com/igorkasyanchuk?v=3&amp;s=32" srcset="https://avatars2.githubusercontent.com/igorkasyanchuk?v=3&amp;s=32 1x, https://avatars2.githubusercontent.com/igorkasyanchuk?v=3&amp;s=64 2x, https://avatars2.githubusercontent.com/igorkasyanchuk?v=3&amp;s=96 3x, https://avatars2.githubusercontent.com/igorkasyanchuk?v=3&amp;s=128 4x"> </a> <!-- day 17 -->
   <a href="https://github.com/jankeesvw" title="Jankees van Woezik"> <img alt="jankeesvw" width="32" height="32" data-proofer-ignore="true" src="https://avatars2.githubusercontent.com/jankeesvw?v=3&amp;s=32" srcset="https://avatars2.githubusercontent.com/jankeesvw?v=3&amp;s=32 1x, https://avatars2.githubusercontent.com/jankeesvw?v=3&amp;s=64 2x, https://avatars2.githubusercontent.com/jankeesvw?v=3&amp;s=96 3x, https://avatars2.githubusercontent.com/jankeesvw?v=3&amp;s=128 4x"> </a> <!-- day 18 --> 
   <a href="https://github.com/marcoroth" title="Marco Roth">         <img alt="marcoroth" width="32" height="32" data-proofer-ignore="true" src="https://avatars3.githubusercontent.com/marcoroth?v=3&amp;s=32" srcset="https://avatars3.githubusercontent.com/marcoroth?v=3&amp;s=32 1x, https://avatars3.githubusercontent.com/marcoroth?v=3&amp;s=64 2x, https://avatars3.githubusercontent.com/marcoroth?v=3&amp;s=96 3x, https://avatars3.githubusercontent.com/marcoroth?v=3&amp;s=128 4x"> </a> <!-- day 20 --> 
   <a href="https://github.com/pienkowb" title="Bartosz Pieńkowski"> <img alt="pienkowb" width="32" height="32" data-proofer-ignore="true" src="https://avatars3.githubusercontent.com/pienkowb?v=3&amp;s=32" srcset="https://avatars3.githubusercontent.com/pienkowb?v=3&amp;s=32 1x, https://avatars3.githubusercontent.com/pienkowb?v=3&amp;s=64 2x, https://avatars3.githubusercontent.com/pienkowb?v=3&amp;s=96 3x, https://avatars3.githubusercontent.com/pienkowb?v=3&amp;s=128 4x"> </a> <!-- day 22 -->

   <a href="https://github.com/janxious" title="Joel Meador">      <img alt="janxious" width="32" height="32" data-proofer-ignore="true" src="https://avatars0.githubusercontent.com/janxious?v=3&amp;s=32" srcset="https://avatars0.githubusercontent.com/janxious?v=3&amp;s=32 1x, https://avatars0.githubusercontent.com/janxious?v=3&amp;s=64 2x, https://avatars0.githubusercontent.com/janxious?v=3&amp;s=96 3x, https://avatars0.githubusercontent.com/janxious?v=3&amp;s=128 4x"> </a> <!-- day 23 -->
   <a href="https://github.com/codenamev" title="Valentino Stoll">  <img alt="codenamev" width="32" height="32" data-proofer-ignore="true" src="https://avatars1.githubusercontent.com/codenamev?v=3&amp;s=32" srcset="https://avatars1.githubusercontent.com/codenamev?v=3&amp;s=32 1x, https://avatars1.githubusercontent.com/codenamev?v=3&amp;s=64 2x, https://avatars1.githubusercontent.com/codenamev?v=3&amp;s=96 3x, https://avatars1.githubusercontent.com/codenamev?v=3&amp;s=128 4x"> </a> <!-- day 24 -->
  
   <!-- backups or double posts on sundays -->
   <a href="https://github.com/philnash" title="Phil Nash">         <img alt="philnash" width="32" height="32" data-proofer-ignore="true" src="https://avatars1.githubusercontent.com/philnash?v=3&amp;s=32" srcset="https://avatars1.githubusercontent.com/philnash?v=3&amp;s=32 1x, https://avatars1.githubusercontent.com/philnash?v=3&amp;s=64 2x, https://avatars1.githubusercontent.com/philnash?v=3&amp;s=96 3x, https://avatars1.githubusercontent.com/philnash?v=3&amp;s=128 4x"> </a>
   <a href="https://github.com/MikeRogers0" title="Mike Rogers">       <img alt="MikeRogers0" width="32" height="32" data-proofer-ignore="true" src="https://avatars3.githubusercontent.com/MikeRogers0?v=3&amp;s=32" srcset="https://avatars3.githubusercontent.com/MikeRogers0?v=3&amp;s=32 1x, https://avatars3.githubusercontent.com/MikeRogers0?v=3&amp;s=64 2x, https://avatars3.githubusercontent.com/MikeRogers0?v=3&amp;s=96 3x, https://avatars3.githubusercontent.com/MikeRogers0?v=3&amp;s=128 4x"> </a>

   <a href="https://github.com/gettalong" title="Thomas Leitner">  <img alt="gettalong" width="32" height="32" data-proofer-ignore="true" src="https://avatars2.githubusercontent.com/gettalong?v=3&amp;s=32" srcset="https://avatars2.githubusercontent.com/gettalong?v=3&amp;s=32 1x, https://avatars2.githubusercontent.com/gettalong?v=3&amp;s=64 2x, https://avatars2.githubusercontent.com/gettalong?v=3&amp;s=96 3x, https://avatars2.githubusercontent.com/gettalong?v=3&amp;s=128 4x"> </a> <!-- day 25 - move hexapdf guest post from week series -->
   <a href="https://github.com/geraldb" title="Gerald Bauer">    <img alt="geraldb" width="32" height="32" data-proofer-ignore="true" src="https://avatars2.githubusercontent.com/geraldb?v=3&amp;s=32" srcset="https://avatars2.githubusercontent.com/geraldb?v=3&amp;s=32 1x, https://avatars2.githubusercontent.com/geraldb?v=3&amp;s=64 2x, https://avatars2.githubusercontent.com/geraldb?v=3&amp;s=96 3x, https://avatars2.githubusercontent.com/geraldb?v=3&amp;s=128 4x"> </a> <!-- later in 2021 -->
   &nbsp;&nbsp;&nbsp;
<!--
  <a href="https://github.com/planetruby/gems/issues">You - Yes, you can!</a>
-->
</p>

<p>Welcome. The Ruby Advent Calendar 2020
presents a new Ruby library every day
from December 1st to December 25th.</p>



<h3 id="backups-or-sunday-double-posts">Backups (or Sunday Double Posts)</h3>

<p>More upcoming write-ups in the Advent Calendar 2020:</p>



<h2 id="upcoming-in-2021">Upcoming in 2021</h2>

<h3 id="ruby-blockchain-week-2021-january-3rd-to-january-9th---7-days-of-ruby-crypto-gems">Ruby Blockchain Week 2021, January 3rd to January 9th - 7 Days of Ruby (Crypto) Gems</h3>

<p>Welcome. The Ruby Blockchain Week 2021 presents
a new Ruby (crypto) library every day from January 3rd to January 9th.
Have your say! Claim a free day!</p>

<p>Let’s celebrate the 11th birthday of the world’s first genesis block  -
that is, the first block of a blockchain (on January 3rd, 2009) with a week long
celebration of crypto gems from the Ruby universe.</p>

<p>Do you have a (crypto) Ruby gem that you’d like to write about?
We love your posts.  <a href="https://github.com/planetruby/gems/issues">Open an issue ticket</a> or send in a pull request to get the conversation started and your article posted in the Blockchain Week series on Planet Ruby.</p>

<ul>
  <li>
<strong>Day 1 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 2 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 3 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 4 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 5 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 6 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 7 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
</ul>

<h3 id="ruby-open-data-week-2021-march-6th-to-march-12th---7-days-of-ruby-open-data-gems">Ruby Open Data Week 2021, March 6th to March 12th - 7 Days of Ruby (Open Data) Gems</h3>

<p>Welcome. The Ruby Open Data Week 2021 presents
a new Ruby (open data) library every day from March 6th to March 12th.
Have your say! Claim a free day!</p>

<p>Let’s join in and celebrate the (international)
<a href="https://opendataday.org/">Open Data Day 2021</a>
with a week long
celebration of open data gems from the Ruby universe.</p>

<p>Do you have an open data Ruby gem that you’d like to write about?
We love your posts.  <a href="https://github.com/planetruby/gems/issues">Open an issue ticket</a> or send in a pull request to get the conversation started and your article posted in the Open Data Week series on Planet Ruby.</p>

<ul>
  <li>
<strong>Day 1 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 2 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 3 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 4 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 5 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 6 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
  <li>
<strong>Day 7 - Your gem (write-up) here - Unclaimed, You? - <a href="https://github.com/planetruby/gems/issues">Yes, you can!</a></strong> - Your tag line here</li>
</ul>

<h2 id="archive">Archive</h2>

<h3 id="ruby-gem-of-the-week-series">Ruby Gem of the Week Series</h3>

<p>Welcome. The Ruby Gem of the Week series
presents a new Ruby library every week on Thursday.
Have your say!</p>

<!--
Do you have a Ruby gem that you'd like to write about?
We love your posts.
[Open an issue ticket](https://github.com/planetruby/gems/issues)
or send in a pull request
to get the conversation started and your article posted on Planet Ruby.
-->

<ul>
  <li>
<a href="http://planetruby.github.io/gems/week/01-factbook.html"><strong>Week 1 - factbook</strong></a> - turn the world factbook into open structured data e.g JSON</li>
  <li>
<a href="http://planetruby.github.io/gems/week/02-hoe.html"><strong>Week 2 - hoe</strong></a> - build, package and publish gems with hoe rake tasks</li>
  <li>
<a href="http://planetruby.github.io/gems/week/03-slideshow.html"><strong>Week 3 - slideshow</strong></a> - a free web alternative to PowerPoint and Keynote in Ruby</li>
  <li>
<a href="http://planetruby.github.io/gems/week/04-kramdown.html"><strong>Week 4 - kramdown</strong></a> - turn easy-to-read and easy-to-write wiki-style plain text in markdown into hypertext</li>
  <li>
<a href="http://planetruby.github.io/gems/week/05-feedparser.html"><strong>Week 5 - feedparser</strong></a> - web feed parser and normalizers (for RSS 2.0, Atom, n friends)</li>
  <li>
<a href="http://planetruby.github.io/gems/week/06-schemadoc.html"><strong>Week 6 - schemadoc</strong></a> - auto-generate your database schema docs for tables, columns, etc.</li>
  <li>
<a href="http://planetruby.github.io/gems/week/07-gli.html"><strong>Week 7 - gli</strong></a> - git-like interfaces for awesome command-line tools</li>
  <li>
<a href="http://planetruby.github.io/gems/week/08-erd.html"><strong>Week 8 - erd</strong></a> - generate entity-relationship diagrams (ERD) for your activerecord models</li>
  <li>
<a href="http://planetruby.github.io/gems/week/09-state-machine.html"><strong>Week 9 - state_machine(s)</strong></a> - model processes and work flows with finite state machines (FSM) and automata theory</li>
  <li>
<a href="http://planetruby.github.io/gems/week/10-annotate.html"><strong>Week 10 - annotate</strong></a> - annotate your ActiveRecord models with comments about your table structure</li>
  <li>
<a href="http://planetruby.github.io/gems/week/11-worldlite.html"><strong>Week 11 - worldlite</strong></a> - lightweight public domain country data (all data included as good ol’ ruby code)</li>
  <li>
<a href="http://planetruby.github.io/gems/week/12-logutils.html"><strong>Week 12 - logutils</strong></a> - yet another (lightweight, simple) logging library in Ruby</li>
  <li>
<a href="http://planetruby.github.io/gems/week/13-props.html"><strong>Week 13 - props</strong></a> - yet another config (INI) reader in Ruby</li>
  <li>
<a href="http://planetruby.github.io/gems/week/14-html-proofer.html"><strong>Week 14 - html-proofer</strong></a> - auto-proofread (check and validate) your hypertext (HTML) pages</li>
  <li>
<a href="http://planetruby.github.io/gems/week/15-beerdb.html"><strong>Week 15 - beerdb</strong></a>  - serving a Guinness Irish Stout or a Bamberg Aecht Schlenkerla Rauchbier Märzen as JSON w/ Ruby</li>
  <li>
<a href="http://planetruby.github.io/gems/week/16-tilt.html"><strong>Week 16 - tilt</strong></a> - let’s build (yet another) micro web framework in less than 33 lines of code</li>
  <li>
<a href="http://planetruby.github.io/gems/week/17-datapak.html"><strong>Week 17 - datapak</strong></a> - work with tabular data packages (.csv files w/ datapackage.json) using SQLite (w/ ActiveRecord)</li>
  <li>
<a href="http://planetruby.github.io/gems/week/18-hexapdf.html"><strong>Week 18 - hexapdf</strong></a> - read and write PDF documents; start from zero or merge, extract, optimize and much more. Written by <img alt="gettalong" width="20" height="20" data-proofer-ignore="true" src="https://avatars3.githubusercontent.com/gettalong?v=3&amp;s=20" srcset="https://avatars3.githubusercontent.com/gettalong?v=3&amp;s=20 1x, https://avatars3.githubusercontent.com/gettalong?v=3&amp;s=40 2x, https://avatars3.githubusercontent.com/gettalong?v=3&amp;s=60 3x, https://avatars3.githubusercontent.com/gettalong?v=3&amp;s=80 4x"> <a href="https://rubygems.org/profiles/gettalong">Thomas Leitner</a>
</li>
</ul>



    <!-- note: add our own little (inline) footer, see _includes for source -->  
   <!-- try / add footer - why? why not? -->
<p>
    Built with <a href="https://www.ruby-lang.org/">Ruby</a>
      (running <a href="https://jekyllrb.com/">Jekyll</a>)
      on 2020-12-07 08:31:35 +0000 in 0.371 seconds.<br>
      Hosted on <a href="https://pages.github.com/">GitHub Pages</a>.
      &lt;/&gt; <a href="https://github.com/planetruby/gems">Source</a> on GitHub.
      (0) Dedicated to the public domain.
 </p>


    </div></div>]]>
            </description>
            <link>http://planetruby.github.io/gems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302468</guid>
            <pubDate>Fri, 04 Dec 2020 14:24:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against the Managers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302396">thread link</a>) | @wwilson
<br/>
December 4, 2020 | https://www.thebellows.org/against-the-managers/ | <a href="https://web.archive.org/web/*/https://www.thebellows.org/against-the-managers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>On July 8, 1853, Commodore Matthew Perry sailed his squadron of four U.S. Navy warships into Edo Bay. The Japanese, still clinging to their centuries-old policy of total isolation from the rest of the world, were not completely in the dark about the growing power and assertiveness of the Western barbarians. Signs had been identified, studies had been ordered, some preparations had already been made. But the “ships of evil mien,” billowing black smoke without a single white sail in sight, would in short order plunge Japan’s <em>ancien regime</em> into one of the most dramatic and far-reaching social and political upheavals that the world has ever seen.</p>



<p>There are, during times like these, a few reasons to reflect on this odd bit of history, as one-half of America—and the West more generally—celebrates the decisive restoration of the old order under the new president, Joe Biden. In 2016, Donald Trump was, in some ways, a black ship on his own; a <em>president of evil mien</em> in the eyes of the shocked, chattering classes. True to historical example, the progressive managerial class, the career civil servants, and the august captains of (offshore) industry—which he rhetorically placed himself in opposition to—were far from ignorant. Signs had been identified, studies ordered, and New York Times think pieces about ailing coal communities and deaths of despair in the hollowed-out America outside urban metropoles had been dutifully penned and greeted with oohs and ahhs. But these half-hearted preparations could not stop the populist ship from entering the harbor.</p>



<p>In the wake of Trump’s election, Brexit, and the growth of anti-EU populism, the placid doctrines of establishment politics are now being remade. But perhaps more significant is the absolute and utter collapse of Western self-declared “anti-establishment” politics: the “socialist” left has proven to be one of the earliest casualties. The cresting wave of left-wing populism turned out to be illusionary; as it receded, its only lasting legacy was bitter acrimony, rotting political hopes, failed analyses, and stranded careers in academia and the NGO-world.&nbsp;</p>



<p>This is not to say that “the left” has lost. Only the romantic narodism of the 21<sup>st</sup> century left has truly died: the belief that “the people,” or “the working class,” can be relied upon in the political struggle. One need only consider the riots going on even now in the US, or the one of the many institutional revolutions playing out (at <a rel="noreferrer noopener" href="https://www.nytimes.com/2020/06/09/books/poetry-foundation-black-lives-matter.html" target="_blank">foundations</a>, <a rel="noreferrer noopener" href="https://www.spiked-online.com/2020/06/09/a-woke-coup-at-the-new-york-times/" target="_blank">newspaper editorial boards</a>, and <a rel="noreferrer noopener" href="https://quillette.com/2020/07/30/think-cancel-culture-doesnt-exist-my-own-lived-experience-says-otherwise/" target="_blank">academia</a>), to recognize that the movement is still in good health. But after the disappointments of late-2019 and mid-2020, those revolutions will no longer maintain any pretense of being waged by the people. They won’t even pretend to be waged <em>for</em> them.</p>



<p>The situation on the right is equally broken and chaotic. Every victory—Brexit, the 2019 UK election, the surprising triumph of Trump in 2016—has only further discombobulated their old coalitions, hastening the process by which the right (at least as it has been constituted in the post-war era) continues to fall apart. No side, it seems, can escape the looming shadow of those black ships.</p>



<p>In any event, the very concepts of “victory” and “defeat” today are abstract and nebulous. In the UK, the Tories <a href="https://www.theguardian.com/politics/2019/dec/13/labours-red-wall-demolished-by-tory-onslaught" target="_blank" rel="noreferrer noopener">crushed Labour’s red wall</a> in a stunning win that probably outpaced even the most optimistic scenarios of the party’s own strategic planners. Yet one gets the sense that nobody is quite sure what it all actually <em>means</em>. In a way, the Tories are as sheepish about having won over large segments of the working-class demographic as the Labour Party is about having suddenly lost them. The world has moved well past our old ideas about it, and today those ideas huff and puff mightily as they struggle to catch up with events.</p>



<p>To understand the failures and contradictions inherent both within the now-dead project of left populism and the extant but visibly-contradictory project of populisms both from the right (whether European or American) and from new entrants to the political field (such as the Italian <a href="https://en.wikipedia.org/wiki/Five_Star_Movement" target="_blank" rel="noreferrer noopener">M5S</a> movement), one ought to give serious consideration to a phenomena that has not been seriously interrogated: that the death of George Floyd in the United States would kick off large protests, even riots, in capitals across Europe, and that the victory of Joe Biden would be greeted with tears of joy, by, say, a social worker in a mid-sized municipality in Sweden.</p>



<p>This feature of the contemporary Western world is usually explained away as a result of American cultural and/or ideological hegemony. But a millennial growing up in Europe twenty years ago was already watching American sitcoms, eating McDonalds, and playing video games that glorified American participation in World War II. American cultural or ideological “imperialism” is hardly an invention of the Trump cabinet, and yet the sort of extreme identification between the politics of American hub cities (to borrow a term <a href="https://www.thebellows.org/the-double-horseshoe-theory/" target="_blank" rel="noreferrer noopener">from Michael Lind</a>) and its equivalent hub cities in Europe is fairly new.</p>



<div id="block_5fc12ec4ac607">
    <p>
		Yet, it is only just now that we are seeing, with clear eyes, that this class of people might begin acting as a class.    </p>
</div>


<p>The left may prefer to talk about a supposed “<a href="https://www.nytimes.com/2014/06/22/magazine/its-official-the-boomerang-kids-wont-leave.ht" target="_blank" rel="noreferrer noopener">precarization</a>,” of the college educated, and the right may be more comfortable talking about ”<a href="https://twitter.com/benshapiro/status/1328346823568875520" target="_blank" rel="noreferrer noopener">useless college degrees</a>,” but neither side denies the facts on the ground: that for some time now, the West has been using a massive expansion of higher education to create a new class of functionaries—”knowledge-workers” and would-be managers—in numbers far in excess of what the labor market can or could absorb. Yet, it is only just now that we are seeing, with clear eyes, that this class of people (which, again, nobody denies the existence of) might begin <em>acting as a class</em>.&nbsp;</p>



<p>One could argue we’ve been here before. During the <a href="https://en.wikipedia.org/wiki/Revolutions_of_1848" target="_blank" rel="noreferrer noopener">Springtime of Nations</a> that swept Europe in 1848, the students of Vienna were enduring their own “<a href="https://en.wikipedia.org/wiki/Lost_Decade_(Japan)" target="_blank" rel="noreferrer noopener">lost decade,</a>” and were consequently far more militant and revolutionary than the workers they presumed to speak for. To be a student in Vienna back then usually meant graduating into a job with the imperial bureaucracy. But the job market for that line of work had been dismal for some time, owing to years of strained financials within the Austrian empire. Of course, the speed by which revolution spread through Europe in 1848 couldn’t be due to “French cultural imperialism” alone. New ideas about constitutionalism and national liberation spread most rapidly in places where conditions were just right (Germany, Italy, Hungary, etc), and fizzled out in places where they weren’t (the United States, Great Britain).&nbsp;</p>



<p>Rather than try to pin the blame on American television, or even social media, it behooves us to recognize that the conditions for this new “Springtime of the Managers” are just as ripe in London and Berlin as they are in Portland and New York City. What we have now on the left and right—on both sides of the Atlantic—is an open and bitter class war. It is a conflict between a growing cadre of imperial lords and the peasantry they hope to subjugate; between the managers and petty nobility of the much-prophesied “knowledge economy” and those they aim to manage.&nbsp;</p>



<p>Just as few took the existence of this class of people seriously, no one took the existence of this class war seriously until recently. The left was forced to <a href="https://jacobinmag.com/2020/02/michael-lind-new-class-war-review" target="_blank" rel="noreferrer noopener">outright deny it</a> because they were already on the side against the working classes, and any acknowledgment of that fact would destroy their legitimacy. What is East Germany, without Communism? Nothing; it is merely part of greater Germany. The left faced a similar dilemma, and so the charade, emptied of all class conflicts in favor of “cultural” ones, had to be maintained.&nbsp;</p>



<p>Meanwhile, a minority of left intellectuals have already begun jettisoning ideological ties to a people it no longer belonged to or recognized. In the UK, thinkers like Paul Mason diligently sought to replace workers with <a href="https://en.wikipedia.org/wiki/PostCapitalism" target="_blank" rel="noreferrer noopener">young (educated) people who have a smartphone</a> as the natural constituency of the left. In the US, Nathan J. Robinson, the publisher of <a href="https://www.currentaffairs.org/" target="_blank" rel="noreferrer noopener">Current Affairs</a> magazine, <a href="https://podbay.fm/p/current-affairs/e/1547493000?t=3651" target="_blank" rel="noreferrer noopener">pleaded for the left</a> to finally abandon Marxism and historical materialism in favor of couching its arguments in moral terms. These characters were, almost without exception, mocked and ridiculed. But time has vindicated them. It is now clear that they took heat not because they suggested a new and different strategy, but because they were advancing the end to the left’s doublespeak<em> </em>and doublethink. The left had long since abandoned the workers; Mason and Robinson were merely preparing the ideological contingency plan for when the workers would abandon the left, as has <a href="https://www.jacobinmag.com/2020/11/biden-trumpism-election-alternative-democrats" target="_blank" rel="noreferrer noopener">now well and truly happened</a>.</p>



<p>In the leadup to the 2020 election, the right faced a different dilemma. For them, the class conflict they refused to recognize was internal. The Democrats, having fully consolidated its new political coalition between petty managers, Silicon Valley grandees, and a dwindling base of minority clients, could not only defeat the likes of Bernie Sanders, but also reabsorb all of the hammer and sickle-brandishing “revolutionary communists” back into the machine. Unfortunately for the GOP—as with the Tories in Britain and the Sweden Democrats or Rassemblent Nationale in Europe—the consolidation of “the ascendant” into center-left parties has left them stuck with the political leftovers: an entirely ad-hoc coalition consisting of disgruntled heartland workers, small business owners, and big business also-rans. For this reason, and in part due to the intellectual legacy of the Cold War, talk of actual class conflict comes at a very high risk for the right. Trying to unite the competing interests that make up the extant and potential base of the Republican party is nigh impossible. The Democrats—and the Western left in general—talk about culture rather than political economy because …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thebellows.org/against-the-managers/">https://www.thebellows.org/against-the-managers/</a></em></p>]]>
            </description>
            <link>https://www.thebellows.org/against-the-managers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302396</guid>
            <pubDate>Fri, 04 Dec 2020 14:15:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker’s Guide to Online Anonymity]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302389">thread link</a>) | @r4um
<br/>
December 4, 2020 | https://anonymousplanet.github.io/thgtoa/guide.html | <a href="https://web.archive.org/web/*/https://anonymousplanet.github.io/thgtoa/guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<ul>
  <li><a href="#introduction">Introduction:</a></li>
  <li><a href="#requirements">Requirements:</a></li>
  <li><a href="#understanding-some-basics-of-how-some-information-can-lead-back-to-you-and-how-to-mitigate-those">Understanding some basics of how some information can lead back to you and how to mitigate those:</a>
    <ul>
      <li><a href="#your-ip-address">Your IP address:</a></li>
      <li><a href="#your-dns-requests">Your DNS requests:</a></li>
      <li><a href="#your-imei-and-imsi-and-by-extension-your-phone-number">Your IMEI and IMSI (and by extension, your phone number):</a></li>
      <li><a href="#your-wi-fi-mac-address">Your Wi-Fi MAC address:</a></li>
      <li><a href="#your-bluetooth-mac-address">Your Bluetooth MAC address:</a></li>
      <li><a href="#your-operating-systems-and-apps-telemetry-services">Your Operating Systems and Apps telemetry services:</a></li>
      <li><a href="#the-wifis-and-bluetooth-devices-around-you">The WIFIs and Bluetooth devices around you:</a></li>
      <li><a href="#your-metadata-including-your-geo-location">Your Metadata including your Geo-Location:</a></li>
      <li><a href="#your-smart-devices-in-general">Your Smart devices in general:</a></li>
      <li><a href="#your-devices-can-be-tracked-even-when-completely-powered-off">Your Devices can be tracked even when completely powered off:</a></li>
      <li><a href="#your-rfid-enabled-devices">Your RFID enabled devices:</a></li>
      <li><a href="#your-files-propertiesmetadata">Your Files Properties/Metadata:</a></li>
      <li><a href="#your-anonymized-torvpn-traffic">Your “Anonymized” Tor/VPN traffic:</a></li>
      <li><a href="#your-crypto-transactions">Your Crypto transactions:</a></li>
      <li><a href="#exploits-in-your-apps">Exploits in your apps:</a></li>
      <li><a href="#your-cloud-backupssync-services">Your Cloud backups/sync services:</a></li>
      <li><a href="#your-digital-fingerprint-and-footprint">Your Digital Fingerprint And Footprint:</a></li>
      <li><a href="#your-real-life">Your Real Life:</a></li>
      <li><a href="#your-browser-and-device-fingerprints">Your Browser and Device Fingerprints:</a></li>
      <li><a href="#your-face-and-other-biometrics">Your Face and other Biometrics:</a></li>
      <li><a href="#phishing">Phishing:</a></li>
      <li><a href="#forensics">Forensics:</a></li>
      <li><a href="#advanced-targeted-techniques">Advanced targeted techniques:</a></li>
      <li><a href="#notes">Notes:</a></li>
    </ul>
  </li>
  <li><a href="#general-preparations">General Preparations:</a>
    <ul>
      <li><a href="#picking-your-route">Picking your route:</a>
        <ul>
          <li><a href="#budgetmaterial-limitations">Budget/Material limitations:</a></li>
          <li><a href="#skills">Skills:</a></li>
          <li><a href="#adversaries-threats">Adversaries (threats):</a></li>
        </ul>
      </li>
      <li><a href="#steps-for-all-routes">Steps for all routes:</a>
        <ul>
          <li><a href="#get-a-burner-phone">Get a burner phone:</a></li>
          <li><a href="#get-an-anonymous-pre-paid-sim-card">Get an anonymous pre-paid SIM card:</a></li>
          <li><a href="#get-an-usb-key">Get an USB key:</a></li>
          <li><a href="#find-some-safe-places-with-decent-public-wifi">Find some safe places with decent public WIFI:</a></li>
        </ul>
      </li>
      <li><a href="#the-tails-route">The TAILS route:</a></li>
      <li><a href="#steps-for-all-other-routes">Steps for all other routes:</a>
        <ul>
          <li><a href="#get-a-laptop-for-your-anonymous-activities">Get a laptop for your anonymous activities:</a></li>
          <li><a href="#a-note-for-linux-users-to-avoid-wasting-your-time-later">A note for Linux users to avoid wasting your time later:</a></li>
          <li><a href="#biosuefi-settings-of-your-laptop">Bios/UEFI Settings of your laptop:</a></li>
          <li><a href="#tamper-protect-your-laptop">Tamper protect your laptop:</a></li>
        </ul>
      </li>
      <li><a href="#the-whonix-route">The Whonix route:</a>
        <ul>
          <li><a href="#picking-your-host-os-the-os-installed-on-your-laptop">Picking your Host OS (the OS installed on your laptop):</a></li>
          <li><a href="#enable-mac-address-randomization-on-your-laptop">Enable MAC address randomization on your laptop:</a></li>
          <li><a href="#setting-up-a-safe-browser-on-your-host-os">Setting up a safe Browser on your Host OS:</a></li>
          <li><a href="#enable-some-additional-privacy-settings-on-your-host-os">Enable some additional privacy settings on your Host OS:</a></li>
          <li><a href="#windows-host-os-encryption">Windows Host OS encryption:</a></li>
          <li><a href="#virtualbox">Virtualbox:</a></li>
          <li><a href="#get-an-anonymous-cash-paid-vpn-subscription">Get an anonymous (cash-paid) VPN subscription:</a></li>
          <li><a href="#download-various-utilities">Download various utilities:</a></li>
          <li><a href="#whonix-virtual-machines">Whonix Virtual Machines:</a></li>
          <li><a href="#windows-10-virtual-machine">Windows 10 Virtual Machine:</a></li>
          <li><a href="#vpn-client-installation-cash-paid">VPN client installation (cash-paid):</a></li>
          <li><a href="#keepassxc">KeePassXC:</a></li>
        </ul>
      </li>
      <li><a href="#the-qubes-route">The Qubes Route:</a></li>
    </ul>
  </li>
  <li><a href="#creating-your-anonymous-online-identities">Creating your anonymous online identities:</a>
    <ul>
      <li><a href="#understanding-the-methods-used-to-prevent-anonymity-and-verify-identity">Understanding the methods used to prevent anonymity and verify identity:</a>
        <ul>
          <li><a href="#captchas">Captchas:</a></li>
          <li><a href="#phone-verification">Phone verification:</a></li>
          <li><a href="#e-mail-verification">E-Mail verification:</a></li>
          <li><a href="#user-details-checking">User details checking:</a></li>
          <li><a href="#proof-of-id-verification">Proof of ID verification:</a></li>
          <li><a href="#ip-filters">IP Filters:</a></li>
          <li><a href="#browser-and-device-fingerprinting">Browser and Device Fingerprinting:</a></li>
          <li><a href="#human-interaction">Human interaction:</a></li>
          <li><a href="#user-moderation">User Moderation:</a></li>
          <li><a href="#behavioral-analysis">Behavioral Analysis:</a></li>
          <li><a href="#financial-transactions">Financial transactions:</a></li>
          <li><a href="#sign-in-with-some-platform">Sign-in with some platform:</a></li>
          <li><a href="#live-face-recognition-and-biometrics-again">Live Face recognition and biometrics (again):</a></li>
          <li><a href="#manual-reviews">Manual reviews:</a></li>
        </ul>
      </li>
      <li><a href="#getting-online">Getting Online:</a></li>
      <li><a href="#creating-new-identities">Creating new identities:</a></li>
      <li><a href="#protonmail">ProtonMail:</a></li>
      <li><a href="#google">Google:</a></li>
      <li><a href="#twitter">Twitter:</a></li>
      <li><a href="#linkedin">Linkedin:</a></li>
      <li><a href="#microsoft">Microsoft:</a></li>
      <li><a href="#instagram">Instagram:</a></li>
      <li><a href="#facebook">Facebook:</a></li>
      <li><a href="#github">Github:</a></li>
      <li><a href="#discord">Discord:</a></li>
      <li><a href="#telegram">Telegram:</a></li>
      <li><a href="#reddit">Reddit:</a></li>
      <li><a href="#chan">4chan:</a></li>
      <li><a href="#crypto-wallets">Crypto Wallets:</a></li>
      <li><a href="#what-about-those-mobile-only-apps-whatsappsignal">What about those mobile only apps (Whatsapp/Signal):</a></li>
      <li><a href="#anything-else">Anything else:</a></li>
      <li><a href="#maintenance-tasks">Maintenance tasks:</a></li>
    </ul>
  </li>
  <li><a href="#backup-your-work-safely-and-anonymously">Backup your work (safely and anonymously):</a></li>
  <li><a href="#covering-your-tracks">Covering your tracks:</a>
    <ul>
      <li><a href="#protecting-yourself-against-forensics">Protecting yourself against forensics:</a></li>
      <li><a href="#tails">Tails:</a></li>
      <li><a href="#windows-1">Windows:</a>
        <ul>
          <li><a href="#diagnostic-data-and-telemetry">Diagnostic Data and Telemetry:</a></li>
          <li><a href="#eventlogs">Eventlogs:</a></li>
          <li><a href="#veracrypt-history">Veracrypt History:</a></li>
          <li><a href="#external-tool-cleaning">External Tool Cleaning:</a></li>
          <li><a href="#shellbags">Shellbags:</a></li>
          <li><a href="#wi-fi-history">Wi-Fi History:</a></li>
        </ul>
      </li>
      <li><a href="#how-to-securely-wipe-your-whole-laptop-if-you-want-to-erase-everything">How to securely wipe your whole laptop if you want to erase everything:</a>
        <ul>
          <li><a href="#linux-1">Linux:</a></li>
          <li><a href="#windows-2">Windows: </a></li>
        </ul>
      </li>
      <li><a href="#if-you-think-you-got-burned">If you think you got burned:</a>
        <ul>
          <li><a href="#if-you-have-some-time">If you have some time:</a></li>
          <li><a href="#if-you-have-no-time">If you have no time:</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#some-last-opsec-thoughts">Some last OPSEC thoughts:</a></li>
  <li><a href="#appendix-a-windows-installation">Appendix A: (Windows Installation)</a>
    <ul>
      <li><a href="#installation">Installation:</a></li>
      <li><a href="#privacy-settings">Privacy Settings:</a></li>
    </ul>
  </li>
  <li><a href="#appendix-b-windows-additional-privacy-settings">Appendix B: (Windows Additional Privacy Settings)</a></li>
  <li><a href="#appendix-c-windows-installation-media-creation">Appendix C: (Windows Installation Media Creation)</a></li>
</ul>

<p>Version 0.1.1 (draft), December 2020 (work in progress, some parts are incomplete) by AnonymousPlanet</p>

<p>This guide is open-source, licensed under Creative Commons Attribution 4.0 International (cc-by-4.0).</p>

<p>Feel free to submit issues/recommendations/ideas using Github Issues at: <a href="https://github.com/AnonymousPlanet/thgtoa/issues">https://github.com/AnonymousPlanet/thgtoa/issues</a></p>

<p>PDF version of this guide at: <a href="https://github.com/AnonymousPlanet/thgtoa/raw/main/guide.pdf">https://github.com/AnonymousPlanet/thgtoa/raw/main/guide.pdf</a></p>



<p>Making a social media account with a pseudonym or artist/brand name is easy. And it’s enough is most use cases to protect your identity as the next George Orwell. There are plenty of people using pseudonyms all over Facebook/Instagram/Twitter/Linkedin/TikTok/Snapchat/Reddit/… But the vast majority of those are anything but anonymous and can easily be traced to their real identity by your local cops, random people within the OSINT<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (Open-Source Intelligence) community and trolls<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> on 4chan<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This is a good thing as most criminals/trolls are not really tech savvy and will be identified with ease. But this is also a bad thing as most political dissidents, human rights activists and whistleblowers can also be tracked rather easily.</p>

<p>This updated guide aims to provide introduction to various tracking techniques, id verification techniques and guidance to creating and maintaining anonymous identities online including social media accounts safely.</p>

<p>Will this guide help you protect yourself from the NSA, the FSB, Mark Zuckerberg or the Mossad if they’re out to find you? Probably not … Mossad will be doing “Mossad things” <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup> and will probably find you no matter how hard to try to hide<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>You have to consider your threat model<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> before going further.</p>

<p><img src="https://anonymousplanet.github.io/thgtoa/media/image1.jpeg" alt=""></p>

<p>(Illustration by xkcd.com, licensed under CC BY-NC 2.5)</p>

<p>Will this guide help you protect your privacy from OSINT researchers like Belingcat<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup> , Doxing<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup> trolls on 4chan<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup> and others that have no access to the NSA toolbox? More likely. Tho I wouldn’t be so sure about 4chan.</p>

<p>It’s also important to understand this guide is the humble result of years of experience and testing from a single individual (myself) and that many of those systems that aim to prevent anonymity are opaque closed-source systems. Most of those guidelines are guessed based on experience. These experiences take a lot of time and resources and are unfortunately far from being scientific. <strong>Your mileage may vary.</strong></p>

<p>You might think this guide has no legitimate use but there are many<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">10</a></sup><sup id="fnref:11" role="doc-noteref"><a href="#fn:11">11</a></sup> such as:</p>

<ul>
  <li>
    <p>Evading Censorship</p>
  </li>
  <li>
    <p>Evading Oppression</p>
  </li>
  <li>
    <p>Evading Unlawful Government Surveillance</p>
  </li>
  <li>
    <p>Whistle Blowing</p>
  </li>
  <li>
    <p>Journalism</p>
  </li>
  <li>
    <p>Activism</p>
  </li>
</ul>

<p>This guide is written for use by those good intended individuals who might not be knowledgeable enough to consider the big picture of online anonymity.</p>

<p>This guide is not intended for:</p>

<ul>
  <li>
    <p>Creating machine accounts of any kind (bots).</p>
  </li>
  <li>
    <p>Creating impersonation accounts of existing people (identity theft).</p>
  </li>
  <li>
    <p>Helping malicious individuals conduct unlawful or unethical activities (like trolls).</p>
  </li>
  <li>
    <p>Use by minors.</p>
  </li>
</ul>

<p>Feel free to report issues or recommend improvements in this repository if you have any.</p>

<p><strong>Use at your own risk. Anything in here is not legal advice and you should verify compliance with your local law before use (IANAL</strong><sup id="fnref:12" role="doc-noteref"><a href="#fn:12">12</a></sup><strong>).</strong></p>



<ul>
  <li>
    <p><strong>Be a permanent Adult resident in Germany where the courts have upheld up the legality of not using real names on online platforms (§13 VI of the German Telemedia Act of 2007</strong> <sup id="fnref:13" role="doc-noteref"><a href="#fn:13">13</a></sup><strong>). Alternatively be resident of any other country where you can validate and verify this is legal yourself.</strong></p>
  </li>
  <li>
    <p>This guide will assume you already have access to some PC (Windows/Linux) laptop computer (not a work/shared device).</p>
  </li>
  <li>
    <p>Don’t be evil (for real this time)<sup id="fnref:14" role="doc-noteref"><a href="#fn:14">14</a></sup>.</p>
  </li>
  <li>
    <p>Have patience as this process could take several weeks to finalize.</p>
  </li>
  <li>
    <p>Have a little budget to dedicate to this process (you’ll need at least budget for an USB key).</p>
  </li>
  <li>
    <p>Have a lot of free time on your hands to dedicate to this process.</p>
  </li>
  <li>
    <p>Be prepared to read a lot of references (do read them), guides (don’t skip them) and follow a lot of how-to tutorials thoroughly (don’t skip them either).</p>
  </li>
</ul>

<p><strong>This guide will (for the moment) not recommend using MacOS due to the latest Big Sur update which forces “unblockable” telemetry</strong><sup id="fnref:15" role="doc-noteref"><a href="#fn:15">15</a></sup><sup id="fnref:16" role="doc-noteref"><a href="#fn:16">16</a></sup> <strong>and because MacOS doesn’t offer MAC address randomization.</strong></p>



<p>There are many ways you can be tracked besides browser cookies and ads, your e-mail and your phone number. And if you think only the Mossad or the NSA/FSB can find you, you would be terribly wrong.</p>

<p>Here is a non-exhaustive list of some of the many ways you can be de-anonymized:</p>

<h2 id="your-ip-address">Your IP address:</h2>

<p>Your IP address<sup id="fnref:17" role="doc-noteref"><a href="#fn:17">17</a></sup> is the most known and obvious way you can be tracked. That IP is the IP you’re using at the source. This is where you connect to the internet. That IP is usually provided by your ISP (Internet Service Provider) (xDSL, Mobile, Cable, Fiber, Cafe, Bar, Friend, Neighbor). Most countries have data retention regulations<sup id="fnref:18" role="doc-noteref"><a href="#fn:18">18</a></sup> which mandates keeping logs of who is using what IP at a certain time/date for up to several years or indefinitely. Your ISP can tell a third party that you were using a specific IP at a specific date and time, years after the fact. If that IP (the origin one) leaks at any point for any reason, it can be used to track down you directly. In many countries, you won’t be able to have internet access without providing some form of identification to the provider (address, ID, real name, e-mail …).</p>

<p>Useless to say that most platforms (such as social networks) will also keep (sometimes indefinitely) the IP addresses you used to sign-up but also those you used to sign-in.</p>

<p>For those reasons, we’ll need to not use that origin IP (the one tied to your identification) or hide it as much as we can through a combination of various means:</p>

<ul>
  <li>
    <p>Using a public WIFI service (free).</p>
  </li>
  <li>
    <p>Using an anonymous VPN service<sup id="fnref:19" role="doc-noteref"><a href="#fn:19">19</a></sup> (paid by cash).</p>
  </li>
  <li>
    <p>Using the Tor Anonymity Network<sup id="fnref:20" role="doc-noteref"><a href="#fn:20">20</a></sup> (free).</p>
  </li>
</ul>

<p>All those will be explained later in this guide.</p>

<h2 id="your-dns-requests">Your DNS requests:</h2>

<p>DNS stands for “Domain Name System”<sup id="fnref:21" role="doc-noteref"><a href="#fn:21">21</a></sup> and is a service used by your browser (and other apps) to find the IP addresses of a service. It’s pretty much a huge “contact list” (phone book for older people) that works like asking it a name and it returns the number to call. Except it returns an IP instead.</p>

<p>Every time your browser wants to access a certain service such as Google through <a href="https://www.google.com/">https://www.google.com</a>. Your Browser (Chrome or Firefox) will query a DNS service to find the IP addresses of the Google web servers.</p>

<p>Usually the DNS service is provided by your ISP and automatically configured by the network you’re connecting to. This DNS service could also be subject to data retention regulations or will just keep logs for other reasons (data collection for advertising purposes for instance). Therefore this ISP will be capable of …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anonymousplanet.github.io/thgtoa/guide.html">https://anonymousplanet.github.io/thgtoa/guide.html</a></em></p>]]>
            </description>
            <link>https://anonymousplanet.github.io/thgtoa/guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302389</guid>
            <pubDate>Fri, 04 Dec 2020 14:14:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My experience using Lighthouse in the real world]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302334">thread link</a>) | @jerodsanto
<br/>
December 4, 2020 | https://leonardofaria.net/2020/11/30/my-experience-using-lighthouse-in-the-real-world/ | <a href="https://web.archive.org/web/*/https://leonardofaria.net/2020/11/30/my-experience-using-lighthouse-in-the-real-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Lighthouse has been part of my daily work for the last few months and I shared some snippets in my last few posts. For this particular post, it is time to share how I am using Lighthouse in a product used by millions of people and what I have discovered during this process.</p><p><img src="https://leonardofaria.net/wp-content/uploads/2020/11/lighthouse.jpg" alt="Lighthouse photo by Robert Wiedemann"></p><p><em>Disclaimers</em>: 1. This content may be reviewed in the future as I learn more about web performance and Lighthouse; 2. Do not take this post as professional/legal advice; 3. Do not take my comments on tech X or Y as attacks to tech X or Y.</p><p>It sounds obvious but it doesn’t hurt to repeat the message: do not reinvent the wheel (until you absolutely need to). You can start <a href="https://support.google.com/webmasters/answer/9205520">monitoring Core Web Vitals for free</a> in the Google Search Console.</p><p>If this is not enough, or if you have a complex web app behind authentication, or any other scenarios, you can start by using a tool listed in the <a href="https://github.com/GoogleChrome/lighthouse#lighthouse-integrations-in-web-perf-services">Lighthouse integrations docs</a>. From that list, I can only speak of <a href="https://calibreapp.com/">Calibre</a> as I have not used the others. I am not affiliated with them.</p><p>Using Calibre, you can schedule Lighthouse tests, create performance budgets, see pretty charts, and learn what performance looks like in your product. The relevant information is easy to find and their product has a very polished UI, however, at a certain point, you may want more and that means ‘custom development’.</p><p>We have decided to create our own tool at <a href="https://thinkific.com/">Thinkific</a> in order to run Lighthouse tests to be aligned with the monitoring stack and give us more flexibility. Here are some details:</p><ul><li>We run tests every hour;</li><li>We run tests in our Critical User Journeys: these are important routes of our application used by different types of users;</li><li>The report files (JSON, HTML), along with the page screenshot and HAR file are stored in S3 for future reference;</li><li>The numbers (Lighthouse scores, assets file sizes, Web Vitals) are sent to a relational database (Postgres) and <a href="https://prometheus.io/">Promotheus</a>, a monitoring system and time series database. Postgres empowers the creation of custom reports as we need and Prometheus is used with Grafana to create custom dashboards.</li></ul><p>Comparing to open-source solutions, our tool is similar to <a href="https://github.com/Verivox/lighthouse-monitor/">lighthouse-monitor</a>.</p><h3 id="understanding-variability">Understanding variability</h3><p>Running Lighthouse in our tool, we noticed the performance score changed due to inherent variability in web and network technologies, even when there hadn’t been a code change.</p><p>Network, client hardware, and web server variabilities are some examples of how the score can trick you. <a href="https://github.com/GoogleChrome/lighthouse/blob/master/docs/variability.md">Lighthouse documentation</a> clarifies all the different sources of variability and how to deal with them.</p><p>In our case, we run Lighthouse 5 times per URL, calculating a median score. We also store the min/max values in case we want to investigate one-off results.</p><h2 id="working-with-lighthouse-results">Working with Lighthouse results</h2><p>What do I do when I have Lighthouse reports from 9 different URLs?</p><p><img src="https://leonardofaria.net/wp-content/uploads/2020/11/detective-wall.jpg" alt="Detective wall, from the Isle of Dogs movie"></p><p>FCP, LCP, TTI, TBT, CLS: my work in the last few months is analyzing data and connecting dots. Sometimes I find low hanging fruit that improves one metric here and there, sometimes I go down the rabbit hole.</p><p>With data coming from everywhere, I am following the scientific method to focus on what matters:</p><ol><li>Make an observation.</li><li>Ask a question.</li><li>Form a hypothesis or testable explanation.</li><li>Make a prediction based on the hypothesis.</li><li>Test the prediction.</li><li>Iterate: use the results to make new hypotheses or predictions.</li></ol><p>When it comes to performance, there is no silver bullet. Sometimes images are the culprits of bad performance scores, sometimes it is an architecture problem. The goal of my post is not blaming X or Y. In saying this, let me share a few thoughts on these two topics:</p><h3 id="image-optimization">Image optimization</h3><p>Images impact page load time since bigger images will take longer to be downloaded and as a result, it will impact different Lighthouse metrics - usually CLS, LCP.</p><p>Recently, <a href="https://github.com/vercel/next.js/discussions/16832">Google worked with Next.js</a> to create an <a href="https://nextjs.org/docs/basic-features/image-optimization">Image component</a> that delivers optimized images. The framework supports image conversion from via Imgix, Cloudinary, Akamai and as expected, Vercel.</p><p>I predict that the conversion on demand, by using third-party services as mentioned above or by using serverless solutions will become more and more popular. Starting next year, Google <a href="https://developers.google.com/search/blog/2020/11/timing-for-page-experience">will include Web Vitals metrics</a> in the page ranking algorithms.</p><h3 id="old-architectures-didnt-age-well">Old architectures didn’t age well</h3><p>Old SPA architectures doesn’t perform well these days and Lighthouse captures that.</p><p>Here is one example: back in the day, people (including myself) used to build their JS code into a single file. We wanted to avoid multiple files because HTTP/1.1 didn’t support too many concurrent requests, which was improved in HTTP/2. Today, unused JS will be caught in the Lighthouse tests.</p><p><img src="https://leonardofaria.net/wp-content/uploads/2020/11/codesplitting.png" alt="Code splitting cartoon by Crystallize"></p><p>Code Splitting is part of any modern JS tech stack using webpack and, in React, it can be combined with <a href="https://loadable-components.com/docs/getting-started/">Loadable Components</a> and <a href="https://reactjs.org/docs/code-splitting.html#reactlazy"><code>React.lazy</code></a>. Giving the user only what they need is key.</p><p>In the back end, <a href="https://graphql.org/">GraphQL</a> showed us that we can request data as we go. I know this can also be done with REST as long we know what is in the UI but the whole point here is to deliver only the data that users need.</p><h2 id="conclusions">Conclusions</h2><p>I hope this series shed some light (no pun intended) on your front-end performance skills. Lighthouse is so powerful that people out there are creating full SaaS products to make the web better.</p><p>Are you using Lighthouse or planning to start using? Let me know in the comments!</p></div></div>]]>
            </description>
            <link>https://leonardofaria.net/2020/11/30/my-experience-using-lighthouse-in-the-real-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302334</guid>
            <pubDate>Fri, 04 Dec 2020 14:09:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bonsai Launches Free Tax Calculator for US Freelancers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302320">thread link</a>) | @stefanallday
<br/>
December 4, 2020 | https://pulseblueprint.com/careers/entrepreneurship/bonsai-freelance-tax-calculator/ | <a href="https://web.archive.org/web/*/https://pulseblueprint.com/careers/entrepreneurship/bonsai-freelance-tax-calculator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A freelancer is at once the boss, the employee, and the finance manager. But there’s one thing no one likes dealing with: taxes. Even when you have <a href="https://pulseblueprint.com/careers/entrepreneurship/freelance-contract-clauses-every-freelancer-should-use/" target="_blank" rel="noreferrer noopener">iron-clad freelance contracts</a>, taxes can be a nuisance at best and overly complicated and time consuming at worst. One platform – Bonsai – is aiming to fix that.</p><p>Bonsai, a freelance business management platform boasting over 250,000 users, has just launched a new <a href="https://www.hellobonsai.com/self-employment-tax-calculator" target="_blank" rel="noreferrer noopener">freelance tax calculator</a> for US-based freelancers. The calculator provides an estimate of how much tax you might end up owing based on: your state, filing status, income levels, and business expenses.&nbsp;</p><p>“I’ve freelanced for many years, and self-employment taxes were always an area of confusion,” said Bonsai’s Head of Marketing, Madhav Bhandari, in an interview with <a href="https://aithority.com/news/bonsais-freelance-tax-hub-is-free-and-public-for-everyone-now/" target="_blank" rel="noreferrer noopener">AIThority</a>.</p><figure><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201%201'%3E%3C/svg%3E" data-src="https://lh4.googleusercontent.com/GmMCVhDxoFe_WEDJKuqqQlyvamAdCBjYwS4px3EgcdElItJpY46cLhNS-KdaTeNsJnEoJUsxNBWbOj2e25DYV_Bg9jsXykP2RHCyoX0y8It2zxtXdG-Ah7YXoUQYgPqI7a7tEgBs" alt="Bonsai self employment tax calculator" data-old-src="//pulseblueprint.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif"><figcaption>Source: <em>Bonsai Freelance Tax Calculator</em></figcaption></figure><h2>Helping freelancers with self-employment taxes</h2><p>In most states – and most countries outside of the US – freelancers are lumped in with “self-employed individuals.” This means they have to register their businesses as self-employed and handle taxes as such. Thankfully, this means access to all the same deductions as small businesses. Unfortunately, the web of deductions is incredibly complex. What supports you can access depends on both your state and your city, as different municipalities offer different support.&nbsp;</p><p>One thing that every freelancer can leverage to reduce their tax bill, though, is business expenses. Whenever you spend money legitimately to run your business, you can deduct that expense against your taxes. This web can also get complicated, so Bonsai launched a <a href="https://www.hellobonsai.com/self-employment-tax-deductions" target="_blank" rel="noreferrer noopener">library of common self-employment tax deductions</a>. At the top of the page, you’ll see a list of things that almost every freelancer can deduct. These range from set up expenses to ongoing subscriptions. At the bottom, you’ll see a list of types of freelancers – from makeup artists to software engineers – linking out to the common deductions for each type of work.&nbsp;</p><figure><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201%201'%3E%3C/svg%3E" data-src="https://lh4.googleusercontent.com/b-2xmtEMndeM-ASxgzNaFRDiKLR2d42ctCJRXDJBXge_GUoFMEj8K3YzuiIRCnqtBy3yjNktGtXzYbF0kMqAdY0PZEZNaLb7Klvc-2-l5xmCDRGppf0Nik893Hq5-9BsRa4jVUIX" alt="image of Bonsai's tax deductions by career type" data-old-src="//pulseblueprint.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif"><figcaption>Source: <em>Bonsai Tax Deductions Information Hub</em></figcaption></figure><h2>Avoiding the pitfalls of freelancing</h2><p>According to one study, a common <a href="https://pulseblueprint.com/news/biggest-challenges-freelancers-face-skynova-study/" target="_blank" rel="noreferrer noopener">challenge freelancers face</a> is not saving or withholding for taxes. Ideally, once you have a ballpark figure of how much tax you will need to pay, you can also begin to save so you don’t have a surprise bill.&nbsp;</p><p>Many of the other key challenges freelancers face revolve around payment. Freelancers say they have trouble ensuring on-time payment and many send invoices late or don’t have contracts before starting work. All of these challenges are also ones Bonsai says they can help with through their paid platform. However, you don’t want to pay for a platform to get this benefit. There are free ways to ensure clients pay on time, from <a href="https://pulseblueprint.com/careers/entrepreneurship/freelance-contract-clauses-every-freelancer-should-use/" target="_blank" rel="noreferrer noopener">freelance contract clauses</a> to free platforms like <a href="https://www.waveapps.com/" target="_blank" rel="noreferrer noopener">Wave</a>.</p><p>“As the year comes to an end and you start reflecting on 2020 and planning for 2021, we hope this gives freelancers some help and confidence in managing their finances,” said Bhandari.</p><h4><strong>Read Next</strong>: <a rel="noreferrer noopener" href="https://pulseblueprint.com/news/hawaii-remote-program-movers-and-shakas/" target="_blank">Hawaii Will Fly Remote Workers Over, With One Catch </a></h4></div></div>]]>
            </description>
            <link>https://pulseblueprint.com/careers/entrepreneurship/bonsai-freelance-tax-calculator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302320</guid>
            <pubDate>Fri, 04 Dec 2020 14:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Effective Reading]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25302132">thread link</a>) | @accountLost
<br/>
December 4, 2020 | https://maartenvandoorn.nl/reading-guide/ | <a href="https://web.archive.org/web/*/https://maartenvandoorn.nl/reading-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1454">

	<!-- .entry-header -->



	<div>

		
<figure><img src="https://cdn-images-1.medium.com/max/2600/1*0tmBPKA1YGo82VNeMS3KhA.jpeg" alt=""><figcaption> <a rel="noreferrer noopener" href="https://unsplash.com/photos/9pw4TKvT3po?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Let’s make that magic&nbsp;happen</a> </figcaption></figure>



<p>Learning is a heavily misunderstood&nbsp;concept.</p>



<p>As a&nbsp;paradigm&nbsp;example of&nbsp;deep work,&nbsp;we understand that, when reading, directing your full attention to the material at hand is essential.&nbsp;Graspingcomplex information is hard.</p>



<p>But this is only half the battle.</p>



<p>After some string of words hits your retina and has made its way to your brain, you’re&nbsp;not done.</p>



<p>In a&nbsp;cruel&nbsp;irony,&nbsp;these hours of&nbsp;deep work&nbsp;often cause&nbsp;flow&nbsp;states&nbsp;and the feeling that ‘you’ve had a good day’ and learned a&nbsp;shitload&nbsp;of new stuff.</p>



<p>But for many reading&nbsp;episodes&nbsp;this feeling is&nbsp;deceptive.&nbsp;There is anineliminable&nbsp;aspect to learning that takes place&nbsp;<em>after&nbsp;</em>the&nbsp;glorious&nbsp;flow state.</p>



<p>The&nbsp;other half of the battle is&nbsp;to&nbsp;transfer the newly acquired intelligence from your working memory to your&nbsp;long-term&nbsp;understanding and&nbsp;integrate&nbsp;it into your standing stack of mental models.</p>



<p>If you don’t&nbsp;facilitate&nbsp;this, your learning&nbsp;gains&nbsp;are only a&nbsp;fraction&nbsp;of what they could have been.</p>



<p>In this article,&nbsp;I’m going to breakdown how to win the battle and the war — how to&nbsp;avoid&nbsp;these traps and organize your reading habit for a maximalReturn On Investment (ROI)&nbsp;on reading hours.</p>



<p>This is what we’ll cover:</p>



<pre><strong>Table of Contents</strong></pre>



<pre>1. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#1b1d">Meta-Learning</a><br>2. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#1d70">Learning is a two-step process</a><br>3. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#9181">Remembering the right things</a><br>4. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#7b89">Enter: Mental models</a><br>5. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#a837">Learning = upgrading your mental models</a></pre>



<pre>6. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#f0d0">How to ‘get it in there’ (macro-level)</a><br>7. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8823">How to ‘get it in there’ (micro level)</a><br>7.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#19fe">Know your why</a></pre>



<pre>8. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#d988">Active reading</a><br>8.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#414f">How to make a mind map</a><br>8.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#ad79">Which Returns are you aiming for?</a><br>8.3 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#d61e">Written active recall with bullet points</a><br>8.4 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#a187">How to actively read a book</a><br>8.5 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8ead">Remember your why (yes, again)</a></pre>



<pre>9. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#4e04">Advanced active reading</a><br>9.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#9782">The QEC method</a><br>9.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8dac">Keep a running tally</a><br>9.3 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#dc6b">Put your unconsciousness to work</a><br>9.4 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#7a10">Pulling it all together</a><br>9.5 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#6b84">How to actively read a book (advanced)</a></pre>



<pre>10. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#926b">Organizing repetition and reflection</a><br>10.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#f934">Setting up and using your review cycle</a><br>10.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#5182">Improved learning: engage in active recall</a></pre>



<pre><a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#fc24">Conclusion: The cycle of learning</a></pre>



<p>Warning: this is a very&nbsp;nerdy&nbsp;post.</p>



<h3 id="1b1d">Meta-Learning</h3>



<p>Meta-learning&nbsp;is knowing how to learn.&nbsp;It is one of the most important skills to learn, yet few people know how to do to it.</p>



<p>Reading and writing is what I do for a living, and, interestingly, a lot of non-imaginary&nbsp;friends have been asking me how I learn.&nbsp;This is special, becausemost of the times when people don’t know how to do something, they go&nbsp;togreat&nbsp;lengths&nbsp;<em>not&nbsp;</em>to notice their&nbsp;deficiency.</p>



<p>Could it be that many students turned ‘knowledge workers’ have the&nbsp;naggingfeeling that something is missing in their skillset because they were never taught&nbsp;meta-learning?</p>



<p>This is not their fault, but a&nbsp;<a href="https://medium.com/the-understanding-project/schools-dont-support-personal-development-they-distort-it-7e1c227eb01d" target="_blank" rel="noreferrer noopener">lack in our education system</a>.</p>



<p>As Adam Robinson observed on the&nbsp;<a href="https://fs.blog/adam-robinson-pt2/" rel="noreferrer noopener" target="_blank"><em>Farnam Street&nbsp;</em>podcast</a>:</p>



<blockquote><p>“<strong>No one ever shows us how to learn, ever</strong>.&nbsp;Nowhere in school.&nbsp;For example, imagine, Shane, [Shane is the host of the FS podcast] in French class, French 101, your first French class, your teacher said,&nbsp;“Everyone, you’re going to have to learn a lot of vocabulary in this class so before I teach you any words I’m going to teach you a way to remember vocabulary.”&nbsp;They never do that.&nbsp;They just go, “We’re going to have a quiz on these 30 words on Monday.&nbsp;Good luck.”&nbsp;But they don’t teach us how to learn actually, or remember things.”</p></blockquote>



<p>This is&nbsp;weird, because,&nbsp;in today’s high-information world,&nbsp;people need the ability to&nbsp;<em>make sense of</em>&nbsp;complexity and to&nbsp;<em>combine</em>&nbsp;many bits of data into a broad picture of the world.</p>



<p>Merely&nbsp;<em>acquiring</em>information is&nbsp;<em>not&nbsp;</em>(yet) learning.</p>



<p>Learning itself is a skill, and knowing how to do it well is an incredibly valuable advantage.</p>



<p>We take this is for granted, but how to do this is&nbsp;far from&nbsp;obvious&nbsp;and doesn’t get taught in the curriculum.</p>



<hr>



<h3 id="1d70">Learning is a&nbsp;two-step&nbsp;process</h3>



<p>So, how do we learn?</p>



<p>Before we attempt to answer the question,&nbsp;let’s get clear&nbsp;on what a&nbsp;satisfactoryanswer needs to get us.&nbsp;What does it&nbsp;<em>mean&nbsp;</em>to learn?&nbsp;When have you learned something?</p>



<p>In the introduction, I stated that&nbsp;just studying the information isn’t enough(no matter how intense your focus was).&nbsp;Learning has&nbsp;two phases — not one.</p>



<ol><li>Read/listen&nbsp;the damn thing</li><li>Process and&nbsp;recall&nbsp;what you’ve just ‘learned’</li></ol>



<p>A lot has been said about the first phase — about deep work, concentration, blocking out&nbsp;distractions, and so&nbsp;forth.&nbsp;This makes sense:&nbsp;if you’re checking Facebook all the time,&nbsp;your mind is not ‘there’, and you might as well not have spent your afternoon ’reading’ this book.</p>



<p>This is all great and I‘m a big fan, but in the&nbsp;meantime, we’re ignoring step two.</p>



<p>If you don’t spend time revisiting and grappling with the book either,&nbsp;<em>the same applies</em> — you might as well not have read it.&nbsp;In the long run, there is no difference between skipping the first or the second stage (except whether you passed that French test in high school back in 2019…).</p>



<p>After you’ve killed Cersei, you’ve still got the&nbsp;White Walkers to deal with.&nbsp;If you don’t, you lose either way.</p>



<p>That is why students who&nbsp;binge-study&nbsp;the night before the exam quite literally forget everything two days later:&nbsp;while all these&nbsp;lame&nbsp;French words were still in their short-term memory,&nbsp;allowing them to pass the test,&nbsp;the information never&nbsp;transitioned&nbsp;to their long-term understanding — and so, sooner or later, it&nbsp;evaporated.</p>



<p>To learn,&nbsp;you need to transfer the newly acquired intelligence from&nbsp;your working memory to your long-term understanding.</p>



<p><strong>The jump from short-term memory to long-term understanding doesn’t happen automatically.</strong><strong>The default mode, after you close your books for the day, is not&nbsp;</strong><strong>retainment</strong><strong>&nbsp;but&nbsp;<em>forgetting</em></strong><strong>.</strong></p>



<p>This learning guide&nbsp;is not about&nbsp;<a href="https://medium.com/the-understanding-project/why-you-dont-need-to-read-those-productivity-guides-347fe02cc196" target="_blank" rel="noreferrer noopener">how to do generic deep work</a>.&nbsp;It explains how to maximize the ROI on hours spent reading,&nbsp;<em>assuming</em>&nbsp;you did them ‘deep work style’.</p>



<h3 id="9181">Remembering the right&nbsp;things</h3>



<p>First, I need to discuss a common&nbsp;objection&nbsp;that denies phase two of learning matters.&nbsp;If you have no&nbsp;quibble&nbsp;with memorization, and doing the required effort, you can skip this section.</p>



<p>“But Mr. Maarten,” the protest goes, “you mention ‘processing’ and ‘remembering’ into my ‘long-term understanding’, but isn’t memorizing pointless?&nbsp;My Google Assistant can look everything up and also is smarter than me, says my Google Assistant.”</p>



<p>Indeed,&nbsp;Albert Einstein is&nbsp;<a href="https://medium.com/the-polymath-project/studying-history-is-more-important-than-ever-in-todays-economy-c99fde4be7d0" target="_blank" rel="noreferrer noopener">supposed</a>&nbsp;to have said:&nbsp;“Never&nbsp;memorize&nbsp;what you can look up in a book”.&nbsp;In Einstein’s days, books were&nbsp;unequaled&nbsp;as a source of information.&nbsp;We, on the other hand, live in an age where nearly everything can be accessed through the magic vehicle of internet.&nbsp;Following Einstein’s logic, then,&nbsp;<em>nothing&nbsp;</em>is worth memorizing anymore, because&nbsp;<em>everything</em>&nbsp;can be looked up.</p>



<p>But, of course, that is probably not what old Albert was getting at.</p>



<p>Most likely,&nbsp;the advice he wanted to&nbsp;dispense&nbsp;was that&nbsp;you should not waste your time by committing unimportant details to memory.&nbsp;Rather,&nbsp;your&nbsp;focus should be on understanding the bigger picture — on&nbsp;how things relate to each other.</p>



<p>This reminds me of Elon Musk’s&nbsp;approach to learning.&nbsp;He&nbsp;<a href="https://www.reddit.com/r/IAmA/comments/2rgsan/i_am_elon_musk_ceocto_of_a_rocket_company_ama/" rel="noreferrer noopener" target="_blank">recommends</a>viewing knowledge as a tree:</p>



<blockquote><p>Make sure you understand the fundamental principles, the trunk and big branches, before you get into the leaves/details or there is nothing for them to hang on to.</p></blockquote>



<p>To ‘learn’, we need to do more than merely feeding ourselves new information.&nbsp;Expanding our intelligence requires&nbsp;<em>connecting</em>&nbsp;new materials to what we already knew&nbsp;(the second phase of learning).&nbsp;That, in turn, requires something to connect&nbsp;<em>to.</em></p>



<p>There’s no adding branches without a solid trunk.</p>



<p>The very possibility of genuine insight requires a memorized base.&nbsp;Without it, data you consume will not be added to your tree of knowledge.&nbsp;Instead, they will float in the air for a couple of weeks or so, before being taken away by the wind.</p>



<p>Knowledge, gone.&nbsp;Time, wasted.</p>



<p>What I’m saying is&nbsp;<em>not&nbsp;</em>that we should&nbsp;devise&nbsp;techniques which enable us torecite&nbsp;everything we’ve learned.&nbsp;That’s why we’re not talking about, for example,&nbsp;retaining&nbsp;the date of the French revolution.</p>



<p>However,&nbsp;you&nbsp;<em>should&nbsp;</em>learn by heart the lessons it tells you about how the world works&nbsp;and update your representation of reality&nbsp;accordingly.</p>



<p>In&nbsp;other words,&nbsp;you should use it to&nbsp;inform&nbsp;your&nbsp;unconscious — the&nbsp;sum&nbsp;of your mental models.</p>



<h3 id="7b89">Enter: Mental&nbsp;models</h3>



<p>I’ve long been skeptical about mental models since (1) they’re all the rage now and (2) no one seems to be able to explain in concrete terms what they are. A dangerous combination.</p>



<p>It turned out my doubt was due to ignorance on my part.</p>



<p>A mental model,&nbsp;as&nbsp;<a href="https://en.wikipedia.org/wiki/Mental_model" rel="noreferrer noopener" target="_blank">Wikipedia</a>&nbsp;tells us, is</p>



<blockquote><p>An explanation of someone’s thought process about how something works in the real world.&nbsp;<strong>It is a representation of the surrounding world</strong>, the relationships between its various parts and a person’s intuitive perception about his or her own acts and their consequences.</p></blockquote>



<p>Every problem and situation is just another ‘one of those’ — another one of a certain type.&nbsp;Figuring out what type it is and reflecting on principles for handling that type of issue will help you do a better job.</p>



<p>On the conscious level, mental models allow us to ‘fit’ different possible interpretations onto reality to see if it is ‘one of those’.</p>



<p>For example,&nbsp;according to&nbsp;<a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor" rel="noreferrer noopener" target="_blank">Hanlon’s Razor</a>&nbsp;one should&nbsp;“never attribute tomalice&nbsp;that which is adequately explained by carelessness”.&nbsp;When your coworker hands you crappy slides for the presentation you have to give in five minutes — what’s going on here?</p>



<p>Which ‘one of those’ do we have here?</p>



<p>You can see&nbsp;how different mental models in our heads will cause us to reach different conclusions about the correct interpretation of the situation.</p>



<p>A mental model is a mental, simplified&nbsp;depiction&nbsp;of how something works.They are how we order complexity, why we consider some things more relevant than others, and how we reason.&nbsp;They help us filter, organize and understand.</p>



<p>For instance, according to&nbsp;<a href="https://en.wikipedia.org/wiki/Pareto_distribution" rel="noreferrer noopener" target="_blank">Pareto distribution</a>,&nbsp;“for many events,&nbsp;roughly 80% of the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maartenvandoorn.nl/reading-guide/">https://maartenvandoorn.nl/reading-guide/</a></em></p>]]>
            </description>
            <link>https://maartenvandoorn.nl/reading-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302132</guid>
            <pubDate>Fri, 04 Dec 2020 13:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking AWS EKS Distro for a Spin]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302062">thread link</a>) | @robertwinter
<br/>
December 4, 2020 | https://elastisys.com/taking-eks-distro-for-a-spin/ | <a href="https://web.archive.org/web/*/https://elastisys.com/taking-eks-distro-for-a-spin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div data-elementor-type="wp-post" data-elementor-id="8833" data-elementor-settings="[]"><div><div><section data-id="3d1c630" data-element_type="section"><div><div><div data-id="739a184" data-element_type="column"><div><div><div data-id="7afbc26" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><b>TL;DR:</b></p><blockquote><p><span>EKS Distro = kops + Kubernetes fixes + aws-iam-authenticator</span></p></blockquote><p><span>AWS has recently launched </span><a href="https://aws.amazon.com/blogs/opensource/introducing-amazon-eks-distro/"><span>EKS Distro</span></a><span>, the Kubernetes distribution that powers its managed Kubernetes offer, called Elastic Kubernetes Service (EKS). This means that customers no longer have to choose between EKS (as a managed service) and some other Kubernetes setup. Instead, they can choose between EKS as a service managed by AWS or managed by themselves. The application hosted on top won’t observe any difference.</span></p><p><span>Being big fans of Kubernetes distributions, to the point where we open-sourced our own </span><a href="https://compliantkubernetes.io/"><span>Compliant Kubernetes</span></a><span>, we took EKS Distro for a spin.</span></p><p><span>For those unfamiliar with the term, a distribution is to Kubernetes just like a distribution is to Linux. As the saying goes, Kubernetes is a powerful engine, but you need to build a car around it. In other words, a Kubernetes distribution is Kubernetes with a chosen configuration and a chosen set of addons. For example, Kubernetes is </span><a href="https://searchitoperations.techtarget.com/news/252487963/Kubernetes-security-defaults-prompt-upstream-dilemma"><span>not secure by default, nor by itself</span></a><span>. Hence, a security-focused Kubernetes distribution will configure Kubernetes with restrictive PodSecurityPolicies and add intrusion detection addons.</span></p><p><span>Specifically, a Kubernetes distribution consists of three parts:</span></p><ol><li><span>A procedure — either code or documentation — to create </span><b>infrastructure</b><span> necessary for a Kubernetes cluster, such as virtual machines, load balancers, network security policies, DNS records, etc. The distribution may impose a certain base operating system (OS) image or may cater to a large variety of base images.</span></li><li><span>A procedure to </span><b>bootstrap</b><span> Kubernetes control plane components onto the control plane and worker nodes, in particular the apiserver, scheduler, kubelets and controller manager. Most distributions come with a cloud integration. This means that Kubernetes Services of type LoadBalancer and PersistentVolumeClaims automatically work.</span></li><li><span>A procedure to set up </span><b>addons</b><span>, such as Ingress controllers, certificate managers, intrusion detection, custom authentication, to name a few.</span></li></ol><p><span>EKS Distro launched with a </span><a href="https://distro.eks.amazonaws.com/"><span>healthy documentation and code</span></a><span>. You have several ways of using it:</span></p><ul><li><b>Build it from scratch</b><span>: The documentation and code are sufficient to build EKS Distro from scratch, specifically, the container images that make up the Kubernetes control plane components.</span></li><li><b>Start EKS-D</b><span>: If you don’t need to customize control plane images, then you can use the pre-build images by AWS from their public container registry.</span></li></ul><p><span>Our next observation is related to the level of automation of EKS Distro. Let’s take an automation scale with a few levels:</span></p><ol><li><span>Prose-only documentation.</span></li><li><span>Documentation with copy-paste-able code snippets.</span></li><li><span>Command that does everything.</span></li><li><span>API that does everything.</span></li></ol><p><span>EKS Distro is level 2: It focuses on providing a lot of documentation and copy-paste-able. code snippets. However, if you are the “TL;DR” type, EKS Distro will disappoint you. </span><b>You need to carefully read the prose to understand how to use the next code snippet.</b><span>&nbsp;</span></p><p><span>While this could be seen as a weakness, we find it a strength. Instead of pre-baking and imposing many decisions on the user, </span><b>EKS Distro is rather un-opinionated</b><span>. It allows the user to control which decisions to take at each step, while at the same time offering “it just works” defaults.</span></p><p><span>Next observation: </span><b>EKS Distro is built on top of </b><a href="https://github.com/kubernetes/kops"><b>kops</b></a><span>. Comparing kops and </span><a href="https://github.com/kubernetes-sigs/kubespray"><span>kubespray</span></a><span> — the two dominant open source Kubernetes cluster life-cycle managers — deserves its own article. For now, suffice to say that, correctly setting up EKS Distro requires a fair knowledge of kops for things like setting up AWS IAM roles and the DNS stack accordingly. Even small mistakes with kops — e.g., not setting up the DNS stack correctly — will make you unsuccessful with deploying EKS Distro. On the upside, if you are already familiar with kops, EKS Distro will feel like a fairly thin and unobtrusive layer on top.</span></p><p><span>As said before, EKS Distro is a fairly thin layer on top of kops. It basically adds three things:</span></p><ol><li><span>A bit of automation on top of kops.</span></li><li><span>A few fixes for Kubernetes.</span></li><li><span>The AWS IAM authenticator.</span></li></ol><p><span>Let us focus on the last two.</span></p><p><span>The control plane images </span><a href="https://en.wikipedia.org/wiki/Backporting"><span>backport</span></a><span> a few Kubernetes fixes that are critical for EKS Distro. These fixes are available in the main branch of the Kubernetes project, however, backporting them allows AWS to provide these without waiting for a new Kubernetes release.</span></p><p><span>The AWS IAM authentication enables authentication with the Kubernetes cluster using AWS credentials. This does make sense for users who want to leverate AWS IAM roles for everything, including on-prem Kubernetes clusters. However, for users who aim for a cloud-agnostic strategy, </span><a href="https://github.com/dexidp/dex"><span>OpenID</span></a><span> is a more portable Kubernetes authentication solution.</span></p><p><span>Have I already mentioned how thin EKS Distro is? We were surprised to discover that it does not include an Ingress controller, a certificate manager or a log forwarded. Truly un-opinionated!</span></p><p><span>While the ride was pretty smooth, we did bump into a few minor issues:</span></p><ol><li><span>EKS Distro assumes the us-west-2 region in several places. Fortunately, due to its light packaging, fixing the scripts to deploy in my favorite region, eu-north-1, was a no-brainer.</span></li><li><span>EKS Distro blocked the first time I tried it out, due to my laptop being entropy starved and /dev/random being stuck. A simple change, to take randomness from /dev/urandom fixed the problem. In fact, our </span><a href="https://github.com/aws/eks-distro/commit/c1225ea8482db2c69da6b554e280a0365504f590"><span>Pull Request (PR)</span></a><span> was merged within hours. So another point goes to EKS Distro for being very welcoming.</span></li></ol><p><span>Good:</span></p><ul><li><span>Un-opinionated, thin, easy to modify for one’s own needs.</span></li><li><span>Based on kops and will feel familiar to existing kops users.</span></li><li><span>Comes with AWS IAM authentication.</span></li></ul><p><span>Bad:</span></p><ul><li><span>“No battery included, not even removable ones”. EKS Distro has no Ingress controller, no certificate manager, no log forwarder.</span></li><li><span>Minor gotchas, but overall a smooth ride.</span></li></ul><p><span>Ugly:</span></p><ul><li><span>Nothing really. A great AWS project, as expected.</span></li></ul></div></div></div></div></div></div></div></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://elastisys.com/taking-eks-distro-for-a-spin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302062</guid>
            <pubDate>Fri, 04 Dec 2020 13:36:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula for CI at The Qt Company: Running over 4 million VMs per year]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25301783">thread link</a>) | @amarti
<br/>
December 4, 2020 | https://opennebula.io/qt-case-study/ | <a href="https://web.archive.org/web/*/https://opennebula.io/qt-case-study/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="kt-layout-id_7973b9-ed"><div>
<div><div>
<h3>“WE NEEDED SOMETHING THAT WAS DESIGNED TO CREATE VMs ON DEMAND”</h3>



<p><strong>The Qt Company</strong> develops and delivers the Qt development framework under commercial and open source licenses. They enable the reuse of software code across all operating systems, platforms and screen types, from desktops and embedded systems to wearables and mobile devices. Qt is used by more than one million developers worldwide and is the leading independent technology behind millions of devices and applications.&nbsp;&nbsp;</p>



<p>Before starting to use OpenNebula, Qt<strong> </strong>had a performance problem with the CI system. The autotests took over 30 times longer to run compared to a normal situation. The company identified different bottlenecks:&nbsp;</p>



<ul><li>The bandwidth with which the virtual machines stored local data to their virtual hard drives was an issue. The servers, on which our virtual machines ran, store all their data on a centralized storage. That storage had to be cached somehow.</li><li>Several generations of hardware installed, with different speeds sharing the same bandwidth.</li><li>The centralized storage repeatedly went down when trying to start more than 200 VMs in the CI. And consequently, all builds and autotest runs were affected.</li></ul>



<p>In addition, they were using Jenkins, the open source CI/CD automation software. “Jenkins was not intended to run VMs that pop in and out of existence. We had to create nodes via Python scripts and the state machines became painful,” said Tony Sarajärvi, CI Tech Lead at The Qt Company. “We needed something that was designed to create VMs on demand.” This fact turned out to be the key factor for choosing OpenNebula.</p>



<h3 id="kt-adv-heading_c91db1-d2"><em><em>“With open source non-proprietary code we can go deep into</em></em></h3>



<h3 id="kt-adv-heading_ecfaf8-63"><em><em>the root causes of problems and fix drivers if that’s needed</em></em></h3>



<h3 id="kt-adv-heading_9e6572-44"><em><em>to make our VMs run smoothly without hiccups.”</em></em></h3>



<p>Tony Sarajärvi, CI Tech Lead</p>







<h3>“OUR NEW SPINAL CORD IS BASED ON OPENNEBULA”</h3>



<p>Qt<strong> </strong>was using VMware vSphere to create and run VMs, but they were looking for a change. The VMWare’s ESXi licenses were quite expensive for the size of the company and the amount of number crunching hardware they wanted to use. They wanted something that was broadly used and open source so that the community could fix bugs and not everything would fall into their own hands. So they looked for open-source hypervisors, KVM. OpenStack was their initial option. However, they quickly learned about OpenNebula<strong> </strong>and decided to forge ahead with it.</p>



<p>“OpenNebula was more lightweight than OpenStack. We don’t need all the fancy modules it has. After more than three years using OpenNebula in production, we can confirm that it is a great tool for doing the simple task of spawning millions of virtual machines per year that live only a matter of minutes, before being disposed of. That’s what our CI is all about. It verifies developers commits in multiple different environments, after which we either have a positive or negative result” said Sarajärvi.</p>



<p>The swap to OpenNebula<strong> </strong>came along with the new hardware changes. With open source non-proprietary code they went deeper into the root causes of problems and fixed drivers to make their VMs run smoothly without hiccups.</p>



<h3 id="kt-adv-heading_c91db1-d2"><em><em>“OpenNebula was more lightweight than OpenStack. </em></em></h3>



<h3 id="kt-adv-heading_b8706e-ed"><em><em>After more than three years using OpenNebula </em></em></h3>



<h3 id="kt-adv-heading_3b2b1c-19"><em><em>in production, we can confirm that it is a great tool.”</em></em></h3>



<p>Tony Sarajärvi, CI Tech Lead</p>







<p>Qt is currently running over 4 million virtual machines per year on OpenNebula. OpenNebula is hosted in their stack of servers and meant to take care of the infrastructure, with approximately 30 Dell PowerEdge R430 servers with dual 20 core CPUs and 400 GB of RAM doing the heavy lifting of running the builds themselves.</p>







<h3>WITH OPENNEBULA, Qt WILL CONTINUE EXPANDING TO NEW AREAS</h3>



<p>“We have already stumbled upon the limit that it doesn’t support Parallels for example. But we’re working on that ourselves so that we can use macOS hardware as a deployment platform as well,” said Sarajärvi. “So in that sense, OpenNebula with its open source enables us to continue expanding to areas where it wasn’t originally even intended”.</p>
</div></div>
</div></div></div></div>]]>
            </description>
            <link>https://opennebula.io/qt-case-study/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301783</guid>
            <pubDate>Fri, 04 Dec 2020 13:03:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reveal encrypted email address with echo and sed]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25301551">thread link</a>) | @m_b
<br/>
December 4, 2020 | https://myrdn.github.io/mail-address-encryption/ | <a href="https://web.archive.org/web/*/https://myrdn.github.io/mail-address-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          
          <p>
            E-mail scraping sucks. Encrypt your email address with this form and
            just ask your friends to paste the generated command into their
            terminal emulator to reveal your address.
          </p>
          
          
        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://myrdn.github.io/mail-address-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301551</guid>
            <pubDate>Fri, 04 Dec 2020 12:32:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Google Analytics without GDPR consent]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25301500">thread link</a>) | @evrimfeyyaz
<br/>
December 4, 2020 | https://evrim.io/using-google-analytics-without-gdpr-consent/ | <a href="https://web.archive.org/web/*/https://evrim.io/using-google-analytics-without-gdpr-consent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://evrim.io/using-google-analytics-without-gdpr-consent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301500</guid>
            <pubDate>Fri, 04 Dec 2020 12:23:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can You Protect Your Project from Failure?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25301446">thread link</a>) | @_Tata_
<br/>
December 4, 2020 | https://www.ego-cms.com/post/blueprint-effective-project-roadmap | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/blueprint-effective-project-roadmap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/services"><p>Services</p></a><p>BluePrint is basically a quick start to transform the product idea into exact requirements. So why is it so important on the pre-development stage? Why a development team can’t start coding right away?</p></div></div><article><div target="_blank"><p><strong>BluePrint </strong>is basically a quick start to transform the product idea into exact requirements. So why is it so important on the pre-development stage? Why a development team can’t start coding right away?</p><p><strong>Simply because:</strong><br>It’s very similar to construction and building a house. No one wants to do it without a plan. House owner can just say that there should be 4 floors, big windows and a tile roof. But that’s not enough for construction team to start the work, since there is at least million and one aspect that should be defined for the construction team to be able to provide the budget, delivery phases and a plan. And the owner of the house benefits from having a plan, since he outlines the requirements and understands what he’s paying for.</p><p>In the end of the day everyone needs a plan.</p><p><strong>Plan is for the big picture? Yes, exactly! &nbsp;Here is what BluePrint covers additionally to reveal details:</strong></p><ul role="list"><li>Interactive wireframes in a form of clickable prototype</li><li>Design concept to get the look and feel, bring the colors and styles in</li><li>Blueprint doc with project descriptions, key values and goals to achieve</li></ul><p><strong>Now it’s more clear what it contains, but what values does it really bring? Here is the outline of key ones:</strong></p><ul role="list"><li>It’s your <strong>app idea going live on paper</strong> with detailed implementation plan and features to do. Such as a plan needs to be done for building construction.</li><li>Use it as a <strong>proof of concept</strong>! Wireframes are interactive and are delivered in a form of clickable prototype. So those can be used for product idea presentation and/or rising funds. <strong>Get your investments with it!</strong></li><li><strong>Fixed budget for development phase!</strong> With BluePrint on hand you’ll know exactly how much money you’ll need to spend during each phase with detailed breakdown.</li><li>Having it done we can provide<strong> fixed timeline and exact deliveries</strong> for development phase;</li><li>You don’t need to spend tons of hours creating <strong>project documentation</strong>! We’ll do it for you in a best fitting form – specification, walkthrough, screen flows.</li><li>It’s your <strong>business plan</strong> essential for successful project completion and investments implementation. No great project can be done without it, right?</li></ul><p>We’ll put an extra effort into making <strong>BluePrint</strong> more visible for you, please let us know if you’d like to overview the samples and even more details, just drop us a line.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7cffcb459b8827a052bcc_5f6cbc749743acf2fb1fa27f_5d3044689d1896fd44a9b9f1_Product%20Strategy.png" loading="lazy" alt=""></p></figure></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/blueprint-effective-project-roadmap</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301446</guid>
            <pubDate>Fri, 04 Dec 2020 12:13:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sales Prospecting on LinkedIn [tactics we tested with results]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25301415">thread link</a>) | @Ilyazovtsev
<br/>
December 4, 2020 | https://ilya.today/linkedin-prospecting-hn | <a href="https://web.archive.org/web/*/https://ilya.today/linkedin-prospecting-hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ilya.today/linkedin-prospecting-hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301415</guid>
            <pubDate>Fri, 04 Dec 2020 12:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is UnitSystems.jl the most complete resource for physics constants?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25301389">thread link</a>) | @DreamScatter
<br/>
December 4, 2020 | https://geophysics.crucialflow.com/dev/units | <a href="https://web.archive.org/web/*/https://geophysics.crucialflow.com/dev/units">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="documenter-page"><p><em>Physical unit system constants (Metric, English, Natural, etc...)</em></p><p><a href="https://zenodo.org/badge/latestdoi/317419353"><img src="https://zenodo.org/badge/317419353.svg" alt="DOI"></a></p><ul><li><a href="https://geophysics.crucialflow.com/dev/units.html#UnitSystems.jl-1">UnitSystems.jl</a></li><ul><li><a href="https://geophysics.crucialflow.com/dev/units.html#Metric-SI-Units-1">Metric SI Units</a></li><li><a href="https://geophysics.crucialflow.com/dev/units.html#Other-historic-systems-1">Other historic systems</a></li><li><a href="https://geophysics.crucialflow.com/dev/units.html#Natural-units-1">Natural units</a></li><li><a href="https://geophysics.crucialflow.com/dev/units.html#Fundamental-constants-of-physics-1">Fundamental constants of physics</a></li><li><a href="https://geophysics.crucialflow.com/dev/units.html#Common-conversion-factors-1">Common conversion factors</a></li><li><a href="https://geophysics.crucialflow.com/dev/units.html#Index-1">Index</a></li></ul><li><a href="https://geophysics.crucialflow.com/dev/references.html#References-1">References</a></li></ul><p>Specifications for dimensional units are in the <a href="https://github.com/chakravala/UnitSystems.jl">UnitSystems.jl</a> repository.</p><pre><code>pkg&gt; add UnitSystems

julia&gt; using UnitSystems</code></pre><p>A <code>UnitSystem</code> is a consistent set of dimensional values selected to accomodate a particular use case or standardization. In total, five fundamental constants <code>kB,ħ,𝘤,μ₀,mₑ</code> are used to specify a specific unit system. These are the constants of <code>boltzmann</code>, <code>planckreduced</code>, <code>lightspeed</code>, <code>permeability</code>, and <code>electronmass</code>. Different choices of natural units or physical measurements result in a variety of unit systems optimized for many purposes.</p><p>\[k_B, \qquad \hbar, \qquad c, \qquad \mu_0, \qquad m_e, \qquad (M_u)\]</p><p>Another important additional definition is the <code>molarmass</code> constant, which is automatically selected based on the choice of <code>boltzmann</code> constant (but can also be customized if necessary).</p><article><header><a id="UnitSystems.UnitSystem" href="#UnitSystems.UnitSystem"><code>UnitSystems.UnitSystem</code></a> — <span>Type</span></header><section><div><pre><code>UnitSystem{kB,ħ,𝘤,μ₀,mₑ}</code></pre><p>Standardized for engineering based on fundamental constants: <code>kB</code> Boltzmann's constant, <code>ħ</code> reduced Planck's constant, <code>𝘤</code> speed of light, <code>μ₀</code> vacuum permeability, and <code>mₑ</code> electron rest mass. Primarily the <code>Metric</code> SI unit system is used in addition to the historic <code>English</code> engineering unit system. These constants induce derived values for <code>avogadro</code>, <code>boltzmann</code>, <code>universal</code>, <code>planck</code>, <code>planckreduced</code>, <code>lightspeed</code>, <code>planckmass</code>, <code>atomicmass</code>, <code>protonmass</code>, <code>electronmass</code>, <code>newton</code>, <code>einstein</code>, <code>permeability</code>, <code>permittivity</code>, <code>coulomb</code>, and additional constants <code>stefan</code>, <code>radiationintensity</code>, <code>impedance</code>, <code>charge</code>, <code>magneton</code>, <code>conductance</code>, <code>faraday</code>, <code>magneticflux</code>, <code>josephson</code>, <code>klitzing</code>, <code>hartree</code>, <code>rydberg</code>, <code>bohr</code>, <code>bohrreduced</code>, and <code>molarmass</code>.</p><p>Additional reference <code>UnitSystem</code> variants <code>CGS</code>, <code>CGS2019</code>, <code>SI2019</code>, <code>CODATA</code>, <code>Conventional</code>, <code>IAU</code>; along with several natural atomic units based on the fine structure constant <code>1/αinv</code> and the gravitational coupling constant <code>αG</code> (<code>Planck</code>, <code>PlanckGauss</code>, <code>Stoney</code>, <code>Hartree</code>, <code>Rydberg</code>, <code>Schrodinger</code>, <code>Electronic</code>, <code>Natural</code>, <code>NaturalGauss</code>, <code>QCD</code>, <code>QCDGauss</code>, and <code>QCDoriginal</code>).</p></div><a target="_blank" href="https://github.com/chakravala/UnitSystems.jl/blob/483316fd0c1e94b14145164c906d4cdfcfd8d7cf/src/UnitSystems.jl#L15-L24">source</a></section></article><p>Other similar packages include <a href="https://github.com/JuliaPhysics/PhysicalConstants.jl">PhysicalConstants.jl</a>, <a href="https://github.com/LaGuer/MathPhysicalConstants.jl">MathPhysicalConstants.jl</a>, <a href="https://github.com/PainterQubits/Unitful.jl.git">Unitful.jl</a>, <a href="https://github.com/PainterQubits/UnitfulUS.jl">UnitfulUS</a>, <a href="https://github.com/JuliaAstro/UnitfulAstro.jl">UnitfulAstro</a>, <a href="https://github.com/sostock/UnitfulAtomic.jl">UnitfulAtomic</a>, <a href="https://github.com/MasonProtter/NaturallyUnitful.jl">NaturallyUnitful</a>, and <a href="https://github.com/rafaqz/UnitfulMoles.jl">UnitfulMoles</a>.</p><h2 id="Metric-SI-Units-1"><a href="#Metric-SI-Units-1">Metric SI Units</a><a href="#Metric-SI-Units-1" title="Permalink"></a></h2><p>In the Systeme International d'Unites (the SI units) the <code>UnitSystem</code> constants are derived from the most accurate possible physical measurements and a few exactly defined constants. Exact values are the <code>avogadro</code> number, <code>boltzmann</code> constant, <code>planck</code> constant, <code>lightspeed</code> definition, and elementary <code>charge</code> definition.</p><p>\[N_A = 6.02214076\mathrm{e}{23},
k_B = 1.380649\mathrm{e}{-23},
h = 6.62607015\mathrm{e}{-34},
c = 299792458,
e = 1.602176634\mathrm{e}{-19}\]</p><pre><code>julia&gt; NA # avogadro
6.02214076e23

julia&gt; kB # boltzmann
1.380649e-23

julia&gt; 𝘩 # planck
6.62607015e-34

julia&gt; 𝘤 # lightspeed
2.99792458e8

julia&gt; 𝘦 # charge
1.602176634e-19</code></pre><p>Physical measured values with uncertainty are the electron to proton mass ratio <code>μₑₐ</code>, proton to atomic mass ratio <code>μₚₐ</code>, fine structure constant <code>αinv</code>, the Rydberg <code>R∞</code> constant, and the Planck mass <code>mP</code>.</p><p>\[\mu_{eu} = \frac{m_e}{m_u} \approx \frac{1}{1822.9},
\mu_{pu} = \frac{m_p}{m_u} \approx 1.00727647,
\alpha \approx \frac{1}{137.036},
R_\infty \approx 1.097373\mathrm{e}{7},
m_P \approx 2.176434\mathrm{e}{-8},\]</p><pre><code>julia&gt; μₑᵤ # mₑ/mᵤ
0.0005485799090649074

julia&gt; μₚᵤ # mₚ/mᵤ
1.007276466621

julia&gt; αinv # 1/(fine structure)
137.035999084

julia&gt; R∞ # rydberg
1.09737315681601e7

julia&gt; mP # planckmass
2.176434e-8</code></pre><p>From these numbers along with the <code>4π*1e-7</code> value of the Gaussian unit <code>μ₀</code>, the constants <code>planckreduced</code>, <code>permeability</code>, <code>electronmass</code>, <code>molarmass</code>, and proton to electon mass ratio are computed.</p><p>\[\hbar = \frac{h}{2\pi}, \qquad
\mu_0 = \frac{2h\alpha}{ce^2}, \qquad
m_e = \frac{2hR_\infty}{c\alpha}, \qquad
M_u = \frac{m_e}{\mu_{eu}}N_A = \frac{2h R_\infty N_A}{c\alpha\mu_{eu}}, \qquad
\mu_{pe} = \frac{\mu_{pu}}{\mu_{eu}} = \frac{m_p}{m_e}\]</p><pre><code>julia&gt; ħ # 𝘩/2π
1.0545718176461565e-34

julia&gt; μ₀ # 2𝘩/𝘤/αinv/𝘦^2
1.256637062121048e-6

julia&gt; mₑ # αinv^2*R∞*2𝘩/𝘤
9.109383701558256e-31

julia&gt; Mᵤ # mₑ*NA/μₑᵤ
0.000999999999656256

julia&gt; μₚₑ # μₚᵤ/μₑᵤ, mₚ/mₑ
1836.152673432705</code></pre><p>These result in variants based on the original <code>molarmass</code> constant and Gaussian <code>permeability</code> along with the 2019 redefined exact values. The main difference between the two is determined by <span>$\delta\tilde M_u$</span> and <span>$\delta\tilde\mu_0$</span>.</p><p>\[\tilde k_B = \frac{m_e R_u}{\mu_{eu} \tilde M_u} = \frac{k_B N_A}{m_u \tilde M_u}, \quad
\tilde \hbar = \hbar, \quad
\tilde c = c, \quad
\tilde\mu_0 = \frac{4\pi}{10^7} + \delta\tilde \mu_0, \quad
\tilde m_e = m_e, \quad
(\tilde M_u = \frac{1}{1000} + \delta \tilde M_u)\]</p><pre><code>Metric::UnitSystem{Rᵤ*mₑ/μₑᵤ/0.001,ħ,𝘤,4π*1e-7,mₑ}
SI2019::UnitSystem{kB,ħ,𝘤,μ₀,mₑ}</code></pre><p>\[\frac{1}{1000} - M_u = 3.437439135417497\mathrm{e}{-13}, \qquad
\frac{4π}{10^7} - \mu_0 \approx -6.851306461996397\mathrm{e}{-16}\]</p><article><header><a id="UnitSystems.Metric" href="#UnitSystems.Metric"><code>UnitSystems.Metric</code></a> — <span>Constant</span></header><section><div><pre><code>Metric::UnitSystem{Rᵤ*mₑ/μₑᵤ/0.001,ħ,𝘤,4π*1e-7,mₑ}</code></pre><p>Systeme International d'Unites (the SI units) adopted as the preferred <code>UnitSystem</code>.</p><pre><code>julia&gt; boltzmann(Metric) # J⋅K⁻¹
1.3806489995254104e-23

julia&gt; planckreduced(Metric) # J⋅s⋅rad⁻¹
1.0545718176461565e-34

julia&gt; lightspeed(Metric) # m⋅s⁻¹
2.99792458e8

julia&gt; permeability(Metric) # H⋅m⁻¹
1.2566370614359173e-6

julia&gt; electronmass(Metric) # kg
9.109383701558256e-31</code></pre></div><a target="_blank" href="https://github.com/chakravala/UnitSystems.jl/blob/483316fd0c1e94b14145164c906d4cdfcfd8d7cf/src/UnitSystems.jl#L152-L173">source</a></section></article><article><header><a id="UnitSystems.SI2019" href="#UnitSystems.SI2019"><code>UnitSystems.SI2019</code></a> — <span>Constant</span></header><section><div><pre><code>SI2019::UnitSystem{kB,ħ,𝘤,μ₀,mₑ}</code></pre><p>Systeme International d'Unites (the SI units) with <code>μ₀</code> for a tuned <code>charge</code> exactly.</p><pre><code>julia&gt; boltzmann(SI2019) # J⋅K⁻¹
1.380649e-23

julia&gt; planckreduced(SI2019) # J⋅s⋅rad⁻¹
1.0545718176461565e-34

julia&gt; lightspeed(SI2019) # m⋅s⁻¹
2.99792458e8

julia&gt; permeability(SI2019) # H⋅m⁻¹
1.256637062121048e-6

julia&gt; electronmass(SI2019) # kg
9.109383701558256e-31</code></pre></div><a target="_blank" href="https://github.com/chakravala/UnitSystems.jl/blob/483316fd0c1e94b14145164c906d4cdfcfd8d7cf/src/UnitSystems.jl#L244-L265">source</a></section></article><p>Additional reference values include the ground state hyperfine structure transition frequency of caesium-133 <code>ΔνCs</code> and luminous efficacy <code>Kcd</code> of monochromatic radiation of 540 THz.</p><pre><code>julia&gt; ΔνCs
9.19263177e9

julia&gt; Kcd
683.0</code></pre><h2 id="Other-historic-systems-1"><a href="#Other-historic-systems-1">Other historic systems</a><a href="#Other-historic-systems-1" title="Permalink"></a></h2><p>Alternatives to the SI unit system are the centimetre-gram-second variants.</p><p>\[\tilde k_B = 10^7\frac{\tilde m_e R_u}{\mu_{eu} \tilde M_u}, \quad
\tilde \hbar = 10^7\hbar, \quad
\tilde c = 100c, \quad
\tilde\mu_0 = 4\pi + \delta\tilde \mu_0, \quad
\tilde m_e = 1000m_e, \quad
(\tilde M_u = 1 + \delta \tilde M_u)\]</p><pre><code>CGS     ::UnitSystem{1e10*Rᵤ*mₑ/μₑᵤ,1e7*ħ,100𝘤,4π,1000mₑ}
CGS2019 ::UnitSystem{1e7*kB,1e7*ħ,100𝘤,1e7*μ₀,1000mₑ}</code></pre><article><header><a id="UnitSystems.CGS" href="#UnitSystems.CGS"><code>UnitSystems.CGS</code></a> — <span>Constant</span></header><section><div><pre><code>CGS::UnitSystem{1e10*Rᵤ*mₑ/μₑᵤ,1e7*ħ,100𝘤,4π,1000mₑ}</code></pre><p>Centimetre-gram-second <code>UnitSystem</code> variant of <code>Metric</code> system based on factors of <code>1e2,1e3</code>.</p><pre><code>julia&gt; boltzmann(CGS) # erg⋅K⁻¹
1.3806489995254104e-16

julia&gt; planckreduced(CGS) # erg⋅s⋅rad⁻¹
1.0545718176461565e-27

julia&gt; lightspeed(CGS) # cm⋅s⁻¹
2.99792458e10

julia&gt; permeability(CGS) # erg⋅A⁻²⋅cm⁻¹
12.566370614359172

julia&gt; electronmass(CGS) # g
9.109383701558256e-28</code></pre></div><a target="_blank" href="https://github.com/chakravala/UnitSystems.jl/blob/483316fd0c1e94b14145164c906d4cdfcfd8d7cf/src/UnitSystems.jl#L198-L219">source</a></section></article><article><header><a id="UnitSystems.CGS2019" href="#UnitSystems.CGS2019"><code>UnitSystems.CGS2019</code></a> — <span>Constant</span></header><section><div><pre><code>CGS2019::UnitSystem{1e7*kB,1e7*ħ,100𝘤,1e7*μ₀,1000mₑ}</code></pre><p>Centimetre-gram-second <code>UnitSystem</code> variant of the tuned <code>SI2019</code> unit specification.</p><pre><code>julia&gt; boltzmann(CGS2019) # erg⋅K⁻¹
1.380649e-16

julia&gt; planckreduced(CGS2019) # erg⋅s⋅rad⁻¹
1.0545718176461565e-27

julia&gt; lightspeed(CGS2019) # cm⋅s⁻¹
2.99792458e10

julia&gt; permeability(CGS2019) # erg⋅A⁻²⋅cm⁻¹
12.56637062121048

julia&gt; electronmass(CGS2019 # g
9.109383701558256e-28</code></pre></div><a target="_blank" href="https://github.com/chakravala/UnitSystems.jl/blob/483316fd0c1e94b14145164c906d4cdfcfd8d7cf/src/UnitSystems.jl#L221-L242">source</a></section></article><p>Historically, the <code>josephson</code> and <code>klitzing</code> constants have been used to define <code>Conventional</code> and <code>CODATA</code> derived <code>UnitSystem</code> variants.</p><p>\[\tilde k_B = \frac{8 \tilde R_\infty R_u}{c\alpha\mu_{eu} \tilde M_u \tilde K_J^2 \tilde R_K}, \quad
\tilde \hbar = \frac{2}{\pi\tilde K_J^2 \tilde R_K}, \quad
\tilde c = c, \quad
\tilde\mu_0 = \frac{2\tilde R_K\alpha}{c}, \quad
\tilde m_e = \frac{8\tilde R_\infty}{\tilde K_J^2\tilde R_Kc\alpha}, \quad
(\tilde M_u = \frac{1}{1000})\]</p><pre><code>CODATA::UnitSystem{1000Rᵤ*mₑ2014/μₑᵤ,2/RK2014/KJ2014^2/π,𝘤,2RK2014/𝘤/αinv,mₑ2014}()
Conventional::UnitSystem{1000Rᵤ*mₑ/μₑᵤ,2/RK1990/KJ1990^2/π,𝘤,2RK1990/𝘤/αinv,mₑ}()</code></pre><pre><code>julia&gt; josephson(Conventional) # KJ1990
4.835979e14

julia&gt; klitzing(Conventional) # RK1990
25812.807

julia&gt; josephson(CODATA) # KJ2014
4.835978525e14

julia&gt; klitzing(CODATA) # RK2014
25812.8074555</code></pre><article><header><a id="UnitSystems.Conventional" href="#UnitSystems.Conventional"><code>UnitSystems.Conventional</code></a> — <span>Constant</span></header><section><div><pre><code>Conventional::UnitSystem{Rᵤ*mₑ/μₑᵤ/0.001,2/RK1990/KJ1990^2/π,𝘤,2RK1990/𝘤/αinv,mₑ}</code></pre><p>Conventional electronic <code>UnitSystem</code> with 1990 tuned <code>josephson</code> and <code>klitzing</code> constants.</p><pre><code>julia&gt; boltzmann(Conventional) # J⋅K⁻¹
1.3806489995254104e-23

julia&gt; planckreduced(Conventional) # J⋅s⋅rad⁻¹
1.054571611438857e-34

julia&gt; lightspeed(Conventional) # m⋅s⁻¹
2.99792458e8

julia&gt; permeability(Conventional) # H⋅m⁻¹
1.2566370397608662e-6

julia&gt; electronmass(Conventional) # kg
9.109383701558256e-31</code></pre></div><a target="_blank" href="https://github.com/chakravala/UnitSystems.jl/blob/483316fd0c1e94b14145164c906d4cdfcfd8d7cf/src/UnitSystems.jl#L290-L311">source</a></section></article><article><header><a id="UnitSystems.CODATA" href="#UnitSystems.CODATA"><code>UnitSystems.CODATA</code></a> — <span>Constant</span></header><section><div><pre><code>CODATA::UnitSystem{Rᵤ*mₑ2014/μₑᵤ/0.001,2/RK2014/KJ2014^2/π,𝘤,2RK2014/𝘤/αinv,mₑ2014}</code></pre><p>Metric <code>UnitSystem</code> based on Committee on Data of the International Science Council.</p><pre><code>julia&gt; boltzmann(CODATA) # J⋅K⁻¹
2.1973710927822126e-24

julia&gt; planckreduced(CODATA) # J⋅s⋅rad⁻¹
1.0545717999940896e-34

julia&gt; lightspeed(CODATA) # m⋅s⁻¹
2.99792458e8

julia&gt; permeability(CODATA) # H⋅m⁻¹
1.2566370619358342e-6

julia&gt; electronmass(CODATA) # kg
1.4498034204020109e-31</code></pre></div><a target="_blank" href="https://github.com/chakravala/UnitSystems.jl/blob/483316fd0c1e94b14145164c906d4cdfcfd8d7cf/src/UnitSystems.jl#L267-L288">source</a></section></article><p>In Britain and the United States an <code>English</code> system of engineering units was commonly used.</p><p>\[\tilde k_B = 5.657302466\mathrm{e}{-24}, \quad
\tilde \hbar = \frac{\hbar}{\text{slug}\cdot \text{ft}^2}, \quad
\tilde c = \frac{c}{\text{ft}}, \quad
\tilde\mu_0 = 4\pi, \quad
\tilde m_e = \frac{m_e}{\text{slug}}, \quad
(\tilde M_u = \frac{R_u \tilde m_e ^\circ R}{\tilde k_B\mu_{eu} \text{ft}})\]</p><article><header><a id="UnitSystems.English" href="#UnitSystems.English"><code>UnitSystems.English</code></a> — <span>Constant</span></header><section><div><pre><code>English::UnitSystem{5.657302466e-24,ħ/slug/ft^2,𝘤/ft,4π,mₑ/slug}</code></pre><p>Engineering <code>UnitSystem</code> historically used by Britain and United States.</p><pre><code>julia&gt; boltzmann(English) # ft⋅lb⋅°R⁻¹
5.657302466e-24

julia&gt; planckreduced(English) # ft⋅lb⋅s⋅rad⁻¹
7.778122563040369e-35

julia&gt; lightspeed(English) # ft⋅s⁻¹
9.835710564304461e8

julia&gt; permeability(English) # slug⋅ft²⋅?⁻²
12.566370614359172

julia&gt; …</code></pre></div></section></article></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://geophysics.crucialflow.com/dev/units">https://geophysics.crucialflow.com/dev/units</a></em></p>]]>
            </description>
            <link>https://geophysics.crucialflow.com/dev/units</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301389</guid>
            <pubDate>Fri, 04 Dec 2020 12:04:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Hacks of 2020]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25301346">thread link</a>) | @henrikwm
<br/>
December 4, 2020 | https://security.christmas/2020/4 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today we are going to explore five big hacks that took place in 2020. First we'll cover two hacks that targeted Norwegian companies Sykehuspartner and NHH. Then we'll take a look at a hack that targeted the Danish company ISS. To wrap things up we'll cover what is probably the two most high profile hacks of 2020: the Twitter phish and the CWT ransom.</p>
</section><article><section><h2>Sykehuspartner</h2>
<p><img src="https://i.ibb.co/hyMVdWh/Skjermbilde-2020-11-20-kl-07-30-21.png" alt="Sykehuspartner logo" title="Sykehuspartner"></p>
<p>Sykehuspartner deliver IT, HR, project and logistics services to all hospitals in the Norwegian health region Helse Sør-Øst (Health South East). It manages vital IT systems for the hospitals, both clinical and administrative applications, as well as infrastructure and networks.</p>
<p>On august 22 2020 several of Sykehuspartners applications became the target of an unknown malicious actor. Only one hospital (Sykehuset Innlandet) was targeted in this attack. Not much is known by the type and scope of the attack, except for what type of data might possibly have been stolen. The potentially stolen data might include:</p>
<ul>
<li>Information about the deceased</li>
<li>Health information about patients from research projects</li>
<li>Personal information about employees</li>
<li>Name and social security number (fødselsnummer) of students</li>
</ul>
<p>From reports about the incident, we know that 25 patients and several employees have been notified of personal information having been stolen. Following the attack, the hospital has carried out a forced password change for all employees.</p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://sykehuspartner.no/nyheter/dataangrep-mot-sykehuset-innlandet-hf">Sykehuspartner announcing attack</a></li>
<li><a href="https://sykehuspartner.no/nyheter/analysearbeidet-etter-dataangrepet-mot-sykehuset-innlandet-er-avsluttet">Sykehuspartners analysis of attack</a></li>
</ul>
<h2>NHH</h2>
<p><img src="https://i.ibb.co/sjQnhNF/imageedit-10-3684463812.png" alt="NHH logo" title="NHH logo"></p>
<p>In august this year, Norges handelshøgskole (NHH, English: Norwegian School of Economics), experienced a data heist. The school is one of the leading business schools in Europe and is located in the city of Bergen. </p>
<p>Usernames and passwords of both students and employees was compromised. The break in was discovered when the stolen credentials were uploaded to a “hacker” forum. The attack targeted a known vulnerability in an old version of the VPN service called Pulse Secure. An updated version that patches this vulnerability has been available since April 2019. But NHH is decommissioning the service and has thus been neglecting to update it. All students and employees were asked to change their passwords after the incident.</p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://www.dn.no/utdannelse/nhh/datakriminalitet/nhh-oppdaterte-ikke-sikkerhetshull-kjent-siden-april-2019-na-er-handelshoyskolen-rammet-av-internasjonalt-dataangrep/2-1-853329">Norwegian news article about NHH attack</a></li>
</ul>
<h2>ISS</h2>
<p><img src="https://i.ibb.co/XDJVmgQ/imageedit-12-3910494650.png" alt="ISS logo" title="ISS logo"></p>
<p>In the middle of February this year, ISS was hit by a ransomware attack. ISS is a global facility services company, founded in Copenhagen, Denmark. The company has 450,000 employees.</p>
<p>The ransomware was a massive malware attack across IT-systems and networks. Immediately after the attack was discovered, IT-access was removed to isolate the indicent. As reported by the company. Regardless of the actions taken, the company had to write down and change big parts of the IT-infrastructure. It is estimated that the attack will cost the company between 750 and 1340 million Norwegian kroner (NOK).</p>
<p>It was reported that customer data was not stolen.</p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://www.digi.no/artikler/dansk-servicegigant-rammet-etter-skadevareangrep/485762">Norwegian news article about ISS attack</a></li>
<li><a href="https://www.digi.no/artikler/iss-venter-milliardsmell-etter-cyberangrepet-i-februar/488264">Norwegian news article about aftermath of ISS attack</a></li>
</ul>
<h2>Twitter</h2>
<p>Twitter, you know, the social media platform? Yes, that one. In July this year, it was hit with a phishing campaign that was used to target high-profile individuals, like Barack Obama, Joe Biden and Bill Gates.</p>
<p>Twitter stated that "This attack relied on a significant and concerted attempt to mislead certain employees and exploit human vulnerabilities to gain access to our internal systems".</p>
<p>The phish was used to get access to certain high-profile accounts. The compromised accounts were used to promote a bitcoin scam.</p>
<p><img src="https://i.ibb.co/sPXDZK7/external-content-duckduckgo-com.png" alt="Tweets from Joe Biden and Barack Obama promoting a bitcoin scam" title="Biden and Obamas twitter profiles were hacked to promote a bitcoin scam"></p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://edition.cnn.com/2020/07/15/tech/twitter-hack-elon-musk-bill-gates/index.html">News article about Twitter hack</a></li>
<li><a href="https://edition.cnn.com/2020/07/30/tech/twitter-hack-update/index.html">News article about Twitter hack - two weeks later</a></li>
</ul>
<h2>CWT</h2>
<p>CWT is a travel management company that manages business travel, meetings and so on. The 27 of July this year, the company was hit by a massive ransomware attack that knocked 30,000 computers offline. The hackers claimed to have stolen two terabytes of files, including financial reports, security documents and employees’ personal data. CWT paid $4.5 million to the hackers to restore their systems. </p>
<p>One of the fascinating things about this hack was that the negotiation chat, where the company and the hackers met to talk, was left open to the public after the negotiations ended. This gives us a never before seen insight into how the negotiations between hacker and hacked works. As many others have noted after the chat became public, it is rarely advised to actually pay the hackers like CWT did. This is, of course, because of the precedence it sets and that the chance of getting scamed is very high.</p>
<p><img src="https://i.ibb.co/QC7f7MJ/cwt-chat.jpg" alt="Screenshot of chat between hackers and CWT" title="Screenshot of the negotiation chat between hackers and CWT"></p>
<p><strong>Sources</strong></p>
<ul>
<li><a href="https://www.reuters.com/article/us-cyber-cwt-ransom-idUSKCN24W25W">News article about CWT attack</a></li>
</ul>

<p>This is of course not a complete list of all the major hacks that were reported in 2020. It sure has been a very active year in this regard. As you can see, there are many ways of being vulnerable on the internet. If you want to better understand how to prevent some of these things happening to you, take a look at the previous three posts:</p>
<ol>
<li><a href="https://security.christmas/2020/1">Application security check list</a></li>
<li><a href="https://security.christmas/2020/2">Github Security: Getting started with Dependabot</a></li>
<li><a href="https://security.christmas/2020/3">How secure is your build pipeline?</a></li>
</ol>
<p>Also, be sure to follow this advent calendar for even more articles leading up to Christmas day!</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301346</guid>
            <pubDate>Fri, 04 Dec 2020 11:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BBC Micro Bot – Creative Retro Coding]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25301340">thread link</a>) | @rbanffy
<br/>
December 4, 2020 | https://www.bbcmicrobot.com/owlet-test2.html | <a href="https://web.archive.org/web/*/https://www.bbcmicrobot.com/owlet-test2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
    <p><span>Beta test - every image opens in editor + emulator :)</span></p>
    <p><a href="https://www.twitter.com/bbcmicrobot/">BBC Micro bot</a> runs your tweet on an 8-bit computer <a href="https://github.com/mattgodbolt/jsbeeb">emulator</a>. Below is output from 1000 programs that different users submitted to the bot. Click any to see source.</p>
    <p>The tweet sized programs are written in <a href="http://bbc.nvg.org/doc/BBCUserGuide-1.00.pdf">BBC BASIC</a> (1981) a very fast implementation of the language by <a href="https://en.wikipedia.org/wiki/Sophie_Wilson">Sophie Wilson</a> who later created the ARM architecture.</p>
    <p>To squeeze under the 280 character limit techniques include <a href="http://central.kaserver5.org/Kasoft/Typeset/BBC/Ch47.html">abbreviations</a>, <a href="http://www.benryves.com/bin/bbcbasic/manual/Appendix_Tokeniser.htm">bytes tokens</a>, <a href="https://twitter.com/P_Malin/status/1240070955868848129?s=20">base2048</a> encoding, and even inline <a href="https://twitter.com/EbenUpton/status/1230646662680412162?s=20">6502</a> machine code.</p><p>Users express amazing creativity with minimal palette, pixels and bytes.</p>
    
</div></div>]]>
            </description>
            <link>https://www.bbcmicrobot.com/owlet-test2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301340</guid>
            <pubDate>Fri, 04 Dec 2020 11:54:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Sea Turtles Find Their Way]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25301247">thread link</a>) | @dnetesn
<br/>
December 4, 2020 | http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>T</span>he air was warm as the skies grew dark over Diego Garcia. As the nearly full moon reached its highest point, a green sea turtle scuttled her way onto the sand. The ocean giant was more than a meter wide and nearly as long from nose to tail. Her carapace, mottled with splotches of green and black, was slick with salt water.&nbsp;</p>

<p>Turtles glide through the sea with a certain reptilian elegance, but on land their awkward, plodding movements evoke a wind-up toy in need of a few more cranks. After shuffling a suitable distance from the waterline, the turtle began to excavate a shallow hole, using her arms and legs like spades to fling pebbles and sand through the air. Nearly exhausted, she finally began to relax as she released dozens of ping-pong ball-sized eggs into the ground.</p>
<p>It was likely the first time in years sheâ€™d set flipper on dry land. Other than the moments after they hatch and crawl into the surf, sea turtles spend their entire lives in the ocean. Only when females return to lay eggs on the same beaches where they hatched do they leave the water—just briefly, for a few hours, before slipping back into the sea. They may lay several clutches of eggs during the mating season before setting off for their foraging territories. There they stay for several years, regaining energy by feasting on seagrass, before returning to their natal beach, mating just offshore, and beginning the cycle anew.</p>
<p>Having carried out the full extent of her duties as a mother, this turtle had completed a ritual thatâ€™s played out countless times on Diego Garcia, a footprint-shaped atoll in the Indian Ocean's Chagos Archipelago. Green sea turtles have used the atoll as an incubator for hundreds or thousands of generations, or perhaps longer. Each generation disperses and returns; precisely where these now-endangered reptiles go, what route they take to get there, and how they navigate, is a mystery.</p>
<p>And so on that moonlit night in October of 2017 volunteers from the U.S. military facility on Diego Garcia helped <a href="https://www.swansea.ac.uk/staff/science/biosciences/esteban-n/" target="_blank">Nicole Esteban</a>, a marine biologist and sea turtle conservationist at Swansea University, fasten a GPS transmitter to the top of the turtle's shell while she laid her eggs. The volunteers nicknamed the turtle Serenity and watched as she and the computer on her back crept back into the waves and disappeared.</p>
<p>Three months later, Serenity reached her foraging waters along a small island called Farquhar Atoll in the Seychelles archipelago. It is some four thousand kilometers west of Diego Garcia, but the GPS signals traced a circuitous route that wound through more than six thousand kilometers of open ocean. Had she had taken a more direct path, she could have accomplished the entire journey in under a month.</p>
<blockquote>Precisely where these now-endangered reptiles go, what route they take to get there, and how they navigate, is a mystery.</blockquote>
<p>It was an unusual trip in other ways, too. Typically when biologists track turtles from their nesting beaches on small islands, most wind up in coastal territory, having paddled across the open ocean until hitting a continental shelf and then turning left or right. But Serenity ended up on a flyspeck island, and many others of her cohort—Estebanâ€™s team tagged a total of 35 turtles over five years—followed suit.</p>
<p>"A number of these turtles migrated to very, very small island targets, some not more than a couple of hundred meters square,â€� says Alex Rattray, a biologist at Deakin University who was also involved in the research. A few did travel more than 5000 kilometers west to the coastlines of Somalia and Mozambique, but others pulled up short of the coast, joining Serenity elsewhere in the Seychelles archipelago; still others swam north to the Maldives islands.</p>
<p>Their destinations underscored the extraordinary nature of sea turtle migration. Itâ€™s astonishing enough that a sea turtle can navigate across thousands of miles of open ocean, with no discernible landmarks, and wind up in the correct place. Even more astonishing is when the correct place is a dot of sand with nothing but blue until the horizon in every direction.</p>
<p>It's a feat that bewildered Charles Darwin. "Even if we grant to animals a sense of the points of the compass, of which there is no evidence," he wrote, "how can we account, for instance, for the turtles which formerly congregated in multitudes, only at one season of the year, on the shores of the Isle of Ascension, finding their way to that speck of land in the midst of the great Atlantic Ocean."</p>
<p>Since Darwin wrote those words in 1873, scientists have tried to understand just how turtles make these awesome journeys. Before the invention of GPS technology, sailors crossing the globe relied on a combination of complex mechanical instruments and accurate timepieces. Much remains unknown about how turtles accomplish the same task, the only tools at their disposal resting within their own brains and bodies—but biologists have come a long way in understanding how sea turtles find their way.</p>
<center>
<iframe width="733" height="412" src="https://player.vimeo.com/video/486666840?color=ffcd05&amp;title=0&amp;byline=0&amp;portrait=0" frameborder="0" allowfullscreen=""></iframe>
</center>
<p>The animated travel tracks of 35 green sea turtle migrations tracked from nesting beaches in the Chagos archipelago. Hays et al./<em>Current Biology</em></p>

<p><span>I</span>n the first month after slipping off the beaches of Diego Garcia, Serenity had logged nearly four thousand kilometers. She was still in the open ocean, north and a little east of Madagascar. Rattray wouldn't know it yet, but when he switched his computer on to check on her progress, he would find Serenity at almost precisely the longitude of her final destination in <a href="https://en.wikipedia.org/wiki/Farquhar_Atoll" target="_blank">Farquhar Atoll</a>. There was just one problem: was she was at the wrong latitude.</p>
<p>The turtle had missed her target by some two hundred kilometers. That would be like walking from New York City to Los Angeles, but accidentally winding up in Tijuana, Mexico instead. But rather than take a right turn and swim north, she kept heading west, further and further away from her goal.</p>
<p>So how did she get back on course?</p>
<p>Whether you're a sea turtle or a ship's captain, finding your way around the planet requires two tools: a map and a compass. A map tells you where you are relative to some other location: where you started out, for example, or where you want to go. A compass helps to keep you moving in a reasonably straight line.</p>
<p>"There's all sorts of ways to set and maintain a heading," says marine biologist <a href="https://lgl.com/en/staff/staff-directory/179-putman-nathan" target="_blank">Nathan Putman</a>, who studies navigation in sea turtles and salmon. Animals who have good vision can orient based on the polarization of sun light, as some birds are thought to do, or based on the position of stars in the night sky, as in dung beetles. If animals can marry their vision to an internal clock, then they can use the sun's position as a compass, accounting for its movement across the sky throughout the day. It's thought that a time-compensated sun compass, as it is called, is one of the tools that migrating monarch butterflies use to maintain their headings.</p>
<p>Other animals might orient based on the direction that persistent winds blow or the direction waves travel through the ocean. Indeed, when loggerhead sea turtles first hatch on Florida beaches, they know to swim directly into oncoming waves, a strategy that deposits them into the Gulf Stream, part of a larger network of currents called the North Atlantic Sub-tropical Gyre. These currents, which stretch from the eastern seaboard across to southern Europe and northern Africa, encircle a region known as the Sargasso Sea. By staying within the gyre, vulnerable young sea turtles can remain relatively safe.</p>
<p>In 1989 a meteorological fluke helped Ken Lohmann, a biologist at the University of North Carolina at Chapel Hill, confirm that hatchlings use waves as a guide. That year, Hurricane Hugo temporarily caused waves to travel towards the open ocean rather than towards Florida's Atlantic coast. When Lohmann dropped newly hatched turtles into these conditions, they swam into the waves, just as their innate programming instructed them to—and as a result, they went the wrong way.</p>
<p>But what if turtles were to hatch on a calm, windless night with no waves to point the way? Lohmann brought hatchlings into a laboratory to find out. In complete darkness and with no other cues available to guide them, they swam towards the northeast, which in their natural environs would have safely launched them into the Gulf Stream. When he then induced an artificial magnetic field around the tanks, the turtles continued in what they thought was a northeasterly direction. In reality, thanks to Lohmann's magnetic misdirection, they were swimming in precisely the opposite direction. The results confirmed that they really did use Earth's magnetic field.</p>
<blockquote>Sea turtles hatch with at least two strategies for finding their way pre-programmed into their brains: the movement of waves and the Earth's magnetic field.</blockquote>

<p>Taken together, Lohmannâ€™s experiments revealed that sea turtles hatch with at least two strategies for finding their way pre-programmed into their brains: the movement of waves and the Earth's magnetic field.</p>
<p>Currents around Diego Garcia are of course different from those off the Florida coast. Turtles born in Diego Garcia are delivered into the South Equatorial Current, which is part of a larger system called the Indian Ocean Gyre. The parameters of Earth's magnetic field differ as well. But the underlying principle remains the same: turtles are born with a set of instructions that, at least most of the time, safely delivers them into the open ocean.</p>
<p>"Offshore migration is really just the first part in a longer transoceanic migration,â€� says Lohmann, one that occupies the first five to eight years of a sea turtleâ€™s life—a period sometimes called â€œthe lost years,â€� spent in the open ocean, where sea turtles were once thought to lazily drift wherever the currents took them. But Lohmann realized that this strategy could be deadly.&nbsp;</p>
<p>If turtles in Florida floated passively on the North Atlantic Sub-tropical Gyre, for example, then after they cross the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way">http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301247</guid>
            <pubDate>Fri, 04 Dec 2020 11:39:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Science of Managing Our Digital Stuff]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25301143">thread link</a>) | @ColinWright
<br/>
December 4, 2020 | https://humane.computer/review-the-science-of-managing-our-digital-stuff/ | <a href="https://web.archive.org/web/*/https://humane.computer/review-the-science-of-managing-our-digital-stuff/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>For a long time I've held this conviction that hierarchical file systems are a disaster. Over the years, there have been many attempts at building systems which avoided them: the entire hypermedia lineage from <a href="https://en.wikipedia.org/wiki/Memex">Vannevar Bush's Memex</a> with trails, through Ted Nelson’s work, and on to efforts like <a href="https://en.wikipedia.org/wiki/HyperCard">HyperCard</a>, along with completely different approaches like the <a href="https://en.wikipedia.org/wiki/Canon_Cat">Canon Cat</a> (and related, <a href="https://en.wikipedia.org/wiki/Archy">Archy</a>) and <a href="http://www.cs.yale.edu/homes/freeman/lifestreams.html">Lifestreams</a>. The common motivation seems to be that nested folders are a bad match for human thought.</p>
<blockquote>
<p>We sought to reduce the influence of hierarchical directories and conventional files (which we see as large lumps with stuck names in fixed places, with compulsory gratuitous naming — unsuited to overlap, interpenetration, rich connectivity, reasonable backtracking, and most human thinking and creative work.)</p>
</blockquote>
<blockquote>
<p>— <a href="http://www.xanadu.com.au/ted/XUsurvey/xuDation.html">Ted Nelson, Xanalogical Structure</a></p>
</blockquote>
<p>It’s hard not to disagree — I’m relatively fastidious with my organization and my home folder is still full of incomprehensible structures accumulated over the years, not dissimilar to this XKCD comic:</p>
<p><img src="https://humane.computer/content/images/2018/02/filesimg.png" alt=""></p>
<p>However, history has not been kind to these projects — I’ve tried a few myself and they’re okay for a while, but I keep coming back to traditional systems, despite their flaws. Desktop operating systems are still based around folders, more Web apps and mobile apps use a “simulated” files and folders representation, to the point where iOS 11 now adds a "Files" app avoided for the previous ten releases.</p>
<p>In a way, this shouldn't be surprising. The <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy Effect</a> tells us that the longer something non-perishable, like an idea, has been around, the longer its expected lifespan. There’s clearly something powerful behind files and folders, and a thorough analysis of why might give us a framework by which to understand improvements and alternatives. I was stuck without a clear path forwards until I discovered the fantastic book <a href="https://mitpress.mit.edu/books/science-managing-our-digital-stuff">The Science of Managing Our Digital Stuff</a> by <a href="https://mitpress.mit.edu/authors/ofer-bergman">Ofer Bergman</a> and <a href="https://mitpress.mit.edu/authors/steve-whittaker">Steve Whittaker</a>. The book is a summary of the work done in the space of Personal Information Management (PIM) over the past few years, including many studies designed by themselves. From the blurb:</p>
<blockquote>
<p>Bergman and Whittaker report that many of us use hierarchical folders for our personal digital organizing. Critics of this method point out that information is hidden from sight in folders that are often within other folders so that we have to remember the exact location of information to access it. Because of this, information scientists suggest other methods: search, more flexible than navigating folders; tags, which allow multiple categorizations; and group information management. Yet Bergman and Whittaker have found in their pioneering PIM research that these other methods that work best for public information management don’t work as well for personal information management.</p>
</blockquote>
<p>From the book:</p>
<blockquote>
<p>This book provides a scientific understanding of how we select, organize, and access such personal collections. Personal information management (PIM) is the process by which individuals curate their personal data in order to reaccess that data later. Curation involves three distinct processes: how we make decisions about what personal information to keep, how we organize that kept data, and the strategies by which we access it later.</p>
</blockquote>
<p>A poorly designed PIM system can result in "lost personal data”, “large, disorganized personal collections of unclear value”, and “failing to deal with time-sensitive information that requires action”. So far, so good. However, there’s a fundamental tension at the heart of things:</p>
<blockquote>
<p>Choosing appropriate folder organization and labels therefore requires people to predict exactly how they will be thinking about particular information at the time that they need to retrieve it. Predicting future retrieval context is difficult, because there are usually multiple ways that a file can be categorized, such as by author, topic, date or project. The inability to accurately predict how one will think about information in the future makes it more likely that future retrieval will fail.</p>
</blockquote>
<p>After walking through a number of alternatives to folders (search, tagging, group management) and showing that in user studies they don’t perform as well as folders, they get to the crux of their argument. Navigating folders is a spatial task, rather than a linguistic one like search or tags, which uses a different part of the brain:</p>
<blockquote>
<p>Throughout millions of years of evolution, humans have developed mechanisms that allow them to retrieve an item from a specific location (be it real of virtual) by navigating the path that they first followed when storing that information. These deep-rooted neurological biases lead to automatic activation of location-related routines, which have minimal reliance on linguistic processing, leaving the language system available for other tasks.</p>
</blockquote>
<p>PIM systems have a purpose and should be measured and evaluated as such. This gives us a framework by which to start comparing and improving on the traditional folder structure, as they do in the latter part of the book. One suggestion, which I very much agree with, is to get rid of application specific storage locations:</p>
<blockquote>
<p>Documents relating to a given project are stored in one folder hierarchy (e.g., in My Documents), emails in a separate mailbox hierarchy, and favorite websites in yet another browser-related hierarchy…Although the additional structure solution allows users to work in an integrated project environment, it requires managing yet another structure and may increase cognitive complexity. As well as the additional requirement to create a new structure, the user now has yet another retrieval location to maintain and remember.</p>
</blockquote>
<p>The book also leaves open the question of how to manage the interface between public or group information management, where search, hyperlinks, and tags do quite well, and the spatial world of PIM. Perhaps systems should be designed to respect the boundary: shared work drives, like Google Drive, shouldn’t have a shared folder structure but should be tagged and linked (which are shown to work well in group settings and novel content). Individuals can then pull those resources locally, with a stable location that they can navigate to when they need to exploit them.</p>
<p>There are some interesting technologies not evaluated that I would have loved to have seen in the book. The Plan 9 style unioned directory structure, and whether that helps or hinders spatial navigation (I feel like it would help, as traditional directories mix orthogonal concerns, like which physical drive the data is stored on). I would also love to have seen an in-depth discussion of  <a href="https://en.wikipedia.org/wiki/Zooming_user_interface">Zooming User Interfaces</a> such as <a href="https://mrl.nyu.edu/publications/sig93-pad/siggraph-93-origpad.pdf">Pad</a>. They have their own issues <a href="http://www.cs.umd.edu/hcil/trs/2009-21/2009-21.pdf">(a good overview here)</a> but proponents did clearly understand the neurological processes behind spatial navigation:</p>
<blockquote>
<p>We can find things in such a planning room [a room dedicated to project planning where the walls are covered in sticky notes, photos etc.] because we tend to remember landmarks and relative position. “The stuff about marketing is on the right wall, sort of lower down near the far corner,” someone might tell you. On another occasion, you go right to a particular document because you remember that it is just to the left of the orange piece of paper that Aviva put up.</p>
</blockquote>
<blockquote>
<p>— Jeff Raskin, The Human Interface</p>
</blockquote>
<iframe width="560" height="315" src="https://www.youtube.com/embed/0gLw34-AzXM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe>
<p>All of which is fascinating, but the real breakthrough realisation for me came with this section:</p>
<blockquote>
<p>The main aim of information item classification in PIM is not to externalize our internal representation of these items (Hsieh et al. 2008) or to fully describe them, as implied by Civan et al. (2008), but to support easy, fast, and efficient retrieval.</p>
</blockquote>
<p>Novel information management systems need to understand that they are a tool to serve a purpose and conduct usability studies to ensure that they're achieving them. The Lindy Effect is strong: files and folders have been around for a long time, and their staying power is testament to how well they achieve their task. Future PIM proposals will do well to internalise this and look to build on their strengths while addressing current weaknesses.</p>
<!--kg-card-end: markdown-->
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://humane.computer/review-the-science-of-managing-our-digital-stuff/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301143</guid>
            <pubDate>Fri, 04 Dec 2020 11:20:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wikipedia's in Trouble (2019)]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 86 (<a href="https://news.ycombinator.com/item?id=25300942">thread link</a>) | @sanqui
<br/>
December 4, 2020 | http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html | <a href="https://web.archive.org/web/*/http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
I got involved in wikipedia <a href="https://en.wikipedia.org/w/index.php?title=User%3ASpencerk&amp;action=history&amp;year=2006&amp;month=-1&amp;tagfilter=">very early</a>.

It was one of the most revealing things in my life, watching it being laughed at, to become the center of, and authority of, human knowledge.

It was obvious that it was working. The lag of this was 5 years or more.

Wikipedia was an experiment that proved itself, when every graph was going up and to the right.

Some of the graphs are now going down.

</p><p>Wikipedia's Markup language:</p><p>
One of the central design decisions in wikipedia is that <span>all information</span> is stored in an editable document.
This poses a huge amount of challenges for caching and scaling wikipedia. It's not a database, that you can run a script on.

Worse though, is that all of it's content is buried in this ad-hoc, impenetrable, opaque, and mostly <i>un-parsable</i> format.

If wikipedia had used <i>markdown</i>, <i>html</i>, or some <i>standardised format</i>, any parser would flip-it into other future formats.

Wikipedia's custom language is just <a href="https://github.com/spencermountain/wtf_wikipedia/blob/master/README.md">clearly insane</a>, undocumented, hopeless.
There's a team <span>(of great people!)</span> at wikimedia <a href="https://phabricator.wikimedia.org/tag/parsoid/">constantly working on it</a>, and unable to make any backwards-incompatible changes. I imagine their lives are hard.
People are creating weird new syntax concepts all the time.

Here's the markup for the <b>first sentence</b> of the Albert Einstein wikipedia article:
<img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/albert-einstein.jpg">

The first wikimedia parser was called <a href="https://github.com/earwig/mwparserfromhell/">mwparserfromhell</a>. DBPedia, <a href="https://upload.wikimedia.org/wikipedia/commons/a/a9/LOD_Cloud_2014-08.svg">the center of the semantic web</a>, after years of work, has only ever offered limited parsing from categories and infoboxes.
Much of the early-years at <b>Freebase</b> were spent trying, with limited-success, at parsing wikipedia.
I've spent <a href="https://github.com/spencermountain/wtf_wikipedia/graphs/commit-activity">years</a> trying to parse it myself.
I'm a shitty programmer. <i>WolframAlpha</i>, and many other serious companies are using my parser,
       which is <span>down right hilarious</span>.

<img id="rtl" src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/rtl.jpg"></p><p>yes, arabic editors must write it in right-to-left, <a href="https://youtu.be/OCQd02hORJQ">somehow</a>.</p><p>

It's hard to describe how much of a serious problem this is.
Wikipedia's content is never going to go anywhere, or be used by anything.

Wikipedia may slowly die-off - like myspace, or geocities - but it's information will not go on.

Play-around in the official wikipedia android app. Many pages are unreadable.
There is a good-deal of <i>clearfix</i>, and <span>table-span</span> logic, mushed right into the syntax.
Most developers will not touch this kind of stuff.

There will be no move to a wikipedia 2.

</p><p>Static copies of dynamic content</p><p>
The contents of the english wikipedia dump are as follows, (as of Jan 2019):
</p><p>
of the <b>14m</b> records in the wikipedia dump, only <b>5.5m</b> (40%) are public-facing articles.

   <span>Yup.</span>
This does not include deleted pages, or old versions, either.


<b>Redirects:</b>
A computer-science 101 problem is to implement a fuzzy string matching. There's usually a section in the textbook about it:
</p><div>
<p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/clr.jpg"></p><p>oh yes, right here in chapter 34.</p><p>
there are <b>8,550,441</b> redirects in wikipedia.
They are mostly typos, or case-changes, and are mostly created by hand, every day.

<span>and what happens to a redirect when a page gets deleted, or merged, or spli - <a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot">Yup</a>.</span>
</p></div>

<p><b>Talk pages:</b>
Wikipedia has 35m registered users. When a user joins, a bot will often send them a <a href="https://en.wikipedia.org/wiki/Template:Welcome">{{welcome}}</a> template.
Sometimes nice users will do it themselves. It looks <a href="https://en.wikipedia.org/wiki/User_talk:Kj_aviator">like this</a>.

   - when this happens, this creates a new user page, with <b>a copy of this text</b> each time.

There are millions of examples of this in the dump. The same text, verbatim over and over.

The same process happens with <b>'Wikiprojects'</b>. Bots go around adding templates, by creating a talk page, and adding a template to it.

The same process happens with <i>deleted pages, fair-use warnings, and some bot edits</i>. Each time an edit happens, a new page is created, and boilerplate text gets thrown into it.
Resulting in <a href="https://en.wikipedia.org/wiki/Talk:XTC_discography">this</a>:
<img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/boilerplate.png"></p><hr><p>
So let's get things straight:
in <b>1993</b>, a small japanese game company created <a href="https://en.wikipedia.org/wiki/A-Rank_Thunder_Tanjouhen">this videogame</a>:
</p><p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/thunder.jpg">
</p><p>
• In <b>2008</b>, a wikipedia user created the article with <a href="https://en.wikipedia.org/w/index.php?title=A-Rank_Thunder_Tanjouhen&amp;oldid=205879125">two sentences and a link</a>.

• In the past 10 years since, the page has been edited <a href="https://en.wikipedia.org/w/index.php?title=A-Rank_Thunder_Tanjouhen&amp;oldid=205879125">26 times by bots</a>.

• this created a Talk page filled with <a href="https://en.wikipedia.org/wiki/Talk:A-Rank_Thunder_Tanjouhen">11 automated sentences</a>.

A huge bulk of the wikipedia database is this boilerplate text. See <a href="https://en.wikipedia.org/wiki/Talk:764_Gedania">this asteroid</a>, <a href="https://en.wikipedia.org/wiki/Talk:NS3_(HCV)">this virus</a>, or this <a href="https://en.wikipedia.org/wiki/Talk:Oceania_Judo_Union">judo club</a>.

... and remember, if we wanted to change this text, we'd have to go and edit each of these pages - and because this syntax is so nuts, <b>bots have a hard time</b> making even simple stylistic changes, without ruining a whole page.

oh, so what happens to these auto-generated talk pages when a page is deleted, merged, or spli- <a href="https://en.wikipedia.org/wiki/Talk:578_Happelia">yup</a>

<b id="automation">Automated articles:</b>
There is a lot of disagreement about how much of wikipedia is generated by bots, and if this matters.
There's no way of knowing. Any boring-themed article with a few sentences, a reference, and an infobox probably won't get deleted.
So nothing's stopping you from spitting-out articles from a <b>database of enzymes</b>, or <b>college rugby players</b>, or season statistics for defunct sports teams.
</p><p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/enzymes.jpg">
  <img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/subgiants.png">
</p><p>
I have nothing against bots, I have nothing against the long-tail, but I think automated article-creation is responsible for a good amount of the wikipedia's claimed growth, over the past few years.
We need to be up-front about this, if we're talking about the health of the project.

Here's the distribution of words in english wikipedia, by the size of articles:
</p>

<div>
<p><span>ok hey,</span> I don't mind that the wm developers didn't develop a fancy search index, in 2001.
That's fine.
Nobody could have predicted the success and scale of wikipedia early on.
</p><p>
What angers me though
         - <i>and it should anger you</i> -
is that these problems has not been fixed in the <b>18 years</b> since.

God damn them.

Well-meaning people are wasting their time on this <span>everyday</span>.

Any <i>startup job-interview</i> asks questions about implementing a system like this.
Any CS grad can create a lucene index, to handle typos.
Some of it is complicated. Some of it is basic competence.

<span>It's annoying to whine</span>,
     but at some point, we're right to be angry at wikipedia.

            that it cannot find 2nd gear,
     when the rest of the world is zipping-along.
</p>
</div>

<p>Wikidata</p><p>
In 2007 Danny Hillis raised $57 million dollars,<a href="https://www.crunchbase.com/organization/metawebtechnologies#section-overview">[1]</a> bought-out the <b>entire</b> MIT semantic-web group,
hired 50~ employees, (including <a href="https://www.apple.com/leadership/john-giannandrea/">this person</a>, <a href="https://www.amazon.com/Toby-Segaran/e/B001I9RQVS">this person</a>, <a href="http://davidhuynh.net/">this person</a>) and got an office in the mission.

They reconciled all of wikipedia, the entire musicbrainz database, the entire open-library database, the tvdb database, and all of wordnet.
They signed a (massive) deal to import <b>all collections of the stanford library</b>.<a href="https://www.clir.org/pubs/reports/pub152/stanford-linked-data-workshop/">[2]</a>

They hit <b>high-90%</b> classification of all <a href="https://research.google.com/pubs/archive/44818.pdf"><b>50 million</b></a> entities (wikipedia has 5m)
They were evaluated at very-high 90's accuracy by several third-parties.

Facebook, Bing, Amazon, and Google all began using its data in nearly real-time in their search products.

This was one of the largest and most ambitious software projects in history.

In 2010 freebase was bought for a whack of money, and then killed-off by google.
When google announced they would be shutting down the API, they offered to import all of this data to a new wikimedia project called <span>wikidata</span>.

Wikidata was 4-or-5 Lua developers, in Germany, on a few research grants.

</p><p>and they said no. 😐</p><p>

so they said this data didn't meet it's guidelines regarding sourced data.

    <i>... aren't you pulling information <b>from wikipedia</b> blindly?</i>

    <i>... what about your (~60%) unreferenced facts?</i>

    <i>... aren't you <b>multiplying vandalism</b> from multi-lingual wikipedias?</i>

    <i>... how do you use, or verify references?</i>

They built a tool to <b>hand-transfer each freebase fact</b>, which if you have a calculator, may seem funny.
<span>(at 10 people clicking full-time, would have taken 10 million years)</span>

8 years later, <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page">Wikidata</a> remains tiny, buggy, unused, and worse - <i>majority unreferenced</i>.
I mean, they're pulling their data from wikipedia, which gets vandalized almost every minute!

It's accomplished very-little from its 5-year plan. They write academic papers.
They still don't really offer a rest api.
       ...creating new types or properties is I think, possible? or it's supposed to be...

It's got few of the safeguards, momentum, features, and ambition that Freebase had a full decade ago.
If wikidata was a company, it would not exist anymore, and you wouldn't have heard of it.

But Wikimedia places <b>banner-ads</b> on <span>hours of eye-blistering user-created content</span>,
begging children, students, and poor-people for money.
and they choose to be this petty, pithy and behind-the-times.

</p><p>Category-system</p><p>
It's a beautiful idea, to classify information with category-scheme, <a href="https://humane.computer/review-the-science-of-managing-our-digital-stuff/">until it falls-apart</a>.

<a href="http://www.shirky.com/writings/ontology_overrated.html"><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/shirky-category.jpg"></a>
Wikipedia has many-thousands of categories. They <a href="https://en.wikipedia.org/wiki/Wikipedia:Dump_reports/Category_cycles">loop-around</a> all-over the place.

</p><p>
People:
    → Musicians
        → Singers
              → American_Idol
                  → Books_about_American_Idol
</p><p>
or worse:
</p><p><span>Albanian language</span>:
    → Albanian-speaking countries and territories
      → Kosovo (region)
        → Kosovo
          → Kosovar society
            → Languages of Kosovo
              → <span>Albanian language</span>
</p><p>
if you're ever too-cheerful, and wanting to feel depressed, have a visit <a href="https://en.wikipedia.org/wiki/Wikipedia:Categories_for_discussion/Log/Today">Categories for deletion/Today</a>,
where you'll see precious human-life spent debating whether <b>'Category:Goth'</b> should exist, if it is a genre of music, if it's is a fashion-style, etc.

Work is being ravenously deleted all the time. You'll get sad thinking about it.

</p><p>Templates</p>
<div>
  <p>what about all this stuff →</p>
  <p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/infobox.png">
</p></div><p>
You're right.

Wikipedia has good structured-data in <b>infoboxes, lists, tables, citations, etc</b>.

The issue is, as of Feb 2019, Wikipedia has <b>634,755 different kinds of templates</b> (see this <a href="https://s3-us-west-1.amazonaws.com/spencer-scratch/allTemplates-2018-10-26.tsv">21mb download</a>).

Yes, there are all different.

Yes, there are <span>templates-within-templates-with-escaping-with-escaping</span>.

Even if you parse them perfectly, how do you know that for <a href="https://en.wikipedia.org/wiki/Template:HorseDeathYear">Template:HorseDeathYear</a>, the third parameter is the <b>birth date of the horse</b>, and the fourth is the birth-month?

see, for example:

• <a href="https://en.wikipedia.org/wiki/Category:16-Team_bracket_templates">Tennis Brackets vs Table Tennis Brackets</a>

• '<a href="https://en.wikipedia.org/wiki/Template:Birth_date_and_age">Birth_date_and_age</a>' vs '<a href="https://en.wikipedia.org/wiki/Template:Birth-date_and_age">Birth-date_and_age</a>'.

• <a href="https://en.wikipedia.org/wiki/Template:Trapezoidnotation">a template for a Trapezoid unicode symbol</a>
It's just a straight-up mess.

If you're thinking, <i>gee wikipedia editors must feel exhausted and stupid</i> - you're right.

<a href="https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Template:Retired&amp;limit=500">Many</a>…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html">http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html</a></em></p>]]>
            </description>
            <link>http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300942</guid>
            <pubDate>Fri, 04 Dec 2020 10:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using redo to manage R data analysis workflow]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300926">thread link</a>) | @kkoncevicius
<br/>
December 4, 2020 | http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/ | <a href="https://web.archive.org/web/*/http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>Real world data analysis projects are often complicated.
They can involve multi-gigabyte input files, complex data cleaning procedures, week-long computations, and elaborate reports.
Making changes and then tracking down the parts that need to be recomputed becomes close to impossible.
In this article I describe my approach for dealing with this problem, which is based on a lesser known build automation tool - redo<a href="#cn:1" id="cnref:1" title="see citation"><sup>(1)</sup></a>.</p>

<h2 id="redo">Redo</h2>

<p>Data science projects typically have complex pipelines involving input files, code, results, and reports.
Analyses can be computationally intensive and take hours if not days or weeks to complete.
Hence, data science practitioners need to be able to make changes without restarting the whole pipeline from scratch.
Workflow management becomes essential and many projects turn to build automation tools like Make<a href="#cn:2" id="cnref:2" title="see citation"><sup>(2)</sup></a>.
However Make has its warts, in particular when applied to data analysis, and so people end up designing their own variants, such as SCons<a href="#cn:3" id="cnref:3" title="see citation"><sup>(3)</sup></a>, Snakemake<a href="#cn:4" id="cnref:4" title="see citation"><sup>(4)</sup></a>, and Drake<a href="#cn:5" id="cnref:5" title="see citation"><sup>(5)</sup></a>, among others.</p>

<p>One lesser known alternative to the above mentioned tools goes by the name of “redo”.
Redo is a recursive build automation system that promises to be simpler and more powerful than Make.
Unlike Make or its derivatives redo is tiny, recursive, and has no special syntax of its own.
It allows declaring dependencies straight from within the code being executed, which enables writing scripts that “know” they will need to rerun themselves whenever their input data changes all without maintaining a separate dependency configuration file.
This demonstration will use the redo version by “apenwarr”<a href="#cn:6" id="cnref:6" title="see citation"><sup>(6)</sup></a> who rediscovered, documented, and popularized the idea and is the author and current maintainer of its most comprehensive implementation<a href="#cn:7" id="cnref:7" title="see citation"><sup>(7)</sup></a>.</p>

<p>Standard redo workflow has several <code>'.do'</code> files that hold the instructions for producing every output file saved during the analysis.
Computation of each target is requested with a <code>'redo'</code> command which is called straight from the command line.
If we have a simple pipeline where a raw <code>'.csv'</code> data file has to be cleaned, transformed, and then visualized, our final setup might look something like this video:</p>



<video width="700" height="525" controls="" autoplay="">
<source src="http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/figure/redo.mp4" type="video/mp4">
</video>

<h2 id="exampledemonstration">Example demonstration</h2>

<p>A typical data analysis workflow has four parts: 1) obtaining the data; 2) cleaning the data; 3) estimating a model; 4) producing a report.
Similarly our dummy project will consist of four steps:</p>

<ol>
<li>Obtain a dataset of chicken weights and their feed supplements.</li>
<li>Subset the data by only selecting one type of feed supplement.</li>
<li>Produce a “model” for the selected supplement using empirical density estimation.</li>
<li>Summarise the obtained results in a report.</li>
</ol>

<p>Each step will produce an output and save the results to a separate file.
To keep things simple all the scripts for the steps above will be written in R.
The overall goal is to construct a pipeline that can detect changes in our stored data files or our code and automatically reproduce the final report with all its dependencies.
The final pipeline should look something like this:</p>

<p>This demonstration will start simple and add complexity along the way.</p>

<h2 id="doingandredoing">Doing and redoing</h2>

<p>Let’s start with the most basic redo command.
In the first step we have to obtain a dataset of chicken weights plus the type of supplements they were fed and store it in a file.
The dataset is freely available from within R so all we have to do is save it.
We enter the commands for this task to a file named <code>'rawdata.rds.do'</code>:</p>

<pre><code>1.  #!/usr/bin/env Rscript
2.
3.  outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.
5.  saveRDS(chickwts, file = outfile)
</code></pre>

<p>Then to obtain the data file we go to a command line and call redo:</p>

<pre><code>$ redo rawdata.rds

redo:  rawdata.rds
</code></pre>

<p>Which creates the <code>'rds'</code> file named <code>'rawdata.rds'</code> containing the data and informs us about the result.</p>

<p>Some explanation is necessary.
The redo command simply takes an argument and tries to produce a file of the same name.
In this case the argument was <code>'rawdata.rds'</code> and, given the command, redo starts looking for instructions about how to produce it.
The rule for storing instructions is quite simple - they are stored in a separate file with a name constructed by adding a <code>'.do'</code> suffix to the original argument.
In other words - redo looks for instructions about producing <code>'rawdata.rds'</code> file in a file named <code>'rawdata.rds.do'</code>.</p>

<p>The file itself is treated as a shell script.
This is why it is started with a hash-bang<a href="#cn:8" id="cnref:8" title="see citation"><sup>(8)</sup></a> sequence followed by a path to a program that will be used to interpret the instructions.
We want to write our script in R so we specify Rscript.</p>

<p>Finally, when redo calls our script with <code>'redo rawdata.rds.do'</code> it passes three arguments to it:
1) The target name itself - <code>'rawdata.rds'</code>, 2) The basename of the target file - <code>'rawdata'</code>, 3) The temporary file to save the data in - <code>'rawdata.rds.redo.tmp'</code>.
After the execution finishes the file stored in the temp file (3rd argument) will be moved to the target (1st argument).
This mechanism makes sure that in the case of failed computation the existing target will not be corrupted.
And that is why we do not specify the output filename within the script ourselves but rather use the 3rd variable provided by redo.</p>

<p>The dataset is obtained and stored and so the first step of this project is now complete.</p>

<h2 id="dependencies">Dependencies</h2>

<p>What happens if we execute the previous redo command again? - nothing spectacular:</p>

<pre><code>$ redo rawdata.rds

redo  rawdata.rds
</code></pre>

<p>Redo executed the instruction file again and reproduced the output.
But there exists another command called <code>redo-ifchange</code> that behaves a bit differently:</p>

<pre><code>$ redo-ifchange rawdata.rds
</code></pre>

<p>After calling this command - nothing happens.
<code>redo-ifchange</code> differs from redo in an important way: it checks if any dependencies needed to reproduce the specified output have changed.
In our case redo knows only a single dependency for our <code>'rawdata.rds'</code> file - the ‘do’ instruction file itself.
It hasn’t changed so <code>redo-ifchange</code> halts and does not reproduce the target.</p>

<p>So let’s move on to the second step of the project and select a feed type.
To achieve this we produce a separate R file called <code>'subdata.rds.do'</code>:</p>

<pre><code>1.   #!/usr/bin/env Rscript
2.
3.   outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.
5.   system("redo-ifchange rawdata.rds")
6.   rawdata &lt;- readRDS("rawdata.rds")
7.
8.   subdata &lt;- rawdata[rawdata$feed == "soybean", ]
9.
10.  saveRDS(subdata, file = outfile)
</code></pre>

<p>Take a closer look at the 5th line in the file above.
Here, before loading the data, we call the <code>redo-ifchange</code> command on it.
At this step the script temporarily halts and checks if our requested data file, <code>rawdata.rds</code>, needs to be recomputed.
If the target file is missing or some of its dependencies have changed it will be regenerated by calling the <code>'rawdata.rds.do'</code> script.
And if nothing changed the 5th line passes without redoing anything and the already existing data file is used.</p>

<p>Now, to obtain the output for the second step, we request the file with redo, just like before:</p>

<pre><code>$ redo subdata.rds

redo subdata.rds
</code></pre>

<p>All done, the result is stored in <code>'subdata.rds'</code>.
Currently we have the following files in our project:</p>

<pre><code>$ tree
.
├── rawdata.rds
├── rawdata.rds.do
├── subdata.rds
└── subdata.rds.do
</code></pre>

<p>Let’s remove all the <code>'rds'</code> data files and try reproducing the <code>'subdata.rds'</code> again:</p>

<pre><code>$ rm *.rds
$ redo subdata.rds

redo  subdata.rds
redo    rawdata.rds
</code></pre>

<p>Here we asked for <code>'subdata.rds'</code> but redo was smart enough to reproduce both of the data files.
What we did, in essence, is declared a dependency between two R scripts from within the script itself.</p>

<h2 id="defaultinstructions">Default instructions</h2>

<p>Before moving on we have to spend some time on a few redo implementation details.
By convention when we call <code>'redo a.b.rds'</code> command redo starts looking for an <code>'a.b.rds.do'</code> script.
But if the file doesn’t exist redo will search for a different file named <code>'default.b.rds.do'</code> which should store general instructions for producing any <code>'*.b.rds'</code> file.
As an example we rename previous <code>'subdata.rds.do'</code> file to <code>'default.subdata.rds.do'</code>.
Now this do script will get executed whenever we use redo to request a file that ends with <code>'subdata.rds.do'</code>:</p>

<pre><code>$ mv subdata.rds.do default.subdata.rds.do
$ redo a.subdata.rds b.subdata.rds

redo a.subdata.rds
redo b.subdata.rds
</code></pre>

<p>Since both files generated above were produced by the same script <code>'default.subdata.rds.do'</code> they are identical - they both hold the data for soybean feed.
Those files will no longer be needed for our demonstration so we can get rid of them:</p>

<pre><code>$ rm *subdata.rds
$ tree
.
├── default.subdata.rds.do
├── rawdata.rds
└── rawdata.rds.do
</code></pre>

<h2 id="parameters">Parameters</h2>

<p>The default instructions introduced above can be exploited to implement parameters in our do scripts.
In the current stage we have a script - <code>'default.subdata.rds.do'</code> that is executed whenever we request an ‘rds’ file that ends with <code>'subdata.rds'</code>.
It always produces the data for the soybean feed but we can make it return different outputs based on the prefix of the target file.</p>

<p>Currently the feed types we are selecting are hard-coded in the code itself.
It would be nicer if we can specify them as parameters passed to the R script.
We rewrite <code>'default.subdata.rds.do'</code> file:</p>

<pre><code>1.   #!/usr/bin/env Rscript
2.
3.   outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.   feed    &lt;- strsplit(outfile, "\\.")[[1]][1]
5.
6.   system("redo-ifchange rawdata.rds")
7.   rawdata &lt;- readRDS("rawdata.rds")
8.
9.   subdata &lt;- rawdata[rawdata$feed == feed, ]
10.
11.  saveRDS(subdata, file = outfile)
</code></pre>

<p>Two changes were made:
1) the 4th line uses the prefix of the output file in order to decide which feed type should be returned;
2) the 9th line then uses the selected feed type in order to subset the data.
This allows us to request various types of feed data:</p>

<pre><code>$ redo soybean.subdata.rds

redo soybean.subdata.rds

$ redo casein.subdata.rds

redo casein.subdata.rds
</code></pre>

<p>And now we have separate types in separate files.</p>

<h2 id="redoingwithparameters">Redoing with parameters</h2>

<p>In the third step we need a do script that, given subsetted feed data, estimates the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/">http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/</a></em></p>]]>
            </description>
            <link>http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300926</guid>
            <pubDate>Fri, 04 Dec 2020 10:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toward more efficient and inclusive work with asynchronous communication]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300867">thread link</a>) | @munchor
<br/>
December 4, 2020 | https://www.singlestore.com/blog/toward-more-efficient-and-inclusive-work-with-asynchronous-communication/ | <a href="https://web.archive.org/web/*/https://www.singlestore.com/blog/toward-more-efficient-and-inclusive-work-with-asynchronous-communication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    <div>
                <p><span>I once heard that a “book worth reading is worth reading twice”, and I’ve found this to be true about other things as well. There’s a documentation page that’s been with me for the majority of my professional career; a page that I keep coming back to and that I’ve read from start to finish, without skipping a word, more than a few times in the last few years. This document is </span><a href="https://about.gitlab.com/company/culture/all-remote/asynchronous/"><span>GitLab’s Embracing Asynchronous Communication guide</span></a><span>, a section of GitLab’s public handbook that goes over their approach to asynchronous communication as a business.</span></p>
<p><span>To provide you with some context, as of writing this blog post, my role at SingleStore is Engineering Manager and I work with teams that are geographically distributed across a few countries (mainly the US, UK and Portugal). I have direct reports across these 3 countries as well, and prior to the COVID-19 pandemic, I was traveling to San Francisco a few times a year.</span></p>
<p><span>I started at SingleStore around four and a half years ago in San Francisco, but ended up deciding to relocate to Portugal and work there for the last three years. Being based eight hours away from the California time zone, I’ve learnt a lot about working across time zones, but mainly about how to work asynchronously, and all the principles behind async work are things that I apply and will apply in the future whether working across time zones or not.</span></p>
<h2><span>Efficiency and inclusiveness</span></h2>
<p><span>I fundamentally believe asynchronous communication leads to a more inclusive working environment because it allows individuals to work more flexible hours. Whether it’s because folks have to take their kids to school in the morning, or because a health condition prevents them from working continuously for 8 hours, working async allows us to more easily choose our working hours (and these may even change day-to-day).</span></p>
<p><span>Moreover, working asynchronously also allows an organization to more easily hire people in different countries and regions, which is key for diversity and inclusion. By not limiting hiring to a specific city or even country, it’s much easier to hire people with different backgrounds, races and nationalities. My colleague, Carl Sverre, discusses our own successful approach to building a team for remote work and additional considerations regarding asynchronous communication in this </span><a href="https://www.youtube.com/watch?v=AZpNlZWHe2A"><span>talk on geo-diverse team-building</span></a><span>.&nbsp;</span></p>
<p><span>The added efficiency from asynchronous communication comes from various aspects. Perhaps the first one that comes to mind is allowing knowledge workers to block out “focus time” on their calendars to do things like preparing slides, writing and reviewing code, going through applicant resumes, etc. A great book on this subject, which I also recommend, is Cal Newport’s </span><a href="https://www.calnewport.com/books/deep-work/"><span>Deep Work</span></a><span>. Focused work time is an invaluable tool toward getting things done and moving faster.</span></p>
<p><span>Another added benefit of asynchronous work is easier access to information (which also brings further transparency to the workplace), since more things should be written down in public as opposed to communicated 1:1 between 2 individuals.</span></p>
<h2><span>Applying this in my day-to-day</span></h2>
<p><span>The main principle of asynchronous communication that I apply in my day-to-day is not making assumptions about coworkers’ working hours. I may do a 9 AM to 5 PM in my time zone, but somebody else might prefer a very different schedule, even if they’re on the same time zone as I am. To help me not make any assumptions about the working hours of others, I do all of the following (and assume others do as well):</span></p>
<ul>
<li><span>Disabling any type of email or Slack/IM notifications</span></li>
<li><span>Not having Slack or work email on my phone</span></li>
<li><span>Not having an “online” status in your IM tool (i.e., setting yourself as permanently “Away” or permanently “Online”)</span></li>
<li><span>Avoiding communication that feels synchronous in Slack such as “Busy right now, I’ll check this later”. In most situations, I prefer to just reply whenever I can properly reply.</span></li>
</ul>
<p><span>These mechanisms encourage us to prioritize asynchronous communication and also to plan ahead to avoid needing quick or immediate unplanned feedback/help. More and better planning means less urgent things coming up throughout the week. Whenever I file tasks or write documents/emails, I put an emphasis on making sure that people don’t need to ask follow-up questions by including all needed information, and making communication as clear as possible. Writing well is one of the most important skills that one needs to develop when working in a mostly asynchronous environment.</span></p>
<p><span>Notice, however, that I do check Slack regularly (more often than email), especially due to the nature of my role and size of the team, but I check it </span><i><span>when I want to</span></i><span>, thus allowing me to focus on my deep work. Keep in mind that for certain positions (software engineering, site reliability engineering, etc.), an on-call rotation should be set-up with a tool such as PagerDuty to address urgent issues.</span></p>
<p><span>Another principle that I apply in my day-to-day is making sure that meetings are very well organized (which also helps with the aforementioned “better planning”):</span></p>
<ul>
<li><span>Never holding meetings without an agenda (with some exceptions) and sticking to it</span>
<ul>
<li><span>Taking notes alongside the agenda usually works great</span></li>
</ul>
</li>
<li><span>Having participants go through required reading beforehand, if there’s any</span></li>
<li><span>Scheduling meetings only when necessary and not when they can be replaced with an asynchronous workflow</span></li>
<li><span>Recording as many meetings as possible (Google Meet and Zoom make this quite easy)</span></li>
</ul>
<p><span>Moreover, it’s very important to be able to fallback to synchronous mechanisms when it makes sense (and once again, this is really explained in the </span><a href="https://about.gitlab.com/company/culture/all-remote/asynchronous/#when-to-pivot-to-synchronous"><span>linked documentation page</span></a><span>). For example, when new hires join our team, I shift towards a more synchronous working style with them until they’re more independent. We’re also working on trying to make our onboarding process a bit more self-service, but we haven’t gotten there just yet.</span></p>
<p><span>Finally, this style of work can lead to less human interaction, which can be addressed by holding informal events (such as games sessions, “remote coffees” and other things of the sort) to make sure team members are bonding.</span></p>
<h2><span>Last words</span></h2>
<p><span>This was an article that I’ve been meaning to write for a long time, as it’s a topic that I’m quite passionate about. I’d love to hear your feedback (both positive and negative), so reach out on </span><a href="https://twitter.com/davidrfgomes"><span>Twitter</span></a><span> or </span><a href="https://www.linkedin.com/in/davidrfgomes/"><span>LinkedIn</span></a><span>! Also, if this sounds like an environment in which you’d thrive as an engineer, we are hiring. You can find our open positions on our </span><a href="https://www.singlestore.com/careers/"><span>Careers page</span></a><span>.</span></p>
            </div>
                </article></div>]]>
            </description>
            <link>https://www.singlestore.com/blog/toward-more-efficient-and-inclusive-work-with-asynchronous-communication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300867</guid>
            <pubDate>Fri, 04 Dec 2020 10:27:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chang'e-5 unfolds Chinese national flag, takes off with lunar surface samples]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300640">thread link</a>) | @dlcmh
<br/>
December 4, 2020 | https://www.globaltimes.cn/content/1208931.shtml | <a href="https://web.archive.org/web/*/https://www.globaltimes.cn/content/1208931.shtml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      <h3> Chang'e-5 probe unfolds Chinese national flag, takes off from moon with lunar surface samples </h3>
    </p><div>
      <p>By Deng Xiaoci and Fan Anqi Source: Global Times Published: 2020/12/3 23:31:40 Last Updated: 2020/12/4 22:43:38 </p>
      
      
      <hr>
    </div><div>
      <div> <center>
<center><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-04/b65c88eb-92a0-4a86-aa0f-a34cb9bdff5b.jpeg"></center>
<p>Photo:CNSA</p><br>&nbsp;<img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-03/87038a0c-74a3-44f0-aa90-9210ab873966.jpeg"></center>
<p>CNSA illustration shows the lift-off moment of Chang’e-5 ascender from moon surface on Thursday 11:10 pm. About 2 kilograms of lunar surface substance have been put in the vacuum container onboard the ascender before its departure from moon. Photo: CNSA</p><br>
<center><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-03/c7fbc8a5-3e47-45d4-8af0-d0a30c11b8bd.jpeg"></center>
<p>Live image of ascender’s taking off from the lander. Photo: CNSA</p><p>The Chinese national flag shines an even brighter red from moon, and from now on it will be a grand reminder for stargazers from all over the world of the excitement and inspiration we felt from Apollo missions more than half a century ago.</p><p>Having packed samples of soil and rocks from the Earth's only natural satellite within 19 hours after its smooth soft landing, the ascender of the Chinese spacecraft using the lander as a launch pad, took off from the moon surface, according to the China National Space Administration Thursday evening.</p><p>The Chinese space agency said in a statement the CNSA sent to the Global Times on Thursday evening, the Chang'e-5 ascender has successfully taken off from the lunar surface with soil and rock samples, and sent to the lunar orbiter some 15 kilometers away with the 3,000-newton thrust engine.&nbsp;</p><p>Right before the lift-off of Chang'e-5's ascender from lunar surface, the lander vehicle of the Chinese spacecraft unfolded the five-star red national flag, a genuine one made from fabrics, marking a first in the country's aerospace history.</p><p>The probe's successful launch from the lunar surface, as some observers believe, marks the completion of probably the most challenging step in the mission.</p><center><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-03/4239fa1e-7448-4bb3-aa85-a3f2c1a3bf08.jpeg"></center>
<p>Flags on the moon Infographic: GT</p><p>"This is the first attempt in China's aerospace history to lift off from a celestial body other than Earth," chief editor of Aerospace Knowledge magazine Wang Ya'nan said. "The launch is a major test, in that the vehicle had to rely entirely on automatic maneuvers without any ground command."</p><p>Wang explained to the Global Times that the launch from the moon could not afford any time delay. "If the probe receives a command from the Earth to help it control the separation, altitude and speed, there will be at least one second delay, which will put the process in great danger."</p><center><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-04/dcc27158-a339-47cd-911b-ab2c6000a08c.jpg"></center>
<p>Photo: CNSA</p><p>Another factor that posed a challenge to the lunar takeoff is that the lander-ascender combination might sit on a slope, which would bring uncertainty to the probe's altitude and position. It means that the probe must ensure its own altitude is precise enough to enter the designated orbit through automatic decision-making, according to a statement sent to the Global Times from the China Aerospace Science and Technology Corporation (CASC.)</p><p>Chinese researchers have conducted numerous ground simulations to verify the takeoff, but the particularities of the lunar environment have made the verifications difficult, the CASC said.&nbsp;</p><p>The rendezvous and docking, if successful, could be of great value to other deep-space or even manned missions in the future, the significance of which would be no less than the Apollo mission, once the name card of human lunar exploration activities during the Cold War, Chinese analysts said.</p><p>"It will be a milestone for China's aerospace development," Song Zhongping, an aerospace expert and TV commentator, said, calling it "a foresighted practice that lays a technological foundation for future deep-space explorations."</p><p>It will also verify the viability of manned lunar landing missions, and even the construction of a lunar research base, or Mars missions, he told the Global Times.&nbsp;</p><center><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-03/7efca0cc-975e-491f-8f76-05cb5b7bbfe6.jpg"></center>
<p>Developers work on the flag presentation system miniature. Photo: CASIC<br></p>
<center><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-03/203ca177-8f1f-472d-8d8b-ad8e02436382.jpg"></center>
<p>Developers work on the flag presentation system miniature. Photo: CASIC</p><p>Lunar surface substances the lander vehicle collected by scooping and drilling the landing area in around 19 hours, have been sealed and packed in a vacuum container on board the ascender, CNSA said earlier on Thursday.</p><p>Payloads on board the Chang'e-5 lander vehicle, including its lunar soil composition analytical instrument, are working normally, carrying out planned scientific tasks and providing information support for sampling.</p><p>After taking off from the lunar surface, the ascender will rendezvous and dock with an orbital module which is flying and waiting in orbit at an average altitude of 200 kilometers above the moon. The re-entry capsule will then carry the lunar sample and bring them to a designated site in North China's Inner Mongolia Autonomous Region by mid-December.</p><center><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-04/2c167277-3ccb-4a13-8984-c8fcb52b8d88.jpeg"></center>
<p>Photo:CNSA</p><center><strong><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-03/ff29f09a-930e-4d01-8dca-d10968185b02.jpeg"></strong></center>
<p>Chang'e-5 lunar probe carries out automatic sample collecting work on moon surface. Photo: CNSA</p><p><strong>Flag mission accomplished&nbsp;&nbsp;<br></strong><br>More stylish than previous Chang'e landing missions, the lander of Chang'e-5 displayed the five-star red national flag, made of genuine fabric, on the moon.&nbsp;</p><p>The Chinese national flag made its moon debut in December 2013 during the country's first lunar landing mission of Chang'e-3, and it was recorded in pictures from the spacecraft's lander and its rover Yutu-1 took for each other.</p><p>Chang'e-4 lander and rover Yutu-2 brought China's national flag to the dark side of the moon, as the Chinese spacecraft made a historic landing in the unvisited region in January 2019.</p><p>The flags that Chang'e-3 and -4 carried were in the form of the craft's coatings, rather than an actual flag. Chinese space technological development has allowed it to take a step forward in the Chang'e-5 mission, the third consecutive safe soft landing on the moon in seven years.&nbsp;</p><p>The Chang'e-5 flag presentation system was developed by China Space Sanjiang Group under the State-owned China Aerospace Science and Industry Corporation, better known as the CASIC.</p><p>To ensure a complete and smooth unfolding of the flag, the system adopted a secondary rod-type structure, which is applied in solar panel extending for satellites and other types of spacecraft, CASIC developers told the Global Times on Thursday.</p><center>
</center><p>The system weight has been controlled at around one kilogram, and all connecting parts of the system have been given special protection, such as coldness-resistance measures, to help overcome unfavorable lunar surface conditions, including a drastic temperature difference on the moon ranging from 150 C to minus 150 C, Li Yunfeng, the project leader, said in a statement the CASIC company sent to the Global Times.</p><p>"An ordinary national flag on Earth would not survive the severe lunar environment," so the research team also spent more than a year selecting the proper materials to make sure the eventual flag would be strong enough, survive under extreme coldness and heat and capable of showing the fine colors of the national flag and remain so forever, said Cheng Chang, another leading member of the developer team.</p><p>The national flag, 2,000 millimeters wide and 900 millimeter tall, represents cutting-edge technology, they said.</p><p>How to preserve its original color and shape are the two most crucial questions in designing a national flag that must survive more than 380,000 kilometers away from Earth, under extreme temperatures and radiation during its journey, Wang Ya'nan told the Global Times.&nbsp;</p><p>To get a sense of how difficult the task it is, five of the six flags (except for the one Apollo 11 placed on the moon) brought to the moon in the late 1960s and early 1970s during six US crewed moon landings, have been bleached white due to decades-long solar radiation, although they are reportedly still standing and casting shadows.</p><p>Many reports say the Apollo 11 flag was blown over by the exhaust from the ascent engine during lift-off.</p><p>The Soviet Union was the first country to imprint its national symbol on the moon, with a football-sized metal ball, carved with its national flag, full of explosives, smashing to the lunar ground in the Luna 2 mission in 1959.</p><p>Compared to such a method, China has a more advanced approach, which also greatly increased the complexity of the design, Wang noted.</p><center><strong><img src="https://www.globaltimes.cn/Portals/0/attachment/2020/2020-12-01/bb881cd5-4e1a-4040-8160-b364db57d633.jpeg"></strong></center>
<p>A panorama of the moon's surface by the lander-ascender combination of China’s Chang’e-5 probe after its smooth moon landing on Tue Photo: CNSA</p><p><strong>Iconic inspiration</strong></p><p>The Chinese flag that Chang'e-5 displayed officially became the first and only fabric national flag that has ever been placed on the moon in the 21st century, which reminds many of the classic footage of an American national flag planted by Neil Armstrong in the Apollo 11 lunar mission more than five decades ago, observers said.</p><p>And they hailed that as the fresh and new icon of human's lunar exploration, the Chinese national flag would inspire today's mankind, just as Apollo 11 did, encourage and celebrate generations to make an endeavor to space.&nbsp;</p><p>Displaying a national flag on a celestial body represents the comprehensive strength and technological advancement of the country, Song noted.&nbsp;</p><p>&nbsp;"Yesterday's memory is still fresh and clear, when the US astronauts stepped outside their cabins and planted the first flag in human history, an American national flag, on the moon in 1969," Song Zhongping recalled. "But China is about to showcase our own national flag as well, which I believe is a recognition of the achievements and breakthroughs that we have made, which will be the most valuable thing."</p><p>Some readers have left comments under images and video of the Chang'e-5 landing published on the Global Times twitter account in recent days, saying they would not be convinced and acknowledge China's achievements until the lander takes an actual photo of the American flag planted by the previous Apollo mission.&nbsp;</p><p>"Is it an original video, or a TikTok post taken in the Gobi desert," one Twitter user wrote. "Where is the lunar dust while landing," another asked.</p><p>The landing was closely followed by space agencies from all over the world, and the European Space Agency, Russia's Roscosmos and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.globaltimes.cn/content/1208931.shtml">https://www.globaltimes.cn/content/1208931.shtml</a></em></p>]]>
            </description>
            <link>https://www.globaltimes.cn/content/1208931.shtml</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300640</guid>
            <pubDate>Fri, 04 Dec 2020 09:48:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How We Built It: Spotify Lite, One Year Later]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300603">thread link</a>) | @imartin2k
<br/>
December 4, 2020 | https://engineering.atspotify.com/2020/12/03/how-we-built-it-spotify-lite-one-year-later/ | <a href="https://web.archive.org/web/*/https://engineering.atspotify.com/2020/12/03/how-we-built-it-spotify-lite-one-year-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!-- post title -->
        

        <div>
            <p><img src="https://engineering.atspotify.com/wp-content/themes/theme-spotify/images/icon.png" alt=""></p><p><span>December 3, 2020</span>
                <span>
                    Published by Erik Ghonyan (Senior Engineer), Slava Savitskiy (Senior Engineer), and Tommy Tynjä (Engineering Manager)                </span>
            </p>
        </div>
        <!-- post details -->
        <p><a href="https://engineering.atspotify.com/2020/12/03/how-we-built-it-spotify-lite-one-year-later/" title="How We Built It: Spotify Lite, One Year Later">
                        <img src="https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_B.png" alt="" loading="lazy" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_B.png 2105w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_B-250x126.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_B-700x352.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_B-768x386.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_B-1536x772.png 1536w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_B-2048x1029.png 2048w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_B-120x60.png 120w" sizes="(max-width: 2105px) 100vw, 2105px" data-image-size="post-thumbnail" data-stateless-media-bucket="rnd-atspotify" data-stateless-media-name="sites/2/2020/12/Spotify-Lite_B.png">                    </a></p>

        <!-- /post title -->

        
<p>What if, for some users, the very best Spotify is a little less Spotify? Spotify Lite started as an experiment that had to be proven, both from a technical and a product-market fit perspective. In 2017, we found that a significant portion of registrations in some of our fastest-growing markets were happening on Android devices much older than what we were used to seeing in North American and European markets. Because of storage constraints, many of our potential users couldn’t install Spotify, and the ones that could weren’t getting the full “Spotify experience”.</p>



<p>Our mission was clear: we needed to make Spotify accessible to users with constrained resources, i.e., unreliable networks or phones with limited storage, memory, and low-resolution screens. Now we needed a team.</p>



<h2>A flexible, Lite team</h2>



<p>The main Spotify Music Android client is divided into multiple features, all owned by separate teams. But for Spotify Lite, we formed a single, autonomous team to fully own the entire process of designing, developing, and releasing the app. This allowed us to roll out an MVP product in record time.</p>



<p>Before building the new app, the Spotify Lite team — a cross-functional mix of insights, design, product, and engineering — travelled to a number of locations where Lite would be available in order to experience the network and device constraints firsthand. It was absolutely critical to design Spotify Lite with our users in mind, and to experiment and iterate on the streaming experience for cases when devices have poor connectivity or are completely offline. Only then were we able to come up with an optimal, performant solution.</p>



<p>It should be noted that we wouldn’t have achieved success had it not been for the existing tooling that we were able to reuse — tools for enabling recommendations, playback, search, browsing, and instrumentation. We were building on all the work, experience, and knowledge that came before us, giving us the ability to focus on finding solutions for our users.</p>



<h2>Spotify Lite: Spotify’s first separate app</h2>



<p>Creating a more performant and smaller version of the Spotify app proved to be more challenging than we liked, as the codebase hadn’t been modularized. With these challenges in mind, we decided to build a new separate app from scratch, giving us the ability to quickly iterate, obtain feedback, and innovate freely.</p>



<p>Spotify Lite was initially built on an entirely different playback stack than the regular Android app. This allowed Lite to be as small as possible, with minimal memory and network data usage. Having a separate app enabled us to test new performance ideas and to gain insights, such as understanding how application size impacts the new user funnel. We no longer use the initial playback stack, and have evolved towards a tailored setup that guarantees stability and playback quality on unreliable networks.</p>



<p>Building Lite was a lot like packing a backpack for your travels. With limited space, you have to be selective in what you bring. Only the most crucial and necessary components were carried forward.</p>



<h2>A balancing act</h2>



<p>Shrinking the original Spotify app to create Spotify Lite brought up two crucial questions: What key elements of the original Spotify should remain intact to ensure listeners still get the “Spotify experience”? And what sacrifices do we need to make to ensure Spotify Lite does, in fact, remain light?&nbsp;</p>



<p>In answering the first question, we knew that keeping the brand look and feel was absolutely critical to giving listeners a Spotify they could recognize. So, we used the same design philosophy as the original Spotify Android app. However, given a range of constraints (smaller screens, quick/performant interactions), we had to adapt some of our design choices. For example, information density has to be reviewed with smaller screen sizes and lower resolutions in mind, as well as whether information is still readable on a broken or scratched screen (these phones have been around for a while!). We’ve recently added our heuristics for how to design for these constraints to the overall design strategy so that this is kept in mind for other apps and surfaces, as well.</p>



<figure><img loading="lazy" width="700" height="444" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_Iphone-Mockups-01-700x444.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_Iphone-Mockups-01-700x444.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_Iphone-Mockups-01-250x159.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_Iphone-Mockups-01-768x487.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_Iphone-Mockups-01-1536x975.png 1536w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_Iphone-Mockups-01-2048x1300.png 2048w, https://storage.googleapis.com/rnd-atspotify/sites/2/2020/12/Spotify-Lite_Iphone-Mockups-01-120x76.png 120w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<p>Along with streamlining the design, we also had to shrink things down under the hood. The team put a lot of work into implementing all the known techniques for binary size reduction, as well as making tradeoffs when selecting features. As the app includes a native shared library for playback, we have experimented with many compiler and linker flags to prioritize a small app size. This includes, for instance, switching to the <em>lld</em> linker, employing link time code optimizations, and disabling certain language features like RTTI.&nbsp;</p>



<p>On the Android side, it was the use of App Bundles for application publishing, optimizing our R8 shrinking, carefully choosing dependency libraries, and stripping unused translations. We made an effort to reduce the install size, too. We store the shared library unpacked in the APK without copying it to the install folder, and allow users to store both the app and its cache and downloads separately on the SD card.</p>



<p>After the initial larger gains, it became harder and harder to reduce the app size. It was a constant balance between keeping it small while adding additional requested features. Along with monitoring the app download and install sizes in the Google Play Store, we added checks to our continuous delivery pipelines to prevent size bloat.</p>



<h2>Lite is different</h2>



<p>Because Lite was a brand-new concept, some of our work went beyond the app itself, leading to improvements to Spotify systems that other teams could benefit from, too.</p>



<p>Before Lite, developers could safely assume there was only one Spotify app for any given platform — the Android platform and the Android app were considered one and the same. Backend services — including those providing application views and deciding which features are enabled — were built with that assumption in mind. Some of these assumptions cascaded through many different parts of our internal systems.&nbsp;</p>



<p>When we added Lite to the mix, developers needed to know exactly which app a user was using, not just what platform they were on. We generalized that issue beyond our own app and built ways to identify all the apps in the Spotify ecosystem. That work paid off again each time anyone introduced a new Spotify app to the Android platform, including our sister apps <a rel="noreferrer noopener" href="https://www.spotify.com/us/kids/?utm_source=us-en_brand_contextual_text&amp;utm_medium=paidsearch&amp;utm_campaign=alwayson_ucanz_us_premiumbusiness_kids_brand+contextual-desktop+text+exact+us-en+google&amp;gclid=CjwKCAiA8Jf-BRB-EiwAWDtEGnamKsxw1Yx_w3KgzFDyJ1g4NKVvIUkc9jRA8fBFdlHCkR8pD4iHmBoCMLAQAvD_BwE&amp;gclsrc=aw.ds" target="_blank">Spotify Kids</a>, <a rel="noreferrer noopener" href="https://www.spotify.com/us/stations/" target="_blank">Spotify Stations</a>, and <a href="https://spotify-everywhere.com/collections/car-audio/products/polestar" target="_blank" rel="noreferrer noopener">Android Automotive</a>.</p>



<p>We also had to redesign parts of Spotify’s playback library with Lite constraints in mind — taking into account smaller download and installation sizes, memory usage, and the reduced feature set. Similar considerations have been applied to Spotify’s music and image transcoding services.</p>



<h2>Making Lite a big deal</h2>



<p>Our ambition is to be the best-in-class Lite app. We are constantly modifying and updating the app to adapt to our users and their ever-evolving needs. As we’ve seen positive adoption of Spotify Lite since launch, we’ve invested in performance improvements, quality, and resilience. We recently rolled out an overhaul of our client architecture to cater to our growing user base and to reduce playback latencies.</p>



<p>The birth of Spotify Lite has given us flexible solutions that our other apps have benefited from. One such example is our backend service that scales down images to use less network traffic. Another is the support for App Bundles, which has allowed us to reduce the app size significantly so that users only download the assets needed for their particular device. Creating a separate app was a first for our build system — one that laid the groundwork for building native dependencies, sharing code components, and setting up crash and ANR reporting for tracking app quality.</p>



<p>We are continuing our work to lower the barrier for people to access Spotify. We have our backlog full of ideas and performance improvements we want to keep investing in, not only for Lite but also for our other apps to benefit from.</p>
        <br>

        
        

        

            </div></div>]]>
            </description>
            <link>https://engineering.atspotify.com/2020/12/03/how-we-built-it-spotify-lite-one-year-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300603</guid>
            <pubDate>Fri, 04 Dec 2020 09:41:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made 24 high-quality Covid illustrations. Free for commercial and personal use]]>
            </title>
            <description>
<![CDATA[
Score 317 | Comments 116 (<a href="https://news.ycombinator.com/item?id=25300594">thread link</a>) | @andyydao
<br/>
December 4, 2020 | https://www.pixeltrue.com/frontliner-heroes | <a href="https://web.archive.org/web/*/https://www.pixeltrue.com/frontliner-heroes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
<div data-collapse="small" data-animation="default" data-duration="400" role="banner"><div data-w-id="829bd4f8-a52c-9bed-f351-1f1c429ebfb2"><p><a href="#" id="w-node-1f1c429ebfb3-a3ea6df0"><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859794cc27d27_COVID%20Logo.svg" loading="lazy" alt=""></a></p><div id="w-node-1f1c429ebfb6-a3ea6df0"><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%20no%20background.png" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 1439px) 20px, (max-width: 1919px) 25px, 30px" srcset="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-500.png 500w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-800.png 800w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-1080.png 1080w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%20no%20background.png 1214w" alt=""></p></div></div></div><div><div data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c1b"><p data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c1c">Frontliner Heroes</p><p>24 high-quality Covid illustrations. Free for commercial and personal use.</p></div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b2c6728188179a7570d_Hero%20Illustration.svg" loading="eager" width="462" data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c20" alt=""><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b2c672818d125a7570c_Background.svg" loading="lazy" data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c21" alt=""></p></div><div><div><div><div><p>Frontliner Heroes comes with exciting scenes that are commonly used to stop the spread of COVID. In addition, we'll be continually adding new illustration to this pack!</p></div></div></div></div><div><p><h2>24 Illustrations to fight against COVID!</h2></p></div><div><div><h2>Sample Applications</h2><p>These illustrations are perfect for any type of project. Simply Drag and drop them in and you're ready to go!</p></div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b4456b3fd49b0f42063_Sample%20Applications.svg" loading="eager" alt=""></p></div><div><p><h2>Awesome Features</h2></p><div id="benefits"><div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe9410cacea1ebe4_Group%2084.png" alt=""></p><div><h3>Fully Vector<br></h3><p>All illustrations are fully vector meaning you can enlarge illustrations without quality loss<br></p></div></div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe94105ee6a1ebe8_Group%20174.svg" alt=""></p><div><h3>Customizable<br></h3><p>Easily change illustration scenes to match your brand using common programs like Sketch and Figma.<br></p></div></div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe9410876ca1ebe6_Group%20148.png" alt=""></p><div><h3>Different File Formats<br></h3><p>With our Frontliners pack you'll get access to all source files - this includes SVG, PNG&nbsp;and AI&nbsp;files.<br></p></div></div></div></div></div><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->


<!-- Hotjar Tracking Code for www.pixeltrue.com -->






<!-- Memberstack --> 
 








<meta name="p:domain_verify" content="efd5329f8b1be336c6381d60a312999c">



<!-- Facebook Pixel Code -->


<!-- End Facebook Pixel Code -->


<!-- Global site tag (gtag.js) - Google Analytics -->














</div>]]>
            </description>
            <link>https://www.pixeltrue.com/frontliner-heroes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300594</guid>
            <pubDate>Fri, 04 Dec 2020 09:40:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Functional Testing? Complete Guide with Types, Tools, and Techniques]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25300576">thread link</a>) | @DeviQA
<br/>
December 4, 2020 | https://www.deviqa.com/blog/what-is-functional-testing-complete-guide-with-types-tools-and-techniques/ | <a href="https://web.archive.org/web/*/https://www.deviqa.com/blog/what-is-functional-testing-complete-guide-with-types-tools-and-techniques/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><picture><source srcset="https://www.deviqa.com/static/images/posts/functionaltesting/functional-testing.png?webp" type="image/webp" media="(min-width: 600px)"><img src="https://www.deviqa.com/static/images/posts/functionaltesting/functional-testing.png?webp" alt=""></picture></div></div><p>It is no exaggeration to say that functional testing is the backbone of the whole QA process.</p><p>Functional testing is a type of software testing that checks software for consistency with project requirements. A QA engineer verifies every software function during functional testing, providing corresponding input, and checking if the outcome complies with the specification. It is an extensive and time-intensive type of software testing.</p><p>As a rule, the black-box technique is leveraged for functional testing execution as QA engineers imitate end-users' behavior.</p><p>Features that distinguish functional testing from other types of software testing:</p><div><div><p>Particular focus on a specification. The primary purpose is checking whether an app complies with the specification.</p></div><div><p>Early start. Functional testing must be started as soon as a UI is ready.</p></div><div><p>Functional testing cannot be ad hoc. In the process of functional testing, QA engineers strictly adhere to a testing plan.</p></div><div><p>Functional testing doesn't pay attention to software usability, performance, or stability unless they somehow affect functionality.</p></div></div><h2 id="text-14-4-0">Types of Functional Testing</h2><p><span><img src="https://www.deviqa.com/static/images/posts/functionaltesting/functional-testing-types.png?webp" alt="Functional Testing Tools"></span></p><p>As we have already found out, functional testing refers to software functionality verification. Still, functional testing can be conducted in different ways, depending on the situation and goals. Thus, we can differentiate such types of functional testing:</p><h3 id="text-20-5-0">Smoke Testing</h3><p>Core features testing aimed to check if a new build is stable enough to execute more exhaustive testing.</p><h3 id="text-24-5-0">Sanity Testing</h3><p>A subset of regression testing that checks work of a particular function.</p><h3 id="text-28-5-0">Regression Testing</h3><p>Consistent testing checking if new code modifications haven't affected previously developed functionalities.</p><p>Taking into account its specificity, functional testing can be conducted on all testing levels. In these terms, we can speak about the corresponding types of testing:</p><div><div><p>Unit Testing checks whether every single code unit works properly.</p></div><div><p>Integration Testing checks whether combined app modules work properly.</p></div><div><p>System Testing checks a fully integrated software solution.</p></div><div><p>User Acceptance Testing is final testing executed by a customer or end-users to make sure of proper app work in real-world scenarios and compliance with all requirements.</p></div></div><h2 id="text-39-4-0">Functional Testing Process</h2><p><span><img src="https://www.deviqa.com/static/images/posts/functionaltesting/functional-testing-process.png?webp" alt="Functional Testing Tools"></span></p><div><div><div><p><strong>Carefully analyze product documentation</strong></p><p>It is essential to thoroughly study project specifications to understand how an app should work, define main goals, and create a test plan.</p></div></div><div><div><p><strong>Define functionalities that should be tested</strong></p><p>On the ground of project requirements, QA engineers identify software functionalities that should be checked during functional testing.</p></div></div><div><div><p><strong>Identify appropriate test data</strong></p><p>Having studied requirements, QA engineers identify relevant test data.</p></div></div><div><div><p><strong>Create test cases</strong></p><p>QA experts make up test cases, covering functionality that must be tested.</p></div></div><div><div><p><strong>Execute test cases</strong></p><p>Once a UI is ready, a QA engineer starts work on the test execution.</p></div></div><div><div><p><strong>Log bugs</strong></p><p>If any bugs are detected, they must be reported and logged to an issue tracking system.</p></div></div></div><h2 id="text-67-4-0">Functional vs. Non-Functional Testing</h2><p>To help you clearly understand the point of functional testing, we recommend you compare it with non-functional testing.</p><div><table><thead><tr><th>Functional Testing</th><th>Non-Functional Testing</th></tr></thead><tbody><tr><td>Functional tests deal with app functionality.</td><td>Non-functional tests focus on such software characteristics as performance, scalability, and robustness, i.e., system work and behavior.</td></tr><tr><td>Functional testing concentrates on the project requirements.</td><td>Non-functional testing concentrates on users' expectations related to such software characteristics as loading time, stability, robustness, etc.</td></tr><tr><td>Functional testing is of primary importance, and therefore it is performed on a first-priority basis.</td><td>As it is not reasonable to check the general app performance if its core features work improperly, non-functional testing is conducted later.</td></tr><tr><td>Either manual or automated testing techniques can be used for functional testing execution.</td><td>The manual testing technique is not suitable for non-functional testing, which is usually conducted with automation tools.</td></tr></tbody></table></div><h2 id="text-78-4-0">Functional Testing Techniques</h2><p>Functional testing is based on the project specification, which can contain either functional requirements or business scenarios. As a result, two techniques can be applied:</p><div><div><p>Requirement oriented testing is conducted on the ground of functional requirements.</p></div><div><p>Business scenario oriented testing is conducted with due regard for the business process.</p></div></div><h2 id="text-85-4-0">Functional Test Automation</h2><p>Functional testing can be conducted manually. However, when it comes to regression testing of a large-scope project, it makes sense to implement automation. Automated functional testing implies test execution by means of the pre-written scripts with no or little human supervision. Automated functional testing can bring numerous benefits.</p><p>First of all, automated functional tests can be run 24/7 without human involvement. It significantly speeds up the whole testing process. Secondly, automated testing helps avoid human errors and test skipping. Thirdly, they can be rerun whenever it is needed. And finally, it can be cost-effective in the long-term.</p><p>The following aspects must be considered for the effectiveness of functional tests automation:</p><div><div><div><p><strong>Select an appropriate automation tool</strong></p><p>Complete a list of requirements and desired features and pick up an automation tool according to them.</p></div></div><div><div><p><strong>Automate appropriate test cases</strong></p><p>You should thoughtfully select test cases for automation. First of all, you should take into account frequently repeated tests, test cases of high priority, time-consuming test cases, and those that must be run on different browsers and environments.</p></div></div><div><div><p><strong>Frequently run tests</strong></p><p>As soon as a basic suite of automated tests is ready, it is recommended to conduct frequent tests. Thus, you can improve your automation framework and detect more bugs.</p></div></div><div><div><p><strong>Continuously maintain automated scripts</strong></p><p>To avoid test failures and hassle, it is important to continually maintain scripts in accordance with application development and updating.</p></div></div></div><h2 id="text-109-4-0">Functional Testing Tools</h2><p><span><img src="https://www.deviqa.com/static/images/posts/functionaltesting/functional-testing-tools.png?webp" alt="Functional Testing Tools"></span></p><p>To automate functional tests, QA engineers use various tools and frameworks available on the market. These tools considerably simplify testing and provide accurate results.</p><p>These days, there is a vast variety of automation tools. As a rule, QA engineers choose those that comply with project requirements and their own preferences and skills.</p><p>Below you can find the most popular automation tools:</p><h2 id="text-130-4-0">Advantages</h2><p>Functional testing has two main advantages, which are:</p><div><div><p>It imitates end-users' interaction with the software, providing an accurate evaluation of product quality.</p></div><div><p>It ensures high software quality and compliance with both business needs and technical requirements.</p></div></div><h2 id="text-137-4-0">Disadvantages</h2><p>Nothing is perfect in this world, and functional testing also has some weak spots:</p><div><div><p>Very often, functional testing includes redundant tests.</p></div><div><p>There is a chance to omit critical errors.</p></div><div><p>If requirements are unclear or absent, it is challenging to conduct functional testing effectively.</p></div></div><h2 id="text-145-4-0">Conclusion</h2><p>Functional testing is an essential part of the QA process. This testing type ensures product quality, conformance to the requirements, and user satisfaction. It can be rather extensional and time-consuming; therefore, it is reasonable to imply automation when it comes to large scope projects. To make automated functional tests effective, it is crucial to choose a proper automation tool and automate the right test cases. Moreover, continuous script maintenance is your ticket to success in test automation.</p></div></div>]]>
            </description>
            <link>https://www.deviqa.com/blog/what-is-functional-testing-complete-guide-with-types-tools-and-techniques/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300576</guid>
            <pubDate>Fri, 04 Dec 2020 09:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JWT Authentication Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300519">thread link</a>) | @deleteman
<br/>
December 4, 2020 | https://blog.asayer.io/jwt-authentication-best-practices | <a href="https://web.archive.org/web/*/https://blog.asayer.io/jwt-authentication-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="introduction">Introduction</h2><p>Microservices are a great tool when it comes to designing scalable and extensible architectures. They can be used to encapsulate different behaviors or responsibilities in a way that not a lot  of other architecture paradigms can represent.
And if you pair them with a REST-based interface, then you’re not only writing and creating a platform that can grow and scale automatically (given the right infrastructure of course), but you’re also creating a standard and easy-to-use product. </p><p>If you haven’t noticed, I’m a fan of microservices and they’re usually the pattern I go with when designing new architectures, working with Big Data on a day-to-day basis, I tend to require flexibility and scalability out of the box, and they provide that to me.</p><p>The thing not everyone considers when writing microservices though is that they require a way for you to authenticate against them. Both if you’re using a front-end client or just communicating with them through another microservice. And although there are several options out there to solve authentication, I want to cover one of the easiest, yet most powerful, alternative: JSON Web Tokens.</p><h2 id="jwt-based-authentication">JWT-based Authentication</h2><p>The basic thing you need to understand JWT-based authentication is that you’re dealing with an encrypted JSON which we’ll call “token”. This token has all the information required for the back-end system to understand who you are and if, indeed, you are who you say you are.</p><p>The following diagram shows the steps involved in this process:</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/eae220053d72e95dbe803496c8aac458/d2d42/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606545347515_jwt.png" srcset="https://blog.asayer.io/static/eae220053d72e95dbe803496c8aac458/d2d42/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606545347515_jwt.png 545w" sizes="(max-width: 545px) 100vw, 545px" alt="null"></p><p>As you can see, leaving out the user-based steps, you only need 4 steps:</p><ul><li>First, the client application (here I used a front-end app, but you can do the same with another service) will send a sign-in request. This means you’re sending the log-in credentials, just this once.</li><li>Second, the API will validate these credentials and if they’re correct, it’ll generate the token. This is the most important step because the generated token as I mentioned is nothing more than an encrypted JSON object. This allows you to add as much data into it as you want, and you will want to add data because JWT allows you to perform stateless authorization, which I’ll cover in a second.</li><li>Third, with the JWT generated, all you have to do is return it back to the client application. </li><li>Finally, the client app will later send this token on every subsequent request. This token means you’ve been authenticated and can access the secret section of the application.</li></ul><p>That is it, the flow is very straightforward and you don’t need to redirect the user anywhere (I’m looking at you OAuth!).
But let’s get into it with more details, let me break up each step for you to fully understand what is happening behind code.</p><h3 id="the-back-end-side-of-things">The back-end side of things</h3><p>For the back-end, or the microservice if you will, there are two major steps that you need to understand: </p><ol><li>Generating the JSON Web Token. This is key, as I mentioned before because the information you add will be used later (kinda like saying “everything you say will be used against you in a court of law”).</li><li>Validating the token for received requests. I left this part out of the authentication process because this is actually part of the authorization flow. Very similar, and easy to implement, but worth noting as well.</li></ol><p>So, let’s get into it.</p><h4 id="generating-the-jwt">Generating the JWT</h4><p>To generate the token on your back-end microservice, you’ll normally use an existing server-side library. There is no need for you to understand how the token is generated, you just need to understand what goes into it. </p><p>So, what actually goes into the token? You can literally use a JSON object such as:</p><p>And that will be used and sent back to the front-end client, which may be for your business logic it makes sense, maybe your front-end client is waiting for the “foo” key. However, other than the custom attributes you can add, there are also pre-defined options that have a functional meaning for the specific algorithm that the library is using.</p><p>Given I’ll be using the <a href="https://www.npmjs.com/package/jsonwebtoken" target="_blank" rel="noreferrer">jsonwebtoken</a> library for Node.js, the main option you want to take into account is  <code>expiresIn</code>. This is critical to generating a proper JWT because you want the token to have an expiration date. Otherwise, it will last forever, potentially leaving an open vulnerability for someone who can capture it and later use it to impersonate your identity.
For this particular library, this value is expressed in seconds if you provide a number (or you can provide a string using a time unit for something like <code>"``2 days``"</code> to signify 2 days of validity). </p><p>And in turn, the library will add another one called <code>iat</code> which stands for <strong>Issued At</strong> and is a date reference used for expiration checks (i.e that’s the date it’ll take into account when checking if your token is still valid).</p><p>And how do you add all this information into the token then? By signing it:</p><div><pre><p><span>1</span><span>const</span><span> jwt </span><span>=</span><span> </span><span>require</span><span>(</span><span>'jsonwebtoken'</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span>    </span></p><p><span>3</span><span>    </span><span>const</span><span> token </span><span>=</span><span> jwt</span><span>.</span><span>sign</span><span>(</span><span>{</span><span></span></p><p><span>4</span><span>        data</span><span>:</span><span> </span><span>'foobar'</span><span></span></p><p><span>5</span><span>      </span><span>}</span><span>,</span><span> </span><span>'your-secret-key-here'</span><span>,</span><span> </span><span>{</span><span> expiresIn</span><span>:</span><span> </span><span>60</span><span> </span><span>*</span><span> </span><span>60</span><span> </span><span>}</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>6</span><span>       </span></p><p><span>7</span><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>token</span><span>)</span><span></span></p><p><span>8</span><span>    </span></p></pre></div><p>Using the <code>sign</code> method you can create the token, notice that your main object (the one containing the actual information you want to transfer to the front-end) is the first parameter, the second one is the secret key or phrase (you can either pass a secret phrase of your choosing, something that you’ll have to share with your clients) or the content of a PEM key. Either way, the second parameter is used for the encryption algorithm to encode and create the token. Finally, the third attribute contains the configuration options (in our case only the expiration time).</p><p>This token (notice the output on the code above) is then returned as part of the authentication response, for the client to use. </p><h4 id="storing-the-token">Storing the token</h4><p>As an optional step, you can also store the token in your database  to associate it with your user. Normally, you wouldn’t need to do this if all the user information can be stored in your token.
However, if there is more information to manage that you can comfortably store in your token, then keeping an association with your user’s profile inside the database might be a good idea.
In fact, given that looking up this token would be something you’d do on every request, a good alternative is to keep both, the token and the relevant information about your user inside some in-memory storage,  such as <a href="https://redis.io/" target="_blank" rel="noreferrer">Redis</a>. </p><p>The new flow, with storage incorporated and verification support is the following one:</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/fe0c8ead812da347af4abd251f5f0a7e/e0d28/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606580178077_jwt3.png" srcset="https://blog.asayer.io/static/fe0c8ead812da347af4abd251f5f0a7e/e0d28/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606580178077_jwt3.png 689w" sizes="(max-width: 689px) 100vw, 689px" alt="null"></p><p>The taxing interaction here is not the first one (#4) with Redis, but rather the second one (#9) because this one would happen on every request received. We’ll see more about that in a second.</p><h4 id="checking-the-token">Checking the Token</h4><p>Just because we’re getting a token as part of the request, it doesn’t mean such a request is safe, it could very well be a fake one or have an invalid or even expired token. This is why on every request of a secured resource (i.e an endpoint that requires an authenticated user to be accessed, or a section of your website that lives inside the member’s zone) you need to validate the token received.
If you’ve skipped the storage step, then this is a relatively cheap task. All you have to do is use the same server-side framework to validate it:</p><div><pre><p><span>1</span><span>const</span><span> decodedToken </span><span>=</span><span> jwt</span><span>.</span><span>verify</span><span>(</span><span>token</span><span>,</span><span> </span><span>'your-secret-key-here'</span><span>)</span><span></span></p><p><span>2</span><span>    </span><span>console</span><span>.</span><span>log</span><span>(</span><span>decodedToken</span><span>)</span></p></pre></div><p>Notice how I’m using the same “secret phrase”, that’s definitely important because you need to keep using the same one throughout the same project otherwise validation will not work.
An expired token would throw an exception such as:</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/b943837a3499dec9c41a2c4309385182/66f0f/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606627819976_Captura%2Bde%2Bpantalla%2B2020-11-29%2Ba%2Blas%2B6.30.08.png" srcset="https://blog.asayer.io/static/b943837a3499dec9c41a2c4309385182/66f0f/s_1048F41B3AC814B927887FF3C86602B940107555916A37D85A0BACB9135A34EA_1606627819976_Captura%2Bde%2Bpantalla%2B2020-11-29%2Ba%2Blas%2B6.30.08.png 2034w" sizes="(max-width: 2034px) 100vw, 2034px" alt="null"></p><p>And a valid one would just return a valid JSON that you can decode and use however you need.</p><div><pre><p><span>1</span><span>{</span><span> data</span><span>:</span><span> 'foobar'</span><span>,</span><span> iat</span><span>:</span><span> </span><span>1606581962</span><span>,</span><span> exp</span><span>:</span><span> </span><span>1606581963</span><span> </span><span>}</span></p></pre></div><p>Notice the <code>iat</code> and <code>exp</code> parameters added by the library.
An exception in this context would mean you need to invalidate the client’s request and send an invalid response. Normally you would send back a 403 error code since the request is (and the client) is no longer authenticated.</p><h3 id="spa-authentication">SPA authentication</h3><p>Now that we understand what it means for an API (or a microservice if you will) to be protected by a JWT authentication process, I wanted to cover the same process from the POV of a SPA application acting as the client app.
In this case, as I mentioned, you’ll be contacting a service initially by sending your credentials and receiving a token which you’ll have to use on every following request.
The first thing we need to understand though is that session-based authentication is not the same as token-based auth. </p><h4 id="session-based-vs-token-based-authentication">Session-based vs Token-based authentication</h4><p>At a first glance, both of these strategies might seem similar, which is why I wanted to cover the difference.
Essentially both methods work the same way:</p><ol><li>You authenticate against a service.</li><li>That service validates your credentials and sends back a token</li><li>On every following request, you send that token to authenticate yourself with the service.</li></ol><p>So as you can see, the process and the flow of data seem to be the same, but there are some major differences hidden.</p><ul><li>For session-based tokens, the server returns a session key, which references the session data (all data relevant to you as a logged-in user). This data, however, is kept in the memory of the server. This essentially breaks one of the benefits of RESTful APIS: stateless services can scale effortlessly because there is no session information stored in memory. You see, the moment you log-in with a server that keeps session information in memory, every subsequent request sent by you needs to go to that server (because memory can’t be shared between different servers, or at least not easily). If you’re trying to scale up your architecture to handle more traffic, duplicating services to increase your capacity will not be as straightforward as it would be if you had stateless services.</li><li>Session-based auth stores the session key in the browser’s cookies. They send the information as a cookie, and because of that, browsers have a problem when having microservices being served from different domains. This is not a problem for …</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.asayer.io/jwt-authentication-best-practices">https://blog.asayer.io/jwt-authentication-best-practices</a></em></p>]]>
            </description>
            <link>https://blog.asayer.io/jwt-authentication-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300519</guid>
            <pubDate>Fri, 04 Dec 2020 09:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview: Hayabusa2 Capsule Recovery]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300464">thread link</a>) | @sohkamyung
<br/>
December 4, 2020 | https://www.hayabusa2.jaxa.jp/en/topics/20201204_ts3/ | <a href="https://web.archive.org/web/*/https://www.hayabusa2.jaxa.jp/en/topics/20201204_ts3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hayabusa2.jaxa.jp/en/topics/20201204_ts3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300464</guid>
            <pubDate>Fri, 04 Dec 2020 09:16:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I cannot convince Twitter that I am human]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25300445">thread link</a>) | @gregdoesit
<br/>
December 4, 2020 | https://www.swyx.io/proving-our-humanity/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/proving-our-humanity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>If you swung by my Twitter profile in the last week, you probably saw this:</p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/olflh5jfvk5clb15p5z9.png" alt="Alt Text">
</p>
<p>I'm not sure of the precise causes of me being locked out, but I have several abnormal usage factors that probably put me on the high end of Twitter's bot risk system:</p>
<ul>
  <li>I currently live in Singapore but am primarily active during US hours and have a US Phone Number</li>
  <li>I post about 30 tweets a day, probably on the high end of most Twitter users. (30 sounds like a lot, but it's mostly replies, and I maybe post 2-3 actual top tweets a day)</li>
  <li>I switch between and manage three different accounts (<a href="https://twitter.com/Coding_Career">Coding Career</a> and <a href="https://twitter.com/SvelteSociety">Svelte Society</a>) multiple times a day</li>
  <li>As far as I know I have not been reported on, but I do have people that strongly dislike me and they may have used the report button against me. Can't rule that out as a factor.</li>
  <li>Anecdotally <a href="https://twitter.com/b2m9/status/1295748479713779712?s=20">some IPs seem more risky</a> than others - I also use a VPN for work which probably shows me jumping across multiple countries in a single day, which is certainly suspicious on the face of it</li>
  <li>I have also noticed I get verification checks more often when I use scheduled tweets.</li>
</ul>
<p>If you clicked through my scary profile you also saw this:</p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/6xjg8jxiwgidwffvwsnu.png" alt="Alt Text">
</p>
<p>I swear that I haven't mass unfollowed everybody! Most people see this and assume that I used some script to mass unfollow everyone and therefore got flagged as a bot. <strong>The reality is the exact opposite</strong> - I got flagged as a bot, and by default Twitter temporarily removes all follows.</p>
<p>It will be restored once I regain my Twitter account (I've filed a support ticket and am trying to reach out to friends at Twitter for help), but this is the exact user experience I wanted to talk about for this post.</p>
<p>First, a quick detour for a personal anecdote.</p>
<section>
  <h2 id="aside-my-time-as-a-cuban-detainee"><a href="#aside-my-time-as-a-cuban-detainee">Aside: My Time As A Cuban Detainee</a></h2>
  <p>A long time ago I visited Havana with some college friends. Right after landing we headed into a restaurant, all our luggage in tow. After we were done eating, I stood up and turned around - only to find all my luggage gone! Someone had stolen it while we were eating. The restaurant staff of course swore up and down that they had not seen who had taken it.</p>
  <p>Losing all your luggage on day 1 of a weeklong trip sucks, but what is worse is that <strong>my passport was in my luggage</strong>. I needed it to head back to the US at the end of my trip.</p>
  <p>If you've never lost a passport while traveling before, it's a quick trip to bureaucratic hell. If your country has an embassy where you are traveling, you can usually get it reissued in the embassy. But we were in <em>Cuba</em> - and my country had no embassy here. We reported my case to the authorities, but they had no idea what to do. I was an edge case. Worse still, because I said I had come from the US and couldn't produce any papers to prove my identity, I was detained at the police headquarters for questioning on suspicion of being a spy. (<em>I was never really at any risk - being Asian and speaking poor Spanish, I would have made for a pretty lousy spy</em>).</p>
  <p>There was a lot to figure out over the ensuing <em>month</em> of my ordeal - money, lodging, language barriers, administrative hurdles. My family and friends hit the panic button for me and my case reached the ears of both Arlen Specter on the US Senate Foreign Relations Committee and George Yeo, the Singapore Foreign Affairs Minister. We eventually worked it out, but every night for 4 weeks I would wander up and down <a href="https://en.wikipedia.org/wiki/Malec%C3%B3n,_Havana">the Malecón</a>, listening to the crashing waves, not knowing when I could ever leave the country. If I could swim <a href="https://en.wikipedia.org/wiki/Southernmost_point_buoy">the 90 miles to Key West</a> and <a href="https://en.wikipedia.org/wiki/Wet_feet,_dry_feet_policy">dry my feet</a>, I might theoretically make it back to the US on my own.</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/3i8nh2cgaoj3jlrl9ecm.jpg" alt="Alt Text">
  </p>
  <p>But most of all, I thought a lot about <strong>the humanity of having a piece of paper be more important than the human it represents</strong>. I could be physically standing in front of the immigration officer with a lie detector test on and steadfastly stating all manner of provable personal detail, and they would not let me through unless I had a small piece of paper the size of my hand.</p>
  <p>We do this a lot - passports, voter registration cards, national ID systems, licenses, and insurance proofs - mostly because some humans are untrustworthy and try to exploit the system.</p>
  <p>But we often fail to design for people who are innocent and simply don't fit the system in some way.</p>
</section>
<section>
  <h2 id="the-consequences-of-not-being-provably-human"><a href="#the-consequences-of-not-being-provably-human">The Consequences of Not Being Provably Human</a></h2>
  <p>Twitter has a way in which they expect you to verify you are human - you should get a call or text message with a code, that you then enter to prove humanity. This is what I normally get (about once every 1-2 months), and I can receive text messages from Twitter, so I can usually prove humanity with no issue.</p>
  <p>This time, for some reason, I am on a code path that doesn't offer a text message option, and Twitter somehow doesn't make international US number calls, leading to this infinite loop that I think is a bug:</p>
  
  <p>As a result of this unfortunate design:</p>
  <ul>
    <li>My friends think I mass unfollowed them, because Twitter temporarily reduced my follow count to 0</li>
    <li>People who DM me think I am ignoring them, because Twitter doesn't inform them that I am currently locked out</li>
    <li>None of my past tweets show up at all in <a href="https://twitter.com/search?q=from%3Aswyx&amp;src=typed_query">Twitter search</a>, which is problematic because I <a href="https://twitter.com/swyx/status/1245281982797373441?lang=en">use Twitter as a Second Brain</a>. If you read any of my blogposts, you will see that the rich link density of my references mainly come from taking notes in public over an extended period of time.</li>
    <li>I was unable to engage in the normal personal and professional activity I would do during Black Friday and AWS Re:invent</li>
  </ul>
  <p>I've filed a support ticket with Twitter, but you can imagine that support for a 330 million user service isn't very responsive. People who have been through this tell me the only way to resolve it is to hit up a Twitter employee to get past the masses of unrelated and less urgent support issues.</p>
</section>
<section>
  <h2 id="humans-proving-humanity-to-machines"><a href="#humans-proving-humanity-to-machines">Humans Proving Humanity To Machines</a></h2>
  <p>In the grand scheme of things, I know this is minor. I've actually taken it as a welcome social media detox, which I usually take voluntarily in December anyways. But when it's not on my terms, I lose the ability to manage the personal and professional relationships I've painstakingly built up over the past 3-4 years.</p>
  <p>Above all, I think there's an <em>indignity</em> in humans having to prove to machines that they are human, and the error resolution mechanism is to send a ticket to a faceless and unresponsive support email, and the only real way to get around it is again to re-establish human connections.</p>
  <p>I think more about all the other ways that we as software developers and designers fail to honor the dignity of humans trying to interact with the systems we create.</p>
  <p><a href="https://www.theverge.com/2019/2/1/18205610/google-captcha-ai-robot-human-difficult-artificial-intelligence">In 2014</a>, Google pitted one of its machine learning algorithms against humans in solving the most distorted text CAPTCHAs: the computer got the test right 99.8 percent of the time, while the humans got a mere 33 percent. It doesn't impact everyone equally - if you as a sighted, able bodied user struggle with CAPTCHAs, imagine the elderly or differently abled. Most services do not offer any alternative resolution when you cannot prove you are human. This is a problem when your service has essentially killed off the offline alternative and is essential for their basic needs.</p>
  <p>In Eric Meyer's <a href="https://meyerweb.com/eric/thoughts/2016/01/25/designing-for-crisis-design-for-real-life/">Designing for Crisis</a>, he describes how an inaccessible hospital website nearly risked the life of his daughter. I shudder to think how it might be made worse by perfectly well meaning software engineers who don't think about the humanity of the failure path. Imagine if you had to log in to something to save your child's life, and it presented you with a CAPTCHA you couldn't pass.</p>
  <hr>
  <p><em>Update: <a href="https://twitter.com/swyx/status/1334901024201445376?s=20">I've been helped</a>, thank you for reaching out. In case you were wondering what it looks like from Twitter's side, this is what they emailed:</em></p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/wgdlczuq2k5ay8uhql2q.png" alt="Alt Text">
  </p>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/proving-our-humanity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300445</guid>
            <pubDate>Fri, 04 Dec 2020 09:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Elixir]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300420">thread link</a>) | @bendiksolheim
<br/>
December 4, 2020 | https://functional.christmas/2020/4 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today I want to give you an introduction to the programming language Elixir, some of its features and why you might want to check it out!</p>
</section><article><section><h2>The basics</h2>
<p>First things first: Elixir is a concurrent functional language that runs on the Erlang VM. It is inspired by many different languages where Ruby and Erlang are most obvious ones based on the syntax.</p>
<p>Elixir is a <a href="https://thinkingelixir.com/elixir-in-the-type-system-quadrant/">strong, dynamically typed language</a>. This puts it in the same category as Ruby and Python and it has optional functionality for compile time type checking as well.Elixirs data structures are immutable, but variables can be reassigned/rebound. <sup><sup id="fnref-2"><a href="#fn-2">2</a></sup></sup> This was a bit strange for me in that I got started with FP through Elm where there are no variables, just constants.</p>
<p>Elixir inherits a lot its data structures and related syntax from Erlang which in many ways is its biggest influence. <a href="https://elixir-lang.org/blog/2013/08/08/elixir-design-goals/">Elixir Design Goals</a> describes the relation to Erlang like this:</p>
<blockquote>
<p>Elixir is meant to be compatible with the Erlang VM and the existing ecosystem. When we talk about Erlang, we can break it into three parts:</p>
<ul>
<li>A functional programming language, called Erlang</li>
<li>A set of design principles, called OTP (Open Telecom Plaform)</li>
<li>The Erlang Virtual Machine, referred to as EVM or BEAM</li>
</ul>
<p>Elixir runs in the same virtual machine and is compatible with OTP. Not only that, all the tools and libraries available in the Erlang ecosystem are also available in Elixir, simply because there is no conversion cost from calling Erlang from Elixir and vice-versa.</p>
</blockquote>
<p>This is a great feature of Elixir that we will talk more about later.</p>
<p>As for other inspirations Elixir has docstrings from Python, polymorphism and protocols from Clojure, macros and meta-programming from different Lisps, just to name a few. <sup><sup id="fnref-1"><a href="#fn-1">1</a></sup></sup></p>
<h3>Hello World!</h3>
<p>As I said, Elixir is a concurrent functional programming language. For the functional part it means that Elixir mainly uses functions and modules for code structure and has other features that are associated with functional languages. We'll talk about the concurrent part later. </p>
<p>A hello world example in Elixir might look something like this:</p>
<div data-language="elixir"><pre><code><span>defmodule</span> HelloWorld
  <span>def</span> hello_world <span>do</span>
    IO<span>.</span>puts<span>(</span><span>"Hello, World!"</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>Here we define a module with a function that simply writes "Hello, World!" to the console.</p>
<h2>Killer applications</h2>
<p>Many programming languages has <a href="https://en.wikipedia.org/wiki/Killer_application">"killer apps"</a>; libraries, frameworks and use cases, that in themself are enough to justify the transition to the language or try it out. For Ruby it was the web framework Ruby on Rails and in many ways Elixir has its own Rails: Phoenix.</p>
<h3>Phoenix web framework</h3>
<p><a href="https://www.phoenixframework.org/">Phoenix</a> is inspired by Rails (the team originally behind Elixir was previously a Ruby shop) and was an early addition to the Elixir community. The creators of Phoenix has learned from years of Rails development and made their own opinions in addition to the natural changes needed when going from an object oriented language to a functional language.
Compared to Rails Phoenix has with the help of the Erlang VM great performance. Some of you might have heard about Phoenix' amazing <a href="https://www.phoenixframework.org/blog/the-road-to-2-million-websocket-connections">2 million simultaneous web sockets</a> benchmark!</p>
<h3>The Nerves Project</h3>
<p>Another interesting project in the Elixir ecosystem is the embedded/IoT project <a href="https://www.nerves-project.org/">Nerves</a>. Nerves makes it possible to use Elixir code to create embedded system where previously you would have had to use a low level language like C. This does not stop you from bringing your own code (like C, C++, Python, Rust, and more) while using Nerves as a platform for your IoT project.
The project web site says:</p>
<blockquote>
<p>Nerves is a complete IoT platform and infrastructure for you to build and deploy maintainable embedded systems.</p>
</blockquote>
<h2>The BEAM and OTP</h2>
<p>When talking about the advantages of Elixir it is hard to not talk about the advantages of Erlang and its virtual machine, the BEAM (Bogdan's Erlang Abstract Machine). It is in many ways the biggest selling point for Elixir. We are now talking about the concurrent part of Elixir. Erlang and the BEAM has shown its resiliency over many years, exemplified in giving Ericsson 9 nines (99.9999999%) availability in their AXD301 switch.<sup><sup id="fnref-3"><a href="#fn-3">3</a></sup></sup> It is known for its "let it break" philosophy and self-healing properties and by being compatible with Erlang, Elixir inherits a lot of these traits.</p>
<p>Elixirs creator, Jose Valim, attributes one of the motivational factors for the creation of Elixir to the rise of multi-core CPUs and the need to utilize these. Ruby and other languages with a global interperter lock (GIL) limits this, but the Erlang VM and the tools and design prinsiples of OTP have proven to be a great choice for creating concurrent, performant and resilient applications.</p>
<h3>Everything is a process</h3>
<p>Everything in the BEAM is a process. These are not OS processes, but lightweight processes which can be cheaply spawned and killed. In his PhD thesis the co-inventor of Erlang, Joe Armstrong, summarized Erlangs principles regarding processes:</p>
<blockquote>
<ul>
<li>Everything is a process.</li>
<li>Processes are strongly isolated.</li>
<li>Process creation and destruction is a lightweight operation.</li>
<li>Message passing is the only way for processes to interact.</li>
<li>Processes have unique names.</li>
<li>If you know the name of a process you can send it a message.</li>
<li>Processes share no resources.</li>
<li>Error handling is non-local.</li>
<li>Processes do what they are supposed to do or fail.</li>
</ul>
</blockquote>
<p>Sidenote: For some this may sound vaguely familiar. Some object oriented languages has had similar principles, but instead of processes they are applied to objects. Smalltalk is reported to be one of the inspirations to Erlang and it is fun to think about Erlang being a functional language but still be more object oriented than some object oriented languages. This is of course not the case as the definition of OOP has changed over time and Erlang is a functional language, but it is fun to ponder the similarities. 😄 Back to the main story! 😅</p>
<p>These unique principles for processes where they communicate through messages lays a great foundation for creating concurrent application, but there is one more piece to the puzzle: OTP.</p>
<h3>OTP - The Open Telecom Platform</h3>
<p>As with so many other parts of this article OTP is a big topic and could be a separate article, but I'll try make it short! Today the name is a bit strange but it was created by Ericsson for their telephone switches in the 80s and 90s so in that context in makes more sense.</p>
<p>OTP is an integral part of many Erlang applications. In essence OTP is a set of design principles and standards including tools and libraries to make it easier to create applications that adheres to them.<sup><sup id="fnref-4"><a href="#fn-4">4</a></sup></sup> </p>
<p>Since Elixir is compatible with OTP we can leverage these principles and technologies that has been battle tested in high-pressure and critical applications for decades!</p>
<h2>The take-away</h2>
<p>Luckily you don't need to understand or know much about Erlang, BEAM and OTP.
Without deep knowledge of these topics you can still reap the benefits of highly performing web applications and resilient IoT applications. It would certainly help but it is not a prerequisite. This is the great thing about Elixir: it is an approachable language with battle tested underpinnings! 💪</p>
<p>It might not be your idea of a perfect language. It is not mine either, but that does not stop me from using the great tools at my disposal. If you are all into Haskell or the likes it might not be something you would use and that is OK. Whatever your preferences are you might now know a little more about Elixir and Erlang and some more knowledge is always a good thing. 😄</p>
<p>If you would like to check Elixir out I recommend checking out <a href="https://elixir-lang.org/getting-started/introduction.html">the official Getting started guide</a> or the interactive guide <a href="https://try-elixir.herokuapp.com/">Try Elixir</a> and then trying out a project with Phoenix or Nerves. Hands-on experience is always better than something you read on the internet! 🤓</p>
<p>Psst! By the way: there are other languages that run on the BEAM. <a href="https://lfe.io/">Lisp variants</a> and lately some work on <a href="https://gleam.run/">strong statically compiled ML-like languges</a> if you are into that!</p>
</section></article></div>]]>
            </description>
            <link>https://functional.christmas/2020/4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300420</guid>
            <pubDate>Fri, 04 Dec 2020 09:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-host your fonts for better performance]]>
            </title>
            <description>
<![CDATA[
Score 592 | Comments 398 (<a href="https://news.ycombinator.com/item?id=25300396">thread link</a>) | @zwacky
<br/>
December 4, 2020 | https://wicki.io/posts/2020-11-goodbye-google-fonts/ | <a href="https://web.archive.org/web/*/https://wicki.io/posts/2020-11-goodbye-google-fonts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div>
  <div>
    <div>
      
      <p>
        
          November 30, 2020
        
      </p>

      <figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/goodbye-google-fonts.jpg" alt="Google Fonts"> 
</figure>

<p>I’ve used Google Fonts in prototypes and in 10M+ MAU products. It’s incredibly easy to get started with and provides an amazing font discovery. That’s also why it’s currently still used on over <a href="https://trends.builtwith.com/websitelist/Google-Font-API">42M websites</a>!</p>
<p>This convenience has its price: Performance. Many <a href="https://blog.cloudflare.com/fast-google-fonts-with-cloudflare-workers/">have</a> <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">already</a> <a href="https://www.keycdn.com/blog/web-font-performance#disadvantages-of-web-fonts">pointed</a> <a href="https://blog.logrocket.com/self-hosted-fonts-vs-google-fonts-api/">out</a> the cost of multiple requests. If you want the remaining speed boost, then you’re best off downloading your used Google Fonts and self-host them.</p>
<p>This is nothing new. In fact it’s been advocated already for years. Even Google themselves <a href="https://www.youtube.com/watch?v=Mv-l3-tJgGk&amp;feature=youtu.be&amp;t=24m58s">advised others to self-host fonts</a> in their Google I/O ‘18 talk about web performance.</p>
<h2 id="self-hosting-fonts-vs-google-fonts">Self-hosting fonts vs Google Fonts</h2>
<p>By nature Google Fonts, even with all its font and CSS optimisations, can’t be faster than self-hosted fonts.</p>
<p>Sia wrote <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">a great post</a> where she compared the performance between Google Fonts and self-hosted fonts without the impact of a CDN.</p>
<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/with-google-fonts.png" alt="Network flow with Google Fonts"> <figcaption>
            <p>Optimised Google Fonts loading with preconnect</p>
        </figcaption>
</figure>

<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/without-google-fonts.png" alt="Network flow with self-hosting fonts"> <figcaption>
            <p>Optimised self-hosting fonts with preload</p>
        </figcaption>
</figure>

<hr>
<h2 id="the-old-performance-argument">The old performance argument</h2>
<p>So if the bottom-line performance is in self-hosting fonts’ favour: What was the argument that convinced us developers that Google Fonts is at least as performing as the self-host approach?</p>
<p>Google Fonts was designed to be distributed on a global CDN and reap the caching benefits from it. Users request fonts via said CDN. Chances are that they have downloaded the font resources at an earlier point already from a different site.</p>
<blockquote>
<p>“[…] Our cross-site caching is designed so that you only need to load a font once, with any website, and we’ll use that same cached font on any other website that uses Google Fonts.”</p>
<p>— <a href="https://fonts.google.com/about">https://fonts.google.com/about</a></p>
</blockquote>
<h2 id="invalidating-the-old-performance-argument">Invalidating the old performance argument</h2>
<p>Since Chrome v86, released October 2020, cross-site resources like fonts can’t be shared on the same CDN anymore. This is due to the partitioned browser cache (Safari has had this for years already).</p>
<p>In <a href="https://developers.google.com/web/updates/2020/10/http-cache-partitioning">this Google post</a> they explain what the partitioned browser cache is. It got only introduced to prevent a possible cross-site tracking mechanism.</p>
<h2 id="cache-partitioning-in-other-browsers">Cache partitioning in other browsers</h2>
<p>Safari really cares about privacy. It circumvented this very cross-site tracking attack for years already. Then finally comes Chrome. Other browsers that are based off Chromium, still need to signal or implement the feature.</p>
<ul>
<li>✅ <strong>Chrome</strong>: since v86 (October 2020)</li>
<li>✅ <strong>Safari</strong>: since 2013</li>
<li>🚫 <strong>Firefox</strong>: planning to implement</li>
<li>🚫 <strong>Edge</strong>: most likely soon</li>
<li>🚫 <strong>Opera</strong>: most likely soon</li>
<li>🚫 <strong>Brave</strong>: most likely soon</li>
<li>🚫 <strong>Vivaldi</strong>: most likely soon</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Google Fonts resources will be redownloaded for every website, regardless it being cached on the CDN. Self-host your fonts for better performance. The old performance argument is not valid anymore.</p>
<p>Thanks for checking this post out!</p>


      
      <hr><div>
  <p><img src="https://wicki.io/images/me_huc890d15b6e9f2ce8978e9aa27127dd5e_67203_350x0_resize_q75_box.jpg" alt="Simon Wicki">
    
  </p>

  <div>
    <div>
      <p>
        <strong>Simon Wicki</strong> is a Freelance Frontend Developer in
				Berlin. Passionate and fluent in Vue, Angular, React and Ionic. Interested in 
				Tech, frontend &amp; non-fiction books
      </p>
      <p>
        <a href="https://twitter.com/zwacky" onclick="ga('send', 'event', 'clickout', 'bottom_cta', '\/posts\/2020-11-goodbye-google-fonts\/')" target="_blank">
          <img src="https://wicki.io/images/svg/twitter.svg" alt="Twitter" title="Twitter">
          Follow @zwacky
        </a>
      </p>
    </div>
  </div>
</div>

    </div>
  </div>
</div>


        </div></div>]]>
            </description>
            <link>https://wicki.io/posts/2020-11-goodbye-google-fonts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300396</guid>
            <pubDate>Fri, 04 Dec 2020 09:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Neobanks Should Monetize Status Signaling]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300377">thread link</a>) | @julian_digital
<br/>
December 4, 2020 | https://julian.digital/2020/12/03/banking-on | <a href="https://web.archive.org/web/*/https://julian.digital/2020/12/03/banking-on">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 		
<h3>How Neobanks Should Monetize Status Signaling</h3>



<p><span>01</span> Intro</p>



<p>If you’ve been following this blog for a while, you probably know by now that one of my favorite topics to think and write about is “status signaling”.</p>



<p>Signaling explains most of our everyday actions: what clothes we wear, which universities we pick and which religion we subscribe to. Everything has a hidden signaling component with which we communicate our desired tribal affiliation.</p>



<p>In <a href="http://julian.digital/2020/03/28/signaling-as-a-service/">Signaling-as-a-Service</a>, I described the implications signaling has on the monetization of software businesses. For many traditional industries, monetizing the display of status is not a new concept. A Rolex watch, for example, is not better at telling the time than a cheap Casio watch. But a Rolex reveals something about its owners’ wealth and, thus, their status in society. It’s that status message that explains the difference in price.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/equaltime.png"></p><p>Similarly, driving a Prius says something about your views on climate change. A <em>Make America Great Again</em> cap reveals something about your political affiliations. And Nike athletic wear signals a healthy, pro-active lifestyle.</p>



<p>Software is at a crucial disadvantage compared to these physical products because of its intangibility. A fitness app also signals a healthy, pro-active lifestyle, but no one can see it because it only lives on your phone. Everyone can see your Nike gear whenever you wear it in public. Software can’t offer the same benefit. It doesn’t have a signaling distribution channel.</p>



<p>This is why there is no software equivalent of a Rolex watch or a Louis Vuitton handbag. People aren’t willing to spend money on things other people can’t see they spent money on.</p>



<p>But it doesn’t have to be that way. As software is eating the world, the lines between physical and digital products are becoming increasingly blurry. As I have pointed out in my original essay, one way for software companies to solve the signaling distribution problem is to add a physical element to their software product.</p>



<p>In this post I want to explore this idea a little bit further. Specifically, we’ll look at neobanks – and their opportunity to monetize credit card signaling.</p>



<p><span>02</span> Neobanks</p>



<p>In the last couple of years we have witnessed the birth and rise of a new startup vertical: neobanks.</p>



<p>Neobanks differ from traditional banks in two ways:</p>



<p>1) Rather than relying on a physical branch network, the entire banking experience is managed via an app</p>



<p>2) Instead of the <a href="https://www.youtube.com/watch?v=C-q4bEULG64">“how do you do, fellow kids”</a>-cringiness that ad campaigns of traditional banks usually invoke when they try to appeal to a younger audience, neobanks are actually perceived as cool. In fact, many of them feel more like lifestyle brands than banks or tech companies.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/12/1_26qGBSGmB3yaPD7nZJrFIg.gif">



<img src="https://julian.digital/wp-content/uploads/2020/12/lifestylebrand-1.png"></p><p>Interestingly though, neobanks still use one very traditional banking element: physical cards.</p>



<p>At first glance, this might seem counterintuitive. If you are building a mobile-first bank, why not offer virtual cards and let users pay with their phone? Why go through the hassle of producing and shipping physical cards?</p>



<p>The answer is – you guessed it – signaling.</p>



<p>Think about it: Paying for things (offline) is a social activity. It’s an interaction between at least you and a cashier or waiter. But ideally, in a dinner scenario for example, you are surrounded by other people you want to impress: a date, a group of friends, or work colleagues.</p>



<p>This makes the moment you take out your card to pay the bill a great opportunity to make a statement and build social capital.</p>



<p>If you look at neobanks out there today, it’s pretty obvious that signaling is in fact one of the main benefits they offer – and almost the only thing they monetize <span>(apart from interchange, of course)</span>:</p>



<ul><li>The premium subscriptions neobanks offer usually don’t win on features but solely on nicer looking cards. The <a href="https://n26.com/metal">N26</a> or <a href="https://revolut.com/metal">Revolut</a> Metal plans, for example, don’t offer any additional features that <em>really</em> justify the ~€15 / month price tag. They do include a nice looking metal card though – that’s what people pay for.</li><li>Relatedly, it seems like most of the innovation in the industry is happening in card design. The actual banking products are more or less interchangeable, what differs is whether the card comes in <a href="https://www.apple.com/apple-card/">titanium</a>, <a href="https://www.treecard.org/">wood</a>, or <a href="https://twitter.com/cashapp/status/1290694734529400832">glow-in-the-dark yellow</a>.</li><li>You may have noticed that the credit card number has moved from the front to the back of the card. This makes it easier for users to share photos of their cards on social media as an additional signaling distribution channel.</li></ul>



<p><img src="https://julian.digital/wp-content/uploads/2020/11/nocardnumber-1.png"></p><p>Neobanks are popping up like mushrooms after the rain at the moment and it’s unlikely that this trend will end any time soon. Thanks to banking-as-a-service providers, we’ll likely see a lot of non-banking-companies add banking functionalities and cards to their product offering.</p>



<p>There’s an old Twitter joke that every app evolves until it eventually becomes a chat app. The 2020 version of that joke is that every app evolves until it eventually becomes a bank.</p>



<p>When <a href="https://twitter.com/lehrjulian/status/1295024066869567488">I did some research on credit card designs</a> recently, I was surprised by the sheer amount of different neobanks already in existance. And yet, even though almost all of them offer well-designed cards, it’s shocking how similar they all are. It seems like all of them are focusing on the same target audience instead of differentiating their signaling messages.</p>



<p>Let me explain.</p>



<p><span>03</span> In-Groups, Out-Groups and Artificial Scarcity</p>



<p>In every signaling scenario there are two possible target audiences: An in-group and an out-group.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/groups.png"></p><p>The in-group is the tribe you want to join and signal your affiliation to. The out-group is everyone else – people you want to distance yourself from.</p>



<p><a href="https://www.fastcompany.com/90391587/why-we-dont-want-you-and-your-android-green-bubbles-in-our-imessage-chat">iMessage is a great illustration of this</a>: the chat bubble colors clearly indicate who belongs to the in-group (blue = iOS) and who is part of the out-group (green = Android). </p>



<p>It’s important to note that signaling in iMessage is limited to the in-group since these color codes are only visible for iOS users – Android users can’t see who in the group is using which operating system. </p>



<p>Signaling, however, grows stronger the larger the out-group is – as long as the out-group knows about the in-group. This is why luxury car manufacturers deliberately extend their advertising campaigns to people who will never be able to afford their cars: they are increasing the size of the out-group by educating people about the in-group.</p>



<p>At the same time, brands need to control the size of the in-group. The more exclusive the in-group, the higher the signaling strength and, thus, the monetization potential of a customer. </p>



<p>The easiest control mechanism for the size of the in-group is price. If you set the price high enough, few people will be able to afford the product. Ironically, this, in turn, justifies the high price.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/priceloop.png"></p><p>Alternatively, companies create artificial scarcity by setting a hard number on supply. Limited supply creates FOMO and hype which increases the size of the out-group and results in higher social status for members of the in-group. Artificial scarcity explains the price of Bitcoin, Pokémon trading cards and why people spend hours queuing in front of Supreme shops.</p>



<p>The problem with keeping the in-group small is that it also limits the number of potential customers and, thus, overall revenue potential. Companies need to walk a fine line between maximizing the number of customers while simultaneously maximizing the number of people they can (afford to) exclude.</p>



<p><span>04</span> What Neobanks Should Build</p>



<p>The problem with neobanks today is that they all focus on the same in-group. Here are the premium cards of some of the largest European challenger banks – notice any difference?</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/metalcards.png"></p><p>It seems like everyone is trying to become the Apple of Banking – including <a href="https://www.apple.com/apple-card/">Apple itself</a>. The signaling messages are all about displaying economic power.</p>



<p>But we are slowly seeing new banking apps that are focusing on different audiences. For example, there are now a <a href="https://www.tomorrow.one/">handful of</a> <a href="https://blog.gohenry.com/uk/gohenry-news/meet-our-new-biodegradable-eco-card/">“green”</a> <a href="https://www.treecard.org/">neobanks</a> that help users signal environmental altruism. </p>



<p>Or how about <a href="https://www.razer.com/razer-card">this Razer Card</a> targeted at the gamer community?</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/12/environment.png"></p><p>The question for these companies and their investors is whether the in-group is big enough to justify building an entire bank around it. Making the unit economics of a bank work requires a certain amount of users, but as we discussed earlier, the signaling strength decreases as the size of in-group increases.</p>



<p>So how do you solve this problem?<br>By introducing multiple in-groups.</p>



<p>See, the current model looks like this:</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/neogroup01.png"></p><p>(In fact, given how undifferentiated most of the offerings and cards are, there are actually multiple neobanks within the same small in-group bubble.)</p>



<p>But what if one bank would target multiple, different in-groups?</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/10/neogroup02.png"></p><p>For example, what if N26 had dedicated cards for soccer fans, hip-hop enthusiasts and gamers? Instead of focusing on just one signaling audience, their total addressable market would massively increase. </p>



<p>The way they would target these audiences is via brand collaborations. N26 does not have the necessary reputation in any of the above-mentioned areas to build credible signaling messages. It would not be able to build attractive in-groups on its own – but other brands could lend N26 their social capital. </p>



<p>Apple has long worked with <a href="https://www.apple.com/lae/product-red/">RED</a>, IKEA recently <a href="https://www.highsnobiety.com/p/virgil-abloh-ikea-collaboration-best-look/">teamed up with Virgil Abloh</a>, and <a href="https://www.headspace.com/partners/nike-partnerships">Nike partners with Headspace</a>. Why wouldn’t this concept work for neobanks?</p>



<p>What would <strong>N26 x Manchester United</strong> look like? <br>Or <strong>Chime x Supreme</strong>? <br>Or <strong>Revolut x 100 Thieves</strong>?</p>



<p>Because of a bigger target audience overall, individual in-groups could be kept smaller. Cards could be <a href="https://thegeneralist.substack.com/p/scarcity-as-an-api">released as limited edition drops</a> transforming them into collectibles, which would justify a higher price tag per card.</p>



<p>It’s worth noting that different signaling audiences are not mutually exclusive. We don’t just subscribe to a single in-group – our <a href="http://julian.digital/2020/09/25/is-this-real-life/">identities are prismatic</a>. This means that some users might …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://julian.digital/2020/12/03/banking-on">https://julian.digital/2020/12/03/banking-on</a></em></p>]]>
            </description>
            <link>https://julian.digital/2020/12/03/banking-on</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300377</guid>
            <pubDate>Fri, 04 Dec 2020 08:58:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Race to Replace C and C++]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300275">thread link</a>) | @abnercoimbre
<br/>
December 4, 2020 | https://media.handmade-seattle.com/the-race-to-replace-c-and-cpp/ | <a href="https://web.archive.org/web/*/https://media.handmade-seattle.com/the-race-to-replace-c-and-cpp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <article>

                    <header>

                            <div>
                                <p><img src="https://media.handmade-seattle.com/content/images/size/w760h400/2020/11/compiler_podcast.jpg" data-src="/content/images/size/w760h400/2020/11/compiler_podcast.jpg" alt="The Race to Replace C and C++"></p><div>
                                            <p><a href="https://media.handmade-seattle.com/tag/podcasts/" data-id="ctag-podcasts">Podcasts</a>
                                            <a href="https://media.handmade-seattle.com/tag/2020/" data-id="ctag-2020">2020</a>
                                    </p></div>
                            </div>

                        <!-- start: .meta -->
                        <div>
                                <p><a href="https://media.handmade-seattle.com/author/handmade-seattle/" title="Handmade Seattle">                                        
                                        <span></span>
                                    <span>By Handmade Seattle</span>
                                </a>
                            <time datetime="2020-11-27"><svg><use xlink:href="#calendar"></use></svg> November 27, 2020</time></p><a href="#comments"><svg><use xlink:href="#comments-icon"></use></svg> <span data-disqus-url="https://media.handmade-seattle.com/the-race-to-replace-c-and-cpp/" data-disqus-identifier="5fc1d8508d87210039ca74aa">0</span></a>     

                            

                            
                        </div>
                        <!-- end: .meta -->

                        

                    </header>

                <section>

                        <div><figure><iframe src="https://player.vimeo.com/video/484681201?app_id=122963" width="1280" height="720" frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" title="Compiler Podcast - The Race to Replace C and C++"></iframe><figcaption>Aired at Handmade Seattle 2020</figcaption></figure><p>- <a href="https://vimeo.com/handmadeseattle/download/484681201/8c3fec71a9">Download Video</a></p><p>- <a href="https://ziglang.org/">Zig</a>, <a href="https://odin-lang.org/">Odin</a>, <a href="https://twitter.com/machinamentum">Machinamentum</a></p><h3 id="editor-notes">Editor Notes</h3><ul><li>Closed Captioning (CC) Available</li><li>Chapters Menu by <a href="https://miblodelcarpio.co.uk/cinera/">Matt Mascarenhas</a></li><li>There are occasional Discord beeps when the Odin author speaks, for the first 15 minutes or so.</li></ul><hr><figure><img src="https://media.handmade-seattle.com/content/images/2020/09/by-nc-nd.png" alt=""><figcaption><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons</a></figcaption></figure></div>

                    <!-- start: .share-buttons -->
                        
                    <!-- end: .share-buttons -->

                </section>

            </article>
            

                <!-- start: .author -->
                <section id="author">
                    <!--<h3 class="title bordered">About the Author</h3>-->
                    
                    <div>
                        <h4><a href="https://media.handmade-seattle.com/author/handmade-seattle/">Handmade Seattle</a></h4>
                        <p>Seattle's indie conference for systems programmers. We bring you the leading experts on game engines, kernels, drivers, compilers, and more!</p>
                        
                    </div>
                    
                </section>
                <!-- end: .author -->

            <section>
                    <article>
                            
                        <a href="https://media.handmade-seattle.com/you-can-teach-and-old-programmer-new-paradigms/"></a>
                        <p><time datetime="2020-11-25">Nov 25, 2020</time></p>
                        <span><img src="https://media.handmade-seattle.com/assets/images/left-arrow.svg?v=a3f3d72b46" width="15"></span>
                        
                    </article>

                    <article>
                            
                        <a href="https://media.handmade-seattle.com/linux-kernel-adventures/"></a>
                        <p><time datetime="2020-11-27">Nov 27, 2020</time></p>
                        <span><img src="https://media.handmade-seattle.com/assets/images/right-arrow.svg?v=a3f3d72b46" width="15"></span>
                        
                    </article>
                
            </section>

            

            <!-- start: disqus integration -->
            <div id="comments">
                <h3>Comments</h3>
                
            </div>

            
            

            <!-- end: disqus integration -->

            
        </div></div>]]>
            </description>
            <link>https://media.handmade-seattle.com/the-race-to-replace-c-and-cpp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300275</guid>
            <pubDate>Fri, 04 Dec 2020 08:34:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using MySQL with Node and Express (2015)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300251">thread link</a>) | @Fiveplus
<br/>
December 4, 2020 | https://www.terlici.com/2015/08/13/mysql-node-express.html | <a href="https://web.archive.org/web/*/https://www.terlici.com/2015/08/13/mysql-node-express.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

<section>
<time datetime="2015-08-13" pubdate=""></time>


<article><p>Everybody is talking about NoSQL, especially in the NodeJS world. Lot’s of people
even associate Node with Mongo and other NoSQL databases.</p>
<p>However, the world doesn’t end there. SQL databases like MySQL, PostgreSQL, Oracle
or even SQL Server are battle tested in all kind of scenarios. Companies both
large and small use them to run their mission critical systems.</p>
<p>Moreover, if you are already comfortable with MySQL, Postrgres or any other
there is not reason to switch to another database.</p>
<p>Often, it’s better to use what you know and what you love, instead of changing to
another technology for promises that might never materialize.</p>
<p>Actually, even though the last few years people talk mostly about NoSQL, most of
the web apps that you encounter today are still running on SQL databases. The most
popular of which is still MySQL.</p>
<p>Unfortunately, many people take for granted that Node should be used with a
NoSQL database and that is why we are not hearing what can be done with SQL.</p>
<p>Let’s have a look what we can do with MySQL.</p>
<h3 id="connecting-to-mysql">Connecting to MySQL</h3>
<p>Before you do anything, you need to install the right NPM package.</p>
<figure><pre><code data-lang="bash"><span>$ </span>npm <span>install </span>mysql</code></pre></figure>
<p><strong>mysql</strong> is a great module which makes working with MySQL very easy and it provides
all the capabilities you might need.</p>
<p>Once you have <strong>mysql</strong> installed, all you have to do to connect to your database
is</p>
<figure><pre><code data-lang="js"><span>var</span> <span>mysql</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>mysql</span><span>'</span><span>)</span>

<span>var</span> <span>connection</span> <span>=</span> <span>mysql</span><span>.</span><span>createConnection</span><span>({</span>
  <span>host</span><span>:</span> <span>'</span><span>localhost</span><span>'</span><span>,</span>
  <span>user</span><span>:</span> <span>'</span><span>your_user</span><span>'</span><span>,</span>
  <span>password</span><span>:</span> <span>'</span><span>some_secret</span><span>'</span><span>,</span>
  <span>database</span><span>:</span> <span>'</span><span>the_app_database</span><span>'</span>
<span>})</span>

<span>connection</span><span>.</span><span>connect</span><span>(</span><span>function</span><span>(</span><span>err</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>err</span><span>)</span> <span>throw</span> <span>err</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>You are now connected...</span><span>'</span><span>)</span>
<span>})</span></code></pre></figure>
<p>Now you can begin writing and reading from your database.</p>
<h3 id="reading-and-writing-to-mysql">Reading and Writing to MySQL</h3>
<p>You know how you can connect, so let’s have a look at a simple example</p>
<figure><pre><code data-lang="js"><span>var</span> <span>mysql</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>mysql</span><span>'</span><span>)</span>

<span>var</span> <span>connection</span> <span>=</span> <span>mysql</span><span>.</span><span>createConnection</span><span>({</span>
  <span>host</span><span>:</span> <span>'</span><span>localhost</span><span>'</span><span>,</span>
  <span>user</span><span>:</span> <span>'</span><span>your_user</span><span>'</span><span>,</span>
  <span>password</span><span>:</span> <span>'</span><span>some_secret</span><span>'</span><span>,</span>
  <span>database</span><span>:</span> <span>'</span><span>the_app_database</span><span>'</span>
<span>})</span>

<span>connection</span><span>.</span><span>connect</span><span>(</span><span>function</span><span>(</span><span>err</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>err</span><span>)</span> <span>throw</span> <span>err</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>You are now connected...</span><span>'</span><span>)</span>

  <span>connection</span><span>.</span><span>query</span><span>(</span><span>'</span><span>CREATE TABLE people(id int primary key, name varchar(255), age int, address text)</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>err</span><span>,</span> <span>result</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>err</span><span>)</span> <span>throw</span> <span>err</span>
    <span>connection</span><span>.</span><span>query</span><span>(</span><span>'</span><span>INSERT INTO people (name, age, address) VALUES (?, ?, ?)</span><span>'</span><span>,</span> <span>[</span><span>'</span><span>Larry</span><span>'</span><span>,</span> <span>'</span><span>41</span><span>'</span><span>,</span> <span>'</span><span>California, USA</span><span>'</span><span>],</span> <span>function</span><span>(</span><span>err</span><span>,</span> <span>result</span><span>)</span> <span>{</span>
      <span>if</span> <span>(</span><span>err</span><span>)</span> <span>throw</span> <span>err</span>
      <span>connection</span><span>.</span><span>query</span><span>(</span><span>'</span><span>SELECT * FROM people</span><span>'</span><span>,</span> <span>function</span><span>(</span><span>err</span><span>,</span> <span>results</span><span>)</span> <span>{</span>
        <span>if</span> <span>(</span><span>err</span><span>)</span> <span>throw</span> <span>err</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>results</span><span>[</span><span>0</span><span>].</span><span>id</span><span>)</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>results</span><span>[</span><span>0</span><span>].</span><span>name</span><span>)</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>results</span><span>[</span><span>0</span><span>].</span><span>age</span><span>)</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>results</span><span>[</span><span>0</span><span>].</span><span>address</span><span>)</span>
      <span>})</span>
    <span>})</span>
  <span>})</span> 
<span>})</span></code></pre></figure>
<p>First, you connect to the database, then you insert one record and then
you read it back.</p>
<p>You can also see that <strong>?</strong> acts as placeholders for your values. It not only makes
using values easier but it also escapes them so that your queries are always safe.</p>
<h3 id="replacing-your-db-file-for-help">Replacing your DB file for help</h3>
<p>As you saw using the <strong>mysql</strong> module is very easy, but real web apps have more
complex needs. That is why in
<a href="https://www.terlici.com/2015/04/03/mongodb-node-express.html">Connecting and Working with MongoDB</a>
we created a separate file <strong>db.js</strong> to help us manage our connections.</p>
<p>Let’s look how your helper <strong>db.js</strong> file will look like when using MySQL instead
of Mongo. Its purpose is to have easy access to the database whenever you need it
without constantly entering credentials.</p>
<p>Its second goal is to make it easy to run tests which access your database.</p>
<figure><pre><code data-lang="js"><span>var</span> <span>mysql</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>mysql</span><span>'</span><span>)</span>
  <span>,</span> <span>async</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>async</span><span>'</span><span>)</span>

<span>var</span> <span>PRODUCTION_DB</span> <span>=</span> <span>'</span><span>app_prod_database</span><span>'</span>
  <span>,</span> <span>TEST_DB</span> <span>=</span> <span>'</span><span>app_test_database</span><span>'</span>

<span>exports</span><span>.</span><span>MODE_TEST</span> <span>=</span> <span>'</span><span>mode_test</span><span>'</span>
<span>exports</span><span>.</span><span>MODE_PRODUCTION</span> <span>=</span> <span>'</span><span>mode_production</span><span>'</span>

<span>var</span> <span>state</span> <span>=</span> <span>{</span>
  <span>pool</span><span>:</span> <span>null</span><span>,</span>
  <span>mode</span><span>:</span> <span>null</span><span>,</span>
<span>}</span>

<span>exports</span><span>.</span><span>connect</span> <span>=</span> <span>function</span><span>(</span><span>mode</span><span>,</span> <span>done</span><span>)</span> <span>{</span>
  <span>state</span><span>.</span><span>pool</span> <span>=</span> <span>mysql</span><span>.</span><span>createPool</span><span>({</span>
    <span>host</span><span>:</span> <span>'</span><span>localhost</span><span>'</span><span>,</span>
    <span>user</span><span>:</span> <span>'</span><span>your_user</span><span>'</span><span>,</span>
    <span>password</span><span>:</span> <span>'</span><span>some_secret</span><span>'</span><span>,</span>
    <span>database</span><span>:</span> <span>mode</span> <span>===</span> <span>exports</span><span>.</span><span>MODE_PRODUCTION</span> <span>?</span> <span>PRODUCTION_DB</span> <span>:</span> <span>TEST_DB</span>
  <span>})</span>

  <span>state</span><span>.</span><span>mode</span> <span>=</span> <span>mode</span>
  <span>done</span><span>()</span>
<span>}</span>

<span>exports</span><span>.</span><span>get</span> <span>=</span> <span>function</span><span>()</span> <span>{</span>
  <span>return</span> <span>state</span><span>.</span><span>pool</span>
<span>}</span>

<span>exports</span><span>.</span><span>fixtures</span> <span>=</span> <span>function</span><span>(</span><span>data</span><span>)</span> <span>{</span>
  <span>var</span> <span>pool</span> <span>=</span> <span>state</span><span>.</span><span>pool</span>
  <span>if</span> <span>(</span><span>!</span><span>pool</span><span>)</span> <span>return</span> <span>done</span><span>(</span><span>new</span> <span>Error</span><span>(</span><span>'</span><span>Missing database connection.</span><span>'</span><span>))</span>

  <span>var</span> <span>names</span> <span>=</span> <span>Object</span><span>.</span><span>keys</span><span>(</span><span>data</span><span>.</span><span>tables</span><span>)</span>
  <span>async</span><span>.</span><span>each</span><span>(</span><span>names</span><span>,</span> <span>function</span><span>(</span><span>name</span><span>,</span> <span>cb</span><span>)</span> <span>{</span>
    <span>async</span><span>.</span><span>each</span><span>(</span><span>data</span><span>.</span><span>tables</span><span>[</span><span>name</span><span>],</span> <span>function</span><span>(</span><span>row</span><span>,</span> <span>cb</span><span>)</span> <span>{</span>
      <span>var</span> <span>keys</span> <span>=</span> <span>Object</span><span>.</span><span>keys</span><span>(</span><span>row</span><span>)</span>
        <span>,</span> <span>values</span> <span>=</span> <span>keys</span><span>.</span><span>map</span><span>(</span><span>function</span><span>(</span><span>key</span><span>)</span> <span>{</span> <span>return</span> <span>"</span><span>'</span><span>"</span> <span>+</span> <span>row</span><span>[</span><span>key</span><span>]</span> <span>+</span> <span>"</span><span>'</span><span>"</span> <span>})</span>

      <span>pool</span><span>.</span><span>query</span><span>(</span><span>'</span><span>INSERT INTO </span><span>'</span> <span>+</span> <span>name</span> <span>+</span> <span>'</span><span> (</span><span>'</span> <span>+</span> <span>keys</span><span>.</span><span>join</span><span>(</span><span>'</span><span>,</span><span>'</span><span>)</span> <span>+</span> <span>'</span><span>) VALUES (</span><span>'</span> <span>+</span> <span>values</span><span>.</span><span>join</span><span>(</span><span>'</span><span>,</span><span>'</span><span>)</span> <span>+</span> <span>'</span><span>)</span><span>'</span><span>,</span> <span>cb</span><span>)</span>
    <span>},</span> <span>cb</span><span>)</span>
  <span>},</span> <span>done</span><span>)</span>
<span>}</span>

<span>exports</span><span>.</span><span>drop</span> <span>=</span> <span>function</span><span>(</span><span>tables</span><span>,</span> <span>done</span><span>)</span> <span>{</span>
  <span>var</span> <span>pool</span> <span>=</span> <span>state</span><span>.</span><span>pool</span>
  <span>if</span> <span>(</span><span>!</span><span>pool</span><span>)</span> <span>return</span> <span>done</span><span>(</span><span>new</span> <span>Error</span><span>(</span><span>'</span><span>Missing database connection.</span><span>'</span><span>))</span>

  <span>async</span><span>.</span><span>each</span><span>(</span><span>tables</span><span>,</span> <span>function</span><span>(</span><span>name</span><span>,</span> <span>cb</span><span>)</span> <span>{</span>
    <span>pool</span><span>.</span><span>query</span><span>(</span><span>'</span><span>DELETE * FROM </span><span>'</span> <span>+</span> <span>name</span><span>,</span> <span>cb</span><span>)</span>
  <span>},</span> <span>done</span><span>)</span>
<span>}</span></code></pre></figure>
<p>This <strong>db.js</strong> file is a little bit more complicated than what we did before.</p>
<p>First, it provides a way to connect to the database. When you connect you can do
it either in production mode or in test mode. Test mode is for only when running
automated tests.</p>
<p>Then there is a get method which can always provide you with an active connection, which
you can use to query the database.</p>
<p>So whenever you need to contact the database instead of setting up database
passwords and other arguments you just call this method and you are ready to go.</p>
<p>Finally, there are two more methods <strong>fixtures</strong> and <strong>drop</strong>, which exist to
make your life easier when testing.</p>
<p><strong>drop</strong> clears the data, but not the schemas from all the tables that you want.
It will help you to be sure that your test database is always clean before every
test.</p>
<p><strong>fixtures</strong> takes a JSON object and loads its data into the database, so that there
is something on which to run your tests. Let’s have a quick look how it looks
to work with it:</p>
<figure><pre><code data-lang="js"><span>var</span> <span>data</span> <span>=</span> <span>{</span>
  <span>tables</span><span>:</span> <span>{</span>
    <span>people</span><span>:</span> <span>[</span>
     <span>{</span><span>id</span><span>:</span> <span>1</span><span>,</span> <span>name</span><span>:</span> <span>"</span><span>John</span><span>"</span><span>,</span> <span>age</span><span>:</span> <span>32</span><span>},</span>
     <span>{</span><span>id</span><span>:</span> <span>2</span><span>,</span> <span>name</span><span>:</span> <span>"</span><span>Peter</span><span>"</span><span>,</span> <span>age</span><span>:</span> <span>29</span><span>},</span>
    <span>],</span>
    <span>cars</span><span>:</span> <span>[</span>
      <span>{</span><span>id</span><span>:</span> <span>1</span><span>,</span> <span>brand</span><span>:</span> <span>"</span><span>Jeep</span><span>"</span><span>,</span> <span>model</span><span>:</span> <span>"</span><span>Cherokee</span><span>"</span><span>,</span> <span>owner_id</span><span>:</span> <span>2</span><span>},</span>
      <span>{</span><span>id</span><span>:</span> <span>2</span><span>,</span> <span>brand</span><span>:</span> <span>"</span><span>BMW</span><span>"</span><span>,</span> <span>model</span><span>:</span> <span>"</span><span>X5</span><span>"</span><span>,</span> <span>owner_id</span><span>:</span> <span>2</span><span>},</span>
      <span>{</span><span>id</span><span>:</span> <span>3</span><span>,</span> <span>brand</span><span>:</span> <span>"</span><span>Volkswagen</span><span>"</span><span>,</span> <span>model</span><span>:</span> <span>"</span><span>Polo</span><span>"</span><span>,</span> <span>owner_id</span><span>:</span> <span>1</span><span>},</span>
    <span>],</span>
  <span>},</span>
<span>}</span>

<span>var</span> <span>db</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>./db</span><span>'</span><span>)</span>
<span>db</span><span>.</span><span>connect</span><span>(</span><span>db</span><span>.</span><span>MODE_PRODUCTION</span><span>,</span> <span>function</span><span>()</span> <span>{</span>
  <span>db</span><span>.</span><span>fixtures</span><span>(</span><span>data</span><span>,</span> <span>function</span><span>(</span><span>err</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>err</span><span>)</span> <span>return</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>err</span><span>)</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Data has been loaded...</span><span>'</span><span>)</span>
  <span>})</span>
<span>})</span></code></pre></figure>
<p>It is very simple to use, and after running it your tables <em>cars</em> and <em>people</em>
will have data in them.</p>
<h3 id="building-models-with-sql">Building models with SQL</h3>
<p>Everything is in place and the next step is to actually see how you are going
to use <strong>db.js</strong> so that it will make your life easier.</p>
<p>Let’s have an example app with the following structure</p>
<figure><pre><code data-lang="bash">controllers/
  comments.js
  users.js
models/
  comment.js
  user.js
views/
app.js
db.js
package.json</code></pre></figure>
<p><strong>app.js</strong> is the entrypoint of the application and this is the place where we
are going to setup the database connection. Let’s have a look what is inside it.</p>
<figure><pre><code data-lang="js"><span>var</span> <span>db</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>./db</span><span>'</span><span>)</span>

<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/comments</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./controllers/comments</span><span>'</span><span>))</span>
<span>app</span><span>.</span><span>use</span><span>(</span><span>'</span><span>/users</span><span>'</span><span>,</span> <span>require</span><span>(</span><span>'</span><span>./controllers/users</span><span>'</span><span>))</span>

<span>// Connect to MySQL on start</span>
<span>db</span><span>.</span><span>connect</span><span>(</span><span>db</span><span>.</span><span>MODE_PRODUCTION</span><span>,</span> <span>function</span><span>(</span><span>err</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>err</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Unable to connect to MySQL.</span><span>'</span><span>)</span>
    <span>process</span><span>.</span><span>exit</span><span>(</span><span>1</span><span>)</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>app</span><span>.</span><span>listen</span><span>(</span><span>3000</span><span>,</span> <span>function</span><span>()</span> <span>{</span>
      <span>console</span><span>.</span><span>log</span><span>(</span><span>'</span><span>Listening on port 3000...</span><span>'</span><span>)</span>
    <span>})</span>
  <span>}</span>
<span>})</span></code></pre></figure>
<p>Your app will interact with the database through its models. So let’s have a look
how a model can look like. For example this is how your comments model can look
like:</p>
<figure><pre><code data-lang="js"><span>var</span> <span>db</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>../db.js</span><span>'</span><span>)</span>

<span>exports</span><span>.</span><span>create</span> <span>=</span> <span>function</span><span>(</span><span>userId</span><span>,</span> <span>text</span><span>,</span> <span>done</span><span>)</span> <span>{</span>
  <span>var</span> <span>values</span> <span>=</span> <span>[</span><span>userId</span><span>,</span> <span>text</span><span>,</span> <span>new</span> <span>Date</span><span>().</span><span>toISOString</span><span>()]</span>
  
  <span>db</span><span>.</span><span>get</span><span>().</span><span>query</span><span>(</span><span>'</span><span>INSERT INTO comments (user_id, text, date) VALUES(?, ?, ?)</span><span>'</span><span>,</span> <span>values</span><span>,</span> <span>function</span><span>(</span><span>err</span><span>,</span> <span>result</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>err</span><span>)</span> <span>return</span> <span>done</span><span>(</span><span>err</span><span>)</span>
    <span>done</span><span>(</span><span>null</span><span>,</span> <span>result</span><span>.</span><span>insertId</span><span>)</span>
  <span>})</span>
<span>}</span>

<span>exports</span><span>.</span><span>getAll</span> <span>=</span> <span>function</span><span>(</span><span>done</span><span>)</span> <span>{</span>
  <span>db</span><span>.</span><span>get</span><span>().</span><span>query</span><span>(</span><span>'</span><span>SELECT * FROM comments</span><span>'</span><span>,</span> <span>function</span> <span>(</span><span>err</span><span>,</span> <span>rows</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>err</span><span>)</span> <span>return</span> <span>done</span><span>(</span><span>err</span><span>)</span>
    <span>done</span><span>(</span><span>null</span><span>,</span> <span>rows</span><span>)</span>
  <span>})</span>
<span>}</span>

<span>exports</span><span>.</span><span>getAllByUser</span> <span>=</span> <span>function</span><span>(</span><span>userId</span><span>,</span> <span>done</span><span>)</span> <span>{</span>
  <span>db</span><span>.</span><span>get</span><span>().</span><span>query</span><span>(</span><span>'</span><span>SELECT * FROM comments WHERE user_id = ?</span><span>'</span><span>,</span> <span>userId</span><span>,</span> <span>function</span> <span>(</span><span>err</span><span>,</span> <span>rows</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>err</span><span>)</span> <span>return</span> <span>done</span><span>(</span><span>err</span><span>)</span>
    <span>done</span><span>(</span><span>null</span><span>,</span> <span>rows</span><span>)</span>
  <span>})</span>
<span>}</span></code></pre></figure>
<p>As you can see the <strong>db.js</strong> files makes it very easy to build any kind of models
without worrying about connecting the database. It doesn’t even know whether you
are in production or testing mode, so your models will work in both cases.</p>
<p>Then you can use your newly built models in your controllers and they won’t even
know that there is a SQL solution behind.</p>
<h3 id="advanced-usage-using-different-database-instance-for-reading-and-writing">Advanced usage: using different database instance for reading and writing</h3>
<p>As your app grow your needs grow. Many of todays applications are read orientied.</p>
<p>That means that people write data more rarely than they read. For example, all
social networks are this type of applications. Usually a status is written once
but then read by hundreds or even thousands of people.</p>
<p>In this kind of situations it makes sense to have one main database which will
accept all the writes and then synced to a few more MySQL instances which will
serve only the read requests.</p>
<p>Then when you have more users you can easily add more database only for reading
and your app will scale and still be super fast.</p>
<p>But how can this work in our setup from above?</p>
<p>The <strong>mysql</strong> module has the very useful PoolCluster feature, which can take the
configurations for several instances and then connect to all of them. Let’s see
how your <strong>db.js</strong> file will look:</p>
<figure><pre><code data-lang="js"><span>var</span> <span>mysql</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>mysql</span><span>'</span><span>)</span>
  <span>,</span> <span>async</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>async</span><span>'</span><span>)</span>

<span>var</span> <span>PRODUCTION_DB</span> <span>=</span> <span>'</span><span>app_prod_database</span><span>'</span>
  <span>,</span> <span>TEST_DB</span> <span>=</span> <span>'</span><span>app_test_database</span><span>'</span>

<span>exports</span><span>.</span><span>MODE_TEST</span> <span>=</span> <span>'</span><span>mode_test</span><span>'</span>
<span>exports</span><span>.</span><span>MODE_PRODUCTION</span> <span>=</span> <span>'</span><span>mode_production</span><span>'</span>

<span>var</span> <span>state</span> <span>=</span> <span>{</span>
  <span>pool</span><span>:</span> <span>null</span><span>,</span>
  <span>mode</span><span>:</span> <span>null</span><span>,</span>
<span>}</span>

<span>exports</span><span>.</span><span>connect</span> <span>=</span> <span>function</span><span>(</span><span>mode</span><span>,</span> <span>done</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>mode</span> <span>===</span> <span>exports</span><span>.</span><span>MODE_PRODUCTION</span><span>)</span> <span>{</span>
    <span>state</span><span>.</span><span>pool</span> <span>=</span> <span>mysql</span><span>.</span><span>createPoolCluster</span><span>()</span>

    <span>state</span><span>.</span><span>pool</span><span>.</span><span>add</span><span>(</span><span>'</span><span>WRITE</span><span>'</span><span>,</span> <span>{</span>
      <span>host</span><span>:</span> <span>'</span><span>192.168.0.5</span><span>'</span><span>,</span>
      <span>user</span><span>:</span> <span>'</span><span>your_user</span><span>'</span><span>,</span>
      <span>password</span><span>:</span> <span>'</span><span>some_secret</span><span>'</span><span>,</span>
      <span>database</span><span>:</span> <span>PRODUCTION_DB</span>
    <span>})</span>

    <span>state</span><span>.</span><span>pool</span><span>.</span><span>add</span><span>(</span><span>'</span><span>READ1</span><span>'</span><span>,</span> <span>{</span>
      <span>host</span><span>:</span> <span>'</span><span>192.168.0.6</span><span>'</span><span>,</span>
      <span>user</span><span>:</span> <span>'</span><span>your_user</span><span>'</span><span>,</span>
      <span>password</span><span>:</span> <span>'</span><span>some_secret</span><span>'</span><span>,</span>
      <span>database</span><span>:</span> <span>PRODUCTION_DB</span>
    <span>})</span>

    <span>state</span>…</code></pre></figure></article></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.terlici.com/2015/08/13/mysql-node-express.html">https://www.terlici.com/2015/08/13/mysql-node-express.html</a></em></p>]]>
            </description>
            <link>https://www.terlici.com/2015/08/13/mysql-node-express.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300251</guid>
            <pubDate>Fri, 04 Dec 2020 08:29:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invention Agreements can be Unenforceable Covenants not to compete]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300244">thread link</a>) | @genericone
<br/>
December 4, 2020 | https://www.hkemploymentlaw.com/blog/invention-agreements-can-be-unenforceable-covenants-not-to-compete/ | <a href="https://web.archive.org/web/*/https://www.hkemploymentlaw.com/blog/invention-agreements-can-be-unenforceable-covenants-not-to-compete/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hkemploymentlaw.com/blog/invention-agreements-can-be-unenforceable-covenants-not-to-compete/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300244</guid>
            <pubDate>Fri, 04 Dec 2020 08:27:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Project Loom and Structured Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25300233">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html | <a href="https://web.archive.org/web/*/https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<h2>Why Loom?</h2>
<p>In 1998, it was amazing that the Sun Java Web Server (the precursor of Tomcat) ran each request in a separate thread, and not an OS process. It was able to serve thousands of concurrent requests this way! Nowadays, that’s not so amazing. Each thread takes up a significant amount of memory, and you can’t have millions of threads on a typical server.</p>
<p>That’s why the modern mantra of server-side programming is: “Never block!” Instead, you specify what should happen once the data is available.</p>
<p>This asynchronous programming style is great for servers, allowing them to handily support millions of concurrent requests. It isn’t so great for programmers.</p>
<p>Here is an asynchronous request with the <code>HttpClient</code> API:</p>
<pre>HttpClient.newBuilder()
   .build()
   .sendAsync(request, HttpResponse.BodyHandlers.ofString())
   .thenAccept(response -&gt; . . .);
   .thenApply(. . .);
   .exceptionally(. . .);
</pre>
<p>What we would normally achieve with statements is now encoded as method calls. If we loved this style of programming, we would not have statements in our programming language and merrily code in Lisp.</p>
<p>In JavaScript, code tagged as “async” is rewritten into method calls like the ones that you’ve just seen. But that means you can only call async methods from other async methods, and your API splits into a sync and an async part, forcing you to duplicate functionality.</p>

<p>Project Loom takes its guidance from languages such as Erlang and Go, attacking the root of the problem by making blocking very cheap. You run tasks in “virtual threads”, a nearly unlimited resource that is mapped into actual “carrier” threads. When a virtual thread blocks, it is “parked” and another virtual thread runs on the carrier thread. The name is supposed to remind you of virtual memory that is mapped to actual RAM.</p>
<p>Before you complain about the name, remember that naming is hard. The Loom team previously tried “fiber”, but it is already used elsewhere with a slightly different meaning. And “lightweight” or “new” thread might look foolish when something lighter-weight or newer comes along.</p>
<p>After experimenting with separate classes for OS threads and virtual threads, they ended up deciding to use a single class for both—the familiar <code>java.lang.Thread</code>—in order to ease migration.</p>
<p>Of course, good old <code>java.lang.Thread</code>, which has been around for 25 years, ever since Java 1.0, has its share of cruft. Awkward cancellation, thread groups, priorities, depreceated methods <code>stop</code>,<code>suspend</code>, <code>resume</code>. The Loom team felt that these liabilities were minor since most programmers never explicitly use the <code>Thread</code> API but launch tasks with an <code>ExecutorService</code>. (Of course, the same argument would support coming up with a cleaner virtual thread API instead.)</p>
<p>If you have been around for a very long time, you may remember that early versions of Java had “green threads” that were mapped to an OS thread. However, there is a crucial difference. When a green thread blocked, its carrier thread was also blocked, preventing all other green threads from making progress.</p>

<p>You can download binaries of Project Loom at <a href="http://jdk.java.net/loom/">http://jdk.java.net/loom/</a>. They are updated regularly.</p>
<p>As already mentioned, a virtual thread is an object of the <code>Thread</code> class. Here are three ways of producing fibers. First, there is a new factory method that constructs and starts a virtual thread:</p>
<pre>Thread thread = Thread.startVirtualThread(runnable);
  // <cite>Note that the thread is already started</cite></pre>
<p>This is good for demos, tutorials or quick-and-dirty experiments in JShell.</p>
<p>For more customization, there is a builder API:</p>
<pre>Thread thread = Thread.builder()
   .virtual()
   .name(taskname)
   .task(runnable)
   .build();</pre>
<p>However, as you have been told for many years now, it is better to use an executor service than to manually construct <code>Thread</code> instances. The static method <code>Executors.newVirtualThreadExecutor()</code> provides one. (The existing executor services are not useful for virtual threads. It would be counterproductive to pool them!)</p>
<p>For example,</p>
<pre>ExecutorService exec = Executors.newVirtualThreadExecutor();
exec.submit(runnable1);
exec.submit(runnable2);
</pre>
<p>As with the other factory methods in the <code>Executors</code> class, you can optionally supply a <code>ThreadFactory</code>. And the new <code>Thread.Builder</code> class has an easy way to provide a factory, instead of a single instance:</p>
<pre>ThreadFactory factory = Thread.builder()
   .virtual()
   .name(taskname)
   .task(runnable)
   .<b>factory()</b>;

ExecutorService exec = Executors.newThreadExecutor(factory);
</pre>
<p>Let’s try this out. As a first test, we just sleep in each task.</p>
<pre>import java.util.concurrent.*;

public class Test {
   public static int DELAY = 10_000;
   public static int NTASKS = 1_000_000;

   public static void run(Object obj) {
      try {
         Thread.sleep((int) (DELAY * Math.random()));
      } catch (InterruptedException ex) {
         ex.printStackTrace();
      }
      System.out.println(obj);
   }

   public static void main(String[] args) {
      ExecutorService exec = Executors.newVirtualThreadExecutor();
      for (int i = 1; i &lt;= NTASKS; i++) {
         String taskname = "task-" + i;
         exec.submit(() -&gt; run(taskname));
      }
      exec.close();
   }
}
</pre>
<p>Run the program and it just works. Then try using OS threads—change to <code>Executors.newCachedThreadPool()</code> or <code>Executors.newFixedThreadPool(NTASKS)</code>. The program will run out of memory; on my laptop, after about 25,000 threads.</p>
<p>Ok, but in practice, you don’t want to sleep, but do useful work. Consider a program adapted from one of <a href="https://www.javaspecialists.eu/about/heinz/">Heinz Kabutz</a>‘ puzzlers, The program fetches a daily image, from Dilbert or Wikimedia. It consists of classes <a href="http://horstmann.com/unblog/2019-07-27/dailyImages/ImageProcessor.java"><code>ImageProcessor</code></a> and <a href="http://horstmann.com/unblog/2019-07-27/dailyImages/ImageInfo.java"><code>ImageInfo</code></a>. The code is an impenetrable maze of twisty passages, all alike (i.e. helper functions yielding completable futures).</p>
<p>With virtual threads, simply read web contents synchronously. It blocks, but we don’t care. All the complexity goes away. The control flow is simple and comprehensible.</p>
<pre>exec.submit(() -&gt; {
    String pageURL = info.getUrlForDate(date);
    String page = getSync(pageURL, HttpResponse.BodyHandlers.ofString());
    String imageURL = info.findImage(page).getImagePath();
    byte[] image = getSync(imageURL, HttpResponse.BodyHandlers.ofByteArray());
    info.setImageData(image);
    process(info);
    return null;
});</pre>
<p>Here is the simplified <a href="http://horstmann.com/unblog/2020-12-05/dailyImages/ImageProcessor.java"><code>ImageProcessor</code></a> code.</p>
<p><b>Pro tip: </b>The statement <code>return null;</code> makes the lambda into a <code>Callable</code> instead of a <code>Runnable</code>, so that you don’t have to catch checked exceptions 😜</p>
<p>Try this out with something you care about. Call web services and make database connections, without worrying about callbacks. When blocking is cheap, a whole lot of accidental complexity goes away. Of course, to use this in a web app framework, you’ll have to wait for your framework provider to run your code in virtual threads.</p>
<h2>Structured Concurrency</h2>
<p>In <a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">this highly recommended article</a> (from which the images below are taken), Nathaniel Smith proposes structured forms of concurrency. Here is his central argument. Launching a task in a new thread is really no better than programming with GOTO, i.e. harmful:</p>
<pre>new Thread(runnable).start();</pre>
<p><img src="http://horstmann.com/unblog/2019-12-05/sequential-and-go-to-schematic.svg" alt=".svg" width="38%"></p>
<p>When multiple threads run without coordination, it’s spaghetti code all over again. In the 1960s, structured programming replaced <code>goto</code> with branches, loops, and functions:</p>
<p><img src="http://horstmann.com/unblog/2019-12-05/control-schematics.svg" alt=".svg" width="42%"></p>
<p>When you look at a line of code, you know how the program got there.</p>
<p>Structured concurrency does the same for concurrent tasks. We should know, from reading the program text, when they all finish.</p>
<p><img src="http://horstmann.com/unblog/2019-12-05/nursery-schematic-unlabeled.svg" alt=".svg" width="30%"></p>
<p>That way we can control the resources that the tasks use, and we know when it is time to move on.</p>
<p>In Loom, the <code>ExecutorService</code> implements this basic construct. <code>ExecutorService</code> has a <code>close</code> method that blocks until all of its virtual threads have completed. (I used this method in the first sample program to keep <code>main</code> alive until all virtual threads are done. In the past, you had to call the <code>awaitTermination</code> method instead.)</p>
<p>Conveniently, <code>ExecutorService</code> implements the <code>AutoCloseable</code> interface, so that you can just use a <code>try</code>-with-resources statement:</p>
<pre>try (ExecutorService exec = Executor.newVirtualThreadExecutor()) {
   for (int i = 0; i &lt; NTASKS; i++) {
      exec.schedule(() -&gt; run(i));
   }
} // <cite>Blocks until all threads completed</cite>
</pre>
<p>I wrote a simple web crawler as a demonstration of virtual threads—here is the <a href="http://horstmann.com/unblog/2020-12-05/Crawler.java"><code>Crawler</code></a> class. In my first attempt, I fired off a new virtual thread for each URL in a page. If I had wanted to become Google, I could have let my crawler run forever. But I wanted to go no more than 3 hops from the starting point. With “fire and forget”, there is no way of knowing when the recursion is done.</p>
<p>Instead, for each page, I make a new executor service and wait for completion. That way, the whole program completes when all pages have been crawled.</p>
<p>This seems a lot of blocking. But in Loom, blocking is cheap, so we shouldn’t worry about that.</p>
<p>We are used to having one executor service as thread pool for all our tasks. But in Loom, you are encouraged to use a separate executor service for each task set.</p>
<h2>Deadlines</h2>
<p>When crawling the web, you are likely to encounter dead links. Reading from one should time out eventually, but it can take surprisingly long.</p>
<p>The standard remedy is, of course, to provide a timeout. Loom prefers deadlines to timeouts, so you specify</p>
<pre>ExecutorService exec = Executors.newVirtualThreadExecutor().withDeadline(
   Instant.now().plus(30, ChronoUnit.SECONDS))
</pre>
<p>Why deadlines? In general, timeouts compose poorly. Suppose you have to accomplish two sequential tasks with an overall timeout of 10 seconds. You don’t want to give each of the tasks a timeout of 5 seconds. After all, if one takes 6 seconds and the other 3 seconds, you still come in under the finish line. To get the timeout of the second task, you’d have to measure the duration of the first task and subtract that from the overall timeout. With deadlines, it is much simpler. Each task gets the same deadline.</p>
<p>The call <code>exec.close()</code> blocks until all virtual threads have completed or the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html">https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html</a></em></p>]]>
            </description>
            <link>https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300233</guid>
            <pubDate>Fri, 04 Dec 2020 08:24:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction of Unix pseudo-random number functions]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300200">thread link</a>) | @nanxiao
<br/>
December 4, 2020 | https://nanxiao.me/en/introduction-of-unix-pseudo-random-number-functions/ | <a href="https://web.archive.org/web/*/https://nanxiao.me/en/introduction-of-unix-pseudo-random-number-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1517">
	
	<!-- .entry-header -->

	<div>
		<p data-line-start="2" data-line-end="3">I can’t find detailed introduction of&nbsp;<a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/initstate.html#tag_16_244">Unix pseudo-random number functions</a>, so I decide to write one myself. Please notice many platforms provide reentrant versions, like&nbsp;<a href="https://man7.org/linux/man-pages/man3/initstate_r.3.html">Linux</a>. Now that non-reentrant versions should just invoke reentrant versions with global data (refer&nbsp;<a href="https://github.com/bminor/glibc/blob/master/stdlib/random.c">glibc</a>), I will use non-reentrant versions to demonstrate in this post.</p>
<p data-line-start="4" data-line-end="5">(1) Call&nbsp;<code>random()</code>&nbsp;only:</p>
<pre><code data-line-start="6" data-line-end="18">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    for (int i = 0; i &lt; 5; i++)
    {
        printf("%ld\n", random());
    }
    return 0;
}
</code></pre>
<p data-line-start="18" data-line-end="19">Compile and run for&nbsp;<code>2</code>&nbsp;times:</p>
<pre><code data-line-start="20" data-line-end="34"># gcc random.c
# ./a.out
1804289383
846930886
1681692777
1714636915
1957747793
# ./a.out
1804289383
846930886
1681692777
1714636915
1957747793
</code></pre>
<p data-line-start="34" data-line-end="35">Same outputs as expected because they are “pseudo”.</p>
<p data-line-start="36" data-line-end="38">(2) Call&nbsp;<code>srandom(1)</code>. According to&nbsp;<a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/initstate.html#tag_16_244">spec</a>:</p>
<blockquote>
<p data-line-start="39" data-line-end="40">Like rand(), random() shall produce by default a sequence of numbers that can be duplicated by calling srandom() with 1 as the seed.</p>
</blockquote>
<p data-line-start="41" data-line-end="42">Verify it:</p>
<pre><code data-line-start="43" data-line-end="56">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    srandom(1);
    for (int i = 0; i &lt; 5; i++)
    {
        printf("%ld\n", random());
    }
    return 0;
}
</code></pre>
<p data-line-start="56" data-line-end="57">Compile and run:</p>
<pre><code data-line-start="58" data-line-end="66"># gcc random.c
# ./a.out
1804289383
846930886
1681692777
1714636915
1957747793
</code></pre>
<p data-line-start="66" data-line-end="67">Yes, the output is same as the first test (call&nbsp;<code>random()</code>&nbsp;only).</p>
<p data-line-start="68" data-line-end="69">(3) Call&nbsp;<code>srandom(2)</code>:</p>
<pre><code data-line-start="70" data-line-end="83">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    srandom(2);
    for (int i = 0; i &lt; 5; i++)
    {
        printf("%ld\n", random());
    }
    return 0;
}
</code></pre>
<p data-line-start="83" data-line-end="84">Build and run it:</p>
<pre><code data-line-start="85" data-line-end="93"># gcc random.c
# ./a.out
1505335290
1738766719
190686788
260874575
747983061
</code></pre>
<p data-line-start="93" data-line-end="94">Hmm, this time different output is generated.</p>
<p data-line-start="95" data-line-end="96">(4) Let’s see an example of using&nbsp;<code>initstate()</code>:</p>
<pre><code data-line-start="97" data-line-end="118">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    unsigned int seed = 1;
    char state[128];

    if (initstate(seed, state, sizeof(state)) == NULL)
    {
        printf("initstate error\n");
        return 1;
    }

    for (int i = 0; i &lt; 5; i++)
    {
        printf("%ld\n", random());
    }
    return 0;
}
</code></pre>
<p data-line-start="118" data-line-end="119">From the&nbsp;<a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/initstate.html#tag_16_244">spec</a>:</p>
<blockquote>
<p data-line-start="119" data-line-end="121">The initstate() function allows a state array, pointed to by the state argument, to be initialized for future use.<br>
So how&nbsp;<code>initstate()</code>&nbsp;will initialize the&nbsp;<code>state</code>&nbsp;array? Let’s see the implementation of&nbsp;<a href="https://github.com/bminor/glibc/blob/c41d197ec4a564a588e1cf3855d955297f2915c4/stdlib/random_r.c#L265">glibc</a>:</p>
</blockquote>
<pre><code data-line-start="122" data-line-end="132">  ......
  int32_t *state = &amp;((int32_t *) arg_state)[1]; /* First location.  */
  /* Must set END_PTR before srandom.  */
  buf-&gt;end_ptr = &amp;state[degree];

  buf-&gt;state = state;

  __srandom_r (seed, buf);
  ......
</code></pre>
<p data-line-start="132" data-line-end="133"><code>initstate()</code>&nbsp;actually calls&nbsp;<code>srandom()</code>&nbsp;to initialize the&nbsp;<code>state</code>&nbsp;array. Build and run program:</p>
<pre><code data-line-start="134" data-line-end="142"># gcc random.c
# ./a.out
1804289383
846930886
1681692777
1714636915
1957747793
</code></pre>
<p data-line-start="142" data-line-end="143">The same output as the first test (call&nbsp;<code>random()</code>&nbsp;only), and this complies to another quote extracted from&nbsp;<a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/initstate.html#tag_16_244">spec</a>:</p>
<blockquote>
<p data-line-start="143" data-line-end="144">If initstate() has not been called, then random() shall behave as though initstate() had been called with seed=1 and size=128.</p>
</blockquote>
<p data-line-start="145" data-line-end="146">Change&nbsp;<code>seed</code>&nbsp;from&nbsp;<code>1</code>&nbsp;to&nbsp;<code>2</code>:</p>
<pre><code data-line-start="147" data-line-end="168">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    unsigned int seed = 2;
    char state[128];

    if (initstate(seed, state, sizeof(state)) == NULL)
    {
        printf("initstate error\n");
        return 1;
    }

    for (int i = 0; i &lt; 5; i++)
    {
        printf("%ld\n", random());
    }
    return 0;
}
</code></pre>
<p data-line-start="168" data-line-end="169">Compile and run again:</p>
<pre><code data-line-start="170" data-line-end="178"># gcc random.c
# ./a.out
1505335290
1738766719
190686788
260874575
747983061
</code></pre>
<p data-line-start="178" data-line-end="179">This time, the output is same as the third test (call&nbsp;<code>srandom(2)</code>&nbsp;only). Definitely, you can change the size of&nbsp;<code>state</code>&nbsp;array and modify&nbsp;<code>seed</code>&nbsp;during running, like this:</p>
<pre><code data-line-start="180" data-line-end="202">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    unsigned int seed = 2;
    char state[64];

    if (initstate(seed, state, sizeof(state)) == NULL)
    {
        printf("initstate error\n");
        return 1;
    }

    for (int i = 0; i &lt; 5; i++)
    {
        srandom(seed + i);
        printf("%ld\n", random());
    }
    return 0;
}
</code></pre>
<p data-line-start="203" data-line-end="204">(5) Finally, let’s see&nbsp;<code>setstate()</code>. Check following example:</p>
<pre><code data-line-start="205" data-line-end="245">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int main()
{
    unsigned seed = 1;
    char state_1[128], state_2[128];

    if (initstate(seed, state_1, sizeof(state_1)) == NULL)
    {
        printf("initstate error\n");
        return 1;
    }

    seed = 2;
    if (initstate(seed, state_2, sizeof(state_2)) == NULL)
    {
        printf("initstate error\n");
        return 1;
    }

    for (int i = 0; i &lt; 5; i++)
    {
        printf("%ld\n", random());
    }

    if (setstate(state_1) == NULL)
    {
        printf("setstate error\n");
        return 1;
    }

    for (int i = 0; i &lt; 5; i++)
    {
        printf("%ld\n", random());
    }

    return 0;
}
</code></pre>
<p data-line-start="245" data-line-end="246">Compile and run the program:</p>
<pre><code data-line-start="247" data-line-end="260"># gcc random.c
# ./a.out
1505335290
1738766719
190686788
260874575
747983061
1804289383
846930886
1681692777
1714636915
1957747793
</code></pre>
<p data-line-start="260" data-line-end="261">You can see the first&nbsp;<code>5</code>&nbsp;numbers are same as invoking&nbsp;<code>srandom(2)</code>, whilst the last&nbsp;<code>5</code>&nbsp;numbers are same as invoking&nbsp;<code>srandom(1)</code>.</p>
<p data-line-start="262" data-line-end="263">Last but not least, please keep&nbsp;<code>state</code>&nbsp;memory always valid during usage of these pseudo-random number functions.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://nanxiao.me/en/introduction-of-unix-pseudo-random-number-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300200</guid>
            <pubDate>Fri, 04 Dec 2020 08:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C# 9 – Improving performance using the SkipLocalsInit attribute]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300125">thread link</a>) | @flipchart
<br/>
December 4, 2020 | https://www.meziantou.net/csharp-9-improve-performance-using-skiplocalsinit.htm | <a href="https://web.archive.org/web/*/https://www.meziantou.net/csharp-9-improve-performance-using-skiplocalsinit.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>C# 9 brings lots of new language features. One of them is the ability to suppress emitting <code>.locals init</code> flag. This feature allows to improve the performance of a method by not zeroing the local variables before executing the method. Even if <a href="https://github.com/dotnet/runtime/pull/32538">zeroing local has been improved<i></i></a> in .NET 5, not doing it will still be faster.</p><h2 id="what-is-locals-init"><a href="#what-is-locals-init">#</a>What is locals init?</h2><p>By default, the C# compiler emits the <code>.locals init</code> directive. This instructs the JIT to generate a prolog to set all local variables to their default value. This is safer as you cannot use uninitialized memory. You can validate this behavior using unsafe code. The following method constantly prints "0" to the console as the JIT initializes the variable <code>i</code> to its default value.</p><pre><code><span>static</span> <span>unsafe</span> <span><span>void</span></span> <span>DemoZeroing</span><span>(</span><span>)</span>
<span>{</span>
    <span><span>int</span></span> i<span>;</span>
    Console<span>.</span><span>WriteLine</span><span>(</span><span>*</span><span>&amp;</span>i<span>)</span><span>;</span>
    <span>// Display 0 as the local variable is automatically initialized with the default value</span>
<span>}</span></code></pre><p><img src="https://www.meziantou.net/assets/localsinit-1.png?v=da65&amp;utm_medium=social&amp;utm_source=web" width="543" height="273" srcset="https://www.meziantou.net/assets/localsinit-1-th-w500-h0.png?v=5b79&amp;utm_medium=social&amp;utm_source=web 500w,https://www.meziantou.net/assets/localsinit-1.png?v=da65&amp;utm_medium=social&amp;utm_source=web 543w" sizes="100vw"></p><h2 id="suppress-emitting-lo"><a href="#suppress-emitting-lo">#</a>Suppress emitting <code>localsinit</code> flag</h2><p>In C# 9, you can use the new attribute <code>[System.Runtime.CompilerServices.SkipLocalsInit]</code> to instruct the compiler to suppress emitting <code>.locals init</code> flag. This attribute applies at module, class, or method level:</p><pre><code><span>[</span><span><span>AttributeUsage</span><span><span>(</span>
      AttributeTargets<span>.</span>Module
    <span>|</span> AttributeTargets<span>.</span>Class
    <span>|</span> AttributeTargets<span>.</span>Struct
    <span>|</span> AttributeTargets<span>.</span>Interface
    <span>|</span> AttributeTargets<span>.</span>Constructor
    <span>|</span> AttributeTargets<span>.</span>Method
    <span>|</span> AttributeTargets<span>.</span>Property
    <span>|</span> AttributeTargets<span>.</span>Event<span>,</span> Inherited <span>=</span> <span>false</span><span>)</span></span></span><span>]</span>
<span>public</span> <span>sealed</span> <span>class</span> <span>SkipLocalsInitAttribute</span> <span>:</span> <span><span>Attribute</span></span>
<span>{</span>
    <span>public</span> <span>SkipLocalsInitAttribute</span><span>(</span><span>)</span> <span>{</span> <span>}</span>
<span>}</span></code></pre><p>Here's how to use it on a method:</p><pre><code><span>[</span><span><span>System<span>.</span>Runtime<span>.</span>CompilerServices<span>.</span>SkipLocalsInit</span></span><span>]</span>
<span>static</span> <span>unsafe</span> <span><span>void</span></span> <span>DemoZeroing</span><span>(</span><span>)</span>
<span>{</span>
    <span><span>int</span></span> i<span>;</span>
    Console<span>.</span><span>WriteLine</span><span>(</span><span>*</span><span>&amp;</span>i<span>)</span><span>;</span> <span>// Unpredictable output as i is not initialized</span>
<span>}</span></code></pre><p>You can apply the attribute per method, per class, or per module (project):</p><pre><code><span>// For the project</span>
<span>[</span>module<span>:</span> System<span>.</span>Runtime<span>.</span>CompilerServices<span>.</span>SkipLocalsInit<span>]</span>

<span>// For the class</span>
<span>[</span>System<span>.</span>Runtime<span>.</span>CompilerServices<span>.</span>SkipLocalsInit<span>]</span>
<span>class</span> <span>Sample</span>
<span>{</span>
    <span>// ...</span>
<span>}</span></code></pre><p>When decompiling the application, you can see that the method now uses <code>locals</code> instead of <code>.locals init</code> which means that the variables won't be automatically initialized by the JIT.</p><p><a href="https://www.meziantou.net/assets/skiplocalsinit-1.png?v=1593&amp;utm_medium=social&amp;utm_source=web"><img src="https://www.meziantou.net/assets/skiplocalsinit-1.png?v=1593&amp;utm_medium=social&amp;utm_source=web" width="800" height="305" srcset="https://www.meziantou.net/assets/skiplocalsinit-1-th-w500-h0.png?v=1e69&amp;utm_medium=social&amp;utm_source=web 500w,https://www.meziantou.net/assets/skiplocalsinit-1-th-w800-h0.png?v=3687&amp;utm_medium=social&amp;utm_source=web 800w,https://www.meziantou.net/assets/skiplocalsinit-1.png?v=1593&amp;utm_medium=social&amp;utm_source=web 830w" sizes="100vw"></a></p><h2 id="performance-82bd01"><a href="#performance-82bd01">#</a>Performance</h2><p><a href="https://www.meziantou.net/comparing-implementations-with-benchmarkdotnet.htm?utm_medium=social&amp;utm_source=web" title="Comparing implementations with BenchmarkDotnet">BenchmarkDotnet</a> allows to quickly check how the performance is affected depending on the local variables size. The easiest way is to use a <code>stackalloc</code>.</p><pre><code><span>public</span> <span>class</span> <span>SkipLocalsInitBenchmark</span>
<span>{</span>
    <span>[</span><span><span>Params</span><span><span>(</span><span>4</span><span>,</span> <span>8</span><span>,</span> <span>12</span><span>,</span> <span>16</span><span>,</span> <span>20</span><span>,</span> <span>24</span><span>,</span> <span>32</span><span>,</span> <span>64</span><span>,</span> <span>128</span><span>,</span> <span>256</span><span>,</span> <span>512</span><span>,</span> <span>1024</span><span>)</span></span></span><span>]</span>
    <span>public</span> <span><span>int</span></span> Size <span>{</span> <span>get</span><span>;</span> <span>set</span><span>;</span> <span>}</span>

    <span>[</span><span><span>Benchmark</span></span><span>]</span>
    <span>public</span> <span><span>byte</span></span> <span>InitLocals</span><span>(</span><span>)</span>
    <span>{</span>
        <span>Span<span>&lt;</span><span>byte</span><span>&gt;</span></span> s <span>=</span> <span>stackalloc</span> <span>byte</span><span>[</span>Size<span>]</span><span>;</span>
        <span>return</span> s<span>[</span><span>0</span><span>]</span><span>;</span>
    <span>}</span>

    <span>[</span><span><span>Benchmark</span></span><span>]</span>
    <span>[</span><span><span>SkipLocalsInit</span></span><span>]</span>
    <span>public</span> <span><span>byte</span></span> <span>SkipInitLocals</span><span>(</span><span>)</span>
    <span>{</span>
        <span>Span<span>&lt;</span><span>byte</span><span>&gt;</span></span> s <span>=</span> <span>stackalloc</span> <span>byte</span><span>[</span>Size<span>]</span><span>;</span>
        <span>return</span> s<span>[</span><span>0</span><span>]</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre><p><a href="https://www.meziantou.net/assets/benchmark-2.png?v=9e81&amp;utm_medium=social&amp;utm_source=web"><img src="https://www.meziantou.net/assets/benchmark-2.png?v=9e81&amp;utm_medium=social&amp;utm_source=web" width="800" height="950" srcset="https://www.meziantou.net/assets/benchmark-2-th-w500-h0.png?v=2ec1&amp;utm_medium=social&amp;utm_source=web 500w,https://www.meziantou.net/assets/benchmark-2-th-w800-h0.png?v=6b39&amp;utm_medium=social&amp;utm_source=web 800w,https://www.meziantou.net/assets/benchmark-2.png?v=9e81&amp;utm_medium=social&amp;utm_source=web 946w" sizes="100vw"></a></p><p>Unless you heavily use the stack, the gain is very small.</p><h2 id="is-it-safe-to-use-th"><a href="#is-it-safe-to-use-th">#</a>Is it safe to use this attribute globally?</h2><p>The C# compiler ensures you don't use a variable before initializing it. So, this is safe to use the attribute in most cases. However, there are at least 3 exceptions that need manual reviews:</p><ul><li><code>unsafe</code> code</li><li><code>stackalloc</code></li><li>P/Invoke</li></ul><p>In unsafe code, you can use uninitialized variables. You should review every location where you use the address of a variable to be sure your code doesn't rely on the fact that the variable is implicitly initialized to its default value. If needed, you can manually initialize the variable.</p><pre><code><span>static</span> <span>unsafe</span> <span><span>void</span></span> <span>Pointer</span><span>(</span><span>)</span>
<span>{</span>
    <span><span>int</span></span> i<span>;</span>
    <span>int</span><span>*</span> pointer_i <span>=</span> <span>&amp;</span>i<span>;</span> <span>// ⚠ The value of i is not initialized to 0</span>

    <span><span>int</span></span> j <span>=</span> <span>0</span><span>;</span>
    <span>int</span><span>*</span> pointer_j <span>=</span> <span>&amp;</span>j<span>;</span> <span>// ok</span>
<span>}</span></code></pre><p>Starting with C# 8, you can use <code>stackalloc</code> without using the <code>unsafe</code> keyword as shown previously in this post.</p><pre><code><span>struct</span> <span>MyStruct</span>
<span>{</span>
    <span>public</span> <span><span>int</span></span> Field1<span>;</span>
    <span>public</span> <span><span>int</span></span> Field2<span>;</span>
<span>}</span>

<span>Span<span>&lt;</span>MyStruct<span>&gt;</span></span> array <span>=</span> <span>stackalloc</span> MyStruct<span>[</span><span>10</span><span>]</span><span>;</span>
array<span>[</span><span>0</span><span>]</span><span>.</span>Field1 <span>=</span> <span>42</span><span>;</span> <span>// ⚠ Other fields are uninitialize which could be problematic</span>
Console<span>.</span><span>WriteLine</span><span>(</span>array<span>[</span><span>0</span><span>]</span><span>.</span>Field2<span>)</span><span>;</span> <span>// ⚠ Unpredictable output as Field2 is not initialized</span>

array<span>[</span><span>1</span><span>]</span> <span>=</span> <span>new</span> <span>MyStruct</span> <span>{</span> Field1 <span>=</span> <span>42</span> <span>}</span><span>;</span> <span>// Ok as the ctor will initialize the values correctly</span></code></pre><p>If you call a P/Invoke method involving an out parameter, you should be sure to validate that the native method always writes the value for the case where you expect the value to be initialized.</p><pre><code><span><span>int</span></span> a<span>;</span>
NativeMethods<span>.</span><span>Sample</span><span>(</span><span>out</span> a<span>)</span><span>;</span> <span>// ⚠ Be sure that Sample writes the out parameter in any case where you need it</span>
Console<span>.</span><span>WriteLine</span><span>(</span>a<span>)</span><span>;</span> <span>// ⚠ Unpredictable output if Sample doesn't set the value of the variable</span></code></pre><h2 id="conclusion-82bd01"><a href="#conclusion-82bd01">#</a>Conclusion</h2><p>Use the <code>[SkipLocalsInit]</code> attribute if you need to get the maximum performance possible. It's a quick win, but the gains are also very small for most use cases.</p><h2 id="addition-resources-82bd01"><a href="#addition-resources-82bd01">#</a>Addition resources</h2><ul><li><a href="https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.skiplocalsinitattribute?view=net-5.0">SkipLocalsInitAttribute Class<i></i></a></li><li><a href="https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-5/">Performance Improvements in .NET 5<i></i></a></li><li><a href="https://github.com/dotnet/aspnetcore/issues/26586">Perf: Investigate applying SkipLocalsInitAttribute<i></i></a></li></ul><p>Do you have a question or a suggestion about this post? <a href="https://www.meziantou.net/contact.htm?utm_medium=social&amp;utm_source=web">Contact me!</a></p></div></div>]]>
            </description>
            <link>https://www.meziantou.net/csharp-9-improve-performance-using-skiplocalsinit.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300125</guid>
            <pubDate>Fri, 04 Dec 2020 08:05:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git stash doesn’t have to be scary]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300115">thread link</a>) | @todsacerdoti
<br/>
December 4, 2020 | https://jemma.dev/blog/git-stash | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/git-stash">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It was only when I recently heard someone else say, “git stash is scary” that I realized it was top of my list of fears too. It just usually feels like there’s a chance I’ll just lose all of my in progress work to the depths of stashes and never be able to get the right incantation of <code>git</code> commands to reincarnate my code.</p>

<h3 id="what-does-git-stash-do">What does git stash do?</h3>

<p>Let me backtrack a minute! I haven’t yet explained what <code>git stash</code> even does. On the most basic level, <code>git stash</code> is one way to store in progress work in <code>git</code> for subsequent access, leaving behind a clean working directory.</p>

<p><em>Meta-note</em>: this post will be easiest to follow along if you open up a terminal and play around with <code>git stash</code> as you’re reading! The lack of syntax highlighting makes it a little tricky to see git additions / deletions. You can play around with any git repo you have, or clone <a href="https://github.com/githubtraining/hellogitworld">this hello world one</a> locally to work in a complete sandbox!</p>

<h3 id="stacks">Stacks</h3>

<p>Stashes are more easily understood as a basic last in, first out stack.</p>

<ul>
  <li><code>git stash push</code> (equivalent to <code>git stash</code> when used with no arguments) will push any local changes onto the stash and leave a clean working directory.</li>
</ul>

<div><div><pre><code><span>$ </span>git status
On branch main
Your branch is up to <span>date </span>with <span>'origin/main'</span><span>.</span>

Changes not staged <span>for </span>commit:
  <span>(</span>use <span>"git add &lt;file&gt;..."</span> to update what will be committed<span>)</span>
  <span>(</span>use <span>"git restore &lt;file&gt;..."</span> to discard changes <span>in </span>working directory<span>)</span>
	modified:   README.md

no changes added to commit <span>(</span>use <span>"git add"</span> and/or <span>"git commit -a"</span><span>)</span>

<span>$ </span>git stash push
Saved working directory and index state WIP on main: 6ab43aa Initial commit

<span>$ </span>git status
On branch main
Your branch is up to <span>date </span>with <span>'origin/main'</span><span>.</span>

nothing to commit, working tree clean

</code></pre></div></div>

<p>There are a plethora of arguments we can pass to <code>git stash push</code>. The ones I find most helpful are:</p>

<ul>
  <li><code>-m &lt;message&gt;</code> saves the stash with a message, can be helpful for our future selves</li>
</ul>

<div><div><pre><code><span>$ </span>git stash push <span>-m</span> <span>"description"</span>
Saved working directory and index state On main: description
</code></pre></div></div>

<ul>
  <li><code>-p</code> patches changes (used like <code>git add -p</code>), allowing us to select which hunks to add to the stash. <a href="https://www.gnu.org/software/diffutils/manual/html_node/Detailed-Unified.html">Hunks</a> are areas where two files differ. Git will partition files into hunks for us!</li>
</ul>

<div><div><pre><code><span>$ </span>git stash push <span>-p</span>
....
Details about the hunk
....
<span>(</span>1/1<span>)</span> Stash this hunk <span>[</span>y,n,q,a,d,e,?]?
</code></pre></div></div>

<ul>
  <li><code>-u</code> includes untracked files in the stash. Without this flag, a file that <code>git</code> had never seen before would not be included in a stash</li>
</ul>

<div><div><pre><code><span>$ </span><span>touch </span>new-file
<span>$ </span>git status
On branch main
Your branch is up to <span>date </span>with <span>'origin/main'</span><span>.</span>

Untracked files:
  <span>(</span>use <span>"git add &lt;file&gt;..."</span> to include <span>in </span>what will be committed<span>)</span>
	new-file

nothing added to commit but untracked files present <span>(</span>use <span>"git add"</span> to track<span>)</span>

<span>$ </span>git stash push <span>-u</span>
Saved working directory and index state WIP on main: 6ab43aa Initial commit
</code></pre></div></div>

<ul>
  <li><code>-k</code> keeps the files (or hunks) which were staged. Without this option, when we apply a stash, nothing will be staged. More on applying in the next section!</li>
</ul>

<h3 id="accessing-the-stash">Accessing the stash</h3>

<p>Okay, we can now push changes onto the stash. But…. they’re still the stash abyss if we have no way of accessing them.</p>

<p><code>git stash list</code> shows us what is on the stash:</p>

<div><div><pre><code><span>$ </span>git stash list
stash@<span>{</span>0<span>}</span>: On main: Clear description of these changes
stash@<span>{</span>1<span>}</span>: WIP on main: 6ab43aa Initial commit
</code></pre></div></div>

<p>This is where the <code>-m</code> message flag from earlier will be incredibly helpful. The first item in my stash had a message (<code>Clear description of these changes</code>), the second did not.</p>

<p>Okay, okay. We can now <em>see</em> what’s on the stash. But how do we access anything on the stash? Or remove it from the stash?</p>

<p><code>git stash show</code> will show us the difference between the top item on the stash, and our current working directory:</p>

<div><div><pre><code><span>$ </span>git stash show
 README.md | 1 +
 1 file changed, 1 insertion<span>(</span>+<span>)</span>
</code></pre></div></div>

<p>If we want to reference a different set of changes on the stash, and not the most recent one, we can use the stash index of those changes. As we can see above, each item on the stash has an index, and can be referred to by <code>stash@{index}</code></p>

<p>So, to see the set of changes in the next item on our stack, we can run:</p>

<div><div><pre><code><span>$ </span>git stash show stash@<span>{</span>1<span>}</span>
 README.md | 2 +-
 1 file changed, 1 insertion<span>(</span>+<span>)</span>, 1 deletion<span>(</span>-<span>)</span>
</code></pre></div></div>
<p>Neat, so we now know how to get the differences and look at what’s in the stash. But to actually access what’s on the stash, we’ll need <code>git stash apply [&lt;stash&gt;]</code>. It similarly can take an argument with the stash index to reference something later in the stash. If no argument is provided, it will default to the most recent set of changes we put in the stash (the ones at <code>stash@{0}</code>)</p>

<div><div><pre><code><span>$ </span>git stash apply stash@<span>{</span>1<span>}</span>
On branch main
Your branch is up to <span>date </span>with <span>'origin/main'</span><span>.</span>

Changes not staged <span>for </span>commit:
  <span>(</span>use <span>"git add &lt;file&gt;..."</span> to update what will be committed<span>)</span>
  <span>(</span>use <span>"git restore &lt;file&gt;..."</span> to discard changes <span>in </span>working directory<span>)</span>
	modified:   README.md

no changes added to commit <span>(</span>use <span>"git add"</span> and/or <span>"git commit -a"</span><span>)</span>
</code></pre></div></div>

<h4 id="removing-from-the-stash">Removing from the stash</h4>

<p>However, <code>git stash apply</code> will not <em>remove</em> the changes from the stash. If we look at the stash now, we’ll see it’s the same as it was:</p>

<div><div><pre><code><span>$ </span>git stash list
stash@<span>{</span>0<span>}</span>: On main: Clear description of these changes
stash@<span>{</span>1<span>}</span>: WIP on main: 6ab43aa Initial commit
</code></pre></div></div>

<p>In order to remove a set of changes from the stash, we can use <code>git stash drop [&lt;stash&gt;]</code></p>

<div><div><pre><code><span>$ </span>git stash drop stash@<span>{</span>0<span>}</span>
Dropped refs/stash@<span>{</span>0<span>}</span> <span>(</span>b09812812eb27de2cb49bfd02aba43889362b6de<span>)</span>

<span>$ </span>git stash list
stash@<span>{</span>0<span>}</span>: WIP on main: 6ab43aa Initial commit
</code></pre></div></div>

<p>We can see that the set of changes at <code>stash@{0}</code> are now no longer on the stash, and the set of changes which were at <code>stash@{1}</code> are now at <code>stash@{0}</code>.</p>

<p>If we want to <code>apply</code> and <code>drop</code> a set of changes, we can conveniently use <code>git stash pop [&lt;stash&gt;]</code>. <code>pop</code> will only also <code>drop</code> if there’s no merge conflict.</p>

<p>To clear the stash completely, we can run <code>git stash clear</code>. This is the <em>actual</em> scary command which will cause us to lose any work in progress that you had stashed. Only run <code>git stash clear</code> if you never again want to access what is currently on the stash.</p>

<h3 id="why-stash">Why stash?</h3>

<p>So we’ve learned how to use <code>git stash</code>, but still haven’t covered <em>why</em> to use it. Stashing is intended to be a quick and easy way to get to a clean working state while not losing in progress work. And it is! Both quick, and now hopefully easy!</p>

<p>One example of when I might use <code>git stash</code> is if I’m in progress on some changes, but realize I want to amend a prior commit. I can stash the changes, amend the commit, and then apply the stash to get back to where I was.</p>

<p>Another is if I am trying to experiment with a few different ways to solve a problem, and want small, quick examples down each solution path. I might create stashes with all of my examples, and then pick the best and pursue that set of changes in a branch structure.</p>

<p>Additionally, stashing is especially helpful because it is branch agnostic. That is to say, if we switch branches, our stash will remain the same. This means stashing can also be a convenient way to carry changes through different branches.</p>

<h3 id="when-not-to-stash">When not to stash</h3>

<p>Equally import to why stash is when <em>not</em> to use it.</p>

<p>Stashing was built for convenience, and is not intended to be a permanent way to save work; that’s what branches and commits are for. Stashing also only works locally, you can’t push stashes to a repo or have others pull them down.</p>

<h3 id="branches-from-stash">Branches from stash</h3>

<p>Speaking of branches, another fun feature of stashes is that we can create a branch directly from a stash. This is done using <code>git stash branch &lt;branch_name&gt; [&lt;stash&gt;]</code> This will also drop the changes from the stash, equivalent to a <code>git stash pop</code> not a <code>git stash apply</code>.</p>

<div><div><pre><code><span>$ </span>git stash branch new-branch
Switched to a new branch <span>'new-branch'</span>
On branch new-branch
Changes not staged <span>for </span>commit:
  <span>(</span>use <span>"git add &lt;file&gt;..."</span> to update what will be committed<span>)</span>
  <span>(</span>use <span>"git restore &lt;file&gt;..."</span> to discard changes <span>in </span>working directory<span>)</span>
	modified:   README.md

no changes added to commit <span>(</span>use <span>"git add"</span> and/or <span>"git commit -a"</span><span>)</span>
Dropped refs/stash@<span>{</span>0<span>}</span> <span>(</span>d6a804a40c0b477d8e3be27939310ff677f45670<span>)</span>
</code></pre></div></div>

<h3 id="in-summary">In summary</h3>

<ul>
  <li><code>git stash</code> operates on a LIFO stack of sets of changes</li>
  <li><code>git stash list</code> shows what’s on the stash</li>
  <li><code>git stash push</code> pushes to the stash</li>
  <li><code>git stash apply</code> access changes on the stash</li>
  <li><code>git stash drop</code> removes changes from the stash</li>
  <li><code>git stash pop</code> does an <code>apply</code> and a <code>drop</code></li>
  <li>These default to the most recent item on the stash, to reference another one use <code>stash@{index}</code> where you can determine the index from <code>git stash list</code></li>
  <li>Some of these have flags which make them more convenient, including: <code>-m</code> message, <code>-p</code> patch, <code>-u</code> include untracked files, <code>-k</code> keep staged changes staged</li>
</ul>

<p>Hopefully you, too, can now add <code>git stash</code> to the list of fears you’ve conquered!</p>

<p>For further reading on stashing, take a look at the <a href="https://git-scm.com/docs/git-stash">git stash docs</a>. For further reading on <a href="https://www.brainyquote.com/topics/fear-quotes">conquering fears</a>, here is a favorite quote of mine, “Nothing in life is to be feared, it is only to be understood. Now is the time to understand more, so that we may fear less.” - <a href="https://en.wikipedia.org/wiki/Marie_Curie">Marie Curie</a></p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/git-stash</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300115</guid>
            <pubDate>Fri, 04 Dec 2020 08:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advent of Open Source]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25299743">thread link</a>) | @todsacerdoti
<br/>
December 3, 2020 | http://metaredux.com/posts/2020/12/03/advent-of-open-source.html | <a href="https://web.archive.org/web/*/http://metaredux.com/posts/2020/12/03/advent-of-open-source.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Ah, it’s again this magical time of the year - the Advent!
When I was little I associated it mostly with advent candy boxes
with a different candy for each day of the Advent, but these days
I mostly associate this period with the famous <a href="https://adventofcode.com/">Advent of Code</a>.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<p>As much as I love solving puzzles, I’ve realized lately that probably
it’s not the best use of my limited free time. Last year I opted to do
an <a href="http://metaredux.com/posts/2019/12/01/meta-advent-2019.html">blogging challenge</a>, instead of the Advent of Code, and this
year I’m challenging myself to contribute something (meaningful) to my <a href="http://metaredux.com/projects">open-source
projects</a> every day from the 1st of December to Christmas.
Fun times ahead!</p>

<p>Today is the 3rd of December already, so I guess I have to report what I’ve done so far.</p>

<h2 id="dec-1">Dec 1</h2>

<ul>
  <li>Shipped <a href="https://github.com/rubocop-hq/rubocop/releases/tag/v1.5.0">RuboCop 1.5</a></li>
  <li>Lots of improvements to the <a href="https://guide.clojure.style/">Clojure Style Guide</a>
    <ul>
      <li>New sections on <a href="https://guide.clojure.style/#guiding-principles">guiding principles</a> and <a href="https://guide.clojure.style/#a-note-about-consistency">consistency</a></li>
      <li>Documented the <a href="https://guide.clojure.style/#sources-of-inspiration">sources of inspiration</a></li>
      <li>Added lots of new code examples (e.g. <a href="https://guide.clojure.style/#comments">here</a>)</li>
      <li>Fixed many headings that had broken wording after the automated conversion to the current structure last year (each guideline now has a title, and the titles were auto-generated from the old permalinks associated with the guidelines)</li>
    </ul>
  </li>
</ul>

<p>I hope to gradually clean up the backlog for improvements of the style guide in the months to come. I’ll also mention here that I wouldn’t mind
some volunteers willing to help document the best practices for working with <code>cljc</code> and <code>clojure.spec</code>.</p>

<h2 id="dec-2">Dec 2</h2>

<ul>
  <li>Shipped <a href="https://github.com/rubocop-hq/rubocop/releases/tag/v1.5.1">RuboCop 1.5.1</a></li>
  <li><a href="https://github.com/bbatsov/projectile">Projectile</a>
    <ul>
      <li>Groomed the backlog (replied to some tickets, closed some tickets that were addressed/irrelevant, added tags to everything else)</li>
      <li>Merged a few outstanding PRs (see the <a href="https://github.com/bbatsov/projectile/blob/master/CHANGELOG.md#bugs-fixed">changelog</a> for details)</li>
      <li>Lots of improvements to the documentation site
        <ul>
          <li>Improved <a href="https://docs.projectile.mx/projectile/usage.html">Usage</a> page (better basic setup instructions, plus coverage of the mighty but elusive Projectile Commander)</li>
          <li>Improved <a href="https://docs.projectile.mx/projectile/projects.html">Projects</a> page (in particular, you’ll find there a lot of information about the mythical and mystical <code>projectile-project-root-functions</code>)</li>
          <li>Improved <a href="https://docs.projectile.mx/projectile/configuration.html">Configuration</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>It always feels great to revisit Projectile, as it’s both the first open-source project I ever created and the project I use more than anything else.</p>

<h2 id="dec-3-today">Dec 3 (today)</h2>

<ul>
  <li>More work on Projectile’s documentation and grooming the backlog</li>
  <li>Preparing for another RuboCop bug-fix release (1.5.2 might land later today)</li>
</ul>

<h2 id="looking-forward">Looking Forward</h2>

<p>So, what’s next?
My main priorities for the Advent of OSS are currently:</p>

<ul>
  <li>Polish the Clojure Style Guide</li>
  <li>Ship CIDER 1.0</li>
  <li>Ship Emacs Prelude 1.1</li>
  <li>Clean up Projectile’s backlog</li>
</ul>

<p>I probably won’t be able to achieve them all, but I’ve been told it’s good to be ambitious. If someone wants to help me out, be my guest.
My projects have plenty of tickets tagged with <code>Good First Issue</code> that you might try tackling.</p>

<p>I’ll try to post some updates here every few days, both to keep it
up-to-date with my progress and to keep myself honest. That’s all from
me for now. Keep hacking!</p>

<p><strong>P.S.</strong> In the time-honored tradition of the Advent, I’m inviting all of you to join my on the Christmas OSS adventure and see how far are you willing
to go! It will be fun!</p>



  </div></div>]]>
            </description>
            <link>http://metaredux.com/posts/2020/12/03/advent-of-open-source.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299743</guid>
            <pubDate>Fri, 04 Dec 2020 06:55:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wddng – A Wedding with Tech Support]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25299672">thread link</a>) | @s1hfmnn
<br/>
December 3, 2020 | https://blog.s1h.org/wedding-pwa/ | <a href="https://web.archive.org/web/*/https://blog.s1h.org/wedding-pwa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p>It might earn me the "Nerd of the month" prize, but I want to tell you how (and why) I built a PWA for my own wedding. :)</p><p>Some hard facts first:</p><ol><li>I got married. Yay!</li><li>I initially came up with this idea a few years ago, when my best man got married.</li><li>It might sound super weird at first, but I think my reasons why I did this are legit.</li></ol><h2 id="no-really-why-would-anyone-do-this">No really, why would anyone do this?</h2><p>Back when my best man got married I initially came up with this idea to provide them with an app / website which would allow wedding guests to upload photos and text messages throughout the day to kind of document their wedding day as perceived by others.</p><p>Unfortunately, back then I had to finish my Master's thesis and also had to spend some time in hospitals (which is why I at the end also missed his wedding). But the idea somehow stuck in my mind.</p><p>Fast forward to a few weeks ago, I'm close to getting married myself. And to be honest, it's been my wife who put my idea back on the table.</p><p>Besides the obvious reason that I simply like to learn by building things, I also liked the idea to allow our guests to share their impressions privately. There are dozens of social media platforms to share stuff like this, but in my opinion you'll only capture the "<em>true</em>" spirit (stupid faces, fun stories, you name it) of an event if you provide a way to share data privately. You know, stuff you wouldn't post on your Facebook, Twitter etc. Also I didn't / don't want many pictures from <strong>my</strong> wedding wander through social media.</p><p>Another pleasant side effect of such an app / website would be the possibility to provide our guests with infos. Things like a time table, the meal plan, credits and so on.</p><p>So here's the summary of our requirements:</p><p>Provide an app / website to our guests which:</p><ul><li>Holds event data</li><li>Allows them to upload text messages and / or images</li><li>Is kind of "<em>anti-social</em>". Guests only see their own uploads, only my wife and I see all content</li><li>Doesn't look too sh****</li><li>Runs on various devices ranging from <em>"This should be in a museum!"</em> to <em>"It just came out yesterday!"</em>, including various operating systems</li></ul><h2 id="ok-it-doesn-t-sound-that-stupid-how-did-you-build-it">Ok, it doesn't sound <em>that</em> stupid. How did you build it?</h2><p>At first I came up with the idea of building a cross-platform native app using <a href="https://flutter.io/">Flutter</a>. I've built little demo apps back when it was in alpha state and really liked it, so in case of a native app this would've been my goto solution. But native apps require a proper way to distribute them, which in turn would require an Apple developer account, which in turn would cost me 100$ per year, which is why I discarded my native app idea.</p><p>Having heard a lot of positive things about the possibilities provided by progressive web apps (PWAs), I decided to brush up my frontend web development skills. And since my frontend web development skills were basically non-existent, I decided to do it the hard way, using only plain JS, HTML and CSS.</p><h2 id="sounds-reasonable-but-what-did-you-learn-from-building-the-app">Sounds reasonable, but what did you learn from building the app?</h2><h3 id="things-i-had-not-knowingly-used-before-and-therefore-no-clue-about-">Things I had not (knowingly) used before and therefore no clue about:</h3><ul><li>Polyfills</li><li>Promises</li><li>Fetch API</li><li>Intersection observer API</li><li>Service workers</li><li>Media queries</li><li>CSS transforms</li></ul><h3 id="things-i-wanted-to-try-">Things I wanted to try:</h3><ul><li><a href="https://auth0.com/">Auth0</a> for authentication</li></ul><h3 id="things-i-already-knew-but-still-increased-my-knowledge">Things I already knew, but still increased my knowledge</h3><ul><li>Python backend using <a href="http://flask.pocoo.org/">Flask</a></li></ul><h3 id="things-i-built-myself-to-get-a-better-understanding">Things I built myself to get a better understanding</h3><ul><li>A very basic kind of single page application</li><li>Routing, including authentication for certain routes</li><li>Lazy loading of images</li><li>Custom tailored caching via service worker</li></ul><h2 id="pics-or-it-didn-t-happen-">Pics or it didn't happen!</h2><figure><img src="https://blog.s1h.org/content/images/2020/12/landing.png" alt=""></figure><figure><img src="https://blog.s1h.org/content/images/2020/12/drawer.png" alt=""></figure><figure><img src="https://blog.s1h.org/content/images/2020/12/timetable.png" alt=""></figure><figure><img src="https://blog.s1h.org/content/images/2020/12/menu.png" alt=""></figure><figure><img src="https://blog.s1h.org/content/images/2020/12/image_stream.png" alt=""></figure><h2 id="conclusion">Conclusion</h2><ul><li>The best way to learn new things is to actually use them!</li><li>Having a fixed deadline and quite a few people to show your work to really boosts your motivation (and also increases your fear of failing)!</li><li>I've built a responsive, mobile first, material design website which supports modern browsers (Chrome, FireFox, Samsung Internet, Safari) from scratch</li><li>Learned a lot about responsive design, browser peculiarities and front-end development in general</li><li>I hope the result does not look too bad, comments are welcome!</li><li>I enjoyed the design part more than I thought (more on that later)</li><li>It worked! :)</li></ul><p>This post has skipped all technical details and should picture my motivation as well a high level overview. A more technical post will follow, but right now I'm too tired.</p><p>If this has got you interested, feel free to contact me via comments, mail, Twitter etc.</p><p>So long</p><p>Simon</p>
                                </div></div>]]>
            </description>
            <link>https://blog.s1h.org/wedding-pwa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299672</guid>
            <pubDate>Fri, 04 Dec 2020 06:39:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monoliths as a Service]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25299598">thread link</a>) | @gdeglin
<br/>
December 3, 2020 | https://www.themostfamousartist.com/maas | <a href="https://web.archive.org/web/*/https://www.themostfamousartist.com/maas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a13f76d094074a98b8e4"><p><h3>PO BOX 4115</h3><h3>SANTA FE, NM 87502</h3><h3><strong>© 2020 THE MOST FAMOUS ARTIST, LLC</strong></h3></p></div></div>]]>
            </description>
            <link>https://www.themostfamousartist.com/maas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299598</guid>
            <pubDate>Fri, 04 Dec 2020 06:22:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faroe Island roundabout under the Atlantic Ocean]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25299574">thread link</a>) | @sohkamyung
<br/>
December 3, 2020 | https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/ | <a href="https://web.archive.org/web/*/https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1224" class="page">
	<!-- .entry-header -->
	<div>
		<p><img src="http://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o.jpg" alt="" width="2000" height="829" srcset="https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o.jpg 2000w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-300x124.jpg 300w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-1024x424.jpg 1024w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-768x318.jpg 768w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-1536x637.jpg 1536w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-250x104.jpg 250w, https://nordfra.dk/wp-content/uploads/2020/12/128669834_3552788624799306_5681539663523713154_o-350x145.jpg 350w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></p>
<p>The Eysturoyartunnilin (or Eysturoy Tunnel, earlier known as Skálafjarðartunnilin) is a large infrastructure project which connects the island of Streymoy to the island of Eysturoy through a sub-sea road tunnel under the Tangafjørður sound in the Faroe Islands. It also crosses the southern part of Skálafjørður and connects the towns of Runavík on the eastern side and Strendur on the western side of the fjord. Altogether, the three-branch sub-sea tunnel measures 11.24 kilometres (6.8 miles) long, including an underwater roundabout. Construction costs are estimated to be around a billion DKK. It will open for traffic in December 2020.</p>
	</div><!-- .entry-content -->
</article><!-- #post-1224 -->

		</main><!-- #main -->
	</div><!-- #primary -->
</div><!-- .wrap -->


		</div><!-- #content -->

		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299574</guid>
            <pubDate>Fri, 04 Dec 2020 06:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostGraphile – PostgreSQL Schema Design]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25299458">thread link</a>) | @rahimnathwani
<br/>
December 3, 2020 | https://www.graphile.org/postgraphile/postgresql-schema-design/#authentication-and-authorization | <a href="https://web.archive.org/web/*/https://www.graphile.org/postgraphile/postgresql-schema-design/#authentication-and-authorization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Postgres database is rich with features well beyond that of any other
database. However, most developers do not know the extent to which they can
leverage the features in Postgres to completely express their application
business logic in the database.</p>
<p>Often developers may find themselves re-implementing authentication and
authorization in their apps, when Postgres comes with application level security
features out of the box. Or perhaps developers may rewrite basic insert
functions with some extra app logic where that too may be handled in the
database.</p>
<p>This reimplementation of features that come with Postgres is not just an
inefficient way to spend developer resources, but may also result in an
interface that is slower than if the logic was implemented in Postgres itself.
PostGraphile aims to make developers more efficient and their APIs faster by
packaging the repeatable work in one open source project that encourages
community contributions.</p>
<p>In this tutorial we will walk through the Postgres schema design for a forum
application with users who can login and write forum posts. While we will
discuss how you can use the schema we create with PostGraphile, this article
should be useful for anyone designing a Postgres schema.</p>
<p>If you haven't installed PostGraphile already, you can follow our
<a href="https://www.graphile.org/postgraphile/quick-start-guide/">Quick Start Guide</a> to get PostGraphile up and
running.</p>
<h3 id="table-of-contents"><a href="#table-of-contents" aria-label="table of contents permalink"></a>Table of Contents</h3>
<ul>
<li>
<p><a href="#the-basics">The Basics</a></p>
<ul>
<li><a href="#setting-up-your-schemas">Setting Up Your Schemas</a></li>
<li><a href="#the-person-table">The Person Table</a></li>
<li><a href="#table-documentation">Table Documentation</a></li>
<li><a href="#the-post-table">The Post Table</a></li>
</ul>
</li>
<li>
<p><a href="#database-functions">Database Functions</a></p>
<ul>
<li><a href="#set-returning-functions">Set Returning Functions</a></li>
<li><a href="#triggers">Triggers</a></li>
</ul>
</li>
<li>
<p><a href="#authentication-and-authorization">Authentication and Authorization</a></p>
<ul>
<li><a href="#storing-emails-and-passwords">Storing Emails and Passwords</a></li>
<li><a href="#registering-users">Registering Users</a></li>
<li><a href="#postgres-roles">Postgres Roles</a></li>
<li><a href="#json-web-tokens">JSON Web Tokens</a></li>
<li><a href="#logging-in">Logging In</a></li>
<li><a href="#using-the-authorized-user">Using the Authorized User</a></li>
<li><a href="#grants">Grants</a></li>
<li><a href="#row-level-security">Row Level Security</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h3 id="the-basics"><a href="#the-basics" aria-label="the basics permalink"></a>The Basics</h3>
<h4 id="setting-up-your-schemas"><a href="#setting-up-your-schemas" aria-label="setting up your schemas permalink"></a>Setting Up Your Schemas</h4>
<p>All of our database objects will go into one or two custom Postgres schemas. A
schema is essentially a namespace, it allows you to create tables with the same
name like <code>a.person</code> and <code>b.person</code>.</p>
<p>You can name your schema anything, we recommend naming your schema after your
app. This way if you are working on multiple apps in the same database (this
might only realistically happen in development), you can easily query the
databases of the different apps. We are going to create two schemas:
<code>forum_example</code>, and <code>forum_example_private</code>. To create these schemas we use the
<a href="https://www.postgresql.org/docs/current/static/sql-createschema.html"><code>CREATE SCHEMA</code></a>
command.</p>
<div data-language="sql"><pre><code><span>create</span> <span>schema</span> forum_example<span>;</span>
<span>create</span> <span>schema</span> forum_example_private<span>;</span></code></pre></div>
<p>You could create more or less schemas, it is all up to you and how you want to
structure your database. We decided to create two schemas. One of which,
<code>forum_example</code>, is meant to hold data users can see, whereas
<code>forum_example_private</code> will never be directly accessible to users.</p>
<p>Theoretically we want a user to be able to log in directly to our Postgres
database, and only be able to create, read, update, and delete data for their
user all within SQL. This is a mindshift from how we traditionally use a SQL
database. Normally, we assume whoever is querying the database has full
visibility into the system as the only one with database access is our
application. In this tutorial, we want to restrict access at the database level.
Don’t worry though! Postgres is very secure about this, users will have no more
permissions than that which you explicitly grant.</p>
<blockquote>
<p><strong>Note:</strong> When starting PostGraphile, you will want to use the name of the
schema you created with the <code>--schema</code> option, like so:
<code>postgraphile --schema forum_example</code>. Also, don’t forget to add the <code>--watch</code>
flag, with watch mode enabled PostGraphile will update your API as we add
tables and types throughout this tutorial.</p>
</blockquote>
<h4 id="the-person-table"><a href="#the-person-table" aria-label="the person table permalink"></a>The Person Table</h4>
<p>Now we are going to create the tables in our database which will correspond to
our users. We will do this by running the Postgres
<a href="https://www.postgresql.org/docs/current/static/sql-createtable.html"><code>CREATE TABLE</code></a>
command. Here is the definition for our person table:</p>
<div data-language="sql"><pre><code><span>create</span> <span>table</span> forum_example<span>.</span>person <span>(</span>
  id               <span>serial</span> <span>primary</span> <span>key</span><span>,</span>
  first_name       <span>text</span> <span>not</span> <span>null</span> <span>check</span> <span>(</span>char_length<span>(</span>first_name<span>)</span> <span>&lt;</span> <span>80</span><span>)</span><span>,</span>
  last_name        <span>text</span> <span>check</span> <span>(</span>char_length<span>(</span>last_name<span>)</span> <span>&lt;</span> <span>80</span><span>)</span><span>,</span>
  about            <span>text</span><span>,</span>
  created_at       <span>timestamp</span> <span>default</span> <span>now</span><span>(</span><span>)</span>
<span>)</span><span>;</span></code></pre></div>
<p>Now we have created a table with <code>id</code>, <code>first_name</code>, <code>last_name</code>, <code>about</code>, and
<code>created_at</code> columns (we will add an <code>updated_at</code> column later). Let’s break
down exactly what each line in this command does, we will only do this once. If
you already understand, you can skip ahead.</p>
<ol>
<li><code>create table forum_example.person</code>: This tells Postgres that we are
creating a table in the <code>forum_example</code> schema named <code>person</code>. This table
will represent all of our forum’s users.</li>
<li><code>id serial primary key</code>: This line establishes an auto-incrementing id field
which is always guaranteed to be unique. The first person we create will
have an id of 1, the second user will have an id of 2, and so on. The
<code>primary key</code> bit is also very important. PostGraphile will use the
<code>primary key</code> of a table in many places to uniquely identify an object,
including the globally unique id field.</li>
<li><code>first_name text not null check (char_length(first_name) &lt; 80)</code>: We want all
of our users to enter their first name and last name seperately, so this
column definition will create a column named <code>first_name</code>, of type <code>text</code>,
that is required (<code>not null</code>), and that must be less than 80 characters long
(<code>check (char_length(first_name) &lt; 80)</code>).
<a href="https://www.postgresql.org/docs/current/static/ddl-constraints.html">Check constraints</a>
are a very powerful feature in Postgres for data validation.</li>
<li><code>last_name text check (char_length(last_name) &lt; 80)</code>: This is very similar
to our column definition for <code>first_name</code>, except it is missing <code>not null</code>.
This means that unlike the <code>first_name</code> column, <code>last_name</code> is not required.</li>
<li><code>about text</code>: We want users to be able to express themselves! So they get to
write a mini forum post which will go on their profile page.</li>
<li><code>created_at timestamp default now()</code>: This final column definition will
provide us with some extra meta-information about their user. If not
specified explicitly, the <code>created_at</code> timestamp will default to the time
the row was inserted.</li>
</ol>
<p>And that’s our person table! Pretty simple, right?</p>
<p>The syntax and features of the Postgres
<a href="https://www.postgresql.org/docs/current/static/sql-createtable.html"><code>CREATE TABLE</code></a>
command are fairly easy to learn and understand. Creating tables is the easiest,
but also the most fundamental part of your schema design.</p>
<blockquote>
<p><strong>Note:</strong> We prefer singular identifers like <code>forum_example.person</code> over
<code>forum_example.people</code> because when you create a table, it is like you are
creating a class in a statically typed language. Classes have singular names
like “Person” while collections will often have plural names like “People.”
Table as a class is a better analogy than table as a collection because
Postgres itself will internally call tables “classes.”</p>
</blockquote>
<blockquote>
<p><strong>Note:</strong> In case you don’t like serial id of our table above, an alternative
to the <code>serial</code> primary key is UUIDs. To use UUIDs you would just need to add
the popular UUID extension, <code>uuid-ossp</code>, in your database setup, and specify a
default in your table creation. Like so:</p>
<div data-language="sql"><pre><code><span>create</span> extension <span>if</span> <span>not</span> <span>exists</span> <span>"uuid-ossp"</span><span>;</span>

<span>create</span> <span>table</span> forum_example<span>.</span>person <span>(</span>
  id uuid <span>primary</span> <span>key</span> <span>default</span> uuid_generate_v1mc<span>(</span><span>)</span><span>,</span>
  <span>.</span><span>.</span><span>.</span>
<span>)</span><span>;</span></code></pre></div>
<p>Alternatively you could use fully random UUIDs:</p>
<div data-language="sql"><pre><code><span>create</span> extension <span>if</span> <span>not</span> <span>exists</span> <span>"pgcrypto"</span><span>;</span>

<span>create</span> <span>table</span> forum_example<span>.</span>person <span>(</span>
  id uuid <span>primary</span> <span>key</span> <span>default</span> gen_random_uuid<span>(</span><span>)</span><span>,</span>
  <span>.</span><span>.</span><span>.</span>
<span>)</span><span>;</span></code></pre></div>
<p>There are pros and cons to both approaches, choose what works best for your
application!</p>
</blockquote>
<h4 id="table-documentation"><a href="#table-documentation" aria-label="table documentation permalink"></a>Table Documentation</h4>
<p>Now that we have created our table, we want to document it within the Postgres
database. By adding comments to our table and its columns using the Postgres
<a href="https://www.postgresql.org/docs/current/static/sql-comment.html"><code>COMMENT</code></a>
command, we will allow tools like PostGraphile to display rich domain specific
documentation.</p>
<p>To add comments, just see the SQL below:</p>
<div data-language="sql"><pre><code><span>comment</span> <span>on</span> <span>table</span> forum_example<span>.</span>person <span>is</span> <span>'A user of the forum.'</span><span>;</span>
<span>comment</span> <span>on</span> <span>column</span> forum_example<span>.</span>person<span>.</span>id <span>is</span> <span>'The primary unique identifier for the person.'</span><span>;</span>
<span>comment</span> <span>on</span> <span>column</span> forum_example<span>.</span>person<span>.</span>first_name <span>is</span> <span>'The person’s first name.'</span><span>;</span>
<span>comment</span> <span>on</span> <span>column</span> forum_example<span>.</span>person<span>.</span>last_name <span>is</span> <span>'The person’s last name.'</span><span>;</span>
<span>comment</span> <span>on</span> <span>column</span> forum_example<span>.</span>person<span>.</span>about <span>is</span> <span>'A short description about the user, written by the user.'</span><span>;</span>
<span>comment</span> <span>on</span> <span>column</span> forum_example<span>.</span>person<span>.</span>created_at <span>is</span> <span>'The time this person was created.'</span><span>;</span></code></pre></div>
<p>Incredibly simple, yet also incredibly powerful.</p>
<blockquote>
<p><strong>Note:</strong> Feel free to write your comments in Markdown! Most tools, including
GraphiQL which PostGraphile uses, will render your comments with the
appropriate styles.</p>
</blockquote>
<p>With this we have completed our person table, now let’s create a table for our
forum posts.</p>
<h4 id="the-post-table"><a href="#the-post-table" aria-label="the post table permalink"></a>The Post Table</h4>
<p>The users of our forum will want to be able to create posts. That’s the entire
reason we have a forum after all. To create the post table we go through a very
similar process as creating our <code>forum_example.person</code> table, but first we want
to create a type we will use in one of the columns. See the SQL below:</p>
<div data-language="sql"><pre><code><span>create</span> <span>type</span> forum_example<span>.</span>post_topic <span>as</span> <span>enum</span> <span>(</span>
  <span>'discussion'</span><span>,</span>
  <span>'inspiration'</span><span>,</span>
  <span>'help'</span><span>,</span>
  <span>'showcase'</span>
<span>)</span><span>;</span></code></pre></div>
<p>The Postgres
<a href="https://www.postgresql.org/docs/current/static/sql-createtype.html"><code>CREATE TYPE</code></a>
command will let you create a custom type in your database which will allow you
to do some really cool things. You can create a
<a href="https://www.postgresql.org/docs/current/static/rowtypes.html">composite type</a>
which is basically a typed object in GraphQL terms, you can create a
<a href="https://www.postgresql.org/docs/current/static/rangetypes.html">range type</a>
which represents exactly what you might think, or you can create an
<a href="https://www.postgresql.org/docs/current/static/datatype-enum.html">enum type</a>
which is what we did here.</p>
<p>Enum types are a static set of values, you <em>must</em> use one of the string values
that make up the enum in any column of the enum’s type. Having this type is
useful for us, because we want our forum posts to have one, or none, topics so
user’s may easily see what a post is about.</p>
<blockquote>
<p><strong>Note:</strong> PostGraphile implements custom handling for user-defined types. An
enum type like that defined above will be turned into a GraphQL enum that
looks like:</p>
<div data-language="graphql"><pre><code><span>enum</span> <span>PostTopic</span> <span>{</span>
  <span>DISCUSSION</span>
  <span>INSPIRATION</span>
  <span>HELP</span>
  <span>SHOWCASE</span>
<span>}</span></code></pre></div>
<p>You can also create custom composite types which will turn into GraphQL object
types with PostGraphile.</p>
<div data-language="sql"><pre><code><span>create</span> <span>type</span> my_schema<span>.</span>my_type <span>as</span> <span>(</span>
  foo <span>integer</span><span>,</span>
  bar <span>integer</span>
<span>)</span><span>;</span></code></pre></div>
<p>Would become the following GraphQL type:</p>
<div data-language="graphql"><pre><code><span>type</span> <span>MyType</span> <span>{</span>
  <span>foo</span><span>:</span> Int
  <span>bar</span><span>:</span> Int
<span>}</span></code></pre></div>
</blockquote>
<p>Now it is time to actually create our post table:</p>
<div data-language="sql"><pre><code><span>create</span> <span>table</span> …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.graphile.org/postgraphile/postgresql-schema-design/#authentication-and-authorization">https://www.graphile.org/postgraphile/postgresql-schema-design/#authentication-and-authorization</a></em></p>]]>
            </description>
            <link>https://www.graphile.org/postgraphile/postgresql-schema-design/#authentication-and-authorization</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299458</guid>
            <pubDate>Fri, 04 Dec 2020 05:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Manage My Random Daily Notes]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 180 (<a href="https://news.ycombinator.com/item?id=25299442">thread link</a>) | @hachibu
<br/>
December 3, 2020 | https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/ | <a href="https://web.archive.org/web/*/https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/featured.png"><figcaption><p>Illustration: Hachibu</p></figcaption></figure><p>For years, I kept track of random notes by creating a text or Markdown
file on my desktop. And at the end of the day, I would delete that file and
start over again the next day. Inspired by the minimalism of <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>,
I created a similar system to manage my own notes.</p><p>Keep reading for more details or skip to the code: <a href="https://github.com/hachibu/note.sh">github.com/hachibu/note.sh</a>.</p><h4 id="introduction">Introduction</h4><p>As I mentioned before, I used to keep a single notes file on my desktop, and I
would delete it everyday. I would use this notes file to keep track of random
thoughts and details related to my work and personal life. My notes file might
contain code snippets from work, inspirational quotes, or it might have my
latest and greatest open-source software idea, or maybe even the beginning of a
new blog post. Anyway, I loved the simplicity of it, and I didn’t want any more
apps, databases or logins in my life.</p><p>But it wasn’t until I started using <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>
that I considered writing a script to manage my own notes. The brilliant part
about <code>todo-txt-cli</code> is that it’s just text files stored in my Dropbox and a
small shell script to interface with those files.</p><p>Inspired by the minimalism of <code>todo-txt-cli</code>, I built <a href="https://github.com/hachibu/note.sh">note.sh</a>.
In total, the entire project consists of 1 Bash script, 1 environment variable
to configure the notes directory and 1 symlink to install it to your
<code>/usr/local/bin</code> directory.</p><h4 id="how-it-works">How It Works</h4><p>The way it works is that every time I run the script, it opens the note for that
day in my editor of choice. For example, if today was December 2, 2020 then the
script would open a file named <code>2020-12-02.md</code> in the notes directory.</p><p>I use Vim as my editor, and I have my notes stored on Dropbox so I can access
them on all of my computers. So, my shell RC file looks like this.</p><div><pre><code data-lang="shell"><span>export</span> <span>EDITOR</span><span>=</span><span>"vim"</span>
<span>export</span> <span>NOTE_DIR</span><span>=</span><span>"</span><span>$HOME</span><span>/Dropbox/Notes"</span>
</code></pre></div><p>And my Dropbox directory looks like this.</p><p><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/dropbox-screenshot.png" alt="Dropbox Screenshot"></p><p>For searching, the script accepts a pattern and runs a recursive grep over the
notes directory. I chose grep because I use this script on both Mac and Linux,
and I wanted the script to be as portable as possible.</p><h4 id="conclusion">Conclusion</h4><p>I’ve been using this script for several months across several computers, and I
still love it. I don’t search as often as I thought I would, but it’s comforting
to know it’s all there if I need it. I also ended up creating an alias for my
script so all I need to type is the letter <code>n</code> to run the script.</p><p>In the future, I’d like to add a test suite to the code base, figure out how
to create a Homebrew formula, and add archiving for older notes.</p></div></div>]]>
            </description>
            <link>https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299442</guid>
            <pubDate>Fri, 04 Dec 2020 05:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pentagon’s Unidentified Aerial Phenomena Task Force]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25299329">thread link</a>) | @weare138
<br/>
December 3, 2020 | https://www.thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force/ | <a href="https://web.archive.org/web/*/https://www.thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span data-preserver-spaces="true">In an exclusive feature for&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">, U.S. military and intelligence officials, as well as Pentagon emails, offer an unprecedented glimpse behind the scenes of what’s currently going on with The Pentagon’s investigation into UFOs, or as they term them, “Unidentified Aerial Phenomena” (UAP).&nbsp;&nbsp;</span></p><p><span data-preserver-spaces="true">For the last two years, the Department of Defense’s newly revamped “Unidentified Aerial Phenomena Task Force” (or UAPTF) has been busy briefing lawmakers, Intelligence Community stakeholders, and the highest levels of the U.S. military on encounters with what they say are mysterious airborne objects that defy conventional explanations.&nbsp;</span></p><p><span data-preserver-spaces="true">Along with classified briefings, multiple senior U.S. officials with direct knowledge of the matter say two classified intelligence reports on UAP have been widely distributed to the U.S. Intelligence Community. Numerous sources from various government agencies told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true"> that these reports include clear photographic evidence of UAP. The reports also explicitly state that the Task Force is considering the possibility that these unidentified objects could, as stated by one source from the U.S. Intelligence Community said, be operated by “intelligences of unknown origin.”&nbsp;</span></p><p><span data-preserver-spaces="true">Significantly, a retired U.S. Air Force brigadier general and head of RAND corporation’s Space Enterprise Initiative has—for the first time—gone on record to discuss some of the most likely explanations for UAP. His responses were surprising.</span></p> <figure id="attachment_1293" aria-describedby="caption-attachment-1293"><img src="https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1.jpg" alt="US Navy" width="2560" height="1704" srcset="https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1.jpg 2560w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-1024x682.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-768x511.jpg 768w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-1536x1022.jpg 1536w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-2048x1363.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"><figcaption id="caption-attachment-1293">U.S. Navy photo by Mass Communication Specialist Seaman Hillary Becke</figcaption></figure><h2><strong><span data-preserver-spaces="true">Briefings At The Highest Levels&nbsp;</span></strong></h2><p><span data-preserver-spaces="true">In June, the Senate Select Committee on Intelligence’s </span><a href="https://www.govinfo.gov/content/pkg/CRPT-116srpt233/pdf/CRPT-116srpt233.pdf" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">FY2021 Intelligence Authorization Act</span></a><span data-preserver-spaces="true"> contained an intriguing section titled report on “Advanced Aerial Threats.” In the inclusion, the committee gave an eye-opening official hint (in recent history) the government takes UFOs seriously by offering its support for the “efforts of the Unidentified Aerial Phenomenon Task Force at the Office of Naval Intelligence.” The Intelligence Committee additionally requested an unclassified report detailing the analysis of “UAP” or “Anomalous Aerial Vehicles.”&nbsp;</span></p><p><span data-preserver-spaces="true">Though already acknowledged by the Intelligence Committee, in mid-August, the Pentagon&nbsp;</span><a href="https://www.thedebrief.org/the-dod-has-officially-announced-it-has-a-uap-task-force-heres-what-that-means/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">formally acknowledged</span></a><span data-preserver-spaces="true">&nbsp;they had established a task force looking into UAP. In a press announcement, the Secretary of Defense’s Office&nbsp;</span><a href="https://www.defense.gov/Newsroom/Releases/Release/Article/2314065/establishment-of-unidentified-aerial-phenomena-task-force/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">stated</span></a><span data-preserver-spaces="true">, “the UAPTF’s mission will be to detect, analyze and catalog UAPs that could potentially pose a threat to U.S. national security.” According to the release, authority for the Task Force was approved by the DoD’s chief operating officer, Deputy Secretary of Defense David L. Norquist.&nbsp;</span></p><p><span data-preserver-spaces="true">The summer news of the establishment of the UAPTF seemingly suggests—for the first time since the shuttering of Project Blue Book (the Air Force’s official investigations into UFOs) in 1969—that the Pentagon is now taking the subject of UFOs seriously.&nbsp;</span></p><p><span data-preserver-spaces="true">However, an internal email obtained by&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">shows that almost one year before the DoD’s announcement, the highest levels of the U.S. military were already being briefed on UAP.&nbsp;</span></p> <figure id="attachment_1299" aria-describedby="caption-attachment-1299"><img src="https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM.png" alt="UAP Task Force Briefs the Joint Chiefs of Staff " width="1424" height="616" srcset="https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM.png 1424w,https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-300x130.png 300w,https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-1024x443.png 1024w,https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-768x332.png 768w" sizes="(max-width: 1424px) 100vw, 1424px"><figcaption id="caption-attachment-1299">Copy of the Email Obtained by The Debrief via FOIA.</figcaption></figure><p><span data-preserver-spaces="true">The email, obtained via Freedom of Information Act request, shows an October 16th, 2019 exchange between then Vice Chief of Naval Operations, Admiral Robert Burke, and current Vice Chief of Staff for the Air Force General Stephen “Steve” Wilson.&nbsp;</span></p><p><span data-preserver-spaces="true">In the email, Adm. Burke tells Gen. Wilson, “Recommend you take the brief I just received from our Director of Naval Intelligence VADM Matt Kohler, on Unidentified Aerial Phenomena (UAP).” Adm. Burke concludes the email, “SECNAV [Secretary of the Navy] will get the same brief tomorrow at 1000.”&nbsp;</span></p><p><span data-preserver-spaces="true">The “SECNAV” referenced in Adm. Burke’s email was then-Secretary of the Navy, Richard V. Spencer. A little over a month after this UAP briefing, Spencer was fired by then-Secretary of Defense Mark Esper over public disagreements stemming from a&nbsp;</span><a href="https://www.theguardian.com/us-news/2019/nov/28/navy-secretary-richard-spencer-donald-trump-navy-seal" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">series of controversies&nbsp;</span></a><span data-preserver-spaces="true">involving the court-martial of Navy SEAL Eddie Gallagher.</span></p><p><span data-preserver-spaces="true">Speaking on background, one U.S. Defense official lamented that a lack of continuity with DoD leadership might have hindered some of the UAPTF’s work. Within the past 24 months, there have been four different Secretaries of the Navy and five additional Secretaries of Defense. Vice Admiral Matt Kohler, noted for having provided the briefings, retired after 36 years with the Navy in June of this year.&nbsp;</span></p> <figure id="attachment_1322" aria-describedby="caption-attachment-1322"><img src="https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1.jpg" alt="Vice Adm. Robert Burke" width="2560" height="1707" srcset="https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1.jpg 2560w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-1024x683.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-768x512.jpg 768w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-1536x1024.jpg 1536w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-2048x1366.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"><figcaption id="caption-attachment-1322">Vice Adm. Robert Burke – U.S. Navy photo by Mass Communication Specialist 3rd Class Charles D. Gaddis IV</figcaption></figure><p><span data-preserver-spaces="true">Reaching out to several active government officials and individuals who retain their government-issued security clearances,&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">&nbsp;learned that last fall was a busy time for the UAPTF.&nbsp;</span><span data-preserver-spaces="true">On October 21st, 2019, a briefing on UAP was conducted at the Pentagon for several Senate Armed Services Committee staffers.&nbsp;</span></p><p><span data-preserver-spaces="true">Attendees at the meeting told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">&nbsp;that they were provided information on two previous DoD-backed UFO programs: The Advanced Aerial Weapons Systems Applications Program (AAWSAP) and the Advanced Aerospace Threat Identification Program (AATIP). They were also briefed on “highly sensitive categories of UFO investigations.” Only two days later on October 23rd, staffers with the Senate Select Intelligence Committee were provided the same information in a meeting on Capitol Hill.&nbsp;</span></p><p><span data-preserver-spaces="true">A former private contractor for AAWSAP and AATIP, Dr. Hal Puthoff, confirmed for&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">he was one of a handful of persons who conducted the October briefings. “I have been invited to brief congressional staffers on the Senate Armed Services Committee on UAP matters in the last couple of years,” Puthoff said in an email, “and have done so on more than one occasion.” Dr. Puthoff described the staffers during these meetings as being “engaged,” and provided “positive responses, [and] more details always being requested.”&nbsp;</span></p> <figure id="attachment_1325" aria-describedby="caption-attachment-1325"><img src="https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1.jpg" alt="The Pentagon Press Briefing Room" width="2560" height="1709" srcset="https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1.jpg 2560w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-1024x684.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-768x513.jpg 768w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-1536x1025.jpg 1536w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-2048x1367.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"><figcaption id="caption-attachment-1325">The Pentagon Press Briefing Room seal (Credit: DoD/photo by Lisa Ferdinando)</figcaption></figure><p><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">reached out to the Assistant Secretary of Defense for Public Affairs Office and DoD Executive Services Office and formally requested an interview with someone authorized to speak on the UAP briefings with the Joint Chiefs of Staff. In an email, Senior Strategist and Pentagon spokesperson Susan Gough responded, “To maintain operations security, which includes not disseminating information publicly that may be useful to our adversaries, DOD does not discuss publicly the details of either the observations or the examination of reported incursions into our training ranges or designated airspace, including those incursions initially designated as UAP – and that includes not discussing the UAPTF publicly, also.”&nbsp;</span></p><p><span data-preserver-spaces="true">Official public affairs channels indicate the Pentagon is not interested in sharing any more information on the UAP topic. However, several current and former officials with the DoD and individuals working for multiple U.S. intelligence agencies told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">that there was much more going on behind closed doors.</span></p><p><iframe title="UAP Filmed Over Nellis Range, Nevada, November 1994" width="1170" height="878" src="https://www.youtube.com/embed/ua-a838Vw00?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><h2><strong><span data-preserver-spaces="true">UAP Intelligence Position Reports</span></strong></h2><p><span data-preserver-spaces="true">Multiple sources confirmed for&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">&nbsp;that the UAPTF had issued two classified intelligence position reports, which one individual described as “shocking.” Details provided on these reports suggest both a greater degree of Pentagon involvement, and that the UAPTF’s&nbsp;hunt for unidentified objects isn’t confined only to aerial phenomena.&nbsp;</span></p><p><span data-preserver-spaces="true">Two officials with the DoD and one from the U.S. Intelligence community were willing to provide details on the contents of the classified report. An additional three other U.S. Intelligence Officials and a federal law enforcement officer confirmed the report’s existence but were only willing to provide comments on their distribution. Given the report’s classification and their discussion of a “sensitive intelligence matter,” the officials we spoke with did so only under strict conditions of anonymity. While&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">has agreed not to provide information on sources, identities, and employers, though everyone we spoke with works within the U.S. Intelligence Community and under the authority of the U.S. Director of National Intelligence.&nbsp;</span></p> <figure id="attachment_1329" aria-describedby="caption-attachment-1329"><img src="https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013.jpg" alt="The National Reconnaissance Office" width="1280" height="853" srcset="https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013.jpg 1280w,https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-1024x682.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-768x512.jpg 768w" sizes="(max-width: 1280px) 100vw, 1280px"><figcaption id="caption-attachment-1329">Aerial view of the headquarters of the National Reconnaissance Office (NRO) in Chantilly, Virginia, by Trevor Paglen.</figcaption></figure><p><span data-preserver-spaces="true">One of the intelligence reports, released in 2018, is said to have provided a general overview of the UAP topic and included details of previous military encounters. According to sources who had read it, the report also contained an unreleased photograph of an “aerial phenomena” categorized as “unidentified.”&nbsp;</span></p><p><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">was told the accompanying photo was captured from within the cockpit of an F/A-18 fighter jet with a pilot’s personal cell phone. According to three U.S. officials who had seen it, the photo showed an unidentified silver “cube-shaped” object. The report is said to have indicated the object was “hovering” or completely motionless when military pilots encountered it. All three officials agreed that based on the photo, the object appeared to be at an altitude of roughly 30,000 to 35,000 feet and approximately 1,000 feet from the fighter jet.&nbsp;</span></p><p><span data-preserver-spaces="true">Defense and intelligence officials willing to discuss the report and those who only wished to confirm its dissemination all expressed shock that it had been so widely distributed amongst the Intelligence community.&nbsp;</span></p><p><span data-preserver-spaces="true">“In decades with the [Intelligence Community] I’ve never seen anything like this,” said one intelligence official.&nbsp;</span></p><p><span data-preserver-spaces="true">One defense official described the report’s distribution as having gone through “normal, non-public, information sharing channels.” Other officials who’d seen and read the report either declined to elaborate or indicated the report was distributed on various secure systems. One defense official indicated it was distributed on the DoD’s Secret Internet Protocol Router Network (SIPRNet). Two other intelligence officials said they received the information via “NSANet” (the NSA’s official intranet). An additional source said the report was distributed via the CIA’s Intelink system.&nbsp; &nbsp;</span></p><p><span data-preserver-spaces="true">According to …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force/">https://www.thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force/</a></em></p>]]>
            </description>
            <link>https://www.thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299329</guid>
            <pubDate>Fri, 04 Dec 2020 05:29:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Dothraki Horde, Part I: Barbarian Couture]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25299176">thread link</a>) | @parsecs
<br/>
December 3, 2020 | https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the first part of a three part (II, III) look at the Dothraki, the fictional horse-borne nomads of the <em>Game of Thrones</em> / <em>A Song of Ice and Fire</em> series and the degree to which George R.R. Martin’s claim that they are “an amalgam of a number of steppe and plains cultures” holds up to scrutiny.  This is something that I have been suggesting I would get to since (checks notes),<a href="https://acoup.blog/2019/05/04/new-acquisitions-that-dothraki-charge/"> May.  Of Last Year.</a>  So it is about time we actually get to it.</p>



<p>The plan is for this series to run in three parts.  Part I (this part) will discuss how the Dothraki <em>look</em> in the setting.  Part II will look at broader questions of social organization and culture (I am nearly certain this is one of those cases where there will be a IIa and a IIb, but my hope for brevity springs eternal).  Part III will look at military culture.  In all three parts I am going to use both the books and the show – noting where they diverge – in part because the heaviest characterization the Dothraki got in the show was when Martin was still significantly involved with it (meaning that large parts of it likely still reflect his vision), but also because the show is how the vast majority of people experience this particular fiction.  Both the original text and the show derived from it deserve to have their vision discussed.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>First, a <strong>content warning for this series</strong>: this is discussing <em>A Song of Ice and Fire</em> and <em>Game of Thrones</em> which features a lot of content which is not G-rated.  More to the point, it is a discussion of what – I will argue – Martin presents as one of, if not the most brutal and sexually violent society in that setting.  And that means those themes are going to come up here (less in this essay, but more in the other parts); we are going to remain serious and adult about those things of course, but they will be a part of this analysis nonetheless.  If that is not for you, by all means feel free to check out for a few weeks.</p>



<p>Before we get into the main point, <strong>I want to note that I am going to reference my series on the <a href="https://acoup.blog/2020/01/17/collections-the-fremen-mirage-part-i-war-at-the-dawn-of-civilization/">Fremen Mirage</a> <em>a lot</em> here</strong>, because there is a lot of Fremen stuff going on with how Dothraki society is depicted.  As a result, it may be useful to go back and read those, but just to recap, we may define the Fremen Mirage this way:</p>



<p><a href="https://acoup.blog/2020/02/21/collections-the-fremen-mirage-interlude-ways-of-the-fremen/"><strong>The Fremen Mirage is a literary trope, <em>unconnected to historical reality</em>, which presents societies as a contrast between unsophisticated, but morally pure, hyper-masculine and militarily effective ‘strong men’ societies honed by ‘hard times’ (that is, the Fremen of the term) and a sophisticated but effeminate and decadent ‘weak men’ societies weakened by ‘good times,’ frequently with an implicit assertion of the superior worth of the former.</strong></a></p>



<p>Next, a note on citation here from the books.  My understanding is that different printings of the books have different pagination, which seems to be why the Wiki of Ice and Fire cites by chapter numbers (except that the chapters of the books, as printed, <em>aren’t numbered</em> in the print editions I’ve seen, making this classical-style citation extremely cumbersome and inexact).  I am going to cite by the page numbers of my edition, which is the 2011 Bantam Books Trade Paperback Edition (the box set).  Hopefully that will be enough.</p>



<p>Finally, a note on my expertise here.  <strong>I am not a scholar of either the peoples of the Eurasian Steppe or the American Great Plains</strong>.  The former group does intrude into my period and study, as steppe nomads, in the form of Scythians, Sarmatians and Huns did interact (sometimes peacefully, sometimes violently) with the broader Mediterranean world.  Consequently, my knowledge of steppe peoples tend to be better that my knowledge of the Native American peoples of the Great Plains, but I have tried, within the limits of time and availability, to do my research. <strong> I actually think, in a strange sense, this is useful, because my own initial unfamiliarity with the topic has demonstrated to me just how <em>basic</em> the level of research and reading necessary to avoid the failures of this depiction are</strong>.  You do not, in turns out, need to be an experienced scholar on the topic; just a few books and a couple of emails is enough to already radically improve on what we see and read in <em>A Song of Ice and Fire</em>, much less the absolute <em>mess </em>of what we see in <em>A Game of Thrones</em>.</p>



<p>Writing this has been tricky.  I am well aware that both of these broad cultural groups (that is, Steppe peoples and Plains Native Americans) are often represented in popular culture only in the form of inaccurate and demeaning stereotypes.  I do not want to be just another link in that chain of poor understanding.  I have thus tried to root my argument here, wherever possible, in either the writings of specialist scholars (there will be more of that next week as we get into subsistence patterns, warfare, etc.) or primary evidence, particularly in terms of <em>period photographs</em>, when it comes to clothing and dress.  With luck I have not erred overmuch.</p>



<figure><img data-attachment-id="5355" data-permalink="https://acoup.blog/1024px-skythian_archer_plate_bm_e135_by_epiktetos/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg" data-orig-size="1024,991" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-skythian_archer_plate_bm_e135_by_epiktetos" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Scythians#/media/File:Skythian_archer_plate_BM_E135_by_Epiktetos.jpg">Via Wikipedia</a>, an Attic vase-painting of a Scythian archer (c. 500 BCE).  The Scythians, like the Huns and Mongols, were a Eurasian Steppe people, many of them horse-borne nomads of the same sort.  Far from being drab, their clothing was colorful and distinctive, including their particular hats, which show up not only in Greek but also in Persian artwork.</figcaption></figure>



<h2>…But, Why?</h2>



<p>But before we get into the issue proper, it is important to clear away the standard objections, both why subject <em>A Song of Ice and Fire</em> (and its spin-off properties) to critical analysis at all and also why, if we are going to do that, we are going to focus squarely in on the Dothraki.  The answer to the first is something that we’ve rehearsed a number of times, but bears restating: for most of its readers (and the watchers of <em>A Game of Thrones</em>), <em>A Song of Ice and Fire</em> will be their primary exposure to the idea of the Middle Ages.  This is particularly true because of the reputation that the series has for being ‘<a href="https://acoup.blog/2019/05/28/new-acquisitions-not-how-it-was-game-of-thrones-and-the-middle-ages-part-i/">how it really was</a>,’ a reputation that George R.R. Martin has consciously cultivated (as with his classic complaint of <a href="https://youtu.be/p-VxvKoDFIw">‘what was Aragorn’s tax policy’</a> – there is a rich irony that, had Martin understood rulership in the Middle Ages better, he would have understood why Aragorn’s tax policy was less important).  Martin has been quite open that he “<a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">draw[s] inspiration from history</a>” and that fact has long been a selling point of the series over more obviously fantastical kinds of medieval-themed high fantasy as well as a <a href="https://ew.com/article/2015/06/03/george-rr-martin-thrones-violence-women/">response to some of the series’ more controversial moments</a>.</p>



<p><strong>Naturally, that cloak of verisimilitude has tended to intensify the degree to which elements of <em>A Song of Ice and Fire</em> is taken by its readers and viewers as representative of the Middle Ages more generally.</strong>  And of course as I have noted in the (quite recent) past,<strong> <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">fiction is often how the public conceptualizes the past and that concept of the past shapes the decisions we make in the present</a></strong>.  In the case of <em>A Song of Ice and Fire</em> in particular, this vision of the past is <a href="https://acoup.blog/2019/06/12/new-acquisitions-how-it-wasnt-game-of-thrones-and-the-middle-ages-part-iii/">particularly worth interrogating</a> because it serves as the basis for a<a href="https://youtu.be/ek2O6bVAIQQ"> parable on power and violence</a>.</p>



<p>But <em>even if it didn’t</em>, it would still be worth discussing these aspects of the universe of <em>A Song of Ice and Fire</em>, because that is what we are supposed to do with cultural products, with <em>literature</em>.  <strong>I am sometimes baffled that the very fans who insist that their particular loves be treated seriously, as <em>art</em> are the same fans who react with frustration if one then sets out to interrogate those same genres the way one would interrogate serious art or literature</strong>.  This is it, after all!  This is what you (we, really) wanted!  A (quite unimpressive, I’ll grant you) ivory tower academic is taking this genre seriously and subjecting it to serious criticism!  Isn’t that what emerging genres often hope for, to be taken seriously as ‘high’ literature?</p>



<p><strong>And of course we should take it seriously.</strong>  And here I want to speak briefly to the purpose of these sorts of endeavors, <strong>because the goal here is not to force anyone to dislike <em>A Song of Ice and Fire</em></strong>.   We’re not here to ‘cancel’ <em>ASOIF</em> any more than we were going to ‘cancel’ <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/"><em>AC:Valhalla</em> two weeks ago</a> (a game I continue to play, I might add).  Instead, discussing cultural products like this is a form of inoculation against their potentially negative aspects, because once a reader knows that, for instance, the depiction of a given culture in a work of fiction has relatively little to do with any real world culture, they can compartmentalize that to the fiction itself; <strong>it loses its power to mislead</strong> <strong>and so may be enjoyed in safety, as it were</strong>.  And there are good things in <em>A Song of Ice and Fire</em> and in the first six or so seasons of <em>Game of Thrones</em>; but we also need to be honest about the failings.</p>



<p>(Of course, more broadly, doing this as a practice exercise is a key part of building up that skill – what we may term ‘critical reading’ – more generally, rendering the alert reader more resistant to this sort of thing, both in its unintended form (as, I suspect, in this case) or  in its more dangerous<em> intended form</em>.  Put another way, developing critical reading skills is one important way to make one’s self a harder target for misinformation, including historical misinformation.)</p>



<h2>A Dash of Pure Fantasy</h2>



<p>Alright, so <em>A Song of Ice and Fire</em> is worth looking at closely.  So why <em>this</em> part of the fiction?  It comes down to something <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">George R.R. Martin wrote</a>:</p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299176</guid>
            <pubDate>Fri, 04 Dec 2020 05:05:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do you know all of these Adobe products and what they do?]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25299123">thread link</a>) | @amiamigo
<br/>
December 3, 2020 | https://monalidor.com/adobe-products/ | <a href="https://web.archive.org/web/*/https://monalidor.com/adobe-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p><em><strong>...This article is still developing!</strong></em></p><p>Apparently, Adobe has over 100 lists of software products scattered among the web, desktop, mobile, and server. In this article I will try to list the ones that I think you should know about...it's quite a lot still</p><p>Before I begin this extensive list, it's important to note that there a lot of Adobe products that are no longer maintained or in development. They have pretty much been killed by the Adobe Team, I am not going to talk about those. They may include products like Adobe Flash, Adobe Edge, Adobe Muse, Adobe Fireworks, Adobe Story Plus, Adobe Speedgrade, Adobe Encore, Adobe Fuse, etc. The production and development of all those and many more is long gone.</p><p>...</p><p>Most of the products I am gonna explain here do fall under their different suites or clouds as they call them. Most of you might already be familiar with the Adobe Creative Cloud, but do you know there is also Adobe Experience Cloud and Adobe Document Cloud? Adobe Creative Cloud also known as Adobe CC is a collection of all of Adobe creative line of products...and one can choose to buy a license for one individual product or for all of them. </p><p>Sometimes (actually a lot of times!) it can be confusing to differentiate between several Adobe Products. People can confuse between Photoshop and Illustrator or Lightroom and Photoshop for example.</p><p>You might even question yourself why does Adobe has so many products that kinda do the same thing. Beginning video creators might wonder about After Effects and Premiere Pro</p><p>The aim of this article is to introduce you to the so many wonderful Adobe products and know exactly what each Adobe product is used for. It's true one software can do pretty much what the other software does...but it's always great to use the specific tool that was made for the job.</p><p>I will try my best in this article to list almost all Adobe products, and to make it easy to follow I will categorize them into the following groups:</p><ol><li><strong>PHOTO</strong></li></ol><p>The following are different lines of Adobe products that can be used to edit and manipulate photos.</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/12/Monalidor---Adobe-Products-Photo.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/12/Monalidor---Adobe-Products-Photo.png 600w, https://monalidor.com/content/images/size/w1000/2020/12/Monalidor---Adobe-Products-Photo.png 1000w, https://monalidor.com/content/images/size/w1600/2020/12/Monalidor---Adobe-Products-Photo.png 1600w, https://monalidor.com/content/images/2020/12/Monalidor---Adobe-Products-Photo.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/12/Monalidor---Adobe-Products-Photo-2.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/12/Monalidor---Adobe-Products-Photo-2.png 600w, https://monalidor.com/content/images/size/w1000/2020/12/Monalidor---Adobe-Products-Photo-2.png 1000w, https://monalidor.com/content/images/size/w1600/2020/12/Monalidor---Adobe-Products-Photo-2.png 1600w, https://monalidor.com/content/images/2020/12/Monalidor---Adobe-Products-Photo-2.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Adobe Products for Manipulating Photos</figcaption></figure><p><strong>Adobe Photoshop</strong> – Photoshop is used for photo editing, compositing, digital painting and graphic design. It's such a powerful application. You can even do animation in Photoshop. It's used by both Artists and photographers and pretty much everyone. You can make posters, ads, wallpapers, etc.</p><p><strong>Adobe Photoshop Elements </strong>– If Photoshop is overwhelming for you, start with Photoshop Elements, it's a simpler version of Photoshop</p><p><strong>Adobe Photoshop Express </strong>– This a Photoshop mobile app. If you wanna do editing on the go using your Android or iOS phone, Photoshop Express is your guy. It's interface resembles the desktop app. Photoshop Express "is intentionally built for mobile device photography"</p><p><strong>Adobe Photoshop Camera</strong> – Another mobile app...this one according to Adobe is like having photoshop inside your camera. It's an intelligent camera app that has best lenses and effects for your photos.</p><p><strong>Adobe Photoshop Mix</strong> – Also a mobile app, and is supposed to bring Photoshop seriousness to mobile devices. It offers some photo enhancing and advance imaging.</p><p><strong>Adobe Photoshop Fix</strong> – I think soon Adobe will run out of names, okay Photoshop Fix is used to adjust images to perfection, doing things like healing, lightening, color adjustment, etc.</p><p>The main difference between Photoshop Fix and Photoshop Mix is that Fix is used for photo retouching and enhancing your images WHILE Mix is used for compositing, you can combine images and cut out backgrounds with it.</p><p><strong>Adobe Photoshop Lightroom</strong> – Lightroom is a photo editor for both desktop, mobile and web. It's used to edit, organize and store photos. Lightroom is built for photographs.</p><p><strong>Adobe Photoshop Lightroom Classic</strong> – Lightroom Classic is only available for Desktop and it's pretty much like Lightroom but is generally recommended for experienced photo editors.</p><p>I have to admit, Adobe products are confusing...you need to dig a bit deeper if you wanna get a clear distinction between their confusing line of products!</p><p><strong>2. VIDEO</strong></p><p>Now is the time for all the Adobe products used for videos, let it be editing, rendering, etc.</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/12/Monalidor---Adobe-Products-Video.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/12/Monalidor---Adobe-Products-Video.png 600w, https://monalidor.com/content/images/size/w1000/2020/12/Monalidor---Adobe-Products-Video.png 1000w, https://monalidor.com/content/images/size/w1600/2020/12/Monalidor---Adobe-Products-Video.png 1600w, https://monalidor.com/content/images/2020/12/Monalidor---Adobe-Products-Video.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/12/Monalidor---Adobe-Products-Video-2.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/12/Monalidor---Adobe-Products-Video-2.png 600w, https://monalidor.com/content/images/size/w1000/2020/12/Monalidor---Adobe-Products-Video-2.png 1000w, https://monalidor.com/content/images/size/w1600/2020/12/Monalidor---Adobe-Products-Video-2.png 1600w, https://monalidor.com/content/images/2020/12/Monalidor---Adobe-Products-Video-2.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Adobe Products for Videos</figcaption></figure><p><strong>Adobe Premiere Pro</strong> – This is the industry standard for video editing. You can edit video in any format using Premiere. Because of its advance uses the learning curve might be steep.</p><p><strong>Adobe Premiere Rush</strong> – This is both a Desktop and mobile app. It's mainly used to create and edit videos on the go. Easier to use than Premiere Pro</p><p><strong>Adobe After Effects</strong> – After effects is mostly used for motion graphics and visual effects. You can create cinematic movie titles, intros, transitions, and even some animation too.</p><p><strong>Adobe Prelude</strong> – It's made to work with Premiere Pro, and is used &nbsp;for tagging media and logging data, also to generate rough cuts that can be sent to Premiere Pro. Best for media organization and metadata entry</p><p><strong>Adobe Media Encoder</strong> – Mainly used for transcoding and rendering. It can output to almost any format imaginable. Using Media Encoder you can export videos to YouTube, Vimeo, DVDs, Mobile Phones, and TV</p><p><strong>Adobe Premiere Elements</strong> – This is a scaled-down version of Adobe Premiere Pro. It's tailored to novice users. It should not be confused with Premiere Rush as Rush is mostly tailored to creating social media videos from the comfort of your portable mobile device. Premiere Elements is a full-featured consumer video editor only not as powerful as Premiere Pro. However, it still has a lot of features.</p><p>...</p><p>...</p><p><em><strong>...This article is still developing!</strong></em></p>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://monalidor.com/tag/30-in-30/" title="30 in 30">30 in 30</a>
                      </li>
                      <li>
                        <a href="https://monalidor.com/tag/adobe/" title="adobe">adobe</a>
                      </li>
                  </ul>
                </section>
            </div></div>]]>
            </description>
            <link>https://monalidor.com/adobe-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299123</guid>
            <pubDate>Fri, 04 Dec 2020 04:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing Clojure namespace forms using Raku Grammars]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25299099">thread link</a>) | @samebchase
<br/>
December 3, 2020 | https://raku-advent.blog/2020/12/04/day-4-parsing-clojure-namespaces-with-grammars/ | <a href="https://web.archive.org/web/*/https://raku-advent.blog/2020/12/04/day-4-parsing-clojure-namespaces-with-grammars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-687">

	

	
	<div>
		
<p>One day, I started wondering if it would be possible to parse <a href="https://clojure.org/reference/namespaces">Clojure namespace</a> forms and generate a dependency graph of the various namespaces used in a real-world Clojure project. While that was the original motivation, I ended up down the <a href="https://docs.raku.org/language/grammars">Raku grammar</a> rabbit hole, and had an enjoyable time learning how to use them. I’m glad you’re joining me in reliving that journey.</p>



<h2><a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#background"></a>Background<a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#grammars"></a></h2>



<h3>Grammars</h3>



<p>Informally speaking, grammars can be thought of as a set of rules that describe a language. With these rules, one can meaningfully parse (to make sense of, or deconstruct into its grammatical components) a piece of text. It turns out that this is a common task in computing. We need to frequently translate programs from one language to another. This is the job of a compiler. Before being able to translate it, the compiler needs to know whether the original program is even valid, according to the language’s grammar.</p>



<p>While we have explained in theory what grammars are, Raku grammars help us model abstract grammars as a programming construct (the <code>grammar</code> keyword and its adjacent helpers) using which we can perform parsing tasks. It is <em>important</em> to understand this distinction.</p>



<p>First class <a href="https://docs.raku.org/language/grammars">grammars</a> are considered one of the revolutionary features of Raku. Normally, you’d find grammars as a library or a standalone tool, but Raku has embraced it wholesale, and has a powerful implementation of grammars which makes light work of most parsing tasks.<a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#clojure"></a></p>



<h3>Clojure</h3>



<p><a href="https://clojure.org/">Clojure</a> is a modern lisp, and happens to be the language I use in <code>$DAYJOB</code>. At the top of most Clojure files, there is a namespace form importing various internal and external namespaces. This way we can neatly organize our project into many separate files, rather than having to put them all into one big file. We are shortly going to design a grammar that can parse these namespace forms.</p>



<h3><a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#grammartracer"></a>Grammar::Tracer</h3>



<p><a href="https://github.com/jnthn/grammar-debugger">Grammar::Tracer</a> is helpful in figuring out where your grammar fails to match, and is invaluable in debugging. Make sure you do <code>zef install Grammar::Tracer</code> before running the code examples.</p>



<h2><a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#lets-start-cookin"></a>Let’s start cookin’</h2>



<h3><a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#a-trivial-example"></a>A trivial example</h3>



<p>A Clojure namespace is a Lisp form, which as expected starts with an open paren and ends with a close paren. Let’s write a grammar for one of the simplest Clojure forms, the empty list.</p>



<pre>()</pre>



<pre><code>grammar EmptyLispForm {
    token TOP { &lt;lparen&gt; &lt;rparen&gt; }

    token lparen { '(' }
    token rparen { ')' }
}</code></pre>



<p>This is one of the simplest possible grammars we can write. Parsing always starts with the <code>TOP</code> token, and recurses into the various component tokens from there. We just have two such tokens <code>lparen</code> and <code>rparen</code> which are used to denote the left and right parens. Play around with <a href="https://gist.github.com/samebchase/e988e1ed9609daffaf1849c2527af51d">trivial.raku</a> to see how we can parse this.</p>



<h3><a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#warmup-slaying-a-cliched-interview-question-using-raku-grammars"></a>Warmup: Slaying a cliched interview question using Raku grammars</h3>



<p>Q: Write a program that checks that parentheses are balanced.</p>



<p>For example:</p>



<pre>() ;; balanced
(()) ;; balanced
(()(())) ;; balanced
(()(((()))) ;; unbalanced</pre>



<pre>grammar BalancedParens {
    token TOP { &lt;balanced-paren&gt; }

    token balanced-paren { &lt;lparen&gt; &lt;balanced-paren&gt;* &lt;rparen&gt; }

    token lparen { '(' }
    token rparen { ')' }
}</pre>



<p>It’s likely I’ve made this more wordy than necessary, but that’s still only <em>six</em> rather-readable lines.</p>



<p>Now, under time pressure which seems more likely? Coding up a stack and fiddling with corner cases or using grammars with the awesomeness of <code>Grammar::Tracer</code> to quickly hack out a declarative solution.</p>



<p>It turns out, that we have just tackled one of the trickiest aspects of writing a real-world grammar, and that is dealing with nested structures. As programmers we know that when we see nested structures, we know we will have to deal with recursion in some form.</p>



<p>You can play around with <a href="https://gist.github.com/samebchase/fad8108cb6daeaf8043d92a40eb29276">balanced-parens.raku</a> program on the console, and observe how the grammar is parsed.</p>



<p>Note: It turns out there is a <a href="https://docs.raku.org/language/regexes#Tilde_for_nesting_structures">better</a> way to parse nested structures, but this is fine for now.<a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#parsing-our-first-namespace-form"></a></p>



<h3>Parsing our first namespace form</h3>



<p>Let’s try to parse this simple namespace declaration:</p>



<pre><code>;; 1   3
   |   |
;; (ns my-own.fancy.namespace)
    |                        |
;;  2                        4</code></pre>



<p>While this is easy, it is going to be an important building block in tackling more complicated namespace forms. Let’s break this down into its four component <a href="https://en.wikipedia.org/wiki/Lexical_analysis#Lexeme">lexemes</a>. We can see the open and close parens, we see <code>ns</code>, the namespace <code>my-own.fancy.namespace</code> and finally the close paren. That’s it! Let’s tackle these individual pieces using a grammar.</p>



<pre>grammar SimpleNs {
    token TOP { &lt;simple-ns&gt; }

    #                  1        2            3         4
    #                  |        |            |         |
    token simple-ns { &lt;lparen&gt; &lt;ns-keyword&gt; &lt;ns-name&gt; &lt;rparen&gt; }

    token ns-keyword { 'ns' }
    token ns-name { &lt;.ns-name-component&gt;+ % '.' }
    token ns-name-component { ( &lt;.alnum&gt; | '-' )+ }

    token lparen { '(' }
    token rparen { ')' }
}</pre>



<p>Over here we can see that we have translated this into a simple Raku grammar. You could argue that defining <code>simple-ns</code> is not even required, we could have just put it in <code>TOP</code> directly, but anyway.</p>



<p>We will need to deal a little with <a href="https://en.wikipedia.org/wiki/Regular_expression">regexes</a> here. In the various flavours of regexes, <code>+</code> usually means one or more. <code>|</code> has a slightly different meaning from what you’re expecting, but you can check the regex <a href="https://docs.raku.org/language/regexes">documentation</a> for all the details on the difference between <code>|</code> and <code>||</code>. Loosely speaking, we are saying that a <em>namespace component</em>, i.e. the thing between two dots, is made up of one or more alphanumneric characters or hyphens. Now, if there is a rule saying a namespace has to start with an alphabetic character, and not a number, the grammar will become a little more complex, but this is a pedagogic example, so we’ll not be too pedantic.</p>



<p>I expect eagle-eyed readers to point out a few things:</p>



<ol><li>Where is <code>&lt;.alnum&gt;</code> being defined, and why does it have a dot before it?</li></ol>



<p><code>alnum</code> is predefined. The reason it has a <code>.</code> before it is so that we are not interested in capturing each letter; it’s too low level. We are interested in capturing a top-level token like <code>ns-name</code> instead, and not each individual character. Play around with the code examples by adding and removing a dot from various tokens and see the difference in <code>Grammar::Tracer</code>‘s output.</p>



<ol start="2"><li>What does <code>%</code> mean?</li></ol>



<p>This is a very useful convenience to describe patterns where something is interspersed between a bunch of other things. For example, we can have a namespace like <code>foo.bar.baz</code> or we could have an IPv4 address <code>192.168.0.1</code> where integers are separated by dots.</p>



<pre>token ns-name { &lt;.ns-name-component&gt;+ % '.' }</pre>



<p>This means that <code>ns-name</code> is made up of at least one <code>ns-name-component</code>‘s (denoted by the <code>+</code>) and separated by a <code>.</code> (denoted by <code>%</code>).</p>



<p>Okay, so this should work I guess? Let’s see what happens when we run the code!</p>



<p>No, that didn’t work. As <code>Grammar::Tracer</code> helpfully tells us, we did not account for the space after <code>ns</code>. In traditional compiler theory, there is a process of tokenisation, where some lightweight regexes are used to separate the program into its component lexemes and discard all the extraneous spaces before the parser takes over. However, here we will not do that, and we’ll deal with it in the grammar itself. Now, it could be argued whether that is a good decision, but that’s another discussion. Let’s add some allowance for whitespace and see what happens. While building the full Clojure NS grammar, I got myself into a position where I liberally used to sprinkle <code>&lt;.ws&gt;*</code> indicating zero or more whitespace characters in places where I felt that we should allow optional whitespace, as you would expect in a real-world program.</p>



<pre>token simple-ns { &lt;lparen&gt; &lt;ns-keyword&gt; &lt;.ws&gt; &lt;ns-name&gt; &lt;rparen&gt; }</pre>



<p>With that tiny addition, we are now able to parse the simple namespace form. You can play around with <a href="https://gist.github.com/samebchase/0820b9ecfdb011a9b73aedfb4ba349d1">simple-ns.raku</a>.<a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#lets-make-our-lives-a-little-more-difficult"></a></p>



<h3>Let’s make our lives a little more difficult</h3>



<p>Okay, now we are getting the hang of this, so let’s see a namespace form which is a little more <a href="https://gist.github.com/samebchase/3debbe6190eb1c8f5325ae2640840db4">realistic</a>.</p>



<pre>(ns my-amazing.module.core
  (:require [another-library.json.module :as json]
            [yet-another.http.library :as http]))</pre>



<p>This is a realistic namespace form which we shall parse by adding support for the <code>:require</code> form where other libraries are imported and given a short nickname.</p>



<p>Can this be done? You bet!</p>



<pre>grammar RealisticNs {
    token TOP { &lt;realistic-ns&gt; }

    token realistic-ns { &lt;lparen&gt;
                           &lt;ns-keyword&gt; &lt;.ws&gt; &lt;ns-name&gt; &lt;.ws&gt;
                           &lt;require-form&gt;
                         &lt;rparen&gt; }

    token ns-keyword { 'ns' }

    token ns-name { &lt;.ns-name-component&gt;+ % '.' }
    token ns-name-component { ( &lt;.alnum&gt; | '-' )+ }

    token require-form { &lt;lparen&gt;
                           &lt;require-keyword&gt; &lt;ws&gt;? &lt;ns-imports&gt;
                         &lt;rparen&gt; }

    token require-keyword { ':require' }

    token ns-imports { &lt;ns-import&gt;+ % &lt;.ws&gt; }

    token ns-import { &lt;lsquare&gt;
                        &lt;ns-name&gt; &lt;.ws&gt; ':as' &lt;.ws&gt; &lt;ns-nickname&gt;
                      &lt;rsquare&gt; }

    token ns-nickname { &lt;.alnum&gt;+ }

    token lsquare { '[' }
    token rsquare { ']' }
    
    token lparen { '(' }
    token rparen { ')' }
}</pre>



<p>Nothing too scary as yet. We can see how the grammar evolves. At the top level, in <code>realistic-ns</code> we have added an extra token called <code>&lt;require-form&gt;</code> and we flesh out the details later. We can manage complexity in this manner, so that we have the ability to zoom in and out of the details as necessary.<a href="https://gist.github.com/samebchase/8d37f7d961ecc981e9ab9a5d36763dd5#using-the-parsed-data"></a></p>



<h3>Using the parsed data</h3>



<p>Now that we have been able to parse the data, we need to make use of what we’ve parsed. This is where <em>Actions</em> come into the picture.</p>



<p>When we do <code>RealisticNs.parse(...)</code>, that returns a <code>Match</code> object corresponding to the <code>RealisticNs</code> grammar. While we can query that object to get the pieces of data that we require, it is less cumbersome to use <em>Actions</em> to build up the data we are actually interested in.</p>



<p>Given, a namespace, we want to extract out:</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raku-advent.blog/2020/12/04/day-4-parsing-clojure-namespaces-with-grammars/">https://raku-advent.blog/2020/12/04/day-4-parsing-clojure-namespaces-with-grammars/</a></em></p>]]>
            </description>
            <link>https://raku-advent.blog/2020/12/04/day-4-parsing-clojure-namespaces-with-grammars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299099</guid>
            <pubDate>Fri, 04 Dec 2020 04:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes for Devs Talking to Designers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25298889">thread link</a>) | @philipkiely
<br/>
December 3, 2020 | https://philipkiely.com/essays/designer_talk.html | <a href="https://web.archive.org/web/*/https://philipkiely.com/essays/designer_talk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Thanks to a conversation I had with <a href="https://twitter.com/jackzerby">Jack Zerby</a> at Gumroad, I now feel confident asking designers to create a user interface, graphic, visual identity, or any other design artifact and have become much more productive at communicating and delegating design tasks. This is essential because my design skills are non-existent. Fortunately, design skills don’t matter in creating a spec, design thinking does. These are my notes from that&nbsp;conversation.</p>
<p>Readers familiar with speccing software or anything else may realize that the advice I’m conveying here matches both your use case and the general case. That, in fact, is the insight that I was missing before the conversation. I already knew how to spec a design, I just needed the right&nbsp;words.</p>
<h3>Step-by-Step&nbsp;Spec</h3>
<p>If you write a spec with all of this information, your designer should have everything they need to get&nbsp;started.</p>
<h4>Step 1: Specify context and&nbsp;canvas</h4>
<p>The canvas is the size and nature of the space the designer has to work in. For graphics, it is the literal dimensions, for software, it is the range of screens that a user might interface with the design from. Web vs mobile is also a canvas&nbsp;question.</p>
<p>Context is what else is nearby. This can mean other aspects of the application as a whole, or it can mean where the user is in a certain process when they encounter the design. If you are asking for a graphic to use on Twitter, that is part of the context, and is very different than asking for a graphic to use on a physical billboard in ways that just the size of the canvas doesn’t fully&nbsp;convey.</p>
<h4>Step 2: List the&nbsp;ingredients</h4>
<p>What actually goes in the design? What information needs to be conveyed? What actions does the user have access to? Be complete, if you don’t list it, the designer won’t know to include&nbsp;it.</p>
<p>An existing stylesheet, illustration, library, or other asset is also an ingredient in the&nbsp;design.</p>
<p>Make sure you have the right number of ingredients for your canvas and context. The more skilled your designer, the more range you get on this, but only to a certain&nbsp;limit.</p>
<h4>Step 3: Identify patterns and&nbsp;hierarchies</h4>
<p>Tell your designer which elements and ingredients are the most important. When you tell your designer the relative importance of the various aspects they use their tools to communicate that importance to the&nbsp;user. </p>
<p>Work with patterns of information within the hierarchy while avoiding identical sections blurring together. Information should match and rhyme, not repeat. But, without a pattern, the design will present friction to the&nbsp;user.</p>
<p>You can communicate hierarchy in words. Lists, especially nested lists, are important here. Order matters, especially in something that can be scrolled&nbsp;through.</p>
<p>If you communicate hierarchy in pictures, don’t go any higher fidelity than a <a href="https://basecamp.com/shapeup/1.3-chapter-04">fat marker sketch</a>. Otherwise, you’ll artificially limit your designer early in the&nbsp;process.</p>
<h4>Step 4: Set&nbsp;tone</h4>
<p>Asking to communicate emotions, impressions, and themes is okay, even good. “X but not Y” is a powerful pattern for doing so, like “minimalist but not empty” or “whimsical but not frivolous.” The more evocative your description, the&nbsp;better.</p>
<h4>Step 5: Send and&nbsp;iterate</h4>
<p>Everything in the spec should be written to avoid friction with the designer. Every time they have to ask you what you mean or you go back and forth on an aspect of your spec, that adds friction to the design process. The faster the turnaround, the more specific your request should be. Specify how many iterations your project merits or your timeline&nbsp;allows.</p>
<p>Design iterations alternate between wide and deep. A “wide” iteration yields several versions of the requested design as a whole. A “deep” iteration takes a chosen design from the wide iteration and comes up with variations on the&nbsp;theme.</p>
		</div></div>]]>
            </description>
            <link>https://philipkiely.com/essays/designer_talk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298889</guid>
            <pubDate>Fri, 04 Dec 2020 04:19:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pitfalls of Language Runtimes and Multi-Tenant]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25298636">thread link</a>) | @gk1
<br/>
December 3, 2020 | https://goteleport.com/blog/multi-tenant-pitfalls/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/multi-tenant-pitfalls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p>Modern languages like Python, NodeJS, and Go make it easy to handle
concurrent requests for multiple customers at the same time by using threads or goroutines.</p>

<p>Such services seem very cost effective because one process can handle hundreds or thousands
of tenants. However, this efficiency comes at a hidden, steep price. When language runtime
scheduling breaks down, one tenant can cause an outage for everyone.</p>

<h2 id="concurrency-made-simple">Concurrency made simple</h2>

<p>Go makes it trivial to handle concurrency.</p>

<p>Here is an example from <a href="https://tour.golang.org/concurrency/1">A Tour Of Go</a> that
launches two goroutines that work independently of each other:</p>
<div><pre><code data-lang="go"><span>package</span> <span>main</span>

<span>import</span> (
	<span>"fmt"</span>
	<span>"time"</span>
)

<span>func</span> <span>say</span>(<span>s</span> <span>string</span>) {
	<span>for</span> <span>i</span> <span>:=</span> <span>0</span>; <span>i</span> &lt; <span>5</span>; <span>i</span><span>++</span> {
		<span>time</span>.<span>Sleep</span>(<span>100</span> <span>*</span> <span>time</span>.<span>Millisecond</span>)
		<span>fmt</span>.<span>Println</span>(<span>s</span>)
	}
}

<span>func</span> <span>main</span>() {
	<span>go</span> <span>say</span>(<span>"world"</span>)
	<span>say</span>(<span>"hello"</span>)
}
</code></pre></div>
<p>The Go runtime makes sure that each goroutine gets its fair share of CPU and memory.
It gives the impression that both run in parallel:</p>
<div><pre><code data-lang="bash"><span># GOMAXPROCS sets system threads to 1</span>
<span># This sets up the go language runtime to use one system thread across</span>
<span># all goroutines. Removing this setting will introduce some parallelism,</span>
<span># but will not solve the problems described in this article.</span>
$ GOMAXPROCS<span>=</span><span>1</span> go run main.go
world
hello
hello
world
...</code></pre></div>
<h2 id="language-runtimes-and-multi-tenancy">Language Runtimes and Multi-Tenancy</h2>

<p>Let’s implement a sample Go SaaS that fetches the contents of a URL
for multiple tenants in parallel:</p>
<div><pre><code data-lang="go"><span>package</span> <span>main</span>

<span>import</span> (
    <span>"fmt"</span>
    <span>"net/http"</span>
    <span>"sync"</span>
)

<span>// fetch in our example performs some SaaS work for a tenant,
</span><span>// in this case it gets the URL contents from the internet
</span><span></span><span>func</span> <span>work</span>(<span>wg</span> <span>*</span><span>sync</span>.<span>WaitGroup</span>, <span>tenant</span> <span>int</span>, <span>url</span> <span>string</span>) {
    <span>defer</span> <span>wg</span>.<span>Done</span>()
    <span>// Don't ignore errors in real code, folks, and close the response body
</span><span></span>    <span>re</span>, <span>err</span> <span>:=</span> <span>http</span>.<span>Get</span>(<span>url</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>fmt</span>.<span>Printf</span>(<span>"Tenant(%v) error -&gt; -&gt;  %v\n"</span>, <span>tenant</span>, <span>err</span>)
        <span>return</span>
    }
    <span>defer</span> <span>re</span>.<span>Body</span>.<span>Close</span>()
    <span>fmt</span>.<span>Printf</span>(<span>"Tenant(%v) -&gt; %v\n"</span>, <span>tenant</span>, <span>re</span>.<span>Status</span>)
}

<span>func</span> <span>main</span>() {
    <span>// wg waits for a collection of goroutines to finish
</span><span></span>    <span>// https://golang.org/pkg/sync/#WaitGroup
</span><span></span>    <span>wg</span> <span>:=</span> <span>sync</span>.<span>WaitGroup</span>{}
    <span>url</span> <span>:=</span> <span>"http://www.golang.org/"</span>
    <span>for</span> <span>tenant</span> <span>:=</span> <span>0</span>; <span>tenant</span> &lt; <span>3</span>; <span>tenant</span><span>++</span> {
        <span>wg</span>.<span>Add</span>(<span>1</span>)
        <span>// 'go' starts a goroutine, a lightweight thread which is managed by the Go runtime
</span><span></span>        <span>// https://tour.golang.org/concurrency/1
</span><span></span>        <span>go</span> <span>work</span>(<span>&amp;</span><span>wg</span>, <span>tenant</span>, <span>url</span>)
    }
    <span>// wait for all goroutines to finish
</span><span></span>    <span>wg</span>.<span>Wait</span>()
}
</code></pre></div>
<p>My computer runs the program in no time:</p>
<div><pre><code data-lang="bash">$ go run simple/main.go 
Tenant<span>(</span>2<span>)</span> -&gt; <span>200</span> OK
Tenant<span>(</span>1<span>)</span> -&gt; <span>200</span> OK
Tenant<span>(</span>0<span>)</span> -&gt; <span>200</span> OK</code></pre></div>
<p>We can imagine that the Go runtime executes the program in the following order:</p>
<div><pre><code data-lang="go"><span>goroutine0</span> = <span>call</span> <span>work</span> <span>with</span> <span>args</span>(<span>0</span>, <span>"http://golang.org"</span>)
<span>handle0</span> = <span>http</span>.<span>Get</span>(<span>"http://golang.org"</span>)
<span>handles</span>.<span>Add</span>(<span>handle0</span>, <span>goroutine0</span>)
<span>sleepingGoroutines</span>.<span>Add</span>(<span>goroutine0</span>)

<span>goroutine0</span> = <span>call</span> <span>work</span> <span>with</span> <span>args</span>(<span>1</span>, <span>"http://golang.org"</span>)
<span>handle1</span> = <span>http</span>.<span>Get</span>(<span>"http://golang.org"</span>)
<span>handles</span>.<span>Add</span>(<span>handle1</span>, <span>goroutine1</span>)
<span>sleepingGoroutines</span>.<span>Add</span>(<span>goroutine1</span>)
<span>...</span>
<span>// main program waits until any function returns data from the internet
</span><span></span><span>handle</span> = <span>epoll</span>(<span>handles</span>)
<span>...</span> 
<span>// Continue execution of goroutine 0
</span><span></span>print(<span>response</span>)
<span>// main program waits until any other handle returns data from the internet
</span><span></span><span>handle</span> = <span>epoll</span>(<span>handles</span>)
<span>// Continue execution of goroutine 0
</span><span></span>print(<span>response</span>)
</code></pre></div>
<p>This parallelism and blocking call is an illusion created by a combination of the use of the asynchronous
<a href="https://kovyrin.net/2006/04/13/epoll-asynchronous-network-programming/">epoll</a> Linux function
and Go’s built in runtime scheduler. <code>epoll</code> can efficiently handle thousands of network sockets at once.</p>

<p>The Go runtime activates a smart scheduler to handle <code>go</code> statements - goroutines.
It makes sure that every goroutine gets its share of CPU time and suspends
execution when the function is waiting on network or file input/output.
It’s not unusual to have tens of thousands of goroutines in the system
and see the Go runtime handle the requests well.</p>

<p>If you are interested in a more detailed intro to the Go scheduler, take a look at this article
from <a href="https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html">Ardan Labs</a>.</p>

<p>This makes Go a great language for handling concurrent network requests
that constitute the bulk of an average software as a service program that reads and writes to a database
or an external service.</p>

<h2 id="when-fair-scheduling-breaks-down">When fair scheduling breaks down</h2>

<p>Language runtimes do not have full control and visibility into
the resource allocation that is done by the Linux kernel.</p>

<p>This is where the multi-tenancy service promise of fair scheduling breaks down.</p>

<p>Take a look at this number-crunching service that computes factorials on demand:</p>
<div><pre><code data-lang="go"><span>package</span> <span>main</span>

<span>import</span> (
    <span>"fmt"</span>
    <span>"sync"</span>
    <span>"time"</span>
)

<span>// This implementation has a problem, but our code review did not catch it -
</span><span>// all the engineers were busy arguing on HN.
</span><span></span><span>func</span> <span>factorial</span>(<span>n</span> <span>int64</span>) <span>int64</span> {
    <span>b</span> <span>:=</span> int64(<span>1</span>)
    <span>for</span> <span>i</span> <span>:=</span> int64(<span>1</span>); <span>i</span> <span>&lt;=</span> <span>n</span>; <span>i</span><span>++</span> {
        <span>b</span> <span>*=</span> <span>i</span>
    }
    <span>return</span> <span>b</span>
}

<span>func</span> <span>work</span>(<span>wg</span> <span>*</span><span>sync</span>.<span>WaitGroup</span>, <span>tenant</span> <span>int</span>, <span>number</span> <span>int64</span>) {
    <span>defer</span> <span>wg</span>.<span>Done</span>()
    <span>number</span> = <span>factorial</span>(<span>number</span>)
    <span>end</span> <span>:=</span> <span>time</span>.<span>Now</span>().<span>UTC</span>()
    <span>fmt</span>.<span>Printf</span>(<span>"Tenant(%v) -&gt; %v at %v\n"</span>, <span>tenant</span>, <span>number</span>, <span>end</span>.<span>Format</span>(<span>"15:04:05.000000"</span>))
}

<span>func</span> <span>main</span>() {
    <span>// wg waits for a collection of goroutines to finish
</span><span></span>    <span>// https://golang.org/pkg/sync/#WaitGroup
</span><span></span>    <span>wg</span> <span>:=</span> <span>sync</span>.<span>WaitGroup</span>{}
    <span>for</span> <span>tenant</span> <span>:=</span> <span>0</span>; <span>tenant</span> &lt; <span>10</span>; <span>tenant</span><span>++</span> {
        <span>wg</span>.<span>Add</span>(<span>1</span>)
        <span>// 'go' starts a goroutine, a lightweight thread which is managed by the Go runtime
</span><span></span>        <span>// https://tour.golang.org/concurrency/1
</span><span></span>        <span>if</span> <span>tenant</span> <span>==</span> <span>0</span> {
            <span>go</span> <span>work</span>(<span>&amp;</span><span>wg</span>, <span>tenant</span>, <span>10000000000</span>)
        } <span>else</span> {
            <span>go</span> <span>work</span>(<span>&amp;</span><span>wg</span>, <span>tenant</span>, <span>10</span><span>+</span>int64(<span>tenant</span>))
        }
    }
    <span>// wait for all goroutines to finish
</span><span></span>    <span>wg</span>.<span>Wait</span>()
}
</code></pre></div>
<p>In this case, you would not observe the same efficient parallelism.</p>

<p>My execution prints:</p>
<div><pre><code data-lang="bash"><span># GOMAXPROCS limits the execution to one CPU</span>
$ GOMAXPROCS<span>=</span><span>1</span> go run fib/main.go
Tenant<span>(</span>9<span>)</span> -&gt; <span>121645100408832000</span> at 00:20:42.111520
Tenant<span>(</span>1<span>)</span> -&gt; <span>39916800</span> at 00:20:52.480150
Tenant<span>(</span>2<span>)</span> -&gt; <span>479001600</span> at 00:20:52.480171
Tenant<span>(</span>3<span>)</span> -&gt; <span>6227020800</span> at 00:20:52.480174
Tenant<span>(</span>4<span>)</span> -&gt; <span>87178291200</span> at 00:20:52.480177
Tenant<span>(</span>5<span>)</span> -&gt; <span>1307674368000</span> at 00:20:52.480179
Tenant<span>(</span>6<span>)</span> -&gt; <span>20922789888000</span> at 00:20:52.480181
Tenant<span>(</span>7<span>)</span> -&gt; <span>355687428096000</span> at 00:20:52.480184
Tenant<span>(</span>8<span>)</span> -&gt; <span>6402373705728000</span> at 00:20:52.480209
Tenant<span>(</span>0<span>)</span> -&gt; <span>0</span> at 00:20:52.480212</code></pre></div>
<p>Because of the inefficient factorial implementation that took a lot of iterations
and number crunching, tenant 0 consumed all the CPU time and degraded performance for the others.</p>

<p>We can fix the factorial function and add code that limits the possible input numbers.
However, our service has just suffered an outage due to a bug in the code for all our customers,
<a href="https://goteleport.com/resources/videos/workflow-access-pageduty-slack/">PagerDuty</a> is ringing and we are not sleeping again.</p>

<h2 id="a-real-world-example">A real-world example</h2>

<p>I made up our factorial example, but let’s create a real world one using
decompression bombs.</p>

<p>Decompression bombs are specially crafted archives that are small, but expand
into files ranging from tens to thousands of times their size.</p>

<p>They are specifically designed to take down your service. Anyone can download
one <a href="https://bomb.codes/bombs">from the internet</a>.</p>

<p>Some archives use simple techniques like compressing very large files
filled with zeroes. They take advantage of the fact that compression algorithms
represent a huge file with zeroes with a version of <code>repeat billion zeroes here</code>.</p>

<p>More <a href="https://www.usenix.org/system/files/woot19-paper_fifield_0.pdf">sophisticated approaches</a>
explore compression techniques in depth and craft evil files
that can explode to petabytes of disk space. The danger is real and lots of programs are
vulnerable on the internet right now.</p>

<p>Let’s explore the effect of such archive on a multi-tenant service.
Our new service unpacks the archive and counts the number of words in a file:</p>
<div><pre><code data-lang="go"><span>package</span> <span>main</span>

<span>import</span> (
	<span>"bufio"</span>
	<span>"bytes"</span>
	<span>"compress/gzip"</span>
	<span>"fmt"</span>
	<span>"io"</span>
	<span>"io/ioutil"</span>
	<span>"log"</span>
	<span>"sync"</span>
	<span>"time"</span>
)

<span>func</span> <span>createArchive</span>() []<span>byte</span> {
	<span>var</span> <span>buf</span> <span>bytes</span>.<span>Buffer</span>
	<span>zw</span> <span>:=</span> <span>gzip</span>.<span>NewWriter</span>(<span>&amp;</span><span>buf</span>)

	<span>_</span>, <span>err</span> <span>:=</span> <span>zw</span>.<span>Write</span>([]byte(<span>"A long time ago in a galaxy far, far away..."</span>))
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}

	<span>if</span> <span>err</span> <span>:=</span> <span>zw</span>.<span>Close</span>(); <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}

	<span>return</span> <span>buf</span>.<span>Bytes</span>()
}

<span>func</span> <span>count</span>(<span>wg</span> <span>*</span><span>sync</span>.<span>WaitGroup</span>, <span>tenant</span> <span>int</span>, <span>archive</span> []<span>byte</span>) {
	<span>defer</span> <span>wg</span>.<span>Done</span>()
	<span>buf</span> <span>:=</span> <span>bytes</span>.<span>NewBuffer</span>(<span>archive</span>)
	<span>zr</span>, <span>err</span> <span>:=</span> <span>gzip</span>.<span>NewReader</span>(<span>buf</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>unpacked</span> <span>:=</span> <span>&amp;</span><span>bytes</span>.<span>Buffer</span>{}
	<span>if</span> <span>_</span>, <span>err</span> <span>:=</span> <span>io</span>.<span>Copy</span>(<span>unpacked</span>, <span>zr</span>); <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>if</span> <span>err</span> <span>:=</span> <span>zr</span>.<span>Close</span>(); <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>words</span> <span>:=</span> <span>0</span>
	<span>scanner</span> <span>:=</span> <span>bufio</span>.<span>NewScanner</span>(<span>unpacked</span>)
	<span>scanner</span>.<span>Split</span>(<span>bufio</span>.<span>ScanWords</span>)
	<span>for</span> <span>scanner</span>.<span>Scan</span>() {
		<span>words</span><span>++</span>
	}
	<span>end</span> <span>:=</span> <span>time</span>.<span>Now</span>().<span>UTC</span>()
	<span>fmt</span>.<span>Printf</span>(<span>"Tenant(%v) -&gt; counted %v words at %v\n"</span>, <span>tenant</span>, <span>words</span>, <span>end</span>.<span>Format</span>(<span>"15:04:05.000000"</span>))
}

<span>func</span> <span>main</span>() {
	<span>archive</span> <span>:=</span> <span>createArchive</span>()

	<span>// CAUTION: this can crash your computer.
</span><span></span>	<span>// Take a gzip bomb from https://bomb.codes
</span><span></span>	<span>// https://github.com/bones-codes/bombs/raw/master/archives/10GB/10GB.gz.bz2
</span><span></span>	<span>// bzip2 -d 10GB.gz.bz2 and then
</span><span></span>	<span>bomb</span>, <span>err</span> <span>:=</span> <span>ioutil</span>.<span>ReadFile</span>(<span>"./10GB.gz"</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>, <span>bomb</span>)
	}

	<span>wg</span> <span>:=</span> <span>sync</span>.<span>WaitGroup</span>{}
	<span>for</span> <span>tenant</span> <span>:=</span> <span>0</span>; <span>tenant</span> &lt; <span>100</span>; <span>tenant</span><span>++</span> {
		<span>wg</span>.<span>Add</span>(<span>1</span>)
		<span>if</span> <span>tenant</span><span>%</span><span>2</span> <span>==</span> <span>0</span> {
			<span>go</span> <span>count</span>(<span>&amp;</span><span>wg</span>, <span>tenant</span>, <span>bomb</span>)
		} <span>else</span> {
			<span>go</span> <span>count</span>(<span>&amp;</span><span>wg</span>, <span>tenant</span>, <span>archive</span>)
		}
	}
	<span>wg</span>.<span>Wait</span>()
}
</code></pre></div>
<p>Here is a run on my machine:</p>
<div><pre><code data-lang="bash">$ go run multi.go 
Tenant<span>(</span>1<span>)</span> -&gt; counted <span>10</span> words at 01:32:57.558848
..
Tenant<span>(</span>63<span>)</span> -&gt; counted <span>10</span> words at 01:32:57.888672
...
Tenant<span>(</span>21<span>)</span> -&gt; counted <span>10</span> words at 01:32:58.337926
signal: killed</code></pre></div>
<p>My computer terminated the process that ran out of memory.</p>

<h2 id="resource-isolation-with-cgroups">Resource isolation with cgroups</h2>

<p>The core of the problem is that CPU time is limited. Programming language runtimes lack
the control and context required to efficiently distribute the CPU time per goroutine.</p>

<p>There is no great solution in the modern programming language runtime that solves
this problem once and for all. Some language runtimes, like the <a href="https://hamidreza-s.github.io/erlang/scheduling/real-time/preemptive/migration/2016/02/09/erlang-scheduler-details.html">Erlang</a>
preemptive scheduler provide more isolation and control. Unfortunately, Erlang does not solve
the problem of memory management and its isolation comes with a performance cost.</p>

<p>There are some workarounds we can use today to provide better quality of service
guarantees to our …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goteleport.com/blog/multi-tenant-pitfalls/">https://goteleport.com/blog/multi-tenant-pitfalls/</a></em></p>]]>
            </description>
            <link>https://goteleport.com/blog/multi-tenant-pitfalls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298636</guid>
            <pubDate>Fri, 04 Dec 2020 03:43:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No dog food today – the Linux Foundation annual report]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25298501">thread link</a>) | @BerkhanBerkdemi
<br/>
December 3, 2020 | https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><a href="https://daniel-lange.com/categories/17-Strategy"><img title="Strategy: Airplanes are interesting toys but of no military value. (Marechal Ferdinand Foch, Professor of Strategy, Ecole Superieure de Guerre)" alt="Strategy" src="https://daniel-lange.com/uploads/strategy.serendipityThumb.jpg"></a></p><p>The Linux Foundation has published its <a href="https://www.linuxfoundation.org/wp-content/uploads/2020/11/2020-Linux-Foundation-Annual-Report_113020.pdf">annual report</a> today. LWN <a href="https://lwn.net/Articles/838871">calls it glossy</a> and yeah, boy, it is shiny.</p>

<p>So shiny that people that work in the publishing industry immediately see this has been produced with the Adobe toolchain which - unfortunately - is one of the big suites of software not yet available for Linux.</p>

<p>Checking the PDF file metadata reveals the keywords "open source, open standards, open hardware, open data". That is what the Linux Foundation is about. Good stuff.</p>

<p><!-- s9ymdb:667 --><img width="552" height="676" src="https://daniel-lange.com/uploads/entries/Linux-Foundation-Annual-Report-2020-cover.jpg" title="Mouseovers are for xkcd!" alt="Linux Foundation annual report 2020 cover"></p>

<p>The PDF producer meta data for the annual report PDF has been set to "Linux kernel 0.12.1 for Workgroups" and the PDF creator meta data element to "Sharp Zaurus XR-5000 (Maemo5) Edition". Somebody thought to better hide the real data and had some tongue-in-cheek ideas. Kudos.</p>

<p>But nicer would have been to use Open Source software to produce the report, not?</p>

<p>Running <code>strings 2020-Linux-Foundation-Annual-Report_113020.pdf | grep Adobe | wc -l</code> gives us 1229 lines and confirms the suspicion of the toolchain.</p>

<p>A stale <code>/Title (Annual Report 2020) /Producer (macOS Version 10.15.7 \(Build 19H15\) Quartz PDFContext)</code> has been forgotten in the document to tell us about the platform.</p>

<p>So, ladies and gentlemen, the Linux Foundation 2020 annual report has been produced on a Mac.</p>

<p>Running Adobe Creative Cloud on MacOS Catalina 10.15.7.</p>

<p>Which is proprietary software. Its kernel (and some userland pieces) are based on BSD. Not Linux.</p>

<hr>

<p>The image on the front page also struck me as a bit odd ... using a ballpoint pen on the laptop screen?</p>

<p>Unbranded laptop.
Unbranded cup in the foreground.</p>

<p>Kid in the background <em>not</em> paying attention to his tablet.</p>

<p>All of that cries stock image so loud it hurts.</p>

<p>Google currently finds ~560 uses of the picture and any <a href="https://www.shutterstock.com/support/article/Do-I-need-to-credit-Shutterstock-the-artist-when-I-use-Images-or-Footage">editorial use</a> nicely tells us that it is © <a href="https://www.shutterstock.com/de/g/draganagordic">Dragana Gordic / Shutterstock</a>.</p>

<p>The image is "Smiling mom working at home with her child on the sofa while writing an email. Young woman working from home, while in quarantine isolation during the Covid-19 health crisis".</p>

<p>See the <a href="https://www.dailymail.co.uk/news/article-8683629/Staff-working-home-nearly-extra-hour-day-research-shows-send-emails.html">Daily Mail</a> for a wonderful example of the working mum in context. I hope, if her laptop had been powered on, it would have run Linux. I mean, what else would still run on an old white MacBook with an Intel "Core 2 Duo" processor from 2008?</p>

<p><!-- s9ymdb:668 --><img width="504" height="742" src="https://daniel-lange.com/uploads/entries/DailyMail-screenshot-stock-image.png" title="O.k., here you go: Shiny, too!" alt="Daily Mail screenshot of the same stock image used"></p>

                </div><div id="extended">
        <p>Bonus round:</p>

<p>The Ethernet port, the USB ports and the headset connector are on the left side of the MacBook. The Daily Mail got it right.</p>

<p>Mirroring images is usually not a good idea. To Linux Foundation's defense ... similar pictures are available <a href="https://www.shutterstock.com/de/image-photo/busy-young-woman-son-home-shot-1680921679">already mirrored on Shutterstuck</a> next to the <a href="https://www.shutterstock.com/de/image-photo/smiling-mom-working-home-her-child-1680923362">correctly oriented picture</a>.</p>

        </div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298501</guid>
            <pubDate>Fri, 04 Dec 2020 03:18:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker’s Guide to Online Anonymity]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25298487">thread link</a>) | @todsacerdoti
<br/>
December 3, 2020 | https://anonymousplanet.github.io/thgtoa/guide.html | <a href="https://web.archive.org/web/*/https://anonymousplanet.github.io/thgtoa/guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<ul>
  <li><a href="#introduction">Introduction:</a></li>
  <li><a href="#requirements">Requirements:</a></li>
  <li><a href="#understanding-some-basics-of-how-some-information-can-lead-back-to-you-and-how-to-mitigate-those">Understanding some basics of how some information can lead back to you and how to mitigate those:</a>
    <ul>
      <li><a href="#your-ip-address">Your IP address:</a></li>
      <li><a href="#your-dns-requests">Your DNS requests:</a></li>
      <li><a href="#your-imei-and-imsi-and-by-extension-your-phone-number">Your IMEI and IMSI (and by extension, your phone number):</a></li>
      <li><a href="#your-wi-fi-mac-address">Your Wi-Fi MAC address:</a></li>
      <li><a href="#your-bluetooth-mac-address">Your Bluetooth MAC address:</a></li>
      <li><a href="#your-operating-systems-and-apps-telemetry-services">Your Operating Systems and Apps telemetry services:</a></li>
      <li><a href="#the-wifis-and-bluetooth-devices-around-you">The WIFIs and Bluetooth devices around you:</a></li>
      <li><a href="#your-metadata-including-your-geo-location">Your Metadata including your Geo-Location:</a></li>
      <li><a href="#your-smart-devices-in-general">Your Smart devices in general:</a></li>
      <li><a href="#your-devices-can-be-tracked-even-when-completely-powered-off">Your Devices can be tracked even when completely powered off:</a></li>
      <li><a href="#your-rfid-enabled-devices">Your RFID enabled devices:</a></li>
      <li><a href="#your-files-propertiesmetadata">Your Files Properties/Metadata:</a></li>
      <li><a href="#your-anonymized-torvpn-traffic">Your “Anonymized” Tor/VPN traffic:</a></li>
      <li><a href="#your-crypto-transactions">Your Crypto transactions:</a></li>
      <li><a href="#exploits-in-your-apps">Exploits in your apps:</a></li>
      <li><a href="#your-cloud-backupssync-services">Your Cloud backups/sync services:</a></li>
      <li><a href="#your-digital-fingerprint-and-footprint">Your Digital Fingerprint And Footprint:</a></li>
      <li><a href="#your-real-life">Your Real Life:</a></li>
      <li><a href="#your-browser-and-device-fingerprints">Your Browser and Device Fingerprints:</a></li>
      <li><a href="#your-face-and-other-biometrics">Your Face and other Biometrics:</a></li>
      <li><a href="#phishing">Phishing:</a></li>
      <li><a href="#forensics">Forensics:</a></li>
      <li><a href="#advanced-targeted-techniques">Advanced targeted techniques:</a></li>
      <li><a href="#notes">Notes:</a></li>
    </ul>
  </li>
  <li><a href="#general-preparations">General Preparations:</a>
    <ul>
      <li><a href="#picking-your-route">Picking your route:</a>
        <ul>
          <li><a href="#budgetmaterial-limitations">Budget/Material limitations:</a></li>
          <li><a href="#skills">Skills:</a></li>
          <li><a href="#adversaries-threats">Adversaries (threats):</a></li>
        </ul>
      </li>
      <li><a href="#steps-for-all-routes">Steps for all routes:</a>
        <ul>
          <li><a href="#get-a-burner-phone">Get a burner phone:</a></li>
          <li><a href="#get-an-anonymous-pre-paid-sim-card">Get an anonymous pre-paid SIM card:</a></li>
          <li><a href="#get-an-usb-key">Get an USB key:</a></li>
          <li><a href="#find-some-safe-places-with-decent-public-wifi">Find some safe places with decent public WIFI:</a></li>
        </ul>
      </li>
      <li><a href="#the-tails-route">The TAILS route:</a></li>
      <li><a href="#steps-for-all-other-routes">Steps for all other routes:</a>
        <ul>
          <li><a href="#get-a-laptop-for-your-anonymous-activities">Get a laptop for your anonymous activities:</a></li>
          <li><a href="#a-note-for-linux-users-to-avoid-wasting-your-time-later">A note for Linux users to avoid wasting your time later:</a></li>
          <li><a href="#biosuefi-settings-of-your-laptop">Bios/UEFI Settings of your laptop:</a></li>
          <li><a href="#tamper-protect-your-laptop">Tamper protect your laptop:</a></li>
        </ul>
      </li>
      <li><a href="#the-whonix-route">The Whonix route:</a>
        <ul>
          <li><a href="#picking-your-host-os-the-os-installed-on-your-laptop">Picking your Host OS (the OS installed on your laptop):</a></li>
          <li><a href="#enable-mac-address-randomization-on-your-laptop">Enable MAC address randomization on your laptop:</a></li>
          <li><a href="#setting-up-a-safe-browser-on-your-host-os">Setting up a safe Browser on your Host OS:</a></li>
          <li><a href="#enable-some-additional-privacy-settings-on-your-host-os">Enable some additional privacy settings on your Host OS:</a></li>
          <li><a href="#windows-host-os-encryption">Windows Host OS encryption:</a></li>
          <li><a href="#virtualbox">Virtualbox:</a></li>
          <li><a href="#get-an-anonymous-cash-paid-vpn-subscription">Get an anonymous (cash-paid) VPN subscription:</a></li>
          <li><a href="#download-various-utilities">Download various utilities:</a></li>
          <li><a href="#whonix-virtual-machines">Whonix Virtual Machines:</a></li>
          <li><a href="#windows-10-virtual-machine">Windows 10 Virtual Machine:</a></li>
          <li><a href="#vpn-client-installation-cash-paid">VPN client installation (cash-paid):</a></li>
          <li><a href="#keepassxc">KeePassXC:</a></li>
        </ul>
      </li>
      <li><a href="#the-qubes-route">The Qubes Route:</a></li>
    </ul>
  </li>
  <li><a href="#creating-your-anonymous-online-identities">Creating your anonymous online identities:</a>
    <ul>
      <li><a href="#understanding-the-methods-used-to-prevent-anonymity-and-verify-identity">Understanding the methods used to prevent anonymity and verify identity:</a>
        <ul>
          <li><a href="#captchas">Captchas:</a></li>
          <li><a href="#phone-verification">Phone verification:</a></li>
          <li><a href="#e-mail-verification">E-Mail verification:</a></li>
          <li><a href="#user-details-checking">User details checking:</a></li>
          <li><a href="#proof-of-id-verification">Proof of ID verification:</a></li>
          <li><a href="#ip-filters">IP Filters:</a></li>
          <li><a href="#browser-and-device-fingerprinting">Browser and Device Fingerprinting:</a></li>
          <li><a href="#human-interaction">Human interaction:</a></li>
          <li><a href="#user-moderation">User Moderation:</a></li>
          <li><a href="#behavioral-analysis">Behavioral Analysis:</a></li>
          <li><a href="#financial-transactions">Financial transactions:</a></li>
          <li><a href="#sign-in-with-some-platform">Sign-in with some platform:</a></li>
          <li><a href="#live-face-recognition-and-biometrics-again">Live Face recognition and biometrics (again):</a></li>
          <li><a href="#manual-reviews">Manual reviews:</a></li>
        </ul>
      </li>
      <li><a href="#getting-online">Getting Online:</a></li>
      <li><a href="#creating-new-identities">Creating new identities:</a></li>
      <li><a href="#protonmail">ProtonMail:</a></li>
      <li><a href="#google">Google:</a></li>
      <li><a href="#twitter">Twitter:</a></li>
      <li><a href="#linkedin">Linkedin:</a></li>
      <li><a href="#microsoft">Microsoft:</a></li>
      <li><a href="#instagram">Instagram:</a></li>
      <li><a href="#facebook">Facebook:</a></li>
      <li><a href="#github">Github:</a></li>
      <li><a href="#discord">Discord:</a></li>
      <li><a href="#telegram">Telegram:</a></li>
      <li><a href="#reddit">Reddit:</a></li>
      <li><a href="#chan">4chan:</a></li>
      <li><a href="#crypto-wallets">Crypto Wallets:</a></li>
      <li><a href="#what-about-those-mobile-only-apps-whatsappsignal">What about those mobile only apps (Whatsapp/Signal):</a></li>
      <li><a href="#anything-else">Anything else:</a></li>
      <li><a href="#maintenance-tasks">Maintenance tasks:</a></li>
    </ul>
  </li>
  <li><a href="#backup-your-work-safely-and-anonymously">Backup your work (safely and anonymously):</a></li>
  <li><a href="#covering-your-tracks">Covering your tracks:</a>
    <ul>
      <li><a href="#protecting-yourself-against-forensics">Protecting yourself against forensics:</a></li>
      <li><a href="#tails">Tails:</a></li>
      <li><a href="#windows-1">Windows:</a>
        <ul>
          <li><a href="#diagnostic-data-and-telemetry">Diagnostic Data and Telemetry:</a></li>
          <li><a href="#eventlogs">Eventlogs:</a></li>
          <li><a href="#veracrypt-history">Veracrypt History:</a></li>
          <li><a href="#external-tool-cleaning">External Tool Cleaning:</a></li>
          <li><a href="#shellbags">Shellbags:</a></li>
          <li><a href="#wi-fi-history">Wi-Fi History:</a></li>
        </ul>
      </li>
      <li><a href="#how-to-securely-wipe-your-whole-laptop-if-you-want-to-erase-everything">How to securely wipe your whole laptop if you want to erase everything:</a>
        <ul>
          <li><a href="#linux-1">Linux:</a></li>
          <li><a href="#windows-2">Windows: </a></li>
        </ul>
      </li>
      <li><a href="#if-you-think-you-got-burned">If you think you got burned:</a>
        <ul>
          <li><a href="#if-you-have-some-time">If you have some time:</a></li>
          <li><a href="#if-you-have-no-time">If you have no time:</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#some-last-opsec-thoughts">Some last OPSEC thoughts:</a></li>
  <li><a href="#appendix-a-windows-installation">Appendix A: (Windows Installation)</a>
    <ul>
      <li><a href="#installation">Installation:</a></li>
      <li><a href="#privacy-settings">Privacy Settings:</a></li>
    </ul>
  </li>
  <li><a href="#appendix-b-windows-additional-privacy-settings">Appendix B: (Windows Additional Privacy Settings)</a></li>
  <li><a href="#appendix-c-windows-installation-media-creation">Appendix C: (Windows Installation Media Creation)</a></li>
</ul>

<p>Version 0.1.1 (draft), December 2020 (work in progress, some parts are incomplete) by AnonymousPlanet</p>

<p>This guide is open-source, licensed under Creative Commons Attribution 4.0 International (cc-by-4.0).</p>

<p>Feel free to submit issues/recommendations/ideas using Github Issues at: <a href="https://github.com/AnonymousPlanet/thgtoa/issues">https://github.com/AnonymousPlanet/thgtoa/issues</a></p>

<p>PDF version of this guide at: <a href="https://github.com/AnonymousPlanet/thgtoa/raw/main/guide.pdf">https://github.com/AnonymousPlanet/thgtoa/raw/main/guide.pdf</a></p>



<p>Making a social media account with a pseudonym or artist/brand name is easy. And it’s enough is most use cases to protect your identity as the next George Orwell. There are plenty of people using pseudonyms all over Facebook/Instagram/Twitter/Linkedin/TikTok/Snapchat/Reddit/… But the vast majority of those are anything but anonymous and can easily be traced to their real identity by your local cops, random people within the OSINT<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (Open-Source Intelligence) community and trolls<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> on 4chan<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This is a good thing as most criminals/trolls are not really tech savvy and will be identified with ease. But this is also a bad thing as most political dissidents, human rights activists and whistleblowers can also be tracked rather easily.</p>

<p>This updated guide aims to provide introduction to various tracking techniques, id verification techniques and guidance to creating and maintaining anonymous identities online including social media accounts safely.</p>

<p>Will this guide help you protect yourself from the NSA, the FSB, Mark Zuckerberg or the Mossad if they’re out to find you? Probably not … Mossad will be doing “Mossad things” <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup> and will probably find you no matter how hard to try to hide<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>You have to consider your threat model<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> before going further.</p>

<p><img src="https://anonymousplanet.github.io/thgtoa/media/image1.jpeg" alt=""></p>

<p>(Illustration by xkcd.com, licensed under CC BY-NC 2.5)</p>

<p>Will this guide help you protect your privacy from OSINT researchers like Belingcat<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup> , Doxing<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup> trolls on 4chan<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup> and others that have no access to the NSA toolbox? More likely. Tho I wouldn’t be so sure about 4chan.</p>

<p>It’s also important to understand this guide is the humble result of years of experience and testing from a single individual (myself) and that many of those systems that aim to prevent anonymity are opaque closed-source systems. Most of those guidelines are guessed based on experience. These experiences take a lot of time and resources and are unfortunately far from being scientific. <strong>Your mileage may vary.</strong></p>

<p>You might think this guide has no legitimate use but there are many<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">10</a></sup><sup id="fnref:11" role="doc-noteref"><a href="#fn:11">11</a></sup> such as:</p>

<ul>
  <li>
    <p>Evading Censorship</p>
  </li>
  <li>
    <p>Evading Oppression</p>
  </li>
  <li>
    <p>Evading Unlawful Government Surveillance</p>
  </li>
  <li>
    <p>Whistle Blowing</p>
  </li>
  <li>
    <p>Journalism</p>
  </li>
  <li>
    <p>Activism</p>
  </li>
</ul>

<p>This guide is written for use by those good intended individuals who might not be knowledgeable enough to consider the big picture of online anonymity.</p>

<p>This guide is not intended for:</p>

<ul>
  <li>
    <p>Creating machine accounts of any kind (bots).</p>
  </li>
  <li>
    <p>Creating impersonation accounts of existing people (identity theft).</p>
  </li>
  <li>
    <p>Helping malicious individuals conduct unlawful or unethical activities (like trolls).</p>
  </li>
  <li>
    <p>Use by minors.</p>
  </li>
</ul>

<p>Feel free to report issues or recommend improvements in this repository if you have any.</p>

<p><strong>Use at your own risk. Anything in here is not legal advice and you should verify compliance with your local law before use (IANAL</strong><sup id="fnref:12" role="doc-noteref"><a href="#fn:12">12</a></sup><strong>).</strong></p>



<ul>
  <li>
    <p><strong>Be a permanent Adult resident in Germany where the courts have upheld up the legality of not using real names on online platforms (§13 VI of the German Telemedia Act of 2007</strong> <sup id="fnref:13" role="doc-noteref"><a href="#fn:13">13</a></sup><strong>). Alternatively be resident of any other country where you can validate and verify this is legal yourself.</strong></p>
  </li>
  <li>
    <p>This guide will assume you already have access to some PC (Windows/Linux) laptop computer (not a work/shared device).</p>
  </li>
  <li>
    <p>Don’t be evil (for real this time)<sup id="fnref:14" role="doc-noteref"><a href="#fn:14">14</a></sup>.</p>
  </li>
  <li>
    <p>Have patience as this process could take several weeks to finalize.</p>
  </li>
  <li>
    <p>Have a little budget to dedicate to this process (you’ll need at least budget for an USB key).</p>
  </li>
  <li>
    <p>Have a lot of free time on your hands to dedicate to this process.</p>
  </li>
  <li>
    <p>Be prepared to read a lot of references (do read them), guides (don’t skip them) and follow a lot of how-to tutorials thoroughly (don’t skip them either).</p>
  </li>
</ul>

<p><strong>This guide will (for the moment) not recommend using MacOS due to the latest Big Sur update which forces “unblockable” telemetry</strong><sup id="fnref:15" role="doc-noteref"><a href="#fn:15">15</a></sup><sup id="fnref:16" role="doc-noteref"><a href="#fn:16">16</a></sup> <strong>and because MacOS doesn’t offer MAC address randomization.</strong></p>



<p>There are many ways you can be tracked besides browser cookies and ads, your e-mail and your phone number. And if you think only the Mossad or the NSA/FSB can find you, you would be terribly wrong.</p>

<p>Here is a non-exhaustive list of some of the many ways you can be de-anonymized:</p>

<h2 id="your-ip-address">Your IP address:</h2>

<p>Your IP address<sup id="fnref:17" role="doc-noteref"><a href="#fn:17">17</a></sup> is the most known and obvious way you can be tracked. That IP is the IP you’re using at the source. This is where you connect to the internet. That IP is usually provided by your ISP (Internet Service Provider) (xDSL, Mobile, Cable, Fiber, Cafe, Bar, Friend, Neighbor). Most countries have data retention regulations<sup id="fnref:18" role="doc-noteref"><a href="#fn:18">18</a></sup> which mandates keeping logs of who is using what IP at a certain time/date for up to several years or indefinitely. Your ISP can tell a third party that you were using a specific IP at a specific date and time, years after the fact. If that IP (the origin one) leaks at any point for any reason, it can be used to track down you directly. In many countries, you won’t be able to have internet access without providing some form of identification to the provider (address, ID, real name, e-mail …).</p>

<p>Useless to say that most platforms (such as social networks) will also keep (sometimes indefinitely) the IP addresses you used to sign-up but also those you used to sign-in.</p>

<p>For those reasons, we’ll need to not use that origin IP (the one tied to your identification) or hide it as much as we can through a combination of various means:</p>

<ul>
  <li>
    <p>Using a public WIFI service (free).</p>
  </li>
  <li>
    <p>Using an anonymous VPN service<sup id="fnref:19" role="doc-noteref"><a href="#fn:19">19</a></sup> (paid by cash).</p>
  </li>
  <li>
    <p>Using the Tor Anonymity Network<sup id="fnref:20" role="doc-noteref"><a href="#fn:20">20</a></sup> (free).</p>
  </li>
</ul>

<p>All those will be explained later in this guide.</p>

<h2 id="your-dns-requests">Your DNS requests:</h2>

<p>DNS stands for “Domain Name System”<sup id="fnref:21" role="doc-noteref"><a href="#fn:21">21</a></sup> and is a service used by your browser (and other apps) to find the IP addresses of a service. It’s pretty much a huge “contact list” (phone book for older people) that works like asking it a name and it returns the number to call. Except it returns an IP instead.</p>

<p>Every time your browser wants to access a certain service such as Google through <a href="https://www.google.com/">https://www.google.com</a>. Your Browser (Chrome or Firefox) will query a DNS service to find the IP addresses of the Google web servers.</p>

<p>Usually the DNS service is provided by your ISP and automatically configured by the network you’re connecting to. This DNS service could also be subject to data retention regulations or will just keep logs for other reasons (data collection for advertising purposes for instance). Therefore this ISP will be capable of …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anonymousplanet.github.io/thgtoa/guide.html">https://anonymousplanet.github.io/thgtoa/guide.html</a></em></p>]]>
            </description>
            <link>https://anonymousplanet.github.io/thgtoa/guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298487</guid>
            <pubDate>Fri, 04 Dec 2020 03:14:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Perfection is a process, not the result]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25298477">thread link</a>) | @phongduong
<br/>
December 3, 2020 | https://phongduong.dev/blog/perfection-is-a-process-not-the-result/ | <a href="https://web.archive.org/web/*/https://phongduong.dev/blog/perfection-is-a-process-not-the-result/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For me, perfection is that I don't want to have any errors in what I do. It's hard and exhausted to keep everything perfect. When I publish a piece of content, I want it to be perfect. But I always feel something was wrong and afraid someone would point out the error. After all, I just make a little modification and leave it behind because it's wasting time.</p>
<p>I have so much content I want to create. I don't want to stick with a piece of content for too long. When I start creating another piece of content, I try to avoid previous mistakes. I also try something new in it. The joy of creating content is you can try something new and see if it works.</p>
<p>This is the issue that makes me hesitate to create content. I want my content to be useful to my audiences. I also want to create as much content as possible. After trying some ways, I think I should prioritize the quantity rather than quality. Because I can improve my content by creating more. </p>
<p>Now, perfection for me is not the result of a piece of content. It's a process in which I try, modify, and improve pieces by pieces. If I satisfy with a blog post or video, I just publish it and create another. When I find a mistake, I will fix it.</p>
</div></div>]]>
            </description>
            <link>https://phongduong.dev/blog/perfection-is-a-process-not-the-result/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298477</guid>
            <pubDate>Fri, 04 Dec 2020 03:12:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PixelNeRF Neural Radiance Fields from One or Few Images]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25298426">thread link</a>) | @choppaface
<br/>
December 3, 2020 | https://alexyu.net/pixelnerf/ | <a href="https://web.archive.org/web/*/https://alexyu.net/pixelnerf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p id="paper-title">
            
            <h3>
                Neural Radiance Fields from One or Few Images
            </h3>
            <h3>
                <small title="Note: This is a joke">IEEE International Conference on Neural Radiance Fields (ICNeRF)</small>
            </h3>
        </p>

        
        
        <div>
            <div>
                <div id="dynamic-teaser">
                     <!-- row -->

                     <!-- row -->
                    <div id="teaser-dtu">
                        <div>
                            <p>3 Input Views</p>
                            
                            <p><strong>pixelNeRF</strong></p>
                            <p>3-view NeRF</p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_inputs.jpg">
                            </p>
                            
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_outputs_sm.gif">
                            </p>
                        </div> <!-- row -->
                    </div>
                </div> <!-- dynamic-teaser -->
                <!-- <img id="teaser" src="img/teaser.png" class="img-responsive" alt="teaser figure"> -->
                <p>
                    We propose pixelNeRF, a learning framework that predicts a continuous neural scene representation conditioned on
                    one or few input images.
                    The existing approach for
                    constructing neural radiance fields&nbsp;<a href="https://www.matthewtancik.com/nerf">[Mildenhall et al. 2020]</a>
                    involves optimizing the representation to every scene independently, requiring many calibrated views and significant compute time.
                    We take a step towards resolving these shortcomings
                    by introducing an architecture that conditions a NeRF on image inputs in a fully convolutional manner. This allows the network to be trained across multiple scenes to learn a scene prior, enabling it to perform novel view synthesis in a feed-forward manner from a sparse set of views (as few as one).
                </p>

            </div>
        </div>
        <div id="overview-video">
            <div>
                <h4>Narrated Overview</h4>
                <p>
                    <iframe src="https://www.youtube.com/embed/voebZx7f32g" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </p>
            </div>
        </div>
        <div>
            <div>
                <p>
                    Leveraging the volume rendering approach of NeRF, our model can be trained directly from images with no explicit 3D supervision.
                    We conduct extensive experiments on ShapeNet benchmarks for single image novel view synthesis tasks with held-out objects as well as entire unseen categories.
                    We further demonstrate the flexibility of pixelNeRF by demonstrating it on multi-object ShapeNet scenes and real scenes from the DTU dataset. In all cases, pixelNeRF outperforms current state-of-the-art baselines for novel view synthesis and single image 3D reconstruction.
                </p>
                <p><img src="https://alexyu.net/pixelnerf/img/pipeline.png" alt="pipeline">
            </p></div>
        </div>
        <div>
            <div>
                <h4>Feed-forward NeRF from One View</h4>
                <p>
                    Using multiview image supervision, we train a single pixelNeRF to 13 largest object categories
                    in ShapeNet in order to perform novel-view synthesis on unseen objects.
                    Our approach operates in <strong>view-space</strong>—as opposed to canonical—and requires <strong>no test-time optimization</strong>.
                    Nevertheless, in terms of image metrics, we significantly outperform existing methods quantitatively, as shown in the paper.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_000.gif" alt="shapenet results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_001.gif" alt="shapenet results animated">
                    </p></div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Scene-level Representation</h4>
                <p>
                    Since our method requires <strong>neither canonical space nor object-level information such as masks</strong>,
                    it can represent scenes with multiple objects, where a canonical space is unavailable,
                    without modification.
                    Our method can also <strong>seemlessly integrate multiple views</strong> at test-time to obtain better results.
                    SRN performs extremely poorly here due to the lack of a consistent canonical space.
                </p>
                <div>
                    <div>
                        <div>
                            <p>2 Input Views</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                    <div>
                        <div>
                            
                            <p>1 Input View</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Real-world Scenes</h4>
                <p>
                    We show that our method can also conduct wide-baseline view synthesis on more complex real scenes from the <a href="http://roboimagedata.compute.dtu.dk/?page_id=36">DTU MVS</a> dataset,
                    producing reasonable results when given only 1-3 views at inference time.
                    Moreover, it is feed-forward without requiring test-time optimization for each scene.
                </p>
                <div>
                    
                    <div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu_inputs.jpg" alt="DTU 3 input images">
                        </p>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu.gif" alt="DTU results animated">
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Generalization</h4>
                <p>
                    To demonstrate generalization capabilities,
                    we apply a model trained on ShapeNet planes, cars, and chairs to unseen ShapeNet categories.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_000.gif" alt="shapenet unseen category results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_001.gif" alt="shapenet unseen category results animated">
                    </p></div>
                </div>
                <p>
                    Separately, we apply a pretrained model on real car images after background removal.
                </p>
                
                
            </div>
        </div>
        <div>
            <div>
                <h4>Related Links</h4>
                <ul>
                    <li>
                        NeRF was introduced in <a href="https://www.matthewtancik.com/nerf">Mildenhall et al. (2020)</a>
                    </li><li>
                        Local image features were used in the related regime of implicit surfaces in
                        <a href="https://shunsukesaito.github.io/PIFu/">Saito et al. (2019)</a>
                        and
                        <a href="https://arxiv.org/abs/1905.10711">Xu et al. (2019)</a>
                    </li><li>
                        Our MLP architecture is
                        inspired by
                        <a href="https://avg.is.tuebingen.mpg.de/publications/niemeyer2020cvpr">DVR</a>
                    </li><li>
                        Parts of our
                        PyTorch NeRF implementation are taken from
                        <a href="https://github.com/kwea123/nerf_pl">kwea123</a>
                    </li><li>
                        Also see the concurrent work
                        <a href="https://arxiv.org/abs/2010.04595">GRF</a>
                        which also introduces image features for NeRF, showing image features can even improve NeRF when a large number of views are available.
                </li></ul>
            </div>
        </div>
        
        <div>
            <div>
                <h4>Acknowledgements</h4>
                <p>
                    We thank Shubham Goel and Hang Gao for comments on the text. We also thank
                    Emilien Dupont and Vincent Sitzmann for helpful discussions.
                    This website is inspired by the template of <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                </p>
                <p>
                    Please send any questions or comments to <a href="https://alexyu.net/">Alex Yu</a>.
                </p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexyu.net/pixelnerf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298426</guid>
            <pubDate>Fri, 04 Dec 2020 03:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Bagatto – an extensible, transparent static site generator]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25298374">thread link</a>) | @crux
<br/>
December 3, 2020 | https://git.sr.ht/~subsetpark/bagatto | <a href="https://web.archive.org/web/*/https://git.sr.ht/~subsetpark/bagatto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="readme">
    <div>
      <div><h2 id="bagatto"><a href="#bagatto" rel="nofollow noopener">#</a>Bagatto</h2>
<p><img alt="Il Mago" src="https://git.sr.ht/~subsetpark/bagatto/blob/master/logo.jpg"></p>
<h3 id="the-extensible-transparent-static-site-generator"><a href="#the-extensible-transparent-static-site-generator" rel="nofollow noopener">#</a>The extensible, transparent static site generator</h3>
<p>Bagatto is a static site generator written in <a href="https://janet-lang.org/index.html" rel="nofollow noopener">Janet</a>.</p>
<p>It is inspired most directly by Garrett Smith's <a href="https://github.com/gar1t/lambdapad" rel="nofollow noopener">LambdaPad</a>, a SSG
in Erlang. LambdaPad falls more to code side of the config--code
spectrum, and Bagatto follows that philosophy. Thus, it's designed to
expose the full expressive power and extensiblity of the language it's
written in. Janet is a lisp that's designed for simplicity and ease of
embedding, and thus it's a very good fit for this model.</p>
<p>To create a Bagatto website, you should create a single Janet source
file. Because you're writing normal source code, you have the full
power of the Janet language at your disposal. Bagatto tries to keep
the "magic" to a minimum; in all cases, it tries to make the process
of loading source files and of generating new files completely
transparent, inspectable and extensible.</p>
<h3 id="the-model"><a href="#the-model" rel="nofollow noopener">#</a>The Model</h3>
<p>In Bagatto, a website consists of two things: a <strong>data specification</strong>,
and a <strong>site specification</strong>.</p>
<p>A data specification describes all the inputs into the site
generator. These are of two main types: either Janet values or
references to other source files, eg., JSON configuration files or
Markdown articles. When Bagatto evaluates a data specification, it
loads all of the files and parses them for arbitrary
<strong>attributes</strong>. It includes some baseline attributes, like path and
contents, but allows the site author to specify or implement other
attribute parsers. For instance, it comes with a parser function that
will read the YAML frontmatter from a Markdown file and include those
as additional attributes.</p>
<p>Here's an example data specification:</p>
<div><pre><span></span><span>(</span><span>def </span><span>data</span> <span>{</span><span>:config</span> <span>{</span><span>:attrs</span> <span>{</span><span>:title</span> <span>"A Demo Bagatto Config"</span><span>}}</span>
           <span>:posts</span> <span>{</span><span>:src</span> <span>(</span><span>bagatto/slurp-*</span> <span>"posts/*.md"</span><span>)</span>
                   <span>:attrs</span> <span>parse-post</span><span>}</span>
           <span>:static</span> <span>{</span><span>:src</span> <span>(</span><span>bagatto/*</span> <span>"static/*"</span><span>)</span>
                    <span>:attrs</span> <span>bagatto/parse-base</span><span>}</span>
           <span>:config-json</span> <span>{</span><span>:src</span> <span>"config.json"</span>
                         <span>:attrs</span> <span>bagatto/parse-json</span><span>}</span>
           <span>:config-file</span> <span>{</span><span>:src</span> <span>"config.jdn"</span><span>}})</span>
</pre></div>
<p>A site specification describes all of the outputs of the site
generator: the paths and contents of all the files that the generator
should create. For static files like CSS and images, this might be as
simple as copying the original file to a new path. For the generated
content of the website, this will include rendering <strong>templates</strong> by
using the attributes in the input step.</p>
<p>Here's an example site specification:</p>
<div><pre><span></span><span>(</span><span>def </span><span>site</span> <span>{</span><span>:post-index</span> <span>{</span><span>:path</span> <span>index-path</span>
                        <span>:contents</span> <span>render-post-index</span><span>}</span>
           <span>:posts</span> <span>{</span><span>:each</span> <span>:posts</span>
                   <span>:path</span> <span>make-post-path</span>
                   <span>:contents</span> <span>render-post</span><span>}</span>
           <span>:static</span> <span>{</span><span>:each</span> <span>:static</span>
                    <span>:path</span> <span>make-static-path</span><span>}})</span>
</pre></div>
<h3 id="demo"><a href="#demo" rel="nofollow noopener">#</a>Demo</h3>
<p>A demo project can be seen <a href="https://git.sr.ht/~subsetpark/bagatto/tree/refs/heads/master/demo/index.janet" rel="nofollow noopener">in this
repository</a>. This consists of a simple module
which includes some source files and some rendered pages.</p>
<p>To run it, navigate to the demo directory and then run <code>bag</code>:</p>
<pre><code>code-src/bagatto/demo [master !] ⊕ bag index.janet 
site/index.html
site/static/hello.png
site/posts/blog-post-1046213634.html
site/posts/blog-post-778149589.html
</code></pre>
<p>Bagatto outputs the path of each file it copies or creates.</p>
<p>We can then open up <code>site/index.html</code> in a web browser and click
around. Beware: it's pretty ugly. Both <code>index.janet</code> and the template
files it references are very thoroughly commented; hopefully they can
provide a whirlwind introduction.</p>
<h3 id="manual"><a href="#manual" rel="nofollow noopener">#</a>Manual</h3>
<p>See the <a href="https://git.sr.ht/~subsetpark/bagatto/tree/refs/heads/master/MANUAL.md" rel="nofollow noopener">Manual</a> for a deep dive.</p>
</div>
    </div>
  </div></div>]]>
            </description>
            <link>https://git.sr.ht/~subsetpark/bagatto</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298374</guid>
            <pubDate>Fri, 04 Dec 2020 02:53:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slack got their first SaaS customers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25298100">thread link</a>) | @MatthewBF
<br/>
December 3, 2020 | https://www.firstsaascustomer.com/blog/how-slack-got-their-first-saas-customers | <a href="https://web.archive.org/web/*/https://www.firstsaascustomer.com/blog/how-slack-got-their-first-saas-customers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This blog is a part of the series, <strong><em>How to get your first SAAS customer</em></strong>. You can get the book <a href="https://www.firstsaascustomer.com/" data-splitbee-event="Clicked top blog callout link">here</a>.</p></div><div><p>Stewart Butterfield is apparently an expert at turning computer games into businesses — <em>there also might be a hidden strategy in here</em>. I don't mean monetizing games. I mean taking what you've learned or built with a video game, and building a business off of it. Stewart has founded two massively successful online companies, both of which originated from (or were a product of) video games Stewart and some friends were working on.</p><p>First, Stewart was working on a game called Game Never Ending, which had a very popular photo sharing feature. He then went and built Flikr, the photo sharing app, which he sold shortly after.</p><p>As his next endeavour he and his colleagues decided to start working on an online multiplayer game that was described as "A mix between world of war craft, super mario, and a splash of Doctor Suess". His team was split between a couple cities and they were unsatisfied with their remote communication.</p><p>Stewart built an internal tool so he could chat within anyone on the team, no matter where they were. He realized that this was pretty valuable in and of itself.</p><p>‍</p><figure id="w-node-5e20e900fc9d-c9bb4729"><p><img src="https://assets.website-files.com/5fbed83c9b5bca1ced485e3a/5fc148fcc755c6585611d022_Slack1.png" loading="lazy" alt=""></p><figcaption>Stewart coming up with the SLACK name</figcaption></figure><p>‍</p><p>‍</p><p>‍</p><blockquote>[Internet Relay Chat] has this one fundamental concept called a 'channel' and you send messages to the channel rather than to individuals or to groups of individuals as you do in e-mail or most messaging systems. It’s a fundamental shift because the channel can exist before you arrive and it can exist after you leave, you can look into other channels across the system. When you join the organization, whether it’s the next day or six months later or five years later, all of that stuff is archived in all these different channels. And we slowly, over the course of years, built feature after feature, solved the really irritating problems, took advantage of the obvious opportunities. So now fast forward to 2012 at the end of the year, it was apparent that the game wasn’t going to work, like it just wasn’t going to be viable, it was never going to be the kind of business that would justify the $17 million bucks or venture capital investment we had raised, but we all realized we would never work without a system like this one again and so thought that it might be something that the rest of the world would want," Butterfield says in an interview in 2017.<p><strong>— Steward reflecting on the Slack technology</strong></p></blockquote><p>‍</p><p>After almost 3 years of working on a game, with no encouraging traction, Stewart and team switched to working on Slack.</p><p>The team knew quite a few other friends and old colleagues who worked at other startups. They reached out and begged them to try Slack.</p><p>‍</p><figure><p><img src="https://assets.website-files.com/5fbed83c9b5bca1ced485e3a/5fc14911e38b234d33329445_Slack2.png" loading="lazy" alt=""></p><figcaption>The first slack website</figcaption></figure><p>‍</p><p>‍</p><p>‍</p><p>What separated the Slack team from everyone else was their internal focus on growth. They were fully prepared to make small or large changes, advances, or pivots — evidenced by the huge pivot from a game they had been working on for 3 years to a chat app — to make customers happy.</p><p>Companies had email, phone, and other IRC technology, but Slack made it delightful. They solved the problems they already knew distributed teams were facing. It was baked right into the company name, Searchable Log of All Conversation and Knowledge (SLACK).</p><p>Slack made customer feedback the epicenter of its efforts. They made sure customers were heard, serviced, and supported. Slack worked day and night to fix issues, release improvements, and build the features their customers needed.</p><p>When Slack noticed issues with product adoption at a whole or user adoption within a company, they quickly identified the root cause and developer clever solutions. For example, Slack noticed that new hired when added to a Slack team had difficulty knowing which channels to join (There were usually many), so Slack developed channel descriptions and showed how many people were a part of and using each channel.</p><p>Slack made it dead simple for individuals to convince the rest of their team that they needed Slack, “We created materials to explain Slack to individuals" Stewart said. They explained what it was for, how it worked, what you’re supposed to do. "We also built resources for team administrators. We wanted to give them ammunition to help convince the team", Butterfield says.</p><p>A lot of promotion and ground work was done by their customers. From there, Slack's internal focus on growth, customer feedback, and iteration propelled them into the market.</p><p><strong>Takeaways from Slack</strong></p><ol role="list"><li>Make user feedback your core focus</li><li>Help users to convince themselves and teammates/colleagues/friends</li><li>Pay attention to key user problems</li></ol><p>‍</p></div></div>]]>
            </description>
            <link>https://www.firstsaascustomer.com/blog/how-slack-got-their-first-saas-customers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298100</guid>
            <pubDate>Fri, 04 Dec 2020 02:06:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flat – Generative Infrastructure for Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25297869">thread link</a>) | @pabs3
<br/>
December 3, 2020 | https://xxyxyz.org/flat/ | <a href="https://web.archive.org/web/*/https://xxyxyz.org/flat/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<header>
		<nav>
			<h4><a href="http://xxyxyz.org/">Xxyxyz</a></h4>
			<ul>
				<li><a href="http://xxyxyz.org/flat/">Flat</a></li>
				<li><a href="http://xxyxyz.org/even/">Even</a></li>
			</ul>
		</nav>
	</header>
	<section>
		<h4>Flat — Generative infrastructure for Python</h4><p>Flat is a library for creating and manipulating digital forms of fine arts. Its aim is to enable experimentation with and testing of unpredictable or automated processes, to inspect the beginning of the "new".</p><p>It grew out of the needs for generative design, architecture and art. The concept of "design" is more of a subject of study yet to be delved into, hence the fitter term for subtitle is "infrastructure".</p><p>It is written in pure Python and distributed under a liberal license.</p><h4>Content</h4><ul><li><a href="#features">Features</a></li><li><a href="#concepts">Core concepts</a></li><li><a href="#tutorial">Tutorial</a></li><li><a href="#examples">Examples</a></li><li><a href="#reference">API reference</a></li><li><a href="#installation">Installation</a></li><li><a href="#source">Source code</a></li><li><a href="#history">Previous releases</a></li><li><a href="#contact">Contact</a></li></ul><h4><a name="features"></a>Features</h4><ul><li><strong>Graphic formats</strong><ul><li>PNG, JPEG, PDF, SVG, OpenType (both TrueType and PostScript outlines), STL</li></ul></li><li><strong>Color spaces</strong><ul><li>grayscale, grayscale + alpha, RGB, RGBA, CMYK, spot colors, overprint</li></ul></li><li><strong>Image manipulation</strong><ul><li>resizing, blurring, dithering, ...</li></ul></li><li><strong>Image synthesis</strong><ul><li>Bezier path rasterization, BVH accelerated path tracing with explicit emitters and stratified sampling</li></ul></li><li><strong>Vector graphic primitives</strong><ul><li>line, polyline, ..., path, text, outlines, groups and units</li></ul></li><li><strong>Typography</strong><ul><li>kerning, greedy line breaking, threaded text frames</li></ul></li><li><strong>Computational geometry</strong><ul><li>Boolean operation on polygons</li></ul></li><li><strong>Data visualization</strong><ul><li>tree layout</li></ul></li></ul><h4><a name="concepts"></a>Core concepts</h4><p>Flat library consists of three (slightly overlapping) parts: image, document and scene.
An image is basically a container of pixels and a color kind. There are a few methods which operate over those pixels, such as "blur" or "put".
It is possible to create completely new image, by opening a file or by "rasterizing" a page of document.</p><p>Document is then assembled from pages, and each page holds number of "placed" items, both of which can be exported, too.
Here it also makes sense to introduce other entities: colors, shapes and strikes. There is support for following colors or color spaces, if you will:
the usual ones (grayscale, RGB, CMYK, ...), spot colors that can be used for controlling the application of special colorants and "overprint", which allows for printing of a graphic figure without erasing anything below it.
A shape includes both graphical properties such as stroke width or miter limit and means of creating items with said properties that are to be "placed" into a page, for example "line" or "circle".
Strike is a similar combination of text attributes (font, size, color, ...) and a way of constructing text "spans". A span likewise connects text string to text attributes, one or more spans can form a "paragraph", which in turn may form "text" or "outlines". Outlines are similar to texts but they use paths of glyph outlines, instead of characters.
One additional thing to note is that placed texts or outlines may be linked into a story or "chain" of blocks, making the text gradually "flow" from one text frame to another.
Any of the items may be placed into a "group" as well.</p><p>Finally, a scene is made of (possibly light emitting) materials, meshes built of triangular faces defined by "triplets" of 3D vertices and a camera.</p><h4><a name="tutorial"></a>Tutorial</h4><pre><code>from flat import rgb, font, shape, strike, document

red = rgb(255, 0, 0)
lato = font.open('Lato-Reg.otf')
figure = shape().stroke(red).width(2.5)
headline = strike(lato).color(red).size(20, 24)

d = document(100, 100, 'mm')
p = d.addpage()
p.place(figure.circle(50, 50, 20))
p.place(headline.text('Hello world!')).frame(10, 10, 80, 80)
p.image(kind='rgb').png('hello.png')
p.svg('hello.svg')
d.pdf('hello.pdf')
</code></pre><p>Short commentary:</p><p>We first prepared some invariants which we are going to use later, like the body typeface, some RGB color or a typeface we opened from a font file. One can think of <code>shape</code> and <code>strike</code> as of customizable factories which produce more concrete objects, for example lines or spans of text.</p><p>Next is the basic document hierarchy with just one page that can have items be placed into. The origin of coordinate system (0, 0) is at the top left corner and most of the time the default unit is "points" (1 inch = 72 points). A placed item may have some additional properties as position or <code>frame</code>. The latter is used to define the boundaries inside whose the text may run. As Flat currently lacks any kind of color management, we need to use the same color space for rasterizing the page into a PNG file. To access a page at any time one can simply keep a reference to it (<code>p</code>). Lastly, note that PDF is one of the few graphic formats which can hold multiple pages.</p><h4><a name="examples"></a>Examples</h4><p>There is also a public <a href="https://github.com/xxyxyz/flat-examples">repository</a> hosting additional examples.</p><h4><a name="reference"></a>API reference</h4><h4>image.py</h4><ul><li><strong><code>image.open(</code></strong><code>path</code><strong><code>)</code></strong><ul><li><ul><li>Open an image located at <code>path</code>. Supported formats are JPEG and PNG.</li></ul></li></ul></li><li><strong><code>image(</code></strong><code>width, height, kind='rgb'</code><strong><code>)</code></strong><ul><li><ul><li>Create an image <code>width</code> by <code>height</code> pixels in resolution, where <code>kind</code> can be one of: <code>'g'</code> (grayscale), <code>'ga'</code> (grayscale + alpha), <code>'rgb'</code>, <code>'rgba'</code>, <code>'cmyk'</code>.</li></ul></li><li><strong><code>copy()</code></strong><ul><li>Return a deep copy of the image.</li></ul></li><li><strong><code>get(</code></strong><code>x, y</code><strong><code>)</code></strong><ul><li>Return the color values of pixel at <code>x</code>, <code>y</code>.</li></ul></li><li><strong><code>put(</code></strong><code>x, y, components</code><strong><code>)</code></strong><ul><li>Set the color of pixel at <code>x</code>, <code>y</code> to <code>components</code>.</li></ul></li><li><strong><code>fill(</code></strong><code>components</code><strong><code>)</code></strong><ul><li>Fill the image with solid color of <code>components</code>.</li></ul></li><li><strong><code>white()</code></strong><ul><li>Fill the image with solid white.</li></ul></li><li><strong><code>black()</code></strong><ul><li>Fill the image with solid black.</li></ul></li><li><strong><code>blit(</code></strong><code>x, y, source</code><strong><code>)</code></strong><ul><li>Copy a region from <code>source</code>. Position of the region is <code>x</code>, <code>y</code> in this image, <code>0</code>, <code>0</code> in the source. Size of the region is the size of the source, cropping it to size of this image as necessary.</li></ul></li><li><strong><code>crop(</code></strong><code>x, y, width, height</code><strong><code>)</code></strong><ul><li>Crop the image to frame with origin at <code>x</code>, <code>y</code> and size <code>width</code>, <code>height</code>. The result will not enlarge beyond original size.</li></ul></li><li><strong><code>flip(</code></strong><code>horizontal, vertical</code><strong><code>)</code></strong><ul><li>Flip the image horizontally and/or vertically.</li></ul></li><li><strong><code>transpose()</code></strong><ul><li>Flip the image over the diagonal.</li></ul></li><li><strong><code>rotate(</code></strong><code>clockwise</code><strong><code>)</code></strong><ul><li>Rotate the image by 90 degrees clockwise if <code>clockwise</code> is <code>True</code>, anti-clockwise otherwise.</li></ul></li><li><strong><code>resize(</code></strong><code>width=0, height=0, interpolation='bicubic'</code><strong><code>)</code></strong><ul><li>Resize the image to <code>width</code> by <code>height</code>, where <code>interpolation</code> can be one of: <code>'nearest'</code>, <code>'bicubic'</code>, <code>'lanczos'</code>. Nearest-neighbor is fastest kernel and produces "pixelated" look when upsizing, bicubic is good general-purpose filter, Lanczos resampling preserves most detail and is slowest of the three. <code>0</code> width or height maintains the aspect ratio.</li></ul></li><li><strong><code>rescale(</code></strong><code>factor, interpolation='bicubic'</code><strong><code>)</code></strong><ul><li>Similar to <code>resize</code> but uses <code>scale</code> factor to calculate new dimensions.</li></ul></li><li><strong><code>blur(</code></strong><code>radius</code><strong><code>)</code></strong><ul><li>Blur the image with Gaussian filter kernel.</li></ul></li><li><strong><code>dither(</code></strong><code>levels=2</code><strong><code>)</code></strong><ul><li>Reduce the number of grayscale intensities to <code>levels</code> using Burkes dithering.</li></ul></li><li><strong><code>gamma(</code></strong><code>value</code><strong><code>)</code></strong><ul><li>Perform gamma correction of <code>value</code> on the image.</li></ul></li><li><strong><code>invert()</code></strong><ul><li>Invert color of the image.</li></ul></li><li><strong><code>png(</code></strong><code>path='', optimized=False</code><strong><code>)</code></strong><ul><li>Return the image serialized into PNG format. If <code>path</code> is set, save it as well. Improve the compression by setting <code>optimized</code> to <code>True</code>.</li></ul></li><li><strong><code>jpeg(</code></strong><code>path='', quality=95</code><strong><code>)</code></strong><ul><li>Return the image serialized into JPEG format. If <code>path</code> is set, save it as well. Higher (up to <code>100</code>) <code>quality</code> lowers the perceptible loss in image quality but increases the storage size.</li></ul></li></ul></li><li><strong><code>placedimage</code></strong><ul><li><ul><li>Don't call directly. Use <code>page.place()</code> instead.</li></ul></li><li><strong><code>position(</code></strong><code>x, y</code><strong><code>)</code></strong><ul><li>Move the placed image to <code>x</code>, <code>y</code>.</li></ul></li><li><strong><code>frame(</code></strong><code>x, y, width, height</code><strong><code>)</code></strong><ul><li>Move the placed image to <code>x</code>, <code>y</code> and resize it to <code>width</code>, <code>height</code>.</li></ul></li><li><strong><code>fitwidth(</code></strong><code>width</code><strong><code>)</code></strong><ul><li>Proportionally scale the placed image to match <code>width</code>.</li></ul></li><li><strong><code>fitheight(</code></strong><code>height</code><strong><code>)</code></strong><ul><li>Proportionally scale the placed image to match <code>height</code>.</li></ul></li></ul></li><li><strong><code>raw(</code></strong><code>width, height</code><strong><code>)</code></strong><ul><li><ul><li>Create a so called "raw" RGB image that comprises of floating-point intensities.</li></ul></li><li><strong><code>put(</code></strong><code>x, y, r, g, b</code><strong><code>)</code></strong><ul><li>Set the color of pixel at <code>x</code>, <code>y</code> to <code>r</code>, <code>g</code>, <code>b</code>.</li></ul></li><li><strong><code>tonemapped(</code></strong><code>key=0.18, white=1.0</code><strong><code>)</code></strong><ul><li>Return an <code>image</code> with reduced dynamic range of integer values 0-255, where <code>key</code> indicates whether the scene is subjectively light or dark, typically varying from <code>0.18</code> to <code>0.4</code>, and <code>white</code> is the smallest luminance mapped to pure white.</li></ul></li></ul></li></ul><h4>document.py</h4><ul><li><strong><code>page</code></strong><ul><li><ul><li>Don't call directly. Use <code>document.addpage()</code> instead.</li></ul></li><li><strong><code>meta(</code></strong><code>title</code><strong><code>)</code></strong><ul><li>Set metadata about the page, such as <code>title</code>.</li></ul></li><li><strong><code>size(</code></strong><code>width, height, units='mm'</code><strong><code>)</code></strong><ul><li>Set the default document size to <code>width</code> by <code>height</code>, where <code>units</code> can be one of: <code>'pt'</code>, <code>'mm'</code>, <code>'cm'</code>, <code>'in'</code>.</li></ul></li><li><strong><code>place(</code></strong><code>item</code><strong><code>)</code></strong><ul><li>Place an <code>item</code> on the page.</li></ul></li><li><strong><code>chain(</code></strong><code>block</code><strong><code>)</code></strong><ul><li>Add new text block to the <code>block</code>, enabling its text to flow along the linked blocks. A chain eventually eliminates <code>overflow</code>.</li></ul></li><li><strong><code>svg(</code></strong><code>path='', compress=False</code><strong><code>)</code></strong><ul><li>Return the page serialized into SVG format. If <code>path</code> is set, save it as well. Reduce size by setting <code>compress</code> to <code>True</code> (currently not implemented).</li></ul></li><li><strong><code>image(</code></strong><code>ppi=72, kind='g'</code><strong><code>)</code></strong><ul><li>Return the page rasterized at <code>ppi</code> (pixels per inch) into <code>image</code> of <code>kind</code>.</li></ul></li></ul></li><li><strong><code>document.open(</code></strong><code>path</code><strong><code>)</code></strong><ul><li><ul><li>Open a document located at <code>path</code>. Currently not implemented.</li></ul></li></ul></li><li><strong><code>document(</code></strong><code>width=210.0, height=297.0, units='mm'</code><strong><code>)</code></strong><ul><li><ul><li>Create a document with dimensions of <code>width</code> by <code>height</code><code>units</code>.</li></ul></li><li><strong><code>meta(</code></strong><code>title</code><strong><code>)</code></strong><ul><li>Set metadata about the document, such as <code>title</code>.</li></ul></li><li><strong><code>size(</code></strong><code>width, height, units='mm'</code><strong><code>)</code></strong><ul><li>Set dimensions of the document to <code>width</code> by <code>height</code><code>units</code>.</li></ul></li><li><strong><code>addpage()</code></strong><ul><li>Create and add one page to the document and return it.</li></ul></li><li><strong><code>pdf(</code></strong><code>path='', compress=False, bleed=False, cropmarks=False</code><strong><code>)</code></strong><ul><li>Return the document serialized into PDF. If <code>path</code> is set, save it as well. Reduce size by setting <code>compress</code> to <code>True</code> (currently not implemented), include <code>bleed</code> or <code>cropmarks</code> by setting the arguments to <code>True</code>.</li></ul></li></ul></li></ul><h4>mesh.py</h4><ul><li><strong><code>mesh.openstl(</code></strong><code>path</code><strong><code>)</code></strong><ul><li><ul><li>Open an STL mesh located at <code>path</code>.</li></ul></li></ul></li><li><strong><code>mesh(</code></strong><code>triplets</code><strong><code>)</code></strong><ul><li><ul><li>Create a mesh with <code>triplets</code> of triangular face vertices. Each vertex is a triplet of x, y, z coordinates.</li></ul></li><li><strong><code>stl(</code></strong><code>path=''</code><strong><code>)</code></strong><ul><li>Return the mesh serialized into STL format. If <code>path</code> is set, save it as well.</li></ul></li></ul></li></ul><h4>scene.py</h4><ul><li><strong><code>diffuse(</code></strong><code>reflectance, emittance=None</code><strong><code>)</code></strong><ul><li><ul><li>Create a diffuse material with <code>reflectance</code> and <code>emittance</code>, each of being an RGB floating-point triplet.</li></ul></li></ul></li><li><strong><code>scene()</code></strong><ul><li><ul><li>Create empty scene.</li></ul></li><li><strong><code>environment(</code></strong><code>sky, ground</code><strong><code>)</code></strong><ul><li>Set the <code>sky</code> and <code>ground</code> emittance, each of being an RGB floating-point triplet.</li></ul></li><li><strong><code>camera(</code></strong><code>origin, target, length=50.0</code><strong><code>)</code></strong><ul><li>Point the camera from <code>origin</code> to <code>target</code>, each of being an 3D point coordinate. Set focal length to <code>length</code> in millimetres.</li></ul></li><li><strong><code>clear()</code></strong><ul><li>Remove all items from the scene.</li></ul></li><li><strong><code>add(</code></strong><code>mesh, material</code><strong><code>)</code></strong><ul><li>Add <code>mesh</code> combined with <code>material</code> to the scene.</li></ul></li><li><strong><code>render(</code></strong><code>width, height, samples=10, multiprocessing=True, info=True</code><strong><code>)</code></strong><ul><li>Render the scene to <code>raw</code> image with size <code>width</code> by <code>height</code> pixels using <code>samples</code>&nbsp;×&nbsp;<code>samples</code> number of path tracing samples. To use all available cores set <code>multiprocessing</code> to <code>True</code> and to report rendering progress set <code>info</code> to <code>True</code>.</li></ul></li></ul></li></ul><h4>color.py</h4><ul><li><strong><code>gray(</code></strong><code>intensity</code><strong><code>)</code></strong><ul><li><ul><li>Create a grayscale color with <code>intensity</code>. <code>0</code> corresponds to black, <code>255</code> to white.</li></ul></li></ul></li><li><strong><code>ga(</code></strong><code>g, a</code><strong><code>)</code></strong><ul><li><ul><li>Create …</li></ul></li></ul></li></ul></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xxyxyz.org/flat/">https://xxyxyz.org/flat/</a></em></p>]]>
            </description>
            <link>https://xxyxyz.org/flat/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297869</guid>
            <pubDate>Fri, 04 Dec 2020 01:24:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My experience interviewing with Stripe – Daeyoung Choi]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25297850">thread link</a>) | @dhruvarora013
<br/>
December 3, 2020 | https://daeyoungchoi.com/stripe-interview/ | <a href="https://web.archive.org/web/*/https://daeyoungchoi.com/stripe-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
<p>Interviewing for a job often is a daunting experience. It may commonly be described as a two-way selection process, one in which the candidate is evaluating the company as much as the company is the candidate, but the sober truth is that outside of the most highly sought-after segments of the talent pool, the balance of power resides squarely with the hiring company and the candidate has little leverage until the moment a job offer is presented. This seemingly is especially true in Silicon Valley, where each job opening routinely attracts hundreds of applicants and it is not uncommon that the candidate simply never hears back from the company in the case the interview is deemed unsuccessful at any point along the process, without even a notice of rejection, let alone being provided an explanation or feedback of any kind. Basic decency and decorum can seem to fly out the window once the company makes the determination you are “not a fit,” which effectively translates to “henceforth a waste of time,” simply an undesired byproduct of an essential process, to be discarded as quickly as possible.</p>



<p>But every once in a while, as is the case with life in general, an exception comes along that runs against the grain of your learned expectations. It shows you the extraordinary does exist and offers a reminder that much of what happens in this world lies on a distribution, despite the seeming tyranny of what occupy the regions of central tendency. While it won’t negate the broadly observed norms, the reminder that excellence exists in almost all domains of human activity sometimes is enough to sustain one in a journey that is full of pitfalls and trials, providing the inspiration that helps keep alive hopes and aspirations even when the objective and dispassionate prognosis appears far from welcoming. Interviewing with Stripe, the payment startup, for me, was such an example.</p>



<p>My very first interview with Stripe started off quite inauspiciously. It was a phone interview with the recruiter, and after spending some time to explore and discuss both my background and that of the job, he let me know that my skill set probably was not as good a match for what the hiring team was looking for as initially thought. In retrospect that sort of upfront candor might have been an early indication of the caliber of the organization that was to be revealed more fully later on. But the remarkable thing that happened after he uttered that assessment was that he wanted to refer me to another recruiter, for a different role which he thought presented a better match. This was something that quite literally had never happened in my experience, admittedly a small sample as it may be – a recruiter that not only was well-versed enough in another position for which he was not recruiting, was empowered enough by the organization to make that kind of an autonomous referral decision without consultation, but also, probably most impressively, cared enough to take on such an initiative when I was deemed no longer useful for his immediate need, which was to fill the position at hand.</p>



<p>The subsequent interviews, for the new role, went more smoothly, uneventfully in the best sense. Over the course of the ensuing few weeks, in succession, I had a phone call with the new recruiter, a Zoom video call with the head of the business unit for the role (who was based overseas), a writing assignment, and in-person coffee shop chats in San Francisco with the said head of the business unit who happened to be in town that week and also with the hiring manager. All of that led to culminate in an on-site round of interviews with 7 individuals that lasted over 4 hours in January of this year at the San Francisco headquarters of Stripe.</p>



<p>In retrospect, it is clear I did not perform as well on the on-site interviews as I should have. What was unique about Stripe was the interview questions were actually provided in advance – the recruiter arranged a call with me prior to the scheduled date to go over the questions one by one. Gripped by the notion, somehow, that interviews are just conversations, however, I did not spend a lot of time preparing specific answers for those questions. Looking back, I now think a big part of the reason why was hubris; I have a tendency to think I enjoy all conversations, and proceeded to draw the conclusion in my mind that conversations I enjoy in an interview setting must be good interviews. The mere fact that I was ready to enjoy the interviews, in their natural, unscripted, conversational formulation, was, in a way, enough preparation. But once the on-site interviews began it became apparent the interviewers were pressing for a higher level of specificity in the answers than I was prepared to give in the courses of casual conversations. I could feel the inadequacy of my answers resulting from the lack of deeper considerations given them in advance, and I simply was not good enough to get to the level of detailed thoughtfulness on the spot. As I was ushered out of the building after the interviews concluded, I recall feeling a sense of regretful uneasiness creeping in. Almost compulsively, I remained hopeful, but far from confident. And surely enough, a few days later I was informed that I didn’t get the job. </p>



<p>I was devastated, but this is the point from which I was led to Stripe revealing itself to be a truly unique, unconventional company in the most unexpectedly wonderful ways. First, the recruiter offered to schedule a call so we could review the decision. I was pleasantly surprised to be given such an unusual opportunity, so I took him up on it. During the call he relayed some useful feedback, though it is clear in retrospect that I got too excited to be on such a call and spent way more time talking than listening to what he had to say. But importantly, the conversation helped me come to a realization, in concrete ways, that I was a much worse interviewee than had previously believed myself to be. It prompted me to ex-examine my natural tendencies in the ways I think, talk, and engage with others in conversations. When I shared the revelation with my wife, she was more than happy to supply additional pointers in areas of my failing.</p>



<p>The fact that the recruiter, and by extension the company, was willing to engage with and spend the time and effort on someone deemed to be “not wanted” was an enormous departure from everything I had experienced previously. Frankly, it was the kind of thoughtfulness and generosity of goodwill that I never expected any corporate entity to possess or display. I knew I had been rejected, but now I wanted Stripe even more, and I couldn’t let myself just give up. So I did something quite silly: I sent an email to the CEO. Fortunately Patrick Collison, Stripe’s CEO, lists his email address on his personal website. But I had no idea if the email would actually reach him, or if he would read it if it got to him, or if he would respond in any way. The overwhelmingly realistic outcome was that nothing would happen, and I knew it. It was a desperation move, one you are able to make only because you have nothing to lose.</p>



<p>Then, I got an email from the recruiter. He asked if I wanted to speak with the company’s chief risk officer – the job I interviewed for was a risk function – for reasons that were not entirely clear. He mentioned I might want “a bit more closure,” but I didn’t want closure; if anything, I wanted to keep the door ajar as much and as long as possible. He also said that the meeting was optional, with “no pressure.” Perplexed yet intrigued, I took up the opportunity to speak with the executive. She began the call with something to the effect of “I know you reached out to Patrick.” I had reached out to everyone I had interviewed with to solicit feedback, and since the name “Patrick” didn’t register right away I processed it to mean one of the interviewers. But about 5 seconds later I realized there was no one named Patrick that I had met, and then it hit me that it must be Patrick Collison, the CEO. My email to him was why this call was happening, which the chief risk officer confirmed when I asked her in disbelief. I was stunned. Having taken place almost a half year ago, much of the details of the call is a blur. But I recall distinctly her asking why Stripe should hire someone like myself. Most improbably, it seemed, this might be a second chance.</p>



<p>I had written to Patrick the CEO with a proposition: I offered myself to be a counterfactual data point in an evaluation of Stripe’s hiring process, after learning that Stripe’s credit card fraud detection system lets through some transactions which its algorithms flag as likely frauds in order to determine whether they turn out to be true positives or false positives – thereby evaluating the algorithms themselves – in a process called “counterfactual evaluation.” When the chief risk officer asked why I should be hired, I reiterated that proposition: the case I was making was not about my merits, but the willingness on Stripe’s part to apply counterfactual evaluation to its hiring process, to determine whether I was a false positive (incorrectly rejected) or a true positive (truly no good) by letting me join Stripe, without a bias to either outcome. I couldn’t tell if I was making any headway with the argument, but we soon ran out of time and she had to go to another meeting.</p>



<p>In the end, the outcome of my interviews did not change and I remain not an employee of Stripe. But out of all the job interview experiences I’ve had in my life, the one with Stripe stands out as singularly remarkable. When I shared my story with a friend she was so impressed that even though she wasn’t looking for a new job, she said she still might apply to Stripe just for the experience. Today Stripe has earned a reputation as one of the best embodiments of the ideals of Silicon Valley – a place of inventive and ambitious companies that not only come up …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daeyoungchoi.com/stripe-interview/">https://daeyoungchoi.com/stripe-interview/</a></em></p>]]>
            </description>
            <link>https://daeyoungchoi.com/stripe-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297850</guid>
            <pubDate>Fri, 04 Dec 2020 01:22:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Microsoft Crushed Slack]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25297612">thread link</a>) | @aparsons
<br/>
December 3, 2020 | https://www.platformer.news/p/how-microsoft-crushed-slack | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/how-microsoft-crushed-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.platformer.news/p/how-microsoft-crushed-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297612</guid>
            <pubDate>Fri, 04 Dec 2020 00:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn By Example: Understanding the ampersand in Elixir (capture operator)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25297502">thread link</a>) | @2upmedia
<br/>
December 3, 2020 | https://jorgecolonconsulting.com/learn-by-example-understanding-the-ampersand-in-elixir-capture-operator/ | <a href="https://web.archive.org/web/*/https://jorgecolonconsulting.com/learn-by-example-understanding-the-ampersand-in-elixir-capture-operator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			
    <article id="5fbb4a63c29c8e00ed9bc152">
        
        


                <header>
                    <img srcset="https://jorgecolonconsulting.com/content/images/size/w300/2020/12/elixir-capture-operator-header@2x-1.png 250w,
                    https://jorgecolonconsulting.com/content/images/size/w600/2020/12/elixir-capture-operator-header@2x-1.png 400w,
                    https://jorgecolonconsulting.com/content/images/size/w800/2020/12/elixir-capture-operator-header@2x-1.png 600w,
                    https://jorgecolonconsulting.com/content/images/size/w1600/2020/12/elixir-capture-operator-header@2x-1.png 2x" sizes="(max-width: 600px) 400px, 800px" src="https://jorgecolonconsulting.com/content/images/size/w800/2020/12/elixir-capture-operator-header@2x-1.png" alt="Learn By Example: Understanding the ampersand in Elixir (capture operator)">
                </header>


        


        <p>Seeing the ampersand for the first time in Elixir I wanted to dig deep into what it meant. The first <code>&amp;</code> effectively either gets a reference to the original function or starts an anonymous function. Any ampersand after the first that references the positional argument passed to it. You could use this to write very concise anonymous functions. </p><p>Here's a couple of examples:</p><pre><code>messages = ["One", "Two"]

no_capture_operator = fn msg -&gt;
  IO.inspect(msg, label: 'no_capture_operator')
  %{itemValue: msg}
end
# no_capture_operator: "One"
# no_capture_operator: "Two"

messages |&gt; Enum.map(no_capture_operator)

new_messages = messages |&gt; Enum.map(&amp;%{itemValue: &amp;1})

IO.inspect(new_messages)
# [%{itemValue: "One"}, %{itemValue: "Two"}]

new_messages = messages |&gt; Enum.map(fn msg -&gt;
  IO.inspect(msg)
  %{itemValue: msg}
end)
# "One"
# "Two"

IO.inspect(new_messages, label: "new_messages =")
# new_messages =: [%{itemValue: "One"}, %{itemValue: "Two"}]

message_func = fn msg -&gt;
  IO.inspect(msg)
  %{itemValue: msg}
end

messages |&gt; Enum.map(&amp;message_func.(&amp;1))
# "One"
# "Two"

# the enum tuples have zero-based indexes, hence the + 1
message_with_odd_even = &amp;%{itemValue: &amp;1, type: (if rem(&amp;2 + 1, 2) === 0, do: "even", else: "odd")}

msg_tuple = {"One", 0}

IO.inspect(message_with_odd_even.(elem(msg_tuple, 0), elem(msg_tuple, 1)))
# %{itemValue: "One", type: "odd"}

IO.inspect(message_with_odd_even.("One", 0))
# %{itemValue: "One", type: "odd"}

new_messages = messages |&gt; Enum.with_index |&gt; Enum.map(&amp;message_with_odd_even.(elem(&amp;1, 0), elem(&amp;1, 1)))

IO.inspect(new_messages, label: 'new_messages 2 =')
# new_messages 2 =: [%{itemValue: "One", type: "odd"}, %{itemValue: "Two", type: "even"}]

messages |&gt; Enum.each(&amp;IO.inspect(&amp;1, label: "label for " &lt;&gt; &amp;1))
# label for One: "One"
# label for Two: "Two"
</code></pre><p>Read more at the official docs: <a href="https://elixir-lang.org/getting-started/modules-and-functions.html#function-capturing">https://elixir-lang.org/getting-started/modules-and-functions.html#function-capturing</a></p>


                
        
      

        
    </article>


		</div></div>]]>
            </description>
            <link>https://jorgecolonconsulting.com/learn-by-example-understanding-the-ampersand-in-elixir-capture-operator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297502</guid>
            <pubDate>Fri, 04 Dec 2020 00:32:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Winston Churchill on land value taxation (1909)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25297495">thread link</a>) | @BirdieNZ
<br/>
December 3, 2020 | http://savingcommunities.org/docs/churchill.winston/landandincometaxes.html | <a href="https://web.archive.org/web/*/http://savingcommunities.org/docs/churchill.winston/landandincometaxes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <td>
      
      
      <p><a name="justice"></a>We
are often assured by sagacious persons that the civilisation of modern
States is largely based upon respect for the rights of private
property. If that be true, it is also true that such respect cannot be
secured, and ought not, indeed, to be expected, unless property is
associated in the minds of the great mass of the people with ideas of
justice and of reason.</p>
      <p><a name="harmony"></a>It is, therefore,
of the first importance to the country - to any country - that there
should be vigilant and persistent efforts to prevent abuses, to
distribute the public burdens fairly among all classes, and to
establish good laws governing the methods by which wealth may be
acquired. The best way to make private property secure and respected is
to bring the processes by which it is gained into harmony with the
general interests of the public. When and where property is associated
with the idea of reward for services rendered, with the idea of
recompense for high gifts and special aptitudes displayed or for
faithful labour done, then property will be honoured. When it is
associated with processes which are beneficial, or which at the worst
are not actually injurious to the commonwealth, then property will be
unmolested; but when it is associated with ideas of wrong and of
unfairness, with processes of restriction and monopoly, and other forms
of injury to the community, then I think that you will find that
property will be assailed and will be endangered.</p>
      <p><a name="socialism"></a>A
year ago I was fighting an election in Dundee. In the course of that
election I attempted to draw a fundamental distinction between the
principles of Liberalism and of Socialism, and I said "Socialism
attacks capital; Liberalism attacks monopoly." And it is from that
fundamental distinction that I come directly to the land proposals of
the present Budget.</p>
      <p><a name="mother"></a>It is quite
true that the land monopoly is not the only monopoly which exists, but
it is by far the greatest of monopolies; it is a perpetual monopoly,
and it is the mother of all other forms of monopoly. It is quite true
that unearned increments in land are not the only form of unearned or
undeserved profit which individuals are able to secure; but it is the
principal form of unearned increment, derived from processes, which are
not merely not beneficial, but which are positively detrimental to the
general public. Land, which is a necessity of human existence, which is
the original source of all wealth, which is strictly limited in extent,
which is fixed in geographical position - land, I say, differs from all
other forms of property in these primary and fundamental conditions.</p>
      <p><a name="opponents"></a>Nothing
is more amusing than to watch the efforts of our monopolist opponents
to prove that other forms of property and increment are exactly the
same and are similar in all respects to the unearned increment in land.
They talk to us of the increased profits of a doctor or a lawyer from
the growth of population in the towns in which they live. They talk to
us of the profits of a railway through a greater degree of wealth and
activity in the districts through which it runs. They tell us of the
profits which are derived from a rise in stocks and shares, and even of
those which are sometimes derived from the sale of pictures and works
of art, and they ask us - as if it were their only complaint - "Ought
not all these other forms to be taxed too?"</p>
      <p><a name="analogies"></a>But
see how misleading and false all these analogies are. The windfalls
which people with artistic gifts are able from time to time to derive
from the sale of a picture - from a Vandyke or a Holbein - may here and
there be very considerable. But pictures do not get in anybody's way.
They do not lay a toll on anybody's labour; they do not touch
enterprise and production at any point; they do not affect any of those
creative processes upon which the material well-being of millions
depends. And if a rise in stocks and shares confers profits on the
fortunate holders far beyond what they expected, or, indeed, deserved,
nevertheless, that profit has not been reaped by withholding from the
community the land which it needs, but, on the contrary, apart from
mere gambling, it has been reaped by supplying industry with the
capital without which it could not be carried on.</p>
      <p><a name="service"></a>If
the railway makes greater profits, it is usually because it carries
more goods and more passengers. If a doctor or a lawyer enjoys a better
practice, it is because the doctor attends more patients and more
exacting patients, and because the lawyer pleads more suits in the
courts and more important suits. At every stage the doctor or the
lawyer is giving service in return for his fees; and if the service is
too poor or the fees are too high, other doctors and other lawyers can
come freely into competition. There is constant service, there is
constant competition; there is no monopoly, there is no injury to the
public interest, there is no impediment to the general progress.</p>
      <p><a name="other"></a>Fancy
comparing these healthy processes with the enrichment which comes to
the landlord who happens to own a plot of land on the outskirts or at
the centre of one of our great cities, who watches the busy population
around him making the city larger, richer, more convenient, more famous
every day, and all the while sits still and does nothing! Roads are
made, streets are made, railway services are improved, electric light
turns night into day, electric trams glide swiftly to and fro, water is
brought from reservoirs a hundred miles off in the mountains - and all
the while the landlord sits still. Every one of those improvements is
effected by the labour and at the cost of other people. Many of the
most important are effected at the cost of the municipality and of the
ratepayers. To not one of those improvements does the land monopolist,
as a land monopolist, contribute, and yet by every one of them the
value of his land is sensibly enhanced.</p>
      <p><a name="contributes"></a>He
renders no service to the community, he contributes nothing to the
general welfare, he contributes nothing even to the process from which
his own enrichment is derived. If the land were occupied by shops or by
dwellings, the municipality at least would secure the rates upon them
in aid of the general fund; but the land may be unoccupied,
undeveloped, it may be what is called "ripening" - ripening at the
expense of the whole city, of the whole country - for the unearned
increment of its owner. Roads perhaps have to be diverted to avoid this
forbidden area. The merchant going to his office, the artisan going to
his work, have to make a detour or pay a tram fare to avoid it. The
citizens are losing their chance of developing the land, the city is
losing its rates, the State is losing its taxes which would have
accrued, if the natural development had taken place - and that share
has to be replaced at the expense of the other ratepayers and
taxpayers; and the nation as a whole is losing in the competition of
the world - the hard and growing competition in the world - both in
time and money. And all the while the land monopolist has only to sit
still and watch complacently his property multiplying in value,
sometimes manifold, without either effort or contribution on his part.
And that is justice!</p>
      <p><a name="agricultural"></a>But let
us follow the process a little farther. The population of the city
grows and grows still larger year by year, the congestion in the poorer
quarters becomes acute, rents and rates rise hand in hand, and
thousands of families are crowded into one-roomed tenements. There are
120,000 persons living in one-roomed tenements in Glasgow alone at the
present time. At last the land becomes ripe for sale - that means that
the price is too tempting to be resisted any longer - and then, and not
till then, it is sold by the yard or by the inch at ten times, or
twenty times, or even fifty times, its agricultural value, on which
alone hitherto it has been rated for the public service.</p>
      <p><a name="disservice"></a>The
greater the population around the land, the greater the injury which
they have sustained by its protracted denial, the more inconvenience
which has been caused to everybody, the more serious the loss in
economic strength and activity, the larger will be the profit of the
landlord when the sale is finally accomplished. In fact you may say
that the unearned increment on the land is on all-fours with the profit
gathered by one of those American speculators who engineer a corner in
corn, or meat, or cotton, or some other vital commodity, and that the
unearned increment in land is reaped by the land monopolist in exact
proportion, not to the service, but to the disservice done.</p>
      <p><a name="transfer"></a>It
is monopoly which is the keynote; and where monopoly prevails, the
greater the injury to society, the greater the reward of the monopolist
will be. See how this evil process strikes at every form of industrial
activity. The municipality, wishing for broader streets, better houses,
more healthy, decent, scientifically planned towns, is made to pay, and
is made to pay in exact proportion, or to a very great extent in
proportion, as it has exerted itself in the past to make improvements.
The more it has improved the town, the more it has increased the land
value, and the more it will have to pay for any land it may wish to
acquire. The manufacturer purposing to start a new industry, proposing
to erect a great factory offering employment to thousands of hands, is
made to pay such a price for his land that the purchase-price hangs
round the neck of his whole business, hampering his competitive power
in every market, clogging him far more than any foreign tariff in his
export competition; and the land values strike down through the profits
of the manufacturer on to the wages of the workman. The railway company
wishing to build a new line finds that the price of land which
yesterday was only rated at its agricultural value has risen to a
prohibitive figure the moment it was known that the new line was
projected; and either the railway …</p></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://savingcommunities.org/docs/churchill.winston/landandincometaxes.html">http://savingcommunities.org/docs/churchill.winston/landandincometaxes.html</a></em></p>]]>
            </description>
            <link>http://savingcommunities.org/docs/churchill.winston/landandincometaxes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297495</guid>
            <pubDate>Fri, 04 Dec 2020 00:31:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Light-based quantum computer Jiuzhang achieves quantum supremacy]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25297488">thread link</a>) | @justicezyx
<br/>
December 3, 2020 | https://todayheadline.co/light-based-quantum-computer-jiuzhang-achieves-quantum-supremacy/ | <a href="https://web.archive.org/web/*/https://todayheadline.co/light-based-quantum-computer-jiuzhang-achieves-quantum-supremacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://todayheadline.co/light-based-quantum-computer-jiuzhang-achieves-quantum-supremacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297488</guid>
            <pubDate>Fri, 04 Dec 2020 00:31:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My First Micro-SaaS, from 0–10 Customers]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25297374">thread link</a>) | @bfoks
<br/>
December 3, 2020 | https://blog.rchase.com/my-first-saas-from-0-10-customers/ | <a href="https://web.archive.org/web/*/https://blog.rchase.com/my-first-saas-from-0-10-customers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.rchase.com/content/images/size/w300/2020/01/hostifi-google-analytics-launch.png 300w,
                            https://blog.rchase.com/content/images/size/w600/2020/01/hostifi-google-analytics-launch.png 600w,
                            https://blog.rchase.com/content/images/size/w1000/2020/01/hostifi-google-analytics-launch.png 1000w,
                            https://blog.rchase.com/content/images/size/w2000/2020/01/hostifi-google-analytics-launch.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.rchase.com/content/images/size/w2000/2020/01/hostifi-google-analytics-launch.png" alt="My First Micro-SaaS, From 0–10 Customers">
            </figure>

            <section>
                <div>
                    <p>It took around 3 weeks after launch for my UniFi controller hosting service, <a href="https://hostifi.net/" rel="noopener nofollow">https://hostifi.net</a> to get from 0–11 customers, and in this post I’ll be sharing what I did during that time to find those first customers.</p><p>When starting a new business, getting your first 10 customers is super hard. If you can do it though, it’s a huge milestone. It means that you’re much more likely to be able to get to 100.</p><p>If you have 10 customers, you’ve probably done at least something right. Your product or service has proven it has potential to create value, and you’ve found at least one method of customer acquisition that is working.</p><p>There are many reasons why it’s so hard to get to 10. When you’re at 0, you don’t have any testimonials or positive reviews. You have no brand reputation, and because of that it is really hard to earn trust.</p><p>If that wasn’t bad enough, you also more than likely don’t have any idea how to get customers. Any ideas you do have are unproven so far.</p><p>When you built your product or service, you thought that you knew exactly what your customer needed, but because you haven’t had any customers yet, you’ll probably realize later that the requirements will change based on feedback.</p><p>You might even find out that the type of customer you thought would need your product doesn’t need it at all, and your actual customer profile is completely different than what you were expecting. That's what happened to me!</p><h3 id="may-24-2018-june-16-2018">May 24, 2018 — June 16, 2018<br></h3><p>From 0–11 Customers</p><figure><img src="https://blog.rchase.com/content/images/2020/01/image-14.png"><figcaption>Timeline of HostiFi’s customer and lead acquisition from launch to 11 customers</figcaption></figure><p>Typically when you start a business, your first few customers are your friends or family. As you do good work, improve your product or service, and get some positive reviews, it becomes easier to work your way out to the friends of friends and casual acquaintance zone. Eventually customers start to come in from referrals, and then one day you’ve got customers coming to you who you have no relation to, thanks to your brand awareness efforts.</p><p>Unfortunately, this traditional model was not possible for HostiFi. The problem was, I didn’t know a single person who needed UniFi controller hosting! That made getting those initial customers even harder.</p><p>Luckily, I had read Tyler Tringas’s Micro-SaaS ebook which had lots of helpful ideas on getting started: <a href="https://tylertringas.com/chapter-5-getting-your-first-customers/" rel="noopener nofollow">https://tylertringas.com/chapter-5-getting-your-first-customers/</a></p><p>Between that, listening to Omer Kahn’s <a href="https://saasclub.io/saas-podcast" rel="noopener nofollow">SaaS Podcast</a>, reading about SaaS success stories on <a href="http://indiehackers.com/" rel="noopener nofollow">Indie Hackers</a>, and others, I had an idea of what I needed to do. I was going to start by finding places on the internet where my potential customers congregate and begin reaching out to them.</p><h2 id="launch">Launch</h2><figure><img src="https://blog.rchase.com/content/images/2020/01/image-15.png"></figure><p>This is what Google Analytics looked like for the web traffic during the time period which the first 11 customers signed up.</p><p>The traffic from the first spike was mainly driven by my Tweet about launching HostiFi:</p><figure><img src="https://blog.rchase.com/content/images/2020/01/image-16.png"></figure><h2 id="initial-marketing-attempts">Initial Marketing Attempts</h2><p>At first, I tried several ways of getting the word out about HostiFi. Most of them were complete failures.</p><h3 id="upwork">Upwork</h3><figure><img src="https://blog.rchase.com/content/images/2020/01/image-17.png"><figcaption>HostiFi’s Upwork Profile</figcaption></figure><p><strong>Didn't work<strong>. </strong></strong>On launch day (May 24), I created an Upwork profile for HostiFi. This didn’t bring in a single lead to date. It’s not a bad idea though, and might work if I put a bit more time into building the profile up with small Ubiquiti jobs to get a higher ranking within the site. The idea is to find customers who are looking to pay for someone to do what your product does, and then recommend your product to them. I think the reason I gave up quickly on this was because I was seeing a very low volume for Ubiquiti related job postings.</p><h2 id="linkedin">LinkedIn</h2><figure><img src="https://blog.rchase.com/content/images/2020/01/image-18.png"><figcaption>HostiFi’s first LinkedIn post</figcaption></figure><p><strong>Didn't work<strong>.</strong></strong> See where it says 15 impressions? That’s how many people might have looked at that post. Not on that day. That’s 15 impressions total for May through October. Using LinkedIn to find Ubiquiti users wasn’t going to work. Although LinkedIn has hashtags and groups where Ubiquiti users can be found, company pages can’t engage with other people’s posts. A company page also can’t “connect” with anyone. It’s a one way street where users can interact with a company, but a company can’t interact with users.</p><h3 id="reddit">Reddit</h3><figure><img src="https://blog.rchase.com/content/images/2020/01/image-19.png"><figcaption>r/Ubiquiti moderators remove HostiFi’s advertisement</figcaption></figure><p><strong>Didn't work<strong>. </strong></strong>This one still really, really bums me out. The Ubiquiti SubReddit has an incredible 22.4k subscribers, certainly one of the biggest congregation of Ubiquiti users on the internet. On May 25 (day after launch), I created an account for HostiFi and sheepishly asked “What do you guys think of <a href="https://hostifi.net/" rel="noopener nofollow">https://hostifi.net</a>?" Almost immediately my post was deleted and I was reprimanded by the mods. I argued that the content I posted wasn’t spammy and was useful to the community, but they weren’t buying it.</p><h3 id="forums">Forums</h3><figure><img src="https://blog.rchase.com/content/images/2020/01/image-20.png"><figcaption>HostiFi reaches out to users of a Ubiquiti forum via private messaging</figcaption></figure><p><strong>Sort of worked<strong>.</strong></strong> This one was a big disappointment. On launch day, and for the first week after launch, I reached out to dozens of Ubiquiti users in a forum. I was asking for their feedback on HostiFi. Only 6 people replied. None were interested.</p><p>I listed this as a "sort of worked", because although private messaging didn't work, making non-spammy posts on the forum by helping answer questions about UniFi for people proved to be a big success in driving traffic to the site and getting customers.</p><h3 id="twitter">Twitter</h3><figure><img src="https://blog.rchase.com/content/images/2020/01/image-21.png"></figure><p><strong><strong>Success!</strong></strong> I created a Twitter account for HostiFi pre-launch, on May 16, 2018. I spent that month following #Ubiquiti and #UniFi. I mainly retweeted, liked, and followed users who were posting there.</p><figure><img src="https://blog.rchase.com/content/images/2020/01/image-22.png"></figure><p>Above is a screenshot of HostiFi’s Twitter Analytics in May 2018.</p><figure><img src="https://blog.rchase.com/content/images/2020/01/image-23.png"></figure><p>And above is HostiFi’s Twitter Analytics for June. As you can see, there was a major improvement in followers, impressions, and profile visits, all which were helping drive traffic to the site early on.</p><p>Twitter was the first place that I felt I was getting some traction. Unlike LinkedIn, I was able to directly interact with other users. I could find my people using hashtags, and engage in discussions with them openly. And unlike Reddit and the Ubiquiti Forums, I wasn’t at risk of being shutdown by mods.</p><h2 id="closing-thoughts">Closing thoughts</h2><p>Most of the initial marketing attempts that I did were completely new to me. I’ve been working full-time in IT my entire career. I’ve never had much experience in sales, marketing, or building a brand.</p><p>It wasn’t that hard though. The concept is pretty simple. Ideally, if you’ve created a product, you’ve made it with a certain group of people in mind. Where can you find those people on the internet, or in person? Direct your efforts in those places where your ideal customers congregate.</p><p>After the first 10, it’s important to start developing more scalable marketing approaches. Some I have been trying out since then are creating content, YouTube videos, paid advertising on Google, Facebook, Twitter, and LinkedIn, and referral commissions — I’ve been sending out $15 Amazon gift cards each time one of my customers refers a friend who signs up.</p><ul><li>Do try lots of strategies</li><li>Don’t spam online communities</li><li>Do engage with relevant people one-on-one and get feedback</li><li>Do invest more time into what initially begins working</li><li>Do eventually move onto more scalable long-term strategies like content marketing, paid advertising, referral programs</li></ul>
                </div>
            </section>

                <section>
    <h3>Subscribe</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
          
            
           

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.rchase.com/my-first-saas-from-0-10-customers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297374</guid>
            <pubDate>Fri, 04 Dec 2020 00:15:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Body Ritual Among the Nacirema [pdf] (1956)]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25297359">thread link</a>) | @pmoriarty
<br/>
December 3, 2020 | https://www.sfu.ca/%7Epalys/Miner-1956-BodyRitualAmongTheNacirema.pdf | <a href="https://web.archive.org/web/*/https://www.sfu.ca/%7Epalys/Miner-1956-BodyRitualAmongTheNacirema.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>]/Index[35 18]/Info 34 0 R/Length 63/Prev 1231329/Root 36 0 R/Size 53/Type/XRef/W[1 2 1]&gt;&gt;stream
hÞbbd``b`ê�@‚ñ �`‰ýÜ- în !³
Hœ;ÄÀÄÈ°	¤˜�7ñŸqÝ/€œÑ	û
endstream
endobj
startxref
0
%%EOF
        
52 0 obj
&lt;&gt;stream
hÞb```a``Re`b`0ôcf@a&nbsp;3P–ã�Ã_Äéêôê„ÞŸ°Œÿ?0ˆs·zXÀÑÐAh
�La‡b†ƒ¼S›
æÖf_‘xezS¤�¸ˆ%„þèBùùÖ:
endstream
endobj
36 0 obj
&lt;&gt;
endobj
37 0 obj
&lt;&gt;
endobj
38 0 obj
&lt;&gt;stream
hÞ„TÉnÛ0ý•9¶(Ü7-@ À²ã$@’–Û™¶‰Ê’ 1�Ý¯ïPrâmÓ!ÎÂ7ó‡’
�!°@‚Œ€q2¦È8S&nbsp;(LNÅ ’\\à¤.ë6ota¼Ñ…þtsÚÆ�¶iŠ—w•;í|ÎUÎ&lt;æ˜Õ•#ßŒyÄÁõÐÖEnÜ¦3\˜ƒ[¥éo&amp;“Lwf
T•òVKÌM£[íl]aVêâÇ©0ÈhE¨_`£ËÎÐææã“™ßAð9à¸86æÜÖÍOS:;µ›�iMU˜n)8vž ÕFªiªÒlÜ°kívç@J,êý^ãîØìLEôð§ik¬+C¼ÐíZC�ûl°³ìÌ³©ÐøÃXYÊ
Ž1ƒˆã5DÞá=Äç�D¨ñ\£Á
nq‡–.'Æ÷Xa�
0&amp;±Å&gt;Ñ}1&lt;®NÄª¢^ÛjÛÓw…©áG8ÑÍu_œìtKZÀŒ&nbsp;Öxxâ­‡£Ò%µåùÂï©‘–Ú¹¦7ØPÑ�6ñìiœ	ÔÎbõü&amp;Ù&nbsp;Ï ×&nbsp;ÆGœš¡É#Ö³Ro;�ý€dY}XŽ¢F\ÐhrÑªÎliÍd?tÞq¯÷³ÛËûéÕ§‰.K»mu³³…ä,[Œæõ^WÞ8]Úb\mKC2äÎì¿Ñ·×ÍcøVZÛ¸ºíÕó“çÝÿ…}ÑÜ¿–¾ÛvÎ‹4Co�ýKò)·ú”áï.zt¾ßÃEýµ²Hƒ'úÜ×þð»]»]·äBBÿ\"ýz±¹â Xøj«@�P§ÜpÈ‰êý’%ô€é¹'üÝ1�!Œ¢¿Æù§Ÿ± ¡ûão#‘ˆß­òÞ’	ý&gt;úSñ�^Ù4%‚Kò%&nbsp;¸©³QQB1AcúËž5�‘4X"tæ-¾¢YKÓ_Õpc6
endstream
endobj
39 0 obj
&lt;&gt;stream
hÞt“[Oã0…ßý+æ±•¨ëñÄvüXº7­4Ë&gt;tC(A4�¤ñïñ%Î²ÊF‘ëóøœ3Éä…!ÔÀ+A£„•±È­�®b7Ð°õ÷Â¡gç[C@(î™Ì¹�A¸+­­àB	Jj.•UP™„¢cëmŸÃvçNî¶—Îç§;ô\ixsì~ývà.–•½C}Ù¸²¢ô·7¶8_�Œkc¤«+¾°E@–g	Ü&nbsp;H$ð��@’H
à:Cyª¨c…Q	œ C	¼FQ9ºìc‹	&lt;
vÖv@.GÛcÌa³Ùæš¡¹1ØahnÞeýaˆ&gt;jTÑ…ô¬Æ¥è&gt;­™m·Œ@êÙwØÅ m&amp;¾“þ'.!Ù×‚]ýw1Cèiþ2-8’Íüüý;SqßÍÕÊ¯ò0\ÞáGÛíË
.ê¦ê‚™€r™y÷Ocøy‹Èo™ÌW,î»ö
BÍQiò¡PZ.´O…ÊµmÉ§òÇpÌa‚úæXuu¹o`Óœºö¹}ju%C‹$‰»öôD�F5ÔÎ­Òg&nbsp;òÛÝ.ÝBÐÊýé]~0cTØý
endstream
endobj
40 0 obj
&lt;&gt;stream
hÞœ–wTT×‡Ï½wz¡Í0Òz“.0€ô. QfÊÃMlˆ¨@DE�&nbsp;€£¡H¬ˆb!(¨`HPb0Š¨¨dFÖJ|yyïåå÷Ç½ßÚgïs÷Ù{Ÿµ.$O./– ™'àz8ÓW…GÐ±ýx€¦0Yé©¾AîÁ@$/7zºÈ	ü‹ÞHü¾eèéO§ƒÿOÒ¬T¾È_ÄælN:KÄù"NÊ¤Ší3"¦Æ$ŠF‰™/JPÄrbŽ[ä¥Ÿ}ÙQÌìd[ÄâœSÙÉl1÷ˆx{†�#bÄGÄ\N¦ˆo‹X3I˜Ìñ[ql2‡™Š$¶8¬x›ˆ˜Ätñrp¤¸/8æp²âC¹¤¤fó¹qñº.K�njmÍ&nbsp;{r2“8�¡?“•Èä³é.)É©L^6‹gþ,qmé¢"[šZ[Zš™~Q¨ÿºø7%îí"½
øÜ3ˆÖ÷‡í¯üRê`ÌŠj³ë[Ì~:¶ wÿ›æ!$E}k¿ñÅyhây‰RmŒ�333�¸–‘¸&nbsp;¿ë:ü
}ñ=#ñv¿—‡îÊ‰e
“tqÝX)I)B&gt;==•ÉâÐ
ÿ&lt;Äÿ8ð¯óXÈ‰åð9<qd¨hÊ¸¼8q»yl®€›Â£syÿ©‰ÿ0ìozœk‘(õŸ�5ÊhÝ äç>€¢yPÜõßûæƒâ›¦:±8÷Ÿýû®p‰ø‘Î�ûçLg	ù‹kâk	Ð€$È&nbsp;t�!0VÀ87°ø�`ÖˆÉ€2A.Ø
@Øö‚JPêA#h'@8
.€Ëà:¸	î€`Œƒç`¼óa!2D�ä!UH2€Ì d¹A&gt;P ECqB¹Ð¨*…*¡Z¨ú:]€®BÐ=hš‚~…ÞÃL‚©°2¬
ÃØ	ö†ƒá5pœçÀùðN¸®ƒ�Áíðø:|�ŸÃ³@ˆ
QCâ‚ø!H,ÂG6 …H9R‡´ ]H/rA¦‘w(Š‚¢£Q¶(OTŠ…JCm@£*QGQí¨Ô-Ô(jõ	MF+¡
Ð6h/ô*t:]€.G7&nbsp;ÛÐ—ÐwÐãè7††ÑÁXa&lt;1á˜Ì:L1æ¦s3€ÃÌb±Xy¬Öë‡ebØì~ì1ì9ì vûGÄ©âÌpî¸—‡+Ç5áÎâq¸y¼^oƒ÷Ã³ñÙø|=¾?ŽŸ'Htv„`Ba3¡‚ÐB¸DxHxE$Õ‰ÖÄ"—¸‰XA<n¼b%¾#É�ôi.¤h’�´“t„tžt�ôŠl&k“Édy'¹‘|‘ü˜üv‚"a$á%Á–Ø(q%Ñ.1(ñb ©%é$¹v2g²\ò¤ä="" Éi)¼”¶”‹sjƒt•Ô)©a©yiŠ´©´Ÿt²t±t“ôuéi¬Œ¶Œ›="" [&_æ°Ìe™1="" bÑ ¸px”-”zÊ%Ê8cÕ¡zq¨eÔo¨ýÔyÙe²¡²y²u²gdghm›æek¢•ÐnÐ†hï—(="" qzÂy²ciË’Á%srŠrŽr¹b¹v¹;rïåéònò‰ò»å;ä) ô2*\r˜v¤*Ú*²o(Þw‚•ô••Ö)vêsšuvqöpnuÞ¯|qyz…¦â¨’ r¦rvej•¢j¯Êu-s="§úŒ.Kw¢'Ñ+è=ô5%5O5¡Z­Z¿Ú¼ºŽzˆzžz«ú#" ‚c#v£l£[cfsuÓw3w³yó¾^‹¡¯µo«wkn[g;l{›v‡ö¤ŽœŽ—nŽn³Îc]²®ƒnšn�îm="ŒC/Qï€ÞM}XßB?^¿Jÿ†l`iÀ58`0°½Ôz)oiÝÒaC’¡“a†a³á¨ÍÈÇ(Ï¨Ãè…±¦q„ñnã^ãO&amp;&amp;I&amp;õ&amp;LeLW˜æ™v™þj¦oÆ2«2»mN6w7ßhÞiþr™Á2Î²ƒËîZP,|-¶Yt[|´´²ä[¶XNYiZE[U[" 3¨="" f1ãŠ5ÚÚÙz£õiëw6–6›6¿ØÚ&Ú6Ùn.×yÎy^¿|ÌnÝŽiwk7bo·�¶?d?â æÀt¨sxâ¨áÈvlpœpÒsjp:æôÂÙÄ™ïÜæ<çbã²Þå¼+âêázèÚï&ãâvéöØ]Ý="Î½Ù}ÆÃÂc�ÇyO´§·çnÏa/e/–W£×Ì" «ëwôx“¼ƒ¼+½Ÿøèûð}º|aß¾{|®ÔzÉ[Ùáü¼üöø="ò×ñOóÿ">àPð4Ð407°7ˆÔô&amp;Ø9¸$øAˆnˆ0¤;T242´1t.Ì5¬4ld•ñªõ«®‡+„sÃ;#°¡
³«ÝVï]=iY9´FgMÖš«kÖ&amp;­=%ÅŒ:�Ž‹nŠþÀôcÖ1gc¼bªcfX.¬}¬çlGv{ŠcÇ)åLÄÚÅ–ÆNÆÙÅí‰›Šwˆ/�Ÿæºp+¹/&lt;jæý�$.$…%µ&amp;ã’£“Oñdx‰¼ž•”¬”�TƒÔ‚Ô‘4›´½i3|o~C:”¾&amp;½S@ýLõ	u…[…£öUo3C3OfIgñ²ú²õ³wdOä¸ç|½µŽµ®;W-wsîèz§õµ&nbsp;
1º7jlÌß8¾ÉcÓÑÍ„Í‰›È3É+Í{½%lKW¾rþ¦ü±­[›$
øÃÛl·ÕlGmçnïßa¾cÿŽO…ìÂkE&amp;EåEŠYÅ×¾2ýªâ«…�±;ûK,KîÂìâíÚí°ûh©tiNéØß=íeô²Â²×{£ö^-_V^³�°O¸o¤Â§¢s¿æþ]û?TÆWÞ©r®j­VªÞQ=w€}`ð&nbsp;ãÁ–åš¢š÷‡¸‡îÖzÔ¶×i×•ÆÎ8ü´&gt;´¾÷kÆ×�

E
�ðŽŒ
&lt;ÚÓhÕØØ¤ÔTÒ7›§ŽE»ù�ë7�-†-µ­´Ö¢ãà¸ðø³o£¿:á}¢û$ãdËwZßU·QÚ
Û¡öìö™ŽøŽ‘ÎðÎ�S+NuwÙvµ}oôý‘Ój§«ÎÈž)9K8›vá\Î¹Ùó©ç§/Ä]ëŽê~pqÕÅÛ==ý—¼/]¹ì~ùb¯Sï¹+vWN_µ¹zêãZÇuËëí}}m?XüÐÖoÙß~ÃêFçMë›]ËÎ:^¸åzëòm¯Û×ï¬¼302tw8rxä.ûîä½¤{/ïgÜŸ°é!úaá#©Gå�•×ý¨÷cëˆåÈ™Q×Ñ¾'AOŒ±Æžÿ”þÓ‡ñü§ä§åª�“f“§§Ü§n&gt;[ýlüyêóùé‚Ÿ¥®~¡ûâ»_é›Y53þ’ÿrá×âWò¯Ž¼^öº{Ööñ›ä7ós…oåß}Çx×û&gt;ìýÄ|æì‡Š�z»&gt;yz¸�¼°ð›÷„óû
endstream
endobj
41 0 obj
&lt;&gt;stream
hÞýýÿÿÿýýýüüüúûûùùúøøù÷÷øöö÷õööôõõóôôóóóòòóññòðññïððîïðíîïííîìííëììêëìéêëééêèèéçèèæçèåæçäåæãäåãäåâãäáâãàáâßàáÞßáÞßàÝÞßÜÝÞÛÜÞÚÛÝÙÛÜÙÚÛØÙÛ×ØÚÖ×ÙÕ×ØÔÖ×ÔÕ×ÓÔÖÒÓÕÑÓÔÐÒÓÏÑÓÏÐÒÎÏÑÍÏÐÌÎÐËÍÏËÌÎÊËÍÉËÌÈÊÌÇÉËÆÈÊÅÇÉÅÆÈÄÆÈÃÅÇÂÄÆÁÃÅÀÂÄÀÁÄ¿ÁÃ¾ÀÂ½¿Á¼¾À»½À»½¿º¼¾¹»½¸º¼·¹¼¶¸»¶¸ºµ·¹´¶¸³µ¸²´·²´¶±³µ°²´¯±´®°³­°²­¯±¬®°«­°ª¬¯©¬®©«­¨ª­§©¬¦¨«¥¨ª¥§©¤¦©£¥¨¢¤§¡¤¦¡£¥&nbsp;¢¥Ÿ¡¤ž&nbsp;£ž&nbsp;¢�Ÿ¡œž¡›�&nbsp;š�Ÿšœž™›ž˜š�—™œ—™›–˜›•—š”–™“•˜’”—‘“–‘“•�’•�‘”Ž�“Ž�’��‘ŒŽ‘‹��‹��ŠŒŽ‰‹ŽˆŠ�ˆŠŒ‡‰‹†ˆ‹…‡Š…†‰„†ˆƒ…ˆ‚„‡‚ƒ†�ƒ…€‚…�„€ƒ~€‚}‚|~�|}€{}z|z{~yz}xz|wy{wx{vwzuwytvxtuxstwrtvqsuprtpqtopsnprmoqmnplmpklojknikmijlhikghkfgjegidfhdegcdfbcfabe`ad`ac_`b^_a]^`\]`[\_[\^Z[]YZ\XY[WXZVWYUVXTUWSTVSSURRTQQSPPROOQNNPMMOLLNKKMJJLIIKHHJHGIGFHFFGEEFDDECCDBBCAAB@@A?&gt;@&gt;=?=&lt;&gt;&lt;;&lt;:9;98:8787576454343132011/00-..,--*,,)*+()*'((%&amp;'$%&amp;#$%""$ !# ÞH¼¿
endstream
endobj
42 0 obj
&lt;&gt;stream
hÞt™y�å}÷W6ì¶c{q�#ž‡t“7v|¤l‡'&amp;„‰	t¡•VÚûœ��Ù¹{fúž§ïcÎ��Ù�½µ‡Ž’�@H ƒ¹m§¸ÊÁðÖkcûMù¨$-&lt;$õ&gt;="®üóª«¶JU3OwÿŽï÷óûÍ¦–«&gt;Ö²iÓ¦ë·lßzïíßÿ›ÛôvûŒôôvÞøw7lyøkÚâ}æ/.ÃOù._÷©ÏßÒ&nbsp;¯»ê�?d®v?y�{ÓŸZ×]ßóÙ–�mÚtÍ—¾qÇC‡G_Ã�×:Üõÿ=¬e¾Z&gt;±©åÓ›ZþtSËçZZ&gt;UËÿÚÔò•––¯ojùfKË¢åž«ZúxËî––/ál�-dßò»M·lšùØ§?vòãèª¯^õÓ«»Zÿ±õWmï}‚ø“w&gt;õÝOïnŸ»†þÌmŸyû³Ÿüìù?K|nÅ÷úçËþàæŸ\û&gt;xÞ~]ëu?ù‹9KÜ­—Ï4¶úþÐú¡ð_­m?xÙwyó:nnmo&lt;Ðî¶Þê»Ç¶¨[ªáPŽ©ë*@¢!Øäè¿&amp;ÜMî§ÁËÚ�¬×IûõÂë“o¨%µ¬MÚ¤l#&nbsp;H²€H$ˆƒi&amp;d)‰—ŒÞúFì«Dü«Ì×¿	nÒ¶Ø÷’íîßó©ÔR
²ižIRt†e8 !VI“sShlj\¶q[S·�é[âÿ4ñ&gt;ÌG¸0ÁEÄtHT$RRIƒ–aWu
©YÉ³¿¨þ²ðk¢ðkãçï‚Ÿq?I=G¶7n9Ø8ì“URa¹6u|Ž²‹fÎ°§�l~Ã½êè�ÀŒXáòdžgôLÇü»ƒTpW¨#ÒÝwgïöî‰L‚g$ "	ß²ýz·î&gt;ê“U”¯[Ò…TD¥&nbsp;ÄgCêÌœ˜È†!~í¬3œÀ‰”ÄJÑQÀ#I¤ˆI�HÎ"•BKÙ¸¼”•–(IW²Zº¬ÊTûOÝ¯½ãó/$��OåOÌ.“ËsGJðÄrl`ššÌx&lt;š&lt;46Dzã`G_aaŒrå~ßÑ�Ê…WÀËÑ§ú×Èµ�}“÷ÃÛ
<h<|è6p÷ä®õ.²ký©ð‹ð¹sÕ“ëtû–·g}ã<Í±€ai?ž&+È€Ö³ j?†Åv]c²l)2rt`eõ™Œ¢d6…ˆ÷Ð�ÐÓ¤|a="">­¬ÈÎg‹p4¨’"Ê¤,áyQ‘J&lt;°_zhM$²(I‰Ž/H’H‰¢$ ƒ8YÄ‘Q³:,´[m3«iZVƒ�k‹ña!$í÷¹¶køò3úL
,¦êÁ
Y	ŽX½p&lt;$rT˜O²Ã¤Ù›$XZÈß‡É’GQ+”V)ËE8]aª�0"ã ÀŽ'ƒdr&lt;:ŒqËg8"Åq8�sRTAëá©ñâ(Qô££&nbsp;—	„È‰À@ªNŒë¹1JaqV¡À11ŽbãBŠ¬Æ[)Xq¾z©rì,uöhýôS`‘™�Í’±Ù±…ž¥úle6?C´»]oùúŠ½]&nbsp;�’ÁñaºŽø5ÇOÉ¼àÍ³4Oñ´˜Jáçâóøè\I¬ÀÎWŽmP'ŽUÏ^�Ç�
¯’#«»×·žÐWr3å|)¿hœ@ÿ¦lÖ[õVKWu™’
TªMR%/9"&nbsp;Ô*ñ|V€�ïNvÑ‡¯MNuf&lt;×ª¡ŸÀe8~Ùç‹ã°²&lt;Ár/x}‡«Dj†¨8”ìØÈ†ÇqiÖ©ú@þà.°�î
“ÃÁáxì*¯ŽSÁúÌ%ðVåÇë/’ë/=}áµSegÒ©ØÄ”m›*~&amp;EÄm$ˆˆ‡éñL¤—ê‰ôûÆîÚ³ë¡žmDÏ¶È[À�“;Ö�VÏ/Â‹g¼â]?9ùôKàRìÌÐ9¸v¨ò¨J´óîµe_Ç_�oû£D¨.f§¼R&nbsp;&amp;OWNNÃýÛ7\ß¿'[Õ&lt;ÍònîU«ðQµ
�î„Ûï“•‡)”áp±rXÅ$J$†#mñ6Fæ4Õ–ÊðùÖù¹,š£æÐšEÛ-;¯ïø+¢ýŒû¦;ì+Ì‘~0˜òO„Éð„?Ý»‡œi,/5zéXÖçóu2W¯ÔêS/&lt;Ñ_�¯¸¾Øtfn	,™3ÅI²\¬Z³p¡–
•¨RÈêƒ¬?�«6
�Ä{+þjtšø»ÆßÄPº÷ ØU8´0D-�ŸƒÏœ*¯®R««åÓÏ€£é#sdx®o~ïÂÑùÙ¹b�(Îš‹«àqz50CÖ¹N¸çp´o�ê�uì=ú@ÞOæF§s¡ƒcƒ#á!¢ýU·VöÕó9[kF
—‘(dyÈãe(‰á$vöM®�R#k‰ÓÁ†}dj–œ�ªç—áÚB¸{šªu9{îßßºÿrÿý÷t~'�äãBT "Bše+ó2VHY“tX?¢9Ç©ãÎja¾ôÜÊéÇ—ÎËçKÏ½þ9|©çùxÏ¾ÚpçcÁŽ.ªë@xç6pq×ÒaòÐÒÑ‰S°PÑó3Tûå¯\¾Ç}Ó'õvK]�H–†4�E)êñ×ÖŸ_¼°x¡zÒYªÝU½¿òÈÔÎÉýåî~±Oì‘w¢±âëœ*„¨ÚF¾H•
'gåñU´ˆ¢eè²÷ú‚êU¬,B‘¹4Åg2bM?1L
�Ùå¶Ýænó¿0þÃðóÄóaz‰‡™›PãI:ÃcmÂ¥Nb?Àåïêº•ì¾uÇ—oo\ÓµýÐÝß'Üìæ±aŠ€Ã¡`ß²jóÏ¬Qk�&lt;±p|vuef#OäO¼©»­š•-@TÈe-ødã«7W;‰v×p‡/|GÑº¼F¢UeY�·U[qdBv”ƒO‹
-RƒÅÃ{ÀÎpg÷9Ò³3q;L´Ò­çû|r¹€?ôÂ¹hÿQj½¯‚‹a¬g`”8˜xŽªf€
˜Q'“tÁ�,B²¤b¸{Û*ê¤RRˆÆõ�_âS¤Cc†gNPìñu~¾ûJå(Ãõ™ó/�sÑýËdßòî™»Jëå…™ê"Q]²WÖÁÅ‰“]óäB×Ã…ïÁîC{€ê`÷gö&amp;	Ü}O%÷&nbsp;�½¢B«�jËZ™RË9‡]U�˜	ð_9Š&amp;Ð8�Æ³]�€Æ…F÷-’ûVæ!Ú¯!Yˆh¿\ý`¿»âCÑl4îîdï&amp;%ZbEÀþ£–mEŸ¤&amp;u|a±0dUÍÑMu¼&lt;Ù±lð”Ä	X*Ò¬j
”`ŠµUàÞ »ŸWGª¿×.è¦†�ª€ˆ2Tó#�D"�X(²Y)M‰CÃ’²©,ŠS(Fg3$%ˆ&lt;�·IZtQeå4!§ÐÄèn{X:$úIqTˆóB†ósûBØÿ&nbsp;xì:ŒÐaê�|PÙ¯%T[²»“›Mº­`ÑÐ,ü’L!QÀÊ{Eü¤½»¤G`&nbsp;w³€o.Jøæâ›þŒÑ!\¤`|�%›Ki”F+�‚Æ—¥Æ&amp;ñ6R¼]¸Ÿß#Ž~&gt;HàE	ð²WÅ–a
ž(/;5…@²’Å(¦XºåÅñ#?’ V/ŽØ“D˜b�§ðËæ«à-tI&gt;FÊG•iÕTM[/*„R:"?	Ÿû�$^¢.‰—„gxBAÁhÿ`Ënu[}7Í”ØPÆŸÇno�¢†é)ˆ¨¶®™Ñc³ÅT%SL×Òóé…ØÓ¡·&amp;^�ý0yŽ&gt;—9ÁsbQ,3l!ƒ¢JDŽàþ‰¤Ðÿ`‘‚š0¤0‚ÚD²søÞŽèø‡ßØþ×k=ç½zèµ]¿¹Çýs6Ï”ÒSÄãÁD�ƒÍÑãÔ8H�¥ð8F„ŸN¤ÓØ°®DªYwÂ,J±Ù€Ž-°eqVÚNäbVÌˆFBM± ™èù9rëþqoã†d¢?ÖKÄû˜°ØT©Ù!*†ja�·S1+ç¼ñþÆ/Oÿæ©êoOýýÑ[�Þ²°­²“�eIñÒ¢âî‘q¨àô“k¯œýÙ?»ô¯¯¹?Õ¸o¥ë7á®ùí¯ú¶¿ŒÝ
,§†(¹„pïåþÅzG‡ÐÿEy÷=ðSñIš�±hˆ¡ˆÅ†Ç2ciAâDV$&amp;˜T†ÁUÅ!üº%pEaîu(Í±eÖËÑ&gt;üºýê-�O‚‡¤‡…¤°CØÉíüÊÏ¿ö‹Þ¿áßúÕ·…lÅVsÖ4Cª¨ñ:©ñ¼"4›	›Q:#±˜Ê²(ƒkshtŠÎs¡q¼"BŽÎD£T4šIñ@°Õqrj|r¬àïlÄ÷4jì%˜a&gt;*6‚ë^‘E:…™'Š˜¡d
©Zió³î½çÜ»O¸w¸‰†à~µñõ—·cÝ}Åýíû&gt;M°+Hi&gt;¥Ò‘(ƒ©ŒfïˆõàdÛ&nbsp;_*o“ÊÛÊJI­XÅ¢C8ÅI­×c3Ôvâ=&nbsp;?Ý$#ãã£±—â“‘äX�¯Œcö]ï&gt;ÿèÿþûçw¬Œ�•…ä4,­HuCS�ÉõL‘½S=³½‹;Îì&gt;Ûñ$Ñqn|ÁšaR×4œçùééÙâ"QZ4Á…ÈÉ¾Er©o_ñ&gt;Øñ›ÜKí£÷†÷&amp;RIþ8^ÀœÎâŒñ¤ cåƒj^wj”S+é6ÔÔLD¡ä:|¸¥­q½ôEñnRÜÆÆƒ�ÂµM$Òë¯ð$§`à‚rÑ*ÏRsåÙB=_±gœ…<q¤x²u¬Œª ‘í¯¸ ¸="">„ñT{’‡üjü±C0×lš¢m6_óåÙ•¹2}¦tÉ&amp;„¬ÀƒÉÆ^_¼0ÅÔaeJ5ªTÕt˜¬šDd¥äŒ1ùL™ÈLò3KÀA´@ÊóÙé2¸˜&gt;ž"«á~û1¸»—£'¨P*mz�×I’,;Š6Ej•Š2	ç«é–ˆ1Ú
è¶oÆ¿?¶§ŸØÝ?ÖÕÆÌp)A&amp;ŠÓÌ&lt;\Z2ŠKÔrq~jvN¶‚…8Ñþ–û¾û¢o®7¿‡‡ÊãØ}Çâ‡ááá\=BEfÒÇ/€…¶—õ�|‘,åfÌ5¸±é›¥º7ùd·U}Ñ(i9ËvL"gèšÒ„Ÿ=+êˆõÑ~F”¤¬ Ø,ÙtS
8RÛ£<t7hÜ,4¾À4þ„”ryn±Éøzœl¬gnÂwž®�Ü 6¯^|ü r¶ç(y´we'ëmŒî§oçh6»†'Ú÷Ùw6jùrµtÍwœ="" áljŽæ¹š="" 7Ÿ„‡ÇÒ="" ÅÒ,ëã±h*Ìlxœ÷Ã}Ý¥åjd9±ñ48n-mÖÈjyÖy†«'£oplÎðÄ¦;u¬uµ #f="" aïÒ†á½�;duî="°l+í9ÒGö9}" .Ï¨f™jÿ÷ßÝò‰ƒÒ„Àp="" šžhé‰="" €ú="" ózæ“ÇžgÍÕ2§ò¢½�«däjt•¯±Óiéfñai�×ø°áàh¸wi^ºâa.|="" ÌÚzÅ"+vÕª™¦láÙ’¨èv“ši½4ŒÈ'(!ic&dxÕÄnaj“óàr›û—ÈmuÞ#•÷Ôó˜)="" –�7ˆ¼aèêà½’<ƒu3âÂ<!4Ñ'*f¸Œ„xh{åg³\hƒÙáq<?'ä0öÄp¥àÖ‡�á�ÿ±Ð="ß÷›Ã�3¿{.¬UŽ�¤,ËÄÝO¤³”&amp;Ûó.á&amp;}*V}pÌ">RÁ°^™ÉÏÃR�KÙ”“ÒQ0‡ÈáÐáä^ŽÀ½©÷î’ïd­Z«€z.€[&amp;0hwÁ‡÷övR‡ö…¼l/ï^í%{VÏF^„Gê²Z¢ŠjÑÎ—jõòt¾Jä§Œ‚�ßVõj¥‰&lt;Ë¥Šcx<cnŒ‡b!œ·�Ÿ†‡œÚ8¨%–¹�×«?¨mlí_voºÿé+˜˜"(ìt†ã­ašÃƒhØølkuf�ûµøü<tjw¡¸Š#¨pwucñÆàb˜‚Æá¯pi4ØØÛoõï�Þu#îv1$›åxÐÕšiåei½Áo`a´�mú�¤è’ó­–! ¥ˆˆi�Æj|aÙjÞ®¨=":4mÕlnÎLdª9Õ½Fwèeô:J´¿ëVÜ¿ö‰ØŸÒ°g0_£üõäÒ:Xvæ«Óät­î,ÀÅ™L¤LMF¬ña0ÁùÓdj€�±" ›Š�‰7ŸðÍÎ�Ñ`(4Ò9jú;÷'öÀþ€fÇ¨˜Å`Ï)£d%ÅÂÃjv–‰$¬�0j…p@côØØ‘j’¤+ì1øó·'×_£^][="~â³#kd:ÏØœ­%+LS.y`je³NZuµ6" Œ¬!¤¤{×ÿ‘6;†—eazhmŽd4zaŠmm´="" ù="" ;¨_kÊŽw´¯›êéãÉb="" žwÈ�…µèœ,+ž¶ô²3u¶†k}3]dûïÜ¯]æ|ïj¯Øçh„_5ýÁ½Ù›×qb¨áÔpz�aÅŒ”ˆ="">Í6Qª)Ú2æLEË"“B¦‘Õ¡m,~LVN±.ò8Õ™,Ã‚ŸmK´±øÿxÜB»›‚ñË¤LÙÑ
:�ð?èhºi·§m¶m
óŽIÊ¦¢kjÎ)˜%�ÐK%¥�/Ä‡ÊTyÈÜy3¸=±kdˆÄð.H@¸‚Àª‚9ÙºS¡°dÚSVŸŽ¿\ÔLÃzFá,N“·ãXI`(FLráŒr\^•´€¦'Áó©3¡%r)4Xê„ãc\j”¥û#‡üD{ãËî—¿àÓ³*Ž‘¨ð^ü±nA1Å3a*ÂDØ(—h!�cÄ¥8�ê9¹‰›ž+HÖ)YW‘Š©ŽKc®O+�.Ð`ÛÆP±$‹ð;À¬!ç52�k:§j²*Ë
�¿©ªÙ,’Ò²=ÜÑ¶'ä3ÊiònÕ—Jq‰ˆiI›&amp;SNŽ+Âb^³±´ØZ¾
\žvH'•Ðb0–ähšjo|áÍ„¯ÉÄXs=Xð4§ÐÖó8h¦LKuÔ¢JLé¶nxÅpesä'
)ŠO¥¤¤Y=‡§G\&lt;
žis¿ƒÜ«ågHùu]+«9ÓÎ[DÞôù?àmR;AM°!6Ä³ƒëÉsPOe³®õ&nbsp;Ü±�Í&amp;ƒ…²áhLµÝÄm£;ÈöËmî¸û{Ÿ^,(y¸R�a22vÜˆû…}¤””+‹Ðœ*="×óªéÁ‰�álµÍÉZ:n$Ì&amp;­æÔ‚wÔ±ùøH‰*�xõô½Ì#Ñ!RÂNàm¢=òâµjTÍš6gL&lt;ž*¶LT4K÷ô_X½7I&nbsp;)‘N‰iÈ
HÁ’&amp;Kšl4ímÖÐÒ,x)}6‚++<r< #61d="" &{Ã�~®–šŒæ‰b4l„`$ÈÒ£ÔÝ="">èç'3åD�(&amp;h#
³ŒgÈc#¦U!Á´Àb"ÃÄèQ¾Ü¤|!\e®Q8[IŽå¨Ü˜Þ¹lîâî%ï—‚+ûE±9ÙËŽjMQS¦ím&nbsp;
eV9C(gÐ“¦²EHv�Ã¥\ÉW»{Õo2¾æ(ámÖ!žRñßg¦pÏ¬¡�kÑÉìésv6WR1ki&nbsp;X(:e“0Keµ×çbƒ¸i­½wƒ­Ìýñ=¤Äyž�%DnÂ¿¤BÙRMœ«d”tGÍ«%õ£ {ÛTÏ²½ ¸gñ´�…ˆÇ£»¬àéÌ˜¹Q­“òZY/eNGçÉùÈh¡Ž�°t?ÕG÷Gû&amp;ØJª”,…DÚ` ¾»ÀQ‘d8Êp"#¤"Á³¼ðÑ.\YL(Í_4)°V¤C6eµ¾}&nbsp;hcš!oÎ}Çý‰oápa÷ýà Ýô“þñád&lt;Ð3¹&gt;D
­ÇO]gìõJ�¬OÍçÖáãë‡ç©½á;ÔzóUy×‘n²ûÈ™ð%øÃóž<y}úðrø©žuòhÏžÊ½pÛ£ÁŽnªý×îwÝ|è ù”¼q°fÞ«à¼\€Ç~\è£n÷ð@â1?Ùçï‰î‡ñr’­Ð*­£óèiù="" ñÝ¡¯™wœ<Ôü�‘Ï¯]íþc[aÈ9‰óŽäÀw="" t7np'nv="" þ<{bðyl wêlÓ— âlˆŽvø7—d|5#0uq8iœçbšg"t˜‰r1="">-¦„¤@„ùÇ6�ñ–mÍÙœIÉ¦†cké\;FzÀ‡£mWvCí7º[ÜßúŒ¬•Â¼Azë ÔÜçp0›dI2�KùS,Îv¥›fÙfþ„fþdˆEËQZÎ‘m˜3Ù¤J©	yp7x´m«xy%6ë9GS4²8*JNs¦È)Ç1d&lt;§£º|‡û¤|L&gt;mÌçœœ]3V™VÖ�EìuEp±MÏâ‘^CE‚éNdll|ˆhêL{Ùýù¢ïøüÔúi°šš
–ÈP©Ó¾_Û¥ôëq‹ˆ›La
L™¥bžÌ•ªú,\\bË”`iØ-T
wžÖeÛVJj¤SüpWglƒÔ`´ë1Ðc�V£d¬z$sžk�*ñ¬EÙŒFÇÁHtl Hºèýp0&nbsp;ç£T,—™¬£í¿—Ê^N`±LqR,âma””yqx4mÏnŠëuq¾t¾0‚jßå’²/]›áëpyÅ(¬P«…r&gt;��”½ØaSõÖKÍg‚T:â'`÷H¾¥¢õÌ‰gÁšEs$š“ç°ÍºTkÞ@J-u˜-qíHØ�`ãK­ÊŒ1ãÌŠ!c—Åjƒsî)¬ñÊJˆ8®qõ7c™ÆmìýhÂ1Þ"·I#Þ"w¾Õ�ü�@v&lt;Ô›–††@!VNÖ2DûÿuÿkÙ‡Éœ1#W–#žê=W£¦óŽe„sª‘â²tdœÊžÀÂ‚Ö=2@3jU-¸àQ`@âtRc9üÐØþ3øE3Q&amp;Î’ˆ­fDž¥�Ôüy¤˜1‡A£¯ÍŸ¤ƒ,ÁÃBv�æê˜$ë™ÇŸ§ä¥Fª5mÒÌcâÑ
“0US?ödÁË–”ü,ÿqƒ˜'Yžü{’ÅàA¥Ã�&nbsp;4$u‘R—4w;{ªƒä`m%všu§zœZ�\(N;„DgSiÐþŽÛñŠ/7¦EÓ ÃÆã¤È»ñ—&lt;ÖVQ¸» ¶
œR/ªMgÉ›HÁ)kšfº?¼Þ,«Šªh6‡rÕÌbr“Ì¬†šéTIUdoè`âŠ£¹4—iÜÜØØÜð¹ÇEMÔãÚ"Ë¼W0éJ‡2ï�hžˆ{CJs3Ï‘ütÒeÕ¤Ë”MèXkPk%¬	÷ªFl3~Dl</y}úðrø©žuòhïžê½pû£ážnªý×îwý|è></r<></cnœ‡b!œ·�ÿ†‡œú8¨%–¹�×«?¨mlí_voºÿé+˜˜"(ìt†ã­ašãƒhøølkuf�ûµøü<tjw¡¸š#¨pwucñæàb˜‚æá¯pi4øøûoõï�þu#îv1$›åxðõšiåei½áo`a´�mú�¤è’ó­–!></t7hü,4¾à4þ„”ryn±éøzœl¬gnâwž®�ü 6¯^|ü></q¤x²u¬œª ‘í¯¸></h<|è6p÷ä®õ.²ký©ð‹ð¹sõ“ëtû–·g}ã<í±€ai?ž&+è€ö³></n¼b%¾#é�ôi.¤h’�´“t„tžt�ôšl&k“édy'¹‘|‘ü˜üv‚"a$á%á–ø(q%ñ.1(ñb></qd¨hê¸¼8q»yl®€›â£syÿ©‰ÿ0ìozœk‘(õÿ�5êhý äç></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sfu.ca/%7Epalys/Miner-1956-BodyRitualAmongTheNacirema.pdf">https://www.sfu.ca/%7Epalys/Miner-1956-BodyRitualAmongTheNacirema.pdf</a></em></p>]]>
            </description>
            <link>https://www.sfu.ca/%7Epalys/Miner-1956-BodyRitualAmongTheNacirema.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297359</guid>
            <pubDate>Fri, 04 Dec 2020 00:13:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes from Nowhere – A Utopian Novel of Hawaii in the Future – Free [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 2 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25297338">thread link</a>) | @ZguideZ
<br/>
December 3, 2020 | http://chrisdamitio.com/books/NotesFromNowhere.pdf | <a href="https://web.archive.org/web/*/http://chrisdamitio.com/books/NotesFromNowhere.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://chrisdamitio.com/books/NotesFromNowhere.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297338</guid>
            <pubDate>Fri, 04 Dec 2020 00:12:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A terminal-based workflow for research, writing, and programming]]>
            </title>
            <description>
<![CDATA[
Score 271 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25297268">thread link</a>) | @jerodsanto
<br/>
December 3, 2020 | http://jacobzelko.com/workflow/ | <a href="https://web.archive.org/web/*/http://jacobzelko.com/workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><em>My personal workflow for terminal-based coding, writing, research, and more!</em></p>

<p>Hello everyone!
It has been quite sometime since I last posted!
Suffice it to say, I have been immensely busy the past year but I am happy to say I am able to resurrect this blog! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p>

<p>I have thoroughly grown into my own workflow for programming, research, and writing.
Today, I am happy to be able to share it with you!</p>

<p>If you prefer to watch a video describing most of this entire process, here is an overview of my workflow from one of my <a href="https://www.twitch.tv/thecedarprince">live streams</a>.
It does not go as in-depth as this document but should serve as a strong complement to this post. <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<p><a href="https://youtu.be/2SLZQQfMF8E"><img src="http://jacobzelko.com/assets/workflow_youtube_vid.jpg" alt=""></a></p>



<p>I use <a href="https://github.com/alacritty/alacritty">Alacritty</a> as my terminal, <a href="https://www.zsh.org/">zsh</a> and <a href="https://ohmyz.sh/">oh-my-zsh</a> as my shell and plugin manager respectively, <a href="https://github.com/tmux/tmux">tmux</a> as my multiplexer, <a href="https://github.com/Peltoche/lsd">lsd</a> as my list command with fun icons, <a href="https://github.com/belluzj/fantasque-sans">Fantasque Sans Mono</a> as my typeface font, <a href="https://github.com/neovim/neovim">neovim</a> for my editor, <a href="https://github.com/junegunn/fzf">fzf</a> paired with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> for speedy and interactive file finding, <a href="https://github.com/sharkdp/bat">bat</a> an enhanced <code>cat</code> with a git diff gutter, <a href="https://github.com/jgm/pandoc">pandoc</a> for writing in markdown and LaTeX and outputting the piece to whatever file type I want, <a href="http://jacobzelko.com/setting-up-zotero/">Zotero</a> for managing my collection on scientific literature, <a href="https://github.com/ranger/ranger">ranger</a> as a terminal-based file explorer, and <a href="https://github.com/morhetz/gruvbox-contrib">gruvbox-dark</a> as my general color palette.</p>

<p>Here are gists to the relevant config files I use to modify my interface and user experience:</p>

<ul>
  <li>
<strong>neovim</strong>: <a href="https://gist.github.com/TheCedarPrince/7b9b51af4c146880f17c39407815b594">init.vim</a>
</li>
  <li>
<strong>Alacritty</strong>: <a href="https://gist.github.com/TheCedarPrince/7743091bd8743a7568b718f30bf707c2">.alacritty.yml</a>
</li>
  <li>
<strong>tmux</strong>: <a href="https://gist.github.com/TheCedarPrince/07f6f8f79b1451ec436ff8dee236ccdd">.tmux.conf</a>
</li>
  <li>
<strong>zsh</strong>: <a href="https://gist.github.com/TheCedarPrince/77afe2674803d965a0f5abd108337040">.zshrc</a>
</li>
</ul>

<p>Here is a picture of what that looks like altogether:</p>

<p><img src="http://jacobzelko.com/assets/workflow_layout.png" alt=""></p>

<h2 id="my-workflow-in-action-boom">My Workflow in Action <img title=":boom:" alt=":boom:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a5.png" height="20" width="20">
</h2>

<p>The following sections describe in broad strokes my workflow.
I mention some plugins that I use and are provided in my config files.
If you want to learn more about them, I encourage you to read through my config files or search for them.</p>

<h3 id="floating-terminals">Floating Terminals</h3>

<p><img src="http://jacobzelko.com/assets/float_term.gif" alt=""></p>

<p>Floating terminals are immensely powerful and I love them!
This enables me to quickly pull up a terminal and do some changes without having to split tmux panes or get out of vim.
Furthermore, what is awesome is that you can use it as a sort of <code>vim-slime</code> tool to send lines of code to the floating terminal.
This is a great feature as it uses your last used floating terminal for its target - therefore, if you switch between projects a lot, just switch your floating terminal accordingly.
No need to keep opening and closing REPL sessions and such!</p>

<h3 id="persistent-working-sessions-via-tmux">Persistent Working Sessions via tmux</h3>

<p><img src="http://jacobzelko.com/assets/tmux_restore.gif" alt=""></p>

<p>Though it is a little hard to see, I closed my terminal completely.
Oh no!
All my paneling and windows have disappeared! 
I’ll have to spend valuable time getting my workflow set back up… Or do I?</p>

<p>tmux can actually remember all these layouts with the plugins, <code>resurrect</code> and <code>continuum</code>. 
This is great for when your computer unexpectedly dies or crashes as everything is backed up at regular intervals you define!
Furthermore, pairing the (neo)vim plugin, <code>obsession</code>, allows tmux to also automatically recover vim layouts and sessions as well.
You will never have to worry about losing your terminal workflow again!</p>

<h3 id="mouse-mode">Mouse Mode</h3>

<p><img src="http://jacobzelko.com/assets/mouse_mode.gif" alt=""></p>

<p>tmux and (neo)vim also support mouse mode and interactivity!
I can quickly jump all over the place with my mouse or easily resize any opened pane.</p>

<h3 id="interactive-file-finding">Interactive File Finding</h3>

<p><img src="http://jacobzelko.com/assets/vim_fzf.gif" alt=""></p>

<p>I integrated the powerful file finding tool, <code>fzf</code>, with <code>ripgrep</code> to quickly find files I am looking to use. 
Then, in my (neo)vim configuration file, I merged these two together into one function that I can easily call while editing files in (neo)vim. 
find files I search for and pandoc to enable citations in pandoc, markdown, or TeX files.</p>

<h3 id="terminal-based-file-explorer">Terminal-Based File Explorer</h3>

<p><img src="http://jacobzelko.com/assets/ranger_mode.gif" alt=""></p>

<p>Furthermore, I also use the great tool, <code>ranger</code>, which allows me to have a terminal based file explorer.
It’s nice as it pops up in its own window and does not actually directly interfere with any of the background files being edited. 
It even has image preview capabilities!</p>

<h3 id="citation-engine--live-preview">Citation Engine &amp; Live Preview</h3>

<p><img src="http://jacobzelko.com/assets/citation_mode.gif" alt=""></p>

<p>As a researcher, this part gets me immensely excited!
While I am writing, I can actively insert citation keys into whatever I am working on via <code>vim-pandoc</code>.
With my config file, you will have to specify where your own .bib file exists.
Furthermore, <code>markdown-preview</code> allows me to preview my markdown in a web browser and <code>vim-latex-live-preview</code> allows me to view my current TeX files in a pdf viewer – works for subfiles too! 
This works for whenever I write TeX files or markdown files which makes writing a breeze!</p>

<p>If any of this section is confusing, I strongly encourage you to read my article on <a href="http://jacobzelko.com/personal-research-management/">Knowledge Management</a>.</p>



<p>These are parts of my workflow that I used to use.
They have been retired for a variety of reasons but all in an effort to improve my workflow.
I have kept these around in case anyone finds it useful!</p>

<h3 id="vim-slime-for-rapid-evaluation">Vim-Slime for Rapid Evaluation</h3>

<p><strong>Rationale for deprecation:</strong> I used to use <code>vim-slime</code> but deprecated it from my workflow because of the flexibility of floating terminals.
Not only could I use floating terminals to send code, I could also quickly flip through terminals in one button press.</p>

<p><img src="http://jacobzelko.com/assets/vim_slime.gif" alt=""></p>

<p>Here, I target my Julia REPL in a tmux panel and use the <code>vim-slime</code> plugin to send code from my Julia script opened in neovim to the Julia REPL for rapid evaluation. 
This config works for any time you want to target a window.
This also works for code chunks such as functions or loops!</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you found my workflow and toolchain interesting!
My dream would be for this workflow to serve as inspiration for your own workflow.
Make it your own and all the best!</p>

<p><em>If you spot any errors or have any questions, feel free to <a href="http://jacobzelko.com/contact/">contact me</a> about them!</em></p>

<hr>

        </div></div>]]>
            </description>
            <link>http://jacobzelko.com/workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297268</guid>
            <pubDate>Fri, 04 Dec 2020 00:05:02 GMT</pubDate>
        </item>
    </channel>
</rss>
